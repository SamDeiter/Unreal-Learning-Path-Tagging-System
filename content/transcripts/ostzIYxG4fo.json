[
  {
    "text": "Hello. So, thank you all for joining us.",
    "start": 1.68,
    "duration": 6.4
  },
  {
    "text": "So, my name is Sarah and I'm joined by",
    "start": 6.0,
    "duration": 5.12
  },
  {
    "text": "Salvador and uh we are both uh research",
    "start": 8.08,
    "duration": 5.84
  },
  {
    "text": "scientists at Epic Games. So, today",
    "start": 11.12,
    "duration": 4.399
  },
  {
    "text": "we're going to be talking through X",
    "start": 13.92,
    "duration": 4.0
  },
  {
    "text": "Aera, expressive audioddriven animation",
    "start": 15.519,
    "duration": 4.801
  },
  {
    "text": "for Metahumans. And this is technology",
    "start": 17.92,
    "duration": 4.48
  },
  {
    "text": "that's been part of Metahuman Animator",
    "start": 20.32,
    "duration": 5.28
  },
  {
    "text": "since 55. But with the 56 release, we've",
    "start": 22.4,
    "duration": 5.76
  },
  {
    "text": "introduced some new updates um including",
    "start": 25.6,
    "duration": 4.72
  },
  {
    "text": "audioddriven head motion, a greater",
    "start": 28.16,
    "duration": 5.12
  },
  {
    "text": "control of uh facial expression and also",
    "start": 30.32,
    "duration": 6.759
  },
  {
    "text": "our streaming solution.",
    "start": 33.28,
    "duration": 3.799
  },
  {
    "text": "So first off, what do we mean by",
    "start": 39.84,
    "duration": 4.719
  },
  {
    "text": "audioddriven animation? So we are",
    "start": 42.16,
    "duration": 4.8
  },
  {
    "text": "defining audioddriven animation as the",
    "start": 44.559,
    "duration": 5.441
  },
  {
    "text": "system for predicting lip sync, facial",
    "start": 46.96,
    "duration": 4.88
  },
  {
    "text": "expression and head motion of a",
    "start": 50.0,
    "duration": 3.36
  },
  {
    "text": "character directly from the audio",
    "start": 51.84,
    "duration": 3.68
  },
  {
    "text": "speech. So speech goes in, animation",
    "start": 53.36,
    "duration": 4.4
  },
  {
    "text": "comes out.",
    "start": 55.52,
    "duration": 4.32
  },
  {
    "text": "And why are we doing this? What is our",
    "start": 57.76,
    "duration": 4.959
  },
  {
    "text": "motivation here? So as you're all very",
    "start": 59.84,
    "duration": 5.12
  },
  {
    "text": "aware, facial animation is a key",
    "start": 62.719,
    "duration": 4.561
  },
  {
    "text": "component of character animation, but it",
    "start": 64.96,
    "duration": 4.0
  },
  {
    "text": "is incredibly difficult to do it very",
    "start": 67.28,
    "duration": 5.6
  },
  {
    "text": "well. So the problem is as humans we are",
    "start": 68.96,
    "duration": 6.88
  },
  {
    "text": "so used to seeing how humans faces move",
    "start": 72.88,
    "duration": 4.879
  },
  {
    "text": "and we're really tuned into like the the",
    "start": 75.84,
    "duration": 4.319
  },
  {
    "text": "subtleties of expression like the nuance",
    "start": 77.759,
    "duration": 4.161
  },
  {
    "text": "of articulation",
    "start": 80.159,
    "duration": 4.561
  },
  {
    "text": "and so if facial animation is not 100%",
    "start": 81.92,
    "duration": 4.879
  },
  {
    "text": "accurate we we really do notice and it",
    "start": 84.72,
    "duration": 4.32
  },
  {
    "text": "can be quite distracting and this is",
    "start": 86.799,
    "duration": 4.481
  },
  {
    "text": "especially challenging as we approach",
    "start": 89.04,
    "duration": 6.16
  },
  {
    "text": "photo realism as we are with metahuman.",
    "start": 91.28,
    "duration": 5.68
  },
  {
    "text": "Now, because audioddriven animation,",
    "start": 95.2,
    "duration": 5.12
  },
  {
    "text": "it's a machine learning approach, we are",
    "start": 96.96,
    "duration": 5.76
  },
  {
    "text": "training our models on real examples of",
    "start": 100.32,
    "duration": 5.2
  },
  {
    "text": "how real faces move during speech. It",
    "start": 102.72,
    "duration": 4.96
  },
  {
    "text": "does give us the potential to get much",
    "start": 105.52,
    "duration": 4.0
  },
  {
    "text": "closer to facial realism, to human",
    "start": 107.68,
    "duration": 5.2
  },
  {
    "text": "realism much more easily.",
    "start": 109.52,
    "duration": 5.36
  },
  {
    "text": "So, secondly, facial animation, it's",
    "start": 112.88,
    "duration": 3.919
  },
  {
    "text": "it's a laborious process. So,",
    "start": 114.88,
    "duration": 3.44
  },
  {
    "text": "classically, facial animation has been",
    "start": 116.799,
    "duration": 3.521
  },
  {
    "text": "done by hand, and this is incredibly",
    "start": 118.32,
    "duration": 3.839
  },
  {
    "text": "time consuming.",
    "start": 120.32,
    "duration": 3.52
  },
  {
    "text": "More recently, facial performance",
    "start": 122.159,
    "duration": 3.441
  },
  {
    "text": "capture is becoming more popular. Um,",
    "start": 123.84,
    "duration": 3.52
  },
  {
    "text": "this is also not particularly fast",
    "start": 125.6,
    "duration": 3.76
  },
  {
    "text": "process, especially if we start working",
    "start": 127.36,
    "duration": 4.16
  },
  {
    "text": "with like thousands, thousands of audio",
    "start": 129.36,
    "duration": 4.239
  },
  {
    "text": "samples, for instance.",
    "start": 131.52,
    "duration": 4.719
  },
  {
    "text": "So in contrast, audioddriven animation",
    "start": 133.599,
    "duration": 5.841
  },
  {
    "text": "is fast and it really does provide us",
    "start": 136.239,
    "duration": 4.72
  },
  {
    "text": "with the potential for really speeding",
    "start": 139.44,
    "duration": 3.84
  },
  {
    "text": "up the animation pipeline because it",
    "start": 140.959,
    "duration": 5.441
  },
  {
    "text": "gives us the ability to generate either",
    "start": 143.28,
    "duration": 5.12
  },
  {
    "text": "uh the the animation or at least a",
    "start": 146.4,
    "duration": 3.28
  },
  {
    "text": "starting point for an animator",
    "start": 148.4,
    "duration": 3.199
  },
  {
    "text": "incredibly quickly with just a few",
    "start": 149.68,
    "duration": 3.68
  },
  {
    "text": "clicks.",
    "start": 151.599,
    "duration": 4.241
  },
  {
    "text": "And then finally, hand animation",
    "start": 153.36,
    "duration": 3.76
  },
  {
    "text": "performance capture. These are really",
    "start": 155.84,
    "duration": 3.039
  },
  {
    "text": "great for generating offline content",
    "start": 157.12,
    "duration": 3.759
  },
  {
    "text": "where we know all of our speech content",
    "start": 158.879,
    "duration": 4.0
  },
  {
    "text": "ahead of time, but audioddriven",
    "start": 160.879,
    "duration": 4.0
  },
  {
    "text": "animation, it opens up the opportunity",
    "start": 162.879,
    "duration": 4.481
  },
  {
    "text": "for interaction. And this is because we",
    "start": 164.879,
    "duration": 6.481
  },
  {
    "text": "can generate animation on the fly.",
    "start": 167.36,
    "duration": 6.08
  },
  {
    "text": "And this is really this is really so as",
    "start": 171.36,
    "duration": 3.599
  },
  {
    "text": "audio streams in, we can stream out",
    "start": 173.44,
    "duration": 3.28
  },
  {
    "text": "animation. And this is really essential",
    "start": 174.959,
    "duration": 4.721
  },
  {
    "text": "for things like AI characters or really",
    "start": 176.72,
    "duration": 4.64
  },
  {
    "text": "any type of interaction in the",
    "start": 179.68,
    "duration": 4.479
  },
  {
    "text": "metaverse. And so in this talk today,",
    "start": 181.36,
    "duration": 5.44
  },
  {
    "text": "Salvador will be talking through uh our",
    "start": 184.159,
    "duration": 4.321
  },
  {
    "text": "streaming real-time solution in the",
    "start": 186.8,
    "duration": 5.32
  },
  {
    "text": "second part of the talk.",
    "start": 188.48,
    "duration": 3.64
  },
  {
    "text": "So today, first I'm going to be going",
    "start": 192.4,
    "duration": 4.479
  },
  {
    "text": "through the research behind our",
    "start": 194.64,
    "duration": 3.92
  },
  {
    "text": "audioddriven animation in Metahuman",
    "start": 196.879,
    "duration": 3.841
  },
  {
    "text": "Animator. I'll be talking you through",
    "start": 198.56,
    "duration": 4.64
  },
  {
    "text": "our training data, the model that we",
    "start": 200.72,
    "duration": 4.4
  },
  {
    "text": "train and how we train it. And then I'll",
    "start": 203.2,
    "duration": 3.759
  },
  {
    "text": "give a very quick demonstration of how",
    "start": 205.12,
    "duration": 3.92
  },
  {
    "text": "you can use this in the engine. and then",
    "start": 206.959,
    "duration": 3.681
  },
  {
    "text": "I'll hand over to Salvador who'll talk",
    "start": 209.04,
    "duration": 5.8
  },
  {
    "text": "you through the streaming solution.",
    "start": 210.64,
    "duration": 4.2
  },
  {
    "text": "Okay, so we need to train our model on",
    "start": 215.68,
    "duration": 5.279
  },
  {
    "text": "examples of how human faces and heads",
    "start": 218.239,
    "duration": 6.56
  },
  {
    "text": "move during speech. There are some very",
    "start": 220.959,
    "duration": 6.481
  },
  {
    "text": "small number of existing speech and 3D",
    "start": 224.799,
    "duration": 4.401
  },
  {
    "text": "animation data sets that we can use for",
    "start": 227.44,
    "duration": 3.76
  },
  {
    "text": "this. But all of them are very limited.",
    "start": 229.2,
    "duration": 3.44
  },
  {
    "text": "So some are limited in terms of their",
    "start": 231.2,
    "duration": 3.759
  },
  {
    "text": "size. Other others are limited in terms",
    "start": 232.64,
    "duration": 4.72
  },
  {
    "text": "of their expressivity and none of them",
    "start": 234.959,
    "duration": 4.401
  },
  {
    "text": "contain any examples of laughter,",
    "start": 237.36,
    "duration": 4.64
  },
  {
    "text": "singing, non-verbal sounds and none of",
    "start": 239.36,
    "duration": 4.64
  },
  {
    "text": "them have any head motion or tongue",
    "start": 242.0,
    "duration": 5.2
  },
  {
    "text": "motion in them. So for these reasons, we",
    "start": 244.0,
    "duration": 6.48
  },
  {
    "text": "decided to capture our own data.",
    "start": 247.2,
    "duration": 5.119
  },
  {
    "text": "And we spent quite a lot of time",
    "start": 250.48,
    "duration": 3.92
  },
  {
    "text": "designing the data before we set out to",
    "start": 252.319,
    "duration": 4.801
  },
  {
    "text": "capture it. So, we're probably all aware",
    "start": 254.4,
    "duration": 4.0
  },
  {
    "text": "here that machine learning models,",
    "start": 257.12,
    "duration": 3.76
  },
  {
    "text": "they're really only as good as the data",
    "start": 258.4,
    "duration": 4.48
  },
  {
    "text": "from which they've been trained, both in",
    "start": 260.88,
    "duration": 4.64
  },
  {
    "text": "terms of quality and in terms of",
    "start": 262.88,
    "duration": 5.12
  },
  {
    "text": "diversity. So, we want to make sure that",
    "start": 265.52,
    "duration": 4.32
  },
  {
    "text": "we collect all the different types of",
    "start": 268.0,
    "duration": 3.44
  },
  {
    "text": "behaviors that we want our model to be",
    "start": 269.84,
    "duration": 3.919
  },
  {
    "text": "able to animate to.",
    "start": 271.44,
    "duration": 4.4
  },
  {
    "text": "So, first up, of course, we want our",
    "start": 273.759,
    "duration": 4.16
  },
  {
    "text": "model to have really high quality,",
    "start": 275.84,
    "duration": 5.04
  },
  {
    "text": "really articulate lip sync. And for this",
    "start": 277.919,
    "duration": 4.801
  },
  {
    "text": "reason, we collect a few hundred",
    "start": 280.88,
    "duration": 3.599
  },
  {
    "text": "phonetically balanced sentences taken",
    "start": 282.72,
    "duration": 3.44
  },
  {
    "text": "from the Harvard corpus which is cited",
    "start": 284.479,
    "duration": 4.241
  },
  {
    "text": "below. By phonetically balanced I mean",
    "start": 286.16,
    "duration": 5.039
  },
  {
    "text": "it contain they contain like a diverse",
    "start": 288.72,
    "duration": 4.4
  },
  {
    "text": "array of different phonms or speech",
    "start": 291.199,
    "duration": 3.681
  },
  {
    "text": "sounds in many different contexts. So",
    "start": 293.12,
    "duration": 2.72
  },
  {
    "text": "they've got a good coverage of",
    "start": 294.88,
    "duration": 3.52
  },
  {
    "text": "coarticulation which um our model needs",
    "start": 295.84,
    "duration": 4.799
  },
  {
    "text": "to learn from.",
    "start": 298.4,
    "duration": 4.16
  },
  {
    "text": "An example of one of these sentences is",
    "start": 300.639,
    "duration": 3.681
  },
  {
    "text": "the birch canoe slid on the smooth",
    "start": 302.56,
    "duration": 3.68
  },
  {
    "text": "planks. And we collect performances of",
    "start": 304.32,
    "duration": 4.24
  },
  {
    "text": "these sentences in a very neutral a",
    "start": 306.24,
    "duration": 4.88
  },
  {
    "text": "neutral style.",
    "start": 308.56,
    "duration": 4.4
  },
  {
    "text": "Having said that, we do also want to",
    "start": 311.12,
    "duration": 3.84
  },
  {
    "text": "capture expression and really emotional",
    "start": 312.96,
    "duration": 5.76
  },
  {
    "text": "speech too. So we designed a list of 21",
    "start": 314.96,
    "duration": 5.76
  },
  {
    "text": "different emotion emotional categories.",
    "start": 318.72,
    "duration": 3.44
  },
  {
    "text": "And we took this list from different",
    "start": 320.72,
    "duration": 4.4
  },
  {
    "text": "academic sources. For each of these 21",
    "start": 322.16,
    "duration": 4.64
  },
  {
    "text": "emotions, we scripted three or four",
    "start": 325.12,
    "duration": 3.2
  },
  {
    "text": "different sentences. And these were",
    "start": 326.8,
    "duration": 3.44
  },
  {
    "text": "designed to really get our actor to",
    "start": 328.32,
    "duration": 4.0
  },
  {
    "text": "incite those emotions or to perform",
    "start": 330.24,
    "duration": 4.399
  },
  {
    "text": "those emotions. And for each of these",
    "start": 332.32,
    "duration": 4.56
  },
  {
    "text": "sentences, we collected performances of",
    "start": 334.639,
    "duration": 4.081
  },
  {
    "text": "them at varying intensities from low",
    "start": 336.88,
    "duration": 5.28
  },
  {
    "text": "intensity up to exaggerated intensity.",
    "start": 338.72,
    "duration": 5.6
  },
  {
    "text": "So an example of a surprise sentence",
    "start": 342.16,
    "duration": 4.4
  },
  {
    "text": "might be, \"You're here. I didn't know",
    "start": 344.32,
    "duration": 5.68
  },
  {
    "text": "you were coming back.\"",
    "start": 346.56,
    "duration": 4.8
  },
  {
    "text": "Now, the problem with these first two",
    "start": 350.0,
    "duration": 3.44
  },
  {
    "text": "categories is that when we ask our actor",
    "start": 351.36,
    "duration": 3.839
  },
  {
    "text": "to perform them, we provide the prompt",
    "start": 353.44,
    "duration": 3.28
  },
  {
    "text": "for them on the screen and they read the",
    "start": 355.199,
    "duration": 3.121
  },
  {
    "text": "prompt from the screen. So because of",
    "start": 356.72,
    "duration": 3.44
  },
  {
    "text": "this, we are not collecting natural",
    "start": 358.32,
    "duration": 4.96
  },
  {
    "text": "blinking or natural head motion.",
    "start": 360.16,
    "duration": 6.08
  },
  {
    "text": "So what we also do is we include several",
    "start": 363.28,
    "duration": 5.199
  },
  {
    "text": "sessions of unscripted diatic",
    "start": 366.24,
    "duration": 4.079
  },
  {
    "text": "conversation. This is essentially a",
    "start": 368.479,
    "duration": 3.761
  },
  {
    "text": "conversation between our actor on stage",
    "start": 370.319,
    "duration": 4.241
  },
  {
    "text": "and somebody else.",
    "start": 372.24,
    "duration": 4.48
  },
  {
    "text": "And although this is unscripted, we do",
    "start": 374.56,
    "duration": 3.6
  },
  {
    "text": "provide some prompts just to keep the",
    "start": 376.72,
    "duration": 3.759
  },
  {
    "text": "conversation flowing if necessary. So",
    "start": 378.16,
    "duration": 4.0
  },
  {
    "text": "one of these prompts might be where",
    "start": 380.479,
    "duration": 3.521
  },
  {
    "text": "would you go on vacation if you had no",
    "start": 382.16,
    "duration": 4.4
  },
  {
    "text": "budget.",
    "start": 384.0,
    "duration": 4.56
  },
  {
    "text": "And in these sessions, this means we're",
    "start": 386.56,
    "duration": 3.28
  },
  {
    "text": "capturing because it's it's completely",
    "start": 388.56,
    "duration": 2.72
  },
  {
    "text": "unscripted and free flowing. We're",
    "start": 389.84,
    "duration": 3.52
  },
  {
    "text": "capturing natural blinks, natural head",
    "start": 391.28,
    "duration": 4.4
  },
  {
    "text": "motions, and all these spontaneous",
    "start": 393.36,
    "duration": 3.6
  },
  {
    "text": "expressions and really interesting",
    "start": 395.68,
    "duration": 2.72
  },
  {
    "text": "things that come from real life",
    "start": 396.96,
    "duration": 4.44
  },
  {
    "text": "interaction.",
    "start": 398.4,
    "duration": 3.0
  },
  {
    "text": "And finally, we also want to be able to",
    "start": 401.84,
    "duration": 4.56
  },
  {
    "text": "animate non-verbal sounds. So, as",
    "start": 403.68,
    "duration": 4.0
  },
  {
    "text": "humans, we make all these different",
    "start": 406.4,
    "duration": 3.28
  },
  {
    "text": "noises and sounds that they're not",
    "start": 407.68,
    "duration": 3.519
  },
  {
    "text": "directly related to verbal",
    "start": 409.68,
    "duration": 2.959
  },
  {
    "text": "communication, but we make them very",
    "start": 411.199,
    "duration": 3.761
  },
  {
    "text": "frequently. things like coughs or",
    "start": 412.639,
    "duration": 4.481
  },
  {
    "text": "clearing our throat or sniffs or",
    "start": 414.96,
    "duration": 4.32
  },
  {
    "text": "laughter, even tuts. All of these",
    "start": 417.12,
    "duration": 3.519
  },
  {
    "text": "things, they're all very interesting. We",
    "start": 419.28,
    "duration": 4.319
  },
  {
    "text": "want to be able to animate these. So, we",
    "start": 420.639,
    "duration": 5.441
  },
  {
    "text": "put together a list of the commonly used",
    "start": 423.599,
    "duration": 4.32
  },
  {
    "text": "ones and we also capture repetitions of",
    "start": 426.08,
    "duration": 5.16
  },
  {
    "text": "each of these.",
    "start": 427.919,
    "duration": 3.321
  },
  {
    "text": "So, for each of these categories, we",
    "start": 434.479,
    "duration": 4.801
  },
  {
    "text": "capture the synchronized audio, face,",
    "start": 436.88,
    "duration": 6.56
  },
  {
    "text": "and body motion from 10 actors.",
    "start": 439.28,
    "duration": 6.24
  },
  {
    "text": "We collect audio from a microphone",
    "start": 443.44,
    "duration": 4.96
  },
  {
    "text": "that's attached to our actor's chest and",
    "start": 445.52,
    "duration": 4.959
  },
  {
    "text": "we capture that at a sounding rate of 44",
    "start": 448.4,
    "duration": 4.799
  },
  {
    "text": "kHz. We capture facial performance from",
    "start": 450.479,
    "duration": 5.201
  },
  {
    "text": "this stereo HMC. So, we're capturing a",
    "start": 453.199,
    "duration": 4.0
  },
  {
    "text": "top view and a lower view of the face",
    "start": 455.68,
    "duration": 3.12
  },
  {
    "text": "simultaneously.",
    "start": 457.199,
    "duration": 4.801
  },
  {
    "text": "We capture the body with this 24 camera",
    "start": 458.8,
    "duration": 5.6
  },
  {
    "text": "motion capture system at 100 frames per",
    "start": 462.0,
    "duration": 4.16
  },
  {
    "text": "second.",
    "start": 464.4,
    "duration": 3.6
  },
  {
    "text": "So, next I'll talk you through how we",
    "start": 466.16,
    "duration": 6.439
  },
  {
    "text": "process the face and the body data.",
    "start": 468.0,
    "duration": 4.599
  },
  {
    "text": "So let's start with the face.",
    "start": 473.28,
    "duration": 5.84
  },
  {
    "text": "So for each of our actors, we first",
    "start": 476.639,
    "duration": 4.881
  },
  {
    "text": "create a personalized metahuman facial",
    "start": 479.12,
    "duration": 4.24
  },
  {
    "text": "control rig.",
    "start": 481.52,
    "duration": 4.72
  },
  {
    "text": "And then to what we do is we solve their",
    "start": 483.36,
    "duration": 5.44
  },
  {
    "text": "facial performance from their video to",
    "start": 486.24,
    "duration": 5.04
  },
  {
    "text": "their personalized control rig. And we",
    "start": 488.8,
    "duration": 4.399
  },
  {
    "text": "do all this using the like the fantastic",
    "start": 491.28,
    "duration": 3.44
  },
  {
    "text": "tooling that's available in Metahuman",
    "start": 493.199,
    "duration": 3.28
  },
  {
    "text": "Animator.",
    "start": 494.72,
    "duration": 3.599
  },
  {
    "text": "And this is available for anyone to use.",
    "start": 496.479,
    "duration": 3.521
  },
  {
    "text": "So, let me show you some results of this",
    "start": 498.319,
    "duration": 5.0
  },
  {
    "text": "facial solve",
    "start": 500.0,
    "duration": 3.319
  },
  {
    "text": "with tenure. Zuzies have all the more",
    "start": 505.599,
    "duration": 4.641
  },
  {
    "text": "leisure for yotting, but her",
    "start": 508.4,
    "duration": 4.96
  },
  {
    "text": "publications are no good. He ripped down",
    "start": 510.24,
    "duration": 5.52
  },
  {
    "text": "the cellophane carefully and laid three",
    "start": 513.36,
    "duration": 5.44
  },
  {
    "text": "dogs on the tin foil.",
    "start": 515.76,
    "duration": 5.36
  },
  {
    "text": "So, we did this for all of the actors in",
    "start": 518.8,
    "duration": 3.599
  },
  {
    "text": "our data set. So, here are some more",
    "start": 521.12,
    "duration": 3.44
  },
  {
    "text": "examples. And this gives us a really",
    "start": 522.399,
    "duration": 4.081
  },
  {
    "text": "nice representation of how the faces are",
    "start": 524.56,
    "duration": 5.279
  },
  {
    "text": "moving during speech.",
    "start": 526.48,
    "duration": 5.359
  },
  {
    "text": "So the the metahumor facial control rig",
    "start": 529.839,
    "duration": 4.801
  },
  {
    "text": "has over 160 controls on it, but we",
    "start": 531.839,
    "duration": 4.401
  },
  {
    "text": "don't use them all. We're kind of",
    "start": 534.64,
    "duration": 3.6
  },
  {
    "text": "interested in keeping the broad facial",
    "start": 536.24,
    "duration": 4.56
  },
  {
    "text": "motion. Um so for this we keep the",
    "start": 538.24,
    "duration": 4.4
  },
  {
    "text": "primary controls and we remove the",
    "start": 540.8,
    "duration": 4.32
  },
  {
    "text": "tweakers. We also at this stage remove",
    "start": 542.64,
    "duration": 4.08
  },
  {
    "text": "the eye gaze controls because as I",
    "start": 545.12,
    "duration": 3.279
  },
  {
    "text": "previously mentioned most of our data is",
    "start": 546.72,
    "duration": 3.52
  },
  {
    "text": "from red performances, red prompts from",
    "start": 548.399,
    "duration": 3.521
  },
  {
    "text": "a screen. So at this stage we're not",
    "start": 550.24,
    "duration": 5.44
  },
  {
    "text": "interested in modeling eye gaze.",
    "start": 551.92,
    "duration": 6.0
  },
  {
    "text": "So after this step this results in a",
    "start": 555.68,
    "duration": 4.96
  },
  {
    "text": "reduced set of 81 controls that encode",
    "start": 557.92,
    "duration": 4.56
  },
  {
    "text": "the facial performance. So this means we",
    "start": 560.64,
    "duration": 4.319
  },
  {
    "text": "end up with this 81dimensional vector",
    "start": 562.48,
    "duration": 5.359
  },
  {
    "text": "for every frame in our uh video in our",
    "start": 564.959,
    "duration": 5.201
  },
  {
    "text": "captured video. And this representation",
    "start": 567.839,
    "duration": 4.641
  },
  {
    "text": "is essentially what we want our model to",
    "start": 570.16,
    "duration": 4.16
  },
  {
    "text": "output. This is the representation of",
    "start": 572.48,
    "duration": 5.32
  },
  {
    "text": "the model output.",
    "start": 574.32,
    "duration": 3.48
  },
  {
    "text": "So, I'm just going to talk about the",
    "start": 580.48,
    "duration": 2.96
  },
  {
    "text": "tongue quickly because the tongue is",
    "start": 581.76,
    "duration": 3.12
  },
  {
    "text": "something that Metahuman Animator does",
    "start": 583.44,
    "duration": 4.079
  },
  {
    "text": "not solve for. When the tongue is",
    "start": 584.88,
    "duration": 5.12
  },
  {
    "text": "visible, it's actually incredibly",
    "start": 587.519,
    "duration": 4.801
  },
  {
    "text": "important to our perception of speech",
    "start": 590.0,
    "duration": 4.08
  },
  {
    "text": "and it really aids kind of speech",
    "start": 592.32,
    "duration": 4.8
  },
  {
    "text": "interpretability and understanding.",
    "start": 594.08,
    "duration": 5.199
  },
  {
    "text": "However, most of the time the tongue is",
    "start": 597.12,
    "duration": 4.24
  },
  {
    "text": "oluded by like the teeth and the tongue",
    "start": 599.279,
    "duration": 3.601
  },
  {
    "text": "and the lips and you can't actually see",
    "start": 601.36,
    "duration": 3.52
  },
  {
    "text": "it. So, it's almost impossible to track",
    "start": 602.88,
    "duration": 6.079
  },
  {
    "text": "the tongue directly from the video.",
    "start": 604.88,
    "duration": 6.32
  },
  {
    "text": "So instead we leveraged the ex this is",
    "start": 608.959,
    "duration": 5.521
  },
  {
    "text": "existing tongue mocap data set called",
    "start": 611.2,
    "duration": 7.68
  },
  {
    "text": "IMT 2022 or 22. This was actually",
    "start": 614.48,
    "duration": 7.2
  },
  {
    "text": "captured as a collaboration between Epic",
    "start": 618.88,
    "duration": 5.92
  },
  {
    "text": "Games and Haskins Lab at Yale a few",
    "start": 621.68,
    "duration": 4.96
  },
  {
    "text": "years ago now. And it contains",
    "start": 624.8,
    "duration": 3.76
  },
  {
    "text": "approximately two and a half hours of a",
    "start": 626.64,
    "duration": 5.04
  },
  {
    "text": "single actor or my boss uh saying uh",
    "start": 628.56,
    "duration": 5.6
  },
  {
    "text": "phonetically balanced uh sentences and",
    "start": 631.68,
    "duration": 4.0
  },
  {
    "text": "it contains the speech together with the",
    "start": 634.16,
    "duration": 4.72
  },
  {
    "text": "tongue mocap data. The tongue moap data",
    "start": 635.68,
    "duration": 5.839
  },
  {
    "text": "was collected using an electromagnetic",
    "start": 638.88,
    "duration": 5.68
  },
  {
    "text": "articular graph or an EMA device. And it",
    "start": 641.519,
    "duration": 5.521
  },
  {
    "text": "collected the motion of 10 sensors",
    "start": 644.56,
    "duration": 4.8
  },
  {
    "text": "positioned on the tongue, the lips, and",
    "start": 647.04,
    "duration": 4.239
  },
  {
    "text": "the jaw. And you can see the lip ones on",
    "start": 649.36,
    "duration": 4.479
  },
  {
    "text": "that image there on the right.",
    "start": 651.279,
    "duration": 4.401
  },
  {
    "text": "And then using both the position and the",
    "start": 653.839,
    "duration": 3.761
  },
  {
    "text": "orientation of these sensors, we solved",
    "start": 655.68,
    "duration": 5.76
  },
  {
    "text": "these to the metahuman uh tongue tongue",
    "start": 657.6,
    "duration": 6.08
  },
  {
    "text": "controls as you can see down there on",
    "start": 661.44,
    "duration": 4.48
  },
  {
    "text": "the right. And I should say that this",
    "start": 663.68,
    "duration": 3.839
  },
  {
    "text": "data set is actually available for",
    "start": 665.92,
    "duration": 4.96
  },
  {
    "text": "anyone to use. It has been released.",
    "start": 667.519,
    "duration": 5.281
  },
  {
    "text": "So the way that we use this data set is",
    "start": 670.88,
    "duration": 5.36
  },
  {
    "text": "to generate synthetic tongue animation",
    "start": 672.8,
    "duration": 6.4
  },
  {
    "text": "for our captured data. So the first step",
    "start": 676.24,
    "duration": 4.96
  },
  {
    "text": "in this process is that we train this",
    "start": 679.2,
    "duration": 4.56
  },
  {
    "text": "speechto tongue model which is trained",
    "start": 681.2,
    "duration": 6.0
  },
  {
    "text": "completely on the IMT22 data set and it",
    "start": 683.76,
    "duration": 5.28
  },
  {
    "text": "learns to map from the audio of the",
    "start": 687.2,
    "duration": 5.04
  },
  {
    "text": "IMT22 data set to the tongue uh rig",
    "start": 689.04,
    "duration": 6.08
  },
  {
    "text": "controls of this data set.",
    "start": 692.24,
    "duration": 4.64
  },
  {
    "text": "And then once this has been trained, we",
    "start": 695.12,
    "duration": 4.32
  },
  {
    "text": "simply input the audio from our captured",
    "start": 696.88,
    "duration": 4.8
  },
  {
    "text": "data. And this gives us a prediction of",
    "start": 699.44,
    "duration": 4.079
  },
  {
    "text": "how the tongue's moving for that for",
    "start": 701.68,
    "duration": 3.68
  },
  {
    "text": "those that captured data. And we merge",
    "start": 703.519,
    "duration": 3.76
  },
  {
    "text": "these controls with the cap the solved",
    "start": 705.36,
    "duration": 5.4
  },
  {
    "text": "facial controls.",
    "start": 707.279,
    "duration": 3.481
  },
  {
    "text": "Okay. So next I'll talk about the body",
    "start": 710.959,
    "duration": 6.161
  },
  {
    "text": "data. So let me just play this video.",
    "start": 713.279,
    "duration": 6.8
  },
  {
    "text": "So the first thing that we did is we",
    "start": 717.12,
    "duration": 7.2
  },
  {
    "text": "retargeted our captured uh mocap to the",
    "start": 720.079,
    "duration": 6.32
  },
  {
    "text": "metahuman skeleton. As you can see on",
    "start": 724.32,
    "duration": 5.519
  },
  {
    "text": "the left, we were careful to choose the",
    "start": 726.399,
    "duration": 5.68
  },
  {
    "text": "skeleton preset that would best match",
    "start": 729.839,
    "duration": 4.24
  },
  {
    "text": "the proportions of our actor in terms of",
    "start": 732.079,
    "duration": 3.841
  },
  {
    "text": "their height and their build. Now we",
    "start": 734.079,
    "duration": 3.361
  },
  {
    "text": "have parametric bodies. Maybe this could",
    "start": 735.92,
    "duration": 5.12
  },
  {
    "text": "be improved even further.",
    "start": 737.44,
    "duration": 7.12
  },
  {
    "text": "But actually we are only interested in",
    "start": 741.04,
    "duration": 5.359
  },
  {
    "text": "this project in adding on like a little",
    "start": 744.56,
    "duration": 5.76
  },
  {
    "text": "bit of proity related head motion. So we",
    "start": 746.399,
    "duration": 6.56
  },
  {
    "text": "only retain the head motion for this",
    "start": 750.32,
    "duration": 6.4
  },
  {
    "text": "project. As you can see on the right",
    "start": 752.959,
    "duration": 6.721
  },
  {
    "text": "we are representing head motion with the",
    "start": 756.72,
    "duration": 5.119
  },
  {
    "text": "motion of the last four bones along the",
    "start": 759.68,
    "duration": 3.599
  },
  {
    "text": "kinematic chain to the head. So this",
    "start": 761.839,
    "duration": 5.041
  },
  {
    "text": "includes spine five uh neco one, neco",
    "start": 763.279,
    "duration": 5.601
  },
  {
    "text": "two and head.",
    "start": 766.88,
    "duration": 3.44
  },
  {
    "text": "Let me just play this one more time. And",
    "start": 768.88,
    "duration": 4.16
  },
  {
    "text": "we represent these joints as C 6D",
    "start": 770.32,
    "duration": 4.24
  },
  {
    "text": "rotations.",
    "start": 773.04,
    "duration": 3.2
  },
  {
    "text": "So this representation is becoming quite",
    "start": 774.56,
    "duration": 2.959
  },
  {
    "text": "popular in machine learning because it",
    "start": 776.24,
    "duration": 3.12
  },
  {
    "text": "has some really nice properties. So they",
    "start": 777.519,
    "duration": 3.76
  },
  {
    "text": "don't suffer from gimbal lock like oil",
    "start": 779.36,
    "duration": 3.76
  },
  {
    "text": "angles and they are continuous through",
    "start": 781.279,
    "duration": 4.0
  },
  {
    "text": "zero as well. We also keep like the",
    "start": 783.12,
    "duration": 3.839
  },
  {
    "text": "relative translation of the pelvis. You",
    "start": 785.279,
    "duration": 3.041
  },
  {
    "text": "see there's some lateral motion in that",
    "start": 786.959,
    "duration": 2.721
  },
  {
    "text": "video on the right there because this",
    "start": 788.32,
    "duration": 2.8
  },
  {
    "text": "adds some more richness to the",
    "start": 789.68,
    "duration": 4.44
  },
  {
    "text": "animation.",
    "start": 791.12,
    "duration": 3.0
  },
  {
    "text": "Okay. So after all of those processing",
    "start": 794.16,
    "duration": 3.44
  },
  {
    "text": "steps, this is what some of our training",
    "start": 796.079,
    "duration": 4.88
  },
  {
    "text": "samples looks like.",
    "start": 797.6,
    "duration": 6.479
  },
  {
    "text": "I can't believe how amazing today has",
    "start": 800.959,
    "duration": 5.921
  },
  {
    "text": "been. Everything is falling into place",
    "start": 804.079,
    "duration": 4.641
  },
  {
    "text": "perfectly.",
    "start": 806.88,
    "duration": 4.24
  },
  {
    "text": "I know I let you down and I feel so",
    "start": 808.72,
    "duration": 5.2
  },
  {
    "text": "terrible about it. I just hope I can",
    "start": 811.12,
    "duration": 5.11
  },
  {
    "text": "find a way to make it right.",
    "start": 813.92,
    "duration": 8.93
  },
  {
    "text": "[Laughter]",
    "start": 816.23,
    "duration": 6.62
  },
  {
    "text": "So, yeah, we've got a nice mixture of",
    "start": 824.56,
    "duration": 2.959
  },
  {
    "text": "things there.",
    "start": 825.92,
    "duration": 3.12
  },
  {
    "text": "Okay, so next I'll talk about the",
    "start": 827.519,
    "duration": 3.921
  },
  {
    "text": "machine learning model uh architecture",
    "start": 829.04,
    "duration": 4.479
  },
  {
    "text": "and a little a few details about how we",
    "start": 831.44,
    "duration": 6.24
  },
  {
    "text": "train it. So this is our model. If we",
    "start": 833.519,
    "duration": 6.161
  },
  {
    "text": "zoom out a little bit, you can see at a",
    "start": 837.68,
    "duration": 4.32
  },
  {
    "text": "very high level the audio is given as",
    "start": 839.68,
    "duration": 4.959
  },
  {
    "text": "input on the left and the the two",
    "start": 842.0,
    "duration": 4.959
  },
  {
    "text": "outputs of our model are the head motion",
    "start": 844.639,
    "duration": 4.721
  },
  {
    "text": "as you can see on the right in then this",
    "start": 846.959,
    "duration": 4.161
  },
  {
    "text": "is in the 6D representation that I",
    "start": 849.36,
    "duration": 4.08
  },
  {
    "text": "previously mentioned and the facial",
    "start": 851.12,
    "duration": 5.6
  },
  {
    "text": "animation which is on a metahuman. This",
    "start": 853.44,
    "duration": 5.6
  },
  {
    "text": "model is incredibly modular. So first",
    "start": 856.72,
    "duration": 3.76
  },
  {
    "text": "I'm going to be talking you through this",
    "start": 859.04,
    "duration": 3.039
  },
  {
    "text": "module here which is responsible for",
    "start": 860.48,
    "duration": 4.0
  },
  {
    "text": "generating the facial animation. Then",
    "start": 862.079,
    "duration": 4.0
  },
  {
    "text": "I'll touch upon this module which",
    "start": 864.48,
    "duration": 3.919
  },
  {
    "text": "generates the head motion. And then",
    "start": 866.079,
    "duration": 4.081
  },
  {
    "text": "finally I won't talk through this one",
    "start": 868.399,
    "duration": 2.961
  },
  {
    "text": "today but we have this final module",
    "start": 870.16,
    "duration": 4.56
  },
  {
    "text": "which generates additive blinks.",
    "start": 871.36,
    "duration": 5.919
  },
  {
    "text": "And we refer to this entire uh model as",
    "start": 874.72,
    "duration": 4.479
  },
  {
    "text": "X aer which stands for expressive",
    "start": 877.279,
    "duration": 5.56
  },
  {
    "text": "audioddriven animation.",
    "start": 879.199,
    "duration": 3.64
  },
  {
    "text": "Okay. So I'll start off with uh",
    "start": 883.12,
    "duration": 5.04
  },
  {
    "text": "describing the facial animation module.",
    "start": 885.199,
    "duration": 5.681
  },
  {
    "text": "So for this we take a transfer learning",
    "start": 888.16,
    "duration": 4.479
  },
  {
    "text": "approach.",
    "start": 890.88,
    "duration": 4.079
  },
  {
    "text": "This means that we take a model that was",
    "start": 892.639,
    "duration": 5.361
  },
  {
    "text": "trained for one task and then use it for",
    "start": 894.959,
    "duration": 6.24
  },
  {
    "text": "a related but different task. So in our",
    "start": 898.0,
    "duration": 6.56
  },
  {
    "text": "case we take the encoder from OpenAI's",
    "start": 901.199,
    "duration": 5.681
  },
  {
    "text": "whisper model and this was trained for",
    "start": 904.56,
    "duration": 4.56
  },
  {
    "text": "speech recognition and we apply it to",
    "start": 906.88,
    "duration": 4.88
  },
  {
    "text": "our facial animation task. And the",
    "start": 909.12,
    "duration": 5.12
  },
  {
    "text": "reason that we do this is because the",
    "start": 911.76,
    "duration": 3.84
  },
  {
    "text": "whisper model has been trained on",
    "start": 914.24,
    "duration": 3.44
  },
  {
    "text": "hundreds of thousands of hours of audio",
    "start": 915.6,
    "duration": 4.4
  },
  {
    "text": "speech. And in this speech data set, it",
    "start": 917.68,
    "duration": 4.8
  },
  {
    "text": "contains diversity in terms of like",
    "start": 920.0,
    "duration": 5.199
  },
  {
    "text": "speaker, so speaking style, uh language,",
    "start": 922.48,
    "duration": 3.76
  },
  {
    "text": "it contains loads of different",
    "start": 925.199,
    "duration": 3.521
  },
  {
    "text": "languages. Um environmental conditions",
    "start": 926.24,
    "duration": 4.64
  },
  {
    "text": "and therefore noise conditions, all of",
    "start": 928.72,
    "duration": 4.4
  },
  {
    "text": "these things. And this means that it's",
    "start": 930.88,
    "duration": 5.36
  },
  {
    "text": "incredibly robust at extracting speech",
    "start": 933.12,
    "duration": 4.719
  },
  {
    "text": "related content from the audio",
    "start": 936.24,
    "duration": 4.159
  },
  {
    "text": "regardless of any of these factors. And",
    "start": 937.839,
    "duration": 3.921
  },
  {
    "text": "this means that we can also train our",
    "start": 940.399,
    "duration": 3.361
  },
  {
    "text": "facial animation decoder on much less",
    "start": 941.76,
    "duration": 4.4
  },
  {
    "text": "data because whisper is doing so much of",
    "start": 943.76,
    "duration": 4.4
  },
  {
    "text": "the heavy lifting for us in terms of",
    "start": 946.16,
    "duration": 5.119
  },
  {
    "text": "audio signal processing.",
    "start": 948.16,
    "duration": 5.76
  },
  {
    "text": "So what we do is we use the encoder from",
    "start": 951.279,
    "duration": 5.36
  },
  {
    "text": "the whisper model to extract features,",
    "start": 953.92,
    "duration": 5.359
  },
  {
    "text": "audio features from our audio signal and",
    "start": 956.639,
    "duration": 4.961
  },
  {
    "text": "then we train up a facial animation",
    "start": 959.279,
    "duration": 4.8
  },
  {
    "text": "decoder which converts these features",
    "start": 961.6,
    "duration": 7.08
  },
  {
    "text": "into facial animation on a metahuman.",
    "start": 964.079,
    "duration": 4.601
  },
  {
    "text": "We also want to control somewhat for the",
    "start": 969.6,
    "duration": 5.12
  },
  {
    "text": "speaking style and also the emotion on",
    "start": 971.839,
    "duration": 5.68
  },
  {
    "text": "the generated animation. So we also",
    "start": 974.72,
    "duration": 5.119
  },
  {
    "text": "train up a few extra layers to embed",
    "start": 977.519,
    "duration": 4.961
  },
  {
    "text": "both the speaker ID and the emotion ID",
    "start": 979.839,
    "duration": 4.081
  },
  {
    "text": "and then we use these as an additional",
    "start": 982.48,
    "duration": 6.2
  },
  {
    "text": "inputs to the facial animation decoder.",
    "start": 983.92,
    "duration": 4.76
  },
  {
    "text": "So some technical details here. Um our",
    "start": 990.24,
    "duration": 4.959
  },
  {
    "text": "facial animation decoder is trained as a",
    "start": 993.199,
    "duration": 5.921
  },
  {
    "text": "seven layer 512 unit birectional GRU",
    "start": 995.199,
    "duration": 5.521
  },
  {
    "text": "model which is a gated recurrent unit",
    "start": 999.12,
    "duration": 4.399
  },
  {
    "text": "model. We train it from scratch on epics",
    "start": 1000.72,
    "duration": 5.2
  },
  {
    "text": "data. We train it on overlapping",
    "start": 1003.519,
    "duration": 4.401
  },
  {
    "text": "5-second samples with a stride of one",
    "start": 1005.92,
    "duration": 5.44
  },
  {
    "text": "frame. And this model took approximately",
    "start": 1007.92,
    "duration": 4.719
  },
  {
    "text": "two to three days to train, but this is",
    "start": 1011.36,
    "duration": 2.88
  },
  {
    "text": "incredibly hardware dependent. I'm just",
    "start": 1012.639,
    "duration": 3.2
  },
  {
    "text": "giving you an example or an indication",
    "start": 1014.24,
    "duration": 4.32
  },
  {
    "text": "of the scale of the problem.",
    "start": 1015.839,
    "duration": 4.641
  },
  {
    "text": "And we train it in a supervised manner.",
    "start": 1018.56,
    "duration": 3.92
  },
  {
    "text": "We simply minimize the mean squared",
    "start": 1020.48,
    "duration": 4.4
  },
  {
    "text": "error loss between the predicted output",
    "start": 1022.48,
    "duration": 5.52
  },
  {
    "text": "and our captured performance data.",
    "start": 1024.88,
    "duration": 4.799
  },
  {
    "text": "So let me show you a result of this",
    "start": 1028.0,
    "duration": 4.16
  },
  {
    "text": "model. At one end stood a great",
    "start": 1029.679,
    "duration": 4.721
  },
  {
    "text": "fireplace in which a blue log was",
    "start": 1032.16,
    "duration": 4.639
  },
  {
    "text": "blazing with a blue flame and over the",
    "start": 1034.4,
    "duration": 4.88
  },
  {
    "text": "fire hung four kettles in a row all",
    "start": 1036.799,
    "duration": 5.12
  },
  {
    "text": "bubbling and steaming at a great rate.",
    "start": 1039.28,
    "duration": 4.0
  },
  {
    "text": "So that one was a very that's very",
    "start": 1041.919,
    "duration": 2.961
  },
  {
    "text": "neutral but as I previously mentioned we",
    "start": 1043.28,
    "duration": 3.12
  },
  {
    "text": "can control for the emotion on the face.",
    "start": 1044.88,
    "duration": 4.32
  },
  {
    "text": "So let me show you a happy sample.",
    "start": 1046.4,
    "duration": 5.2
  },
  {
    "text": ">> I think I must show you my patchwork",
    "start": 1049.2,
    "duration": 4.88
  },
  {
    "text": "girl said Margalot laughing at the boy's",
    "start": 1051.6,
    "duration": 4.88
  },
  {
    "text": "astonishment for she is rather difficult",
    "start": 1054.08,
    "duration": 5.04
  },
  {
    "text": "to explain.",
    "start": 1056.48,
    "duration": 4.4
  },
  {
    "text": "And the model is trained with 21",
    "start": 1059.12,
    "duration": 3.2
  },
  {
    "text": "different emotion categories and this is",
    "start": 1060.88,
    "duration": 5.76
  },
  {
    "text": "all of them. We may be stopped. The fact",
    "start": 1062.32,
    "duration": 8.08
  },
  {
    "text": "may be put to us in general terms which",
    "start": 1066.64,
    "duration": 7.12
  },
  {
    "text": "is one way of attenuating it. We may be",
    "start": 1070.4,
    "duration": 6.72
  },
  {
    "text": "told that all trades, professions, it",
    "start": 1073.76,
    "duration": 6.4
  },
  {
    "text": "may be added all the accidents of the",
    "start": 1077.12,
    "duration": 6.32
  },
  {
    "text": "social hierarchy and all forms of",
    "start": 1080.16,
    "duration": 7.759
  },
  {
    "text": "intelligence have their own slang.",
    "start": 1083.44,
    "duration": 6.56
  },
  {
    "text": "Now the problem with this model is that",
    "start": 1087.919,
    "duration": 4.721
  },
  {
    "text": "it requires a speaker ID and an emotion",
    "start": 1090.0,
    "duration": 4.64
  },
  {
    "text": "ID to be given as input kind of manually",
    "start": 1092.64,
    "duration": 5.279
  },
  {
    "text": "for it to run. But there are times when",
    "start": 1094.64,
    "duration": 5.52
  },
  {
    "text": "we might want to run this model uh",
    "start": 1097.919,
    "duration": 3.441
  },
  {
    "text": "completely automatically. So the",
    "start": 1100.16,
    "duration": 2.32
  },
  {
    "text": "question is how can we run this model",
    "start": 1101.36,
    "duration": 3.28
  },
  {
    "text": "fully automatically? Say for example we",
    "start": 1102.48,
    "duration": 4.079
  },
  {
    "text": "do have um like a thousand audio clips",
    "start": 1104.64,
    "duration": 3.44
  },
  {
    "text": "that we want to process and each audio",
    "start": 1106.559,
    "duration": 3.441
  },
  {
    "text": "clip has like a different emotion or or",
    "start": 1108.08,
    "duration": 3.839
  },
  {
    "text": "it changes throughout the sequence. we",
    "start": 1110.0,
    "duration": 4.48
  },
  {
    "text": "may want to automatically detect the",
    "start": 1111.919,
    "duration": 4.321
  },
  {
    "text": "emotion from that audio sequence rather",
    "start": 1114.48,
    "duration": 4.24
  },
  {
    "text": "than having to manually input it. So we",
    "start": 1116.24,
    "duration": 3.439
  },
  {
    "text": "want this model to run fully",
    "start": 1118.72,
    "duration": 3.76
  },
  {
    "text": "automatically for the speaker side of",
    "start": 1119.679,
    "duration": 4.801
  },
  {
    "text": "things. What we actually end up doing is",
    "start": 1122.48,
    "duration": 3.76
  },
  {
    "text": "take the mean taking the mean vector",
    "start": 1124.48,
    "duration": 3.439
  },
  {
    "text": "from the speaker embedding layers and",
    "start": 1126.24,
    "duration": 3.679
  },
  {
    "text": "using that. And actually all the",
    "start": 1127.919,
    "duration": 4.801
  },
  {
    "text": "examples in this talk use that as the uh",
    "start": 1129.919,
    "duration": 4.481
  },
  {
    "text": "speaker embedding. This kind of gives us",
    "start": 1132.72,
    "duration": 3.839
  },
  {
    "text": "the most generic speaking style from all",
    "start": 1134.4,
    "duration": 3.92
  },
  {
    "text": "of the actors that we captured and works",
    "start": 1136.559,
    "duration": 3.441
  },
  {
    "text": "best across most of the rigs that we've",
    "start": 1138.32,
    "duration": 3.2
  },
  {
    "text": "tried.",
    "start": 1140.0,
    "duration": 3.039
  },
  {
    "text": "But for the emotion it's a bit more",
    "start": 1141.52,
    "duration": 3.12
  },
  {
    "text": "tricky.",
    "start": 1143.039,
    "duration": 3.921
  },
  {
    "text": "So what we do is we introduce an emotion",
    "start": 1144.64,
    "duration": 6.56
  },
  {
    "text": "classifier and this is responsible for",
    "start": 1146.96,
    "duration": 7.44
  },
  {
    "text": "detecting the emotion from the voice.",
    "start": 1151.2,
    "duration": 6.08
  },
  {
    "text": "The input to the emotion classifier uh",
    "start": 1154.4,
    "duration": 5.519
  },
  {
    "text": "is the whisper features and the output",
    "start": 1157.28,
    "duration": 5.279
  },
  {
    "text": "is like the emotion probability. So the",
    "start": 1159.919,
    "duration": 4.481
  },
  {
    "text": "probability distribution over the 21",
    "start": 1162.559,
    "duration": 4.721
  },
  {
    "text": "different emotion categories",
    "start": 1164.4,
    "duration": 4.88
  },
  {
    "text": "and the output to the emotion classifier",
    "start": 1167.28,
    "duration": 3.519
  },
  {
    "text": "is used as input to our emotion",
    "start": 1169.28,
    "duration": 4.16
  },
  {
    "text": "embedding layers. The emotion classifier",
    "start": 1170.799,
    "duration": 4.641
  },
  {
    "text": "is also trained as a birectional GU this",
    "start": 1173.44,
    "duration": 6.16
  },
  {
    "text": "time with four layers and 256 units.",
    "start": 1175.44,
    "duration": 6.16
  },
  {
    "text": "And the great thing about this framework",
    "start": 1179.6,
    "duration": 3.68
  },
  {
    "text": "is that the model can now be run either",
    "start": 1181.6,
    "duration": 3.76
  },
  {
    "text": "fully automatically by taking the output",
    "start": 1183.28,
    "duration": 4.16
  },
  {
    "text": "from the emotion classifier as input to",
    "start": 1185.36,
    "duration": 4.48
  },
  {
    "text": "the emotion embedding layers or a user",
    "start": 1187.44,
    "duration": 4.88
  },
  {
    "text": "can override this and instead put the",
    "start": 1189.84,
    "duration": 4.16
  },
  {
    "text": "userdefined emotion into the emotion",
    "start": 1192.32,
    "duration": 4.479
  },
  {
    "text": "embedding layers. So here's another",
    "start": 1194.0,
    "duration": 4.24
  },
  {
    "text": "example. This time the automatic",
    "start": 1196.799,
    "duration": 4.561
  },
  {
    "text": "configuration is shown on the top left.",
    "start": 1198.24,
    "duration": 5.36
  },
  {
    "text": "You are now in the only country in the",
    "start": 1201.36,
    "duration": 4.64
  },
  {
    "text": "world where wit can make a fortune by",
    "start": 1203.6,
    "duration": 5.28
  },
  {
    "text": "selling either a genuine or a false",
    "start": 1206.0,
    "duration": 4.64
  },
  {
    "text": "article.",
    "start": 1208.88,
    "duration": 4.08
  },
  {
    "text": "In the first case, it receives the",
    "start": 1210.64,
    "duration": 4.399
  },
  {
    "text": "welcome of intelligent and talented",
    "start": 1212.96,
    "duration": 5.52
  },
  {
    "text": "people. And in the second, fools are",
    "start": 1215.039,
    "duration": 6.321
  },
  {
    "text": "always ready to reward it, for silliness",
    "start": 1218.48,
    "duration": 4.96
  },
  {
    "text": "is truly a characteristic of the people",
    "start": 1221.36,
    "duration": 4.4
  },
  {
    "text": "here. And however wonderful it may",
    "start": 1223.44,
    "duration": 5.359
  },
  {
    "text": "appear, silliness is the daughter of",
    "start": 1225.76,
    "duration": 4.56
  },
  {
    "text": "wit.",
    "start": 1228.799,
    "duration": 3.441
  },
  {
    "text": "So you may notice that in this example",
    "start": 1230.32,
    "duration": 4.16
  },
  {
    "text": "there is head motion. So that leads me",
    "start": 1232.24,
    "duration": 4.48
  },
  {
    "text": "on to the next section.",
    "start": 1234.48,
    "duration": 4.96
  },
  {
    "text": "Okay. So when it came to to training the",
    "start": 1236.72,
    "duration": 6.319
  },
  {
    "text": "head motion model, the question that we",
    "start": 1239.44,
    "duration": 5.599
  },
  {
    "text": "posed was what information actually",
    "start": 1243.039,
    "duration": 4.401
  },
  {
    "text": "drives head motion? What information",
    "start": 1245.039,
    "duration": 4.88
  },
  {
    "text": "what inputs does our head motion decoder",
    "start": 1247.44,
    "duration": 4.88
  },
  {
    "text": "need to generate the most accurate head",
    "start": 1249.919,
    "duration": 5.681
  },
  {
    "text": "motion animation or head animation? So",
    "start": 1252.32,
    "duration": 5.68
  },
  {
    "text": "we set up an experiment where we trained",
    "start": 1255.6,
    "duration": 4.319
  },
  {
    "text": "our head motion model on different",
    "start": 1258.0,
    "duration": 4.4
  },
  {
    "text": "combinations of input features including",
    "start": 1259.919,
    "duration": 5.361
  },
  {
    "text": "audio, face, speaker and emotion",
    "start": 1262.4,
    "duration": 5.44
  },
  {
    "text": "information. And then as you can see on",
    "start": 1265.28,
    "duration": 4.8
  },
  {
    "text": "the table on the right, we measured the",
    "start": 1267.84,
    "duration": 4.079
  },
  {
    "text": "head error over our test set for each of",
    "start": 1270.08,
    "duration": 4.4
  },
  {
    "text": "these combinations of features. In the",
    "start": 1271.919,
    "duration": 3.76
  },
  {
    "text": "top row, you can see that if we use",
    "start": 1274.48,
    "duration": 4.319
  },
  {
    "text": "audio alone, we get an error of 1.03. If",
    "start": 1275.679,
    "duration": 5.761
  },
  {
    "text": "we add in the face information, the area",
    "start": 1278.799,
    "duration": 4.961
  },
  {
    "text": "decreases and it continues to decrease",
    "start": 1281.44,
    "duration": 4.08
  },
  {
    "text": "as we add in speaker and emotion",
    "start": 1283.76,
    "duration": 4.0
  },
  {
    "text": "information. So we can say that all four",
    "start": 1285.52,
    "duration": 4.08
  },
  {
    "text": "of these input features contribute",
    "start": 1287.76,
    "duration": 4.56
  },
  {
    "text": "positively to head motion. So so that is",
    "start": 1289.6,
    "duration": 6.04
  },
  {
    "text": "what we use.",
    "start": 1292.32,
    "duration": 3.32
  },
  {
    "text": "Before I talk before I show you some",
    "start": 1296.24,
    "duration": 4.48
  },
  {
    "text": "more results, um I just wanted to talk",
    "start": 1298.08,
    "duration": 4.8
  },
  {
    "text": "more about our choice of audio encoder",
    "start": 1300.72,
    "duration": 3.439
  },
  {
    "text": "because I mentioned we use the whisper",
    "start": 1302.88,
    "duration": 3.679
  },
  {
    "text": "encoder. I just want to talk through how",
    "start": 1304.159,
    "duration": 5.441
  },
  {
    "text": "we use it and why we use it. So on the",
    "start": 1306.559,
    "duration": 5.521
  },
  {
    "text": "right there you can see OpenAI's whisper",
    "start": 1309.6,
    "duration": 4.0
  },
  {
    "text": "model.",
    "start": 1312.08,
    "duration": 3.68
  },
  {
    "text": "The left hand column like the pink",
    "start": 1313.6,
    "duration": 4.959
  },
  {
    "text": "blocks there that is essentially the",
    "start": 1315.76,
    "duration": 4.799
  },
  {
    "text": "encoder part of the model and the right",
    "start": 1318.559,
    "duration": 3.6
  },
  {
    "text": "hand column is the decoder part of the",
    "start": 1320.559,
    "duration": 3.6
  },
  {
    "text": "model. So the encoder part of model of",
    "start": 1322.159,
    "duration": 3.921
  },
  {
    "text": "the model is responsible for converting",
    "start": 1324.159,
    "duration": 4.241
  },
  {
    "text": "the audio features into the audio into a",
    "start": 1326.08,
    "duration": 4.719
  },
  {
    "text": "set of features and the right hand part",
    "start": 1328.4,
    "duration": 4.0
  },
  {
    "text": "of the model is essentially responsible",
    "start": 1330.799,
    "duration": 4.401
  },
  {
    "text": "for turning these into tokens or text",
    "start": 1332.4,
    "duration": 4.24
  },
  {
    "text": "and we're not interested in this part of",
    "start": 1335.2,
    "duration": 4.0
  },
  {
    "text": "the model. So we simply remove it and",
    "start": 1336.64,
    "duration": 6.399
  },
  {
    "text": "this leaves us with the uh encoder only.",
    "start": 1339.2,
    "duration": 5.76
  },
  {
    "text": "What this does is it converts our audio",
    "start": 1343.039,
    "duration": 4.321
  },
  {
    "text": "into log into a log ml spectrogram,",
    "start": 1344.96,
    "duration": 4.079
  },
  {
    "text": "passes these through two convolution",
    "start": 1347.36,
    "duration": 3.6
  },
  {
    "text": "layers and 12 transformer blocks and",
    "start": 1349.039,
    "duration": 3.76
  },
  {
    "text": "it's the output of the final transformer",
    "start": 1350.96,
    "duration": 4.48
  },
  {
    "text": "block that we use in our model.",
    "start": 1352.799,
    "duration": 4.721
  },
  {
    "text": "And we did compare whisper against",
    "start": 1355.44,
    "duration": 3.599
  },
  {
    "text": "different pre-trained audio encoders",
    "start": 1357.52,
    "duration": 5.84
  },
  {
    "text": "that exist namely Wavvec 2 from Meta",
    "start": 1359.039,
    "duration": 6.081
  },
  {
    "text": "which is very commonly used for",
    "start": 1363.36,
    "duration": 3.92
  },
  {
    "text": "audiodriven animation in in academic",
    "start": 1365.12,
    "duration": 5.28
  },
  {
    "text": "literature. uh Wavvelm from Microsoft",
    "start": 1367.28,
    "duration": 6.0
  },
  {
    "text": "and also Hubert from Meta.",
    "start": 1370.4,
    "duration": 4.72
  },
  {
    "text": "And you can see in the table below we",
    "start": 1373.28,
    "duration": 4.879
  },
  {
    "text": "report the uh the face animation error",
    "start": 1375.12,
    "duration": 6.0
  },
  {
    "text": "and the emotion classifier accuracy in",
    "start": 1378.159,
    "duration": 5.361
  },
  {
    "text": "the columns two and three. And we report",
    "start": 1381.12,
    "duration": 3.6
  },
  {
    "text": "these for each of the four different",
    "start": 1383.52,
    "duration": 3.279
  },
  {
    "text": "audio encoders.",
    "start": 1384.72,
    "duration": 3.92
  },
  {
    "text": "So Whisper actually performs best in",
    "start": 1386.799,
    "duration": 4.321
  },
  {
    "text": "terms of facial animation error. It",
    "start": 1388.64,
    "duration": 4.08
  },
  {
    "text": "actually performs second best in terms",
    "start": 1391.12,
    "duration": 4.64
  },
  {
    "text": "of emotion classifier accuracy behind",
    "start": 1392.72,
    "duration": 5.839
  },
  {
    "text": "WavelM. But if we look at that final",
    "start": 1395.76,
    "duration": 4.159
  },
  {
    "text": "column, you can see the number of",
    "start": 1398.559,
    "duration": 3.521
  },
  {
    "text": "parameters in each model. And um",
    "start": 1399.919,
    "duration": 4.081
  },
  {
    "text": "actually all of the other audio encoders",
    "start": 1402.08,
    "duration": 3.36
  },
  {
    "text": "share the same underlying architecture.",
    "start": 1404.0,
    "duration": 2.799
  },
  {
    "text": "They've just been trained differently.",
    "start": 1405.44,
    "duration": 3.599
  },
  {
    "text": "So they all have substantially more",
    "start": 1406.799,
    "duration": 4.641
  },
  {
    "text": "parameters than the the whisper encoder",
    "start": 1409.039,
    "duration": 5.441
  },
  {
    "text": "does. So this trade-off in a motion",
    "start": 1411.44,
    "duration": 4.56
  },
  {
    "text": "classifier accuracy is kind of",
    "start": 1414.48,
    "duration": 2.88
  },
  {
    "text": "acceptable for us because it makes the",
    "start": 1416.0,
    "duration": 5.0
  },
  {
    "text": "model much more practical.",
    "start": 1417.36,
    "duration": 3.64
  },
  {
    "text": "Okay. So let me show you some results",
    "start": 1421.2,
    "duration": 2.719
  },
  {
    "text": "now.",
    "start": 1423.12,
    "duration": 2.32
  },
  {
    "text": "I need to preface this by saying that",
    "start": 1423.919,
    "duration": 2.961
  },
  {
    "text": "none of the audio samples that you see",
    "start": 1425.44,
    "duration": 2.96
  },
  {
    "text": "here were used for training the model.",
    "start": 1426.88,
    "duration": 2.64
  },
  {
    "text": "They're all from either different data",
    "start": 1428.4,
    "duration": 3.84
  },
  {
    "text": "sets or completely held out.",
    "start": 1429.52,
    "duration": 4.399
  },
  {
    "text": "I'll start off with some test set",
    "start": 1432.24,
    "duration": 6.04
  },
  {
    "text": "examples from our captured data.",
    "start": 1433.919,
    "duration": 4.361
  },
  {
    "text": ">> Uh yeah, I recently watched the uh baby",
    "start": 1438.799,
    "duration": 4.961
  },
  {
    "text": "reindeer. I think was that was that",
    "start": 1442.24,
    "duration": 2.319
  },
  {
    "text": "Netflix?",
    "start": 1443.76,
    "duration": 2.48
  },
  {
    "text": ">> Agricultural products are unevenly",
    "start": 1444.559,
    "duration": 3.921
  },
  {
    "text": "distributed.",
    "start": 1446.24,
    "duration": 5.76
  },
  {
    "text": ">> Why do we need bigger and better bombs?",
    "start": 1448.48,
    "duration": 3.679
  },
  {
    "text": "I",
    "start": 1452.0,
    "duration": 1.919
  },
  {
    "text": ">> agree. And I think it's useful to",
    "start": 1452.159,
    "duration": 3.041
  },
  {
    "text": "compare against the ground truth as",
    "start": 1453.919,
    "duration": 2.88
  },
  {
    "text": "well. So in these next examples, you'll",
    "start": 1455.2,
    "duration": 3.12
  },
  {
    "text": "see the ground truth or the captured",
    "start": 1456.799,
    "duration": 3.041
  },
  {
    "text": "performance on the left and the",
    "start": 1458.32,
    "duration": 4.0
  },
  {
    "text": "prediction from our model on the right.",
    "start": 1459.84,
    "duration": 4.88
  },
  {
    "text": "With tenure, Suzie have all the more",
    "start": 1462.32,
    "duration": 4.16
  },
  {
    "text": "leisure for yaching, but her",
    "start": 1464.72,
    "duration": 3.439
  },
  {
    "text": "publications are no good.",
    "start": 1466.48,
    "duration": 4.72
  },
  {
    "text": ">> I from the clips I saw, I thought she",
    "start": 1468.159,
    "duration": 5.201
  },
  {
    "text": "she didn't have a great hold on what was",
    "start": 1471.2,
    "duration": 4.64
  },
  {
    "text": "true and what was not true. The small",
    "start": 1473.36,
    "duration": 5.84
  },
  {
    "text": "boy put the worm on the hook.",
    "start": 1475.84,
    "duration": 4.719
  },
  {
    "text": ">> And I just want to bring attention to",
    "start": 1479.2,
    "duration": 3.68
  },
  {
    "text": "the tongue as well. So, um, on the left",
    "start": 1480.559,
    "duration": 4.24
  },
  {
    "text": "we have the kind of pseudo ground truth",
    "start": 1482.88,
    "duration": 3.6
  },
  {
    "text": "tongue motion and on the right is the",
    "start": 1484.799,
    "duration": 3.76
  },
  {
    "text": "prediction from our model.",
    "start": 1486.48,
    "duration": 6.16
  },
  {
    "text": ">> The small boy put the worm on the hook.",
    "start": 1488.559,
    "duration": 6.48
  },
  {
    "text": ">> With tenure, Suzie have all the more",
    "start": 1492.64,
    "duration": 4.159
  },
  {
    "text": "leisure for yaching, but her",
    "start": 1495.039,
    "duration": 5.12
  },
  {
    "text": "publications are no good.",
    "start": 1496.799,
    "duration": 5.041
  },
  {
    "text": ">> Um, and all those samples were quite",
    "start": 1500.159,
    "duration": 3.441
  },
  {
    "text": "neutral. So, I also wanted to show you a",
    "start": 1501.84,
    "duration": 4.64
  },
  {
    "text": "few emotional samples. For each of these",
    "start": 1503.6,
    "duration": 5.12
  },
  {
    "text": "clips, we also show the probability",
    "start": 1506.48,
    "duration": 4.72
  },
  {
    "text": "distribution over the 21 emotion 21",
    "start": 1508.72,
    "duration": 5.6
  },
  {
    "text": "emotions in the top left.",
    "start": 1511.2,
    "duration": 5.2
  },
  {
    "text": ">> You're here. I didn't know you were",
    "start": 1514.32,
    "duration": 5.04
  },
  {
    "text": "coming back. Oh, this is the best",
    "start": 1516.4,
    "duration": 5.04
  },
  {
    "text": "surprise.",
    "start": 1519.36,
    "duration": 4.24
  },
  {
    "text": ">> No manufacturers take any initiative in",
    "start": 1521.44,
    "duration": 5.359
  },
  {
    "text": "pointing out the costs involved.",
    "start": 1523.6,
    "duration": 4.48
  },
  {
    "text": ">> So, it does a pretty reasonable job",
    "start": 1526.799,
    "duration": 3.841
  },
  {
    "text": "there. And although we don't capture any",
    "start": 1528.08,
    "duration": 4.959
  },
  {
    "text": "like languages other than um other than",
    "start": 1530.64,
    "duration": 4.639
  },
  {
    "text": "English in our particular data capture",
    "start": 1533.039,
    "duration": 4.401
  },
  {
    "text": "because we are using the whisper model,",
    "start": 1535.279,
    "duration": 3.921
  },
  {
    "text": "whisper has been trained on all these",
    "start": 1537.44,
    "duration": 3.04
  },
  {
    "text": "different languages. So I think our",
    "start": 1539.2,
    "duration": 3.04
  },
  {
    "text": "model fares pretty well over different",
    "start": 1540.48,
    "duration": 6.12
  },
  {
    "text": "languages too. Here are some examples.",
    "start": 1542.24,
    "duration": 4.36
  },
  {
    "text": "for",
    "start": 1551.84,
    "duration": 3.0
  },
  {
    "text": "obviously I think they look pretty good",
    "start": 1569.6,
    "duration": 2.72
  },
  {
    "text": "but as an English speaker I welcome",
    "start": 1570.72,
    "duration": 3.04
  },
  {
    "text": "feedback from the actual people that",
    "start": 1572.32,
    "duration": 3.04
  },
  {
    "text": "speak these languages as to how good",
    "start": 1573.76,
    "duration": 4.08
  },
  {
    "text": "they are and uh yeah so non-verbal",
    "start": 1575.36,
    "duration": 3.84
  },
  {
    "text": "sounds I previously mentioned that we",
    "start": 1577.84,
    "duration": 2.8
  },
  {
    "text": "captured this data so I wanted to",
    "start": 1579.2,
    "duration": 4.079
  },
  {
    "text": "demonstrate what The results of this",
    "start": 1580.64,
    "duration": 6.84
  },
  {
    "text": "model is on non-verbal sounds.",
    "start": 1583.279,
    "duration": 4.201
  },
  {
    "text": "H",
    "start": 1591.6,
    "duration": 3.0
  },
  {
    "text": "[Laughter]",
    "start": 1607.07,
    "duration": 12.37
  },
  {
    "text": "So, we're getting there. And uh so, and",
    "start": 1616.799,
    "duration": 4.48
  },
  {
    "text": "to finish off, I want to show you some",
    "start": 1619.44,
    "duration": 3.76
  },
  {
    "text": "singing. So, all of the samples that",
    "start": 1621.279,
    "duration": 4.241
  },
  {
    "text": "you're about to see, uh we predicted",
    "start": 1623.2,
    "duration": 4.24
  },
  {
    "text": "them from like the clean vocal track and",
    "start": 1625.52,
    "duration": 5.44
  },
  {
    "text": "then we mixed in the the music after.",
    "start": 1627.44,
    "duration": 5.359
  },
  {
    "text": ">> Judge and Maple, you can throw it on",
    "start": 1630.96,
    "duration": 4.88
  },
  {
    "text": "back. Kick it back in front of the fire.",
    "start": 1632.799,
    "duration": 4.641
  },
  {
    "text": "Take the load off to your heart's",
    "start": 1635.84,
    "duration": 4.48
  },
  {
    "text": "desire. Got a cannon up front out back.",
    "start": 1637.44,
    "duration": 5.04
  },
  {
    "text": "We got home style cooking and that's a",
    "start": 1640.32,
    "duration": 4.64
  },
  {
    "text": "fact. Check the board for what's on",
    "start": 1642.48,
    "duration": 4.48
  },
  {
    "text": "town. We got the best thing up on the",
    "start": 1644.96,
    "duration": 4.56
  },
  {
    "text": "whole dang map. Find the truck and come",
    "start": 1646.96,
    "duration": 4.959
  },
  {
    "text": "on down. We got the best food in this",
    "start": 1649.52,
    "duration": 8.48
  },
  {
    "text": "whole dang town. Yeah, yeah, yeah.",
    "start": 1651.919,
    "duration": 9.481
  },
  {
    "text": "Come on down.",
    "start": 1658.0,
    "duration": 3.4
  },
  {
    "text": "I want you",
    "start": 1664.799,
    "duration": 3.601
  },
  {
    "text": "to",
    "start": 1666.88,
    "duration": 6.48
  },
  {
    "text": "hold that. Yeah, we can wait.",
    "start": 1668.4,
    "duration": 7.279
  },
  {
    "text": "You can trick it like a little. I got a",
    "start": 1673.36,
    "duration": 5.36
  },
  {
    "text": "lot of change in my pocket now. I'm",
    "start": 1675.679,
    "duration": 6.281
  },
  {
    "text": "going to spend it all. Spend it all.",
    "start": 1678.72,
    "duration": 6.749
  },
  {
    "text": "[Music]",
    "start": 1681.96,
    "duration": 3.509
  },
  {
    "text": "Awesome.",
    "start": 1685.6,
    "duration": 6.439
  },
  {
    "text": "Cool. So, let's uh",
    "start": 1687.2,
    "duration": 4.839
  },
  {
    "text": "it's so difficult not to sing along at",
    "start": 1694.0,
    "duration": 3.76
  },
  {
    "text": "this stage. So, you're very lucky that I",
    "start": 1695.679,
    "duration": 4.081
  },
  {
    "text": "didn't. Okay. So, I'm just going to",
    "start": 1697.76,
    "duration": 4.0
  },
  {
    "text": "break it out quickly and show you a",
    "start": 1699.76,
    "duration": 4.48
  },
  {
    "text": "quick demo of how you can run this in",
    "start": 1701.76,
    "duration": 5.2
  },
  {
    "text": "the engine. So, to run this, you'll need",
    "start": 1704.24,
    "duration": 5.439
  },
  {
    "text": "to uh enable the Metahuman Animator",
    "start": 1706.96,
    "duration": 4.4
  },
  {
    "text": "plugin. And for these particular",
    "start": 1709.679,
    "duration": 5.841
  },
  {
    "text": "features, you'll need to be using uh 56.",
    "start": 1711.36,
    "duration": 6.72
  },
  {
    "text": "So, um, we've pulled in an audio sample",
    "start": 1715.52,
    "duration": 4.639
  },
  {
    "text": "and we now have a same soundwave asset.",
    "start": 1718.08,
    "duration": 3.839
  },
  {
    "text": ">> When you're less fatigued, things just",
    "start": 1720.159,
    "duration": 3.841
  },
  {
    "text": "naturally look brighter",
    "start": 1721.919,
    "duration": 3.521
  },
  {
    "text": ">> and, uh, there are multiple ways in that",
    "start": 1724.0,
    "duration": 2.88
  },
  {
    "text": "you can generate animation from a",
    "start": 1725.44,
    "duration": 3.44
  },
  {
    "text": "soundwave asset. Uh, the the first one",
    "start": 1726.88,
    "duration": 3.519
  },
  {
    "text": "is batch processing. So, if you right",
    "start": 1728.88,
    "duration": 3.279
  },
  {
    "text": "click this, click on metahuman",
    "start": 1730.399,
    "duration": 3.201
  },
  {
    "text": "performance and then you've got some",
    "start": 1732.159,
    "duration": 2.801
  },
  {
    "text": "options there. So, you can either",
    "start": 1733.6,
    "duration": 3.36
  },
  {
    "text": "generate level sequences, animation",
    "start": 1734.96,
    "duration": 3.28
  },
  {
    "text": "sequences, or you can create a",
    "start": 1736.96,
    "duration": 3.839
  },
  {
    "text": "performance assets. This is great if you",
    "start": 1738.24,
    "duration": 4.319
  },
  {
    "text": "have like loads of different um, audio",
    "start": 1740.799,
    "duration": 3.281
  },
  {
    "text": "samples. You can just select them all,",
    "start": 1742.559,
    "duration": 2.961
  },
  {
    "text": "right click, and there you go. You can",
    "start": 1744.08,
    "duration": 3.68
  },
  {
    "text": "just generate uh like level sequences or",
    "start": 1745.52,
    "duration": 3.6
  },
  {
    "text": "animation sequences for all of them with",
    "start": 1747.76,
    "duration": 3.039
  },
  {
    "text": "just a few clicks. There's another",
    "start": 1749.12,
    "duration": 2.88
  },
  {
    "text": "option which is the one I'm going to be",
    "start": 1750.799,
    "duration": 3.041
  },
  {
    "text": "going through today, and that is via the",
    "start": 1752.0,
    "duration": 3.84
  },
  {
    "text": "Metahuman performance editor. So, if you",
    "start": 1753.84,
    "duration": 4.4
  },
  {
    "text": "go to the Metahuman menu item, and then",
    "start": 1755.84,
    "duration": 4.64
  },
  {
    "text": "click on Metahuman performance. I guess",
    "start": 1758.24,
    "duration": 6.12
  },
  {
    "text": "I'll call this um",
    "start": 1760.48,
    "duration": 3.88
  },
  {
    "text": "speech clip.",
    "start": 1765.679,
    "duration": 6.0
  },
  {
    "text": "And then we open this up.",
    "start": 1768.399,
    "duration": 7.0
  },
  {
    "text": "um that's over here.",
    "start": 1771.679,
    "duration": 3.72
  },
  {
    "text": "So in here if we change the input type",
    "start": 1775.84,
    "duration": 5.76
  },
  {
    "text": "to audio and then we can select our",
    "start": 1778.32,
    "duration": 4.959
  },
  {
    "text": "audio sample. So I think that was speech",
    "start": 1781.6,
    "duration": 4.679
  },
  {
    "text": "clip",
    "start": 1783.279,
    "duration": 3.0
  },
  {
    "text": "and then we can choose our visualization",
    "start": 1786.399,
    "duration": 6.081
  },
  {
    "text": "mesh. So in this case it has to be",
    "start": 1788.799,
    "duration": 5.841
  },
  {
    "text": "Orlando",
    "start": 1792.48,
    "duration": 4.72
  },
  {
    "text": "for obvious reasons.",
    "start": 1794.64,
    "duration": 5.279
  },
  {
    "text": "And uh yeah we can simply click process.",
    "start": 1797.2,
    "duration": 4.24
  },
  {
    "text": "We have the audio and we have the",
    "start": 1799.919,
    "duration": 2.961
  },
  {
    "text": "visualization mesh and you can see it",
    "start": 1801.44,
    "duration": 4.0
  },
  {
    "text": "doing its work.",
    "start": 1802.88,
    "duration": 6.0
  },
  {
    "text": "Um, if I make this bigger actually. Um,",
    "start": 1805.44,
    "duration": 6.8
  },
  {
    "text": "yes. So, if I click play now,",
    "start": 1808.88,
    "duration": 5.2
  },
  {
    "text": "when you're less fatigued, things just",
    "start": 1812.24,
    "duration": 4.24
  },
  {
    "text": "naturally look brighter.",
    "start": 1814.08,
    "duration": 4.0
  },
  {
    "text": ">> So, this is using the automatic",
    "start": 1816.48,
    "duration": 2.559
  },
  {
    "text": "configuration now where we're",
    "start": 1818.08,
    "duration": 2.319
  },
  {
    "text": "automatically detecting the emotion from",
    "start": 1819.039,
    "duration": 4.64
  },
  {
    "text": "the voice. We also can override this if",
    "start": 1820.399,
    "duration": 5.76
  },
  {
    "text": "we go come down to solve overrides down",
    "start": 1823.679,
    "duration": 4.561
  },
  {
    "text": "here and then we can choose which mood",
    "start": 1826.159,
    "duration": 3.841
  },
  {
    "text": "we want to animate to. So say if we want",
    "start": 1828.24,
    "duration": 4.159
  },
  {
    "text": "to make him angry, uh we select anger.",
    "start": 1830.0,
    "duration": 4.32
  },
  {
    "text": "We can also choose an intensity if you",
    "start": 1832.399,
    "duration": 3.601
  },
  {
    "text": "want to lower the intensity or edit that",
    "start": 1834.32,
    "duration": 4.64
  },
  {
    "text": "in any way. So once I've chosen anger,",
    "start": 1836.0,
    "duration": 6.919
  },
  {
    "text": "let's do some processing again.",
    "start": 1838.96,
    "duration": 3.959
  },
  {
    "text": "So let's go back to the beginning. Now",
    "start": 1844.08,
    "duration": 2.479
  },
  {
    "text": "he should be more angry.",
    "start": 1845.6,
    "duration": 2.64
  },
  {
    "text": ">> When you're less fatigued, things just",
    "start": 1846.559,
    "duration": 3.681
  },
  {
    "text": "naturally look brighter.",
    "start": 1848.24,
    "duration": 3.439
  },
  {
    "text": ">> And then from here, we can export",
    "start": 1850.24,
    "duration": 2.64
  },
  {
    "text": ">> by that time. Perhaps",
    "start": 1851.679,
    "duration": 4.641
  },
  {
    "text": ">> we can export to level sequence. Um",
    "start": 1852.88,
    "duration": 7.12
  },
  {
    "text": "save that. uh",
    "start": 1856.32,
    "duration": 7.12
  },
  {
    "text": "choose our metahuman",
    "start": 1860.0,
    "duration": 5.679
  },
  {
    "text": "that we want to have in our level",
    "start": 1863.44,
    "duration": 3.599
  },
  {
    "text": "sequence. I won't export the camera",
    "start": 1865.679,
    "duration": 4.761
  },
  {
    "text": "because we have one.",
    "start": 1867.039,
    "duration": 3.401
  },
  {
    "text": "And then we should have it.",
    "start": 1871.039,
    "duration": 5.36
  },
  {
    "text": "Oops, sorry.",
    "start": 1873.679,
    "duration": 5.441
  },
  {
    "text": "Yeah. And here's our level sequence.",
    "start": 1876.399,
    "duration": 6.721
  },
  {
    "text": "What I'm going to do is just",
    "start": 1879.12,
    "duration": 7.88
  },
  {
    "text": "um select our",
    "start": 1883.12,
    "duration": 3.88
  },
  {
    "text": "character and pointing to our camera.",
    "start": 1887.84,
    "duration": 3.439
  },
  {
    "text": "I'll drag our camera in here as well, so",
    "start": 1889.6,
    "duration": 3.92
  },
  {
    "text": "it looks nice. And then we have our",
    "start": 1891.279,
    "duration": 4.081
  },
  {
    "text": ">> when you're less fatigued, things just",
    "start": 1893.52,
    "duration": 3.92
  },
  {
    "text": "naturally look brighter.",
    "start": 1895.36,
    "duration": 4.24
  },
  {
    "text": ">> So yeah, I mean, obviously he's not",
    "start": 1897.44,
    "duration": 3.44
  },
  {
    "text": "speaking in an angry voice, but you get",
    "start": 1899.6,
    "duration": 3.6
  },
  {
    "text": "the you get you get the gist. Okay,",
    "start": 1900.88,
    "duration": 4.56
  },
  {
    "text": "cool. So that was the demo. I will now",
    "start": 1903.2,
    "duration": 4.959
  },
  {
    "text": "hand back to Salvador",
    "start": 1905.44,
    "duration": 6.52
  },
  {
    "text": "to go stream.",
    "start": 1908.159,
    "duration": 3.801
  },
  {
    "text": "Um hi. So now I will walk you through",
    "start": 1916.64,
    "duration": 5.12
  },
  {
    "text": "the streaming audiodriven animation",
    "start": 1919.679,
    "duration": 4.48
  },
  {
    "text": "model. Uh we've been working on this",
    "start": 1921.76,
    "duration": 6.159
  },
  {
    "text": "recently and uh whenever we're working",
    "start": 1924.159,
    "duration": 6.081
  },
  {
    "text": "on this, one of the first questions we",
    "start": 1927.919,
    "duration": 5.201
  },
  {
    "text": "always get is why does it have to be",
    "start": 1930.24,
    "duration": 5.6
  },
  {
    "text": "running in real time or why is it do we",
    "start": 1933.12,
    "duration": 5.439
  },
  {
    "text": "need the streaming solution? Well, if",
    "start": 1935.84,
    "duration": 4.559
  },
  {
    "text": "we've been looking around here and the",
    "start": 1938.559,
    "duration": 4.0
  },
  {
    "text": "industry, we've reached this point where",
    "start": 1940.399,
    "duration": 4.16
  },
  {
    "text": "we can beautifully rendered all these",
    "start": 1942.559,
    "duration": 3.761
  },
  {
    "text": "metahumans as the one that you see down",
    "start": 1944.559,
    "duration": 4.72
  },
  {
    "text": "there. But not only that, now we are",
    "start": 1946.32,
    "duration": 5.359
  },
  {
    "text": "capable of realistically animating these",
    "start": 1949.279,
    "duration": 4.801
  },
  {
    "text": "metahumans just as Sarah just showed you",
    "start": 1951.679,
    "duration": 5.6
  },
  {
    "text": "that we're capable of doing with XA.",
    "start": 1954.08,
    "duration": 5.439
  },
  {
    "text": "Um,",
    "start": 1957.279,
    "duration": 5.361
  },
  {
    "text": "so with a streaming solution, the thing",
    "start": 1959.519,
    "duration": 5.921
  },
  {
    "text": "that we can achieve now is interactive",
    "start": 1962.64,
    "duration": 6.08
  },
  {
    "text": "characters, right? And these interactive",
    "start": 1965.44,
    "duration": 6.239
  },
  {
    "text": "characters could be either AIdriven just",
    "start": 1968.72,
    "duration": 6.16
  },
  {
    "text": "as we saw with AI Vader in Fortnite. So",
    "start": 1971.679,
    "duration": 5.761
  },
  {
    "text": "this would allow NPCs to actually be",
    "start": 1974.88,
    "duration": 5.36
  },
  {
    "text": "responsive to the players and have a",
    "start": 1977.44,
    "duration": 5.2
  },
  {
    "text": "personality of their own. Or these",
    "start": 1980.24,
    "duration": 5.36
  },
  {
    "text": "characters could also be playerdriven,",
    "start": 1982.64,
    "duration": 5.759
  },
  {
    "text": "right? With a streaming model, we would",
    "start": 1985.6,
    "duration": 6.88
  },
  {
    "text": "be able to give the people the power to",
    "start": 1988.399,
    "duration": 6.481
  },
  {
    "text": "actually drive their characters and",
    "start": 1992.48,
    "duration": 5.52
  },
  {
    "text": "having like more a more indepth",
    "start": 1994.88,
    "duration": 5.2
  },
  {
    "text": "experience within games. But this",
    "start": 1998.0,
    "duration": 3.84
  },
  {
    "text": "doesn't only stop in games, right? This",
    "start": 2000.08,
    "duration": 4.24
  },
  {
    "text": "could go into VR experiences or live",
    "start": 2001.84,
    "duration": 4.16
  },
  {
    "text": "experiences.",
    "start": 2004.32,
    "duration": 6.4
  },
  {
    "text": "And however, uh this not only stops in",
    "start": 2006.0,
    "duration": 7.36
  },
  {
    "text": "video games, this also enables content",
    "start": 2010.72,
    "duration": 4.24
  },
  {
    "text": "creation.",
    "start": 2013.36,
    "duration": 5.52
  },
  {
    "text": "Um, with this kind of tool, we believe",
    "start": 2014.96,
    "duration": 7.68
  },
  {
    "text": "that streamers, YouTubers, they would be",
    "start": 2018.88,
    "duration": 8.48
  },
  {
    "text": "able to create this uh amazing",
    "start": 2022.64,
    "duration": 7.759
  },
  {
    "text": "indepth high quality content to bring",
    "start": 2027.36,
    "duration": 5.28
  },
  {
    "text": "smiles to everybody.",
    "start": 2030.399,
    "duration": 5.52
  },
  {
    "text": "Um, however, bringing this into life",
    "start": 2032.64,
    "duration": 5.519
  },
  {
    "text": "isn't easy because there are a few key",
    "start": 2035.919,
    "duration": 3.921
  },
  {
    "text": "constraints that we have to design",
    "start": 2038.159,
    "duration": 4.481
  },
  {
    "text": "around. And one of the first key",
    "start": 2039.84,
    "duration": 6.24
  },
  {
    "text": "constraints is time. We have a short",
    "start": 2042.64,
    "duration": 6.32
  },
  {
    "text": "time budget. What we need to do with",
    "start": 2046.08,
    "duration": 4.88
  },
  {
    "text": "this model and this solution is to come",
    "start": 2048.96,
    "duration": 4.48
  },
  {
    "text": "up with animation predictions within a",
    "start": 2050.96,
    "duration": 4.399
  },
  {
    "text": "frame. Right? We cannot take longer than",
    "start": 2053.44,
    "duration": 3.679
  },
  {
    "text": "that. We need to deliver one frame of",
    "start": 2055.359,
    "duration": 4.72
  },
  {
    "text": "animation bel uh that it's faster than",
    "start": 2057.119,
    "duration": 4.641
  },
  {
    "text": "that.",
    "start": 2060.079,
    "duration": 6.161
  },
  {
    "text": "And uh that will make characters that to",
    "start": 2061.76,
    "duration": 7.44
  },
  {
    "text": "feel responsive and natural. The second",
    "start": 2066.24,
    "duration": 4.96
  },
  {
    "text": "constraint that we have is limited",
    "start": 2069.2,
    "duration": 3.52
  },
  {
    "text": "computation.",
    "start": 2071.2,
    "duration": 3.6
  },
  {
    "text": "Uh one of the goals here is that we",
    "start": 2072.72,
    "duration": 4.24
  },
  {
    "text": "would love this solution to actually be",
    "start": 2074.8,
    "duration": 6.24
  },
  {
    "text": "able to run on CPUs and GPUs uh",
    "start": 2076.96,
    "duration": 6.32
  },
  {
    "text": "regardless of whether it's a high-end",
    "start": 2081.04,
    "duration": 3.76
  },
  {
    "text": "workstation",
    "start": 2083.28,
    "duration": 4.399
  },
  {
    "text": "or something more modest. Uh we are",
    "start": 2084.8,
    "duration": 4.879
  },
  {
    "text": "aiming for scalable performance that",
    "start": 2087.679,
    "duration": 4.561
  },
  {
    "text": "doesn't bottleneck your system. And the",
    "start": 2089.679,
    "duration": 4.96
  },
  {
    "text": "third constraint that we have is a small",
    "start": 2092.24,
    "duration": 4.399
  },
  {
    "text": "memory budget.",
    "start": 2094.639,
    "duration": 4.001
  },
  {
    "text": "uh we would like it to be light enough",
    "start": 2096.639,
    "duration": 4.401
  },
  {
    "text": "such that it can run on mobile devices",
    "start": 2098.64,
    "duration": 4.959
  },
  {
    "text": "or servers at scale without hugging the",
    "start": 2101.04,
    "duration": 5.76
  },
  {
    "text": "resources right such that we can deploy",
    "start": 2103.599,
    "duration": 8.0
  },
  {
    "text": "it easily within these platforms. Um so",
    "start": 2106.8,
    "duration": 7.44
  },
  {
    "text": "now to show you how these key",
    "start": 2111.599,
    "duration": 4.961
  },
  {
    "text": "constraints come into play I will",
    "start": 2114.24,
    "duration": 4.8
  },
  {
    "text": "describe how the audio is being",
    "start": 2116.56,
    "duration": 4.08
  },
  {
    "text": "processed and how it's different between",
    "start": 2119.04,
    "duration": 4.48
  },
  {
    "text": "the offline motor or X A and the",
    "start": 2120.64,
    "duration": 6.56
  },
  {
    "text": "streaming model. So for X A",
    "start": 2123.52,
    "duration": 8.16
  },
  {
    "text": "you take the full audio into play right.",
    "start": 2127.2,
    "duration": 7.84
  },
  {
    "text": "So here comes X A and X A is capable of",
    "start": 2131.68,
    "duration": 6.0
  },
  {
    "text": "seeing the full audio right while",
    "start": 2135.04,
    "duration": 5.12
  },
  {
    "text": "processing it. So whenever it wants to",
    "start": 2137.68,
    "duration": 5.12
  },
  {
    "text": "predict at certain given time it's",
    "start": 2140.16,
    "duration": 4.0
  },
  {
    "text": "capable of looking what's happening in",
    "start": 2142.8,
    "duration": 3.2
  },
  {
    "text": "the audio into the future and into the",
    "start": 2144.16,
    "duration": 4.56
  },
  {
    "text": "past right once it has determined this",
    "start": 2146.0,
    "duration": 5.28
  },
  {
    "text": "is the best frame that I should deliver",
    "start": 2148.72,
    "duration": 4.24
  },
  {
    "text": "it just delivers the full sequence of",
    "start": 2151.28,
    "duration": 4.079
  },
  {
    "text": "metahuman rig parameters",
    "start": 2152.96,
    "duration": 6.399
  },
  {
    "text": "in contrast the streaming audio",
    "start": 2155.359,
    "duration": 6.881
  },
  {
    "text": "it has to look at the audio as it comes",
    "start": 2159.359,
    "duration": 6.24
  },
  {
    "text": "so let's take for example sta will only",
    "start": 2162.24,
    "duration": 6.08
  },
  {
    "text": "take one second of audio at a time",
    "start": 2165.599,
    "duration": 6.321
  },
  {
    "text": "Right. So for this second, it can look",
    "start": 2168.32,
    "duration": 5.2
  },
  {
    "text": "back and forth, back and forth, but only",
    "start": 2171.92,
    "duration": 3.84
  },
  {
    "text": "within this second and then determine",
    "start": 2173.52,
    "duration": 4.0
  },
  {
    "text": "which is the best animation frame that",
    "start": 2175.76,
    "duration": 3.839
  },
  {
    "text": "you have there. Since this is a",
    "start": 2177.52,
    "duration": 4.16
  },
  {
    "text": "streaming, we get a little bit more of",
    "start": 2179.599,
    "duration": 5.441
  },
  {
    "text": "audio. Then we slide ST data or the",
    "start": 2181.68,
    "duration": 5.36
  },
  {
    "text": "streaming model and make the prediction",
    "start": 2185.04,
    "duration": 4.16
  },
  {
    "text": "for the next frame. And this will keep",
    "start": 2187.04,
    "duration": 4.48
  },
  {
    "text": "on happening as the streaming comes in",
    "start": 2189.2,
    "duration": 5.36
  },
  {
    "text": "from the audio until we get the online",
    "start": 2191.52,
    "duration": 6.48
  },
  {
    "text": "solution. Right? So now let me show you",
    "start": 2194.56,
    "duration": 5.44
  },
  {
    "text": "how this works within the Metahuman",
    "start": 2198.0,
    "duration": 4.48
  },
  {
    "text": "animator and I'm glad to say that we",
    "start": 2200.0,
    "duration": 4.56
  },
  {
    "text": "have the actor here for this",
    "start": 2202.48,
    "duration": 4.16
  },
  {
    "text": "performance.",
    "start": 2204.56,
    "duration": 3.6
  },
  {
    "text": "It's also possible to drive the",
    "start": 2206.64,
    "duration": 4.4
  },
  {
    "text": "real-time animation from audio only. So",
    "start": 2208.16,
    "duration": 4.8
  },
  {
    "text": "in this case the audio is being picked",
    "start": 2211.04,
    "duration": 5.6
  },
  {
    "text": "up by a microphone fed into UE and the",
    "start": 2212.96,
    "duration": 5.68
  },
  {
    "text": "animation calculated from just that",
    "start": 2216.64,
    "duration": 4.8
  },
  {
    "text": "audio. It mostly drives the lower face",
    "start": 2218.64,
    "duration": 5.439
  },
  {
    "text": "of the lip sync and the jawline. But",
    "start": 2221.44,
    "duration": 5.2
  },
  {
    "text": "also there are some more subtle controls",
    "start": 2224.079,
    "duration": 5.201
  },
  {
    "text": "to the upper face.",
    "start": 2226.64,
    "duration": 6.719
  },
  {
    "text": ">> All right. Thank you. Um so now so now",
    "start": 2229.28,
    "duration": 5.92
  },
  {
    "text": "now how does it process like each of",
    "start": 2233.359,
    "duration": 4.321
  },
  {
    "text": "these windows? So let's take into",
    "start": 2235.2,
    "duration": 5.2
  },
  {
    "text": "consideration this 1 second input window",
    "start": 2237.68,
    "duration": 4.72
  },
  {
    "text": "of audio",
    "start": 2240.4,
    "duration": 4.88
  },
  {
    "text": "and the model still consists of whisper",
    "start": 2242.4,
    "duration": 4.8
  },
  {
    "text": "right but we do not take the full model",
    "start": 2245.28,
    "duration": 3.6
  },
  {
    "text": "because this would actually take a lot",
    "start": 2247.2,
    "duration": 3.6
  },
  {
    "text": "of time. So will it take the first few",
    "start": 2248.88,
    "duration": 4.32
  },
  {
    "text": "layers? uh in this particular case is",
    "start": 2250.8,
    "duration": 4.559
  },
  {
    "text": "the first two convolutional layers the",
    "start": 2253.2,
    "duration": 4.72
  },
  {
    "text": "CNN plus the first transformer encoder",
    "start": 2255.359,
    "duration": 5.521
  },
  {
    "text": "layer. Then we decode those audio",
    "start": 2257.92,
    "duration": 6.24
  },
  {
    "text": "features into the actual animation by",
    "start": 2260.88,
    "duration": 6.32
  },
  {
    "text": "using a transformerbased model.",
    "start": 2264.16,
    "duration": 6.24
  },
  {
    "text": "Same as with X ADA, we did not fine-tune",
    "start": 2267.2,
    "duration": 5.36
  },
  {
    "text": "whatsoever the whisper features or the",
    "start": 2270.4,
    "duration": 4.48
  },
  {
    "text": "whisper layers, but we did train the",
    "start": 2272.56,
    "duration": 5.039
  },
  {
    "text": "decoder layers. Then since a transformer",
    "start": 2274.88,
    "duration": 4.959
  },
  {
    "text": "is a sequenceto-sequence model, what it",
    "start": 2277.599,
    "duration": 4.721
  },
  {
    "text": "will do is actually give you all the",
    "start": 2279.839,
    "duration": 6.401
  },
  {
    "text": "animation uh parameters for that second.",
    "start": 2282.32,
    "duration": 5.6
  },
  {
    "text": "But since we're working with streaming,",
    "start": 2286.24,
    "duration": 4.24
  },
  {
    "text": "we only select one of those and that's",
    "start": 2287.92,
    "duration": 8.439
  },
  {
    "text": "what we deliver per uh input window.",
    "start": 2290.48,
    "duration": 5.879
  },
  {
    "text": "However, training a tiny model, it",
    "start": 2296.72,
    "duration": 5.76
  },
  {
    "text": "usually requires a lot of data when",
    "start": 2300.079,
    "duration": 4.321
  },
  {
    "text": "you're trying to compress these models",
    "start": 2302.48,
    "duration": 4.8
  },
  {
    "text": "in order that they can generalize. So",
    "start": 2304.4,
    "duration": 7.439
  },
  {
    "text": "for this, we distilled X A by using a",
    "start": 2307.28,
    "duration": 7.2
  },
  {
    "text": "teacher student approach where X A would",
    "start": 2311.839,
    "duration": 5.52
  },
  {
    "text": "be the teacher and our string model SDA",
    "start": 2314.48,
    "duration": 5.52
  },
  {
    "text": "would be the student. uh but the epic",
    "start": 2317.359,
    "duration": 5.521
  },
  {
    "text": "data that we have consists for now of 16",
    "start": 2320.0,
    "duration": 6.72
  },
  {
    "text": "hours and only 10 speakers. So we took",
    "start": 2322.88,
    "duration": 6.0
  },
  {
    "text": "another data set which is the liver",
    "start": 2326.72,
    "duration": 4.48
  },
  {
    "text": "speech data set. Why? Because it's",
    "start": 2328.88,
    "duration": 5.36
  },
  {
    "text": "almost a thousand hours of audio and",
    "start": 2331.2,
    "duration": 6.639
  },
  {
    "text": "more than 2400 speakers.",
    "start": 2334.24,
    "duration": 5.839
  },
  {
    "text": "So we took the audio only from that data",
    "start": 2337.839,
    "duration": 5.921
  },
  {
    "text": "set and pass it on to X A who is the",
    "start": 2340.079,
    "duration": 6.401
  },
  {
    "text": "teacher. However, uh on this first",
    "start": 2343.76,
    "duration": 4.48
  },
  {
    "text": "experiment, we didn't consider the",
    "start": 2346.48,
    "duration": 4.48
  },
  {
    "text": "blinks nor the head motion nor the",
    "start": 2348.24,
    "duration": 6.879
  },
  {
    "text": "motion and got all the solves for those",
    "start": 2350.96,
    "duration": 6.08
  },
  {
    "text": "audio files, right, that come from liver",
    "start": 2355.119,
    "duration": 4.401
  },
  {
    "text": "speech and store them into our synthetic",
    "start": 2357.04,
    "duration": 5.52
  },
  {
    "text": "data set which will serve for training",
    "start": 2359.52,
    "duration": 7.2
  },
  {
    "text": "STA. And that's how we trained it.",
    "start": 2362.56,
    "duration": 6.4
  },
  {
    "text": "And then when we compare like how much",
    "start": 2366.72,
    "duration": 7.119
  },
  {
    "text": "did we distill X A into SD A well on",
    "start": 2368.96,
    "duration": 6.879
  },
  {
    "text": "running time when we're running this on",
    "start": 2373.839,
    "duration": 7.201
  },
  {
    "text": "a CPU uh per second of audio X A takes",
    "start": 2375.839,
    "duration": 8.161
  },
  {
    "text": "172 milliseconds per frame you could say",
    "start": 2381.04,
    "duration": 6.0
  },
  {
    "text": "or per second of audio while SD8 it's",
    "start": 2384.0,
    "duration": 5.599
  },
  {
    "text": "only 16 milliseconds and the main reason",
    "start": 2387.04,
    "duration": 4.72
  },
  {
    "text": "is because whisper right whisper tends",
    "start": 2389.599,
    "duration": 4.401
  },
  {
    "text": "to be quite large and we hear just",
    "start": 2391.76,
    "duration": 5.2
  },
  {
    "text": "taking the first few layers.",
    "start": 2394.0,
    "duration": 4.88
  },
  {
    "text": "Then when we go into the realm of number",
    "start": 2396.96,
    "duration": 4.159
  },
  {
    "text": "of parameters that the networks have, uh",
    "start": 2398.88,
    "duration": 6.479
  },
  {
    "text": "X8 has 103.5 million parameters. Well,",
    "start": 2401.119,
    "duration": 8.0
  },
  {
    "text": "STA is almost 20 times smaller with 4.3",
    "start": 2405.359,
    "duration": 6.161
  },
  {
    "text": "million parameters which then this",
    "start": 2409.119,
    "duration": 4.401
  },
  {
    "text": "reflects on the space on disk that they",
    "start": 2411.52,
    "duration": 5.12
  },
  {
    "text": "take. Uh X A and this is just the face",
    "start": 2413.52,
    "duration": 7.52
  },
  {
    "text": "component uh would take 3894.8",
    "start": 2416.64,
    "duration": 7.439
  },
  {
    "text": "megabytes while STA is only 18",
    "start": 2421.04,
    "duration": 4.72
  },
  {
    "text": "megabytes. So this could be deployable",
    "start": 2424.079,
    "duration": 5.441
  },
  {
    "text": "into mobile devices with no issue.",
    "start": 2425.76,
    "duration": 7.359
  },
  {
    "text": "And here is a video comparing uh X A on",
    "start": 2429.52,
    "duration": 6.88
  },
  {
    "text": "the left and STA on the right. And you",
    "start": 2433.119,
    "duration": 5.441
  },
  {
    "text": "will notice that X A can capture the",
    "start": 2436.4,
    "duration": 5.199
  },
  {
    "text": "subtleties of speech. However, STA",
    "start": 2438.56,
    "duration": 4.96
  },
  {
    "text": "gathers like the course uh overall",
    "start": 2441.599,
    "duration": 4.721
  },
  {
    "text": "course animation of the speech.",
    "start": 2443.52,
    "duration": 5.04
  },
  {
    "text": "At one end stood a great fireplace in",
    "start": 2446.32,
    "duration": 4.56
  },
  {
    "text": "which a blue log was blazing with a blue",
    "start": 2448.56,
    "duration": 4.64
  },
  {
    "text": "flame, and over the fire hung four",
    "start": 2450.88,
    "duration": 4.4
  },
  {
    "text": "kettles in a row, all bubbling and",
    "start": 2453.2,
    "duration": 5.52
  },
  {
    "text": "steaming at a great rate. Glue the sheet",
    "start": 2455.28,
    "duration": 7.559
  },
  {
    "text": "to the dark blue background.",
    "start": 2458.72,
    "duration": 4.119
  },
  {
    "text": "It's easy to tell the depth of a well.",
    "start": 2462.88,
    "duration": 6.64
  },
  {
    "text": "Cool. Uh, and now let me show you a demo",
    "start": 2467.04,
    "duration": 6.76
  },
  {
    "text": "of how it runs in the engine.",
    "start": 2469.52,
    "duration": 4.28
  },
  {
    "text": "So for this, the first thing that you",
    "start": 2475.599,
    "duration": 4.401
  },
  {
    "text": "need to do is to install live link and",
    "start": 2477.68,
    "duration": 4.72
  },
  {
    "text": "add the microphone. In this case, we've",
    "start": 2480.0,
    "duration": 5.119
  },
  {
    "text": "got live link already set up and you",
    "start": 2482.4,
    "duration": 4.719
  },
  {
    "text": "need to add a source. Then from the",
    "start": 2485.119,
    "duration": 5.521
  },
  {
    "text": "source, you go into the metahuman audio.",
    "start": 2487.119,
    "duration": 6.081
  },
  {
    "text": "Go into the new created source and then",
    "start": 2490.64,
    "duration": 4.64
  },
  {
    "text": "select the audio device. We're going to",
    "start": 2493.2,
    "duration": 5.919
  },
  {
    "text": "select this microphone over here.",
    "start": 2495.28,
    "duration": 6.24
  },
  {
    "text": "And then we'll call it subject name.",
    "start": 2499.119,
    "duration": 7.041
  },
  {
    "text": "Let's call it the cell mic. It's me.",
    "start": 2501.52,
    "duration": 6.72
  },
  {
    "text": "And once this is on green, this is ready",
    "start": 2506.16,
    "duration": 6.32
  },
  {
    "text": "to go. Then we select the metahuman that",
    "start": 2508.24,
    "duration": 7.44
  },
  {
    "text": "we want to look at. So this will be",
    "start": 2512.48,
    "duration": 5.04
  },
  {
    "text": "Orlando.",
    "start": 2515.68,
    "duration": 4.08
  },
  {
    "text": "And then we go into the details. Within",
    "start": 2517.52,
    "duration": 4.319
  },
  {
    "text": "the details, you just need to select the",
    "start": 2519.76,
    "duration": 4.16
  },
  {
    "text": "lifelink subject that we just created,",
    "start": 2521.839,
    "duration": 4.721
  },
  {
    "text": "which is Sal Mike. And then just link it",
    "start": 2523.92,
    "duration": 6.88
  },
  {
    "text": "with use link. And there we go. Hey",
    "start": 2526.56,
    "duration": 7.519
  },
  {
    "text": "everybody, thanks for coming.",
    "start": 2530.8,
    "duration": 4.96
  },
  {
    "text": "All right, and that's it for my part.",
    "start": 2534.079,
    "duration": 5.181
  },
  {
    "text": "I'll hand it off to Sara.",
    "start": 2535.76,
    "duration": 12.129
  },
  {
    "text": "[Applause]",
    "start": 2539.26,
    "duration": 8.629
  },
  {
    "text": "So yeah, just to summarize and to wrap",
    "start": 2548.079,
    "duration": 5.121
  },
  {
    "text": "things up, we have presented X aer",
    "start": 2549.839,
    "duration": 4.961
  },
  {
    "text": "expressive audioddriven animation on",
    "start": 2553.2,
    "duration": 3.84
  },
  {
    "text": "metahumans. And this is a method for",
    "start": 2554.8,
    "duration": 4.72
  },
  {
    "text": "animating the face, tongue, and head of",
    "start": 2557.04,
    "duration": 4.72
  },
  {
    "text": "a metahuman from speech. We've talked",
    "start": 2559.52,
    "duration": 4.4
  },
  {
    "text": "you through the R&D behind this. So, our",
    "start": 2561.76,
    "duration": 4.319
  },
  {
    "text": "data capture, our model training, and we",
    "start": 2563.92,
    "duration": 3.679
  },
  {
    "text": "showed you a brief demonstration in",
    "start": 2566.079,
    "duration": 3.921
  },
  {
    "text": "Metuman Animator. And Salvador has",
    "start": 2567.599,
    "duration": 4.081
  },
  {
    "text": "talked through uh the streaming",
    "start": 2570.0,
    "duration": 3.599
  },
  {
    "text": "audio-driven animation solution which is",
    "start": 2571.68,
    "duration": 4.88
  },
  {
    "text": "currently in beta is talked about how it",
    "start": 2573.599,
    "duration": 4.881
  },
  {
    "text": "was trained using a teacher student",
    "start": 2576.56,
    "duration": 3.759
  },
  {
    "text": "paradigm and he demonstrated this in the",
    "start": 2578.48,
    "duration": 3.76
  },
  {
    "text": "human animator as well. So, this wraps",
    "start": 2580.319,
    "duration": 3.921
  },
  {
    "text": "up our talk. I would like to invite you",
    "start": 2582.24,
    "duration": 4.16
  },
  {
    "text": "to the booth to test out both of these",
    "start": 2584.24,
    "duration": 4.0
  },
  {
    "text": "versions if you are interested and we",
    "start": 2586.4,
    "duration": 4.56
  },
  {
    "text": "also link to the documentation from that",
    "start": 2588.24,
    "duration": 5.359
  },
  {
    "text": "QR code there. Um and yeah, any feedback",
    "start": 2590.96,
    "duration": 4.56
  },
  {
    "text": "is very welcome and thank you for your",
    "start": 2593.599,
    "duration": 3.351
  },
  {
    "text": "attention.",
    "start": 2595.52,
    "duration": 11.09
  },
  {
    "text": "[Applause]",
    "start": 2596.95,
    "duration": 9.66
  }
]