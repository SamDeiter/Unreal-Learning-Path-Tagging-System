{
  "text": " So now we know the genetic makeup of an AI agent and how we can achieve navigation. We can now look at how we can allow our AI agents to query the world for information and this is where the environment query system really comes in. The environment query system is a feature within Unreal that is used to gather data about the environment. Example use of this can be to find an ideal position to attack the player from or to find where the nearest health pickup might be. It's important to note that the environment query system plugin must be enabled in order to access this in the editor. Environment queries are a powerful tool for developers, each query is tailored to the scenario in mind. An environment query is made up of generators, tests and contexts to provide a full desired result. And we'll discuss each one of those in just a second. Environment queries can be called from within the behaviour tree directly but they can also be called in isolation from the native C++. Although we are discussing environment queries in the context of AI, it's important to note that we can make use of this system to drive pretty much any other gameplay system. In the image on the left we can see that we create an environment query much in the same way that we create a behaviour tree or a blackboard asset. The image to the right however shows what an environment query looks like in the editor content browser. Let's take a look at how we go about creating our own environment queries and it's only natural that we start with the generators. Generators are key to the genetic makeup of an EQS. They're essentially used to generate an array of locations or actors. These are often referred to as items and these items can then be tested and weighed. There are different types of generator already in Unreal so a small example of these would be generating a list of all actors of class to return a list of actors. Alternatively we can generate a list of points in a circle, grid or donor orientation. So now that we know that a generator is used to give us a set of actors or locations known as items. However, a generator alone is not capable of doing such a task without the use of contexts. Environment contexts give generators and tests a frame of reference to use. Contexts can range from something simple such as the querier to more complex contexts such as all actors of class. Contexts can be set up to return one or many items. It's important to note that whatever generator you choose may not be fully compatible with the intended context. More specifically, not all generators can produce items based off of an input of multiple contexts. On top of all the contexts that come out of the box with Unreal, we can also create our own context in both Blueprint and C++. So now we know we can use a generator to give us a set of actors or locations known as items. However, a generator alone is not capable of doing such a task without the use of contexts. Environment contexts give generators and tests a frame of reference to use. Contexts can range from something as simple as the querier to more complex contexts such as all actors of class. Contexts can be set up to return one or many items. But it's important to know what generator you're going to be pairing with what context. Not all generators can deal with multiple items being returned by a context. On top of contexts already provided by the Unreal Engine, you can also create your own context both in Blueprint and in C++. So let's quickly recap what we know so far. We can use generators to create a choice of items and contexts give us a reference to use when generating those items. So whilst we can use these two in conjunction to give a result, we can make use of tests to better refine our result. Tests can be performed to determine which item is the best option out of all of them. Whatever best means in any given circumstance can be tweaked depending on the developer and the technical specification of the task. Unreal already offers a wide range of tests that we can make use of. So a small example of these would be sorting all items by distance, sorting all items by the dot product in relation to the querier's orientation, filtering out items that don't have line of sight with the querier. And then we can see if these items are overlapping with anything in the world. So for instance, are these items generated within the bounds of some kind of geometry? However, like we said, if these tests don't meet your particular specifications, then by all means you can author your own tests and these can be created quite easily within C++. Multiple tests can be attached to a single generator so we can mix and match to get the best results possible. As we can see in the above image, there are some common properties of the tests that we can actually discuss. The test purpose defines what our test aims to do, whether that is to be filter them out from the entire batch entirely, to score the items or a combination of the two. It's important to know that in the case of filter and score, filtering will be done before scoring to avoid calculating the score on items that have already been filtered out. Each test will expose a different set of filter properties if filtering or filtering score is selected in the test purpose drop down. In the example above, we've used the distance test which will filter any items that are further away than our desired threshold. With scoring, we follow a similar pattern. If score or score and filter are selected in the test purpose, then we get to decide how our items will be scored. Again, the score properties will vary depending on the test that's being used. In the example above, we can define that points further away from the query, our AI agent in this case, will be weighted heavier than those that are closer to the query. However, if we wish to flip this around, we could do this in two ways. The first way would be to flip the scoring equation to use inverse linear. The second way in which we could achieve this is by altering the scoring factor to be negative one. We're essentially going to flip the return value. It's highly recommended that you place filtering tests ahead of your scoring tests, again so the scoring calculations can only take place on valid items.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 6.5,
      "text": " So now we know the genetic makeup of an AI agent and how we can achieve navigation.",
      "tokens": [
        50364,
        407,
        586,
        321,
        458,
        264,
        12462,
        6567,
        295,
        364,
        7318,
        9461,
        293,
        577,
        321,
        393,
        4584,
        17346,
        13,
        50689
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11673524358251074,
      "compression_ratio": 1.7840909090909092,
      "no_speech_prob": 0.00831249076873064
    },
    {
      "id": 1,
      "seek": 0,
      "start": 6.5,
      "end": 10.92,
      "text": " We can now look at how we can allow our AI agents to query the world for information",
      "tokens": [
        50689,
        492,
        393,
        586,
        574,
        412,
        577,
        321,
        393,
        2089,
        527,
        7318,
        12554,
        281,
        14581,
        264,
        1002,
        337,
        1589,
        50910
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11673524358251074,
      "compression_ratio": 1.7840909090909092,
      "no_speech_prob": 0.00831249076873064
    },
    {
      "id": 2,
      "seek": 0,
      "start": 10.92,
      "end": 13.92,
      "text": " and this is where the environment query system really comes in.",
      "tokens": [
        50910,
        293,
        341,
        307,
        689,
        264,
        2823,
        14581,
        1185,
        534,
        1487,
        294,
        13,
        51060
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11673524358251074,
      "compression_ratio": 1.7840909090909092,
      "no_speech_prob": 0.00831249076873064
    },
    {
      "id": 3,
      "seek": 0,
      "start": 13.92,
      "end": 17.44,
      "text": " The environment query system is a feature within Unreal that is used to gather data",
      "tokens": [
        51060,
        440,
        2823,
        14581,
        1185,
        307,
        257,
        4111,
        1951,
        34464,
        300,
        307,
        1143,
        281,
        5448,
        1412,
        51236
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11673524358251074,
      "compression_ratio": 1.7840909090909092,
      "no_speech_prob": 0.00831249076873064
    },
    {
      "id": 4,
      "seek": 0,
      "start": 17.44,
      "end": 19.96,
      "text": " about the environment.",
      "tokens": [
        51236,
        466,
        264,
        2823,
        13,
        51362
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11673524358251074,
      "compression_ratio": 1.7840909090909092,
      "no_speech_prob": 0.00831249076873064
    },
    {
      "id": 5,
      "seek": 0,
      "start": 19.96,
      "end": 23.64,
      "text": " Example use of this can be to find an ideal position to attack the player from or to find",
      "tokens": [
        51362,
        24755,
        781,
        764,
        295,
        341,
        393,
        312,
        281,
        915,
        364,
        7157,
        2535,
        281,
        2690,
        264,
        4256,
        490,
        420,
        281,
        915,
        51546
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11673524358251074,
      "compression_ratio": 1.7840909090909092,
      "no_speech_prob": 0.00831249076873064
    },
    {
      "id": 6,
      "seek": 0,
      "start": 23.64,
      "end": 26.48,
      "text": " where the nearest health pickup might be.",
      "tokens": [
        51546,
        689,
        264,
        23831,
        1585,
        25328,
        1062,
        312,
        13,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11673524358251074,
      "compression_ratio": 1.7840909090909092,
      "no_speech_prob": 0.00831249076873064
    },
    {
      "id": 7,
      "seek": 2648,
      "start": 26.48,
      "end": 30.080000000000002,
      "text": " It's important to note that the environment query system plugin must be enabled in order",
      "tokens": [
        50364,
        467,
        311,
        1021,
        281,
        3637,
        300,
        264,
        2823,
        14581,
        1185,
        23407,
        1633,
        312,
        15172,
        294,
        1668,
        50544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14484851159782053,
      "compression_ratio": 1.7462686567164178,
      "no_speech_prob": 0.025159776210784912
    },
    {
      "id": 8,
      "seek": 2648,
      "start": 30.080000000000002,
      "end": 33.4,
      "text": " to access this in the editor.",
      "tokens": [
        50544,
        281,
        2105,
        341,
        294,
        264,
        9839,
        13,
        50710
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14484851159782053,
      "compression_ratio": 1.7462686567164178,
      "no_speech_prob": 0.025159776210784912
    },
    {
      "id": 9,
      "seek": 2648,
      "start": 33.4,
      "end": 37.120000000000005,
      "text": " Environment queries are a powerful tool for developers, each query is tailored to the",
      "tokens": [
        50710,
        35354,
        24109,
        366,
        257,
        4005,
        2290,
        337,
        8849,
        11,
        1184,
        14581,
        307,
        34858,
        281,
        264,
        50896
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14484851159782053,
      "compression_ratio": 1.7462686567164178,
      "no_speech_prob": 0.025159776210784912
    },
    {
      "id": 10,
      "seek": 2648,
      "start": 37.120000000000005,
      "end": 39.4,
      "text": " scenario in mind.",
      "tokens": [
        50896,
        9005,
        294,
        1575,
        13,
        51010
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14484851159782053,
      "compression_ratio": 1.7462686567164178,
      "no_speech_prob": 0.025159776210784912
    },
    {
      "id": 11,
      "seek": 2648,
      "start": 39.4,
      "end": 44.68,
      "text": " An environment query is made up of generators, tests and contexts to provide a full desired",
      "tokens": [
        51010,
        1107,
        2823,
        14581,
        307,
        1027,
        493,
        295,
        38662,
        11,
        6921,
        293,
        30628,
        281,
        2893,
        257,
        1577,
        14721,
        51274
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14484851159782053,
      "compression_ratio": 1.7462686567164178,
      "no_speech_prob": 0.025159776210784912
    },
    {
      "id": 12,
      "seek": 2648,
      "start": 44.68,
      "end": 45.68,
      "text": " result.",
      "tokens": [
        51274,
        1874,
        13,
        51324
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14484851159782053,
      "compression_ratio": 1.7462686567164178,
      "no_speech_prob": 0.025159776210784912
    },
    {
      "id": 13,
      "seek": 2648,
      "start": 45.68,
      "end": 49.6,
      "text": " And we'll discuss each one of those in just a second.",
      "tokens": [
        51324,
        400,
        321,
        603,
        2248,
        1184,
        472,
        295,
        729,
        294,
        445,
        257,
        1150,
        13,
        51520
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14484851159782053,
      "compression_ratio": 1.7462686567164178,
      "no_speech_prob": 0.025159776210784912
    },
    {
      "id": 14,
      "seek": 2648,
      "start": 49.6,
      "end": 52.56,
      "text": " Environment queries can be called from within the behaviour tree directly but they can also",
      "tokens": [
        51520,
        35354,
        24109,
        393,
        312,
        1219,
        490,
        1951,
        264,
        17229,
        4230,
        3838,
        457,
        436,
        393,
        611,
        51668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14484851159782053,
      "compression_ratio": 1.7462686567164178,
      "no_speech_prob": 0.025159776210784912
    },
    {
      "id": 15,
      "seek": 5256,
      "start": 52.56,
      "end": 56.800000000000004,
      "text": " be called in isolation from the native C++.",
      "tokens": [
        50364,
        312,
        1219,
        294,
        16001,
        490,
        264,
        8470,
        383,
        25472,
        13,
        50576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11408511075106534,
      "compression_ratio": 1.8481848184818481,
      "no_speech_prob": 0.22217091917991638
    },
    {
      "id": 16,
      "seek": 5256,
      "start": 56.800000000000004,
      "end": 60.24,
      "text": " Although we are discussing environment queries in the context of AI, it's important to note",
      "tokens": [
        50576,
        5780,
        321,
        366,
        10850,
        2823,
        24109,
        294,
        264,
        4319,
        295,
        7318,
        11,
        309,
        311,
        1021,
        281,
        3637,
        50748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11408511075106534,
      "compression_ratio": 1.8481848184818481,
      "no_speech_prob": 0.22217091917991638
    },
    {
      "id": 17,
      "seek": 5256,
      "start": 60.24,
      "end": 65.56,
      "text": " that we can make use of this system to drive pretty much any other gameplay system.",
      "tokens": [
        50748,
        300,
        321,
        393,
        652,
        764,
        295,
        341,
        1185,
        281,
        3332,
        1238,
        709,
        604,
        661,
        11421,
        1185,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11408511075106534,
      "compression_ratio": 1.8481848184818481,
      "no_speech_prob": 0.22217091917991638
    },
    {
      "id": 18,
      "seek": 5256,
      "start": 65.56,
      "end": 68.80000000000001,
      "text": " In the image on the left we can see that we create an environment query much in the same",
      "tokens": [
        51014,
        682,
        264,
        3256,
        322,
        264,
        1411,
        321,
        393,
        536,
        300,
        321,
        1884,
        364,
        2823,
        14581,
        709,
        294,
        264,
        912,
        51176
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11408511075106534,
      "compression_ratio": 1.8481848184818481,
      "no_speech_prob": 0.22217091917991638
    },
    {
      "id": 19,
      "seek": 5256,
      "start": 68.80000000000001,
      "end": 72.24000000000001,
      "text": " way that we create a behaviour tree or a blackboard asset.",
      "tokens": [
        51176,
        636,
        300,
        321,
        1884,
        257,
        17229,
        4230,
        420,
        257,
        2211,
        3787,
        11999,
        13,
        51348
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11408511075106534,
      "compression_ratio": 1.8481848184818481,
      "no_speech_prob": 0.22217091917991638
    },
    {
      "id": 20,
      "seek": 5256,
      "start": 72.24000000000001,
      "end": 75.4,
      "text": " The image to the right however shows what an environment query looks like in the editor",
      "tokens": [
        51348,
        440,
        3256,
        281,
        264,
        558,
        4461,
        3110,
        437,
        364,
        2823,
        14581,
        1542,
        411,
        294,
        264,
        9839,
        51506
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11408511075106534,
      "compression_ratio": 1.8481848184818481,
      "no_speech_prob": 0.22217091917991638
    },
    {
      "id": 21,
      "seek": 5256,
      "start": 75.4,
      "end": 78.04,
      "text": " content browser.",
      "tokens": [
        51506,
        2701,
        11185,
        13,
        51638
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11408511075106534,
      "compression_ratio": 1.8481848184818481,
      "no_speech_prob": 0.22217091917991638
    },
    {
      "id": 22,
      "seek": 5256,
      "start": 78.04,
      "end": 81.14,
      "text": " Let's take a look at how we go about creating our own environment queries and it's only",
      "tokens": [
        51638,
        961,
        311,
        747,
        257,
        574,
        412,
        577,
        321,
        352,
        466,
        4084,
        527,
        1065,
        2823,
        24109,
        293,
        309,
        311,
        787,
        51793
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11408511075106534,
      "compression_ratio": 1.8481848184818481,
      "no_speech_prob": 0.22217091917991638
    },
    {
      "id": 23,
      "seek": 8114,
      "start": 81.18,
      "end": 84.58,
      "text": " natural that we start with the generators.",
      "tokens": [
        50366,
        3303,
        300,
        321,
        722,
        365,
        264,
        38662,
        13,
        50536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13500165117198024,
      "compression_ratio": 1.7949640287769784,
      "no_speech_prob": 0.7293097972869873
    },
    {
      "id": 24,
      "seek": 8114,
      "start": 84.58,
      "end": 88.34,
      "text": " Generators are key to the genetic makeup of an EQS.",
      "tokens": [
        50536,
        15409,
        3391,
        366,
        2141,
        281,
        264,
        12462,
        6567,
        295,
        364,
        33580,
        50,
        13,
        50724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13500165117198024,
      "compression_ratio": 1.7949640287769784,
      "no_speech_prob": 0.7293097972869873
    },
    {
      "id": 25,
      "seek": 8114,
      "start": 88.34,
      "end": 92.74,
      "text": " They're essentially used to generate an array of locations or actors.",
      "tokens": [
        50724,
        814,
        434,
        4476,
        1143,
        281,
        8460,
        364,
        10225,
        295,
        9253,
        420,
        10037,
        13,
        50944
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13500165117198024,
      "compression_ratio": 1.7949640287769784,
      "no_speech_prob": 0.7293097972869873
    },
    {
      "id": 26,
      "seek": 8114,
      "start": 92.74,
      "end": 97.42,
      "text": " These are often referred to as items and these items can then be tested and weighed.",
      "tokens": [
        50944,
        1981,
        366,
        2049,
        10839,
        281,
        382,
        4754,
        293,
        613,
        4754,
        393,
        550,
        312,
        8246,
        293,
        32844,
        13,
        51178
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13500165117198024,
      "compression_ratio": 1.7949640287769784,
      "no_speech_prob": 0.7293097972869873
    },
    {
      "id": 27,
      "seek": 8114,
      "start": 97.42,
      "end": 100.58,
      "text": " There are different types of generator already in Unreal so a small example of these would",
      "tokens": [
        51178,
        821,
        366,
        819,
        3467,
        295,
        19265,
        1217,
        294,
        34464,
        370,
        257,
        1359,
        1365,
        295,
        613,
        576,
        51336
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13500165117198024,
      "compression_ratio": 1.7949640287769784,
      "no_speech_prob": 0.7293097972869873
    },
    {
      "id": 28,
      "seek": 8114,
      "start": 100.58,
      "end": 104.9,
      "text": " be generating a list of all actors of class to return a list of actors.",
      "tokens": [
        51336,
        312,
        17746,
        257,
        1329,
        295,
        439,
        10037,
        295,
        1508,
        281,
        2736,
        257,
        1329,
        295,
        10037,
        13,
        51552
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13500165117198024,
      "compression_ratio": 1.7949640287769784,
      "no_speech_prob": 0.7293097972869873
    },
    {
      "id": 29,
      "seek": 8114,
      "start": 104.9,
      "end": 110.48,
      "text": " Alternatively we can generate a list of points in a circle, grid or donor orientation.",
      "tokens": [
        51552,
        46167,
        321,
        393,
        8460,
        257,
        1329,
        295,
        2793,
        294,
        257,
        6329,
        11,
        10748,
        420,
        25493,
        14764,
        13,
        51831
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13500165117198024,
      "compression_ratio": 1.7949640287769784,
      "no_speech_prob": 0.7293097972869873
    },
    {
      "id": 30,
      "seek": 11048,
      "start": 110.48,
      "end": 114.0,
      "text": " So now that we know that a generator is used to give us a set of actors or locations known",
      "tokens": [
        50364,
        407,
        586,
        300,
        321,
        458,
        300,
        257,
        19265,
        307,
        1143,
        281,
        976,
        505,
        257,
        992,
        295,
        10037,
        420,
        9253,
        2570,
        50540
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11497519431857887,
      "compression_ratio": 1.8125,
      "no_speech_prob": 0.004608169198036194
    },
    {
      "id": 31,
      "seek": 11048,
      "start": 114.0,
      "end": 115.0,
      "text": " as items.",
      "tokens": [
        50540,
        382,
        4754,
        13,
        50590
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11497519431857887,
      "compression_ratio": 1.8125,
      "no_speech_prob": 0.004608169198036194
    },
    {
      "id": 32,
      "seek": 11048,
      "start": 115.0,
      "end": 121.74000000000001,
      "text": " However, a generator alone is not capable of doing such a task without the use of contexts.",
      "tokens": [
        50590,
        2908,
        11,
        257,
        19265,
        3312,
        307,
        406,
        8189,
        295,
        884,
        1270,
        257,
        5633,
        1553,
        264,
        764,
        295,
        30628,
        13,
        50927
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11497519431857887,
      "compression_ratio": 1.8125,
      "no_speech_prob": 0.004608169198036194
    },
    {
      "id": 33,
      "seek": 11048,
      "start": 121.74000000000001,
      "end": 126.84,
      "text": " Environment contexts give generators and tests a frame of reference to use.",
      "tokens": [
        50927,
        35354,
        30628,
        976,
        38662,
        293,
        6921,
        257,
        3920,
        295,
        6408,
        281,
        764,
        13,
        51182
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11497519431857887,
      "compression_ratio": 1.8125,
      "no_speech_prob": 0.004608169198036194
    },
    {
      "id": 34,
      "seek": 11048,
      "start": 126.84,
      "end": 131.24,
      "text": " Contexts can range from something simple such as the querier to more complex contexts such",
      "tokens": [
        51182,
        4839,
        3828,
        82,
        393,
        3613,
        490,
        746,
        2199,
        1270,
        382,
        264,
        7083,
        811,
        281,
        544,
        3997,
        30628,
        1270,
        51402
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11497519431857887,
      "compression_ratio": 1.8125,
      "no_speech_prob": 0.004608169198036194
    },
    {
      "id": 35,
      "seek": 11048,
      "start": 131.24,
      "end": 134.2,
      "text": " as all actors of class.",
      "tokens": [
        51402,
        382,
        439,
        10037,
        295,
        1508,
        13,
        51550
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11497519431857887,
      "compression_ratio": 1.8125,
      "no_speech_prob": 0.004608169198036194
    },
    {
      "id": 36,
      "seek": 11048,
      "start": 134.2,
      "end": 138.56,
      "text": " Contexts can be set up to return one or many items.",
      "tokens": [
        51550,
        4839,
        3828,
        82,
        393,
        312,
        992,
        493,
        281,
        2736,
        472,
        420,
        867,
        4754,
        13,
        51768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11497519431857887,
      "compression_ratio": 1.8125,
      "no_speech_prob": 0.004608169198036194
    },
    {
      "id": 37,
      "seek": 13856,
      "start": 138.56,
      "end": 142.36,
      "text": " It's important to note that whatever generator you choose may not be fully compatible with",
      "tokens": [
        50364,
        467,
        311,
        1021,
        281,
        3637,
        300,
        2035,
        19265,
        291,
        2826,
        815,
        406,
        312,
        4498,
        18218,
        365,
        50554
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15535599330686173,
      "compression_ratio": 1.6653846153846155,
      "no_speech_prob": 0.3476759195327759
    },
    {
      "id": 38,
      "seek": 13856,
      "start": 142.36,
      "end": 144.24,
      "text": " the intended context.",
      "tokens": [
        50554,
        264,
        10226,
        4319,
        13,
        50648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15535599330686173,
      "compression_ratio": 1.6653846153846155,
      "no_speech_prob": 0.3476759195327759
    },
    {
      "id": 39,
      "seek": 13856,
      "start": 144.24,
      "end": 149.16,
      "text": " More specifically, not all generators can produce items based off of an input of multiple",
      "tokens": [
        50648,
        5048,
        4682,
        11,
        406,
        439,
        38662,
        393,
        5258,
        4754,
        2361,
        766,
        295,
        364,
        4846,
        295,
        3866,
        50894
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15535599330686173,
      "compression_ratio": 1.6653846153846155,
      "no_speech_prob": 0.3476759195327759
    },
    {
      "id": 40,
      "seek": 13856,
      "start": 149.16,
      "end": 150.16,
      "text": " contexts.",
      "tokens": [
        50894,
        30628,
        13,
        50944
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15535599330686173,
      "compression_ratio": 1.6653846153846155,
      "no_speech_prob": 0.3476759195327759
    },
    {
      "id": 41,
      "seek": 13856,
      "start": 150.16,
      "end": 154.44,
      "text": " On top of all the contexts that come out of the box with Unreal, we can also create our",
      "tokens": [
        50944,
        1282,
        1192,
        295,
        439,
        264,
        30628,
        300,
        808,
        484,
        295,
        264,
        2424,
        365,
        34464,
        11,
        321,
        393,
        611,
        1884,
        527,
        51158
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15535599330686173,
      "compression_ratio": 1.6653846153846155,
      "no_speech_prob": 0.3476759195327759
    },
    {
      "id": 42,
      "seek": 13856,
      "start": 154.44,
      "end": 158.36,
      "text": " own context in both Blueprint and C++.",
      "tokens": [
        51158,
        1065,
        4319,
        294,
        1293,
        2177,
        29017,
        293,
        383,
        25472,
        13,
        51354
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15535599330686173,
      "compression_ratio": 1.6653846153846155,
      "no_speech_prob": 0.3476759195327759
    },
    {
      "id": 43,
      "seek": 13856,
      "start": 158.36,
      "end": 164.16,
      "text": " So now we know we can use a generator to give us a set of actors or locations known as items.",
      "tokens": [
        51354,
        407,
        586,
        321,
        458,
        321,
        393,
        764,
        257,
        19265,
        281,
        976,
        505,
        257,
        992,
        295,
        10037,
        420,
        9253,
        2570,
        382,
        4754,
        13,
        51644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15535599330686173,
      "compression_ratio": 1.6653846153846155,
      "no_speech_prob": 0.3476759195327759
    },
    {
      "id": 44,
      "seek": 16416,
      "start": 165.16,
      "end": 170.68,
      "text": " However, a generator alone is not capable of doing such a task without the use of contexts.",
      "tokens": [
        50414,
        2908,
        11,
        257,
        19265,
        3312,
        307,
        406,
        8189,
        295,
        884,
        1270,
        257,
        5633,
        1553,
        264,
        764,
        295,
        30628,
        13,
        50690
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1315009827707328,
      "compression_ratio": 1.7142857142857142,
      "no_speech_prob": 0.5985644459724426
    },
    {
      "id": 45,
      "seek": 16416,
      "start": 170.68,
      "end": 176.04,
      "text": " Environment contexts give generators and tests a frame of reference to use.",
      "tokens": [
        50690,
        35354,
        30628,
        976,
        38662,
        293,
        6921,
        257,
        3920,
        295,
        6408,
        281,
        764,
        13,
        50958
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1315009827707328,
      "compression_ratio": 1.7142857142857142,
      "no_speech_prob": 0.5985644459724426
    },
    {
      "id": 46,
      "seek": 16416,
      "start": 176.04,
      "end": 180.28,
      "text": " Contexts can range from something as simple as the querier to more complex contexts such",
      "tokens": [
        50958,
        4839,
        3828,
        82,
        393,
        3613,
        490,
        746,
        382,
        2199,
        382,
        264,
        7083,
        811,
        281,
        544,
        3997,
        30628,
        1270,
        51170
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1315009827707328,
      "compression_ratio": 1.7142857142857142,
      "no_speech_prob": 0.5985644459724426
    },
    {
      "id": 47,
      "seek": 16416,
      "start": 180.28,
      "end": 182.92,
      "text": " as all actors of class.",
      "tokens": [
        51170,
        382,
        439,
        10037,
        295,
        1508,
        13,
        51302
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1315009827707328,
      "compression_ratio": 1.7142857142857142,
      "no_speech_prob": 0.5985644459724426
    },
    {
      "id": 48,
      "seek": 16416,
      "start": 182.92,
      "end": 186.24,
      "text": " Contexts can be set up to return one or many items.",
      "tokens": [
        51302,
        4839,
        3828,
        82,
        393,
        312,
        992,
        493,
        281,
        2736,
        472,
        420,
        867,
        4754,
        13,
        51468
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1315009827707328,
      "compression_ratio": 1.7142857142857142,
      "no_speech_prob": 0.5985644459724426
    },
    {
      "id": 49,
      "seek": 16416,
      "start": 186.24,
      "end": 190.51999999999998,
      "text": " But it's important to know what generator you're going to be pairing with what context.",
      "tokens": [
        51468,
        583,
        309,
        311,
        1021,
        281,
        458,
        437,
        19265,
        291,
        434,
        516,
        281,
        312,
        32735,
        365,
        437,
        4319,
        13,
        51682
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1315009827707328,
      "compression_ratio": 1.7142857142857142,
      "no_speech_prob": 0.5985644459724426
    },
    {
      "id": 50,
      "seek": 19052,
      "start": 190.52,
      "end": 195.32000000000002,
      "text": " Not all generators can deal with multiple items being returned by a context.",
      "tokens": [
        50364,
        1726,
        439,
        38662,
        393,
        2028,
        365,
        3866,
        4754,
        885,
        8752,
        538,
        257,
        4319,
        13,
        50604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09163374059340533,
      "compression_ratio": 1.7153024911032029,
      "no_speech_prob": 0.015417365357279778
    },
    {
      "id": 51,
      "seek": 19052,
      "start": 195.32000000000002,
      "end": 199.24,
      "text": " On top of contexts already provided by the Unreal Engine, you can also create your own",
      "tokens": [
        50604,
        1282,
        1192,
        295,
        30628,
        1217,
        5649,
        538,
        264,
        34464,
        7659,
        11,
        291,
        393,
        611,
        1884,
        428,
        1065,
        50800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09163374059340533,
      "compression_ratio": 1.7153024911032029,
      "no_speech_prob": 0.015417365357279778
    },
    {
      "id": 52,
      "seek": 19052,
      "start": 199.24,
      "end": 202.8,
      "text": " context both in Blueprint and in C++.",
      "tokens": [
        50800,
        4319,
        1293,
        294,
        2177,
        29017,
        293,
        294,
        383,
        25472,
        13,
        50978
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09163374059340533,
      "compression_ratio": 1.7153024911032029,
      "no_speech_prob": 0.015417365357279778
    },
    {
      "id": 53,
      "seek": 19052,
      "start": 202.8,
      "end": 205.26000000000002,
      "text": " So let's quickly recap what we know so far.",
      "tokens": [
        50978,
        407,
        718,
        311,
        2661,
        20928,
        437,
        321,
        458,
        370,
        1400,
        13,
        51101
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09163374059340533,
      "compression_ratio": 1.7153024911032029,
      "no_speech_prob": 0.015417365357279778
    },
    {
      "id": 54,
      "seek": 19052,
      "start": 205.26000000000002,
      "end": 209.24,
      "text": " We can use generators to create a choice of items and contexts give us a reference to",
      "tokens": [
        51101,
        492,
        393,
        764,
        38662,
        281,
        1884,
        257,
        3922,
        295,
        4754,
        293,
        30628,
        976,
        505,
        257,
        6408,
        281,
        51300
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09163374059340533,
      "compression_ratio": 1.7153024911032029,
      "no_speech_prob": 0.015417365357279778
    },
    {
      "id": 55,
      "seek": 19052,
      "start": 209.24,
      "end": 212.0,
      "text": " use when generating those items.",
      "tokens": [
        51300,
        764,
        562,
        17746,
        729,
        4754,
        13,
        51438
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09163374059340533,
      "compression_ratio": 1.7153024911032029,
      "no_speech_prob": 0.015417365357279778
    },
    {
      "id": 56,
      "seek": 19052,
      "start": 212.0,
      "end": 215.96,
      "text": " So whilst we can use these two in conjunction to give a result, we can make use of tests",
      "tokens": [
        51438,
        407,
        18534,
        321,
        393,
        764,
        613,
        732,
        294,
        27482,
        281,
        976,
        257,
        1874,
        11,
        321,
        393,
        652,
        764,
        295,
        6921,
        51636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09163374059340533,
      "compression_ratio": 1.7153024911032029,
      "no_speech_prob": 0.015417365357279778
    },
    {
      "id": 57,
      "seek": 19052,
      "start": 215.96,
      "end": 219.12,
      "text": " to better refine our result.",
      "tokens": [
        51636,
        281,
        1101,
        33906,
        527,
        1874,
        13,
        51794
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09163374059340533,
      "compression_ratio": 1.7153024911032029,
      "no_speech_prob": 0.015417365357279778
    },
    {
      "id": 58,
      "seek": 21912,
      "start": 219.12,
      "end": 224.12,
      "text": " Tests can be performed to determine which item is the best option out of all of them.",
      "tokens": [
        50364,
        314,
        4409,
        393,
        312,
        10332,
        281,
        6997,
        597,
        3174,
        307,
        264,
        1151,
        3614,
        484,
        295,
        439,
        295,
        552,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11566734313964844,
      "compression_ratio": 1.7552447552447552,
      "no_speech_prob": 0.011327399872243404
    },
    {
      "id": 59,
      "seek": 21912,
      "start": 224.12,
      "end": 227.48000000000002,
      "text": " Whatever best means in any given circumstance can be tweaked depending on the developer",
      "tokens": [
        50614,
        8541,
        1151,
        1355,
        294,
        604,
        2212,
        27640,
        393,
        312,
        6986,
        7301,
        5413,
        322,
        264,
        10754,
        50782
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11566734313964844,
      "compression_ratio": 1.7552447552447552,
      "no_speech_prob": 0.011327399872243404
    },
    {
      "id": 60,
      "seek": 21912,
      "start": 227.48000000000002,
      "end": 230.96,
      "text": " and the technical specification of the task.",
      "tokens": [
        50782,
        293,
        264,
        6191,
        31256,
        295,
        264,
        5633,
        13,
        50956
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11566734313964844,
      "compression_ratio": 1.7552447552447552,
      "no_speech_prob": 0.011327399872243404
    },
    {
      "id": 61,
      "seek": 21912,
      "start": 230.96,
      "end": 233.82,
      "text": " Unreal already offers a wide range of tests that we can make use of.",
      "tokens": [
        50956,
        34464,
        1217,
        7736,
        257,
        4874,
        3613,
        295,
        6921,
        300,
        321,
        393,
        652,
        764,
        295,
        13,
        51099
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11566734313964844,
      "compression_ratio": 1.7552447552447552,
      "no_speech_prob": 0.011327399872243404
    },
    {
      "id": 62,
      "seek": 21912,
      "start": 233.82,
      "end": 238.4,
      "text": " So a small example of these would be sorting all items by distance, sorting all items by",
      "tokens": [
        51099,
        407,
        257,
        1359,
        1365,
        295,
        613,
        576,
        312,
        32411,
        439,
        4754,
        538,
        4560,
        11,
        32411,
        439,
        4754,
        538,
        51328
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11566734313964844,
      "compression_ratio": 1.7552447552447552,
      "no_speech_prob": 0.011327399872243404
    },
    {
      "id": 63,
      "seek": 21912,
      "start": 238.4,
      "end": 243.9,
      "text": " the dot product in relation to the querier's orientation, filtering out items that don't",
      "tokens": [
        51328,
        264,
        5893,
        1674,
        294,
        9721,
        281,
        264,
        7083,
        811,
        311,
        14764,
        11,
        30822,
        484,
        4754,
        300,
        500,
        380,
        51603
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11566734313964844,
      "compression_ratio": 1.7552447552447552,
      "no_speech_prob": 0.011327399872243404
    },
    {
      "id": 64,
      "seek": 21912,
      "start": 243.9,
      "end": 246.72,
      "text": " have line of sight with the querier.",
      "tokens": [
        51603,
        362,
        1622,
        295,
        7860,
        365,
        264,
        7083,
        811,
        13,
        51744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11566734313964844,
      "compression_ratio": 1.7552447552447552,
      "no_speech_prob": 0.011327399872243404
    },
    {
      "id": 65,
      "seek": 24672,
      "start": 246.72,
      "end": 249.76,
      "text": " And then we can see if these items are overlapping with anything in the world.",
      "tokens": [
        50364,
        400,
        550,
        321,
        393,
        536,
        498,
        613,
        4754,
        366,
        33535,
        365,
        1340,
        294,
        264,
        1002,
        13,
        50516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13890349218087603,
      "compression_ratio": 1.7572815533980584,
      "no_speech_prob": 0.026748526841402054
    },
    {
      "id": 66,
      "seek": 24672,
      "start": 249.76,
      "end": 254.16,
      "text": " So for instance, are these items generated within the bounds of some kind of geometry?",
      "tokens": [
        50516,
        407,
        337,
        5197,
        11,
        366,
        613,
        4754,
        10833,
        1951,
        264,
        29905,
        295,
        512,
        733,
        295,
        18426,
        30,
        50736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13890349218087603,
      "compression_ratio": 1.7572815533980584,
      "no_speech_prob": 0.026748526841402054
    },
    {
      "id": 67,
      "seek": 24672,
      "start": 254.16,
      "end": 258.8,
      "text": " However, like we said, if these tests don't meet your particular specifications, then",
      "tokens": [
        50736,
        2908,
        11,
        411,
        321,
        848,
        11,
        498,
        613,
        6921,
        500,
        380,
        1677,
        428,
        1729,
        29448,
        11,
        550,
        50968
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13890349218087603,
      "compression_ratio": 1.7572815533980584,
      "no_speech_prob": 0.026748526841402054
    },
    {
      "id": 68,
      "seek": 24672,
      "start": 258.8,
      "end": 262.44,
      "text": " by all means you can author your own tests and these can be created quite easily within",
      "tokens": [
        50968,
        538,
        439,
        1355,
        291,
        393,
        3793,
        428,
        1065,
        6921,
        293,
        613,
        393,
        312,
        2942,
        1596,
        3612,
        1951,
        51150
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13890349218087603,
      "compression_ratio": 1.7572815533980584,
      "no_speech_prob": 0.026748526841402054
    },
    {
      "id": 69,
      "seek": 24672,
      "start": 262.44,
      "end": 264.84,
      "text": " C++.",
      "tokens": [
        51150,
        383,
        25472,
        13,
        51270
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13890349218087603,
      "compression_ratio": 1.7572815533980584,
      "no_speech_prob": 0.026748526841402054
    },
    {
      "id": 70,
      "seek": 24672,
      "start": 264.84,
      "end": 269.12,
      "text": " Multiple tests can be attached to a single generator so we can mix and match to get the",
      "tokens": [
        51270,
        40056,
        6921,
        393,
        312,
        8570,
        281,
        257,
        2167,
        19265,
        370,
        321,
        393,
        2890,
        293,
        2995,
        281,
        483,
        264,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13890349218087603,
      "compression_ratio": 1.7572815533980584,
      "no_speech_prob": 0.026748526841402054
    },
    {
      "id": 71,
      "seek": 24672,
      "start": 269.12,
      "end": 271.64,
      "text": " best results possible.",
      "tokens": [
        51484,
        1151,
        3542,
        1944,
        13,
        51610
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13890349218087603,
      "compression_ratio": 1.7572815533980584,
      "no_speech_prob": 0.026748526841402054
    },
    {
      "id": 72,
      "seek": 24672,
      "start": 271.64,
      "end": 274.8,
      "text": " As we can see in the above image, there are some common properties of the tests that we",
      "tokens": [
        51610,
        1018,
        321,
        393,
        536,
        294,
        264,
        3673,
        3256,
        11,
        456,
        366,
        512,
        2689,
        7221,
        295,
        264,
        6921,
        300,
        321,
        51768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13890349218087603,
      "compression_ratio": 1.7572815533980584,
      "no_speech_prob": 0.026748526841402054
    },
    {
      "id": 73,
      "seek": 27480,
      "start": 274.8,
      "end": 276.92,
      "text": " can actually discuss.",
      "tokens": [
        50364,
        393,
        767,
        2248,
        13,
        50470
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1319320327357242,
      "compression_ratio": 1.8248175182481752,
      "no_speech_prob": 0.3916105628013611
    },
    {
      "id": 74,
      "seek": 27480,
      "start": 276.92,
      "end": 281.32,
      "text": " The test purpose defines what our test aims to do, whether that is to be filter them out",
      "tokens": [
        50470,
        440,
        1500,
        4334,
        23122,
        437,
        527,
        1500,
        24683,
        281,
        360,
        11,
        1968,
        300,
        307,
        281,
        312,
        6608,
        552,
        484,
        50690
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1319320327357242,
      "compression_ratio": 1.8248175182481752,
      "no_speech_prob": 0.3916105628013611
    },
    {
      "id": 75,
      "seek": 27480,
      "start": 281.32,
      "end": 287.08000000000004,
      "text": " from the entire batch entirely, to score the items or a combination of the two.",
      "tokens": [
        50690,
        490,
        264,
        2302,
        15245,
        7696,
        11,
        281,
        6175,
        264,
        4754,
        420,
        257,
        6562,
        295,
        264,
        732,
        13,
        50978
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1319320327357242,
      "compression_ratio": 1.8248175182481752,
      "no_speech_prob": 0.3916105628013611
    },
    {
      "id": 76,
      "seek": 27480,
      "start": 287.08000000000004,
      "end": 291.18,
      "text": " It's important to know that in the case of filter and score, filtering will be done before",
      "tokens": [
        50978,
        467,
        311,
        1021,
        281,
        458,
        300,
        294,
        264,
        1389,
        295,
        6608,
        293,
        6175,
        11,
        30822,
        486,
        312,
        1096,
        949,
        51183
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1319320327357242,
      "compression_ratio": 1.8248175182481752,
      "no_speech_prob": 0.3916105628013611
    },
    {
      "id": 77,
      "seek": 27480,
      "start": 291.18,
      "end": 296.28000000000003,
      "text": " scoring to avoid calculating the score on items that have already been filtered out.",
      "tokens": [
        51183,
        22358,
        281,
        5042,
        28258,
        264,
        6175,
        322,
        4754,
        300,
        362,
        1217,
        668,
        37111,
        484,
        13,
        51438
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1319320327357242,
      "compression_ratio": 1.8248175182481752,
      "no_speech_prob": 0.3916105628013611
    },
    {
      "id": 78,
      "seek": 27480,
      "start": 296.28000000000003,
      "end": 300.16,
      "text": " Each test will expose a different set of filter properties if filtering or filtering score",
      "tokens": [
        51438,
        6947,
        1500,
        486,
        19219,
        257,
        819,
        992,
        295,
        6608,
        7221,
        498,
        30822,
        420,
        30822,
        6175,
        51632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1319320327357242,
      "compression_ratio": 1.8248175182481752,
      "no_speech_prob": 0.3916105628013611
    },
    {
      "id": 79,
      "seek": 27480,
      "start": 300.16,
      "end": 303.46000000000004,
      "text": " is selected in the test purpose drop down.",
      "tokens": [
        51632,
        307,
        8209,
        294,
        264,
        1500,
        4334,
        3270,
        760,
        13,
        51797
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1319320327357242,
      "compression_ratio": 1.8248175182481752,
      "no_speech_prob": 0.3916105628013611
    },
    {
      "id": 80,
      "seek": 30346,
      "start": 303.46,
      "end": 307.06,
      "text": " In the example above, we've used the distance test which will filter any items that are",
      "tokens": [
        50364,
        682,
        264,
        1365,
        3673,
        11,
        321,
        600,
        1143,
        264,
        4560,
        1500,
        597,
        486,
        6608,
        604,
        4754,
        300,
        366,
        50544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12244858308271929,
      "compression_ratio": 1.7704280155642023,
      "no_speech_prob": 0.002251072321087122
    },
    {
      "id": 81,
      "seek": 30346,
      "start": 307.06,
      "end": 310.28,
      "text": " further away than our desired threshold.",
      "tokens": [
        50544,
        3052,
        1314,
        813,
        527,
        14721,
        14678,
        13,
        50705
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12244858308271929,
      "compression_ratio": 1.7704280155642023,
      "no_speech_prob": 0.002251072321087122
    },
    {
      "id": 82,
      "seek": 30346,
      "start": 310.28,
      "end": 312.85999999999996,
      "text": " With scoring, we follow a similar pattern.",
      "tokens": [
        50705,
        2022,
        22358,
        11,
        321,
        1524,
        257,
        2531,
        5102,
        13,
        50834
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12244858308271929,
      "compression_ratio": 1.7704280155642023,
      "no_speech_prob": 0.002251072321087122
    },
    {
      "id": 83,
      "seek": 30346,
      "start": 312.85999999999996,
      "end": 316.85999999999996,
      "text": " If score or score and filter are selected in the test purpose, then we get to decide",
      "tokens": [
        50834,
        759,
        6175,
        420,
        6175,
        293,
        6608,
        366,
        8209,
        294,
        264,
        1500,
        4334,
        11,
        550,
        321,
        483,
        281,
        4536,
        51034
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12244858308271929,
      "compression_ratio": 1.7704280155642023,
      "no_speech_prob": 0.002251072321087122
    },
    {
      "id": 84,
      "seek": 30346,
      "start": 316.85999999999996,
      "end": 318.82,
      "text": " how our items will be scored.",
      "tokens": [
        51034,
        577,
        527,
        4754,
        486,
        312,
        18139,
        13,
        51132
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12244858308271929,
      "compression_ratio": 1.7704280155642023,
      "no_speech_prob": 0.002251072321087122
    },
    {
      "id": 85,
      "seek": 30346,
      "start": 318.82,
      "end": 324.34,
      "text": " Again, the score properties will vary depending on the test that's being used.",
      "tokens": [
        51132,
        3764,
        11,
        264,
        6175,
        7221,
        486,
        10559,
        5413,
        322,
        264,
        1500,
        300,
        311,
        885,
        1143,
        13,
        51408
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12244858308271929,
      "compression_ratio": 1.7704280155642023,
      "no_speech_prob": 0.002251072321087122
    },
    {
      "id": 86,
      "seek": 30346,
      "start": 324.34,
      "end": 328.46,
      "text": " In the example above, we can define that points further away from the query, our AI agent",
      "tokens": [
        51408,
        682,
        264,
        1365,
        3673,
        11,
        321,
        393,
        6964,
        300,
        2793,
        3052,
        1314,
        490,
        264,
        14581,
        11,
        527,
        7318,
        9461,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12244858308271929,
      "compression_ratio": 1.7704280155642023,
      "no_speech_prob": 0.002251072321087122
    },
    {
      "id": 87,
      "seek": 32846,
      "start": 328.46,
      "end": 333.02,
      "text": " in this case, will be weighted heavier than those that are closer to the query.",
      "tokens": [
        50364,
        294,
        341,
        1389,
        11,
        486,
        312,
        32807,
        18279,
        813,
        729,
        300,
        366,
        4966,
        281,
        264,
        14581,
        13,
        50592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15848318735758463,
      "compression_ratio": 1.7333333333333334,
      "no_speech_prob": 0.49923476576805115
    },
    {
      "id": 88,
      "seek": 32846,
      "start": 333.02,
      "end": 336.85999999999996,
      "text": " However, if we wish to flip this around, we could do this in two ways.",
      "tokens": [
        50592,
        2908,
        11,
        498,
        321,
        3172,
        281,
        7929,
        341,
        926,
        11,
        321,
        727,
        360,
        341,
        294,
        732,
        2098,
        13,
        50784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15848318735758463,
      "compression_ratio": 1.7333333333333334,
      "no_speech_prob": 0.49923476576805115
    },
    {
      "id": 89,
      "seek": 32846,
      "start": 336.85999999999996,
      "end": 341.62,
      "text": " The first way would be to flip the scoring equation to use inverse linear.",
      "tokens": [
        50784,
        440,
        700,
        636,
        576,
        312,
        281,
        7929,
        264,
        22358,
        5367,
        281,
        764,
        17340,
        8213,
        13,
        51022
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15848318735758463,
      "compression_ratio": 1.7333333333333334,
      "no_speech_prob": 0.49923476576805115
    },
    {
      "id": 90,
      "seek": 32846,
      "start": 341.62,
      "end": 345.78,
      "text": " The second way in which we could achieve this is by altering the scoring factor to be negative",
      "tokens": [
        51022,
        440,
        1150,
        636,
        294,
        597,
        321,
        727,
        4584,
        341,
        307,
        538,
        11337,
        278,
        264,
        22358,
        5952,
        281,
        312,
        3671,
        51230
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15848318735758463,
      "compression_ratio": 1.7333333333333334,
      "no_speech_prob": 0.49923476576805115
    },
    {
      "id": 91,
      "seek": 32846,
      "start": 345.78,
      "end": 346.78,
      "text": " one.",
      "tokens": [
        51230,
        472,
        13,
        51280
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15848318735758463,
      "compression_ratio": 1.7333333333333334,
      "no_speech_prob": 0.49923476576805115
    },
    {
      "id": 92,
      "seek": 32846,
      "start": 346.78,
      "end": 349.34,
      "text": " We're essentially going to flip the return value.",
      "tokens": [
        51280,
        492,
        434,
        4476,
        516,
        281,
        7929,
        264,
        2736,
        2158,
        13,
        51408
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15848318735758463,
      "compression_ratio": 1.7333333333333334,
      "no_speech_prob": 0.49923476576805115
    },
    {
      "id": 93,
      "seek": 32846,
      "start": 349.34,
      "end": 353.62,
      "text": " It's highly recommended that you place filtering tests ahead of your scoring tests, again so",
      "tokens": [
        51408,
        467,
        311,
        5405,
        9628,
        300,
        291,
        1081,
        30822,
        6921,
        2286,
        295,
        428,
        22358,
        6921,
        11,
        797,
        370,
        51622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15848318735758463,
      "compression_ratio": 1.7333333333333334,
      "no_speech_prob": 0.49923476576805115
    },
    {
      "id": 94,
      "seek": 35362,
      "start": 353.62,
      "end": 356.94,
      "text": " the scoring calculations can only take place on valid items.",
      "tokens": [
        50368,
        264,
        22358,
        20448,
        393,
        787,
        747,
        1081,
        322,
        7363,
        4754,
        13,
        50530
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2947991575513567,
      "compression_ratio": 0.967741935483871,
      "no_speech_prob": 0.86505526304245
    }
  ],
  "language": "en"
}