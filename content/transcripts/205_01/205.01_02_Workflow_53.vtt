WEBVTT

1
00:00:00.000 --> 00:00:06.360
As we begin to explore using Unreal Engine for animation, we need to first look at virtual

2
00:00:06.360 --> 00:00:11.280
production pipelines and workflows to better understand where Unreal Engine best fits into

3
00:00:11.280 --> 00:00:13.240
a project.

4
00:00:13.240 --> 00:00:18.880
First, let's look at a very simplified overall workflow for a production that begins like

5
00:00:18.880 --> 00:00:22.040
all productions, with an idea.

6
00:00:22.040 --> 00:00:26.260
Once that idea is presented, it moves its way through development and pre-production,

7
00:00:26.260 --> 00:00:28.160
and then into production.

8
00:00:28.160 --> 00:00:33.080
For now, Unreal Engine can be implemented in these two production stages.

9
00:00:33.080 --> 00:00:37.360
But new tools will allow Unreal Engine to push its way into areas of the post-production

10
00:00:37.360 --> 00:00:42.760
stage, allow a production to extend the range where Unreal Engine can be implemented into

11
00:00:42.760 --> 00:00:45.120
the production pipeline.

12
00:00:45.120 --> 00:00:51.560
Now, if we look at this simplified overview of the typical animation studio pipeline,

13
00:00:51.560 --> 00:00:55.720
the current workflow usually begins with story development.

14
00:00:55.720 --> 00:01:00.480
That's where the story department and storyboards start charting the course of the project,

15
00:01:00.480 --> 00:01:03.000
with the main beats of the story.

16
00:01:03.000 --> 00:01:07.320
This lays down the track for the production train to follow, but in this way, you really

17
00:01:07.320 --> 00:01:12.100
can't move ahead in production without these core elements being nailed down for the other

18
00:01:12.100 --> 00:01:14.760
departments to follow.

19
00:01:14.760 --> 00:01:18.640
Once the story department lays the track, then production design and asset construction

20
00:01:18.640 --> 00:01:20.880
can move full steam ahead.

21
00:01:20.880 --> 00:01:26.240
This is where all the modeling, rigging, surfacing, or texturing happens, along with

22
00:01:26.240 --> 00:01:31.480
figuring out all the technical requirements involved in creating the scene assemblies.

23
00:01:31.480 --> 00:01:35.280
From there, production goes into creating rough layouts, and generally chugs along to

24
00:01:35.280 --> 00:01:41.880
compose all the scenes for the project before animation and layout send shots back and forth

25
00:01:41.880 --> 00:01:46.380
until the final layout is completed.

26
00:01:46.380 --> 00:01:50.860
After that, everything is transferred over to the shot enhancement track, and you might

27
00:01:50.860 --> 00:01:56.420
start doing more shot-specific work for things like lighting, character or camera effects,

28
00:01:56.420 --> 00:02:00.380
crowds, simulation, and creating mats for composite.

29
00:02:00.380 --> 00:02:04.220
Finally, when all that's finished, you're ready to start image output.

30
00:02:04.220 --> 00:02:08.220
Of course, the lighting and editorial teams have probably been working through comps during

31
00:02:08.220 --> 00:02:12.900
the entire process, but now all the elements should start to come together and get that

32
00:02:12.900 --> 00:02:14.820
final edit completed.

33
00:02:15.500 --> 00:02:20.620
So as we just saw through the pipeline example, there are some practical differences that

34
00:02:20.620 --> 00:02:24.500
manifest as strengths and weaknesses to this approach.

35
00:02:24.500 --> 00:02:30.460
These become pretty apparent in the traditional CG animation pipeline, as it is a very front-loaded

36
00:02:30.460 --> 00:02:36.060
story process that almost requires the project teams to figure out all the main story beats

37
00:02:36.060 --> 00:02:39.140
before anyone can do anything else.

38
00:02:39.140 --> 00:02:44.180
This creates those very silo-centric publishing requirements, and that in turn forces the

39
00:02:44.220 --> 00:02:49.380
editorial and layout departments to step in and serve as the main production hub, leaving

40
00:02:49.380 --> 00:02:54.300
principal creatives to be governed by the results of pre-production once all the elements

41
00:02:54.300 --> 00:02:56.120
are in place.

42
00:02:56.120 --> 00:03:00.680
This makes that the only way to know where everything else is going.

43
00:03:00.680 --> 00:03:05.460
This means there is potentially less interactivity between departments, and that can result in

44
00:03:05.460 --> 00:03:08.740
a rather labor-intensive revision process.

45
00:03:08.740 --> 00:03:11.540
And sure, you can still do things like dailies.

46
00:03:11.540 --> 00:03:13.140
That doesn't really change.

47
00:03:13.140 --> 00:03:17.900
But in the traditional pipeline, it's less tactile, and once a shot is near completion

48
00:03:17.900 --> 00:03:22.540
and the layered renders are getting composited for final output, it's not that easy to see

49
00:03:22.540 --> 00:03:26.260
the finished result and then suddenly have to make changes.

50
00:03:26.260 --> 00:03:31.060
At that point, the artist would have to go back, make edits, and then re-export the shot

51
00:03:31.060 --> 00:03:33.060
through the entire pipeline.

52
00:03:33.060 --> 00:03:38.100
And on top of that, limited cross-departmental or even cross-studio compatibility if you

53
00:03:38.100 --> 00:03:43.660
have partners or more locations can create an even slower iteration process than what

54
00:03:43.660 --> 00:03:46.660
you might get when working in real time.

55
00:03:46.660 --> 00:03:52.340
Here, we start to see some of the advantages when using real-time game engines in your

56
00:03:52.340 --> 00:03:53.780
production.

57
00:03:53.780 --> 00:03:58.960
The story development process is better integrated into production, and as a result, shot construction

58
00:03:58.960 --> 00:04:03.780
can feel more like a live-action production, where the director can be involved in the

59
00:04:03.780 --> 00:04:10.620
entire shot creation process thanks to Sequencer acting as the production hub.

60
00:04:10.620 --> 00:04:16.100
Since Unreal Engine's editorial tool, Sequencer, now serves as the production hub, the revision

61
00:04:16.100 --> 00:04:21.140
process, led by the director, becomes much more interactive.

62
00:04:21.140 --> 00:04:26.260
The finished or near final results from Unreal Engine can be exported or rendered at final

63
00:04:26.260 --> 00:04:32.100
pixel levels, and overall, the entire pipeline becomes unified and more collaborative thanks

64
00:04:32.180 --> 00:04:34.620
to real-time integration.

65
00:04:34.620 --> 00:04:39.820
The idea here being that you can either build a new pipeline from the ground up with Unreal

66
00:04:39.820 --> 00:04:44.700
Engine at the core of your workflows or have Unreal Engine take over the areas that benefit

67
00:04:44.700 --> 00:04:48.100
your pipeline for enhanced efficiencies.

68
00:04:48.100 --> 00:04:50.900
So what does that pipeline look like?

69
00:04:50.900 --> 00:04:57.340
Well, in the real-time animation studio pipeline you see here, there are two colors.

70
00:04:57.340 --> 00:05:02.700
Everything in purple is a part of the production that can be done in Unreal Engine.

71
00:05:02.700 --> 00:05:07.700
Everything in teal still requires the use of a DCC application, but anything that shares

72
00:05:07.700 --> 00:05:12.420
both colors can be done using whatever tool the production decides to implement.

73
00:05:12.420 --> 00:05:16.740
That means the first thing that can change is the way story development works.

74
00:05:16.740 --> 00:05:20.700
Instead of being cut off from production, the story can be blocked out in Unreal Engine

75
00:05:20.700 --> 00:05:26.340
by using the free Storyboard plugins Epos and Iliad from the Praxinos Co-op group.

76
00:05:26.340 --> 00:05:32.220
This can be used to generate storyboards and create a real-time story reel or animatic.

77
00:05:32.220 --> 00:05:37.980
This first change can drive faster scene assembly, concurrent modeling, rigging, and surfacing,

78
00:05:37.980 --> 00:05:43.740
and lead production through a more collaborative and dynamic production process.

79
00:05:43.740 --> 00:05:46.980
Everything works together to create the sequence assemblies.

80
00:05:46.980 --> 00:05:51.580
Ideas can be tried out, iterated, and either kept or discarded depending on what best serves

81
00:05:51.580 --> 00:05:53.340
the narrative direction.

82
00:05:53.340 --> 00:05:57.820
Performances can be captured in the engine, adjusted, and polished by animators.

83
00:05:57.820 --> 00:06:02.620
Cinematographers working together with the director in real-time don't even need to

84
00:06:02.620 --> 00:06:08.340
be in the same room as the project can be accessed remotely by staff.

85
00:06:08.340 --> 00:06:11.780
Performances don't necessarily need to be finished before some of the shot enhancements

86
00:06:11.780 --> 00:06:17.140
are implemented as the departments can pass shots around or work in parallel to achieve

87
00:06:17.140 --> 00:06:22.620
near final renders or a complete and more simplified final edit that doesn't have

88
00:06:22.620 --> 00:06:30.140
to wait for everything to be perfect and now allows for a faster revision process.

89
00:06:30.140 --> 00:06:37.580
Now I just mentioned how animation can be done in the engine and really that's what

90
00:06:37.580 --> 00:06:39.020
I want to focus on today.

91
00:06:39.020 --> 00:06:45.820
We're going to take a deeper look at this area in the real-time animation studio pipeline.

92
00:06:45.820 --> 00:06:50.300
Once character asset construction is nearing completion or totally complete if you aren't

93
00:06:50.620 --> 00:06:55.340
the Unreal Engine toolset for creation, then your teams can start creating performances

94
00:06:55.340 --> 00:07:02.340
that can be captured, imported, and edited using Sequencer and Control Rig.

95
00:07:02.340 --> 00:07:06.460
The current workflow for polishing the performance capture animation is one that lends itself

96
00:07:06.460 --> 00:07:10.380
to nearly infinite revisions and noodling.

97
00:07:10.380 --> 00:07:14.420
Once the performances are trimmed down, you can use the bone matching and blend tracks

98
00:07:14.420 --> 00:07:16.460
to create your assembly.

99
00:07:16.460 --> 00:07:19.600
Then just choose one of two paths for polish.

100
00:07:19.600 --> 00:07:23.200
Either go directly to using the inverse solve and baking the performance onto a Control

101
00:07:23.200 --> 00:07:29.360
Rig character or add in some transform track keys and then bake down the animation to the

102
00:07:29.360 --> 00:07:30.880
Control Rig.

103
00:07:30.880 --> 00:07:37.800
From there, just create the Control Rig's additive transform layers and start animating.

104
00:07:37.800 --> 00:07:41.880
As you work through the animation, you can always bake down a new animation sequence

105
00:07:41.880 --> 00:07:45.800
and then apply that new animation track to see how it's going.

106
00:07:45.800 --> 00:07:50.020
This workflow is one that is non-destructive and allows you to go back to any previously

107
00:07:50.020 --> 00:07:53.040
saved point along the process.

108
00:07:53.040 --> 00:07:57.860
So that finishes up our look at the pipeline and workflows for virtual production.

109
00:07:57.860 --> 00:08:02.940
But before we try the animation workflow out on our own, we will do a few quick review

110
00:08:02.940 --> 00:08:07.360
sections of some core concepts starting with importing animations.
