WEBVTT

1
00:00:00.000 --> 00:00:09.000
In this section we continue our hands-on exercise with the next steps of the Mesh to MetaHuman workflow.

2
00:00:09.000 --> 00:00:13.000
So let's dive back into Unreal Engine.

3
00:00:13.000 --> 00:00:18.000
Now the next step is to adjust the camera in lighting.

4
00:00:18.000 --> 00:00:22.000
Go here and click on the viewport camera.

5
00:00:22.000 --> 00:00:27.000
Change the field of view to 20 degrees or something less.

6
00:00:28.000 --> 00:00:36.000
And now position the camera so that the scan is facing forward and is completely visible.

7
00:00:36.000 --> 00:00:40.000
Take your time when framing the face.

8
00:00:41.000 --> 00:00:49.000
Now with the camera positioned, the next step is to adjust the lighting.

9
00:00:49.000 --> 00:00:55.000
Go to the top left of the viewport toolbar and click on lit.

10
00:00:55.000 --> 00:01:01.000
Here you can choose from lit, unlit, or lighting only.

11
00:01:01.000 --> 00:01:07.000
For meshes with skins textured with the skins albedo, unlit works best.

12
00:01:07.000 --> 00:01:19.000
For other meshes, you can rotate the light by holding down L until the entire face is evenly lit.

13
00:01:19.000 --> 00:01:28.000
It is worth mentioning that lighting and framing can influence the way in which the tracking markers track the facial features.

14
00:01:28.000 --> 00:01:35.000
With a full view of the face, the next step is to create a neutral pose frame.

15
00:01:35.000 --> 00:01:39.000
Select the neutral pose component.

16
00:01:39.000 --> 00:01:43.000
In the main toolbar, select promote frame.

17
00:01:43.000 --> 00:01:51.000
A pop-up will appear saying that the current promoted frame will be set as the front view.

18
00:01:51.000 --> 00:01:57.000
If you wish to add additional frames, you can add them by clicking on this.

19
00:01:57.000 --> 00:02:10.000
Just ensure by going to the neutral pose detail panel under frame promotion that used to solve is enabled only for the neutral front facing frame.

20
00:02:10.000 --> 00:02:18.000
Before we continue, let's review the steps we just completed.

21
00:02:18.000 --> 00:02:27.000
After creating a metahuman identity asset and populating it, the next step is to adjust the viewport lighting and camera positioning.

22
00:02:27.000 --> 00:02:34.000
As this step can influence the way the tracking markers land on the facial features.

23
00:02:34.000 --> 00:02:39.000
Adjust the lighting by going to the viewport toolbar and selecting lit.

24
00:02:39.000 --> 00:02:44.000
Then, choose between lit, unlit or lighting only.

25
00:02:44.000 --> 00:02:51.000
As mentioned earlier, for meshes with skins textured using the Skinz Albedo, unlit works best.

26
00:02:51.000 --> 00:02:57.000
For the other two lighting options, rotate the light until the face is evenly lit.

27
00:02:57.000 --> 00:03:04.000
There will be variation in the way tracking markers are placed on the facial features with different lighting scenarios.

28
00:03:04.000 --> 00:03:12.000
And you may find one setting may give you better tracker positioning than others depending on your mesh.

29
00:03:12.000 --> 00:03:23.000
For framing in the viewport toolbar, use the viewport camera options to change the field of view to something around 20 degrees or less.

30
00:03:23.000 --> 00:03:30.000
And then position the camera so that the eyes, mouth and nasolabial folds are visible.

31
00:03:30.000 --> 00:03:34.000
The next step is to promote a front-facing frame.

32
00:03:34.000 --> 00:03:40.000
Select the neutral pose component and then in the main toolbar select promote frame.

33
00:03:40.000 --> 00:03:47.000
Additional frames can be helpful for features such as the ears if you wish to track more details.

34
00:03:47.000 --> 00:03:54.000
When using multiple frames in the neutral pose details panel under the frame promotion settings,

35
00:03:54.000 --> 00:04:00.000
ensure that use to solve is enabled only for the front-facing frame.

36
00:04:00.000 --> 00:04:09.000
Now, let's continue with the next steps of this workflow.

37
00:04:09.000 --> 00:04:13.000
The next step is to track the neutral pose.

38
00:04:13.000 --> 00:04:21.000
With the neutral frame selected, go to the main toolbar and select track markers.

39
00:04:21.000 --> 00:04:29.000
Once we click this, we can see that the tracking markers have been placed on the facial features.

40
00:04:29.000 --> 00:04:43.000
Something to note is that the albedo texture from the scan assists the tracking markers in locating and shaping facial features such as the eyebrows and nasolabial fold creases.

41
00:04:44.000 --> 00:04:56.000
If we were to track this without a texture, it is possible we may get different results as the tracking markers may have a harder time locating the shape of the eyebrows for instance.

42
00:04:56.000 --> 00:05:05.000
In the event that tracking markers may need to be adjusted, for instance, I may want to define the eyes a bit more.

43
00:05:05.000 --> 00:05:14.000
You can select individual tracking markers and reposition them by clicking on them and moving them with your mouse.

44
00:05:14.000 --> 00:05:20.000
If you wish to move an entire tracking section, double-click on the tracking marker curve.

45
00:05:20.000 --> 00:05:26.000
This will select all of the tracking markers, allowing you to move these all together.

46
00:05:26.000 --> 00:05:38.000
You can also deselect tracking markers by holding down shift and then clicking on each one individually.

47
00:05:38.000 --> 00:05:47.000
If you want to add more definition to certain features, you might want to add new tracking markers.

48
00:05:47.000 --> 00:05:56.000
Using the mouth area as an example, using the mouse wheel, I'm going to zoom in on the upper right lip.

49
00:05:56.000 --> 00:06:05.000
To add additional tracking markers, press control and then left mouse click on the tracking curve.

50
00:06:06.000 --> 00:06:17.000
I'm going to go and inspect the right eye and move some of these tracking markers to define the tear-duck region a bit more.

51
00:06:17.000 --> 00:06:30.000
And now I'm going to move over to the left eye and do the same by moving some of these tracking markers in order to fine-tune their position over here.

52
00:06:31.000 --> 00:06:39.000
I'm going to zoom out using the mouse wheel and then with my mouse hovering over the mouth, I will zoom in.

53
00:06:39.000 --> 00:06:47.000
Here, I want to add a bit more definition to the top of the upper lip area.

54
00:06:49.000 --> 00:06:57.000
Again, spend some time with this process as this type of solve depends on how these tracking markers are placed on a 2D image,

55
00:06:57.000 --> 00:07:02.000
as opposed to it being solved on the actual geometry.

56
00:07:02.000 --> 00:07:12.000
Once you are happy with the position of the tracking markers, the next step is to run the metahuman identity solve and view the results.

57
00:07:12.000 --> 00:07:18.000
Go to the toolbar and select metahuman identity solve.

58
00:07:19.000 --> 00:07:30.000
Once the solve completes, you can toggle between the solved mesh and the template mesh in the viewport toolbar by clicking on the AMB tabs.

59
00:07:30.000 --> 00:07:38.000
We can view the results side by side or we can view this as an overlay.

60
00:07:39.000 --> 00:07:49.000
The overlay allows us to compare specific regions of the face close up and decide if we are happy with the way the facial features have been tracked.

61
00:07:49.000 --> 00:07:59.000
If there are areas that may still need adjustments, you can continue the process of fine-tuning the positions of the tracking markers.

62
00:07:59.000 --> 00:08:11.000
If you ever get an error after running the identity solve, you may find it helpful to simply move a few tracking markers and then rerun the identity solve.

63
00:08:11.000 --> 00:08:17.000
Now before we continue, let's review the steps we just completed.

64
00:08:17.000 --> 00:08:26.000
Once you have adjusted the framing and lighting and promoted a front-facing frame, the next step is to track a neutral pose.

65
00:08:26.000 --> 00:08:32.000
You can adjust the tracking markers if needed to fit around the facial features.

66
00:08:32.000 --> 00:08:41.000
Using your mouse, you can move individual markers or groups of markers by double-clicking on a track curve and then moving it.

67
00:08:41.000 --> 00:08:49.000
You can deselect tracking markers by holding down shift and then clicking on individual tracking markers.

68
00:08:49.000 --> 00:08:56.000
And you can add markers by pressing control and then left mouse click on a tracking curve.

69
00:08:56.000 --> 00:09:04.000
Once finished repositioning the tracking markers, the next step is to run the metahuman identity solve.

70
00:09:04.000 --> 00:09:09.000
Inspect the results by using the AMB tabs in the viewport toolbar.

71
00:09:10.000 --> 00:09:19.000
You can view the results side by side between the solved mesh and the template mesh or by using the overlay option.

72
00:09:19.000 --> 00:09:23.000
Now let's continue with the next steps of this workflow.

73
00:09:23.000 --> 00:09:25.000
That's it for this section.

74
00:09:25.000 --> 00:09:34.000
In the next video, we continue our hands-on exercise with the final steps of the mesh-to-metahuman workflow.

