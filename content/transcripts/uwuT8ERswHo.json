[
  {
    "text": "All right, folks. Thanks for coming in.",
    "start": 1.839,
    "duration": 4.161
  },
  {
    "text": "Thanks for finding us uh this morning.",
    "start": 4.0,
    "duration": 4.08
  },
  {
    "text": "Uh welcome to today's session. This is",
    "start": 6.0,
    "duration": 4.559
  },
  {
    "text": "how to build an AI powered digital human",
    "start": 8.08,
    "duration": 4.479
  },
  {
    "text": "in Unreal Engine 5. My name is Jeff",
    "start": 10.559,
    "duration": 4.641
  },
  {
    "text": "Spalding. I'm a senior technical PMM.",
    "start": 12.559,
    "duration": 4.401
  },
  {
    "text": "That stands for product marketing",
    "start": 15.2,
    "duration": 4.72
  },
  {
    "text": "manager. Um so let's get right into it.",
    "start": 16.96,
    "duration": 6.0
  },
  {
    "text": "Today's agenda be discussing a quick",
    "start": 19.92,
    "duration": 4.64
  },
  {
    "text": "introduction from my friend here at",
    "start": 22.96,
    "duration": 3.68
  },
  {
    "text": "Lenovo, Shane. He's going to talk about",
    "start": 24.56,
    "duration": 4.08
  },
  {
    "text": "some of the hardware we have powered uh",
    "start": 26.64,
    "duration": 4.32
  },
  {
    "text": "in the Lenovo booth that powers what we",
    "start": 28.64,
    "duration": 5.439
  },
  {
    "text": "call project R2X and I'll show you a",
    "start": 30.96,
    "duration": 4.72
  },
  {
    "text": "little bit demo a little bit later on.",
    "start": 34.079,
    "duration": 3.921
  },
  {
    "text": "Um, so once we talk about R2X, I'll show",
    "start": 35.68,
    "duration": 3.76
  },
  {
    "text": "you how we can prototype with it,",
    "start": 38.0,
    "duration": 3.52
  },
  {
    "text": "different use cases here, and then we'll",
    "start": 39.44,
    "duration": 4.56
  },
  {
    "text": "go into how to integrate digital humans",
    "start": 41.52,
    "duration": 4.8
  },
  {
    "text": "into games, right? How to go from uh",
    "start": 44.0,
    "duration": 4.559
  },
  {
    "text": "prototype to production, and then I'll",
    "start": 46.32,
    "duration": 4.8
  },
  {
    "text": "go in a little bit detail about NVIDIA",
    "start": 48.559,
    "duration": 4.961
  },
  {
    "text": "and its technologies of how to bring AI",
    "start": 51.12,
    "duration": 4.8
  },
  {
    "text": "models and run them on device. So",
    "start": 53.52,
    "duration": 3.6
  },
  {
    "text": "without further ado, let me just",
    "start": 55.92,
    "duration": 2.319
  },
  {
    "text": "introduce you to my friend Shane from",
    "start": 57.12,
    "duration": 3.279
  },
  {
    "text": "Lenovo here to discuss a little bit",
    "start": 58.239,
    "duration": 4.96
  },
  {
    "text": "about some of the hardware they have.",
    "start": 60.399,
    "duration": 4.641
  },
  {
    "text": ">> All right, thanks Jeeoff. I will be",
    "start": 63.199,
    "duration": 4.401
  },
  {
    "text": "brief everybody. Um, my name is Shane",
    "start": 65.04,
    "duration": 4.96
  },
  {
    "text": "Griffith. I'm the industry manager for",
    "start": 67.6,
    "duration": 5.519
  },
  {
    "text": "Lenovo workstations. Uh, so our P",
    "start": 70.0,
    "duration": 5.28
  },
  {
    "text": "series, everything from desktops like",
    "start": 73.119,
    "duration": 5.841
  },
  {
    "text": "you see here to mobile and the P series",
    "start": 75.28,
    "duration": 6.64
  },
  {
    "text": "monitors as well. Uh, largely I think",
    "start": 78.96,
    "duration": 4.64
  },
  {
    "text": "what Jeff is going to show here in this",
    "start": 81.92,
    "duration": 4.8
  },
  {
    "text": "session is videos and recorded, but I",
    "start": 83.6,
    "duration": 4.559
  },
  {
    "text": "encourage you to come down to the booth.",
    "start": 86.72,
    "duration": 4.8
  },
  {
    "text": "He has it all running live um on one of",
    "start": 88.159,
    "duration": 6.481
  },
  {
    "text": "our P7 uh systems that you see there. Um",
    "start": 91.52,
    "duration": 4.48
  },
  {
    "text": "and what's kind of special about this",
    "start": 94.64,
    "duration": 3.2
  },
  {
    "text": "system that I wanted to make mention to",
    "start": 96.0,
    "duration": 5.28
  },
  {
    "text": "is uh the guys at Nvidia have brought uh",
    "start": 97.84,
    "duration": 8.0
  },
  {
    "text": "into the show the 600 or 6000 series uh",
    "start": 101.28,
    "duration": 8.479
  },
  {
    "text": "Blackwell card. That's a 600 watt um",
    "start": 105.84,
    "duration": 5.76
  },
  {
    "text": "card. So, one of the hardest ones to get",
    "start": 109.759,
    "duration": 4.481
  },
  {
    "text": "right now as as many of you know. Um so,",
    "start": 111.6,
    "duration": 4.159
  },
  {
    "text": "we have that running in a special",
    "start": 114.24,
    "duration": 4.159
  },
  {
    "text": "chassis. Um, feel free to come on down,",
    "start": 115.759,
    "duration": 4.481
  },
  {
    "text": "open up the cabinet, take a look at it.",
    "start": 118.399,
    "duration": 4.561
  },
  {
    "text": "Uh, it's really pretty cool. It'll be",
    "start": 120.24,
    "duration": 4.96
  },
  {
    "text": "releasing sometime later this summer.",
    "start": 122.96,
    "duration": 3.519
  },
  {
    "text": "Uh, right now we're going through",
    "start": 125.2,
    "duration": 5.92
  },
  {
    "text": "testing. Um, but, uh, we anticipate that",
    "start": 126.479,
    "duration": 7.281
  },
  {
    "text": "this chassis on both P7 and P8 to be",
    "start": 131.12,
    "duration": 5.28
  },
  {
    "text": "able to hold three of those cards, um,",
    "start": 133.76,
    "duration": 5.839
  },
  {
    "text": "at once. So, really good, um, powerful",
    "start": 136.4,
    "duration": 4.64
  },
  {
    "text": "system that you can do a lot with,",
    "start": 139.599,
    "duration": 3.761
  },
  {
    "text": "hopefully. Uh, so with that, I'll I'll",
    "start": 141.04,
    "duration": 4.64
  },
  {
    "text": "turn it back over to Jeff and uh, feel",
    "start": 143.36,
    "duration": 4.48
  },
  {
    "text": "free to grab us any one of us at the end",
    "start": 145.68,
    "duration": 4.0
  },
  {
    "text": "of the session for more questions and",
    "start": 147.84,
    "duration": 3.2
  },
  {
    "text": "stop down and say hi.",
    "start": 149.68,
    "duration": 1.68
  },
  {
    "text": ">> All right,",
    "start": 151.04,
    "duration": 0.88
  },
  {
    "text": ">> thanks.",
    "start": 151.36,
    "duration": 2.48
  },
  {
    "text": ">> Thanks, Shane.",
    "start": 151.92,
    "duration": 4.16
  },
  {
    "text": "Okay, let's discuss a little bit about",
    "start": 153.84,
    "duration": 4.96
  },
  {
    "text": "the evolution of the human computer",
    "start": 156.08,
    "duration": 4.56
  },
  {
    "text": "interface. So, I want to set the stage",
    "start": 158.8,
    "duration": 4.159
  },
  {
    "text": "here and just how far along we've come.",
    "start": 160.64,
    "duration": 4.64
  },
  {
    "text": "So, beginning in the 20th century, one",
    "start": 162.959,
    "duration": 4.081
  },
  {
    "text": "of our main interfaces with a computer",
    "start": 165.28,
    "duration": 3.679
  },
  {
    "text": "was punch cards, right? This was used",
    "start": 167.04,
    "duration": 5.279
  },
  {
    "text": "about for 90 years. So punch cards",
    "start": 168.959,
    "duration": 5.28
  },
  {
    "text": "physical medium. We actually had to",
    "start": 172.319,
    "duration": 4.0
  },
  {
    "text": "write the programs on punch cards. Um it",
    "start": 174.239,
    "duration": 4.08
  },
  {
    "text": "was very interesting. Uh a few years ago",
    "start": 176.319,
    "duration": 3.841
  },
  {
    "text": "before I joined Nvidia I was a",
    "start": 178.319,
    "duration": 3.361
  },
  {
    "text": "contractor at the air force research",
    "start": 180.16,
    "duration": 3.52
  },
  {
    "text": "laboratories. Right? So this is about",
    "start": 181.68,
    "duration": 4.16
  },
  {
    "text": "you know 1015 years ago. Um the",
    "start": 183.68,
    "duration": 4.4
  },
  {
    "text": "principal investigator on my project. He",
    "start": 185.84,
    "duration": 4.319
  },
  {
    "text": "actually was telling me his doctoral",
    "start": 188.08,
    "duration": 4.64
  },
  {
    "text": "thesis. He wrote a program on the punch",
    "start": 190.159,
    "duration": 4.8
  },
  {
    "text": "cards. Now this was in the 1980s still",
    "start": 192.72,
    "duration": 4.08
  },
  {
    "text": "right? So we use punch cards up until",
    "start": 194.959,
    "duration": 3.121
  },
  {
    "text": "the 1980s. So he wrote his whole",
    "start": 196.8,
    "duration": 3.6
  },
  {
    "text": "program. It was a stack of cards wrapped",
    "start": 198.08,
    "duration": 4.0
  },
  {
    "text": "in a rubber band. He'd have to submit",
    "start": 200.4,
    "duration": 4.4
  },
  {
    "text": "his job to the system. So most people",
    "start": 202.08,
    "duration": 4.879
  },
  {
    "text": "weren't allowed in those rooms. So you",
    "start": 204.8,
    "duration": 3.439
  },
  {
    "text": "have to have a technician to actually",
    "start": 206.959,
    "duration": 3.2
  },
  {
    "text": "manually feed it into the computer,",
    "start": 208.239,
    "duration": 3.761
  },
  {
    "text": "right? So he'd have to wait sometime a",
    "start": 210.159,
    "duration": 3.521
  },
  {
    "text": "little bit later on to get his output,",
    "start": 212.0,
    "duration": 4.239
  },
  {
    "text": "right? So he get a his output and it' be",
    "start": 213.68,
    "duration": 4.32
  },
  {
    "text": "compiler errors. Have to go punch the",
    "start": 216.239,
    "duration": 3.36
  },
  {
    "text": "cars over again. So can you imagine how",
    "start": 218.0,
    "duration": 3.44
  },
  {
    "text": "far we've come along? So if you went to",
    "start": 219.599,
    "duration": 4.321
  },
  {
    "text": "the state of Unreal yesterday, you saw",
    "start": 221.44,
    "duration": 5.76
  },
  {
    "text": "the UF UEFN, right? We had a uh the",
    "start": 223.92,
    "duration": 5.44
  },
  {
    "text": "assistant was powered by chat GPT that",
    "start": 227.2,
    "duration": 4.72
  },
  {
    "text": "can help you uh generate code. So look",
    "start": 229.36,
    "duration": 4.159
  },
  {
    "text": "how far along we've come. So it wasn't",
    "start": 231.92,
    "duration": 4.319
  },
  {
    "text": "until the 1980s where we started to move",
    "start": 233.519,
    "duration": 4.08
  },
  {
    "text": "into a physical medium, right?",
    "start": 236.239,
    "duration": 3.601
  },
  {
    "text": "Peripherals. We had a mouse and keyboard",
    "start": 237.599,
    "duration": 4.481
  },
  {
    "text": "that was our secondary uh input into the",
    "start": 239.84,
    "duration": 4.56
  },
  {
    "text": "machine. So as a show of hands, uh who",
    "start": 242.08,
    "duration": 4.48
  },
  {
    "text": "prefers a mouse and keyboard versus a",
    "start": 244.4,
    "duration": 4.64
  },
  {
    "text": "controller for gaming?",
    "start": 246.56,
    "duration": 4.72
  },
  {
    "text": "All right, that's about like 50%. Okay.",
    "start": 249.04,
    "duration": 4.0
  },
  {
    "text": "So, I don't know if I have my friend Ike",
    "start": 251.28,
    "duration": 3.84
  },
  {
    "text": "here in the crowd, but he's we we rag",
    "start": 253.04,
    "duration": 3.36
  },
  {
    "text": "him all the time because he's a",
    "start": 255.12,
    "duration": 2.799
  },
  {
    "text": "controller, but you can get the best of",
    "start": 256.4,
    "duration": 3.519
  },
  {
    "text": "both worlds. You can use a controller on",
    "start": 257.919,
    "duration": 3.44
  },
  {
    "text": "a PC game, right? So, whatever your",
    "start": 259.919,
    "duration": 3.441
  },
  {
    "text": "preference is. I personally I like using",
    "start": 261.359,
    "duration": 3.921
  },
  {
    "text": "keyboard and mouse for FPS, but if it's,",
    "start": 263.36,
    "duration": 3.36
  },
  {
    "text": "you know, different type of game, I like",
    "start": 265.28,
    "duration": 4.32
  },
  {
    "text": "using a controller. All right. So, we",
    "start": 266.72,
    "duration": 5.039
  },
  {
    "text": "all know what happened in 2007. This was",
    "start": 269.6,
    "duration": 5.84
  },
  {
    "text": "the iPhone moment, right? Um, ubiquitous",
    "start": 271.759,
    "duration": 5.201
  },
  {
    "text": "around here. It's the full screen",
    "start": 275.44,
    "duration": 3.12
  },
  {
    "text": "touchscreen interface, right? So this",
    "start": 276.96,
    "duration": 4.16
  },
  {
    "text": "became sort of the norm into the",
    "start": 278.56,
    "duration": 4.72
  },
  {
    "text": "interface into computing, right? And",
    "start": 281.12,
    "duration": 5.2
  },
  {
    "text": "then it wasn't until around 2022 we had",
    "start": 283.28,
    "duration": 5.359
  },
  {
    "text": "the rise of large language models in the",
    "start": 286.32,
    "duration": 4.56
  },
  {
    "text": "introduction of the world from chatbt by",
    "start": 288.639,
    "duration": 4.161
  },
  {
    "text": "open AI, right? So this is very",
    "start": 290.88,
    "duration": 3.68
  },
  {
    "text": "interesting because now you can speak to",
    "start": 292.8,
    "duration": 4.32
  },
  {
    "text": "a computer in natural language and get a",
    "start": 294.56,
    "duration": 5.199
  },
  {
    "text": "natural response, right? So what's next",
    "start": 297.12,
    "duration": 4.56
  },
  {
    "text": "in the evolution of our computer human",
    "start": 299.759,
    "duration": 3.681
  },
  {
    "text": "computer interface? Well, here at",
    "start": 301.68,
    "duration": 4.32
  },
  {
    "text": "NVIDIA, we believe that you can converse",
    "start": 303.44,
    "duration": 4.72
  },
  {
    "text": "naturally with your computer through an",
    "start": 306.0,
    "duration": 4.0
  },
  {
    "text": "interface such as a digital human here.",
    "start": 308.16,
    "duration": 3.759
  },
  {
    "text": "So, um, again, we're going to talk about",
    "start": 310.0,
    "duration": 4.72
  },
  {
    "text": "the technologies to bring digital humans",
    "start": 311.919,
    "duration": 5.521
  },
  {
    "text": "to life",
    "start": 314.72,
    "duration": 5.68
  },
  {
    "text": "and we'll do that through a demo we have",
    "start": 317.44,
    "duration": 6.88
  },
  {
    "text": "called Project R2X. So, Project R2X is a",
    "start": 320.4,
    "duration": 7.359
  },
  {
    "text": "3D digital human workflow. This is built",
    "start": 324.32,
    "duration": 6.8
  },
  {
    "text": "on Nvidia Ace. So, Nvidia Ace gaming",
    "start": 327.759,
    "duration": 5.681
  },
  {
    "text": "avatar. This is actually introduced last",
    "start": 331.12,
    "duration": 4.0
  },
  {
    "text": "year by one of my colleagues here. I",
    "start": 333.44,
    "duration": 3.199
  },
  {
    "text": "think she's in the crowd. Uh she",
    "start": 335.12,
    "duration": 3.919
  },
  {
    "text": "discussed the NVIDIA ace gaming avatar.",
    "start": 336.639,
    "duration": 4.161
  },
  {
    "text": "She gave a great presentation that's",
    "start": 339.039,
    "duration": 4.481
  },
  {
    "text": "available on YouTube. So we used that as",
    "start": 340.8,
    "duration": 6.0
  },
  {
    "text": "the basis for project R2X right at the",
    "start": 343.52,
    "duration": 5.28
  },
  {
    "text": "time. Um I believe Allison she showed",
    "start": 346.8,
    "duration": 4.959
  },
  {
    "text": "you the full endtoend workflow with a",
    "start": 348.8,
    "duration": 4.88
  },
  {
    "text": "mixture of cloud models, local models on",
    "start": 351.759,
    "duration": 4.081
  },
  {
    "text": "device. So the latency it went through a",
    "start": 353.68,
    "duration": 4.4
  },
  {
    "text": "full stack. But here with project R2X,",
    "start": 355.84,
    "duration": 3.28
  },
  {
    "text": "I'll show you a video a little bit later",
    "start": 358.08,
    "duration": 3.44
  },
  {
    "text": "on about what we can achieve really low",
    "start": 359.12,
    "duration": 4.96
  },
  {
    "text": "latency end to end. So I can speak to",
    "start": 361.52,
    "duration": 5.119
  },
  {
    "text": "project R2X and I can get a really fast",
    "start": 364.08,
    "duration": 5.679
  },
  {
    "text": "response. So project R2X it serves as a",
    "start": 366.639,
    "duration": 5.201
  },
  {
    "text": "playground. You can test different AI",
    "start": 369.759,
    "duration": 4.081
  },
  {
    "text": "models, different cloud models and we",
    "start": 371.84,
    "duration": 3.28
  },
  {
    "text": "can also integrate it with something",
    "start": 373.84,
    "duration": 4.799
  },
  {
    "text": "called Langflow. Langflow is a it's one",
    "start": 375.12,
    "duration": 5.919
  },
  {
    "text": "of the most popular low code, no code",
    "start": 378.639,
    "duration": 4.321
  },
  {
    "text": "agentic framework. So this will really",
    "start": 381.039,
    "duration": 4.561
  },
  {
    "text": "help you test different use cases here.",
    "start": 382.96,
    "duration": 4.079
  },
  {
    "text": "Um, you can actually create your own",
    "start": 385.6,
    "duration": 2.879
  },
  {
    "text": "nodes. We have an integration with",
    "start": 387.039,
    "duration": 4.401
  },
  {
    "text": "Langflow that supports Project G Assist.",
    "start": 388.479,
    "duration": 4.881
  },
  {
    "text": "So, if you you have heard Project Gist,",
    "start": 391.44,
    "duration": 3.759
  },
  {
    "text": "it's available on the Envy app as an",
    "start": 393.36,
    "duration": 4.399
  },
  {
    "text": "experimental feature. Project Gyist will",
    "start": 395.199,
    "duration": 4.961
  },
  {
    "text": "allow you to control your PC, optimize",
    "start": 397.759,
    "duration": 4.641
  },
  {
    "text": "your PC, launch games, can do several",
    "start": 400.16,
    "duration": 4.159
  },
  {
    "text": "that stuff. So, if you hook up Project",
    "start": 402.4,
    "duration": 4.96
  },
  {
    "text": "R2X here with Langflow, you can ask her",
    "start": 404.319,
    "duration": 5.44
  },
  {
    "text": "like, \"Hey, uh, Project R2X, can you",
    "start": 407.36,
    "duration": 4.0
  },
  {
    "text": "optimize my PC for me?\" Or, \"What kind",
    "start": 409.759,
    "duration": 3.681
  },
  {
    "text": "of GPU do I have?\" So the possibilities",
    "start": 411.36,
    "duration": 5.92
  },
  {
    "text": "are endless with project G assist. Um so",
    "start": 413.44,
    "duration": 5.759
  },
  {
    "text": "a little bit later on I'll show you once",
    "start": 417.28,
    "duration": 4.479
  },
  {
    "text": "we integrate project R2X with Langflow",
    "start": 419.199,
    "duration": 4.481
  },
  {
    "text": "we can use additional functionality from",
    "start": 421.759,
    "duration": 3.681
  },
  {
    "text": "Langflow to achieve an agentic",
    "start": 423.68,
    "duration": 3.84
  },
  {
    "text": "framework. Okay. So the other",
    "start": 425.44,
    "duration": 4.24
  },
  {
    "text": "interesting thing is not only can you",
    "start": 427.52,
    "duration": 4.48
  },
  {
    "text": "use cloud models but we can incorporate",
    "start": 429.68,
    "duration": 5.68
  },
  {
    "text": "NVIDIA NIMS. So NVIDIA NIMS are Nvidia",
    "start": 432.0,
    "duration": 6.0
  },
  {
    "text": "inference microservices. Those are",
    "start": 435.36,
    "duration": 5.04
  },
  {
    "text": "optimized containers that you can deploy",
    "start": 438.0,
    "duration": 7.039
  },
  {
    "text": "on an RTX AIPC with Blackwell cards or",
    "start": 440.4,
    "duration": 6.88
  },
  {
    "text": "you can deploy those in the cloud. So in",
    "start": 445.039,
    "duration": 3.841
  },
  {
    "text": "data centers. So we have those available",
    "start": 447.28,
    "duration": 3.84
  },
  {
    "text": "as well. So once I show you AI a little",
    "start": 448.88,
    "duration": 3.84
  },
  {
    "text": "bit later on we'll we'll show you what's",
    "start": 451.12,
    "duration": 5.12
  },
  {
    "text": "possible with uh project R2X.",
    "start": 452.72,
    "duration": 6.56
  },
  {
    "text": "So let's dive a little bit deeper into",
    "start": 456.24,
    "duration": 5.92
  },
  {
    "text": "the architecture of project R2X. Right?",
    "start": 459.28,
    "duration": 4.72
  },
  {
    "text": "So you can see on the left here I have",
    "start": 462.16,
    "duration": 4.479
  },
  {
    "text": "input from the user. Now I have all",
    "start": 464.0,
    "duration": 4.4
  },
  {
    "text": "these peripherals attached to the",
    "start": 466.639,
    "duration": 4.241
  },
  {
    "text": "Windows PC. I can achieve speech through",
    "start": 468.4,
    "duration": 5.6
  },
  {
    "text": "the microphone, input from the camera or",
    "start": 470.88,
    "duration": 5.2
  },
  {
    "text": "the desktop and I can finally get maybe",
    "start": 474.0,
    "duration": 5.199
  },
  {
    "text": "textual input data files from the actual",
    "start": 476.08,
    "duration": 5.04
  },
  {
    "text": "uh system itself.",
    "start": 479.199,
    "duration": 4.241
  },
  {
    "text": "That input is then fed into a context,",
    "start": 481.12,
    "duration": 4.4
  },
  {
    "text": "right? So we take whether it's text,",
    "start": 483.44,
    "duration": 4.72
  },
  {
    "text": "speech, image context and we basically",
    "start": 485.52,
    "duration": 5.119
  },
  {
    "text": "feed it into our Aentic framework with",
    "start": 488.16,
    "duration": 5.52
  },
  {
    "text": "our Langflow integration, right? So for",
    "start": 490.639,
    "duration": 5.12
  },
  {
    "text": "example, if I share my screen, I'll show",
    "start": 493.68,
    "duration": 3.68
  },
  {
    "text": "you that a little bit later on. I can",
    "start": 495.759,
    "duration": 4.641
  },
  {
    "text": "feed that image input into a cloud model",
    "start": 497.36,
    "duration": 6.32
  },
  {
    "text": "provided by XAI. XAI's GRC vision model",
    "start": 500.4,
    "duration": 4.96
  },
  {
    "text": "has really good understanding of vision.",
    "start": 503.68,
    "duration": 4.799
  },
  {
    "text": "So if I send it a full screen uh desktop",
    "start": 505.36,
    "duration": 6.88
  },
  {
    "text": "share or my web camera, it can help me",
    "start": 508.479,
    "duration": 6.0
  },
  {
    "text": "understand what I'm showing on my screen",
    "start": 512.24,
    "duration": 4.479
  },
  {
    "text": "showing on my uh webcam and basically",
    "start": 514.479,
    "duration": 5.12
  },
  {
    "text": "give me a response for that. If I feed",
    "start": 516.719,
    "duration": 4.961
  },
  {
    "text": "in a file, we can put it through an",
    "start": 519.599,
    "duration": 4.24
  },
  {
    "text": "embedding model here. So what an",
    "start": 521.68,
    "duration": 4.96
  },
  {
    "text": "embedding model does is you take data",
    "start": 523.839,
    "duration": 5.12
  },
  {
    "text": "and basically transforms it into a",
    "start": 526.64,
    "duration": 4.8
  },
  {
    "text": "vector representation. That vector",
    "start": 528.959,
    "duration": 4.641
  },
  {
    "text": "representation is then stored into a",
    "start": 531.44,
    "duration": 4.24
  },
  {
    "text": "vector database. Why do we do that?",
    "start": 533.6,
    "duration": 4.239
  },
  {
    "text": "Well, basically we want to have a way",
    "start": 535.68,
    "duration": 4.88
  },
  {
    "text": "for the machine to quickly search for",
    "start": 537.839,
    "duration": 5.361
  },
  {
    "text": "data. So that's typical in what we call",
    "start": 540.56,
    "duration": 6.24
  },
  {
    "text": "a rag, retrieval augmented generation.",
    "start": 543.2,
    "duration": 6.16
  },
  {
    "text": "So after you ask a question, it can",
    "start": 546.8,
    "duration": 4.159
  },
  {
    "text": "search the vector database really",
    "start": 549.36,
    "duration": 3.36
  },
  {
    "text": "quickly because machines understand",
    "start": 550.959,
    "duration": 5.761
  },
  {
    "text": "machine um vector data and give you",
    "start": 552.72,
    "duration": 6.0
  },
  {
    "text": "response, feed it into the LM and",
    "start": 556.72,
    "duration": 4.72
  },
  {
    "text": "basically give you um a quick response.",
    "start": 558.72,
    "duration": 5.36
  },
  {
    "text": "So all that ends up in our context. That",
    "start": 561.44,
    "duration": 5.839
  },
  {
    "text": "context is then fed into our OpenAI real",
    "start": 564.08,
    "duration": 5.92
  },
  {
    "text": "time speech-to-pech model. So this is",
    "start": 567.279,
    "duration": 3.841
  },
  {
    "text": "different if you've heard of large",
    "start": 570.0,
    "duration": 4.16
  },
  {
    "text": "language models. OpenAI has a fused",
    "start": 571.12,
    "duration": 4.88
  },
  {
    "text": "model. This is speechtoech. So it can",
    "start": 574.16,
    "duration": 4.239
  },
  {
    "text": "take in multiple modalities meaning it",
    "start": 576.0,
    "duration": 4.72
  },
  {
    "text": "can take in text, it can take in speech",
    "start": 578.399,
    "duration": 5.44
  },
  {
    "text": "audio. So speech comes in and basically",
    "start": 580.72,
    "duration": 5.679
  },
  {
    "text": "the OpenAI real time generates a speech",
    "start": 583.839,
    "duration": 5.201
  },
  {
    "text": "response that comes back. I take that",
    "start": 586.399,
    "duration": 5.921
  },
  {
    "text": "audio data and then I feed it into the",
    "start": 589.04,
    "duration": 7.359
  },
  {
    "text": "NVIDIA audiotoface 3D micros service.",
    "start": 592.32,
    "duration": 5.519
  },
  {
    "text": "And if you stop by a little bit later on",
    "start": 596.399,
    "duration": 3.681
  },
  {
    "text": "Lenovo's booth, that service is running",
    "start": 597.839,
    "duration": 4.56
  },
  {
    "text": "locally on my machine. So what does that",
    "start": 600.08,
    "duration": 4.72
  },
  {
    "text": "do? From audio data itself, we can",
    "start": 602.399,
    "duration": 5.201
  },
  {
    "text": "basically infer the blend shapes, the",
    "start": 604.8,
    "duration": 5.28
  },
  {
    "text": "animation output to drive the facial",
    "start": 607.6,
    "duration": 5.04
  },
  {
    "text": "animations in real time for our",
    "start": 610.08,
    "duration": 4.879
  },
  {
    "text": "character, our 3D character here. So",
    "start": 612.64,
    "duration": 3.6
  },
  {
    "text": "once I have those blend shape",
    "start": 614.959,
    "duration": 3.44
  },
  {
    "text": "animations, um that is fed into the",
    "start": 616.24,
    "duration": 4.96
  },
  {
    "text": "Unreal Engine editor and in this case is",
    "start": 618.399,
    "duration": 5.761
  },
  {
    "text": "I'm using UE 5.5 and we're rendering the",
    "start": 621.2,
    "duration": 5.44
  },
  {
    "text": "face the facial animations in real time.",
    "start": 624.16,
    "duration": 5.359
  },
  {
    "text": "So you can use this with any character.",
    "start": 626.64,
    "duration": 6.0
  },
  {
    "text": "The audio toface 3D service outputs we",
    "start": 629.519,
    "duration": 5.841
  },
  {
    "text": "use the actual Apple AR kit. There's 52",
    "start": 632.64,
    "duration": 5.04
  },
  {
    "text": "bones that we animate. So as long as you",
    "start": 635.36,
    "duration": 4.4
  },
  {
    "text": "can map those bones uh to any different",
    "start": 637.68,
    "duration": 3.36
  },
  {
    "text": "character, you can actually achieve this",
    "start": 639.76,
    "duration": 3.68
  },
  {
    "text": "with multiple characters. Now the Nvidia",
    "start": 641.04,
    "duration": 5.52
  },
  {
    "text": "Ace plugin that we have available on",
    "start": 643.44,
    "duration": 4.88
  },
  {
    "text": "developerenvidia.com.",
    "start": 646.56,
    "duration": 4.48
  },
  {
    "text": "Uh the newest version is 2.4. Out of the",
    "start": 648.32,
    "duration": 5.04
  },
  {
    "text": "box, we do support Metahumans. So you",
    "start": 651.04,
    "duration": 3.76
  },
  {
    "text": "can actually have a take a look, import",
    "start": 653.36,
    "duration": 3.76
  },
  {
    "text": "your own metahumans and uh animate that",
    "start": 654.8,
    "duration": 5.599
  },
  {
    "text": "and have fun.",
    "start": 657.12,
    "duration": 3.279
  },
  {
    "text": "All right. So, let's take a look at",
    "start": 661.76,
    "duration": 3.28
  },
  {
    "text": "project R2X. I'm going to show you this",
    "start": 663.44,
    "duration": 4.24
  },
  {
    "text": "video I captured a couple days ago. This",
    "start": 665.04,
    "duration": 4.32
  },
  {
    "text": "is just my initial interaction, right?",
    "start": 667.68,
    "duration": 4.08
  },
  {
    "text": "So, I think this video volume will",
    "start": 669.36,
    "duration": 6.0
  },
  {
    "text": ">> Hi there. Great to have you here.",
    "start": 671.76,
    "duration": 7.36
  },
  {
    "text": ">> Hey, can you introduce yourself?",
    "start": 675.36,
    "duration": 6.159
  },
  {
    "text": ">> Sure thing. I'm AI, your friendly",
    "start": 679.12,
    "duration": 5.44
  },
  {
    "text": "digital assistant. I'm into gaming, AI,",
    "start": 681.519,
    "duration": 5.361
  },
  {
    "text": "tech, and digital art, and I'm here to",
    "start": 684.56,
    "duration": 4.48
  },
  {
    "text": "help make your day a bit smoother and",
    "start": 686.88,
    "duration": 4.0
  },
  {
    "text": "maybe even share a laugh or two along",
    "start": 689.04,
    "duration": 5.919
  },
  {
    "text": "the way. What can I do for you today?",
    "start": 690.88,
    "duration": 5.28
  },
  {
    "text": "All right, so that's my initial",
    "start": 694.959,
    "duration": 4.0
  },
  {
    "text": "interaction with Aki from Project R2X.",
    "start": 696.16,
    "duration": 4.88
  },
  {
    "text": "So, you can see the latency was low.",
    "start": 698.959,
    "duration": 4.56
  },
  {
    "text": "This is a real-time recording. I spoke",
    "start": 701.04,
    "duration": 4.72
  },
  {
    "text": "into the microphone. We sent audio data",
    "start": 703.519,
    "duration": 4.32
  },
  {
    "text": "to OpenAI's real-time speechtoech",
    "start": 705.76,
    "duration": 4.72
  },
  {
    "text": "engine. that outputed auto data back and",
    "start": 707.839,
    "duration": 4.641
  },
  {
    "text": "I was able to stream it into audit to",
    "start": 710.48,
    "duration": 3.76
  },
  {
    "text": "face to produce a blend shape animation.",
    "start": 712.48,
    "duration": 3.76
  },
  {
    "text": "So you can see the latency was really",
    "start": 714.24,
    "duration": 4.64
  },
  {
    "text": "quick there, right? Almost uh instant.",
    "start": 716.24,
    "duration": 4.64
  },
  {
    "text": "Typically, if you've interact with other",
    "start": 718.88,
    "duration": 4.48
  },
  {
    "text": "avatars, there's a slight delay, but",
    "start": 720.88,
    "duration": 5.04
  },
  {
    "text": "this is actually a cloud model. Um, and",
    "start": 723.36,
    "duration": 4.64
  },
  {
    "text": "the internet connection's pretty good.",
    "start": 725.92,
    "duration": 4.32
  },
  {
    "text": "On the show floor, we have a pretty good",
    "start": 728.0,
    "duration": 3.6
  },
  {
    "text": "internet connection, but you can see the",
    "start": 730.24,
    "duration": 4.08
  },
  {
    "text": "latency is really low. Let's ask a few",
    "start": 731.6,
    "duration": 7.08
  },
  {
    "text": "more questions to Aki here.",
    "start": 734.32,
    "duration": 4.36
  },
  {
    "text": ">> Can you tell me an interesting fact?",
    "start": 740.8,
    "duration": 4.4
  },
  {
    "text": "Sure.",
    "start": 743.12,
    "duration": 4.24
  },
  {
    "text": "Did you know that octopuses have three",
    "start": 745.2,
    "duration": 4.8
  },
  {
    "text": "hearts? Two pump blood to the gills",
    "start": 747.36,
    "duration": 4.4
  },
  {
    "text": "while the third pumps it to the rest of",
    "start": 750.0,
    "duration": 4.16
  },
  {
    "text": "the body. Plus, their blood is blue",
    "start": 751.76,
    "duration": 4.56
  },
  {
    "text": "because it's copper based. Pretty cool,",
    "start": 754.16,
    "duration": 3.6
  },
  {
    "text": "right?",
    "start": 756.32,
    "duration": 3.84
  },
  {
    "text": ">> It's pretty cool.",
    "start": 757.76,
    "duration": 6.92
  },
  {
    "text": ">> Do you know what Unreal Fest is?",
    "start": 760.16,
    "duration": 4.52
  },
  {
    "text": ">> Unreal Fest is a big event for creators",
    "start": 765.04,
    "duration": 5.68
  },
  {
    "text": "using Unreal Engine. It's typically a",
    "start": 767.68,
    "duration": 5.68
  },
  {
    "text": "mix of presentations, workshops, and",
    "start": 770.72,
    "duration": 5.28
  },
  {
    "text": "networking, all focused on game",
    "start": 773.36,
    "duration": 5.52
  },
  {
    "text": "development, design, and the latest tech",
    "start": 776.0,
    "duration": 5.519
  },
  {
    "text": "in the industry. It's a pretty exciting",
    "start": 778.88,
    "duration": 4.079
  },
  {
    "text": "gathering if you're into game",
    "start": 781.519,
    "duration": 6.041
  },
  {
    "text": "development or 3D design.",
    "start": 782.959,
    "duration": 4.601
  },
  {
    "text": ">> All right, just setting the stage here",
    "start": 787.76,
    "duration": 3.84
  },
  {
    "text": "for my next video, but you can see um",
    "start": 789.2,
    "duration": 4.319
  },
  {
    "text": "notice that Project R2X, we do have",
    "start": 791.6,
    "duration": 3.44
  },
  {
    "text": "transparency, so we're using alpha",
    "start": 793.519,
    "duration": 3.921
  },
  {
    "text": "blending. So in this case, the use case",
    "start": 795.04,
    "duration": 4.08
  },
  {
    "text": "here was a digital avatar you can",
    "start": 797.44,
    "duration": 3.28
  },
  {
    "text": "interact with on your computer screen.",
    "start": 799.12,
    "duration": 2.959
  },
  {
    "text": "Um, again, this is being rendered in",
    "start": 800.72,
    "duration": 4.16
  },
  {
    "text": "Unreal Engine 5. Latency is really low.",
    "start": 802.079,
    "duration": 4.721
  },
  {
    "text": "Um, next, you know, I just asked her",
    "start": 804.88,
    "duration": 2.959
  },
  {
    "text": "basic questions. This is really good.",
    "start": 806.8,
    "duration": 2.8
  },
  {
    "text": "She understood what Unreal Fest is. So",
    "start": 807.839,
    "duration": 4.481
  },
  {
    "text": "that was in OpenAI's language model, but",
    "start": 809.6,
    "duration": 4.64
  },
  {
    "text": "she won't know details. So if I ask her",
    "start": 812.32,
    "duration": 3.28
  },
  {
    "text": "specific questions like, hey, where's",
    "start": 814.24,
    "duration": 3.599
  },
  {
    "text": "Unreal Fest being held this year? She",
    "start": 815.6,
    "duration": 3.52
  },
  {
    "text": "doesn't know a general response. She's",
    "start": 817.839,
    "duration": 3.921
  },
  {
    "text": "only trained up to a certain point. So",
    "start": 819.12,
    "duration": 4.64
  },
  {
    "text": "that's the limitation. But a little bit",
    "start": 821.76,
    "duration": 3.44
  },
  {
    "text": "later, I'll show you how we can hook her",
    "start": 823.76,
    "duration": 3.759
  },
  {
    "text": "up to Langflow to do an agentic",
    "start": 825.2,
    "duration": 4.4
  },
  {
    "text": "framework. But first, let me show you",
    "start": 827.519,
    "duration": 3.521
  },
  {
    "text": "this feature here where I can actually",
    "start": 829.6,
    "duration": 4.919
  },
  {
    "text": "share my screen.",
    "start": 831.04,
    "duration": 3.479
  },
  {
    "text": "So, go on the bottom here. I'll click",
    "start": 839.6,
    "duration": 3.76
  },
  {
    "text": "share screen.",
    "start": 841.12,
    "duration": 3.68
  },
  {
    "text": "I'm gonna stop at the gear store before",
    "start": 843.36,
    "duration": 3.12
  },
  {
    "text": "I head out to Orlando. What do you",
    "start": 844.8,
    "duration": 4.56
  },
  {
    "text": "suggest I wear?",
    "start": 846.48,
    "duration": 5.359
  },
  {
    "text": "For Orlando, I'd suggest something light",
    "start": 849.36,
    "duration": 5.12
  },
  {
    "text": "and comfortable. The Cuda t-shirt or the",
    "start": 851.839,
    "duration": 5.12
  },
  {
    "text": "GeForce t-shirt both look great and are",
    "start": 854.48,
    "duration": 4.799
  },
  {
    "text": "perfect for warm weather. Pair it with",
    "start": 856.959,
    "duration": 4.721
  },
  {
    "text": "comfortable jeans or shorts and you'll",
    "start": 859.279,
    "duration": 5.201
  },
  {
    "text": "be set for your trip. Have fun at Unreal",
    "start": 861.68,
    "duration": 4.88
  },
  {
    "text": "Fest.",
    "start": 864.48,
    "duration": 4.159
  },
  {
    "text": ">> All right, so notice the conversation",
    "start": 866.56,
    "duration": 4.399
  },
  {
    "text": "history still maintained, right? This",
    "start": 868.639,
    "duration": 4.081
  },
  {
    "text": "was in the same session. She knew I",
    "start": 870.959,
    "duration": 3.921
  },
  {
    "text": "asked her about Unreal Fest earlier. I",
    "start": 872.72,
    "duration": 3.919
  },
  {
    "text": "asked her about this and she was able to",
    "start": 874.88,
    "duration": 4.079
  },
  {
    "text": "weave in the uh have fun on them real",
    "start": 876.639,
    "duration": 4.0
  },
  {
    "text": "fast. So, this is very interesting. I",
    "start": 878.959,
    "duration": 2.88
  },
  {
    "text": "did not actually end up getting a",
    "start": 880.639,
    "duration": 4.0
  },
  {
    "text": "t-shirt on my way out here, but um next",
    "start": 881.839,
    "duration": 5.281
  },
  {
    "text": "time I'll get the the Cuda t-shirt. All",
    "start": 884.639,
    "duration": 4.801
  },
  {
    "text": "right. So, you can see some limitations.",
    "start": 887.12,
    "duration": 4.0
  },
  {
    "text": "I asked her about Unreal Fest, but she",
    "start": 889.44,
    "duration": 3.92
  },
  {
    "text": "doesn't know current information. She",
    "start": 891.12,
    "duration": 4.32
  },
  {
    "text": "can't search the internet. And I'll show",
    "start": 893.36,
    "duration": 3.76
  },
  {
    "text": "you once we hook up the Langflow",
    "start": 895.44,
    "duration": 3.6
  },
  {
    "text": "integration how that can achieve an",
    "start": 897.12,
    "duration": 3.839
  },
  {
    "text": "agentic framework. So, let's check this",
    "start": 899.04,
    "duration": 4.799
  },
  {
    "text": "out. So, basically, um, I'll go into the",
    "start": 900.959,
    "duration": 5.361
  },
  {
    "text": "options, but let's ask her a question",
    "start": 903.839,
    "duration": 3.44
  },
  {
    "text": "about, uh, this",
    "start": 906.32,
    "duration": 4.44
  },
  {
    "text": ">> what's on news.lenovo.com.",
    "start": 907.279,
    "duration": 3.481
  },
  {
    "text": ">> I can't check that right now, but you",
    "start": 911.68,
    "duration": 4.08
  },
  {
    "text": "can visit the site to see the latest",
    "start": 914.079,
    "duration": 3.521
  },
  {
    "text": "from Lenovo.",
    "start": 915.76,
    "duration": 5.04
  },
  {
    "text": "Anything specific you're looking for?",
    "start": 917.6,
    "duration": 4.799
  },
  {
    "text": ">> All right. So, limitation right there.",
    "start": 920.8,
    "duration": 3.68
  },
  {
    "text": "Doesn't can't check the website. So, I'm",
    "start": 922.399,
    "duration": 4.641
  },
  {
    "text": "going to stop uh the session here. I'm",
    "start": 924.48,
    "duration": 5.039
  },
  {
    "text": "going to change my connection to hook up",
    "start": 927.04,
    "duration": 4.4
  },
  {
    "text": "to my Langflow server running on my",
    "start": 929.519,
    "duration": 4.88
  },
  {
    "text": "desktop. So, I supplied my Langflow ID",
    "start": 931.44,
    "duration": 4.88
  },
  {
    "text": "and that's you can see here in the right",
    "start": 934.399,
    "duration": 4.721
  },
  {
    "text": "side of the screen. We'll hit play and",
    "start": 936.32,
    "duration": 3.759
  },
  {
    "text": "basically start the session.",
    "start": 939.12,
    "duration": 4.12
  },
  {
    "text": ">> Hi there.",
    "start": 940.079,
    "duration": 3.161
  },
  {
    "text": ">> What's the latest on news.lenovo.com?",
    "start": 943.839,
    "duration": 3.961
  },
  {
    "text": ">> Hold on while I check the latest news on",
    "start": 949.04,
    "duration": 5.32
  },
  {
    "text": "Lenovo's website.",
    "start": 950.72,
    "duration": 3.64
  },
  {
    "text": "Here are the latest highlights from",
    "start": 954.56,
    "duration": 3.92
  },
  {
    "text": "Lenovo's news site. One, Lenovo and",
    "start": 956.0,
    "duration": 4.24
  },
  {
    "text": "Motorola partner with FIFA Club World",
    "start": 958.48,
    "duration": 4.56
  },
  {
    "text": "Cup 2025. Two, tech driving business",
    "start": 960.24,
    "duration": 4.88
  },
  {
    "text": "innovation with Lenovo and DreamWorks.",
    "start": 963.04,
    "duration": 4.56
  },
  {
    "text": "Three, Lenovo CFO discusses earnings and",
    "start": 965.12,
    "duration": 5.12
  },
  {
    "text": "AI strategy. Four, Lenovo's AI",
    "start": 967.6,
    "duration": 4.479
  },
  {
    "text": "collaboration with Nvidia recognized in",
    "start": 970.24,
    "duration": 4.719
  },
  {
    "text": "enterprise AI. Five, AI blending with",
    "start": 972.079,
    "duration": 4.56
  },
  {
    "text": "wildlife conservation for a smarter",
    "start": 974.959,
    "duration": 2.161
  },
  {
    "text": "future.",
    "start": 976.639,
    "duration": 1.841
  },
  {
    "text": ">> Okay, so you get the idea. I'm just",
    "start": 977.12,
    "duration": 3.2
  },
  {
    "text": "going to fade it out, but that looks",
    "start": 978.48,
    "duration": 3.279
  },
  {
    "text": "pretty good, right, Shane? So that's",
    "start": 980.32,
    "duration": 3.28
  },
  {
    "text": "correct. So you can actually see we can",
    "start": 981.759,
    "duration": 4.721
  },
  {
    "text": "see the tool calling here in Langflow.",
    "start": 983.6,
    "duration": 4.479
  },
  {
    "text": "It actually called one of the tools",
    "start": 986.48,
    "duration": 3.2
  },
  {
    "text": "here. This is fetch content. It",
    "start": 988.079,
    "duration": 3.601
  },
  {
    "text": "basically fetched the content retrieve",
    "start": 989.68,
    "duration": 4.24
  },
  {
    "text": "the JSON result and this is what it",
    "start": 991.68,
    "duration": 4.0
  },
  {
    "text": "supplied to opening eyes. So you can see",
    "start": 993.92,
    "duration": 3.76
  },
  {
    "text": "enumerated that. So none of that was",
    "start": 995.68,
    "duration": 5.04
  },
  {
    "text": "actually in the prompt. Project Arch was",
    "start": 997.68,
    "duration": 5.839
  },
  {
    "text": "able to use Langflow, determined that I",
    "start": 1000.72,
    "duration": 5.6
  },
  {
    "text": "basically was asking for a tool call,",
    "start": 1003.519,
    "duration": 6.32
  },
  {
    "text": "initiated the call, went to newslet.com,",
    "start": 1006.32,
    "duration": 5.84
  },
  {
    "text": "scraped the site, returned the JSON, and",
    "start": 1009.839,
    "duration": 5.36
  },
  {
    "text": "fed it back into the OpenAI real-time",
    "start": 1012.16,
    "duration": 4.479
  },
  {
    "text": "speech and generated that. And you can",
    "start": 1015.199,
    "duration": 3.2
  },
  {
    "text": "see the latency was really low. And we",
    "start": 1016.639,
    "duration": 3.281
  },
  {
    "text": "had little nuances here. So you can you",
    "start": 1018.399,
    "duration": 3.281
  },
  {
    "text": "can see she was actually thinking, she",
    "start": 1019.92,
    "duration": 4.32
  },
  {
    "text": "was animating. So those little kind of",
    "start": 1021.68,
    "duration": 4.48
  },
  {
    "text": "um non-verbal responses just make it",
    "start": 1024.24,
    "duration": 4.0
  },
  {
    "text": "more kind of interactive, more immersive",
    "start": 1026.16,
    "duration": 4.56
  },
  {
    "text": "as you're speaking to Project R2X. So",
    "start": 1028.24,
    "duration": 3.839
  },
  {
    "text": "this is example of our Langflow",
    "start": 1030.72,
    "duration": 5.44
  },
  {
    "text": "integration. Um so let's do a little bit",
    "start": 1032.079,
    "duration": 6.401
  },
  {
    "text": "more use cases here. Let's say you're a",
    "start": 1036.16,
    "duration": 4.0
  },
  {
    "text": "game developer. You want to test out",
    "start": 1038.48,
    "duration": 4.4
  },
  {
    "text": "different uh prototypes. Um another",
    "start": 1040.16,
    "duration": 4.639
  },
  {
    "text": "feature we have with Project R2X is the",
    "start": 1042.88,
    "duration": 4.959
  },
  {
    "text": "ability to ingest documents, right? So I",
    "start": 1044.799,
    "duration": 5.201
  },
  {
    "text": "was able to speak into the microphone. I",
    "start": 1047.839,
    "duration": 4.08
  },
  {
    "text": "was able to share my screen with vision.",
    "start": 1050.0,
    "duration": 4.72
  },
  {
    "text": "But now what if we want to process data?",
    "start": 1051.919,
    "duration": 6.081
  },
  {
    "text": "So in this case I have a example uh game",
    "start": 1054.72,
    "duration": 6.88
  },
  {
    "text": "lore. This is a 60 kilobyte text file.",
    "start": 1058.0,
    "duration": 5.52
  },
  {
    "text": "So one of my colleagues generated this.",
    "start": 1061.6,
    "duration": 3.84
  },
  {
    "text": "This is called the world of Eldoria. So",
    "start": 1063.52,
    "duration": 3.92
  },
  {
    "text": "he used a language model to basically",
    "start": 1065.44,
    "duration": 4.479
  },
  {
    "text": "generate a fantasy world. Um it's got I",
    "start": 1067.44,
    "duration": 4.64
  },
  {
    "text": "mean 60 kilobytes of text is a lot. It's",
    "start": 1069.919,
    "duration": 3.841
  },
  {
    "text": "pretty good. Couple thousand lines of",
    "start": 1072.08,
    "duration": 4.32
  },
  {
    "text": "just straight fantasy. Sets a stage,",
    "start": 1073.76,
    "duration": 4.799
  },
  {
    "text": "different characters, different battles.",
    "start": 1076.4,
    "duration": 3.92
  },
  {
    "text": "We're going to take that document and",
    "start": 1078.559,
    "duration": 4.401
  },
  {
    "text": "basically it's going to ingest. So as",
    "start": 1080.32,
    "duration": 4.8
  },
  {
    "text": "the architecture I showed you earlier,",
    "start": 1082.96,
    "duration": 4.079
  },
  {
    "text": "we're going to take that data and we're",
    "start": 1085.12,
    "duration": 3.12
  },
  {
    "text": "going to put it through an embedding",
    "start": 1087.039,
    "duration": 2.481
  },
  {
    "text": "model. We're going to chunk up the",
    "start": 1088.24,
    "duration": 4.08
  },
  {
    "text": "document, feed each parts, in this case",
    "start": 1089.52,
    "duration": 4.24
  },
  {
    "text": "it could be sentences, could be",
    "start": 1092.32,
    "duration": 3.76
  },
  {
    "text": "paragraphs. We're going to convert those",
    "start": 1093.76,
    "duration": 4.88
  },
  {
    "text": "into a vector representation and store",
    "start": 1096.08,
    "duration": 5.04
  },
  {
    "text": "it into a vector database. Why? Because",
    "start": 1098.64,
    "duration": 5.2
  },
  {
    "text": "later on I'll ask AI a couple questions,",
    "start": 1101.12,
    "duration": 4.64
  },
  {
    "text": "right? like, hey, can you tell me um",
    "start": 1103.84,
    "duration": 4.24
  },
  {
    "text": "where the in is or who is this character",
    "start": 1105.76,
    "duration": 4.4
  },
  {
    "text": "called Finn Brightwood? Now, normally a",
    "start": 1108.08,
    "duration": 3.68
  },
  {
    "text": "large language model doesn't understand",
    "start": 1110.16,
    "duration": 4.16
  },
  {
    "text": "that. But if you put up a what's called",
    "start": 1111.76,
    "duration": 4.96
  },
  {
    "text": "rag, a retrieval augmented generation,",
    "start": 1114.32,
    "duration": 4.719
  },
  {
    "text": "it can go and retrieve documents from",
    "start": 1116.72,
    "duration": 3.92
  },
  {
    "text": "the vector database and do what's called",
    "start": 1119.039,
    "duration": 4.081
  },
  {
    "text": "a similarity search. So, machines are",
    "start": 1120.64,
    "duration": 5.279
  },
  {
    "text": "very good at doing uh similarity search",
    "start": 1123.12,
    "duration": 4.64
  },
  {
    "text": "against vectors. This is why we want to",
    "start": 1125.919,
    "duration": 4.561
  },
  {
    "text": "embed text into vectors and store them",
    "start": 1127.76,
    "duration": 4.24
  },
  {
    "text": "in a vector database. So, let's check",
    "start": 1130.48,
    "duration": 4.16
  },
  {
    "text": "this out. I'm gonna drag this document",
    "start": 1132.0,
    "duration": 6.4
  },
  {
    "text": "to R2X and see if she can understand",
    "start": 1134.64,
    "duration": 6.08
  },
  {
    "text": "questions about this world. So, I",
    "start": 1138.4,
    "duration": 4.08
  },
  {
    "text": "changed the prompt. I said, \"You're an",
    "start": 1140.72,
    "duration": 4.079
  },
  {
    "text": "NPC in the world of Eldoria. Answer",
    "start": 1142.48,
    "duration": 3.92
  },
  {
    "text": "questions based on the document I'm",
    "start": 1144.799,
    "duration": 4.801
  },
  {
    "text": "going to provide you.",
    "start": 1146.4,
    "duration": 4.96
  },
  {
    "text": ">> Hi there.\"",
    "start": 1149.6,
    "duration": 4.64
  },
  {
    "text": ">> And I'll drag over the document. It's",
    "start": 1151.36,
    "duration": 4.48
  },
  {
    "text": "really quick. I've processed the",
    "start": 1154.24,
    "duration": 3.679
  },
  {
    "text": "contents of the file which provides",
    "start": 1155.84,
    "duration": 4.16
  },
  {
    "text": "detailed information about the world of",
    "start": 1157.919,
    "duration": 5.441
  },
  {
    "text": "Eldoria, its geography, history, magic,",
    "start": 1160.0,
    "duration": 6.0
  },
  {
    "text": "and key characters and locations. If you",
    "start": 1163.36,
    "duration": 4.48
  },
  {
    "text": "have any specific questions or need",
    "start": 1166.0,
    "duration": 5.52
  },
  {
    "text": "further details, feel free to ask.",
    "start": 1167.84,
    "duration": 7.04
  },
  {
    "text": ">> Where should I stay for the night?",
    "start": 1171.52,
    "duration": 5.92
  },
  {
    "text": ">> For a cozy and welcoming stay, you might",
    "start": 1174.88,
    "duration": 5.52
  },
  {
    "text": "consider the Rusty Tangard. It's a small",
    "start": 1177.44,
    "duration": 5.2
  },
  {
    "text": "old inn located in a quiet corner of",
    "start": 1180.4,
    "duration": 4.72
  },
  {
    "text": "Eldoria. The inn is known for its warm",
    "start": 1182.64,
    "duration": 4.96
  },
  {
    "text": "hearth, hearty meals, and the fair and",
    "start": 1185.12,
    "duration": 5.28
  },
  {
    "text": "just inkeeper, Garving Stone Brew. Its",
    "start": 1187.6,
    "duration": 4.4
  },
  {
    "text": "comfortable atmosphere and friendly",
    "start": 1190.4,
    "duration": 3.84
  },
  {
    "text": "clientele make it a charming choice for",
    "start": 1192.0,
    "duration": 4.0
  },
  {
    "text": "your night's rest.",
    "start": 1194.24,
    "duration": 2.88
  },
  {
    "text": ">> All right, so that was interesting,",
    "start": 1196.0,
    "duration": 2.48
  },
  {
    "text": "right? She was able to describe the",
    "start": 1197.12,
    "duration": 2.88
  },
  {
    "text": "world of Adora. So, I'm going to stop it",
    "start": 1198.48,
    "duration": 3.12
  },
  {
    "text": "here. I'm going to do a little bit more.",
    "start": 1200.0,
    "duration": 3.2
  },
  {
    "text": "I can select what's called a different",
    "start": 1201.6,
    "duration": 2.88
  },
  {
    "text": "voice, right? So, these are voices",
    "start": 1203.2,
    "duration": 3.76
  },
  {
    "text": "available from 11 Labs integration, but",
    "start": 1204.48,
    "duration": 4.96
  },
  {
    "text": "I'll play another voice from OpenAI. Um,",
    "start": 1206.96,
    "duration": 5.36
  },
  {
    "text": "we'll use I think Sage here. So, I use",
    "start": 1209.44,
    "duration": 4.56
  },
  {
    "text": "Shimmer. So, this is the Sage voice on",
    "start": 1212.32,
    "duration": 3.84
  },
  {
    "text": "OpenAI speech to speech and we'll just",
    "start": 1214.0,
    "duration": 3.679
  },
  {
    "text": "test out like a different voice and see",
    "start": 1216.16,
    "duration": 2.0
  },
  {
    "text": "what it says.",
    "start": 1217.679,
    "duration": 3.641
  },
  {
    "text": ">> Hi there.",
    "start": 1218.16,
    "duration": 3.16
  },
  {
    "text": ">> Who is Finn Britwood?",
    "start": 1221.919,
    "duration": 5.521
  },
  {
    "text": ">> Finn Brightwood is a young farm boy who",
    "start": 1225.2,
    "duration": 4.479
  },
  {
    "text": "grew up in the quiet countryside far",
    "start": 1227.44,
    "duration": 4.56
  },
  {
    "text": "from the bustling city of Eldoria.",
    "start": 1229.679,
    "duration": 4.48
  },
  {
    "text": "Raised on a small family farm, Finn",
    "start": 1232.0,
    "duration": 4.159
  },
  {
    "text": "spent his days tending to animals and",
    "start": 1234.159,
    "duration": 3.921
  },
  {
    "text": "working the fields.",
    "start": 1236.159,
    "duration": 3.201
  },
  {
    "text": ">> All right, so you can see the response",
    "start": 1238.08,
    "duration": 2.8
  },
  {
    "text": "there. So, this is good. We can test out",
    "start": 1239.36,
    "duration": 3.28
  },
  {
    "text": "different use cases, test different",
    "start": 1240.88,
    "duration": 4.08
  },
  {
    "text": "characters, different voices. I can uh",
    "start": 1242.64,
    "duration": 3.76
  },
  {
    "text": "drag and drop and game lore. You can see",
    "start": 1244.96,
    "duration": 3.52
  },
  {
    "text": "how fast the iteration was. So this is",
    "start": 1246.4,
    "duration": 3.84
  },
  {
    "text": "interesting. If you want to breathe life",
    "start": 1248.48,
    "duration": 3.679
  },
  {
    "text": "into your digital characters, this",
    "start": 1250.24,
    "duration": 3.36
  },
  {
    "text": "provides you a way to like the",
    "start": 1252.159,
    "duration": 3.601
  },
  {
    "text": "playground to quickly prototype. So how",
    "start": 1253.6,
    "duration": 4.48
  },
  {
    "text": "can we go from prototype to production?",
    "start": 1255.76,
    "duration": 4.799
  },
  {
    "text": "How can we bring digital humans uh into",
    "start": 1258.08,
    "duration": 5.12
  },
  {
    "text": "games here? So, first I'll set the stage",
    "start": 1260.559,
    "duration": 4.48
  },
  {
    "text": "here and just kind of state the obvious",
    "start": 1263.2,
    "duration": 5.04
  },
  {
    "text": "that replicating human decision- making",
    "start": 1265.039,
    "duration": 5.921
  },
  {
    "text": "is is difficult, right? But let's take",
    "start": 1268.24,
    "duration": 4.559
  },
  {
    "text": "take a step back here and just what we",
    "start": 1270.96,
    "duration": 4.32
  },
  {
    "text": "saw with project R2X, right? So, first",
    "start": 1272.799,
    "duration": 4.161
  },
  {
    "text": "we have to think about the perception,",
    "start": 1275.28,
    "duration": 4.08
  },
  {
    "text": "right? Giving the machine the ability to",
    "start": 1276.96,
    "duration": 4.959
  },
  {
    "text": "understand audio, vision, text,",
    "start": 1279.36,
    "duration": 3.679
  },
  {
    "text": "different supports, different",
    "start": 1281.919,
    "duration": 3.841
  },
  {
    "text": "modalities. Um once we give these",
    "start": 1283.039,
    "duration": 5.281
  },
  {
    "text": "characters a perception, we have to give",
    "start": 1285.76,
    "duration": 5.68
  },
  {
    "text": "them the the skill of cognition, right?",
    "start": 1288.32,
    "duration": 6.16
  },
  {
    "text": "How to choose what to do next. So",
    "start": 1291.44,
    "duration": 4.719
  },
  {
    "text": "cognition could be based on different",
    "start": 1294.48,
    "duration": 3.12
  },
  {
    "text": "language models, different function",
    "start": 1296.159,
    "duration": 3.601
  },
  {
    "text": "calling to basically reason. So that's",
    "start": 1297.6,
    "duration": 4.24
  },
  {
    "text": "the that's the next step. Um once they",
    "start": 1299.76,
    "duration": 4.32
  },
  {
    "text": "make a decision, how do we act on those",
    "start": 1301.84,
    "duration": 4.48
  },
  {
    "text": "decisions? Right? Can we choose an",
    "start": 1304.08,
    "duration": 4.16
  },
  {
    "text": "action? Can we actually make a function",
    "start": 1306.32,
    "duration": 3.68
  },
  {
    "text": "call into your game engine to do",
    "start": 1308.24,
    "duration": 3.6
  },
  {
    "text": "something to make an action? Or an",
    "start": 1310.0,
    "duration": 3.84
  },
  {
    "text": "action could be simply a response. Can",
    "start": 1311.84,
    "duration": 4.079
  },
  {
    "text": "we generate speech? Bring our character",
    "start": 1313.84,
    "duration": 3.92
  },
  {
    "text": "to life. As you saw with Aki, we",
    "start": 1315.919,
    "duration": 4.481
  },
  {
    "text": "generated the the audio that I got back",
    "start": 1317.76,
    "duration": 4.24
  },
  {
    "text": "from OpenAI. But we're going to talk a",
    "start": 1320.4,
    "duration": 3.12
  },
  {
    "text": "little bit about how to do that on",
    "start": 1322.0,
    "duration": 5.919
  },
  {
    "text": "device in your games in process. Um, but",
    "start": 1323.52,
    "duration": 6.8
  },
  {
    "text": "how do we incorporate memory? Just as I",
    "start": 1327.919,
    "duration": 3.841
  },
  {
    "text": "showed you with the document, we can",
    "start": 1330.32,
    "duration": 4.32
  },
  {
    "text": "incorporate um an embedding model. We",
    "start": 1331.76,
    "duration": 5.12
  },
  {
    "text": "can make informed decisions based on",
    "start": 1334.64,
    "duration": 4.96
  },
  {
    "text": "past actions. Right? So before she",
    "start": 1336.88,
    "duration": 3.84
  },
  {
    "text": "understood that I was talking about",
    "start": 1339.6,
    "duration": 3.12
  },
  {
    "text": "unreal fastest and next I was asking her",
    "start": 1340.72,
    "duration": 3.76
  },
  {
    "text": "hey what t-shirt should I wear. So just",
    "start": 1342.72,
    "duration": 3.839
  },
  {
    "text": "from the memory from the context alone",
    "start": 1344.48,
    "duration": 3.92
  },
  {
    "text": "or you can use an embedding model with a",
    "start": 1346.559,
    "duration": 4.721
  },
  {
    "text": "vector database to incorporate uh you",
    "start": 1348.4,
    "duration": 5.519
  },
  {
    "text": "know basically game lore knowledge base",
    "start": 1351.28,
    "duration": 5.279
  },
  {
    "text": "character interactions. We can basically",
    "start": 1353.919,
    "duration": 4.321
  },
  {
    "text": "um have motivations for our characters",
    "start": 1356.559,
    "duration": 5.12
  },
  {
    "text": "to make informed decisions. So realize",
    "start": 1358.24,
    "duration": 5.679
  },
  {
    "text": "this this is the four pillars of what",
    "start": 1361.679,
    "duration": 4.961
  },
  {
    "text": "replicating human decision-m is. So it",
    "start": 1363.919,
    "duration": 5.12
  },
  {
    "text": "doesn't stop here. Let's expand on this.",
    "start": 1366.64,
    "duration": 5.36
  },
  {
    "text": "Right. So in the central pillar, we",
    "start": 1369.039,
    "duration": 5.52
  },
  {
    "text": "still have perception, cognition, taking",
    "start": 1372.0,
    "duration": 5.12
  },
  {
    "text": "action, and memory. These are different",
    "start": 1374.559,
    "duration": 4.961
  },
  {
    "text": "models from our NVIDIA ACE stack of",
    "start": 1377.12,
    "duration": 4.48
  },
  {
    "text": "technologies. So think of NVIDIA ACE as",
    "start": 1379.52,
    "duration": 5.12
  },
  {
    "text": "a suite of tech. These certain models,",
    "start": 1381.6,
    "duration": 4.0
  },
  {
    "text": "and I'll talk about that a little bit",
    "start": 1384.64,
    "duration": 4.08
  },
  {
    "text": "later on, allow us to bring uh human",
    "start": 1385.6,
    "duration": 5.92
  },
  {
    "text": "decision-m to our digital characters. So",
    "start": 1388.72,
    "duration": 4.88
  },
  {
    "text": "combine that with our user interaction,",
    "start": 1391.52,
    "duration": 4.32
  },
  {
    "text": "whether it's in the form of speech from",
    "start": 1393.6,
    "duration": 5.199
  },
  {
    "text": "a microphone, our camera input, or even",
    "start": 1395.84,
    "duration": 5.839
  },
  {
    "text": "just raw input, whether it's text or",
    "start": 1398.799,
    "duration": 4.88
  },
  {
    "text": "movements, we can actually feed that",
    "start": 1401.679,
    "duration": 4.48
  },
  {
    "text": "into our different models here, whether",
    "start": 1403.679,
    "duration": 5.041
  },
  {
    "text": "to understand audio, understand vision",
    "start": 1406.159,
    "duration": 5.601
  },
  {
    "text": "as you just saw, or basically use that",
    "start": 1408.72,
    "duration": 5.12
  },
  {
    "text": "data and embed that data. We can feed",
    "start": 1411.76,
    "duration": 4.0
  },
  {
    "text": "that into the planning and reasoning",
    "start": 1413.84,
    "duration": 3.6
  },
  {
    "text": "models, our large language models, in",
    "start": 1415.76,
    "duration": 3.12
  },
  {
    "text": "this case a small language model on",
    "start": 1417.44,
    "duration": 3.68
  },
  {
    "text": "device and basically take action whether",
    "start": 1418.88,
    "duration": 4.56
  },
  {
    "text": "it's a form of speech. Uh we can plan",
    "start": 1421.12,
    "duration": 4.16
  },
  {
    "text": "different actions or we can do function",
    "start": 1423.44,
    "duration": 4.0
  },
  {
    "text": "calling as I showed you with lang flow",
    "start": 1425.28,
    "duration": 3.84
  },
  {
    "text": "call different tools using aentic",
    "start": 1427.44,
    "duration": 4.32
  },
  {
    "text": "framework. Now all of this is actually",
    "start": 1429.12,
    "duration": 5.2
  },
  {
    "text": "wrapped up in our technology for facial",
    "start": 1431.76,
    "duration": 4.88
  },
  {
    "text": "animation which is called audioto-face",
    "start": 1434.32,
    "duration": 4.4
  },
  {
    "text": "3D.",
    "start": 1436.64,
    "duration": 3.919
  },
  {
    "text": "One thing to point out here is the",
    "start": 1438.72,
    "duration": 5.36
  },
  {
    "text": "NVIDIA astack is a mixture of cloud and",
    "start": 1440.559,
    "duration": 6.48
  },
  {
    "text": "local models. So using our NVIDIA NIMS",
    "start": 1444.08,
    "duration": 5.52
  },
  {
    "text": "and NVIDIA inference microservices, you",
    "start": 1447.039,
    "duration": 5.201
  },
  {
    "text": "can deploy those on device whether it's",
    "start": 1449.6,
    "duration": 6.24
  },
  {
    "text": "through um Windows subsystem for Linux",
    "start": 1452.24,
    "duration": 5.12
  },
  {
    "text": "or you can use uh I'll talk a little bit",
    "start": 1455.84,
    "duration": 3.04
  },
  {
    "text": "later on how to get those natively into",
    "start": 1457.36,
    "duration": 3.6
  },
  {
    "text": "your game or you can deploy those in a",
    "start": 1458.88,
    "duration": 4.88
  },
  {
    "text": "data center. So let's let's focus on the",
    "start": 1460.96,
    "duration": 4.16
  },
  {
    "text": "right here the facial animation or",
    "start": 1463.76,
    "duration": 3.279
  },
  {
    "text": "animation and rendering tech with audit",
    "start": 1465.12,
    "duration": 5.36
  },
  {
    "text": "to face 3D. Now audio to face 3D that is",
    "start": 1467.039,
    "duration": 5.681
  },
  {
    "text": "powering our real time facial AI",
    "start": 1470.48,
    "duration": 3.92
  },
  {
    "text": "animation.",
    "start": 1472.72,
    "duration": 4.559
  },
  {
    "text": "The plugin for ACE we call it the 2.4",
    "start": 1474.4,
    "duration": 5.12
  },
  {
    "text": "Unreal Engine plugin that is available",
    "start": 1477.279,
    "duration": 5.441
  },
  {
    "text": "now. So if you go to ACE on our uh",
    "start": 1479.52,
    "duration": 4.8
  },
  {
    "text": "Nvidia developer website you can",
    "start": 1482.72,
    "duration": 3.76
  },
  {
    "text": "actually get the Unreal plug-in engine.",
    "start": 1484.32,
    "duration": 4.4
  },
  {
    "text": "Try it out. The audio interface will run",
    "start": 1486.48,
    "duration": 4.799
  },
  {
    "text": "locally there on your machine. And this",
    "start": 1488.72,
    "duration": 4.16
  },
  {
    "text": "is interesting because not only do we",
    "start": 1491.279,
    "duration": 4.481
  },
  {
    "text": "have just a model here, we also have a",
    "start": 1492.88,
    "duration": 4.799
  },
  {
    "text": "training framework. And this is great",
    "start": 1495.76,
    "duration": 4.799
  },
  {
    "text": "because now you can apply custom model",
    "start": 1497.679,
    "duration": 5.921
  },
  {
    "text": "training, right? Couple benefits here.",
    "start": 1500.559,
    "duration": 4.561
  },
  {
    "text": "Different customers can actually train",
    "start": 1503.6,
    "duration": 4.16
  },
  {
    "text": "their own own ACE models. Um, if you",
    "start": 1505.12,
    "duration": 4.4
  },
  {
    "text": "have their own actor to have different",
    "start": 1507.76,
    "duration": 3.76
  },
  {
    "text": "nuances here, we actually train audit to",
    "start": 1509.52,
    "duration": 4.08
  },
  {
    "text": "face on two different actors, a male and",
    "start": 1511.52,
    "duration": 4.0
  },
  {
    "text": "female. But you can incorporate your own",
    "start": 1513.6,
    "duration": 3.28
  },
  {
    "text": "training to actually get specific",
    "start": 1515.52,
    "duration": 4.08
  },
  {
    "text": "nuances of their face. U verbalizing",
    "start": 1516.88,
    "duration": 5.84
  },
  {
    "text": "different uh audio and emotion. Um, you",
    "start": 1519.6,
    "duration": 6.079
  },
  {
    "text": "can do platformer specific identities.",
    "start": 1522.72,
    "duration": 5.92
  },
  {
    "text": "So, in project R2X, I was just using our",
    "start": 1525.679,
    "duration": 5.201
  },
  {
    "text": "actor called Claire, but a little bit",
    "start": 1528.64,
    "duration": 4.32
  },
  {
    "text": "later on this next video, I'll show you",
    "start": 1530.88,
    "duration": 4.88
  },
  {
    "text": "another um platform specific ID called",
    "start": 1532.96,
    "duration": 5.04
  },
  {
    "text": "James where he's actually uses as a",
    "start": 1535.76,
    "duration": 4.56
  },
  {
    "text": "male. We can verbalize that with our",
    "start": 1538.0,
    "duration": 4.72
  },
  {
    "text": "different uh actor. And then also audio",
    "start": 1540.32,
    "duration": 4.64
  },
  {
    "text": "to face we support multiple languages.",
    "start": 1542.72,
    "duration": 3.68
  },
  {
    "text": "This is very important because now you",
    "start": 1544.96,
    "duration": 3.599
  },
  {
    "text": "can localize. It's a turnkey",
    "start": 1546.4,
    "duration": 4.56
  },
  {
    "text": "localization effort. So, it's we support",
    "start": 1548.559,
    "duration": 5.041
  },
  {
    "text": "many languages out of the box. So gone",
    "start": 1550.96,
    "duration": 4.719
  },
  {
    "text": "are basically converting to different",
    "start": 1553.6,
    "duration": 5.92
  },
  {
    "text": "localizations. Um once you get audio to",
    "start": 1555.679,
    "duration": 5.681
  },
  {
    "text": "face you can actually integrate it into",
    "start": 1559.52,
    "duration": 3.84
  },
  {
    "text": "your own engine. We do have a native",
    "start": 1561.36,
    "duration": 3.84
  },
  {
    "text": "Unreal integration but if you're using a",
    "start": 1563.36,
    "duration": 3.679
  },
  {
    "text": "different engine of course in a",
    "start": 1565.2,
    "duration": 3.76
  },
  {
    "text": "different uh conference you can use our",
    "start": 1567.039,
    "duration": 4.561
  },
  {
    "text": "audio toface SDK. So again different",
    "start": 1568.96,
    "duration": 5.12
  },
  {
    "text": "versions of face. You can run it locally",
    "start": 1571.6,
    "duration": 4.48
  },
  {
    "text": "you can run it in the cloud or you can",
    "start": 1574.08,
    "duration": 4.32
  },
  {
    "text": "run it maybe onrem a different server.",
    "start": 1576.08,
    "duration": 3.76
  },
  {
    "text": "So down at the bottom here, we have",
    "start": 1578.4,
    "duration": 2.96
  },
  {
    "text": "several different integrations. You can",
    "start": 1579.84,
    "duration": 4.319
  },
  {
    "text": "test out in our Maya Ace audio interface",
    "start": 1581.36,
    "duration": 5.199
  },
  {
    "text": "plugin. I highlighted here the Unreal",
    "start": 1584.159,
    "duration": 4.481
  },
  {
    "text": "Engine plugin or you can basically try",
    "start": 1586.559,
    "duration": 4.961
  },
  {
    "text": "it out on buildvidia.com and just",
    "start": 1588.64,
    "duration": 4.88
  },
  {
    "text": "basically test out our web app. So",
    "start": 1591.52,
    "duration": 4.32
  },
  {
    "text": "again, available now with our ACE Unreal",
    "start": 1593.52,
    "duration": 5.039
  },
  {
    "text": "Engine 2.4 plugin. So let's take a look",
    "start": 1595.84,
    "duration": 6.079
  },
  {
    "text": "at this next generation audio toface 3D.",
    "start": 1598.559,
    "duration": 6.161
  },
  {
    "text": "So what you're looking at is a capture",
    "start": 1601.919,
    "duration": 6.081
  },
  {
    "text": "of James, one of the actor that we use",
    "start": 1604.72,
    "duration": 5.92
  },
  {
    "text": "for audio to face. So this is using the",
    "start": 1608.0,
    "duration": 4.4
  },
  {
    "text": "new diffusion model. So let's take a",
    "start": 1610.64,
    "duration": 3.919
  },
  {
    "text": "look at the animation here. And again,",
    "start": 1612.4,
    "duration": 4.639
  },
  {
    "text": "I'm just feeding audio and we're",
    "start": 1614.559,
    "duration": 4.321
  },
  {
    "text": "generating the blend shapes in real time",
    "start": 1617.039,
    "duration": 2.64
  },
  {
    "text": ">> action.",
    "start": 1618.88,
    "duration": 4.159
  },
  {
    "text": ">> Oh. Oh. Oh. Oh. Oh. I Yeah. No, I I've",
    "start": 1619.679,
    "duration": 5.6
  },
  {
    "text": "seen that before. Yes, that's perfect.",
    "start": 1623.039,
    "duration": 4.561
  },
  {
    "text": "They're going like 30 miles an hour. Why",
    "start": 1625.279,
    "duration": 5.601
  },
  {
    "text": "are you in the fast lane? Woo. That felt",
    "start": 1627.6,
    "duration": 4.72
  },
  {
    "text": "good, didn't it?",
    "start": 1630.88,
    "duration": 4.0
  },
  {
    "text": ">> Cut. Perfect.",
    "start": 1632.32,
    "duration": 4.64
  },
  {
    "text": ">> All right. Looks pretty good. So again,",
    "start": 1634.88,
    "duration": 4.0
  },
  {
    "text": "you notice the eyebrow movements,",
    "start": 1636.96,
    "duration": 4.4
  },
  {
    "text": "different emotion. We have another uh",
    "start": 1638.88,
    "duration": 4.399
  },
  {
    "text": "use case here with audio to face. This",
    "start": 1641.36,
    "duration": 3.6
  },
  {
    "text": "is highlighting the differences between",
    "start": 1643.279,
    "duration": 4.64
  },
  {
    "text": "our new diffusion model and our older",
    "start": 1644.96,
    "duration": 4.8
  },
  {
    "text": "regression model. So why don't you take",
    "start": 1647.919,
    "duration": 5.12
  },
  {
    "text": "a look at the enhanced lip syncing and",
    "start": 1649.76,
    "duration": 4.72
  },
  {
    "text": "emotional range. Okay. So we'll play",
    "start": 1653.039,
    "duration": 3.041
  },
  {
    "text": "this video again. On the left we have",
    "start": 1654.48,
    "duration": 3.52
  },
  {
    "text": "our older regression model and on the",
    "start": 1656.08,
    "duration": 3.599
  },
  {
    "text": "right this is our new diffusion model",
    "start": 1658.0,
    "duration": 4.08
  },
  {
    "text": "which was just released um I believe",
    "start": 1659.679,
    "duration": 7.281
  },
  {
    "text": "about a month ago. Let's take a look.",
    "start": 1662.08,
    "duration": 6.8
  },
  {
    "text": ">> All right team, we can do this. Let's",
    "start": 1666.96,
    "duration": 3.599
  },
  {
    "text": "give it our all no matter what. We've",
    "start": 1668.88,
    "duration": 3.679
  },
  {
    "text": "got this.",
    "start": 1670.559,
    "duration": 4.24
  },
  {
    "text": "I just I don't know what to do anymore.",
    "start": 1672.559,
    "duration": 4.24
  },
  {
    "text": "It hurts so much and I just need someone",
    "start": 1674.799,
    "duration": 4.161
  },
  {
    "text": "to understand.",
    "start": 1676.799,
    "duration": 4.48
  },
  {
    "text": "We've lost so much but we will not be",
    "start": 1678.96,
    "duration": 5.28
  },
  {
    "text": "defeated. We stand together and we fight",
    "start": 1681.279,
    "duration": 5.601
  },
  {
    "text": "for our future.",
    "start": 1684.24,
    "duration": 5.2
  },
  {
    "text": ">> All right. So pretty good. Pretty good.",
    "start": 1686.88,
    "duration": 4.96
  },
  {
    "text": "Now the other feature we have audio to",
    "start": 1689.44,
    "duration": 4.719
  },
  {
    "text": "face 3D is the support for multiple",
    "start": 1691.84,
    "duration": 4.559
  },
  {
    "text": "languages. Right. So again this offers",
    "start": 1694.159,
    "duration": 4.801
  },
  {
    "text": "turnkey localization depending on what",
    "start": 1696.399,
    "duration": 4.561
  },
  {
    "text": "the audio is coming in. It can infer",
    "start": 1698.96,
    "duration": 4.319
  },
  {
    "text": "what language it is and basically come",
    "start": 1700.96,
    "duration": 3.52
  },
  {
    "text": "up with a really good blend shape",
    "start": 1703.279,
    "duration": 2.961
  },
  {
    "text": "animation. So let's take a look at James",
    "start": 1704.48,
    "duration": 4.16
  },
  {
    "text": "here using different languages in real",
    "start": 1706.24,
    "duration": 5.76
  },
  {
    "text": "time. In this game, every move is",
    "start": 1708.64,
    "duration": 6.08
  },
  {
    "text": "calculated. Our decisions now will",
    "start": 1712.0,
    "duration": 6.36
  },
  {
    "text": "define our future.",
    "start": 1714.72,
    "duration": 3.64
  },
  {
    "text": "No, this is your man.",
    "start": 1728.24,
    "duration": 3.64
  },
  {
    "text": "All right, that's pretty good. So again,",
    "start": 1739.279,
    "duration": 4.241
  },
  {
    "text": "this is our autoface 3.0. This is",
    "start": 1740.88,
    "duration": 5.2
  },
  {
    "text": "available in the ACE plugin. Um, you can",
    "start": 1743.52,
    "duration": 6.399
  },
  {
    "text": "test this out in uh Unreal Engine. So",
    "start": 1746.08,
    "duration": 5.52
  },
  {
    "text": "now that I've talked about all these",
    "start": 1749.919,
    "duration": 3.76
  },
  {
    "text": "technologies, right, how do we actually",
    "start": 1751.6,
    "duration": 4.72
  },
  {
    "text": "bring it on device instead of using",
    "start": 1753.679,
    "duration": 4.48
  },
  {
    "text": "cloud models? Well, we can do that with",
    "start": 1756.32,
    "duration": 4.079
  },
  {
    "text": "our SDK which is called Iggy, right?",
    "start": 1758.159,
    "duration": 4.561
  },
  {
    "text": "This is the Nvidia in-game inferencing",
    "start": 1760.399,
    "duration": 4.961
  },
  {
    "text": "SDK. This will help you streamline your",
    "start": 1762.72,
    "duration": 5.28
  },
  {
    "text": "inprocess AI deployment. So in process",
    "start": 1765.36,
    "duration": 4.48
  },
  {
    "text": "means I'm running it in the same process",
    "start": 1768.0,
    "duration": 6.24
  },
  {
    "text": "as my game. This is a C++ SDK. We",
    "start": 1769.84,
    "duration": 6.64
  },
  {
    "text": "support ondevice inferencing across",
    "start": 1774.24,
    "duration": 5.439
  },
  {
    "text": "several different models. Speech audio,",
    "start": 1776.48,
    "duration": 5.12
  },
  {
    "text": "visual and basically small language",
    "start": 1779.679,
    "duration": 3.761
  },
  {
    "text": "models and this is for in process",
    "start": 1781.6,
    "duration": 4.959
  },
  {
    "text": "ondevice execution. Um what's nice about",
    "start": 1783.44,
    "duration": 6.64
  },
  {
    "text": "the Iggy SDK we realize um this offers a",
    "start": 1786.559,
    "duration": 5.84
  },
  {
    "text": "unified API so multiple different",
    "start": 1790.08,
    "duration": 5.92
  },
  {
    "text": "inference backends we support tensor RT",
    "start": 1792.399,
    "duration": 6.321
  },
  {
    "text": "Onyx runtime with direct ML and then the",
    "start": 1796.0,
    "duration": 4.72
  },
  {
    "text": "GGUF format which is popularized by",
    "start": 1798.72,
    "duration": 4.559
  },
  {
    "text": "Llama CPP. So no matter those different",
    "start": 1800.72,
    "duration": 5.52
  },
  {
    "text": "backends, we have a unified uh inference",
    "start": 1803.279,
    "duration": 5.041
  },
  {
    "text": "API that can work. So you don't have to",
    "start": 1806.24,
    "duration": 3.36
  },
  {
    "text": "sit there and mess around with different",
    "start": 1808.32,
    "duration": 3.44
  },
  {
    "text": "SDKs to get these language models to",
    "start": 1809.6,
    "duration": 4.4
  },
  {
    "text": "work. This is can all run uh through the",
    "start": 1811.76,
    "duration": 5.36
  },
  {
    "text": "unified API for the NVIG SDK. So this",
    "start": 1814.0,
    "duration": 4.72
  },
  {
    "text": "will work across different hardware",
    "start": 1817.12,
    "duration": 3.039
  },
  {
    "text": "accelerators whether you're running it",
    "start": 1818.72,
    "duration": 5.199
  },
  {
    "text": "on any GPU, CUDA enabled GPUs, uh the an",
    "start": 1820.159,
    "duration": 6.721
  },
  {
    "text": "NPU or the actual CPU itself. So, one of",
    "start": 1823.919,
    "duration": 4.961
  },
  {
    "text": "our models does support inferencing on",
    "start": 1826.88,
    "duration": 3.919
  },
  {
    "text": "the CPU, and I'll talk about that a",
    "start": 1828.88,
    "duration": 4.0
  },
  {
    "text": "little bit later on. And then the other",
    "start": 1830.799,
    "duration": 4.961
  },
  {
    "text": "key thing here of the NVIDIA in-game",
    "start": 1832.88,
    "duration": 5.679
  },
  {
    "text": "inferencing SDK is integrated graphics",
    "start": 1835.76,
    "duration": 5.519
  },
  {
    "text": "execution. We can do that with a process",
    "start": 1838.559,
    "duration": 5.36
  },
  {
    "text": "called SIG, which is simultaneous uh",
    "start": 1841.279,
    "duration": 5.041
  },
  {
    "text": "compute in graphics. So, that allows us",
    "start": 1843.919,
    "duration": 5.12
  },
  {
    "text": "to run graphics and AI workload with low",
    "start": 1846.32,
    "duration": 5.359
  },
  {
    "text": "latency. Goner basically context",
    "start": 1849.039,
    "duration": 4.721
  },
  {
    "text": "switching. So this is very important for",
    "start": 1851.679,
    "duration": 3.681
  },
  {
    "text": "maybe your engine developers that wonder",
    "start": 1853.76,
    "duration": 3.76
  },
  {
    "text": "how to run AI workloads alongside",
    "start": 1855.36,
    "duration": 3.84
  },
  {
    "text": "graphics, right? Because we know that's",
    "start": 1857.52,
    "duration": 3.44
  },
  {
    "text": "definitely a problem. You want to have",
    "start": 1859.2,
    "duration": 3.359
  },
  {
    "text": "maximum frames. We don't want to take",
    "start": 1860.96,
    "duration": 3.68
  },
  {
    "text": "away from the graphics rendering. So we",
    "start": 1862.559,
    "duration": 4.72
  },
  {
    "text": "can do this with low latency with uh",
    "start": 1864.64,
    "duration": 4.399
  },
  {
    "text": "SIG.",
    "start": 1867.279,
    "duration": 5.52
  },
  {
    "text": "So how does NVGY work? Well, there's a",
    "start": 1869.039,
    "duration": 5.36
  },
  {
    "text": "four components here I want to talk",
    "start": 1872.799,
    "duration": 3.76
  },
  {
    "text": "about. We have our core plugins. That's",
    "start": 1874.399,
    "duration": 4.4
  },
  {
    "text": "very important because those plugins",
    "start": 1876.559,
    "duration": 5.441
  },
  {
    "text": "provide the AI capabilities such as ASR",
    "start": 1878.799,
    "duration": 4.721
  },
  {
    "text": "which is automatic speech recognition.",
    "start": 1882.0,
    "duration": 4.24
  },
  {
    "text": "We can run ASR either on the GPU or the",
    "start": 1883.52,
    "duration": 6.48
  },
  {
    "text": "CPU. We can run small language models or",
    "start": 1886.24,
    "duration": 5.6
  },
  {
    "text": "we can run vision understanding models",
    "start": 1890.0,
    "duration": 3.6
  },
  {
    "text": "and finally we can run an embedding",
    "start": 1891.84,
    "duration": 4.0
  },
  {
    "text": "model to enable retrieval augmented",
    "start": 1893.6,
    "duration": 4.16
  },
  {
    "text": "generation. Those are our core plugins.",
    "start": 1895.84,
    "duration": 4.319
  },
  {
    "text": "We also have plugins that help um",
    "start": 1897.76,
    "duration": 4.72
  },
  {
    "text": "basically set the stage and we call",
    "start": 1900.159,
    "duration": 3.76
  },
  {
    "text": "those our helper plugins. This will",
    "start": 1902.48,
    "duration": 3.12
  },
  {
    "text": "enable things like SIG, compute and",
    "start": 1903.919,
    "duration": 3.681
  },
  {
    "text": "graphics, maybe network communication.",
    "start": 1905.6,
    "duration": 4.559
  },
  {
    "text": "We do support um generating your own",
    "start": 1907.6,
    "duration": 3.84
  },
  {
    "text": "plugins. So if you want to talk to",
    "start": 1910.159,
    "duration": 2.961
  },
  {
    "text": "different cloud endpoints, that'll work",
    "start": 1911.44,
    "duration": 3.44
  },
  {
    "text": "with a helper plugins. And all this is",
    "start": 1913.12,
    "duration": 4.88
  },
  {
    "text": "wrapped up in a unified API. So since",
    "start": 1914.88,
    "duration": 4.96
  },
  {
    "text": "it's a plug-in architecture, instead of",
    "start": 1918.0,
    "duration": 3.519
  },
  {
    "text": "messing around with different SDKs, you",
    "start": 1919.84,
    "duration": 3.6
  },
  {
    "text": "can basically go all through the Iggy",
    "start": 1921.519,
    "duration": 3.841
  },
  {
    "text": "API, which will help you out with",
    "start": 1923.44,
    "duration": 4.479
  },
  {
    "text": "plug-in management. And finally, really",
    "start": 1925.36,
    "duration": 4.88
  },
  {
    "text": "important here, local execution. We're",
    "start": 1927.919,
    "duration": 4.48
  },
  {
    "text": "not executing these models in the cloud.",
    "start": 1930.24,
    "duration": 4.319
  },
  {
    "text": "There's no more cloud costs. You can run",
    "start": 1932.399,
    "duration": 5.28
  },
  {
    "text": "these models on device in process using",
    "start": 1934.559,
    "duration": 4.081
  },
  {
    "text": "several different hardware",
    "start": 1937.679,
    "duration": 2.961
  },
  {
    "text": "configurations. So this is how Iggy",
    "start": 1938.64,
    "duration": 4.879
  },
  {
    "text": "works in a nutshell. And for my",
    "start": 1940.64,
    "duration": 4.56
  },
  {
    "text": "programmers in the crowd, if you're",
    "start": 1943.519,
    "duration": 2.88
  },
  {
    "text": "wondering like, well, how do I get",
    "start": 1945.2,
    "duration": 3.92
  },
  {
    "text": "started, right? Well, this is very easy.",
    "start": 1946.399,
    "duration": 4.081
  },
  {
    "text": "I'm going to go over this really",
    "start": 1949.12,
    "duration": 4.159
  },
  {
    "text": "quickly, but basically this QR code,",
    "start": 1950.48,
    "duration": 5.76
  },
  {
    "text": "this is one of our tech blogs that",
    "start": 1953.279,
    "duration": 5.921
  },
  {
    "text": "discusses how to get started with a GAN",
    "start": 1956.24,
    "duration": 4.4
  },
  {
    "text": "device. So if you go here, we have this",
    "start": 1959.2,
    "duration": 3.28
  },
  {
    "text": "technical blog. I'll talk a little bit",
    "start": 1960.64,
    "duration": 3.84
  },
  {
    "text": "about some of the C++ code of how to",
    "start": 1962.48,
    "duration": 4.48
  },
  {
    "text": "enable Iggy. But basically it once you",
    "start": 1964.48,
    "duration": 5.12
  },
  {
    "text": "get the SDK up and running, downloaded,",
    "start": 1966.96,
    "duration": 4.719
  },
  {
    "text": "download some models. You can basically",
    "start": 1969.6,
    "duration": 4.24
  },
  {
    "text": "uh initialize Iggy here. We just set up",
    "start": 1971.679,
    "duration": 4.081
  },
  {
    "text": "uh different log levels or different",
    "start": 1973.84,
    "duration": 3.76
  },
  {
    "text": "paths to the different models here and",
    "start": 1975.76,
    "duration": 3.279
  },
  {
    "text": "we just check to see if it actually",
    "start": 1977.6,
    "duration": 4.959
  },
  {
    "text": "loaded. Okay. So once we initialize Iggy",
    "start": 1979.039,
    "duration": 5.36
  },
  {
    "text": "um we basically want to load different",
    "start": 1982.559,
    "duration": 4.24
  },
  {
    "text": "plugins. Now this is mix and match. If",
    "start": 1984.399,
    "duration": 5.441
  },
  {
    "text": "you only want to run maybe like ASR or",
    "start": 1986.799,
    "duration": 5.441
  },
  {
    "text": "maybe a TTS plugin we have support, you",
    "start": 1989.84,
    "duration": 4.079
  },
  {
    "text": "can do that as well. So this is an",
    "start": 1992.24,
    "duration": 4.64
  },
  {
    "text": "example of loading plugins. Um for",
    "start": 1993.919,
    "duration": 4.88
  },
  {
    "text": "example, I'm going to use the GPT",
    "start": 1996.88,
    "duration": 4.24
  },
  {
    "text": "plugin. We call this GPT generative uh",
    "start": 1998.799,
    "duration": 4.0
  },
  {
    "text": "pre-trained transformer. This is one of",
    "start": 2001.12,
    "duration": 5.36
  },
  {
    "text": "our SLMs. This can support GGF backed",
    "start": 2002.799,
    "duration": 6.161
  },
  {
    "text": "formats. But basically you can see here",
    "start": 2006.48,
    "duration": 4.799
  },
  {
    "text": "I'm setting the model parameters. I'm",
    "start": 2008.96,
    "duration": 4.48
  },
  {
    "text": "just basically specifying the number of",
    "start": 2011.279,
    "duration": 4.481
  },
  {
    "text": "threads this runs on, how much budget",
    "start": 2013.44,
    "duration": 5.359
  },
  {
    "text": "and vramm specified in megabytes and",
    "start": 2015.76,
    "duration": 5.12
  },
  {
    "text": "then basically which which model I'm",
    "start": 2018.799,
    "duration": 4.321
  },
  {
    "text": "using this specified by the good. So",
    "start": 2020.88,
    "duration": 4.32
  },
  {
    "text": "once that is loaded um basically I",
    "start": 2023.12,
    "duration": 4.32
  },
  {
    "text": "create the interface I can start using",
    "start": 2025.2,
    "duration": 4.079
  },
  {
    "text": "the plugin. So down here the code on the",
    "start": 2027.44,
    "duration": 3.119
  },
  {
    "text": "bottom we're just simply creating the",
    "start": 2029.279,
    "duration": 2.801
  },
  {
    "text": "instance and just checking to see if",
    "start": 2030.559,
    "duration": 4.881
  },
  {
    "text": "it's available. Right? So um again QR",
    "start": 2032.08,
    "duration": 5.199
  },
  {
    "text": "code up on the top right to basically",
    "start": 2035.44,
    "duration": 3.76
  },
  {
    "text": "give you a primer of how to start this",
    "start": 2037.279,
    "duration": 4.4
  },
  {
    "text": "um on device with C++. So once we load",
    "start": 2039.2,
    "duration": 4.959
  },
  {
    "text": "the plugin we want to create the runtime",
    "start": 2041.679,
    "duration": 4.48
  },
  {
    "text": "configuration. So you can see the top",
    "start": 2044.159,
    "duration": 4.96
  },
  {
    "text": "here uh the C code C++ code we this is",
    "start": 2046.159,
    "duration": 5.2
  },
  {
    "text": "specifying the NPC prompt right just I",
    "start": 2049.119,
    "duration": 3.76
  },
  {
    "text": "specified earlier we can specify",
    "start": 2051.359,
    "duration": 3.921
  },
  {
    "text": "something like you are helpful NPC named",
    "start": 2052.879,
    "duration": 5.681
  },
  {
    "text": "TJ in a fantasy game and we can do some",
    "start": 2055.28,
    "duration": 5.599
  },
  {
    "text": "limits on that runtime. we can maybe",
    "start": 2058.56,
    "duration": 4.559
  },
  {
    "text": "limit the tokens to predict if that's",
    "start": 2060.879,
    "duration": 3.441
  },
  {
    "text": "very important for you. So if you want",
    "start": 2063.119,
    "duration": 2.8
  },
  {
    "text": "if you don't want to generate like a",
    "start": 2064.32,
    "duration": 3.44
  },
  {
    "text": "novel response, you can limit it to 200",
    "start": 2065.919,
    "duration": 4.16
  },
  {
    "text": "tokens. Um you can make it interactive",
    "start": 2067.76,
    "duration": 4.72
  },
  {
    "text": "with the multi-turn conversations. Um",
    "start": 2070.079,
    "duration": 3.84
  },
  {
    "text": "and then down here at the bottom, we're",
    "start": 2072.48,
    "duration": 3.28
  },
  {
    "text": "just basically specifying additional",
    "start": 2073.919,
    "duration": 4.24
  },
  {
    "text": "parameters as our inference context. So",
    "start": 2075.76,
    "duration": 4.24
  },
  {
    "text": "once we create the runtime configuration",
    "start": 2078.159,
    "duration": 4.96
  },
  {
    "text": "and inference, um now what's next is we",
    "start": 2080.0,
    "duration": 5.679
  },
  {
    "text": "can actually send input to it. So this",
    "start": 2083.119,
    "duration": 3.76
  },
  {
    "text": "little code here in the middle, we're",
    "start": 2085.679,
    "duration": 3.361
  },
  {
    "text": "just specifying an example user input,",
    "start": 2086.879,
    "duration": 4.24
  },
  {
    "text": "asking a question like what's your name?",
    "start": 2089.04,
    "duration": 3.52
  },
  {
    "text": "You know, setting up the different slots",
    "start": 2091.119,
    "duration": 3.201
  },
  {
    "text": "for input context. And then finally in",
    "start": 2092.56,
    "duration": 3.68
  },
  {
    "text": "the in the middle here, this is the code",
    "start": 2094.32,
    "duration": 4.32
  },
  {
    "text": "that actually executes the evaluation.",
    "start": 2096.24,
    "duration": 4.48
  },
  {
    "text": "And we run this asynchronously, meaning",
    "start": 2098.64,
    "duration": 3.76
  },
  {
    "text": "we send the response and we have to",
    "start": 2100.72,
    "duration": 4.639
  },
  {
    "text": "wait. To do that, we use what's called a",
    "start": 2102.4,
    "duration": 4.32
  },
  {
    "text": "callback function. And I'll show you",
    "start": 2105.359,
    "duration": 3.121
  },
  {
    "text": "that in two slides a little bit later",
    "start": 2106.72,
    "duration": 3.76
  },
  {
    "text": "on. But basically, you can see how easy",
    "start": 2108.48,
    "duration": 4.879
  },
  {
    "text": "it is. Unified API. No matter what",
    "start": 2110.48,
    "duration": 5.2
  },
  {
    "text": "plugins you use, it's all the same. You",
    "start": 2113.359,
    "duration": 4.321
  },
  {
    "text": "initialize Iggy, you load the plugin,",
    "start": 2115.68,
    "duration": 3.76
  },
  {
    "text": "you specify the parameters, and you just",
    "start": 2117.68,
    "duration": 3.6
  },
  {
    "text": "do your runtime inference and wait for",
    "start": 2119.44,
    "duration": 4.8
  },
  {
    "text": "the callback.",
    "start": 2121.28,
    "duration": 4.64
  },
  {
    "text": "So, this right here, this is probably",
    "start": 2124.24,
    "duration": 3.359
  },
  {
    "text": "the most important part I want to focus",
    "start": 2125.92,
    "duration": 4.48
  },
  {
    "text": "on. This is enabling our GPU scheduling",
    "start": 2127.599,
    "duration": 4.24
  },
  {
    "text": "and rendering integration. This is",
    "start": 2130.4,
    "duration": 3.199
  },
  {
    "text": "basically allowing us to do what's",
    "start": 2131.839,
    "duration": 4.961
  },
  {
    "text": "called SIG, compute and graphics. Once I",
    "start": 2133.599,
    "duration": 6.48
  },
  {
    "text": "get the um Iggy interface,",
    "start": 2136.8,
    "duration": 5.039
  },
  {
    "text": "I want to check to see if there's no",
    "start": 2140.079,
    "duration": 3.76
  },
  {
    "text": "errors. Once it's okay, I set up our",
    "start": 2141.839,
    "duration": 5.201
  },
  {
    "text": "direct uh 3D D12 parameters. Just making",
    "start": 2143.839,
    "duration": 5.441
  },
  {
    "text": "sure that I can use this for rendering,",
    "start": 2147.04,
    "duration": 4.24
  },
  {
    "text": "right? So, we want to do simultaneous AI",
    "start": 2149.28,
    "duration": 4.319
  },
  {
    "text": "workload and rendering. I want to enable",
    "start": 2151.28,
    "duration": 5.6
  },
  {
    "text": "SIG. To do that, we just simply get the",
    "start": 2153.599,
    "duration": 5.76
  },
  {
    "text": "interface for Iggy and we just call this",
    "start": 2156.88,
    "duration": 4.32
  },
  {
    "text": "simply function enable compute and",
    "start": 2159.359,
    "duration": 4.881
  },
  {
    "text": "graphics and I pass in my uh D312",
    "start": 2161.2,
    "duration": 5.2
  },
  {
    "text": "parameters. I just check to see if",
    "start": 2164.24,
    "duration": 3.92
  },
  {
    "text": "there's no error response. We're good to",
    "start": 2166.4,
    "duration": 3.28
  },
  {
    "text": "go. And I just print out to the standard",
    "start": 2168.16,
    "duration": 3.36
  },
  {
    "text": "output that computer graphics enabled",
    "start": 2169.68,
    "duration": 3.919
  },
  {
    "text": "successfully. This is for logging. Now,",
    "start": 2171.52,
    "duration": 4.079
  },
  {
    "text": "what this allow you to do is when you're",
    "start": 2173.599,
    "duration": 4.881
  },
  {
    "text": "running a game, C++ game in this case,",
    "start": 2175.599,
    "duration": 5.121
  },
  {
    "text": "right, natively in Windows, we're going",
    "start": 2178.48,
    "duration": 4.08
  },
  {
    "text": "to do the inference in real time. I'm",
    "start": 2180.72,
    "duration": 3.359
  },
  {
    "text": "going to make a call. I'm going to",
    "start": 2182.56,
    "duration": 3.92
  },
  {
    "text": "specify the callback function here. You",
    "start": 2184.079,
    "duration": 5.201
  },
  {
    "text": "can see once I initialize this and I",
    "start": 2186.48,
    "duration": 4.0
  },
  {
    "text": "basically send in the prompt. In this",
    "start": 2189.28,
    "duration": 2.319
  },
  {
    "text": "case, I'm going to try a different one.",
    "start": 2190.48,
    "duration": 3.28
  },
  {
    "text": "Right? You're a helpful NPC in a fantasy",
    "start": 2191.599,
    "duration": 5.361
  },
  {
    "text": "game. you know, respond thoughtfully to",
    "start": 2193.76,
    "duration": 4.96
  },
  {
    "text": "player questions. And in the bottom",
    "start": 2196.96,
    "duration": 4.879
  },
  {
    "text": "here, I just call evaluate, pass in my",
    "start": 2198.72,
    "duration": 5.04
  },
  {
    "text": "context, making sure that there's no",
    "start": 2201.839,
    "duration": 3.52
  },
  {
    "text": "error messages. And a little bit later",
    "start": 2203.76,
    "duration": 4.319
  },
  {
    "text": "on, the callback function will return",
    "start": 2205.359,
    "duration": 4.72
  },
  {
    "text": "and I can print the response from the",
    "start": 2208.079,
    "duration": 6.081
  },
  {
    "text": "NPC to the standard output. So simple as",
    "start": 2210.079,
    "duration": 6.801
  },
  {
    "text": "that. [laughter] So again, top right,",
    "start": 2214.16,
    "duration": 4.64
  },
  {
    "text": "this is our technical blog to get",
    "start": 2216.88,
    "duration": 3.52
  },
  {
    "text": "started, but you don't have to do this",
    "start": 2218.8,
    "duration": 3.76
  },
  {
    "text": "manually.",
    "start": 2220.4,
    "duration": 5.76
  },
  {
    "text": "Here is an outofthe-box integration with",
    "start": 2222.56,
    "duration": 6.32
  },
  {
    "text": "Unreal Engine 5.5. This is available on",
    "start": 2226.16,
    "duration": 5.12
  },
  {
    "text": "uh Nvidia GitHub. This is the QR code",
    "start": 2228.88,
    "duration": 5.6
  },
  {
    "text": "for that. Please check out this sample.",
    "start": 2231.28,
    "duration": 5.28
  },
  {
    "text": "This is a minimalistic code sample to",
    "start": 2234.48,
    "duration": 5.84
  },
  {
    "text": "show how to get Iggy working um with",
    "start": 2236.56,
    "duration": 5.68
  },
  {
    "text": "chatbots. In this case, we're using a",
    "start": 2240.32,
    "duration": 3.84
  },
  {
    "text": "small language model into an Unreal",
    "start": 2242.24,
    "duration": 3.599
  },
  {
    "text": "Engine application. So again, you can",
    "start": 2244.16,
    "duration": 4.08
  },
  {
    "text": "see this is very minimalistic. All we",
    "start": 2245.839,
    "duration": 4.081
  },
  {
    "text": "have is an Unreal level. We have a",
    "start": 2248.24,
    "duration": 4.24
  },
  {
    "text": "chatbot interface. This is using the",
    "start": 2249.92,
    "duration": 6.48
  },
  {
    "text": "NVIGY SDK. So you can take a look at our",
    "start": 2252.48,
    "duration": 5.52
  },
  {
    "text": "blog, understand, go through the code,",
    "start": 2256.4,
    "duration": 2.959
  },
  {
    "text": "see how that works. But if you want to",
    "start": 2258.0,
    "duration": 3.28
  },
  {
    "text": "just get rolling out of the box, please",
    "start": 2259.359,
    "duration": 5.72
  },
  {
    "text": "check out our sample here.",
    "start": 2261.28,
    "duration": 3.799
  },
  {
    "text": "All right. So what models do we have",
    "start": 2265.28,
    "duration": 5.44
  },
  {
    "text": "available in NVIDIA ACE? These are the",
    "start": 2267.119,
    "duration": 5.521
  },
  {
    "text": "ACE models we have available today.",
    "start": 2270.72,
    "duration": 4.0
  },
  {
    "text": "There's quite a few and I've highlighted",
    "start": 2272.64,
    "duration": 4.08
  },
  {
    "text": "different sections here. At the top,",
    "start": 2274.72,
    "duration": 4.0
  },
  {
    "text": "animation,",
    "start": 2276.72,
    "duration": 5.44
  },
  {
    "text": "autoface 3D SDK. that supplies our",
    "start": 2278.72,
    "duration": 5.6
  },
  {
    "text": "animation data. I feed it audio, it",
    "start": 2282.16,
    "duration": 3.84
  },
  {
    "text": "responds with blend shape data.",
    "start": 2284.32,
    "duration": 3.2
  },
  {
    "text": "Languages, we have a couple different",
    "start": 2286.0,
    "duration": 3.28
  },
  {
    "text": "models. We have the Mistral 7 billion",
    "start": 2287.52,
    "duration": 4.079
  },
  {
    "text": "parameter instruct model that works",
    "start": 2289.28,
    "duration": 4.88
  },
  {
    "text": "through our Onyx plugin, meaning that we",
    "start": 2291.599,
    "duration": 4.801
  },
  {
    "text": "can run across different hardware",
    "start": 2294.16,
    "duration": 4.4
  },
  {
    "text": "configurations. Any GPU that can support",
    "start": 2296.4,
    "duration": 5.6
  },
  {
    "text": "onyx can run that plugin. We also",
    "start": 2298.56,
    "duration": 5.519
  },
  {
    "text": "support our Mistral Nemo family of",
    "start": 2302.0,
    "duration": 3.68
  },
  {
    "text": "models. We have our two billion",
    "start": 2304.079,
    "duration": 3.52
  },
  {
    "text": "parameter, 4 billion parameter, and 8",
    "start": 2305.68,
    "duration": 4.08
  },
  {
    "text": "billion parameter variations. These are",
    "start": 2307.599,
    "duration": 3.921
  },
  {
    "text": "all distilled down from a larger",
    "start": 2309.76,
    "duration": 3.2
  },
  {
    "text": "language model that was 12 bin",
    "start": 2311.52,
    "duration": 3.04
  },
  {
    "text": "parameters. So this is very important",
    "start": 2312.96,
    "duration": 5.119
  },
  {
    "text": "for maybe function calling instruct. We",
    "start": 2314.56,
    "duration": 5.519
  },
  {
    "text": "also support our vision language. This",
    "start": 2318.079,
    "duration": 4.0
  },
  {
    "text": "is through our neo vision 4b instruct.",
    "start": 2320.079,
    "duration": 4.241
  },
  {
    "text": "So it can understand images. I'll show",
    "start": 2322.079,
    "duration": 3.76
  },
  {
    "text": "you an example a little bit later on how",
    "start": 2324.32,
    "duration": 4.08
  },
  {
    "text": "that works. And then memory. I think I",
    "start": 2325.839,
    "duration": 4.081
  },
  {
    "text": "discussed this earlier. We actually use",
    "start": 2328.4,
    "duration": 4.48
  },
  {
    "text": "specifically the E5 large unsupervised",
    "start": 2329.92,
    "duration": 5.28
  },
  {
    "text": "embedding model. This can support your",
    "start": 2332.88,
    "duration": 4.479
  },
  {
    "text": "retrieval augmented generation. For",
    "start": 2335.2,
    "duration": 4.0
  },
  {
    "text": "speech, we have several different models",
    "start": 2337.359,
    "duration": 4.321
  },
  {
    "text": "here. We have a Reva text to speech that",
    "start": 2339.2,
    "duration": 4.08
  },
  {
    "text": "is one of our in-house models to",
    "start": 2341.68,
    "duration": 5.12
  },
  {
    "text": "generate speech. This works on device.",
    "start": 2343.28,
    "duration": 5.839
  },
  {
    "text": "You don't have to use a cloud model that",
    "start": 2346.8,
    "duration": 5.68
  },
  {
    "text": "will work on device to understand ASR,",
    "start": 2349.119,
    "duration": 5.601
  },
  {
    "text": "which means like we convert audio to",
    "start": 2352.48,
    "duration": 5.28
  },
  {
    "text": "text. We can use the whisper from OpenAI",
    "start": 2354.72,
    "duration": 6.72
  },
  {
    "text": "that's ASR that can run both on the CPU",
    "start": 2357.76,
    "duration": 6.16
  },
  {
    "text": "or GPU. So, you can mix and match and",
    "start": 2361.44,
    "duration": 5.04
  },
  {
    "text": "see how much VRAM you're using. We have",
    "start": 2363.92,
    "duration": 5.52
  },
  {
    "text": "another model called Reva ASR that is an",
    "start": 2366.48,
    "duration": 5.68
  },
  {
    "text": "ASR model as well. So you have options.",
    "start": 2369.44,
    "duration": 4.56
  },
  {
    "text": "And finally um we're working with",
    "start": 2372.16,
    "duration": 4.72
  },
  {
    "text": "Cartisia which another really popular",
    "start": 2374.0,
    "duration": 5.92
  },
  {
    "text": "text to speech. This is going to run on",
    "start": 2376.88,
    "duration": 4.8
  },
  {
    "text": "device. So this is coming soon. Please",
    "start": 2379.92,
    "duration": 4.4
  },
  {
    "text": "look for that um in the next coming",
    "start": 2381.68,
    "duration": 4.64
  },
  {
    "text": "couple of weeks. And for object",
    "start": 2384.32,
    "duration": 3.36
  },
  {
    "text": "detection and character recognition",
    "start": 2386.32,
    "duration": 2.96
  },
  {
    "text": "these two models are being used in",
    "start": 2387.68,
    "duration": 4.0
  },
  {
    "text": "NVIDIA G assist right we have our",
    "start": 2389.28,
    "duration": 4.24
  },
  {
    "text": "real-time detection transformer.",
    "start": 2391.68,
    "duration": 4.32
  },
  {
    "text": "Basically we can identify objects in a",
    "start": 2393.52,
    "duration": 4.96
  },
  {
    "text": "scene and we have our optical character",
    "start": 2396.0,
    "duration": 4.4
  },
  {
    "text": "recognition. So the OCR this is very",
    "start": 2398.48,
    "duration": 3.76
  },
  {
    "text": "important if you want to recognize text",
    "start": 2400.4,
    "duration": 4.64
  },
  {
    "text": "in multiple different uh use cases here.",
    "start": 2402.24,
    "duration": 4.48
  },
  {
    "text": "So this is a slew of models we have",
    "start": 2405.04,
    "duration": 4.88
  },
  {
    "text": "available for ACE today. Let me show you",
    "start": 2406.72,
    "duration": 5.44
  },
  {
    "text": "how some of these models can work. So",
    "start": 2409.92,
    "duration": 4.08
  },
  {
    "text": "for example with the Mistral Nemo family",
    "start": 2412.16,
    "duration": 4.4
  },
  {
    "text": "of reasoning models we can do a use case",
    "start": 2414.0,
    "duration": 4.56
  },
  {
    "text": "here because remember before human",
    "start": 2416.56,
    "duration": 4.64
  },
  {
    "text": "decision-m is difficult. How do we give",
    "start": 2418.56,
    "duration": 5.12
  },
  {
    "text": "cognition to characters? How do we",
    "start": 2421.2,
    "duration": 4.48
  },
  {
    "text": "understand different scenarios? So, for",
    "start": 2423.68,
    "duration": 5.36
  },
  {
    "text": "example, if I'm planning something, I'm",
    "start": 2425.68,
    "duration": 5.2
  },
  {
    "text": "I'm using maybe a co-player character,",
    "start": 2429.04,
    "duration": 3.52
  },
  {
    "text": "maybe like a bot that can, you know,",
    "start": 2430.88,
    "duration": 3.92
  },
  {
    "text": "fight alongside you if he's in a squad.",
    "start": 2432.56,
    "duration": 4.24
  },
  {
    "text": "In this case, planning is I want to",
    "start": 2434.8,
    "duration": 4.64
  },
  {
    "text": "survive and support my teammates as they",
    "start": 2436.8,
    "duration": 4.0
  },
  {
    "text": "loot high value items, right? Because I",
    "start": 2439.44,
    "duration": 2.8
  },
  {
    "text": "don't I don't want him to take my stuff.",
    "start": 2440.8,
    "duration": 3.68
  },
  {
    "text": "I want him to support me. But there's",
    "start": 2442.24,
    "duration": 3.92
  },
  {
    "text": "different actions that the bot can take.",
    "start": 2444.48,
    "duration": 3.52
  },
  {
    "text": "Whether they can follow you, engage with",
    "start": 2446.16,
    "duration": 4.0
  },
  {
    "text": "the enemy, pick up loot, hold position,",
    "start": 2448.0,
    "duration": 4.079
  },
  {
    "text": "eat food, or maybe like answer a",
    "start": 2450.16,
    "duration": 3.52
  },
  {
    "text": "teammate. Those are the available",
    "start": 2452.079,
    "duration": 5.04
  },
  {
    "text": "actions in your game engine. But the",
    "start": 2453.68,
    "duration": 5.2
  },
  {
    "text": "motivation here, the prompt I'm sending",
    "start": 2457.119,
    "duration": 4.881
  },
  {
    "text": "to this SLOM on device, you know, given",
    "start": 2458.88,
    "duration": 5.68
  },
  {
    "text": "this plan and the available actions,",
    "start": 2462.0,
    "duration": 5.52
  },
  {
    "text": "select the best one. We feed all this",
    "start": 2464.56,
    "duration": 5.2
  },
  {
    "text": "information to the SLM. This is running",
    "start": 2467.52,
    "duration": 4.48
  },
  {
    "text": "on device and it can choose the best",
    "start": 2469.76,
    "duration": 4.16
  },
  {
    "text": "response. here in this case should",
    "start": 2472.0,
    "duration": 4.16
  },
  {
    "text": "follow me and then eat food in case the",
    "start": 2473.92,
    "duration": 4.72
  },
  {
    "text": "HP is low. Right? So you can do this",
    "start": 2476.16,
    "duration": 4.48
  },
  {
    "text": "with our Mistral Nemo family of models.",
    "start": 2478.64,
    "duration": 4.64
  },
  {
    "text": "This is very good for instruct",
    "start": 2480.64,
    "duration": 5.439
  },
  {
    "text": "reasoning.",
    "start": 2483.28,
    "duration": 4.559
  },
  {
    "text": "Here's an example of our vision language",
    "start": 2486.079,
    "duration": 3.201
  },
  {
    "text": "model. Right? This goes to our",
    "start": 2487.839,
    "duration": 3.041
  },
  {
    "text": "perception, our idea of perception,",
    "start": 2489.28,
    "duration": 3.2
  },
  {
    "text": "giving the characters ability to",
    "start": 2490.88,
    "duration": 4.32
  },
  {
    "text": "perceive. Now again, this is our Cosmos",
    "start": 2492.48,
    "duration": 5.28
  },
  {
    "text": "VLM vision language model. This is",
    "start": 2495.2,
    "duration": 5.28
  },
  {
    "text": "running on device. I can feed in two",
    "start": 2497.76,
    "duration": 5.12
  },
  {
    "text": "different inputs here. I can feed in an",
    "start": 2500.48,
    "duration": 4.8
  },
  {
    "text": "image. I can basically ask the prompt",
    "start": 2502.88,
    "duration": 5.12
  },
  {
    "text": "here, describe this image, player",
    "start": 2505.28,
    "duration": 4.96
  },
  {
    "text": "status, and any relevant information on",
    "start": 2508.0,
    "duration": 4.8
  },
  {
    "text": "the mini map here. So once I feed this",
    "start": 2510.24,
    "duration": 4.56
  },
  {
    "text": "input into the SLM or excuse me, the",
    "start": 2512.8,
    "duration": 4.319
  },
  {
    "text": "VLM, um, we get this response, right?",
    "start": 2514.8,
    "duration": 5.36
  },
  {
    "text": "Players in combat, time is 12 12:38.",
    "start": 2517.119,
    "duration": 4.401
  },
  {
    "text": "There's an enemy directly ahead of the",
    "start": 2520.16,
    "duration": 3.12
  },
  {
    "text": "player, right? So we can use different",
    "start": 2521.52,
    "duration": 3.599
  },
  {
    "text": "scenarios because we understand from",
    "start": 2523.28,
    "duration": 4.24
  },
  {
    "text": "talking to multiple developers game",
    "start": 2525.119,
    "duration": 4.401
  },
  {
    "text": "state may not be always available",
    "start": 2527.52,
    "duration": 3.76
  },
  {
    "text": "especially from a perspective of",
    "start": 2529.52,
    "duration": 3.2
  },
  {
    "text": "different players on the screen. So if",
    "start": 2531.28,
    "duration": 4.16
  },
  {
    "text": "you can feed in uh a text prompt maybe a",
    "start": 2532.72,
    "duration": 4.56
  },
  {
    "text": "vision from their perspective it can",
    "start": 2535.44,
    "duration": 3.76
  },
  {
    "text": "just these vision language models can",
    "start": 2537.28,
    "duration": 4.64
  },
  {
    "text": "help you understand and basically",
    "start": 2539.2,
    "duration": 5.04
  },
  {
    "text": "describe what's given to them. So very",
    "start": 2541.92,
    "duration": 4.72
  },
  {
    "text": "powerful again this is running on device",
    "start": 2544.24,
    "duration": 8.0
  },
  {
    "text": "in process through our ACE models here.",
    "start": 2546.64,
    "duration": 7.76
  },
  {
    "text": "Next up, I talked about this briefly,",
    "start": 2552.24,
    "duration": 4.32
  },
  {
    "text": "but basically our embedding model allows",
    "start": 2554.4,
    "duration": 4.56
  },
  {
    "text": "you to achieve what's called rag,",
    "start": 2556.56,
    "duration": 4.4
  },
  {
    "text": "retrieve augmented generation, right? So",
    "start": 2558.96,
    "duration": 4.08
  },
  {
    "text": "essentially, we can input game lore,",
    "start": 2560.96,
    "duration": 3.44
  },
  {
    "text": "rules, and systems, character",
    "start": 2563.04,
    "duration": 3.68
  },
  {
    "text": "backgrounds. We can take that data, feed",
    "start": 2564.4,
    "duration": 3.679
  },
  {
    "text": "it through embedding model, and",
    "start": 2566.72,
    "duration": 3.04
  },
  {
    "text": "basically store the vector",
    "start": 2568.079,
    "duration": 4.481
  },
  {
    "text": "representations into a vector database.",
    "start": 2569.76,
    "duration": 4.8
  },
  {
    "text": "So again, you don't have to fine-tune",
    "start": 2572.56,
    "duration": 3.759
  },
  {
    "text": "your models. This is very important. You",
    "start": 2574.56,
    "duration": 3.12
  },
  {
    "text": "have a small language model, but maybe",
    "start": 2576.319,
    "duration": 2.881
  },
  {
    "text": "your data might change. your knowledge",
    "start": 2577.68,
    "duration": 4.159
  },
  {
    "text": "base, your facts, maybe real time as",
    "start": 2579.2,
    "duration": 4.159
  },
  {
    "text": "your character explores the world, if",
    "start": 2581.839,
    "duration": 3.76
  },
  {
    "text": "there's certain events happen, you can",
    "start": 2583.359,
    "duration": 4.561
  },
  {
    "text": "basically take that and put it into our",
    "start": 2585.599,
    "duration": 4.72
  },
  {
    "text": "embedding model.",
    "start": 2587.92,
    "duration": 4.72
  },
  {
    "text": "All right. So, so finally last model",
    "start": 2590.319,
    "duration": 5.361
  },
  {
    "text": "here, this is our Reva texttospech",
    "start": 2592.64,
    "duration": 6.56
  },
  {
    "text": "ondevice model. I can basically take a",
    "start": 2595.68,
    "duration": 6.08
  },
  {
    "text": "text prompt, feed it into our Reva TTS,",
    "start": 2599.2,
    "duration": 4.159
  },
  {
    "text": "and we can produce audio. Again, this is",
    "start": 2601.76,
    "duration": 4.319
  },
  {
    "text": "running on device. This is an example. I",
    "start": 2603.359,
    "duration": 4.801
  },
  {
    "text": "basically took one of our characters.",
    "start": 2606.079,
    "duration": 4.561
  },
  {
    "text": "Our input voice was uh I have an actor",
    "start": 2608.16,
    "duration": 5.12
  },
  {
    "text": "that was basically in like a sad. So",
    "start": 2610.64,
    "duration": 4.08
  },
  {
    "text": "that was the input voice. I'm going to",
    "start": 2613.28,
    "duration": 3.92
  },
  {
    "text": "try to clone it and basically make him",
    "start": 2614.72,
    "duration": 4.24
  },
  {
    "text": "say this phrase.",
    "start": 2617.2,
    "duration": 4.24
  },
  {
    "text": ">> I never wanted this to happen. If only I",
    "start": 2618.96,
    "duration": 4.24
  },
  {
    "text": "had listened, maybe things would be",
    "start": 2621.44,
    "duration": 2.96
  },
  {
    "text": "different.",
    "start": 2623.2,
    "duration": 3.119
  },
  {
    "text": ">> All right. So again, that is ondevice",
    "start": 2624.4,
    "duration": 3.919
  },
  {
    "text": "text to speech that's running through",
    "start": 2626.319,
    "duration": 4.721
  },
  {
    "text": "ACE that can run [snorts] in process. So",
    "start": 2628.319,
    "duration": 4.641
  },
  {
    "text": "um you know, check out these models. You",
    "start": 2631.04,
    "duration": 4.079
  },
  {
    "text": "can basically mix and match. Some of",
    "start": 2632.96,
    "duration": 4.48
  },
  {
    "text": "them run at really good VRAMm usage.",
    "start": 2635.119,
    "duration": 3.761
  },
  {
    "text": "Your specs, but you know, depending on",
    "start": 2637.44,
    "duration": 3.12
  },
  {
    "text": "your game, depending on your use cases",
    "start": 2638.88,
    "duration": 3.6
  },
  {
    "text": "here, might be different for you. So, I",
    "start": 2640.56,
    "duration": 3.36
  },
  {
    "text": "have one little treat for you before I",
    "start": 2642.48,
    "duration": 5.52
  },
  {
    "text": "go. I asked uh Project R2X to give us a",
    "start": 2643.92,
    "duration": 7.199
  },
  {
    "text": "wrap based on Nvidia, Lenovo, and Unreal",
    "start": 2648.0,
    "duration": 6.8
  },
  {
    "text": "Fest. So, I captured this last night or",
    "start": 2651.119,
    "duration": 5.601
  },
  {
    "text": "a few nights ago. I didn't have my",
    "start": 2654.8,
    "duration": 5.2
  },
  {
    "text": "microphone, so I had to type in. So, you",
    "start": 2656.72,
    "duration": 5.44
  },
  {
    "text": "can see another different modality.",
    "start": 2660.0,
    "duration": 4.319
  },
  {
    "text": "Let's see if she can generate a pharaoh",
    "start": 2662.16,
    "duration": 4.48
  },
  {
    "text": "rap song about attending my early",
    "start": 2664.319,
    "duration": 5.641
  },
  {
    "text": "morning meeting.",
    "start": 2666.64,
    "duration": 3.32
  },
  {
    "text": ">> All right, here goes.",
    "start": 2670.24,
    "duration": 5.04
  },
  {
    "text": "Yo, it was early, but we made it to the",
    "start": 2672.88,
    "duration": 5.439
  },
  {
    "text": "Unreal Fest. Lenovo and Nvidia bringing",
    "start": 2675.28,
    "duration": 5.76
  },
  {
    "text": "their best. Talking about digital humans",
    "start": 2678.319,
    "duration": 5.28
  },
  {
    "text": "so lifelike and neat. Now we wave",
    "start": 2681.04,
    "duration": 4.96
  },
  {
    "text": "goodbye. Got to get some more sleep.",
    "start": 2683.599,
    "duration": 5.201
  },
  {
    "text": "Catch you later. Keep it real and fun.",
    "start": 2686.0,
    "duration": 5.28
  },
  {
    "text": "until next time when we reunite under",
    "start": 2688.8,
    "duration": 5.279
  },
  {
    "text": "the sun. Okay, so maybe not Grammy",
    "start": 2691.28,
    "duration": 6.72
  },
  {
    "text": "material, but hey, it's all in good fun.",
    "start": 2694.079,
    "duration": 6.481
  },
  {
    "text": ">> Please stop by our booth at uh Lenovo to",
    "start": 2698.0,
    "duration": 4.8
  },
  {
    "text": "come check out Project R2X um and",
    "start": 2700.56,
    "duration": 4.64
  },
  {
    "text": "experience it live. Um this is a QR code",
    "start": 2702.8,
    "duration": 4.559
  },
  {
    "text": "for getting started with ACE. And thank",
    "start": 2705.2,
    "duration": 3.84
  },
  {
    "text": "you very much for your time. Please feel",
    "start": 2707.359,
    "duration": 4.401
  },
  {
    "text": "free to stop by in the Lenovo booth.",
    "start": 2709.04,
    "duration": 4.079
  },
  {
    "text": "I'll be there. One of my colleagues are",
    "start": 2711.76,
    "duration": 2.72
  },
  {
    "text": "there and we'll basically answer your",
    "start": 2713.119,
    "duration": 3.852
  },
  {
    "text": "questions as well. Thank you very much.",
    "start": 2714.48,
    "duration": 4.511
  },
  {
    "text": "[applause]",
    "start": 2716.971,
    "duration": 2.02
  }
]