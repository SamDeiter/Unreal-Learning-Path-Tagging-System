{
  "text": " In this portion of our course, we will explore various workflows that can be used to make changes to the metahuman neutral pose. We begin with pipeline considerations for achieving likeness using DNA calibration. Then we cover different approaches for fitting metahuman topology to face scan data and sculpted 3D head meshes. From there, we move on to two hands-on exercises. For the first exercise, we will export a metahuman identity conformed mesh from Unreal Engine that can be used for additional fitting. For the second one, we will solve a metahuman identity based on geometry using the Mesh to Metahuman workflow with the Template Mesh option. We then delve into best practices for fitting the metahuman head geometry and its additional assets, such as the eyes, eyelashes, and so on, to our target delta. Let's begin by exploring workflows for achieving likeness using 3D sculpted head meshes and face scan data. In this section, we begin by looking at pipeline considerations for achieving likeness using DNA calibration. We then delve into different approaches for fitting metahuman topology to face scan data and sculpted 3D head meshes. To finalize changes that have been made to the metahuman neutral pose, metahuman DNA needs to be updated before bringing the modified assets back into Unreal Engine. To do this, we can use the DNA Calibration toolset. The main step we will see when working with either scan or sculpted mesh workflows is that metahuman DNA will need to be recalibrated before bringing any changes back into Unreal Engine. One of the reasons is due to the relationship the vertex and joint positions have with each other. Each joint name has a value assigned as a vertex index. Once we start to work with DNA calibration, you will notice two commands we will be running, which is to save the current vertex and joint positions, then update the vertex and joints to their new positions, and save those changes to the DNA. The images in the top right demonstrate the surface joint positions before and after they have been updated once the vertex positions have been changed. Surface joints are responsible for preserving volume, especially for lower LODs. So once a change is made to the vertex positions, using commands, we are able to snap the surface joints to their new vertex positions, so that the volume is preserved. Simply put, when making changes to the vertex positions or joint positions, the DNA file needs to account for these changes by updating the behavior and geometry layer of the DNA file. And we do this so that when we bring our finalized rig back into Unreal Engine, along with the updated DNA file, it will behave correctly. Now, let's take a look at pipeline considerations when working with a face skin or sculpted head mesh. When working with a head sculpt, the focus will be on fitting the metahuman topology to the sculpt first, and then fitting the additional face geometry assets to it. The first step would be to select a metahuman preset and wrap the LOD 0 head topology to the head sculpt. The second step would be to use the mesh to metahuman workflow with the template mesh option to create a metahuman identity that is solved based on geometry, as this will get the geometry and joints closer to the target delta. This differs from the standard mesh to metahuman workflow, which solves a metahuman identity based on image and how the tracking markers are positioned. The third step would be to refit any details that may have been lost from the solve, and then manually fit all of the additional face geometry assets to the metahuman identity head mesh vertex by vertex. This is the most time consuming portion of this workflow. The fourth step would be to use DNA calibration to update the vertex and joint positions and save those changes to the DNA file. The head LODs can then be exported as FBX, along with the new DNA file. And the final step would be to bring the modified assets back into Unreal Engine and configure the new assets. This workflow chart represents what a pipeline might look like, and it is not a hard roadmap, as the steps may vary depending on a pipeline's needs. Now, let's take a look at how this workflow may differ if using face scan data. For face scan data, the focus may be more on transferring the texture maps correctly by aligning the head geometry with the original face scan. Step one would be to use the standard mesh to metahuman workflow to create an initial metahuman identity that is solved based on image, which relies on where the tracking markers are placed on the facial features. This would align the head geometry with the scan in order to transfer the textures. Step two would be to export the conformed mesh from the metahuman identity asset and refit any details that were lost from the solve. Step three would be to use the mesh to metahuman workflow with the template mesh option in order to get the geometry and joints closer to the target delta. And step four would be to use this new metahuman identity to refit any lost details and then fit the additional head geometry assets. Step five would be to update the changes to the vertex and joint positions and save those changes to the DNA and then export the head LODs as FBX bundled with the new DNA file. Step six would be to finalize the rig by bringing the modified assets into Unreal Engine and then configure them. The process of transferring textures is not included in this workflow chart. As mentioned, these charts are not a hard roadmap. They simply demonstrate different approaches for fitting and that by adding DNA calibration to a workflow, This ensures that the metahuman DNA file will take into account changes that have been made to the neutral pose. And once those changes have been brought back into Unreal Engine, the metahuman face will behave correctly. In the next section, we will delve into approaches for fitting metahuman topology to a scan or sculpted mesh.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 10.0,
      "text": " In this portion of our course, we will explore various workflows that can be used to make changes to the metahuman neutral pose.",
      "tokens": [
        50364,
        682,
        341,
        8044,
        295,
        527,
        1164,
        11,
        321,
        486,
        6839,
        3683,
        43461,
        300,
        393,
        312,
        1143,
        281,
        652,
        2962,
        281,
        264,
        1131,
        545,
        6829,
        10598,
        10774,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10334534187839456,
      "compression_ratio": 1.4772727272727273,
      "no_speech_prob": 0.01825481280684471
    },
    {
      "id": 1,
      "seek": 0,
      "start": 10.0,
      "end": 17.0,
      "text": " We begin with pipeline considerations for achieving likeness using DNA calibration.",
      "tokens": [
        50864,
        492,
        1841,
        365,
        15517,
        24070,
        337,
        19626,
        36946,
        442,
        1228,
        8272,
        38732,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10334534187839456,
      "compression_ratio": 1.4772727272727273,
      "no_speech_prob": 0.01825481280684471
    },
    {
      "id": 2,
      "seek": 0,
      "start": 17.0,
      "end": 25.0,
      "text": " Then we cover different approaches for fitting metahuman topology to face scan data and sculpted 3D head meshes.",
      "tokens": [
        51214,
        1396,
        321,
        2060,
        819,
        11587,
        337,
        15669,
        1131,
        545,
        6829,
        1192,
        1793,
        281,
        1851,
        11049,
        1412,
        293,
        12613,
        292,
        805,
        35,
        1378,
        3813,
        8076,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10334534187839456,
      "compression_ratio": 1.4772727272727273,
      "no_speech_prob": 0.01825481280684471
    },
    {
      "id": 3,
      "seek": 2500,
      "start": 25.0,
      "end": 29.0,
      "text": " From there, we move on to two hands-on exercises.",
      "tokens": [
        50364,
        3358,
        456,
        11,
        321,
        1286,
        322,
        281,
        732,
        2377,
        12,
        266,
        11900,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.061388368959780094,
      "compression_ratio": 1.649746192893401,
      "no_speech_prob": 0.11586620658636093
    },
    {
      "id": 4,
      "seek": 2500,
      "start": 29.0,
      "end": 37.0,
      "text": " For the first exercise, we will export a metahuman identity conformed mesh from Unreal Engine that can be used for additional fitting.",
      "tokens": [
        50564,
        1171,
        264,
        700,
        5380,
        11,
        321,
        486,
        10725,
        257,
        1131,
        545,
        6829,
        6575,
        18975,
        292,
        17407,
        490,
        34464,
        7659,
        300,
        393,
        312,
        1143,
        337,
        4497,
        15669,
        13,
        50964
      ],
      "temperature": 0.0,
      "avg_logprob": -0.061388368959780094,
      "compression_ratio": 1.649746192893401,
      "no_speech_prob": 0.11586620658636093
    },
    {
      "id": 5,
      "seek": 2500,
      "start": 37.0,
      "end": 47.0,
      "text": " For the second one, we will solve a metahuman identity based on geometry using the Mesh to Metahuman workflow with the Template Mesh option.",
      "tokens": [
        50964,
        1171,
        264,
        1150,
        472,
        11,
        321,
        486,
        5039,
        257,
        1131,
        545,
        6829,
        6575,
        2361,
        322,
        18426,
        1228,
        264,
        376,
        14935,
        281,
        6377,
        545,
        6829,
        20993,
        365,
        264,
        39563,
        473,
        376,
        14935,
        3614,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.061388368959780094,
      "compression_ratio": 1.649746192893401,
      "no_speech_prob": 0.11586620658636093
    },
    {
      "id": 6,
      "seek": 4700,
      "start": 47.0,
      "end": 60.0,
      "text": " We then delve into best practices for fitting the metahuman head geometry and its additional assets, such as the eyes, eyelashes, and so on, to our target delta.",
      "tokens": [
        50364,
        492,
        550,
        43098,
        666,
        1151,
        7525,
        337,
        15669,
        264,
        1131,
        545,
        6829,
        1378,
        18426,
        293,
        1080,
        4497,
        9769,
        11,
        1270,
        382,
        264,
        2575,
        11,
        37017,
        11,
        293,
        370,
        322,
        11,
        281,
        527,
        3779,
        8289,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05661659315228462,
      "compression_ratio": 1.454054054054054,
      "no_speech_prob": 0.013422751799225807
    },
    {
      "id": 7,
      "seek": 4700,
      "start": 60.0,
      "end": 68.0,
      "text": " Let's begin by exploring workflows for achieving likeness using 3D sculpted head meshes and face scan data.",
      "tokens": [
        51014,
        961,
        311,
        1841,
        538,
        12736,
        43461,
        337,
        19626,
        36946,
        442,
        1228,
        805,
        35,
        12613,
        292,
        1378,
        3813,
        8076,
        293,
        1851,
        11049,
        1412,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05661659315228462,
      "compression_ratio": 1.454054054054054,
      "no_speech_prob": 0.013422751799225807
    },
    {
      "id": 8,
      "seek": 6800,
      "start": 69.0,
      "end": 77.0,
      "text": " In this section, we begin by looking at pipeline considerations for achieving likeness using DNA calibration.",
      "tokens": [
        50414,
        682,
        341,
        3541,
        11,
        321,
        1841,
        538,
        1237,
        412,
        15517,
        24070,
        337,
        19626,
        36946,
        442,
        1228,
        8272,
        38732,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.03454498917448754,
      "compression_ratio": 1.3674698795180722,
      "no_speech_prob": 0.014951763674616814
    },
    {
      "id": 9,
      "seek": 6800,
      "start": 77.0,
      "end": 87.0,
      "text": " We then delve into different approaches for fitting metahuman topology to face scan data and sculpted 3D head meshes.",
      "tokens": [
        50814,
        492,
        550,
        43098,
        666,
        819,
        11587,
        337,
        15669,
        1131,
        545,
        6829,
        1192,
        1793,
        281,
        1851,
        11049,
        1412,
        293,
        12613,
        292,
        805,
        35,
        1378,
        3813,
        8076,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.03454498917448754,
      "compression_ratio": 1.3674698795180722,
      "no_speech_prob": 0.014951763674616814
    },
    {
      "id": 10,
      "seek": 8700,
      "start": 87.0,
      "end": 98.0,
      "text": " To finalize changes that have been made to the metahuman neutral pose, metahuman DNA needs to be updated before bringing the modified assets back into Unreal Engine.",
      "tokens": [
        50364,
        1407,
        2572,
        1125,
        2962,
        300,
        362,
        668,
        1027,
        281,
        264,
        1131,
        545,
        6829,
        10598,
        10774,
        11,
        1131,
        545,
        6829,
        8272,
        2203,
        281,
        312,
        10588,
        949,
        5062,
        264,
        15873,
        9769,
        646,
        666,
        34464,
        7659,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.04990894595781962,
      "compression_ratio": 1.7797356828193833,
      "no_speech_prob": 0.012050079181790352
    },
    {
      "id": 11,
      "seek": 8700,
      "start": 98.0,
      "end": 102.0,
      "text": " To do this, we can use the DNA Calibration toolset.",
      "tokens": [
        50914,
        1407,
        360,
        341,
        11,
        321,
        393,
        764,
        264,
        8272,
        3511,
        897,
        2405,
        2290,
        3854,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.04990894595781962,
      "compression_ratio": 1.7797356828193833,
      "no_speech_prob": 0.012050079181790352
    },
    {
      "id": 12,
      "seek": 8700,
      "start": 104.0,
      "end": 116.0,
      "text": " The main step we will see when working with either scan or sculpted mesh workflows is that metahuman DNA will need to be recalibrated before bringing any changes back into Unreal Engine.",
      "tokens": [
        51214,
        440,
        2135,
        1823,
        321,
        486,
        536,
        562,
        1364,
        365,
        2139,
        11049,
        420,
        12613,
        292,
        17407,
        43461,
        307,
        300,
        1131,
        545,
        6829,
        8272,
        486,
        643,
        281,
        312,
        850,
        304,
        897,
        5468,
        949,
        5062,
        604,
        2962,
        646,
        666,
        34464,
        7659,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.04990894595781962,
      "compression_ratio": 1.7797356828193833,
      "no_speech_prob": 0.012050079181790352
    },
    {
      "id": 13,
      "seek": 11600,
      "start": 116.0,
      "end": 122.0,
      "text": " One of the reasons is due to the relationship the vertex and joint positions have with each other.",
      "tokens": [
        50364,
        1485,
        295,
        264,
        4112,
        307,
        3462,
        281,
        264,
        2480,
        264,
        28162,
        293,
        7225,
        8432,
        362,
        365,
        1184,
        661,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.03262863953908284,
      "compression_ratio": 1.7963800904977376,
      "no_speech_prob": 0.000656271877232939
    },
    {
      "id": 14,
      "seek": 11600,
      "start": 122.0,
      "end": 127.0,
      "text": " Each joint name has a value assigned as a vertex index.",
      "tokens": [
        50664,
        6947,
        7225,
        1315,
        575,
        257,
        2158,
        13279,
        382,
        257,
        28162,
        8186,
        13,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.03262863953908284,
      "compression_ratio": 1.7963800904977376,
      "no_speech_prob": 0.000656271877232939
    },
    {
      "id": 15,
      "seek": 11600,
      "start": 127.0,
      "end": 136.0,
      "text": " Once we start to work with DNA calibration, you will notice two commands we will be running, which is to save the current vertex and joint positions,",
      "tokens": [
        50914,
        3443,
        321,
        722,
        281,
        589,
        365,
        8272,
        38732,
        11,
        291,
        486,
        3449,
        732,
        16901,
        321,
        486,
        312,
        2614,
        11,
        597,
        307,
        281,
        3155,
        264,
        2190,
        28162,
        293,
        7225,
        8432,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.03262863953908284,
      "compression_ratio": 1.7963800904977376,
      "no_speech_prob": 0.000656271877232939
    },
    {
      "id": 16,
      "seek": 11600,
      "start": 136.0,
      "end": 143.0,
      "text": " then update the vertex and joints to their new positions, and save those changes to the DNA.",
      "tokens": [
        51364,
        550,
        5623,
        264,
        28162,
        293,
        19949,
        281,
        641,
        777,
        8432,
        11,
        293,
        3155,
        729,
        2962,
        281,
        264,
        8272,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.03262863953908284,
      "compression_ratio": 1.7963800904977376,
      "no_speech_prob": 0.000656271877232939
    },
    {
      "id": 17,
      "seek": 14300,
      "start": 143.0,
      "end": 153.0,
      "text": " The images in the top right demonstrate the surface joint positions before and after they have been updated once the vertex positions have been changed.",
      "tokens": [
        50364,
        440,
        5267,
        294,
        264,
        1192,
        558,
        11698,
        264,
        3753,
        7225,
        8432,
        949,
        293,
        934,
        436,
        362,
        668,
        10588,
        1564,
        264,
        28162,
        8432,
        362,
        668,
        3105,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0565026601155599,
      "compression_ratio": 1.8525345622119815,
      "no_speech_prob": 0.00019109461572952569
    },
    {
      "id": 18,
      "seek": 14300,
      "start": 153.0,
      "end": 159.0,
      "text": " Surface joints are responsible for preserving volume, especially for lower LODs.",
      "tokens": [
        50864,
        36052,
        19949,
        366,
        6250,
        337,
        33173,
        5523,
        11,
        2318,
        337,
        3126,
        441,
        14632,
        82,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0565026601155599,
      "compression_ratio": 1.8525345622119815,
      "no_speech_prob": 0.00019109461572952569
    },
    {
      "id": 19,
      "seek": 14300,
      "start": 159.0,
      "end": 171.0,
      "text": " So once a change is made to the vertex positions, using commands, we are able to snap the surface joints to their new vertex positions, so that the volume is preserved.",
      "tokens": [
        51164,
        407,
        1564,
        257,
        1319,
        307,
        1027,
        281,
        264,
        28162,
        8432,
        11,
        1228,
        16901,
        11,
        321,
        366,
        1075,
        281,
        13650,
        264,
        3753,
        19949,
        281,
        641,
        777,
        28162,
        8432,
        11,
        370,
        300,
        264,
        5523,
        307,
        22242,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0565026601155599,
      "compression_ratio": 1.8525345622119815,
      "no_speech_prob": 0.00019109461572952569
    },
    {
      "id": 20,
      "seek": 17100,
      "start": 171.0,
      "end": 185.0,
      "text": " Simply put, when making changes to the vertex positions or joint positions, the DNA file needs to account for these changes by updating the behavior and geometry layer of the DNA file.",
      "tokens": [
        50364,
        19596,
        829,
        11,
        562,
        1455,
        2962,
        281,
        264,
        28162,
        8432,
        420,
        7225,
        8432,
        11,
        264,
        8272,
        3991,
        2203,
        281,
        2696,
        337,
        613,
        2962,
        538,
        25113,
        264,
        5223,
        293,
        18426,
        4583,
        295,
        264,
        8272,
        3991,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.035093673518006234,
      "compression_ratio": 1.5603864734299517,
      "no_speech_prob": 0.0005527292378246784
    },
    {
      "id": 21,
      "seek": 17100,
      "start": 185.0,
      "end": 195.0,
      "text": " And we do this so that when we bring our finalized rig back into Unreal Engine, along with the updated DNA file, it will behave correctly.",
      "tokens": [
        51064,
        400,
        321,
        360,
        341,
        370,
        300,
        562,
        321,
        1565,
        527,
        2572,
        1602,
        8329,
        646,
        666,
        34464,
        7659,
        11,
        2051,
        365,
        264,
        10588,
        8272,
        3991,
        11,
        309,
        486,
        15158,
        8944,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.035093673518006234,
      "compression_ratio": 1.5603864734299517,
      "no_speech_prob": 0.0005527292378246784
    },
    {
      "id": 22,
      "seek": 19500,
      "start": 195.0,
      "end": 202.0,
      "text": " Now, let's take a look at pipeline considerations when working with a face skin or sculpted head mesh.",
      "tokens": [
        50364,
        823,
        11,
        718,
        311,
        747,
        257,
        574,
        412,
        15517,
        24070,
        562,
        1364,
        365,
        257,
        1851,
        3178,
        420,
        12613,
        292,
        1378,
        17407,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06727283079545576,
      "compression_ratio": 1.7476635514018692,
      "no_speech_prob": 0.32730355858802795
    },
    {
      "id": 23,
      "seek": 19500,
      "start": 202.0,
      "end": 214.0,
      "text": " When working with a head sculpt, the focus will be on fitting the metahuman topology to the sculpt first, and then fitting the additional face geometry assets to it.",
      "tokens": [
        50714,
        1133,
        1364,
        365,
        257,
        1378,
        12613,
        11,
        264,
        1879,
        486,
        312,
        322,
        15669,
        264,
        1131,
        545,
        6829,
        1192,
        1793,
        281,
        264,
        12613,
        700,
        11,
        293,
        550,
        15669,
        264,
        4497,
        1851,
        18426,
        9769,
        281,
        309,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06727283079545576,
      "compression_ratio": 1.7476635514018692,
      "no_speech_prob": 0.32730355858802795
    },
    {
      "id": 24,
      "seek": 19500,
      "start": 214.0,
      "end": 222.0,
      "text": " The first step would be to select a metahuman preset and wrap the LOD 0 head topology to the head sculpt.",
      "tokens": [
        51314,
        440,
        700,
        1823,
        576,
        312,
        281,
        3048,
        257,
        1131,
        545,
        6829,
        32081,
        293,
        7019,
        264,
        441,
        14632,
        1958,
        1378,
        1192,
        1793,
        281,
        264,
        1378,
        12613,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06727283079545576,
      "compression_ratio": 1.7476635514018692,
      "no_speech_prob": 0.32730355858802795
    },
    {
      "id": 25,
      "seek": 22200,
      "start": 223.0,
      "end": 238.0,
      "text": " The second step would be to use the mesh to metahuman workflow with the template mesh option to create a metahuman identity that is solved based on geometry, as this will get the geometry and joints closer to the target delta.",
      "tokens": [
        50414,
        440,
        1150,
        1823,
        576,
        312,
        281,
        764,
        264,
        17407,
        281,
        1131,
        545,
        6829,
        20993,
        365,
        264,
        12379,
        17407,
        3614,
        281,
        1884,
        257,
        1131,
        545,
        6829,
        6575,
        300,
        307,
        13041,
        2361,
        322,
        18426,
        11,
        382,
        341,
        486,
        483,
        264,
        18426,
        293,
        19949,
        4966,
        281,
        264,
        3779,
        8289,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05034376626991364,
      "compression_ratio": 1.8221153846153846,
      "no_speech_prob": 0.2171904444694519
    },
    {
      "id": 26,
      "seek": 22200,
      "start": 238.0,
      "end": 248.0,
      "text": " This differs from the standard mesh to metahuman workflow, which solves a metahuman identity based on image and how the tracking markers are positioned.",
      "tokens": [
        51164,
        639,
        37761,
        490,
        264,
        3832,
        17407,
        281,
        1131,
        545,
        6829,
        20993,
        11,
        597,
        39890,
        257,
        1131,
        545,
        6829,
        6575,
        2361,
        322,
        3256,
        293,
        577,
        264,
        11603,
        19175,
        366,
        24889,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05034376626991364,
      "compression_ratio": 1.8221153846153846,
      "no_speech_prob": 0.2171904444694519
    },
    {
      "id": 27,
      "seek": 24800,
      "start": 249.0,
      "end": 263.0,
      "text": " The third step would be to refit any details that may have been lost from the solve, and then manually fit all of the additional face geometry assets to the metahuman identity head mesh vertex by vertex.",
      "tokens": [
        50414,
        440,
        2636,
        1823,
        576,
        312,
        281,
        1895,
        270,
        604,
        4365,
        300,
        815,
        362,
        668,
        2731,
        490,
        264,
        5039,
        11,
        293,
        550,
        16945,
        3318,
        439,
        295,
        264,
        4497,
        1851,
        18426,
        9769,
        281,
        264,
        1131,
        545,
        6829,
        6575,
        1378,
        17407,
        28162,
        538,
        28162,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06091081264407136,
      "compression_ratio": 1.6595744680851063,
      "no_speech_prob": 0.005384193267673254
    },
    {
      "id": 28,
      "seek": 24800,
      "start": 263.0,
      "end": 267.0,
      "text": " This is the most time consuming portion of this workflow.",
      "tokens": [
        51114,
        639,
        307,
        264,
        881,
        565,
        19867,
        8044,
        295,
        341,
        20993,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06091081264407136,
      "compression_ratio": 1.6595744680851063,
      "no_speech_prob": 0.005384193267673254
    },
    {
      "id": 29,
      "seek": 24800,
      "start": 267.0,
      "end": 277.0,
      "text": " The fourth step would be to use DNA calibration to update the vertex and joint positions and save those changes to the DNA file.",
      "tokens": [
        51314,
        440,
        6409,
        1823,
        576,
        312,
        281,
        764,
        8272,
        38732,
        281,
        5623,
        264,
        28162,
        293,
        7225,
        8432,
        293,
        3155,
        729,
        2962,
        281,
        264,
        8272,
        3991,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06091081264407136,
      "compression_ratio": 1.6595744680851063,
      "no_speech_prob": 0.005384193267673254
    },
    {
      "id": 30,
      "seek": 27700,
      "start": 277.0,
      "end": 283.0,
      "text": " The head LODs can then be exported as FBX, along with the new DNA file.",
      "tokens": [
        50364,
        440,
        1378,
        441,
        14632,
        82,
        393,
        550,
        312,
        42055,
        382,
        479,
        33,
        55,
        11,
        2051,
        365,
        264,
        777,
        8272,
        3991,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.056786546520158354,
      "compression_ratio": 1.5747126436781609,
      "no_speech_prob": 2.7968737413175404e-05
    },
    {
      "id": 31,
      "seek": 27700,
      "start": 283.0,
      "end": 290.0,
      "text": " And the final step would be to bring the modified assets back into Unreal Engine and configure the new assets.",
      "tokens": [
        50664,
        400,
        264,
        2572,
        1823,
        576,
        312,
        281,
        1565,
        264,
        15873,
        9769,
        646,
        666,
        34464,
        7659,
        293,
        22162,
        264,
        777,
        9769,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.056786546520158354,
      "compression_ratio": 1.5747126436781609,
      "no_speech_prob": 2.7968737413175404e-05
    },
    {
      "id": 32,
      "seek": 27700,
      "start": 290.0,
      "end": 300.0,
      "text": " This workflow chart represents what a pipeline might look like, and it is not a hard roadmap, as the steps may vary depending on a pipeline's needs.",
      "tokens": [
        51014,
        639,
        20993,
        6927,
        8855,
        437,
        257,
        15517,
        1062,
        574,
        411,
        11,
        293,
        309,
        307,
        406,
        257,
        1152,
        35738,
        11,
        382,
        264,
        4439,
        815,
        10559,
        5413,
        322,
        257,
        15517,
        311,
        2203,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.056786546520158354,
      "compression_ratio": 1.5747126436781609,
      "no_speech_prob": 2.7968737413175404e-05
    },
    {
      "id": 33,
      "seek": 27700,
      "start": 300.0,
      "end": 306.0,
      "text": " Now, let's take a look at how this workflow may differ if using face scan data.",
      "tokens": [
        51514,
        823,
        11,
        718,
        311,
        747,
        257,
        574,
        412,
        577,
        341,
        20993,
        815,
        743,
        498,
        1228,
        1851,
        11049,
        1412,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.056786546520158354,
      "compression_ratio": 1.5747126436781609,
      "no_speech_prob": 2.7968737413175404e-05
    },
    {
      "id": 34,
      "seek": 30600,
      "start": 306.0,
      "end": 316.0,
      "text": " For face scan data, the focus may be more on transferring the texture maps correctly by aligning the head geometry with the original face scan.",
      "tokens": [
        50364,
        1171,
        1851,
        11049,
        1412,
        11,
        264,
        1879,
        815,
        312,
        544,
        322,
        31437,
        264,
        8091,
        11317,
        8944,
        538,
        419,
        9676,
        264,
        1378,
        18426,
        365,
        264,
        3380,
        1851,
        11049,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.03839067979292436,
      "compression_ratio": 1.6081081081081081,
      "no_speech_prob": 0.00018521941092330962
    },
    {
      "id": 35,
      "seek": 30600,
      "start": 316.0,
      "end": 330.0,
      "text": " Step one would be to use the standard mesh to metahuman workflow to create an initial metahuman identity that is solved based on image, which relies on where the tracking markers are placed on the facial features.",
      "tokens": [
        50864,
        5470,
        472,
        576,
        312,
        281,
        764,
        264,
        3832,
        17407,
        281,
        1131,
        545,
        6829,
        20993,
        281,
        1884,
        364,
        5883,
        1131,
        545,
        6829,
        6575,
        300,
        307,
        13041,
        2361,
        322,
        3256,
        11,
        597,
        30910,
        322,
        689,
        264,
        11603,
        19175,
        366,
        7074,
        322,
        264,
        15642,
        4122,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.03839067979292436,
      "compression_ratio": 1.6081081081081081,
      "no_speech_prob": 0.00018521941092330962
    },
    {
      "id": 36,
      "seek": 33000,
      "start": 330.0,
      "end": 336.0,
      "text": " This would align the head geometry with the scan in order to transfer the textures.",
      "tokens": [
        50364,
        639,
        576,
        7975,
        264,
        1378,
        18426,
        365,
        264,
        11049,
        294,
        1668,
        281,
        5003,
        264,
        24501,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.03647646623499253,
      "compression_ratio": 1.8284313725490196,
      "no_speech_prob": 0.23920828104019165
    },
    {
      "id": 37,
      "seek": 33000,
      "start": 336.0,
      "end": 345.0,
      "text": " Step two would be to export the conformed mesh from the metahuman identity asset and refit any details that were lost from the solve.",
      "tokens": [
        50664,
        5470,
        732,
        576,
        312,
        281,
        10725,
        264,
        18975,
        292,
        17407,
        490,
        264,
        1131,
        545,
        6829,
        6575,
        11999,
        293,
        1895,
        270,
        604,
        4365,
        300,
        645,
        2731,
        490,
        264,
        5039,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.03647646623499253,
      "compression_ratio": 1.8284313725490196,
      "no_speech_prob": 0.23920828104019165
    },
    {
      "id": 38,
      "seek": 33000,
      "start": 345.0,
      "end": 355.0,
      "text": " Step three would be to use the mesh to metahuman workflow with the template mesh option in order to get the geometry and joints closer to the target delta.",
      "tokens": [
        51114,
        5470,
        1045,
        576,
        312,
        281,
        764,
        264,
        17407,
        281,
        1131,
        545,
        6829,
        20993,
        365,
        264,
        12379,
        17407,
        3614,
        294,
        1668,
        281,
        483,
        264,
        18426,
        293,
        19949,
        4966,
        281,
        264,
        3779,
        8289,
        13,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.03647646623499253,
      "compression_ratio": 1.8284313725490196,
      "no_speech_prob": 0.23920828104019165
    },
    {
      "id": 39,
      "seek": 35500,
      "start": 355.0,
      "end": 365.0,
      "text": " And step four would be to use this new metahuman identity to refit any lost details and then fit the additional head geometry assets.",
      "tokens": [
        50364,
        400,
        1823,
        1451,
        576,
        312,
        281,
        764,
        341,
        777,
        1131,
        545,
        6829,
        6575,
        281,
        1895,
        270,
        604,
        2731,
        4365,
        293,
        550,
        3318,
        264,
        4497,
        1378,
        18426,
        9769,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.04997639020284017,
      "compression_ratio": 1.5897435897435896,
      "no_speech_prob": 0.082667276263237
    },
    {
      "id": 40,
      "seek": 35500,
      "start": 365.0,
      "end": 378.0,
      "text": " Step five would be to update the changes to the vertex and joint positions and save those changes to the DNA and then export the head LODs as FBX bundled with the new DNA file.",
      "tokens": [
        50864,
        5470,
        1732,
        576,
        312,
        281,
        5623,
        264,
        2962,
        281,
        264,
        28162,
        293,
        7225,
        8432,
        293,
        3155,
        729,
        2962,
        281,
        264,
        8272,
        293,
        550,
        10725,
        264,
        1378,
        441,
        14632,
        82,
        382,
        479,
        33,
        55,
        13882,
        1493,
        365,
        264,
        777,
        8272,
        3991,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.04997639020284017,
      "compression_ratio": 1.5897435897435896,
      "no_speech_prob": 0.082667276263237
    },
    {
      "id": 41,
      "seek": 37800,
      "start": 378.0,
      "end": 386.0,
      "text": " Step six would be to finalize the rig by bringing the modified assets into Unreal Engine and then configure them.",
      "tokens": [
        50364,
        5470,
        2309,
        576,
        312,
        281,
        2572,
        1125,
        264,
        8329,
        538,
        5062,
        264,
        15873,
        9769,
        666,
        34464,
        7659,
        293,
        550,
        22162,
        552,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05208449494348814,
      "compression_ratio": 1.519650655021834,
      "no_speech_prob": 0.03307545930147171
    },
    {
      "id": 42,
      "seek": 37800,
      "start": 386.0,
      "end": 391.0,
      "text": " The process of transferring textures is not included in this workflow chart.",
      "tokens": [
        50764,
        440,
        1399,
        295,
        31437,
        24501,
        307,
        406,
        5556,
        294,
        341,
        20993,
        6927,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05208449494348814,
      "compression_ratio": 1.519650655021834,
      "no_speech_prob": 0.03307545930147171
    },
    {
      "id": 43,
      "seek": 37800,
      "start": 391.0,
      "end": 394.0,
      "text": " As mentioned, these charts are not a hard roadmap.",
      "tokens": [
        51014,
        1018,
        2835,
        11,
        613,
        17767,
        366,
        406,
        257,
        1152,
        35738,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05208449494348814,
      "compression_ratio": 1.519650655021834,
      "no_speech_prob": 0.03307545930147171
    },
    {
      "id": 44,
      "seek": 37800,
      "start": 394.0,
      "end": 401.0,
      "text": " They simply demonstrate different approaches for fitting and that by adding DNA calibration to a workflow,",
      "tokens": [
        51164,
        814,
        2935,
        11698,
        819,
        11587,
        337,
        15669,
        293,
        300,
        538,
        5127,
        8272,
        38732,
        281,
        257,
        20993,
        11,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05208449494348814,
      "compression_ratio": 1.519650655021834,
      "no_speech_prob": 0.03307545930147171
    },
    {
      "id": 45,
      "seek": 40100,
      "start": 401.0,
      "end": 408.0,
      "text": " This ensures that the metahuman DNA file will take into account changes that have been made to the neutral pose.",
      "tokens": [
        50364,
        639,
        28111,
        300,
        264,
        1131,
        545,
        6829,
        8272,
        3991,
        486,
        747,
        666,
        2696,
        2962,
        300,
        362,
        668,
        1027,
        281,
        264,
        10598,
        10774,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05469696145308645,
      "compression_ratio": 1.625615763546798,
      "no_speech_prob": 0.02756723202764988
    },
    {
      "id": 46,
      "seek": 40100,
      "start": 408.0,
      "end": 415.0,
      "text": " And once those changes have been brought back into Unreal Engine, the metahuman face will behave correctly.",
      "tokens": [
        50714,
        400,
        1564,
        729,
        2962,
        362,
        668,
        3038,
        646,
        666,
        34464,
        7659,
        11,
        264,
        1131,
        545,
        6829,
        1851,
        486,
        15158,
        8944,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05469696145308645,
      "compression_ratio": 1.625615763546798,
      "no_speech_prob": 0.02756723202764988
    },
    {
      "id": 47,
      "seek": 40100,
      "start": 415.0,
      "end": 423.0,
      "text": " In the next section, we will delve into approaches for fitting metahuman topology to a scan or sculpted mesh.",
      "tokens": [
        51064,
        682,
        264,
        958,
        3541,
        11,
        321,
        486,
        43098,
        666,
        11587,
        337,
        15669,
        1131,
        545,
        6829,
        1192,
        1793,
        281,
        257,
        11049,
        420,
        12613,
        292,
        17407,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.05469696145308645,
      "compression_ratio": 1.625615763546798,
      "no_speech_prob": 0.02756723202764988
    }
  ],
  "language": "en"
}