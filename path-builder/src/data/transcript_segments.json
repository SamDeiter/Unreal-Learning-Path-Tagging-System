{"100.01":{"01_Intro":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"Greetings everybody, my name is Sam Dider and I'm a senior Unreal Engine instructor with Epic Games. In the following video tutorial series, I'm going to introduce you to the various tools and feature Unreal Engine 5 provides and give you a brief explanation of what they do so you can make a better choice on whether or not you want to utilize these tools and features and whatever project you happen to be creating. Now there is a lot to cover so we are first going to start by taking a look at the Unreal Engine 5 documentation."},{"start":"0:35","end":"1:19","startSec":35.0,"text":"This is a great place to start learning more about all of the tools and features Unreal Engine 5 supports as well as get more detailed explanations should you be having trouble with a particular tool or feature or you want to learn more about how a particular tool or feature works. Next we are going to take a look at the Epic Games Launcher. This tool is used to not only download and manage various versions of the Unreal Engine 5 editor it can also be utilized to help you manage any projects that you happen to create or download as well as content that you might have purchased or downloaded from the FAB marketplace."},{"start":"1:19","end":"1:59","startSec":79.0,"text":"Then we are going to take a look at the Unreal Engine project structure as understanding how projects are structured is key to ensuring smooth delivery of your project to either teammates or when you happen to cook your project for consoles, PC or mobile devices. Then we are going to take a look at the content pipeline so that you can understand how easy it is to get content from various digital content creation programs into Unreal Engine 5 to use inside of your projects."},{"start":"1:59","end":"2:43","startSec":119.0,"text":"We are then going to take a look at the editor UI so we can familiarize ourselves with the various areas and interactions that we will need to build upon in order to be most successful when we use the engine. Then we are going to take a look at actors as all of our Unreal Engine 5 projects are going to utilize actors in some way, shape or form. Finally, we are going to finish up by taking a look at some of the most common tools and features Unreal Engine 5 provides and go over any interesting information you might need to be aware of in order to get the best utilization from these tools."},{"start":"2:43","end":"2:52","startSec":163.0,"text":"We have a lot to cover so let's go ahead and get started with the Unreal Engine 5 documentation."}],"02_Documentation":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Unreal Engine 5 is a massive toolset and knowing where the documentation lies can be helpful when looking for more information on how to use a particular feature or toolset. The Unreal Engine 5 documentation pages are quite robust and they also cover various versions of the engine, not just the latest and greatest, but previous versions as well. If we were to pop over to our documentation, and here it is right here in a web page, we"},{"start":"0:31","end":"1:04","startSec":31.3,"text":"can see here these are the various versions. We go from 5.5 all the way down to 4.27. We have the ability to also look at forums, there's documentation, there is learning samples and there are snippets. Snippets are kind of cool. There are code repositories kind of showing us how to do certain things inside of Unreal Engine 5. Learning is going to show us our various learning. If we ever want to learn about something specifically, we can search for tutorials through here. Our documentation is going to be our documentation and this is going to be split up into various"},{"start":"1:04","end":"1:36","startSec":64.2,"text":"higher level areas such as programming and scripting. Then when we click on these, we're going to be able to go down and get into some more details about each one of these. Then the Unreal forums right here, this is going to offer us interactivity between developers and people on the web as well as just getting help from your fellow Unreal Engine 5 developers. Again, the Unreal Engine documentation isn't just the documentation but is a collection of various resources that you can use to find out more about the engine."},{"start":"1:36","end":"1:48","startSec":96.6,"text":"I highly recommend that everybody go out there and check this resource out as it is going to help you figure something out no matter what type of project you're building inside of Unreal Engine 5."}],"03_Launcher":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"The Epic Games Launcher is a powerful piece of software that's used for managing and downloading various versions of Unreal Engine as well as content that you've associated with those versions of the Engine. When you open up the Launcher, you're going to be greeted with something that looks like this. And no matter what you're using Unreal Engine for, you'll need to utilize the Launcher in some way. Let's take a look at the Launcher now. So across the top we have our News, Sample, Fab, Library, Twinmotion, and Reality Capture."},{"start":"0:33","end":"1:07","startSec":33.3,"text":"News is where we're going to get the latest and greatest news about Unreal Engine, such as new releases and anything that's happening in the community you might want to check out. Samples are going to take us to any of the Unreal Engine sample content that you can download and take apart to see how it was created so you can learn more about how Unreal Engine works and help you with whatever project you happen to be building. Fab takes us to the Start Exploring, which will bring us to the web version of Fab."},{"start":"1:07","end":"1:38","startSec":67.6,"text":"Our library allows us to at the top browse different versions as well as add versions of Unreal that we might currently need to use or currently have installed. For that we'll find my projects which show all the projects we have installed or created for this particular computer. And then underneath that we're going to have our Fab library, which shows us all of the things we've collected from Fab that we can add or install for our particular engine or to our project."},{"start":"1:38","end":"2:10","startSec":98.3,"text":"Now Twinmotion is, I like to refer to it as PowerPoint for 3D, and you can install that by coming over to the Twinmotion category. This is a great way for real-time visualization. It's very, very simple to use. And next to that we have Reality Capture. Reality Capture is the desktop photogrammetry solution that Epic Games provides if you need to process photogrammetry locally. Now no matter what you're using Unreal Engine for, you're going to need to utilize the Epic"},{"start":"2:10","end":"2:27","startSec":130.6,"text":"Games launcher in some way, shape, or form. So just keep that in mind. And I encourage you to explore especially the samples and the Fab section because there's some really awesome and great stuff out there. And the Epic Games launcher provides you a great way to access that content."}],"04_ProjectStructure":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Understanding how Unreal Engine 5 projects are structured is very important as Unreal Engine 5 projects are set up in a slightly different way than you might be used to in traditional applications. This is because in a traditional application, you generally use a single project file to visualize your scene. So when we're inside a Photoshop and we save, we're going to save it to a .psd. Or inside of Word when we save, we're going to save to the .doc or the same for Maya if"},{"start":"0:30","end":"1:02","startSec":30.0,"text":"we save, we're going to save to the .mb format. Now Unreal has a slightly different approach to this. When you're inside of Unreal Engine 5 and you want to import something such as a model, a texture, audio, or animations, all of that is going to be stored in the content folder and use a .usset file format. There are two other file formats that we should be aware of. The first one is the level file format. This is called the .umap file format."},{"start":"1:02","end":"1:33","startSec":62.6,"text":"And this is for any levels that we happen to be saving. And levels is a term for what we place actors or our content and we light and it's what the end user ends up seeing in your project. Now if we are creating, say, a material or editing an asset inside of Unreal, whatever we're doing inside of there is going to be saved again in the .usset file format."},{"start":"1:33","end":"2:05","startSec":93.6,"text":"Again, if we are importing something such as a static mesh or maybe a texture, whatever we export will be done is, say, a .fbx or a .png. And when we bring that into Unreal, that's going to be imported and then saved as this .usset file format. Now here is an example of an Unreal Engine project folder. And you'll notice quite a few different folders in here, but don't worry."},{"start":"2:05","end":"2:37","startSec":125.8,"text":"A lot of these folders are actually auto-generated and can be deleted in case you need to either share your project with someone else or you run into an issue and you kind of want to start fresh. We can actually do that. So let's go ahead and take a look at what these folders are now. So right down here we have our .uproject. This is going to associate Unreal Engine to run. When we click on this, it's going to say, hey, I want you to load Unreal Engine, but I want you to load the Engine and all of the content that is created inside of this folder right"},{"start":"2:37","end":"3:09","startSec":157.5,"text":"here. Now above that we have the Valley of the Ancients.png. This is our thumbnail that represents what we'll see inside of the Unreal Engine launcher that's associated with our project. Then we have Source. So this is going to contain any of our C++ code that we might run custom for this particular project. And this is a file that you need to keep, so never delete your source. Now saved contains saved information and this can be a whole bunch of different things."},{"start":"3:09","end":"3:41","startSec":189.8,"text":"One of the things that you'll find in here are, say, screenshots. You'll also find crash dumps. You'll find build data. One of the things you can do with saved is you can actually delete this folder should you ever need to just maybe free up some space or something like that. This is a saved folder to delete. It will automatically be recreated once your project has been relaunched. Now your plugins folder contains any plugins that you might have either purchased or created specifically for this particular project or maybe there are plugins that you have set"},{"start":"3:41","end":"4:15","startSec":221.4,"text":"up so that you can share content in between your projects. The plugins folder is not safe to delete as doing so could actually reduce functionality that your project needs. So you need to keep that folder at all times. Your intermediates folder is where things like shader compilation data builds, partially completed compilations and other things like that are stored. It's a bunch of just miscellaneous data in here. This folder can be safely deleted should you be running into any issues as it will automatically"},{"start":"4:15","end":"4:51","startSec":255.0,"text":"be recreated once the engine has been relaunched. Your derived data cache is a folder that contains pre-compiled versions of your shaders and this allows the engine to run much, much quicker. I shouldn't say run. I apologize. It allows it to load much, much quicker. You can delete your derived data cache but I suggest that you don't as this will greatly affect your loading times. Next is our content. So the content is where all of our content are .usets and our .umaps files live."},{"start":"4:51","end":"5:23","startSec":291.0,"text":"We always need to keep the content folder that's not safe to delete that folder or you'll be deleting all of the content for your project. Next we have our config. The config is where we store all of our config information and this will control how the editor starts or what settings are used when the game is loaded. You should not be deleting the config folder as you need that information for when the editor starts or when your game launches. Next we have our build. This is where we are going to temporarily store builds that we have done for our project"},{"start":"5:23","end":"5:55","startSec":323.2,"text":"that is safe to delete your builds folder. This folder can actually grow quite large so if your project is all of a sudden taking up too much space you might want to delete this folder. It will be recreated when Unreal Engine restarts. And then last but not least we have our binaries. This is going to be created should you have any binaries that you want to have for your project. If you don't see this folder that's okay. I believe it was created after the fact but you can delete this folder without any issues."},{"start":"5:55","end":"6:25","startSec":355.1,"text":"Now if we dive into one of these folders we're going to look at something like this. Here we are looking at the attenuation and this is basically notice that there are all UAsset files here. We're just looking at one folder here. While I am visualizing this inside of Windows Explorer one thing I want to note is that you should never mess with files outside of Unreal. Let's say we did want to take all of these attenuation files and maybe make a new folder"},{"start":"6:25","end":"7:01","startSec":385.5,"text":"and split half of them or some other organizational thing that we want to do. We should never ever ever do that outside of Unreal Engine 5. We should always do that inside of the editor using the editor renaming and moving functionalities that are provided in there. Now with all of these great files and everything there can be some bottlenecks. Traditionally in older versions of Unreal whenever you wanted to make a change to anything"},{"start":"7:01","end":"7:34","startSec":421.7,"text":"you would need to make that change inside of our UMAP. Now the problem with this is that the UMAP folder was or should say the UMAP file is unique and only one person can have it checked out at one time. This means that whenever I want to make a change to it I either have to wait for somebody else to finish making their changes or come up with a complex way to work on my stuff and then somehow merge it with theirs later on."},{"start":"7:34","end":"8:06","startSec":454.4,"text":"This can create a lot of conflicts especially as teams start to grow in size. With Unreal Engine 5 we've introduced a new file system called one file per actor which reduces overlaps between users and does this by saving data for instance the vectors in external files and this actually removes the need to save everything to the UMAP file. So instead of everything being saved to the UMAP file it's now linked to the UMAP file"},{"start":"8:06","end":"8:42","startSec":486.8,"text":"and this will allow multiple people to be working in the same world all adding and adjusting things without worrying about whether or not somebody has something checked in or checked out. Now just a couple of things to note about one file per actor. It is recommended that you do use Unreal Engine 5 source control when you enable this because it is going to involve a lot more files than you might be used to because remember we're going to be making a file for pretty much everything that you see that's placed inside"},{"start":"8:42","end":"9:18","startSec":522.0,"text":"of the level. With that said you should also be utilizing the built in editor check in and check out tools to help check your data in, check your data out and last but not least remember that using one file per actor is meant to work in tandem with world partition so using it outside of this system might result in some unintended uses or unforeseen edge cases so"},{"start":"9:18","end":"9:20","startSec":558.2,"text":"just be on the lookout for that."}],"05_ContentPipeline":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Understanding a few things about how Unreal deals with content is important as this will ensure that whatever content you're bringing into the engine will function in the way that you want without any unforeseen performance issues. And the first thing we're going to talk about in the content pipeline is the unit of measurement Unreal uses when dealing with static or skeletal meshes. Unit 5 uses centimeters for its unit of measurement. So this means that one Unreal unit equals one centimeter."},{"start":"0:33","end":"1:04","startSec":33.9,"text":"It's best to make sure that your digital content creation tools such as 3max, Maya, Blender, or whatever tools you happen to use have their system or scene scale set to centimeters. This way you can avoid any and all scaling issues from your pipeline. The next thing in our content pipeline I'd like to talk about deals with textures. Now textures for the best performance should always be a power of 2 in either the X or"},{"start":"1:04","end":"1:34","startSec":64.4,"text":"the Y axis. This means that they can range from 2 by 16 to 128 by 256 all the way up to 4096 by 8192. Textures do not have to be square so 64 by 64, 128 by 128 is good but you can also have 128 by 256 or 1024 by 2048. Textures just need to maintain this power of 2 ratio in the X or the Y axis."},{"start":"1:34","end":"2:08","startSec":94.6,"text":"Unreal Engine also supports on import a number of uncompressed and compressed formats. So for uncompressed on imports you can bring in BMP, TARGA, and PSD or you can bring in PNG, JPG, DDS, and HDR depending again on what format meets the needs of your project. When importing content into Unreal there's a couple of different ways we can do this. You can either drag and drop right from the OS folder or your desktop right into the content browser or you can click the add button in the content browser and then from there you"},{"start":"2:08","end":"2:31","startSec":128.1,"text":"have a number of options under get content. You can also click on the fab icon which will launch the fab browser inside of the editor allowing you to search for and purchase content for your project. You can even download content right from within the fab browser inside of the editor for anything that you have in your library."}],"06_EditorUIOverview":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In this section of our tutorial I'd like to talk about the editor UI and go over how we navigate through the editor as well as how we play and what some of the various menus do. Now the editor itself is going to be broken down in kind of the six major areas. So one we have our file menu bar. This is going to be the same throughout a lot of editors that you see inside of Unreal Engine 5. Two, we have our main toolbar."},{"start":"0:32","end":"1:03","startSec":32.8,"text":"This goes across the top here. Three is our editor viewport. So we're going to be spending a lot of our time. Four is the tabbed drawer system. Five is our content browser. And then six here, this is going to be our output log and some things for notifications for save. So take a look at each one of these areas in more depth in the editor because it's kind of important to understand what each one does."},{"start":"1:03","end":"1:35","startSec":63.8,"text":"So again, across the top here we have our file, edit, window tools, build selected, actors and help. So file is going to allow us to access anything that's related to opening or saving a level as well as opening up our projects or even zipping up our projects right here should be want to share them. It is going to do anything that we have revolving or I should say involving, undo as well as our editor preferences and our project settings and plugins."},{"start":"1:35","end":"2:09","startSec":95.0,"text":"So these are important settings right down here. If we ever want to edit any preferences for our editor or a project or disable or enable any plugins, we can access those options right here. Window allows us to access the various level editor windows and other tools that we might want to work with. The cool thing about this is we can open up multiple content browsers or detail panels. We can also activate things like our layers or our levels or our light mixer should we want to do that. One of the other super useful features of the windows tab is this load layout."},{"start":"2:09","end":"2:39","startSec":129.7,"text":"You can use this in case you accidentally loaded something inside of Unreal and you weren't sure you want to kind of go back. This is a great way to just quickly get your UI back to its default state. Now tools allows us to view various tools that we can use to help us do everything from say merge actors to audit our assets and even set up our device managers and our profiles. We can also run Python scripts and convert levels to world partition through this menu."},{"start":"2:39","end":"3:12","startSec":160.0,"text":"Build allows us to build either everything by clicking on the build all levels up here at the top or it allows us to just build these individual things here. We're going to build things like our reflection or pre-computed static visibility. If we're using HLODs we can build those from this particular menu, landscape and texture streaming all types of other things can all be done from the build level right here. Select has to deal with selection. If I have something selected here and I come to select you can see here I can get a few"},{"start":"3:12","end":"3:42","startSec":192.3,"text":"options so I can select all. I'm going to hold down L and click really quick and I'm going to click select again and you can see here I get some slightly different settings so I can select all relevant lights or select all lights or select all stationary lights that exceed overlap. There's a lot of interesting things I can do here with select. Now actor is going to be context sensitive. That means that if I don't have anything selected actor is not going to show any information and with that actor selected it's going to allow me to do a bunch of different things"},{"start":"3:42","end":"4:17","startSec":222.6,"text":"with this particular actor that I have selected such as I can convert this, I could replace it with another asset. There's a ton of things that I can do here including grouping and changing it to pivot or attaching it and then last but not least we have help. Help is where we're going to view all of the various help so from our viewport controls and level documentation to API references to credits and even our bout or visit you can find everything that you need for help here in our help menu."},{"start":"4:17","end":"4:51","startSec":257.1,"text":"Alright so two is going to be our main toolbar so that's going to cover this area that is right here so this is going to be our save current level to disk. Now this doesn't save everything this just saves the current level this browses to the current level that's on disk. Selection mode changes the editor's tool set to respect the different thing that you have selected here and we'll cover these tools later on in this in more detail but note for now that selection mode is how we can access some further tools inside of Unreal Engine"},{"start":"4:51","end":"5:25","startSec":291.7,"text":"5. Next to that we have quickly add to the project what this does is this allows us to quickly add things such as lights or shapes or cinematic things to our project that we might need to work with. Next to that we have our blueprint this allows us to either add blueprints or open and edit our level blueprint we can also modify our game blueprint and our game mode override here should be need to from this menu. Next to that we have our cinematics cinematics I should say it's called by another name which"},{"start":"5:25","end":"5:57","startSec":325.7,"text":"is sequencer so if I open this up you can see here I can add a level sequence or add a level sequence for the shots should I need to use that. Next to this we have our PIE or play in editor control so if I just click play right now it's going to plop me right there but if I click these little ellipses right here you can see I have a bunch of different options. Now the great thing about this is that not only can I simulate or play this game either in a new viewport or in a standalone game I can also simulate multiplayer by adding"},{"start":"5:57","end":"6:31","startSec":357.3,"text":"the number of players down here and adjusting the settings I want for multiplayer. Next to that we have platforms what this does is this allows us to quickly launch our project on the various platforms that is selected so for example if we're coming down here to Android we would pick package project and then we'd be able to run that from our Android devices if we had an Android device plugged in and ready we'd see it right up here at the top and we could just select it as well to quickly launch on it. Now the last setting up here is settings and what this settings does is there are some"},{"start":"6:31","end":"7:02","startSec":391.6,"text":"settings here for things like translucent selection but the main usage of this is going to be for your scalability for our material quality levels and our preview platform overrides. These allow us to adjust the visual settings of Unreal Engine 5's editor window right here so that we can get a better idea of what the project is going to look like on say reduced settings or limited hardware. Alright so three is our viewport. This is where you're going to spend 99% of your time inside of Unreal Engine 5."},{"start":"7:02","end":"7:34","startSec":422.0,"text":"This is because the viewport is where we add objects but we also manipulate them, move them around, duplicate them and things of that nature in order to bring us the creations that you are building with Unreal Engine 5 and you can see here I'm just kind of navigating around the viewport. There are a few options across the top here at the viewport. On the left hand side we have some options for our viewport then we have the ability to change our camera. We have the ability to look at various lighting modes and then we have show which will show"},{"start":"7:34","end":"8:04","startSec":454.8,"text":"us various flags and options such as rendering sprites like this player start or this point light. Going a little bit further down here we have our select, move, rotate and scale as well as controls to control the snapping and this last little button right here this controls our maximize and minimizes the viewport here. Now next to that we have our outliner and our details panel."},{"start":"8:04","end":"8:35","startSec":484.8,"text":"These are Unreal's tab drawer system and the reason I want to bring that up is these can be just brought up and kind of docked together like that so you're not stuck with this particular menu but these two outliners and details panels are very important to understand what they do. So the outliner will outline all of the objects or actors that we have placed inside of our scene so it's going to show us this and this and this and whatever I have currently selected the outliner is going to show us that we can also select things inside of the outliner."},{"start":"8:35","end":"9:11","startSec":515.4,"text":"Now the details panel that is going to show us the details or the properties of the actor that we have selected so you can see here when I select a player start I can come down here and I have a transformation and object and a rendering but when I select a light you'll notice I have a transformation but I have a light now instead of the other properties that I had when I had the player start so there we go. So you can see here the outliner again allows us to look at objects or actors that have been placed inside of our scene and then the details panel allows us to get more information"},{"start":"9:11","end":"9:46","startSec":551.8,"text":"or edit its properties. So next we have the content drawer so this is really simply just allows us to access the content browser you can also access this by hitting control space on the keyboard and if you like you can press this dock in layout to have that dock right there in the layout for you so that it is constantly up so you can search with it. Finally we have our output log our command section and what this does is this just allows us to look at our log should we need to use this for any debug information our CMD here"},{"start":"9:46","end":"10:18","startSec":586.1,"text":"this allows us to input either commands or Python commands that we need to activate inside of the editor. Trace allows us to run memory traces and this is used for advanced debugging on your projects you need to figure out why your project is performing poorly. Our derived data cache is used when we are working on a team of multiple people and we want to have our data load a little more quickly we can use this to help in our data loading. We then have our map status which is showing us currently this map is unsaved and then"},{"start":"10:18","end":"10:47","startSec":618.9,"text":"we have our version control or revision control that shows us if we are working with some form of version control what we are connected to and what changes are currently being applied or what changes we currently need to make. That represents the Unreal Engine kind of editor UI. Now as I was going in the editor I was moving around and to do that there are actually two"},{"start":"10:50","end":"11:26","startSec":650.5,"text":"different ways we can go about this. We can use the WAS and D keys and the left or right mouse button so we can use the WAS and D to move us around or we can use the right mouse button to and this would be commonly referred to as first person controls so it is pretty standard across multiple first person shooter games where we use WAS and D to move our carat forward backwards left and right. There is another way that we can move throughout the editor we can hold down the right mouse"},{"start":"11:27","end":"12:01","startSec":687.3,"text":"button to drag around the scene from a static POV or we can hold down the middle mouse button to track up down left and right. Let's just take a look at that again so again we hold down the left mouse button and we can go like this hold down the right mouse button and we can move we hold them both together and we can move left and right and we hold down the middle mouse button we can also move up and down. One of the things that I like to do is just kind of mess with the WAS and D until I get"},{"start":"12:01","end":"12:31","startSec":721.3,"text":"to something and then I use the individual mouse buttons to help kind of focus in what it is that I happen to try to be looking at. We can also use Q and E to raise the camera up and down. Z and C will temporarily allow us to increase or decrease our field of view so we can kind of get a zoom in effect there or see our project in extreme distortion. If you hold down ALT with something selected you will get an orbit style and you can also"},{"start":"12:31","end":"13:04","startSec":751.3,"text":"use the middle mouse button to move your camera around similar to how you would do the camera inside of something like 3D Studio Max or Maya. Finally if you press the F key this will focus you into something so let's say that maybe you got super zoomed out or something like that you can just simply grab something and hit the F key to focus right in on it. Now when we are editing objects we have the ability to move, rotate and scale them and"},{"start":"13:04","end":"13:35","startSec":784.3,"text":"each one of those functionalities is going to be notified by a specific gizmo. The move gizmo looks like this, our rotation gizmo shows us different axes that we can rotate and our scale looks similar to our move but instead of showing arrows it has these little handles we can pull to scale in our relative directions. Each one of our select transform, rotate and scale has some options as well as the ability to snap to a grid."},{"start":"13:35","end":"14:08","startSec":815.3,"text":"The reason we want to snap to a grid is this helps us move things in certain increments so we can move this every 10 units or we can rotate this every 10 degrees or we can snap this every .25 in scale and this really helps when we are trying to maybe move something or scale something in a very precise increments. Let's pop over to the editor and look at that now. So first off I'm just going to grab this ball right here and I'm going to hit F to focus"},{"start":"14:08","end":"14:39","startSec":848.3,"text":"in on it and then I'm just going to hit the space bar to cycle through my various widgets and then once I have a widget I want I can again just grab on that axis to do the rotation or the move or I should say the rotation and the scale. There we go, set it backwards. Then I want. Now if I don't want any of that I can come here and actually do this and you'll see here that I have a lot more finer control over how I am doing this scaling operation or if"},{"start":"14:39","end":"15:11","startSec":879.3,"text":"I was to come here to my, let's just turn it off for everything. You can see here now I can move this over ever so slightly as with the grid on I have a little bit of a snapping on there and the same thing with our rotation. I can rotate this ever so slightly. You can even see that reflected in the degree operation there that you're seeing at the top of my gizmo it's showing me that I'm going at 14.8, 16 and if I turn this back on we will see that going at every 10 degree increments."},{"start":"15:11","end":"15:42","startSec":911.3,"text":"Now the last thing that I do want to talk about is a little bit more on PIE because there are some other things that we can do with this. So again PIE stands for play in editor and it can be used to play literally right from the area you are navigating. You can also use alt PIE on your keyboard to set this as a shortcut and we use this for a lot of things."},{"start":"15:42","end":"16:17","startSec":942.3,"text":"Let me just pop over to the editor really quick. So first and foremost right click play from here. This is going to be something to use a lot of times and this is really great because it basically launches you from the area that you clicked on. So it's going to right click, it's going to select that pixel over there and basically put me as close to that pixel as I can. The reason this is so good is if I was to hit play, play is always going to start me from over here. So let's say that I am trying to look at something over here that I'm investigating or something like that. When I hit play I'm going to go all the way over here in order to get there."},{"start":"16:17","end":"16:59","startSec":977.3,"text":"So that's why this right click play from here is so powerful because it allows me to play right from an area that I need to get to to get information. One of the other things that you can do is we drop down this arrow, there's going to be this simulate. So what simulate does is it runs the game but it doesn't add the player. So this is really good if we are trying to debug something and we want the game to run but we don't necessarily need the game to give us a player. So we can use simulate to simulate things like the physics thread and once we've done that we can then stop and then do that one more time to run without having to actually get out of the player or navigate to another location."},{"start":"16:59","end":"17:30","startSec":1019.3,"text":"Simulate makes it really really easy to do this right inside of the editor viewport. So again, Alt S is to simulate and we'll hit escape to stop that and then Alt P is to play the actual game. And these are going to really help you out especially once you have been play testing or you need to test something throughout further interaction you're going to find that this is a really great way to do that."}],"07_Actors":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Actors are a vital part of any Unreal Engine 5 project, and that's because actors can be anything that's placed into a level. Here we have a collection of just random actors pulled from the editor, starting with a trigger volume. We have directional light, there's a static mesh, there's a skeletal mesh, a player start, particle effect, even blueprints and other level interactive icons are all actors. At its base, we can think of as an actor as something that contains a translation,"},{"start":"0:34","end":"1:05","startSec":34.8,"text":"a rotation and a 3D scale. So it's something that we can place inside of the scene and we can move it around, we can scale it and we can rotate it. Now it doesn't necessarily have to have a visual representation, but it can't. Actors can also be spawned and destroyed through gameplay code, whether that be C++ or blueprints. Let's pop over to the editor now and take a look at some actors. Well inside of the content examples here, this is an actor, this BP demo display, and"},{"start":"1:05","end":"1:37","startSec":65.7,"text":"if I click on the details panel, notice there are some things that I can change with that. And it's going to be true for many of the actors that you place. So if I come up here to quickly add, and I come here to add maybe like a point light, you can see here with my point light selected in the details panel, I'm going to have many different properties that I can select. And again, as I go through here, I can select many different types of actors and they're going to have many different types of properties. And this is why it's so critical to understand what actors are. And it's not complicated."},{"start":"1:37","end":"1:45","startSec":97.7,"text":"Remember actors are just simply the term for objects that can be placed or spawned into any level that you're working with in Unreal Engine 5."}],"07_Actors_55":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Actors are a vital part of any Unreal Engine 5 project, and that's because actors can be anything that's placed into a level. Here we have a collection of just random actors pulled from the editor, starting with a trigger volume. We have directional light, there's a static mesh, there's a skeletal mesh, a player start, particle effect, even blueprints and other level interactive icons are all actors. At its base, we can think of as an actor as something that contains a translation,"},{"start":"0:34","end":"1:05","startSec":34.8,"text":"a rotation and a 3D scale. So it's something that we can place inside of the scene and we can move it around, we can scale it and we can rotate it. Now it doesn't necessarily have to have a visual representation, but it can't. Actors can also be spawned and destroyed through gameplay code, whether that be C++ or blueprints. Let's pop over to the editor now and take a look at some actors. Well inside of the content examples here, this is an actor, this BP demo display, and"},{"start":"1:05","end":"1:37","startSec":65.7,"text":"if I click on the details panel, notice there are some things that I can change with that. And it's going to be true for many of the actors that you place. So if I come up here to quickly add, and I come here to add maybe like a point light, you can see here with my point light selected in the details panel, I'm going to have many different properties that I can select. And again, as I go through here, I can select many different types of actors and they're going to have many different types of properties. And this is why it's so critical to understand what actors are. And it's not complicated."},{"start":"1:37","end":"1:45","startSec":97.7,"text":"Remember actors are just simply the term for objects that can be placed or spawned into any level that you're working with in Unreal Engine 5."}],"08_Tools&Features":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"The Unreal Engine 5 level editor is a very powerful tool and a tool to spend quite a bit of time in as this is how we build the interactions or projects we wish inside of Unreal Engine 5. Let's go ahead and pop into the editor real quick and have a look at it in more detail. We can navigate through this using the WAS and D keys or the left and right mouse buttons depending on our preference. The editor viewport is in real time and if we want to adjust something in the editor we can simply click on it."},{"start":"0:35","end":"1:10","startSec":35.0,"text":"Once we do that whatever we click on properties will be displayed inside of the details panel over here allowing us to adjust whatever we wish to adjust. Remember this editor is happening in real time so what we see here is going to be the same if we come up to if we press play. The only time this could be different is if you're deploying to a mobile device or a console as there could be slight differences in the rendering. But the level editor does provide a very accurate representation of what you could expect the end rendering to be."}],"08_Tools&Features_55":[{"start":"0:00","end":"0:20","startSec":0.0,"text":"Now that we know a little bit more about the basic features of Unreal Engine, let's take a look at some of the tools and features that are provided with the Engine so you have a better idea of what features come default and how you might utilize those features within any project you happen to be creating."}],"09_ProjectBrowser":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"The Unreal Engine project browser can be used to help you create projects as well as browse recent projects that you have opened on your local computer. From this tool, we can create a number of projects based on Epic Provided Templates or select the Blank template. Let's go ahead and take a look at how we can use this tool and the editor. We can access this tool and the editor a number of different ways. First off, we can go up here to File and we have the new project and the open project."},{"start":"0:31","end":"1:06","startSec":31.8,"text":"The open project, what this is going to do is this is going to allow us to open any projects that we currently have on our computer. Come up here to File and New Projects. This is where we're going to get access to the project wizard, which allows us to select a number of different templates provided by Epic. One of the things to note here under the project defaults, if you're unaware, a project can be either based on Blueprint code, which is the default, or C++. If you do select C++, you will need to have Visual Studio or some other type of compiler"},{"start":"1:06","end":"1:42","startSec":66.2,"text":"installed so that you can compile the required files. Underneath that, we have our target platform. We can change this to desktop or mobile. You might want to change this if you know you are targeting a mobile or a lower end device or keep it at desktop if you know that you are targeting a desktop or a console. Quality preset allows us to set this to maximum. The defaults are scalable. Scalable would be set in tandem if you were to set this to mobile, so you want to start with as few options as possible and then through testing, enable options as you have performance"},{"start":"1:42","end":"2:10","startSec":102.1,"text":"to do that. Last but not least, we have the starter content. The starter content is a collection of content that can be used to help you quickly get up and started with prototyping inside of the engine. You do have the ability to also specify your project's location and the name of the project. Once you have everything set, you simply hit Create and your new project will be created and loaded right inside of the editor."}],"10_ContentBrowser":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"The Content Browser is an extremely powerful tool for managing all of the content that you'll find in any of your Unreal Engine 5 projects. Not only can you use the Content Browser to import content and manage content, you can also do advanced searches as well as get detailed information about your assets right from within the Content Browser itself. So let's go ahead and pop over to the Engine and take a look at this in more detail. Now to access the Content Browser there's two different ways."},{"start":"0:31","end":"1:03","startSec":31.4,"text":"We can come down here and go to the Content drawer which is going to open it up and if you don't want to keep doing that you can press this dock in layout which is actually going to dock this right here. The other way we can do this is by hitting Control Space and that is going to bring up this Content Browser and the active window that we have. For now I'm just going to click on this dock in layout so that we can look at this in a little more detail. So over here on the left hand side we have our add. This is where we're going to do things like import or add features or content packs or"},{"start":"1:03","end":"1:35","startSec":63.6,"text":"add things from Quixel or Fab. We can also create new folders and then you're going to see a bunch of different things here for creating basic assets. Now whenever we want to create something inside of Unreal like a Blueprint or a Material we do that by either coming here and looking for the appropriate one up here and then create basic assets or if we need something a little bit more advanced under the Create Advanced Assets you're going to see a lot of different options down here so what you see is not up here it's probably down here. The other way we can do this also is just by right clicking inside of the Content Browser"},{"start":"1:35","end":"2:07","startSec":95.3,"text":"will access the same menu. We then have a Favorites which allows us to favorite certain assets that we use quite a bit and then we have our folder structure that allows us to look at all of the folders that we have and we can also right click in here and do something like a new folder or should we want to do something like that. As we go a little bit further on we have our import which allows us to import save all. This is going to save everything that you have edited inside of the Content Browser"},{"start":"2:07","end":"2:41","startSec":127.8,"text":"but it does not save your level so if we want to save our level we click here this saves the level. This will save actually all the modified assets. We then have a little navigation here and this is a menu bar that lets us know where we're currently at in the folder structure. Then we have our settings so our settings are pretty cool because they allow us to do a couple of different things. First off under the View Type we can change this to things like Lists or Columns and the cool thing about this is let's just find some stuff here."},{"start":"2:41","end":"3:11","startSec":161.3,"text":"When we're at Columns you can see here what I get is a bunch of different information and this is really cool because this can help me make better decisions about what I am currently looking at in terms of maybe some optimization. Here we go if I click on the cloth one I can sort these by my vertices or triangles to get a better idea of what is going on with them. I'm going to click this back over to tiles and I'm also going to come over here now and I want to show you this show engine content. I'm going to click that on and what that's going to do is you're not going to see anything"},{"start":"3:11","end":"3:42","startSec":191.8,"text":"really different but we are going to get our engine folder here and you might need to enable this. Sometimes if you want to access stuff that's inside of a plugin or maybe you need to access some content inside of the engine to make something that is always loading or something like that. That's how you can actually see that by coming up here again and doing this show engine content. If not then you won't be able to see that. A couple of other things to note here. Thumbnail size, thumbnail edit mode and real time thumbnails. These are great if you are trying to."},{"start":"3:42","end":"4:13","startSec":222.2,"text":"Let me just click back here and go to this right here. If I go to my thumbnail edit mode I can drag this thumbnail around. I wasn't on the thumbnail. There we go. I can drag this around and move it and then when I'm done here I can just press done editing and that will save those changes. If I ever need to adjust this. Unreal does a really great job of giving you thumbnails automatically so you might not need to do that but in case you do that option is there."},{"start":"4:13","end":"4:52","startSec":253.2,"text":"There is also an extremely powerful search and filter. I'm just going to reset the filters really quick. If you want to search we have very powerful so I can do underscore N or let me just click on the content folder right here and we'll do something like dirt. There we go. There's the only dirt that I have right there. It looks like it's only in the content examples. One of the other cool things that we can do with the search and I'm just going to paste this into here is we can make these very complex operands to check for items of certain sizes"},{"start":"4:52","end":"5:28","startSec":292.7,"text":"or certain properties. In this example what I'm doing here is I'm looking for triangles less than or equal to 10,500. Files that are going to have more than 10,500 triangles that's what I'm looking for and this will spit them all out for me. The search is extraordinarily powerful. The other thing is the filter. If we click on this little arrow right here we get a list of filters. I generally run with my textures and my static meshes on probably my materials and maybe"},{"start":"5:28","end":"6:02","startSec":328.4,"text":"my material instances but our filters allow us to filter by whatever we have and then we can do something like let's look for underscore N, maybe check out all of the normal maps that we have. Again, very, very powerful features inside of the content browser and something that you're going to be utilizing quite a bit inside of your project especially as everything that you want to import is going to be imported into here and everything that you want to create in the editor is going to be created from the content browser menu and then utilized"},{"start":"6:02","end":"6:03","startSec":362.8,"text":"as you need."}],"11_FabContent":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"You can access all of your content in Fab from right within the editor by pressing either the Fab button that's located next to the Add button and the Content Browser, or by clicking the Add button and then from Get Content Clicking Fab. No matter which method you choose, it will open up the Fab browser, which will then allow you to browse, download, and purchase content for any of your projects. Let's go ahead and take a look at how that works now. So again, we can access this two different ways."},{"start":"0:31","end":"1:04","startSec":31.6,"text":"From our Content Browser, we can click on Add and Fab, or we can click on Fab right here. Once we do that, Fab will open up and I've already been logged in, so that's why you'll see some things populate here for me, but if you haven't logged in, you will need to log in before you can download items from your library. And let's just click on these rocks right here and we'll go Add to my project right there and we will see in our Megascans here, give it just a moment."},{"start":"1:04","end":"1:37","startSec":64.2,"text":"And there we go. There is our rock. Let me just move this over and here we go. So there we go. There is our asset right from Fab that we can use and then pull right into our project should we want to use that particular asset. So again, remember Fab can be accessed from two locations by clicking the Fab icon right here or by going to Add and clicking on Fab from right here. Once the Fab browser is open, you are then able to browse and purchase, download and"},{"start":"1:37","end":"1:40","startSec":97.0,"text":"add to your project any content that you may desire."}],"12_Lumen":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Unreal Engine 5 provides a very powerful yet flexible lighting solution called Lumen. Lumen is a fully dynamic global illumination and reflection system that is designed for next generation consoles and PCs. It renders diffuse inner reflections with infinite bounces and indirect specular reflections in large detailed environments at ranges from a few millimeters to a kilometer. And one of the greatest features of Lumen is that there's not a lot that you have to"},{"start":"0:33","end":"0:43","startSec":33.0,"text":"do to enable it or use it. You simply set up your scene, add and adjust your lights as normal and Lumen will work in the background for you."}],"13_VSM_55":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"The shadowing system in Unreal Engine 5 has been updated to include virtual shadow maps to help deliver consistent higher resolution shadows that work with film quality assets and even enlarge dynamically lit open worlds. Virtual shadow maps are also built to work seamlessly with Unreal Engine 5's nanite visual geometry, Lumen global illumination and reflections, as well as world partition features."},{"start":"0:33","end":"1:10","startSec":33.0,"text":"The images we see on the screen in front of us show us what kind of detail we can get from virtual shadowing. If we take a look at this image, we'll notice that the shadows on the right hand side look fairly crisp, but let's take a look in the very background of this image as this will really help to highlight the true power that virtual shadow maps give us. By zooming in on this area and comparing an old version with our previous shadow map technology with the new version, we can see quite a difference in detail."},{"start":"1:10","end":"1:42","startSec":70.0,"text":"In the older version, notice there are shadows, but a lot of the detail of the shadows are missing. For example, right here, this should be shadowed. Instead, we're getting just this little blob right here, which represents the shadowed area. We're also completely missing shadowing information in this area over here. Comparing that to using virtual shadow maps, notice the fine detail that we're getting across the entire scene. There are shadows in places and not only that, but intricate shadow detail throughout this entire area."},{"start":"1:42","end":"2:09","startSec":102.0,"text":"And remember, this is representing a very, very small yet scaled up part of the image that you're seeing on the right hand side of the screen. Finally, the best part about virtual shadow maps is that they are a default feature of Unreal Engine 5, and there is no setting that you need to enable to turn them on. You just need to simply use the editor and virtual shadow maps will work as intended."}],"14_SkyAtmosphere":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"UB-5 provides a sky atmosphere actor that you can place in your scene and then configure to help simulate a planet's atmosphere. On this actor you will find a number of different controls that allow you to adjust how the atmosphere will look and react to lighting, as well as a number of controls that will allow you to adjust the look without adjusting the physical plausibility."},{"start":"0:30","end":"1:03","startSec":30.9,"text":"Let's go ahead and take a look at this inside of the editor now. So inside of the editor I just have a file, a new level here, and I selected the open world template because this will be set up with everything that we need. So if we come over here to lighting and we look for our sky atmosphere, you're going to see that actor right there. If we look down we have a number of different parameters that we can adjust here like our atmosphere height or the effects of multi-scattering. We can also change how this is transformed so that we can adjust this based on if we"},{"start":"1:03","end":"1:36","startSec":63.6,"text":"are looking again at the ground or if we are looking at this in space. There are also a number of other parameters around here, each with their own setting on how this is going to affect the look and the feel of this atmosphere. One of the other cool things about this whole system is that it does work with the directional light and the skylight as well as the exponential height fog. One pro tip, if you do hit control, alt, and L, you will bring up a quick lighting positioning"},{"start":"1:36","end":"2:07","startSec":96.2,"text":"tool which will position the directional light in easy to use manner. Again, that's the directional light selected here. We just do control, alt, L, and make sure that we rotate around the scene. And again, this reason that we want to use this is because our sky atmosphere is going to be slightly different based off of the sun's location and things like that. So being able to quickly adjust the direction of that directional light to allow us to properly visualize everything is very important."}],"15_LevelEditor":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"The Unreal Engine 5 level editor is a very powerful tool and a tool to spend quite a bit of time in as this is how we build the interactions or projects we wish inside of Unreal Engine 5. Let's go ahead and pop into the editor real quick and have a look at it in more detail. We can navigate through this using the WAS and D keys or the left and right mouse buttons depending on our preference. The editor viewport is in real time and if we want to adjust something in the editor we can simply click on it."},{"start":"0:35","end":"1:10","startSec":35.0,"text":"Once we do that whatever we click on properties will be displayed inside of the details panel over here allowing us to adjust whatever we wish to adjust. Remember this editor is happening in real time so what we see here is going to be the same if we come up to if we press play. The only time this could be different is if you're deploying to a mobile device or a console as there could be slight differences in the rendering. But the level editor does provide a very accurate representation of what you could expect the end rendering to be."}],"16_StaticMeshEditor":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Unreal Engine 5's Static Mesh Editor allows you to view and edit the properties of any static meshes that you have imported or downloaded from the FAB marketplace. Inside of this editor, you can do things like enable Nanite, adjust LOD settings, or adjust collision settings, and even add sockets or disable properties that affect how the static mesh is rendered. You can also look at mesh properties such as vertex colors, the pivot, and even the"},{"start":"0:32","end":"1:06","startSec":32.4,"text":"normals. Let's take a look at this inside the Engine now. Now to access this tool, all we need to do is simply double click on any static mesh. Once we do that, it will automatically open up that mesh inside of the Static Mesh Editor, and then we can edit its properties on the right hand side underneath the Details panel. Some other things to note here are the properties that we see on the left hand side. This can give us information such as our triangles, vertices, UV channels, and approximate size."},{"start":"1:06","end":"1:39","startSec":66.4,"text":"We can also view our UVs, our collision, and should we want to adjust the pivot of this by enabling the modeling tools. We can also re-import or re-import this mesh with dialogue, which allows us to re-import this mesh with new settings. Finally, the Save button allows us to save any of the settings that we have adjusted over here, ensuring that this will be saved to disk so that when we reopen this tool or use this asset in another location, those settings have been saved and applied."}],"17_TextureEditor":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"The Unreal Engine 5 Texture Editor is a powerful tool that allows you to adjust various properties of your textures once they've been imported into the Engine. You can quickly access the Texture Editor by double clicking on any texture you see in the Content Browser or Texture Input you see throughout the Editor. Let's take a look at the tool in a little more depth by going over to the Editor now. Once we're in the Editor, I'm going to hit Control Space to bring up my Content Browser. Then I'm going to go over here to Texture."},{"start":"0:31","end":"1:02","startSec":31.0,"text":"Once I do that, I'm going to double click on this Bark Texture and you'll notice as soon as I do that, I'm brought to the Texture Editor. The Texture Editor should look kind of similar with the File, Edit, Asset, Window, Tools, and Help menu across the top as many of the other editors in Unreal Engine 5 have. Next what we have is our Save and our Browse to Asset. Remember this Browses to this Asset in the Content Browser. Then we have Reimport which allows us to reimport this asset from the location it was imported"},{"start":"1:02","end":"1:32","startSec":62.6,"text":"from. Then we have the ability to isolate the red, green, blue, or alpha channels of this Texture. This is useful if you're using a masked workflow and you want to isolate each channel for further inspection. Next to that we have the ability to adjust which MIP level is currently being displayed. This will allow us to further inspect that in case there are issues. Now for those of you who are unaware, MIP maps are generated for you by default if the"},{"start":"1:32","end":"2:04","startSec":92.6,"text":"Texture you have imported is a power of two in the X and the Y axis. We covered this in a few slides in the beginning of this presentation. Next to that we have the ability to zoom. This allows us again to just kind of get a closer inspection on our Texture here. We can also do this by using the middle mouse wheel and scrolling up or down. Next to that we have our preview platform. This allows us to adjust the Texture compression settings here to emulate what it would look"},{"start":"2:04","end":"2:34","startSec":124.3,"text":"like on an Android, iOS, Linux, Mac, TV, or Windows device. Our Details panel allows us to look at some important information at the top such as the imported size, displayed size, and max end game size of this Texture. We can also see the resource size or the amount of memory that this is going to consume. These numbers up here are important because we can actually constrain our textures to have a different resolution than what they were originally imported with."},{"start":"2:34","end":"3:08","startSec":154.4,"text":"This can help in terms of memory as remember reducing Texture size will help reduce the amount of resources this will consume. On the right hand side of that we have a method streamed format DTX, supports format Alpha false, combined LOD bias zero, number of MIPs 11, and our end code speed final. Out of these settings the ones that you need to pay most attention to are method streamed, format, and number of MIPs. Remember that if we want to use Unreal Engine's advanced Texture Streaming System we need to"},{"start":"3:08","end":"3:39","startSec":188.6,"text":"make sure that our textures are a power of two in the X and the Y axis and if they are then this method stream will show up right here and we want to see that as well as the number of MIP maps. With that we have our level of detail, compression, texture, adjustment, file pass, and compositing sections. Let's take a look at these in detail. So level of detail what this does is this controls how our MIP maps are generated. In the MIP GIN settings right here if we click on this drop down we have the ability to either"},{"start":"3:39","end":"4:12","startSec":219.8,"text":"sharpen or blur. So if I was to say blur this and let's just do like a blur five and I come here to my LOD bias which allows us to bias this or change the size of the LOD. You can see here that that is very very very blurry and that's not really what I want. So I'm just going to go, actually I'm just going to reset this default so that you can see what that actual option does right here. So this is just a little pro tip. Anytime you set something and you want to get back to what you were before and you don't know just press this and you will automatically go back to the default."},{"start":"4:12","end":"4:44","startSec":252.5,"text":"Another group down here what this allows us to do is set this texture to another group and we can control these groups through our INIs and the groups allow us to control settings that we're seeing inside of this texture editor should we want to adjust all of the textures in our project. Compression deals with how this is going to be compressed. Now one thing that we might want to consider enabling is this compressed without alpha. The reason for this is that alpha textures take up about two times as much memory because"},{"start":"4:44","end":"5:15","startSec":284.6,"text":"alpha information is uncompressed. Because of this we want to make sure that any textures we're using do not accidentally contain alpha information. So by making sure that compressed without alpha is enabled when we import a texture the alpha information will be removed even if it was there by accident. The other setting that we need to be aware of here is our compression settings. What this allows us to do is adjust the different compression methods that are used on this texture."},{"start":"5:15","end":"5:47","startSec":315.1,"text":"Now most of the time default or normal map which Unreal will set for you will be okay. But if you happen to be dealing with something like maybe a mask or a vector displacement or maybe a HDR image that's where you'll want to change these settings right here in order to accommodate for that compression method. Under texture we have our padding and resizing and what this will do is this will allow us to take non-power of two textures and modify them in a way that turns them into a power"},{"start":"5:47","end":"6:20","startSec":347.6,"text":"of two texture. And then sRGB right here this makes sure that we enable or disable gamma correction. This is highly important for dealing with a mask or a normal map we always want to make sure we have this turned off. This allows us to adjust various properties of this texture. So for example if I want to make it a little bit darker I can do something like that. If I want to make it a little brighter I can do something like that. The great part is also remember that this is non-destructive even if I was to save this by adjusting it I could simply come back here and undo that setting and it would go right"},{"start":"6:20","end":"6:32","startSec":381.0,"text":"back to the way it was before. Our file path shows us the file and the date stamp of when this was edited and then compositing deals with compositing when we composite with this."}],"18_BlueprintEditor":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Unreal Engine 5's Blueprint Editor is one of its most powerful tools as this allows you to create C++ code without actually having to write or know that much about C++ code. This is achieved by laying down various nodes and then connecting them in a flowchart-like manner in order to construct game logic or interactivity."},{"start":"0:30","end":"1:03","startSec":30.6,"text":"Blueprints can be simple assets that just contain a mesh or a light, or they can be very complex and even have the ability to call other blueprints within blueprints. Let's pop over to the editor now and just take a look at these briefly to get a better understanding of what we're working with here. I'm going to hit Control Space on my keyboard and then I'm going to make sure that I have my Blueprint classes here. These are all the various blueprints that are in this particular project."},{"start":"1:03","end":"1:37","startSec":63.7,"text":"For example, I can pull out this Blueprint ceiling light here and let me just pull this up and we can see here that this is a light. If I come over here, you can see I have a brightness and I have a color property here that I can adjust and I have a source radius. Now, I'm going to select this and I'm going to hit Control E on my keyboard and that's going to open up the Blueprint Editor. This is our Blueprint Editor. The Blueprint Editor has three main parts. There's a viewport which represents our visual part. If our Blueprint needs to have some type of visual component, our viewport is where we"},{"start":"1:37","end":"2:08","startSec":97.6,"text":"position it and make sure that everything is the way we want it to look. Then we have the Event Graph and the Construction Script. The Event Graph is functional when we press play. When I press the play button right here, things that happen inside of the Event Graph will fire off. The Construction Script, on the other hand, this works when I'm inside of the Editor. The Construction Script, when I go ahead and set something like the brightness here, notice that the Construction Script is firing off."},{"start":"2:08","end":"2:39","startSec":128.5,"text":"That's again because we're telling that Construction Script to change the brightness and we do that inside of our Event Graph. As I come through here, we're going to have a bunch of different things that I can do. Here's another Blueprint for Echo. This will take just a second. I think it hasn't been compiled. Give us just a second here. Did I lose it? I'll just bring it right there."},{"start":"2:39","end":"3:13","startSec":159.7,"text":"There we go. Here is our Echo. If I was to hit Ctrl E on this, we're going to notice a much more complicated Blueprint here. We're going to take a look at the Open. It looks like I actually opened up the demo display. Let me close that. I meant to grab her and hit Ctrl E. There we go. Here's her Construction Script. It's setting up her hair. It looks like here's the Event Graph. It looks like it's doing some stuff with the hair. Here's our viewport. Then over here, we have our components, which contain different things like there's stuff"},{"start":"3:13","end":"3:37","startSec":193.2,"text":"for her hair. A lot of stuff around her hair on this. Again, the Blueprint Editor is a super, super powerful tool that allows anybody, whether they be a level designer, a technical artist, regular artist, or even just a regular designer, the ability to block out code or experiment in ways that just haven't been possible before."}],"19_AnimationEditor":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Unreal's animation editor isn't a single tool, but a collection of the following five different tools. There is the animation blueprint editor, the skeletal mesh editor, the skeleton editor, the animation editor, and the physics editor. And each one of these tools plays a different role when it comes to dealing with animations. So let's pop over to the editor now and take a look at this. So inside the editor, I'm going to hit Control Space to bring up my content browser."},{"start":"0:31","end":"1:01","startSec":31.0,"text":"For my filters, I'm going to click on Skeletal Mesh and I'm going to bring up this tentacle right here. And notice as soon as I do that, we are brought into the Skeleton tool, or I should say, I'm sorry, the Skeletal Mesh Editor. From here, we can do things like assign our materials, adjust our LODs, as well as adjust many of the various properties like skin weights, import settings, and things like that."},{"start":"1:01","end":"1:34","startSec":61.0,"text":"We also have our Skeleton Editor. The Skeleton Editor allows us to adjust the skeleton or the rig that was brought in with this. From here, we can right click and we can copy bone names or add sockets or add virtual bones and other things of that nature. This right here opens up our Animation Editor. The Animation Editor allows us to add notifies or adjust various properties that have been assigned to our animations."},{"start":"1:34","end":"2:16","startSec":94.0,"text":"Next to that, we have our Animation Blueprint. Animation Blueprints are very powerful as they allow you to combine the power of animation and blueprints to do things like set up state machines or have your animations wait for particular input in order to fire off some other type of animation logic. Last but not least, we have the Physics Authoring tool or the FAT Editor. This tool right here is used to create the physics bodies that will be used whenever this is used in some types of physics simulation."}],"20_ClothEditor_55":[{"start":"0:00","end":"0:38","startSec":0.0,"text":"The clothing tools that Unreal Engine 5 provides are actually inside of the animation tools, particularly when you open up a Skeletal Mesh, there is an Activate and Deactivate Clothing Paint, which allows you access to Unreal's cloth system. Now, Unreal Engine uses the Chaos Cloth Solver, which is a low-level clothing solver responsible for the particle simulation that runs clothing. This clothing solver allows integrations to be lightweight and is very extensible because we now have direct access to the simulation data."},{"start":"0:38","end":"1:09","startSec":38.0,"text":"Unreal's clothing tools are cross-platform enabled, and let's take a look at those tools in the editor now. To access the tools, I do need to bring up a Skeletal Mesh, so I'm going to hit Control Space on the keyboard, and then click on Skeletal Meshes. Inside the content examples, we do have a couple of clothing examples, so I'm just going to click one and open it up. Now, once I have the Skeletal Mesh editor open, if I click on Activate Clothing Paint, this is where I will get the tools."},{"start":"1:09","end":"1:40","startSec":69.0,"text":"Once I click on this, you can see here I then have the ability to paint on this surface, and if we right-click on this and go to Set Target, you can see here I have a bunch of different options for different settings for clothing circumstances, such as how the clothing will react when it teleports away from the user, whether or not it should react to lift if it has drag and things like that. There are also a number of different settings down inside of the tool under Cloth Can Figs."},{"start":"1:40","end":"2:12","startSec":100.0,"text":"We can adjust things like our mass or our density, as well as how this reacts to collision. Justing the brush is actually done inside of the tool. Down here at the bottom, we have this Clothing Tool, and we can click on this and change a brush, gradient, smooth, or fill, and then we can simply paint as we are used to. Once we're done with this, we just need to simply close this and try that one more time. There we go, and we will see the results there in real time in the editor."}],"21_NiagaraEditor":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Niagara is Unreal Engine 5's visual effects editor, but it's so much more than that. Niagara can also be used for gameplay interactions, and even updated without the need of an engineer. That's right, you can actually add your own modules to Niagara to develop your own behaviors using a node-based system, and you can add functionality that wasn't there, or adjust functionality that is already existing to better meet your needs."},{"start":"0:31","end":"1:04","startSec":31.0,"text":"That's right, this entire thing is built to be improved upon, but it's also pretty easy for the average user to understand. Let's pop into Unreal and have a look at it now. So, in order to get the most out of Niagara, we're going to need to create a Niagara system. To do that, I'm going to hit Control Space, and then inside of our content browser here, I'm going to right-click, and from our Create Basic Assets, I'm going to select Niagara System. Now, because Niagara is such a robust toolset, it is often daunting to start out from a blank slate."},{"start":"1:04","end":"1:38","startSec":64.0,"text":"So, there is a wizard system that gives you some examples or some templates to work from. The templates that we have right here, this is going to do blowing particles or fountain, or maybe we have some particles hanging in the air, or maybe we want an upward burst of meshes or something like that. This is going to give us a great way to get started so that we can quickly build out some effects to our liking. Lightweight has to deal with a system that requires less rendering resources."},{"start":"1:38","end":"2:10","startSec":98.0,"text":"Learning content is, these are some things that go along with our learning content and also show you how to do things like sub-UV animation, particles with unique IDs, or particles that spawn in a grid. And then last but not least, we have the Niagara Fluids examples. That is right. With the Niagara Editor, you can create real-time water and smoke, and these can even interact with things inside of your scene using collision. While this is very, very complicated, now to the scope of this talk,"},{"start":"2:10","end":"2:44","startSec":130.0,"text":"you can actually look at all of these examples simply by just selecting it and then creating it and have a look at how all of this is built up. Now, for this one, what we're going to be doing is we're just going to take a look at a quick fountain. So, I'm going to hit Create, I'm going to say NS underscore example, and let's double-click on it to open it up. Alright, so the Niagara Editor should look a little bit familiar because like with many of the other editors, it's set up in a similar manner. Across the top, we have our file, edit, asset, window, tools, and help menus."},{"start":"2:44","end":"3:16","startSec":164.0,"text":"And then we have the main toolbar. The features you'll want to be most concerned with here are your save and browse to asset in the content browser. The compile button, what this does is this compiles our Niagara system in order to make sure that everything is working and nothing is incorrect or values are not bad or need to be adjusted. We have our thumbnail button which generates an image thumbnail to make this easier to see in the content browser. If I click that now, what should happen when I hit Control Space is we should see that example."},{"start":"3:16","end":"3:49","startSec":196.0,"text":"So, it's just showing us right there. The bounds shows us the rendering bounds of this object. This is particularly important when we're using something like a GPU particle which needs a fixed bound size for rendering. We have the ability to look at different debugs. Our simulation allows us to select if it's autoplay, reset on change, or resimulate when paused. The baker allows us to actually bake this particle into a series of still images that we can then replay."},{"start":"3:49","end":"4:25","startSec":229.0,"text":"What this does is this takes some of the complex calculation out of this particle effect and makes it cheaper to run. Then we have our scalability. Our preview viewport over here is going to work very similar to the other preview viewports. We can adjust the things like real time or show our stats or our field of view. We can also come here and adjust the view and maybe change to an orthographic, a top right or a side view. We can adjust our lighting. We can also show things like our execution order or our memory consumption for this particular particle."},{"start":"4:25","end":"5:00","startSec":265.0,"text":"Then we can change the background here in case the epic headquarters is distracting. Over here we have our parameters, local modules, and user parameters. Parameters are things that come by default with this system. For example, age is going to be something or loop count. These are all things that every system is going to need in order to act correctly. Our location, I always say location, but I mean our local modules are bits of code that we have written specific for this particular effect."},{"start":"5:00","end":"5:41","startSec":300.0,"text":"Basically, if we're trying something out and we want to maybe see how it's going to work or something like that, we can do that inside of here. We don't have to expose that to everything else. Should we just be making an experiment? Now, user parameters, this one is very cool. What this allows us to do is expose various parameters inside of our effects so that when we place this in the world, we can adjust those parameters accordingly. Now, our timeline allows us to adjust, I shouldn't say adjust, allows us to see how this particle is playing in relation to others that might be in this system."},{"start":"5:41","end":"6:11","startSec":341.0,"text":"Remember, we can have multiple Niagara admittors and a single Niagara system. This timeline can help with the timing of those. We can set this up because we can pull the little trail heads of these around. We could have maybe one fountain that goes off and then another fountain that goes off. We can control the timing of those using these. What you cannot do with this timeline is control any of the properties of your material."},{"start":"6:11","end":"6:42","startSec":371.0,"text":"Say you wanted to do something like have your particle start at zero and then ramp up the amount of particles it spawns and then stop, say, at five seconds. That is not something you can do. You cannot do keyframed events down here. Script stats will show us the script stats for this. It's a way for us to get some performance information. Curves will show us any property that we have marked as a curve and then it will allow us to edit that curve. It just makes it a little bit easier to edit."},{"start":"6:42","end":"7:14","startSec":402.0,"text":"Then we have our log here, which will point out any issues should the system not compile correctly. Next, we have our details panel. Our details panel, like the details panel in most of the editor, is going to be context sensitive and it's going to change based off what I have selected. Now, inside of the system overview, this is where we're going to be spending a lot of time, particularly on this Niagara Admitter."},{"start":"7:14","end":"7:45","startSec":434.0,"text":"When we click the Admitter, what we're going to get in the details panel is all of the details that are available that we have set inside of here. If we want to narrow this down, all we need to do is simply select either one of these drop down areas or the individual module that is in that area to select. This is simply a way for you to either look at everything that's in there or have a more zoomed in look at what is going on to get rid of some of the noise."},{"start":"7:45","end":"8:16","startSec":465.0,"text":"To add or remove something, we can right click on this and we can delete it or if we click on this plus sign, we can then add different modules and things like that to our Admitter. One of the other things I want to show you before we wrap up is if we come here to say like our spawn rate and we click on this, we're going to look for this, make and then we want, I'm sorry, not make, new user and there we go, read from new user parameters."},{"start":"8:16","end":"8:49","startSec":496.0,"text":"So if I hit that and I come over to my user parameters, you're going to see we have this spawn rate set at 90. So let's just compile and save that. I'm going to move this out of the way here and hit control space and just bring this into my level. So with that there, check out my spawn rate. I can set that to maybe like a spawn rate of one or 10. And that's how I expose a parameter for someone to use when this is placed inside of the world. So they don't actually have to come here and open up the particle editor. They can just adjust the spawn rate right in here like you would any other actor."},{"start":"8:49","end":"8:59","startSec":529.0,"text":"So that is Unreal Engine's particle editor Niagara. It's very, very, very simple to use, but takes a long time to master."}],"22_UMGEditor":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Unreal Motion Graphics, or UMG for short, is Unreal Engine 5's tool for creating user interfaces. Unlike some of Unreal Engine's other tools, this tool actually features two tools in one. UMG contains a designer and a graph, and the designer is responsible for designing the look and feel of your UI, while the graph is responsible for the functionality of your UI."},{"start":"0:30","end":"1:02","startSec":30.5,"text":"Let's go ahead and pop over to the Engine now and take a look at this in more detail. So first off, we need to actually create a user interface blueprint. So to do that, we're going to hit Control Space, and then from the Content Browser, we're going to right-click, and underneath User Interfaces, we're going to look for a Widget Blueprint. Now when we do that, we are going to be asked to pick parent class, and what we're going to do is from Common, we're just going to select a user widget. I'm going to call this Widget Blueprint underscore example."},{"start":"1:02","end":"1:34","startSec":62.8,"text":"Now let's double-click on this to open it up, and when we do, it's going to open it up in the UMG Editor with the Designer tab open. Now remember, there is a designer and there is a graph, so the designer is how we're going to make this UMG look, and the graph is how we're going to make this UMG functional. So let's take a look at the Designer tab first, and then we will go over to the Graph tab. So across the top, though, we have our File, Edit, Asset, View, Debug, Window, Tools, and Help, much like we have in all of our other editors."},{"start":"1:34","end":"2:07","startSec":94.9,"text":"Then we have our main toolbar, and this is actually going to look pretty similar to the main toolbar inside of Blueprints. We have Save and Browse to this asset in the Content Browser. We have our Compile. We also have a Diff. What this does is, if we're using Source Control, this allows us to compare two different Widget Blueprints to see why they are different or what was changed or if something's broken, we can see what happened and why it became broken. This here allows us to start a play in our active viewport if we're trying to debug our"},{"start":"2:07","end":"2:42","startSec":127.4,"text":"UI, and we need to look at our time or something like that. This will allow us to just quickly do that from inside of here. No debug object selected option is actually how we select the debug. What we would do is when we play and call this UI widget, we would see its name up here and be able to select it. The Widget Reflector is a great tool for diagnosing live widgets. Say we run into an issue with a widget, and the only way to actually look at that issue is during the game when things are running, because maybe it's spawned off of something"},{"start":"2:42","end":"3:15","startSec":162.4,"text":"else. We would use the Widget Reflector to help us diagnose those problems for widgets that are possibly spawned by other widgets or things that are happening while the project is running that are kind of hard to see inside of this editor. Then we have our palette and our library. Our library contains all of our various things for like a check mark box or an image or something like that. We would actually use the library that much unless you are adding some custom content."},{"start":"3:15","end":"3:51","startSec":195.4,"text":"The palette on the other hand is where you're going to spend a majority of your time. This is where we're going to find a lot of the functionality for our UI. The first thing we need to do here though is add a Canvas panel. I'm going to add that down here to our hierarchy. That's going to add me a UI that can be stretched across an entire screen. Pro tip, if you grab this little handle right here, you'll be able to stretch the UI to various resolutions to see how it's going to look when it's set from 1280 by 720 to 1136 by 640."},{"start":"3:51","end":"4:24","startSec":231.4,"text":"There are a lot of different things inside of here. I'm not going to go through all of them. I highly suggest that you go through and experiment. To work with this stuff, all you simply need to do is just drag what you want from the palette there down to our hierarchy. Our hierarchy is going to show us the hierarchy of where things are placed inside of this UI. I can also take things and I can have them independent from one another or I can have them as a child of something else."},{"start":"4:24","end":"4:56","startSec":264.5,"text":"That's some really cool things that I can do. Then we have our details panel. Much like the details panel in many of the other editors, it's going to be context sensitive based off of what I have selected. You can see here when I select my whole UI, we get some different interactions over here than when I select the canvas panel versus the button. Speaking of the button, when we want to do something like have this button say be clickable, we will select that button and then over in the details panel under events, we have all"},{"start":"4:56","end":"5:31","startSec":296.9,"text":"of these various events. The cool thing about it is if we bring in something like a check mark box or maybe we bring in an analog slider. With those selected and we come down to the events, notice we have the analog on analog capture or on mouse capture begin, on mouse capture end. What's really cool about this, I'm just like the button for easiness, but I'm going to click this on click and what it's going to do is it's going to change me over to the graph. Notice I'm in something that looks kind of like blueprints and that's because the UMG"},{"start":"5:31","end":"6:03","startSec":331.4,"text":"designer or I should say UMG itself is broken up into a designer and a graph. So the designers, how we make things pretty and the graph is how we make things functional. So on clicked, now I can pull off of this and do something like print and I could do a print string. So when we press that button, we are going to print this hello a couple of things to note from the graph here. If I come over here to my blueprint, notice I'm going to have like my pre construct, my events are up here. I have functions and macros that I can look at or override."},{"start":"6:03","end":"6:36","startSec":363.7,"text":"Here is my variables so I can add variables much like I can in normal blueprints and then I will get the details panel here will contain the various details if there is something that has details that I can use. Go ahead and compile and save that. Now you do need to set up UMG render widgets to be rendered to the screen, which is a little bit outside the scope of this, but trust in that this is a simple process and that UMG can be used to create any type of UI no matter what type of project you are creating."}],"23_SequencerEditor":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Sequencer is Unreal Engine 5's editor for creating and editing linear animations, but it can also be used for so much more than that. You can actually use Sequencer for gameplay events to help you generate movies or promotional items. It can be used pretty much like an offline renderer or in a real time capacity. Let's pop into the editor now and see more about how this tool works."},{"start":"0:33","end":"1:04","startSec":33.4,"text":"First off, to create and work with Sequencer, we need to create something called a level sequence. To do that, there's a number of different ways. We can right-click inside of here and we can come down to our, I believe it is under Cinematics, we can create a level sequence or animation sequence or a template sequence, we can come up here to the sequences up here and we can either add a level sequence or add a level sequence with a shots track."},{"start":"1:04","end":"1:35","startSec":64.5,"text":"The difference between them is this. A level sequence will allow us to have one shot, but a level sequence with a shots track will allow us to have a level sequence with multiple cameras inside of it. Let's say that we know we're going to be using five or six cameras because we have five or six camera cuts. Instead of setting those all up for us one by one, we can click the add level sequence with shots to have those five shots already created for us."},{"start":"1:35","end":"2:10","startSec":95.2,"text":"For now though, I'm just going to select this add level sequence and we're going to call this LS underscore example. When I do that, you're going to notice something a little bit different happens. All of a sudden the sequence opens up and if I hit control space, we can see it's right there. We can close sequencer just by hitting that X and then open it anytime by just clicking on the sequence to open it up. One of the cool things about sequencer is we can add transforms or rotations or pretty"},{"start":"2:10","end":"2:45","startSec":130.4,"text":"much anything that we want just as long as we see one of these little key frame. Key property can actually be key framed if it has one of those little diamonds next to it. Let's just take a quick look at the editor itself. Across the top here, we're going to have our main toolbar. This is our actors that we want to put in here. There's our save, there's our browse. This creates a new camera and sets it to the new camera cut. This allows us to render things out if we want to take a pre-rendered video or something"},{"start":"2:45","end":"3:19","startSec":165.6,"text":"like that. This opens up our blueprints, these are our actions and there's a whole bunch of different things inside of here. These are our view options, we have our playback options and then our key frame and our snapping as well as our playback speed and our curve editor. Now, to add something to sequence, what you can do is select it inside the viewport and then come here to add and you can add, like we can add the new logo, we can look for it or we can add selected from the content browser. For me, I'm just going to add this new UEE logo and you can see as soon as I do that,"},{"start":"3:19","end":"3:57","startSec":199.4,"text":"it adds a track. This works just the same as any linear based editor. We put down key frames and then we move this over like this and then we maybe go like that and you can see here it's automatically actually going to make that key frame motion for me. There we go. To work with one of these properties, it's the same way. Let's come up here to our, maybe we'll do our transform. We'll do something like, I don't know, add a key frame"},{"start":"3:57","end":"4:30","startSec":237.0,"text":"and actually it's in auto mode so I don't even need to add one but you can see here it's doing that. We can also take multiple objects. So let me just come here and we're going to go add a point light. There we go. Where is that? Let's hit G so we can kind of see where that is. There we go. So let's just add that, add a sequencer, add our point light. There we go. And then we can do something like our intensity is set to 8 but we come here, maybe we set it to like 80."},{"start":"4:30","end":"5:04","startSec":270.0,"text":"So you know, maybe we set it back to 8. There we go. So it's kind of like making a little, let's move this a little bit closer to the ground. There we go. There we go, something like that. So just showing you can have multiple different actors in the same sequence all going off. Now to actually play this sequence inside of your project, you will need to set up a little bit of blueprint logic just to fire off the sequence when the level plays."},{"start":"5:04","end":"5:29","startSec":304.6,"text":"But other than that, sequences are a fantastic way to create any type of interactive cinematic or content or linear based content that you wish and have it rendered all in real time, output to video and it can really cut down on production times, especially again if you're using this for any type of linear based media."}],"24_LandscapeEditor":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"The Landscape Tools Unreal Engine provides allow you to modify your landscapes right inside of the editor and can be used to create landscapes of any size. Let's go ahead and take a look at how we use this tool in the editor now. So from this blank menu, I'm going to come up here to my selection mode and go down to Landscape. This is going to open up our Landscape tool. The Landscape tool is set up into three different kind of sub-tools."},{"start":"0:32","end":"1:02","startSec":32.0,"text":"There is the Manage mode, which helps us manage the size, location, and scale of our landscapes. So right now what I'm going to do is set this to 31 by 31 and hit Create. Now once I do that, you're going to see that my landscape is added to the world and then my tool is set to Sculpt. And Sculpt allows us to actually sculpt our landscape. As you can see here, I can use the various tools to affect the look of our landscape."},{"start":"1:02","end":"1:34","startSec":62.0,"text":"We also have the ability to change the brush size and its fall-off as well as its strength to help us further refine the look and the feel of the landscape. Over on Paint, you have the ability to actually paint the surface of the landscape. Now this current material landscape has on it automatically adjust its look based on the slope of the landscape. But if we wanted to paint individual layers that represent grass, rocks, and things of that nature, we could do that right on the surface here using the Paint tool."},{"start":"1:34","end":"2:08","startSec":94.0,"text":"The Manage mode of our landscape actually allows us, if we come here to our Import, we can actually export this as a height map. So that we can export or import a height map that was made in a third-party program into Unreal so that we can use that as a basis to work on. Or we can export it out into another application to tidy up a little bit and then bring that back into Unreal Engine 5. Now the landscape does have a few limitations that you should be made aware of."},{"start":"2:08","end":"2:39","startSec":128.0,"text":"For example, the landscape's tessellation is at the maximum amount that it can be. So if we come in here and we look at this from the Wireframe mode, a landscape can never get more dense than it currently is. I do believe the current is 1 meter per centimeter. You can enable Nanite on your landscape. And if you're dealing with a massive open world, I highly recommend that you do this so that you get the performance of Nanite on your landscape."},{"start":"2:39","end":"3:12","startSec":159.0,"text":"To do this, all you need to do is select your landscape and then come down to our Nanite and then just enable the Nanite settings and then build your data. Once you do that, you will then have a landscape. And if we come over here real quick, we can actually see some of that Nanite tessellation on this right there. So there's some of that Nanite tessellation coming through. And if we come here to our Lit and our Nanite visualization and go Overview, you can see here we are using Nanite on our terrain. So that's how we are getting some of this cool offset."},{"start":"3:12","end":"3:47","startSec":192.0,"text":"But just go back to Lit mode and I'm going to go over to our Wireframe. It is not actually, you know, again, increasing the regular tessellation of our landscape. It's just increasing the visual density of it, giving us this look. So remember that we can't actually increase the tessellation of our landscape. If we want something to have some more detail, we're either going to need to add static meshes or work with displacement and Nanite tessellation in order to get that look that we're going for."}],"25_FoliageEditor":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Unreal Engine 5's foliage tool can be used to paint mass amounts of static meshes across your scene. This tool will work on landscapes, static meshes, BSPs, transparent surfaces, and even other foliage meshes. That's right, you can get some foliage inception by painting your foliage on top of foliage. Let's take a look at how this tool works by popping over to the editor now. So for this tool to work, what we need to do first is come up to our selection and go down to foliage."},{"start":"0:30","end":"1:01","startSec":30.4,"text":"And this is going to activate the tool. Now across the top here we have our select all these select, select and valid, lasso, paint, reapply, single fill, erase, remove, and move. Out of all of these tools, the ones that you're probably going to be using the most are going to be select. What this does is this actually allows you to select individual foliage actors and then adjust their properties. The next one is going to be paint, as paint allows us to paint. So let's go ahead and add something to this to see how this tool works."},{"start":"1:01","end":"1:34","startSec":61.6,"text":"So hitting control space, I have my static meshes selected. I'm just going to grab this basic asset two and drop it right in there. With that selected now, you're going to see there is my foliage brush. And if I just left click, look at that. So a couple of things that we can adjust here across the top, we have our brush size, which allows us to increase the size of our brush. Our paint density allows us to increase the density that things are going to be painted at. I'm going to set that back to 0.5. And then our erase density does the same thing."},{"start":"1:34","end":"2:04","startSec":94.0,"text":"It allows us to increase the density of the erase. You can see here when I hold shift, that's how I'm actually erasing things right there. Further on down here, what we have is the individual settings for our foliage actor. So the painting controls how this is going to look when it is painted. So we have our density here, which decreasing this, setting this to like one is going to give us fewer. And then setting this to something really high is going to give us a whole lot of them."},{"start":"2:04","end":"2:34","startSec":124.3,"text":"Radius is a really cool option. So what radius does is it defines the minimum distance between the foliage actors so that they don't collide with one another. One way to figure out this number is if you double click on your static mesh here, and under the approximate size, if you look at this middle number 104, we're going to close that. We're going to set our radius here to 104. And this is a great way to figure out what a good size is going to be for your particular mesh so that things do not intersect."},{"start":"2:34","end":"3:05","startSec":154.8,"text":"You can also use the bracket keys on your keyboard to make the brush smaller or larger. And you can do this with actually all of the editors like the landscape editor. If you need to adjust the size of your brush, we can also adjust the min and the max. So set that to two. One of the other things that we can do here under our placement is we have the ability to adjust how our normals are, how this object is aligned to the normals of a surface."},{"start":"3:05","end":"3:37","startSec":185.0,"text":"And then we can even set things like the ground slope angle so that, for example, we could have maybe a certain mesh that we want to use that can only be selector. Maybe it only grows on a certain angle so that when we paint this particular thing across our landscape, it will only go on areas that meet this particular criteria. We can get actually very advanced in particular with the restrictions that we make with this tool. Underneath the instance settings, this is going to control how this reacts to things"},{"start":"3:37","end":"4:10","startSec":217.7,"text":"like lighting and collision, which I highly recommend. You do not put collision on your foliage objects. It is just going to cause you problems. We have a physics which will allow us to override our physical materials and scalability in drawing in the virtual texture. One of the other things that we can do with this tool is notice that there's a little save icon right here. We could actually save these settings to a specific thing called a foliage asset, which will make it a lot easier when we need to apply this foliage to another level or we want"},{"start":"4:10","end":"4:40","startSec":250.6,"text":"to use it in some other instance. Now one of the other things that I want to show you here, let's click on select. If I click select here, notice that I can select them. If I hit the space bar, I can rotate it, I can scale it, and I can also delete it. This is really great if you happen to paint a bunch of foliage and you realize it's going through say a building or something, you can come in here and select or we could do like a lasso selection and select a bunch of them and just remove the ones that happen to be intersecting."},{"start":"4:41","end":"5:13","startSec":281.2,"text":"The other thing that I want to show you, and this will be the last one for this, is reapply. What reapply does, let me just come here to paint really quick and let's paint a bunch in here. What reapply does is it allows you to reapply a setting without actually having to erase everything and reapply everything manually. What reapply does is if we come here and we go to, I don't know, placement, let's just say like negative 50 by negative 125 and we'll just do like that."},{"start":"5:13","end":"5:44","startSec":313.3,"text":"That's probably a little bit too much. So zero, the maximum could be like negative 50 and the minimum could be, for some reason they're like linked. I don't know what's up with that, but there we go. Something like that. So what this is doing is it's allowing us and we decide, you know what, I don't actually want that at all. So I want them to go back to the way that they were. So there we go. Now I've reapplied that particular setting without actually having to remove them. So if we're really happy with our foliage, we can come in here to the reapply and just adjust the parameter that we want."},{"start":"5:44","end":"6:12","startSec":344.8,"text":"We're also not limited to just one single foliage type. I can do a bunch of different things. Let me just come out here and not sure why they're not showing up for me. Oh, because I'm in reapply. Let me come over here to paint. There we go. That's the beginning, all of those individual little things sitting out here. So there we go. All right, so that's the foliage tool."}],"26_MeshPaintEditor":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Unreal Engine 5's Mesh Paint mode allows you to paint on your static meshes, both vertex colors, vertex weights, textures, and even allows you to blend in between two different materials should you want to do that. Let's pop into the editor and take a brief look at how we use this tool now. So before I access the tool, I am going to add myself here a sphere, and this is just going to give me something to demonstrate the tool with. It's not needed to use the tool, but is"},{"start":"0:30","end":"1:00","startSec":30.4,"text":"needed for demonstration. So with that added, there we go. I'm going to come up here to activate the tool by coming down to our selection mode and then going to Mesh Paint. And looks like right there I have that selected. So across the top we have our vertex color, our vertex weights, our texture color, and our texture. So textures is going to require a unique setup. It's a little bit outside the scope of this demo, but let's demonstrate the vertex color. So to do this, all we need to do is click on the paint here, and then we can just start to paint. And you can see here I'm"},{"start":"1:00","end":"1:33","startSec":60.8,"text":"painting right in the vertex color information. I can change this to like red. You can tell this is vertex color because we can see it putting color in between the vertices and we're getting kind of these little gradients that you see right there. You can also see it snapping to each of the individual vertices there. But very, very powerful tool. Another thing that we have the ability to I'm going to come over here to our texture color. If I click on this add right here, check this out. If I come over here to paint, now I have the ability to actually paint right here on this. And I can"},{"start":"1:33","end":"1:57","startSec":93.2,"text":"do things like fill, paint different colors, or I can swap my colors here and do all types of interesting things. And again, I'm doing this all right inside of the editor. So very, very powerful tool and worth doing some investigating into seeing how this can affect your workflow as, again, you're working right inside of the editor and it is a super powerful tool to use."}],"27_FractureEditor":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Unreal Engine 5's Fracture mode is actually part of the Chaos Destruction toolset, and this allows you to create cinematic quality fractures that run with real-time performance. The Fracture Editor allows you to create fractured versions of any static mesh that can be used to help increase the realism of destruction no matter how that destruction is caused. Within the Fracture Editor, you have full control over how something should look when it fractures, and you can even add multiple levels of destruction, allowing you further"},{"start":"0:33","end":"1:06","startSec":33.6,"text":"control over how something looks when it starts to be fractured during the middle of its fracture and its final, end-destructed state. Let's pop over to the Editor now and take a look at this tool in a little more in-depth. Now first, before I start, I do need to get something to do Fracture, so I'm going to come up here to my shapes and add a sphere. There we go. Then what I'm going to do is I'm going to come up here to my selection mode and go to Fracture. Now with the Fracture tool open, the first thing I need to do is create a geometry collection."},{"start":"1:06","end":"1:36","startSec":66.5,"text":"I'm going to do that right there. I'm going to go ahead and just leave this all default and just press the Create Geometry Collection. There we go. Now once that has taken place, the next thing that I need to do is come down to the actual Fracture, and you can see there's multiple options here. For this demo, though, we're just going to click on Uniform, and then as soon as I do that, I want to hit the Fracture button right there. That's going to actually fracture stuff. Now I can explode things out to see how my fracture takes place. One of the other things I'm going to do here is I'm going to take this Break Damage Propagation"},{"start":"1:36","end":"2:07","startSec":96.6,"text":"and set that up to like five so that we can see what happens when I press Play here. We should be getting some. Might need to just bring this up a little bit higher in the level. Let's just do that one more time. There we go. That's what we wanted to see. That's the first thing, Break Apart. So again, just needed to bring it up a little bit higher, but that is the Fracture tool. Again, it's very simplistic to use, but it can give you really finite control over how your fractured objects are going to look, increasing the realism no matter what your"},{"start":"2:07","end":"2:09","startSec":128.0,"text":"end target happens to be."}],"28_ModelingEditor":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Unreal Engine 5 has a very powerful set of modeling tools that can be accessed right inside of the editor that allow you to not only create messages inside of the engine, but also edit existing messages. And this is fantastic if you ever need to do something like reset a pivot or you want to maybe fix a minor detail or adjust something in a slight way. You don't have to go back to your digital content creation tool. You can do it right from within the engine. Let's pop over to the editor now and take a quick look at these tools."},{"start":"0:33","end":"1:04","startSec":33.2,"text":"So to access the tools, I come up here to my selection and then I come down to my modeling. Now I can use the modeling mode with a pre-selected static mesh or I can create a static mesh to model from. So in this instance, I'm just going to create a box here and then once I have that, I'm going to say accept. With that done, I'm now going to go over to my modeling mode here, go to my Poly Group edit and this is going to allow me to do things like extrude this face."},{"start":"1:04","end":"1:38","startSec":64.0,"text":"And then I can also move things around and rotate as I would in any other DCC. And you can see here I have a number of different options that I can do. For example, I could come here and select each one of these edges and then do something like a bevel. So in accept that action. And then once I'm all done with everything I can do except and there we go. Here's my newly modeled mesh, although it's not the world's greatest mesh, but I did model it right inside of the editor. Notice that I also have things like baking of UVs. I can voxelize my mesh in case I'm making something very complex and I want to cut down"},{"start":"1:38","end":"2:10","startSec":98.5,"text":"on geometry or maybe I just want to wrap it inside of another mesh for some reason to get that resulting geometry and do something else with it. There's a bunch of things here that go from simplifying our meshes so that maybe we bring in a mesh that is very high poly and we want to simplify it. We can do that right within this tool set. So this is a very, very powerful tool set modeling mode and it can do much, much more than just model. And I highly suggest that everybody dig into it to find out all of its benefits for any"},{"start":"2:10","end":"2:12","startSec":130.9,"text":"of the projects you're working on."}],"29_AnimationMode":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Unreal Engine 5 Animation Mode is a mode that exposes new tools, panels, and editor behaviors that assist with animation workflows. This essentially turns Unreal Engine into a toolkit for making or editing animations. When using this mode and animating with something like Control Rig, it's going to offer a more animation focused editor experience by exposing tabs that aid with the selecting of controls,"},{"start":"0:31","end":"1:03","startSec":32.0,"text":"transform displays, and launching of tools related to animation. Animation mode is mainly dependent on using Control Rig within Sequencer. Therefore, a basic knowledge of Sequencer is required to get the most out of this. Now, normally we would pop right into a demo of us utilizing this, but because this is a tool that exposes more tools, I'll show you how to activate it, but we don't have a lot of example content because that is very dependent on what you are doing with this particular tool set."},{"start":"1:03","end":"1:36","startSec":63.4,"text":"So let's just pop over here into the editor. Now, I am in a bit of a different example here. I am in the FK example here for Control Rig, and the reason I want to do that is I do want to have at least something to populate in the windows when I select the tool set. So if I come down here to my selection mode and come to Animation, we can see here that under my constraints, you can see that I have two undefined ones right here that are representative of this right here. The other tools that I have here are things for poses, tweens, snappers, trails, animation layers,"},{"start":"1:36","end":"1:57","startSec":96.7,"text":"and temporarily adjusting pivots, but notice that I also have my animation, Outliner animation details as well. So again, this is not necessarily a tool that does one specific thing. What this mode does is it adjusts the way the editor interacts, giving you a more animation focused workflow."}],"30_Outro":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"It's now time to wrap up this video tutorial series on an introduction to Unreal. We started with looking at the Unreal Engine 5 documentation. Remember that's the best place to get any help you need with any of the various features or tools that Unreal Engine 5 provides. We then took a look at what we can use the Epic Games Launcher for. Remember we used that to download various versions of Unreal Engine as well as access our Fav library. We then looked at how Unreal Engine projects are structured because they're working a slightly"},{"start":"0:32","end":"1:03","startSec":32.5,"text":"different way than we might be used to using multiple project specific files. We then took a look at the Unreal content pipeline and how we can get various pieces of content into the editor so that we can work with them in whatever project we're creating. We took a look at the editor UI. We covered what actors are. Then we took a look at the various tools and features that Unreal Engine 5 provides and how you might be able to utilize those in whatever it is you're creating. So that's it."},{"start":"1:03","end":"1:07","startSec":63.0,"text":"That's going to wrap up this video tutorial series. Thanks for watching and I'll see you next time."}]},"100.02":{"01_Introduction":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Hello and welcome to Quickstart your first project. This course we will be using Unreal Engine version 5.6. Now this is one of the first courses you should take if you're new to Unreal. And by the end of this course we hope you will be able to firstly create the right project set up for your goals, navigate through the Epic Games Launcher and the Unreal Engine Editor,"},{"start":"0:33","end":"1:05","startSec":33.0,"text":"have a good idea of how to import and manage assets inside your projects, and move content to and from other tools. Finally, we'd like to go over some of the main modes and features. Now we're not expecting you to learn them from this video. What we are hoping is that you'll have a good idea of what areas you need to learn in future, specific to what you're hoping to achieve within the Engine."},{"start":"1:05","end":"1:38","startSec":65.0,"text":"Unreal Engine started out its life as solely a game engine. It was built for the game Unreal Tournament, and this is how it's got its name. However, over the years, not only has it been provided to other game studios for creation of a lot of different games, but it's also grown to be used in numerous other industries, as we'll go over here. The main thing that is unique about a game engine is that it needs to produce"},{"start":"1:38","end":"2:09","startSec":98.0,"text":"all of its graphics in real time. Unlike other offline tools that can render frames over minutes or hours, Unreal and other game engines need to do it instantaneously. Historically, this would mean that we would have to sacrifice the quality of the output so that it could be responsive and fun to play, but as new methods of rendering have been invented and technology has improved,"},{"start":"2:09","end":"2:44","startSec":129.0,"text":"we are able to achieve a quality of output which is very competitive versus other offline renderers. Unreal these days is now being used in games from Indie to AAA, ARC-Viz and simulations for training visualization and interactive tools, VR and AR simulations, and it's also being used in a couple of other new interesting fields such as virtual production."},{"start":"2:44","end":"3:14","startSec":164.0,"text":"This is used in filming where an LED wall is placed behind the actors when filming footage and it can then be altered dependent on how the camera moves and this can produce much higher quality in-camera footage and save time in host production, cleanup and VFX. Unreal is also used in a lot of human machine interfaces such as a lot of the cars that are brought out today"},{"start":"3:14","end":"3:49","startSec":194.0,"text":"and used in things like the entertainment system. The output from Unreal Engine is now so good that it is being integrated into a lot of traditional animation workflows, allowing animators to see the end product much faster and quickly iterate on their product. This is why the project setup matters a lot in Unreal Engine. Different goals need different settings. A project for an automotive HMI is not the same as one for a virtual production,"},{"start":"3:49","end":"4:21","startSec":229.0,"text":"so starting with the right templates and options is going to save time and avoid headaches later. Here at Epic Games, we have an entire ecosystem that is produced to support and complement Unreal Engine. Now, there is a lot of tools coming from different stores, photogrammetry tools and things like metahumans. First one is UEFN and this is Unreal Editor for Fortnite."},{"start":"4:21","end":"4:53","startSec":261.0,"text":"This allows you to build playable experiences inside Fortnite using many Unreal Engine features. You can access a huge audience and earn based on player engagement. The other option we have is Twinmotion. It is a simplified, easier to learn, real-time tool, primarily aimed at architectural and design visualisation. This is great for speed and presentation, however you may hit some limits."},{"start":"4:53","end":"5:18","startSec":293.0,"text":"For that, you would need to move to the full Unreal Engine for advanced control. So that brings us to the end of this introduction. In the next video, we are going to download and install the Epic Game Launcher. We are going to walk through the key launcher options and create our first project with the correct settings. Thanks for watching. I will see you in the next video."}],"02_CreateProject":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"Hello and welcome to this video on project setup. In this we're going to be going through all the different steps that are required in order to make your first project. Now before we can actually make a project, we are going to have to download the launcher and before even downloading the launcher, we are going to have to create an epic login. In order to do this, all we need to do is visit store.epicgames.com and that should direct"},{"start":"0:36","end":"1:11","startSec":36.5,"text":"you to your local server for that, in this case it shows the US. Now after you're doing this, it's going to guide you through setting up your own epic games login. You can use a Google, Facebook, Apple store login and that's fine, we can attach your account to them. But this account is going to be quite important. It's going to be used across multiple different stores and we recommend that you create a"},{"start":"1:11","end":"1:42","startSec":71.0,"text":"secure password and keep it all safe. So once you have summed in, you're going to see in the top right hand corner there is a blue button on the site that says download. Clicking on this will take you to the download page and it's going to walk you through three steps if you want to get hold of the engine. Now the first one is to download the launcher. That's all I'd like you to do at this point if you haven't already done it."},{"start":"1:42","end":"2:13","startSec":102.3,"text":"And once you have downloaded the launcher, it will guide you through a short wizard to install the launcher and you'll be able to fire that up on your system. Once you've downloaded and installed the launcher, you're going to end up in a page that looks something like this. Now by default, it's going to show you some epic game news. Now this is targeted a lot more to the game's consumers."},{"start":"2:13","end":"2:50","startSec":133.3,"text":"So you're going to find that our first step in any of this is about people who are looking to purchase games. Now you'll see down the left hand side, we have three tabs, the store tab, a library tab and an Unreal Engine tab. If I was to click on the store tab, this will jump us into the game store. It's going to allow us to purchase different games from different companies, not all necessarily made on Unreal Engine and a number of them that are free giveaways to entice people to"},{"start":"2:50","end":"3:20","startSec":170.5,"text":"the website. Now below this, we will have the library tab. It'll skip over that, but that's going to be the games or software that you have purchased from the store. It's this last tab which is of interest to us here called Unreal Engine. If I click on that, it's going to bring us up a very different page. It will give us a number of other tabs that we have across the top here."},{"start":"3:20","end":"3:57","startSec":201.0,"text":"Now all of this is specific to creators or people who use the engine. So the news that we see in this instance is going to be a lot more about people who are making computer games or animations and much more specific to that, rather than the external games player. We will also have a whole load of different tabs that are going to offer us starting points. The last two tabs, Reality Scan, is dedicated to our Reality Scan software for photogrammetry."},{"start":"3:57","end":"4:28","startSec":237.8,"text":"I'm not going to cover in this. And Toyin Motion that we touched on a little bit in the last video. It's a paired down version of Unreal Engine. It's a lot more easy to get up and running with. Now the one that of interest to us that we're going to jump to is Library. This is going to give us a number of different sections. At the top here, we have the different installed engine versions."},{"start":"4:28","end":"5:02","startSec":268.3,"text":"I have 5.5, 5.3 and 5.6 installed at the moment. We'll probably start with none and just a button prompting you to a download version. Below that, you'll have all of the project files that can be found on the engine. And below that further, we have something that's called the FAB Library. We will touch on that as we go on. Now the first thing you're going to need is a engine version downloaded."},{"start":"5:02","end":"5:35","startSec":302.6,"text":"If I come up here, you can see that there is a plus button that as I push, it will bring up another version to install. This will give us a dropdown with all the different versions of the engine we will be capable of installing. And an install button. Next to the install button, we have another dropdown. And that's going to allow us to set it to current or go away and remove. If I was to tick install, it's going to ask us a couple of different things."},{"start":"5:35","end":"6:06","startSec":335.4,"text":"First thing it's going to do is ask us where we want this installed. What folder and path that the engine itself will be installed. Now this is not the project files themselves. The projects will be independent of this and can get quite big in themselves. Now there is the ability to browse. Below that we have options. Now I think it's worth looking at the options quickly because this is going to give you"},{"start":"6:06","end":"6:37","startSec":366.1,"text":"an idea of how large the engine is. Down here we have a download size. This is just what would be downloaded is 14.54 gigabytes. However, the required storage space once it's all installed and compressed is twice that at 38.3 gigabytes. Now the core components that are required are 33.5 gigabytes themselves."},{"start":"6:37","end":"7:09","startSec":397.6,"text":"So these are required. Without them you're not going to be able to remove them. But there are a few other options. For content I would always leave this on because this is a number of textures and effects and stuff which you can easily add to a project and use. I find it very useful but it is optional. The templates and feature packs are 3.7 gig. I would always leave that on as well. And I'll probably keep an engine source."},{"start":"7:09","end":"7:39","startSec":429.0,"text":"There are also other options for debugging. If you're working in C++ you may find this useful. We also have a number of different options here with target platforms. And I have them all turned off by default. You can see that these can get quite large. So a point 8 gig for Android Linux is coming in here at 20 gig. So you might want to turn these off if you know you're not going to be building to any of these."},{"start":"7:39","end":"8:11","startSec":459.3,"text":"All the compilation is being done elsewhere. Once you hit apply you can install the engine and it will go away and it will install the appropriate engine and you'll have a version that is brought here. Now that might take you half an hour or so depending on your speed of your internet. So do feel free to pause the video there and hit off again if you have not previously done it. Now next up let's create a project."},{"start":"8:11","end":"8:47","startSec":491.7,"text":"So I am going to hit the launch button here. And that's it. This is going to go away and fire up Unreal Engine and allow us to select our starting project. Now after you've gone away for a bit it should bring you to a screen that looks like something like this. Now we're going to ignore the recent projects and we're going to have a look down at what"},{"start":"8:47","end":"9:18","startSec":527.8,"text":"templates are available to us. The templates are broken down here by industry as I've made here. However, don't feel like you are restricted to these. We've always changed things as we go ahead. First off we have games. Now on the games you can see we have the option for a blank template. We also have a first person, third person, top down, handheld, AR, virtual reality and"},{"start":"9:18","end":"9:48","startSec":558.9,"text":"vehicles. These have functionality put together in them that allow you a good starting point. What's also interesting to see is if you look down in the settings we have first person as a main here but within variants we have a few more. We have none, an arena shooter, a survival horror or all."},{"start":"9:49","end":"10:22","startSec":589.5,"text":"What this is going to do is add in some extra functionality, some extra classes and models which will allow you to easily make one of these games. If you select none you're just going to get a very basic first person shooter with a gun and your character. Any of these are going to add in extra functionality and all is going to add everything into it. You're not limited to these, you can add these in as a later date if you need them."},{"start":"10:22","end":"10:53","startSec":622.0,"text":"The main thing that's really useful is for example in the third person characters we have a couple of variants but this is going to provide us with animations and skeletal mesh for money and Quinn which are our two default humanoid characters we can use within the engine. Now top down again is going to give us a strategic or twin stick setup."},{"start":"10:53","end":"11:33","startSec":653.4,"text":"So these are your main, sort of a quick look at the templates that are also available to us. We have one that is set up and geared for virtual production or VR scouting and we have one set up just for lighting rigs for performance and end display. This is what is often used for virtual production where we will display stuff, project stuff on tools. Within architecture we have a design configurator, a VR or desktop collaborative and a handheld"},{"start":"11:33","end":"12:08","startSec":693.0,"text":"augmented reality setup. Within automotive and product design and manufacturing again this is going to give us things like the product configurator which in this example we have a guitar but it could be used for pretty much anything and it's an application in itself where you just need to add in the different settings and plug in what you need. Finally simulation for this we have our virtual reality setup and our black simulation document."},{"start":"12:08","end":"12:42","startSec":728.7,"text":"So let's select for this we are going to go into games. We are going to select the basic third person setup. We're not going to worry about the variants in this. We're just going to go with the basic. For this we have a project location and a name. So I'm going to set this to just some defaults. And let's have a look at the different options that we have on the defaults."},{"start":"12:42","end":"13:16","startSec":762.1,"text":"We have blueprints or C++. Now blueprints is our visual scripting language which we are going to be using in this example. C++ is going to download all of the C++ code which if you are used to working with C++ is very useful. You can always convert a blueprint only project to a C++. You cannot go back in the other direction after. The target platform we are looking at is desktop. Here we are going to use desktop in this example and the quality presets we are going to set"},{"start":"13:16","end":"13:48","startSec":796.2,"text":"to maximum. Okay, after we've done this I'm going to hit the button to allow us to create this project. Well, once you've done that you should have something that looks a little bit like this. Let's talk a little bit about how an Unreal project is set up. Now in most software applications you would usually find that your project is saved to"},{"start":"13:48","end":"14:24","startSec":828.5,"text":"a singular file. So for example a Photoshop would be saved to a .psd file, Word to a .doc and Maya to a .mb. Unreal projects don't work like this. Firstly because the Unreal projects themselves can be incredibly big. Secondly, because you will often be working with something like source control and there will be numerous people working on the same projects. Therefore it is beneficial for us to be able to have all of the different files saved out"},{"start":"14:24","end":"14:56","startSec":864.9,"text":"to their own unique files. This allows us for source control to be able to lock files when one person is editing them so other people can't edit them at the same time. It also allows our projects to be moved around, move around parts of a project or parts of an asset and not have to copy the entire project. So whenever we create a file within Unreal it will create a file on your disk."},{"start":"14:56","end":"15:29","startSec":896.2,"text":"Though for example a level would be saved as a .umap file, a asset would be saved as a .umap asset. Things like a material would also be solved as a .umap asset. If you would import a model from Maya for example that too would be converted to a .umap asset and if you imported an image from Photoshop that too would be converted to a .umap asset. So this means that a project itself is going to have lots and lots of different files to"},{"start":"15:29","end":"16:05","startSec":929.6,"text":"be parts of it and they will be converted to a specific type of file which is readable and understandable by Unreal Engine. Now you will be able to see all of these files on the disk. However it is highly recommended that you never move the files around manually outside of Unreal Engine and that is because the files all have references where the references connect to each other and if you move files around outside of the engine in Windows Explorer"},{"start":"16:05","end":"16:38","startSec":965.4,"text":"for example you're going to break all of those references and your project is going to stop working basically. You can usually fix them within the project but there's a lot of work. However if you move things around within the editor it will automatically update all of the corresponding references. So that brings us to the end of the project suss up. In the next video we are going to be looking at the interface and how to navigate it."},{"start":"16:38","end":"16:38","startSec":998.0,"text":"Thank you very much."}],"03_Interface":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"Hello and welcome to this next video where we will be looking at the interface and looking at some basic controls. Now in the previous video we've created a project, I've just jumped into it here. You should be confronted with a screen that looks a little bit like this. If you've previously used it, you might get a slightly different layout, but all the elements are going to effectively be there. So let's go through the sections piece by piece."},{"start":"0:35","end":"1:06","startSec":35.6,"text":"The first thing we have up the top here is our menu bar. For this menu bar functions like most other menu bars and applications. There will be different menus that will open up and allow you control over the project. One thing that is worth noting is windows. The reason windows is specifically interesting is because if you are missing any of the other windows that we talk about, you'll find that you can switch them on or off here."},{"start":"1:06","end":"1:37","startSec":66.6,"text":"For example, if you were missing a details panel, you could come in here, tick on, and this would open up a new details panel for you. So this is just interesting because if I reference some kind of menu and you can't find it, it will usually be because it's not turned on here. The second part is across the top here. This is our tool bar. Now this is going to have a number of different selections."},{"start":"1:37","end":"2:08","startSec":97.6,"text":"The first one is save. This will save the current level. It will save the layout of the level you have in front of you to disk. It won't have anything else, so they'll just save the current level, but it will mean anything that you've moved around will be saved. It will also have browse. Now this is all over the engine as we use it. It allows us to browse within a content browser. Now if you click on it, you'll see there brings up content browser,"},{"start":"2:08","end":"2:40","startSec":128.6,"text":"and it automatically highlights, in this case, the level. So that's a good example. We'll talk about the content browser as we'll learn later on. Next up, all we have is the mode. We are at the moment in selection mode, and we will look at a couple of the other modes as we're going on. Next we have add, quickly add to the project. And what this is going to do is this is going to give us some options"},{"start":"2:40","end":"3:17","startSec":160.6,"text":"to either import, get content. It allows to brooring content in from other places, such as the fab store or Cooksville bridge, or just manually import from files. It will also allow us to place different actors within the level. An actor is a reference to anything which is in the level. For example, if I was to come up here and select a shape, sphere, you can see that it adds this sphere to all of them."},{"start":"3:17","end":"3:48","startSec":197.6,"text":"Next to that, we also have a couple of other options. We're not going to touch on these in a moment, but here we have the play button. If I was to press play, you would see that our character is generalized into the world. We are able to run the application or gain inside the editor. We'll touch on that a bit more later as well. In the center we have the viewport, and this is the visual representation of the level or world that we're working on."},{"start":"3:48","end":"4:19","startSec":228.6,"text":"We'll go over this in detail in a minute. On the right-hand side, we have the outliner. Now, what the outliner is, is a list of all of the different actors. We reference actors, but actors means anything that is inside the level. As you'll see down here, some of them have a visual element to them, some of them just exist in space. If I was to come in here and select, say for example, a cylinder,"},{"start":"4:19","end":"4:49","startSec":259.6,"text":"and if I was to press P. You would see that this cylinder has a representation in the world, and it is also as a part of the list in the outliner. This is very useful for us to be able to find and select things accordingly. Finally, down in the bottom here, we have a details panel. Now, what the details panel is, is a contextual menu."},{"start":"4:49","end":"5:22","startSec":289.6,"text":"So, say for example, I select something within the scene or the outliner. It will bring up all of the details for that selected object. Now, this again, the details panel is something which we are going to see all over the engine, all of the different menus. It's always pretty much contextual. So, whatever you have selected at any one point, it will have, it will give you the options that are connected to that."},{"start":"5:22","end":"5:52","startSec":322.6,"text":"Now, let's have a bit of a deeper dive into our viewport. Now, for the viewport, first thing you'll want to know is how to move around. And I believe these are the most common ways of moving around. If you are to hold down the right-hand mouse button, then use the W, S, A and D. W moves forward, S backwards, A and D would strafe left or right. That will allow you to move in the works."},{"start":"5:52","end":"6:23","startSec":352.6,"text":"And those will be in reference to the camera viewport. Holding down the right-hand mouse button is going to mean that you can control the viewport. I'll demonstrate that in a second. We also have two more keys that allow you to go up and down. And that is Q and E, again, with the right-hand mouse button down. But the F key will allow you to focus on a selected actor. You can see I tried that out a little bit earlier."},{"start":"6:23","end":"6:53","startSec":383.6,"text":"It allows you to jump and just focus on a single actor. Finally, we have Alt and Left Click. And this will allow you to orbit a selected actor. Let's jump into the engine and try those. So again, in this case, what I've done is I've held down the right-hand mouse button. Now you'll see as I move the mouse, I can move the angle of the camera, which is being used in the viewport."},{"start":"6:53","end":"7:31","startSec":413.6,"text":"And if I push W, I'll go forward, S backwards, A left, D right. This will allow you to navigate and move around. If you're used to playing computer games, this will feel quite natural for you. Next up, we have from holding down the right-hand mouse button. If I push Q, it will send me down. Here, that's to increase or lower the altitude of the cone."},{"start":"7:31","end":"8:01","startSec":451.6,"text":"Finally, F. Though if I was to select, say, this cylinder inside the level, whereas if I was to press F, it would frame focus on that cylinder. If I was to select something else, press F, it would move me directly. The sphere that we brought in is a really useful way to very quickly get to an object."},{"start":"8:01","end":"8:36","startSec":481.6,"text":"We also do the same thing by selecting something inside the outline, pressing F to focus. Now if we come back and focus on our sphere, I hold down in this time the left-hand's button and hold. Then as I move the mouse, I'm going to orbit that specific actor. It's going to allow me to get the correct angle I want to get from it."},{"start":"8:36","end":"9:07","startSec":516.6,"text":"Another button that's worth knowing about is the mouse wheel. It's going to allow you to zoom in and zoom out. Now when you're working on levels, levels can get quite big. And you might want to move between common places multiple times. You don't want to have to spend your whole time running around trying to find a specific angle. So for this, we have a bookmarking system."},{"start":"9:07","end":"9:41","startSec":547.6,"text":"And how a bookmarking system works is if you find a specific location, say for example, I'm viewing here, I hold down control and one. And then I also want one that views from above. Move up here and press control and two. Now if I push one, I will jump to the bookmark location and two, I will jump back to the other one. So this is a really useful way to be able to jump between different points in the engine."},{"start":"9:41","end":"10:16","startSec":581.6,"text":"So again, to reiterate that in the bookmarking system, if you just hold down the control and number key from zero to nine, you can bookmark a location and you can then push zero to nine in order to jump to that location. Because very useful as your levels get larger. Next up, let's have a look at the options that we have across the top here. So to start with, we have this element here, which is the camera speed."},{"start":"10:16","end":"10:48","startSec":616.6,"text":"This will allow you to speed up and slow down the camera as you move around the world. It is also connected to the middle mouse button. So if you hold down the right mouse button, you can scroll in order to speed up and slow down the cap. And this again is really useful if you want to get a very specific angle. You can get close by going fast."},{"start":"10:48","end":"11:18","startSec":648.6,"text":"And then you can reduce the speed so that you can get absolutely perfect. So this is the speed of the camera. We also have a couple of other options here under this dropdown. So it's going to allow us stuff like, for example, we can change the field of view, the near plane, and some of the camera options going to game view."},{"start":"11:18","end":"11:49","startSec":678.6,"text":"And right at the bottom here, we're able to take a screenshot. You'll also see that we have some orthographic options. For example, we can come into top view. Then we get something that looks like this. Now you'll notice when we move into top view or orthographic, we are locked into one axis. Well, you'll also notice that this has gone wire-free. Now it brings me to the menu that's right of this."},{"start":"11:49","end":"12:23","startSec":709.6,"text":"This gives us a number of different view mode settings. By default, we would be on lit. That's going to give us the bioframe from above like this. However, we also have pun-lit, which is just going to give us the albedo or the base color pass. Wireframe is very useful so that we can tell where objects are. We have the lit wireframe as well, which will give us a combination of the wireframe and the models beneath it."},{"start":"12:23","end":"12:58","startSec":743.6,"text":"And there are lots of other ones to look through, far too much for us to go over in this instance. You could also select bottom left, right, right, front. I'm going to go back to perspective. And that brings us to a logical point to stop or the interface. We've looked at the different windows that were connected up and we've learned how to move about. In the next video, we're going to look about bringing assets into the editor."},{"start":"13:01","end":"13:04","startSec":781.6,"text":"Thank you for watching."}],"04_ManipulatingActors":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Hello and welcome to the next video on the interface. This time we're going to look at how you can manipulate and move actors around a scene. Okay, so we're back in the editor now. And before we start moving actors around, let's add in a primitive or a shape that we can see it slightly better on. I'm gonna come over here and I'm gonna come up to the add, the quickly add to project."},{"start":"0:34","end":"1:05","startSec":34.0,"text":"I'm gonna come down and I will search for shapes. I'm gonna select the cube. That's gonna create a cube in front of me here. And I'll focus on that cube. Bye, so we have a cube. Now, you probably don't see this widget if you just come in and that's because you'd be in selection mode. If you look around, move stuff around, you can see that in selection mode, there are no widgets,"},{"start":"1:05","end":"1:37","startSec":65.9,"text":"but we do have a clear frame in order to select things. So what I'm gonna do is I'm gonna come up to the top left-hand corner here. And you can see in this, we have a blue highlighted select object. And next to it, we have another three options. So if I select the second one, which is translate, you'll now be able to see that we get this widget"},{"start":"1:37","end":"2:12","startSec":97.8,"text":"with these three axes pins. And if you'd notice down in the details panel, we have a location here. And if I was to move the location, it's going to change the location of the object. Also, if I was to change the rotation, it's gonna change the rotation too. And scale, I'll be able to scale it up and down on different axes. And that is not the easiest way to do this."},{"start":"2:12","end":"2:43","startSec":132.0,"text":"It's far easier to do it within the editor itself in the viewport. So in translation mode, you can see that I can now move the actor on any one of the specific axes. And if I was to come in closer, you can see that I have a square between two of the axes. And all this would do is you'll only move it on the two selected axes. So I'm left clicking and dragging it around."},{"start":"2:45","end":"3:16","startSec":165.1,"text":"And this is useful if you want to sort of move something on the wall or on the floor. You also select the center, which is gonna move it, it's slightly consistent with the camera itself. I don't use that very much. But that is the translate mode. It's gonna allow us to move the location of the actor itself. Next up, we have the rotate. And this is gonna give us a slightly different widget."},{"start":"3:16","end":"3:47","startSec":196.5,"text":"It's going to give us a widget still with three axes. It's gonna allow us to move it on any of these specific axes. Now it's to rotate it in space accordingly. There's not the option to select two axes within this. Turn it to normal. Final one is scale. And again, with scale, we can just select one of the specific axes, X, Y, Z."},{"start":"3:49","end":"4:21","startSec":229.9,"text":"Or we can select two by going on the triangle in the middle that allow us to scale on the lock one of the axes. Or we can select the middle, which will allow us to uniformly scale the whole thing. Now, we've manually clicked on the different select object elements here. However, that is not necessary because we have them on hotkeys. And the hotkeys will be the first four buttons"},{"start":"4:21","end":"4:52","startSec":261.8,"text":"in the top left-hand corner of a QWERTY keyboard. So Q is selection mode, W is translate, E is rotate and R is scale. So you can quickly slip between these by just clicking on the buttons. So just to reiterate there, in order to move them around, the Q will give us the just select object, W will give us the translate,"},{"start":"4:52","end":"5:23","startSec":292.6,"text":"E will give us the rotate and R would give us the rotate. And R would give us the scale. Next up, let's have a look at these three buttons on top. You may have noticed, as I've been moving things, it's very hard to see, that they are moving in increments. So the moment I have this set of things,"},{"start":"5:23","end":"5:52","startSec":323.0,"text":"they're snapping in increments. Increments start off as quite small, so it's a little bit hard to see, but if I was to use the drop down here and select a larger increment, you'd see that it is snapping in a larger increment. Now we have three of these, one for translation, rotation and scale. And you can see next to each of them, we have a drop down that determines our increments."},{"start":"5:53","end":"6:25","startSec":353.0,"text":"So I would, if I can come into this, I've set it to 60 increments, so for rotation, you'd see that it rotates in large increments like this. And for scale, I'm gonna set it to one, so if we were to change the scale, it's going to move up in quite large increments. Now you might not always want this, so if you want to turn this off, you can just click on any of these."},{"start":"6:25","end":"6:56","startSec":385.0,"text":"The moment they're highlighted as on, because they're in blue, if I was to turn them off, for example, let's do that on rotation, now we can freely rotate. Come that's exactly the same for scale and translation. So that is snapping. The increments are below, you can go into edit to preferences and change the increments if you specifically need them."},{"start":"6:56","end":"7:27","startSec":416.1,"text":"We're talking about translation, the unreal units are centimeters. Another hot key that's worth knowing is if I was to grab this and press the end key, that's going to drop it to the ground. So it just uses the collision to figure out where things are or drop it to the ground at that point."},{"start":"7:29","end":"7:59","startSec":449.5,"text":"Now we have looked at adding actors to your scene by using the add button in the top left hand corner. And in the next video, we're going to be looking at using the content browser. However, there is one other method that I'd like to bring up whilst I'm here. And that is if you were to hold down the alt P whilst moving or changing the transform of an object,"},{"start":"8:00","end":"8:32","startSec":480.0,"text":"rather than changing the translation of the object, it is going to duplicate the actor itself. And this tends to be one of the quickest ways to add an extra actor, especially if you already have one in scene. It's a very quick way. And you can see this will work for Penny or the, or any of the actors that exist in the scene, even if they are not static meshes that we have at this point. Okay, and that brings us to the end of our interface section"},{"start":"8:32","end":"8:41","startSec":512.3,"text":"on manipulating actors within the scene. In the next video, we're going to look at using the content browser."}],"05_ContentBrowser":[{"start":"0:00","end":"0:37","startSec":0.0,"text":"Hello and welcome to this next video, only interface series and we're going to be looking at the content browse. Right, so we're back into the editor and up to this point we have been either using the actors that were already in the scene or we have been using the quickly add to project button in the top here. Now for this I would like to concentrate on the content browser. Now the content browser can be accessed across the engine by holding down control and space"},{"start":"0:37","end":"1:08","startSec":37.0,"text":"bar. What that's going to do is that will bring up the content browser here. Now I use the content browser a lot so I am going to click on the dock in layout and what this is going to mean is the content browser is now added to the screen here. If you don't like it in this location you can always drag up and place things in different places. You can do that with all of the windows but I'm used to it being in the bottom of the"},{"start":"1:08","end":"1:42","startSec":68.8,"text":"screen like this sort of throwback to previous versions of Unreal. So the content browser is our file navigation system much like Windows Explorer on the windows it's going to allow us to look into different folders and see what files are there. Now at any point for example with this MI third person call way this is a material by right hand click you can see I can actually come over and see this file in Explorer."},{"start":"1:42","end":"2:19","startSec":102.5,"text":"Let's go show in Explorer and we can access and see the U asset files in the Windows Explorer. Again I want to iterate to not move files around within the Windows Explorer it will work. What it will do is break any references that connect to that asset. Okay so let's talk about the content browser on the left hand side here we have our breakdown"},{"start":"2:19","end":"2:51","startSec":139.7,"text":"of the file system we can move through it much similar to your normal file system and on the right hand side we have what is actually in our file system. Again you can double click on any of them and you can also double click to open up any of the assets. So in this case I've opened up the third person character which we haven't really touched on how these work at this point but that is a blueprint that I've opened up."},{"start":"2:51","end":"3:22","startSec":171.0,"text":"Now there are a couple of things which are useful to know in order to navigate easily around this. The first thing is if I was to select something within the world for example how the cube and I was to press control B that will navigate to that object in the browser. The control B at any point will navigate to the specific asset in the browser so that you can find it."},{"start":"3:22","end":"3:57","startSec":202.1,"text":"And this is really useful because at any point we can take an asset and drag it into the world and that will create an equivalent actor if possible. In this case these are static meshes which are models and if I was to drag one into the world it's actually going to create a static mesh actor with the values of the static mesh being set to the mesh that we've identified and the materials of the default material"},{"start":"3:57","end":"4:35","startSec":237.5,"text":"on this asset. Delete that and go a little bit just per cushion the delete button. However some of these function differently. For example if we go back to our content directory and we had somewhere in here we had a we in the third person we had this material which is the third person cover Y. You can see this is the color which is used on all of these assets. Now this is not a static mesh and it's a material so that means it will dictate how a static"},{"start":"4:35","end":"5:09","startSec":275.9,"text":"mesh looks. Now in this case if I was to drag it in it would not create an actor but what it would do is it would detect under the mouse cursor what the static mesh is and attempt to apply the material to it. So you can see in this case it's applied that material to the static mesh that we're using is the floor. I'm going to press control Z and that will undo the assigned."},{"start":"5:09","end":"5:41","startSec":309.8,"text":"So they're quite clever. When we drag in an asset it will know what kind of asset you're dragging in and it's going to try and apply it to the world in the most logical way. So material would apply a material a static mesh would create a static mesh actor and if we were to go back and into our third person character blueprint is going to spawn an instance"},{"start":"5:41","end":"6:13","startSec":341.8,"text":"of the blueprint into the world like we have here. So third person character. So just by dragging stuff into the world that's going to make sense. Now there are some things that don't necessarily make sense such as a game mode so that wouldn't happen with everything. Okay so that's dragging things into the world and that's referred to as making an instance of the blueprint."},{"start":"6:13","end":"6:43","startSec":373.2,"text":"Now as your project becomes more complicated it might be worth knowing some more advanced methods of navigating your content system. So the first one is filters. As you can see here in the top left hand corner there is an open or add filters menu. If you jump this down or this is going to do if I go to the content directory it's going to allow us for example to select on a filter for static meshes."},{"start":"6:43","end":"7:13","startSec":403.4,"text":"So now this is going to show me all of the static meshes which are below the content directory and you'll also see that we get an extra window here for filters so I can turn this on and off. And for example if I wanted materials it's going to show me just the materials which are below my content directory and there are and you can do that for any any clients where you can create a custom filter."},{"start":"7:13","end":"7:48","startSec":433.8,"text":"Next up would be favorites. At the moment here you can see we have a favorite section at the top and if we know there is a directory which we're going to come back to a lot such as blueprints I could come in right hand click on the directory go add to favorites. Now we'll find under favorites and we'll be able to see the blue pinched direction allowing us to find it quick. Also to reinforce that if we were looking for if we had a group of them you can set the"},{"start":"7:48","end":"8:20","startSec":468.3,"text":"folders to be a specific color. In this case I'm going to set my blueprints directory to below and now it's easy to see particular. Finally we have collections. Now if you come down to the bottom here what a collection is is it's going to allow us to tag all of the assets with a specific value and then we're going to be able to filter and see a collection of just the assets that we've tapped."},{"start":"8:20","end":"8:56","startSec":500.5,"text":"So for example if I wanted to have if I added a collection and I had a local collection I'm going to call this meshes. Now if I wanted to come in I'll select the static meshes and I'm going to drag into the directory all of the meshes which are designed to put together a environment. And now I can select that and it will just give me these meshes and I can then drag into"},{"start":"8:56","end":"9:35","startSec":536.6,"text":"the world. To reiterate what we've covered here you've got favorite directories that are going to be assembled out moving to a different area. You've got the directory colors to allow you to quickly see them in the browser. Collections this allows you to tag different assets and then view only those tagged assets. We've got the filtering system which is going to allow you to filter on different terms usually the type of asset and that will bring us to the end of our video."},{"start":"9:35","end":"9:36","startSec":575.8,"text":"See you in the next one."}],"06_PlayModes":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Hello and welcome to the last video in about interfaces. And in this, I'm just going to be going into a little bit more detail about the play option in the editor. Okay, so here we are back in the editor, and I have added in three cubes, which are set to rotate. Don't worry about too much about how I've done it. It's just so that we can see when the game is running and when it is not."},{"start":"0:32","end":"1:04","startSec":32.7,"text":"Now what I want to look at is the different play options that we have. So you can see up here with our standard play, if we were to hit normal play, here would default at the moment to playing it within the editor window. Now I could push F11 to make this full screen. That's fine, it just runs within the editor window. Now if I press escape, that's going to bring me out of it."},{"start":"1:04","end":"1:38","startSec":64.1,"text":"Now it's set to play an editor, but we have a couple of options. So first option that we have is still play an editor, and that's what play means, but it will do it in a separate window. And this is useful if you want it running, so that you can make changes next to it. It's exactly the same thing. And again, escape will let you come out of it. And you'll see that this has now changed the default to be playing a new window. As we swap between the models, they will sit as a default."},{"start":"1:38","end":"2:12","startSec":98.4,"text":"The next one that I want to look at is a standalone game. And this is interesting because what it does is it fires up as if it was a compiled packaged game. Now it obviously won't be as compiled as if it had gone through the packaging, but you can see it had to load the shaders there. And this runs independently. Now in this case, escape will not work, because that's an editor function."},{"start":"2:12","end":"2:45","startSec":132.0,"text":"Escape within the actual game is going to be something you'd have to code in yourself. So I'm just going to manually kill it. Now the final option I want you to be aware of is called simulate. And what simulate does is it will not spawn the pawn that you have attached to the game. It'll actually spawn something called a spectator pawn. And this is going to allow you to move around the world and see how the games function it."},{"start":"2:45","end":"3:16","startSec":165.2,"text":"So if you have things like NPCs, they would run around, but it'll allow you to just check and see what's going on without having to be spawned as a character. And that's really useful. You'll also have this option here where you can press F8. All that it's going to do is that's going to now spawn the character and allow you to move around. So those are your main options. So just to clarify that, we have a number of options here."},{"start":"3:16","end":"3:51","startSec":196.6,"text":"You have the selected viewport, which is the default one. The new editor window is going to create a new editor window and still allow you to see this viewport behind it. Standalone game, which runs it as a separate app. And finally, we have simulate, which will play in the editor with a spectator pawn for free movement. Also, I just want to iterate some of the hotkeys. If you press Alt plus P, it will start the play mode that you have selected."},{"start":"3:51","end":"4:17","startSec":231.7,"text":"Here in time. If you press F8, it will switch between the spectator pawn and the player pawn. And finally, escape is going to end. This will only work in the editor play modes. And with that, that will bring us to the end of the interface sections. We can now move on to have a look at importing assets into Unreal."}],"07_Import1":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Hello and welcome to this video on importing assets. For this we're going to be going over the different ways that we can get assets into Unreal Engine. Well, there are multiple different ways to get assets into Unreal Engine and we're not going to be going over each of them in depth. We'll only do the main ones but I'll just mention them here so that you are aware of them for future research."},{"start":"0:32","end":"1:02","startSec":32.4,"text":"So first of all there's manual importing and we're going to be demonstrating this with an FBX former file that you might get from Blender or Maya or some other software. Also there is the fab integration. Fab is our asset and art store. This has a ton of different assets available in it and Unreal is heavily integrated into it."},{"start":"1:02","end":"1:38","startSec":62.6,"text":"So it's really straightforward to buy assets or get assets from the store and then just import them directly into projects. Datasmith. Now Datasmith we will not be going over in this. Datasmith is a tool designed for primarily people like architects where rather than importing in a singular asset such as a car or a character or something you would import an entire scene"},{"start":"1:38","end":"2:12","startSec":98.5,"text":"and you'd want to be able to keep the settings of the scene like where all the lights are and where all the different assets are placed in their transforms. So it's really useful for workflow where you're building your scenes in another asset and you want to import them into Unreal. We'll be touching on migration and just as a concept really but if you want to move files between projects, migration allows you to move them across and keep all of the references"},{"start":"2:12","end":"2:44","startSec":132.1,"text":"intact so that they work when you when you've imported. Finally Quixel. Quixel is a service that we have where we have photo, geometry, high res models and textures. Now these are all pretty much integrated now with the fab store. However, before we do this, let's talk about something that's called plugins. Now plugins are a method of adding things to a project."},{"start":"2:44","end":"3:18","startSec":164.4,"text":"Now when you set up a project and you pick a template, a number of different plugins are automatically going to be enabled and placed into that project. Now there are a bunch which are very, very standard and there are a bunch that are a lot more niche. Unreal has a ton of different plugins that are available, but you can also get lots of other plugins from the stores or you can create your own plugins in order as a method"},{"start":"3:18","end":"3:48","startSec":198.7,"text":"to easily transfer things between projects. So let's jump into the engine here and see how you might go about adding a plugin to a project. If I was to come up to the edit window, you can see at the bottom here we have an option for plugins. If I click on that, it's going to give me a list of all of the different plugins which are available in your version of the engine."},{"start":"3:48","end":"4:23","startSec":228.8,"text":"Now some of them will be selected and ticked on as you can see here. However, there are a ton more which are not selected. Now if I was, for example, to type in Niagara, Niagara is our article system which has a whole load of different great elements that are part of it. You can see that there are a load of plugins which are specific to Niagara."},{"start":"4:23","end":"4:54","startSec":263.8,"text":"Niagara itself is usually turned on by default, it's used a lot in the engine. There is also one here called Niagara Fluids. If I was to tick that, it would warn me that this is in a beta version. Now what Unreal will do is they will release all of the plugins and all of the different functionality usually first in a beta version. Don't let beta turn you off too much because you're going to find that a lot of the engine"},{"start":"4:54","end":"5:28","startSec":294.8,"text":"is perpetually in beta. A hell of a lot of this is stuff that we're already shipping in games such as Fortnite. So don't just ignore things because they're in the beta. I'm going to click Yes and at the bottom here it's going to ask me to restart. So I will restart and now this is restarted back up. I'm going to close this down. It took me a little bit of time to find it but I've navigated to the plugin Niagara"},{"start":"5:28","end":"6:00","startSec":328.4,"text":"Fluid content. It's got a couple of templates here. So I'm going to drag this into the world. Now you can now see that we have a fluid simulation going on inside the world. Now I was just giving this as a demonstration of how you can use a plugin in order to get extra functionality or to add in different assets into your C."},{"start":"6:00","end":"6:31","startSec":360.6,"text":"That's just one of the examples that come with it. Now you may find in the Fudge Store when we come to that that there will be asset packs which are offered as plugins. And what it will allow you to do is download them and add them to your engine version and then they will be available in the list of plugins. Next up we have add feature or content pack."},{"start":"6:31","end":"7:05","startSec":391.8,"text":"Now this is useful because all of the different templates have different features and content packs and these are available to be added to any other project. So let me show you. So at the moment we are in the third person template. Now the third person template doesn't have any guns in it. They say I wanted to bring in a gun. I know that one exists in the first person."},{"start":"7:05","end":"7:39","startSec":425.1,"text":"If I come up to add and come up to add feature or content pack you can now see that I could come over to the first person template and I could add this to the project. We have a couple other options as well. Here is the start of content. If you didn't select the start of content at the beginning you always add it to a project here. If I add the first person add to the project. So it's going to import the directory for the first person."},{"start":"7:39","end":"8:10","startSec":459.8,"text":"Now you can see I've got the first person as a directory and inside of the blueprints we have my search for weapon. You can see that we now have a whole load of different options when it comes to weapons. So for example I've got the grenade launcher. I can just drag into the scene."},{"start":"8:10","end":"8:42","startSec":490.5,"text":"That's going to bring that. It will also bring everything else that comes with it. So we'll have a whole load of combinations that can be used for shooting and a whole load of other special effects that are specific to the first person. Our next option is to add content and add. Now add is our store and I'm just going to show you quickly how you would go about adding the content."},{"start":"8:42","end":"9:17","startSec":522.9,"text":"Now I'm back in the epic launcher and if you scroll down at the bottom of it you're going to find something that says fablib. These are all of the different tracks that I have acquired from the fab store over the years. If I click to visit the fab store it's going to bring me to a store that looks like this. Now I have connected this to my epic account and at any point I can now come in here and"},{"start":"9:17","end":"9:48","startSec":557.7,"text":"I can purchase or search for stuff. You'll find that we don't just offer for Unreal Engine but we also offer it for Unity and Unreal Editor for Fortnite. Everything is broken down like you do in a standard asset shop. You can see things by categories or by specific channels. Now you'll find that at any one point we usually have a number of assets for free."},{"start":"9:48","end":"10:21","startSec":588.8,"text":"At the moment we have the warehouse environment, where Wolf and the spine plug-in that could all be purchased for free. These are already in my library as you can see. However, there are a ton of stuff that is permanently free on here and so if I was to come into Unreal Engine, verify the look for 3D models. I can sort by price. I can just select free."},{"start":"10:21","end":"10:56","startSec":621.4,"text":"This is going to provide me with a whole load of free assets. Now these are permanently free. Some of them are from Epic but there are a ton of them here. So it's a great place to start. Once you've purchased one of these, once you've grabbed one, you've chosen, you've added it to your library, you'll then find that it appears within the launcher. So once you've purchased it and it shows up in your launcher, you can refresh to get"},{"start":"10:56","end":"11:29","startSec":656.4,"text":"any new items that are coming in. There is going to be a list that looks something like this. Now you'll notice that on these yellow buttons, there are a couple of different options. There is either the add to a project, there is create a project, or there is install into the engine. Now if, for example, something that requires creating a project, this needs to create its own project, you'll then need to migrate the assets that you want over into the project"},{"start":"11:29","end":"12:05","startSec":689.8,"text":"that you're looking at. We'll show you quickly how to do that. But if it says add to a project, so for example, I have a blank and a dash of the effects in this one, this is compatible with our version of the engine. I'm going to select add to a project, like in first project, add to the project. And you can see that it is going to add it in here. Now bear in mind, if you can see that it has this little yellow element here, that means"},{"start":"12:05","end":"12:38","startSec":725.3,"text":"it's downloaded onto your computer. You can see that my entire FAB library is 58 dig. So you have to be careful. If you don't want one, you can just remove the local content, but it can get big. So now that I've imported it, you can see that we have a blank and dash of the effects. If I jump in here, I can add the effect to the level. Yeah, see that effect is already there."},{"start":"12:38","end":"13:00","startSec":758.8,"text":"So it's as quick as that. You can just really quickly just add in effects from the store. Just a question of downloading it and dragging it in and all of the assets of that. That brings us to the end of our first session on importing assets. Next up, we're going to go over the other methods you can use."}],"08_Import2":[{"start":"0:00","end":"0:37","startSec":0.0,"text":"Hello and welcome to the second video in the importing asset section. In this, we will be importing a file from an FBX. And we will be looking at how you'd go about migrating something from one project to another. Right, let's look at importing into a project via the file. For this, we are going to use an FBX. This is a common format that you would be able to output from something like Maya or Blender."},{"start":"0:37","end":"1:10","startSec":37.8,"text":"So what I'm going to do is I'm going to start off by opening a new file. So I'm going to call this Robot. It's going to be importing a skeletal match for one of our asset packs. Now, I've got a couple of different options. But the one I'm going to use here is the import. If I push import, it's immediately going to jump me into the file explorer, asking me to find where the files are to be imported."},{"start":"1:10","end":"1:45","startSec":70.3,"text":"Now, you're only going to be able to see in this files, which Unreal understands as important. You can see in this directory, all I have is three PNGs. If I was to select one of these, it would import it as a texture. And a SK underscore bot, which is a 3D object and is of type FBX. FBX is supported by default. However, there are other versions with plugins you can get the engine to work with."},{"start":"1:45","end":"2:19","startSec":105.7,"text":"So I'm now going to select OK. And it's going to bring me up a huge amount of options. And now I know that these options work, so I'm not going to mess around with them. But you can probably find stuff that would work with your pipeline. So I'm just going to hit import. And see importing down here. And then suddenly we've got everything in already."},{"start":"2:19","end":"2:51","startSec":139.4,"text":"Now, if I was to drag in our little character here, and see that it's in the engine, all right, I'm going to push the G button. I haven't mentioned this yet, but that puts us in game mode. And that will turn off any of the widgets that we have. So you can see how something would look when it's in game mode. And that is working great. I can even open up the material and see that all of the textures and stuff are connected up."},{"start":"2:51","end":"3:24","startSec":171.0,"text":"So it really is quite straightforward, as long as you're using some of the default ones. It's just a question of finding the file and importing them. You may find that the preparation for a clean import is a little bit harder, especially when it comes to materials, because different engines work with materials in different works. We will touch on that as we go on. You also find that you can import animations in the same way and apply them to specific skeletal measures."},{"start":"3:24","end":"3:55","startSec":204.5,"text":"So that really is the basics of importing from a file. OK, let's talk about migration. So that is moving elements from one project to another. Now, out of the moment, I jumped into another project here, and I have a mesh from our Quixel collection. And this is a tree. And what I want to do is move that into the project that we are working. So this is how I would go about that."},{"start":"3:55","end":"4:28","startSec":236.0,"text":"First thing I would do is I would right-hand click and under asset actions, I would select migrate. It asked me to save the level. And what it's going to do then is it's going to go away and find all of the different dependencies, which would be required in order to get this model to work in the new project. And it's to be noted, I'm on the same version of the engine, which makes this a lot easier, makes everything comply."},{"start":"4:28","end":"5:01","startSec":268.8,"text":"Now, what I'm going to do is I'm going to go OK. And then I'm going to the first project and the content directory. And I'm going to select that. Now, we're looking to move things into a content directory because otherwise it isn't going to all of the references route from a content directory. So in this case, it needs to be in the content. And select the folder. Now it's going to go away and migrate all those different assets and validate them."},{"start":"5:03","end":"5:33","startSec":303.6,"text":"So here we are back in our original project. And you can now see that we have this asset directory. And within the meshes, we have my tree. I drag this in and take a second for it to be compiled. Well, Hey, Presto, the tree is now in the new project,"},{"start":"5:34","end":"5:50","startSec":334.5,"text":"along with all of its dependencies. OK, and with that, it brings us to the end of our foundation, sort of importing assets into Unreal Engine. Thank you very much."}],"09_Modes":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Hello and welcome to this video on the different modes which are available within Unreal Engine. We're just going to be looking at a couple of them quickly so that you're aware of them. If you want to learn more, there are other courses which cover them in detail. Now to change mode, you'll see that there is a drop-down in the top left-hand corner of the editor. This will allow you to either select the mode manually or it will show you the hotkeys required"},{"start":"0:34","end":"1:07","startSec":34.7,"text":"to jump to this mode. And that's Shift plus one of the number keys. By default, you will be in the selection mode. This is what will allow you to manually select and move items around. Next up, we have Landscape. Now the landscape mode is designed so that we can create a large mesh for the landscape. It will be divided into different segments."},{"start":"1:07","end":"1:37","startSec":67.4,"text":"When you first load it up, you're going to see this wireframe green grid. They will indicate the size of the landscape that you are about to make. Now you can either generate this from a height map by importing a file or you can just change the settings and create the landscape yourself. Now I'm going to hit the Create button to create it. And that will then create the mesh. And we'll see where the cursor is."},{"start":"1:37","end":"2:13","startSec":98.0,"text":"We now have a blush. You'll see that we come onto the center tab. It's part of it that's called Sculpt. This will allow me to use the left-hand mouse button to sculpt the landscape. I can hold down Shift and that will make the landscape go down. It will allow me to create a landscape. There are also a number of other brushes that are available to you. For example, erosion. This will try and simulate physics to how mountains would erode over time,"},{"start":"2:13","end":"2:47","startSec":133.3,"text":"giving you a more realistic look. That looks quite good. Now there's only so far you can go with sculpting the landscape before you're going to need a material to be attached to it. So I have a very simple material already set up in this example. So I'm just going to add that. Now I'm going to come onto the third tab for Paint. And it has the material applied. So I'm going to go create layers from the assigned material."},{"start":"2:47","end":"3:17","startSec":167.2,"text":"And I have to also create some supporting files. So this gives me two different layers which I can now paint with. So for example, I have a very simple grass which I'm going to cover most of this with. And I could also paint in a mud layer."},{"start":"3:17","end":"3:47","startSec":197.8,"text":"So we create a muddy section down the center here. Now this is very simple. Good landscape materials would look a lot better. This just sort of demonstrates the workflow. So that is landscape. It allows us to sculpt a landscape and gives us the option to paint it inside the texture. To complement landscape, we have the foliage tool."},{"start":"3:48","end":"4:17","startSec":228.2,"text":"Now what the foliage tool does is rather than in selection where you manually place a static mesh actor, the foliage allows you to paint foliage onto a landscape. So you can paint multiple meshes and they'll use something called static mesh instances. Which are more optimized than a static mesh. As far as demonstrating this quickly by one that I previously made using the trees."},{"start":"4:18","end":"4:51","startSec":258.6,"text":"And select that, you can now see that I can paint the trees onto our landscape just by using a brush. This is a lot quicker and more optimized and manually inserted. Next up, I'd like to have a look at the modeling tool. And what the modeling tool does is this gives us functionality within the engine that you would expect to find in a modeling program such as Maya or Blender."},{"start":"4:52","end":"5:27","startSec":292.9,"text":"Now we can create meshes. We can change their UVs. We can bake textures. We can remesh them and do a lot of things inside here. It is a quick demonstration. This I've created a box. And I'm coming into the modeling tool. Select the main face and then select insert will allow me to create an insert except."},{"start":"5:28","end":"6:02","startSec":328.9,"text":"And now I'm going to extrude the middle, push in and accept that. So now I have created a mesh box which is has an inside open. But just shows you how you can quickly create models or adapt models inside of the engine. Next up, I'd like to show you the fracture tool. Well, what this is is this works with our physics engine called chaos"},{"start":"6:03","end":"6:33","startSec":363.3,"text":"that allows us to do things like destroy boxes and create realistic explosions and build some things. So let me quickly look at this. So what I'm going to do is I've selected the box. I'm going to add new geometry collection. And I'm going to then fracture this geometry collection like this. Push fracture and see if I push change the explosion amount."},{"start":"6:33","end":"6:54","startSec":393.4,"text":"We can see how this is going to smash up. So we've got our fractured box. I'm now going to just drag this higher up, rotate it slightly on one edge. I'm going to select the geometry collection."},{"start":"7:03","end":"7:34","startSec":423.5,"text":"Change the damage threshold so it's very low. So you can see that this box has broken as it's broken. Now again, this can get a lot more complicated and you can make a lot more impressive explosions and destruction that it all comes under that mode for fracture. The other modes that we haven't touched on include mesh paint."},{"start":"7:35","end":"8:06","startSec":455.0,"text":"Mesh paint allows us to paint onto a mesh into the vertex data and then use that within materials. Brush editing. This is useful for gray boxing out level. And animation. So this mode gives us some supporting tools to use with our sequencer model that will allow us to do things like this. That will allow us to create and bake out animations. Thank you for sticking with us there."},{"start":"8:07","end":"8:17","startSec":487.0,"text":"Those recovered all of the modes. In our next video, we're going to be looking at some of the other features that are offered inside Unreal Engine."}],"10_Features":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Hello, and welcome to the last video in this course. For this, we're just going to be going over some final points to sort of round out your understanding of the engine and to give you a good idea of what your next steps or what you would like to learn about next is to fit your personal workflow. So for this, I'd like to start with coding. Unreal Engine works with a number of different languages when it comes to coding, but the"},{"start":"0:31","end":"1:02","startSec":31.3,"text":"main two are C++ and our visual scripting language, Blueprints. Unreal Engine is built in C++. It is a very fast and powerful programming language, and it allows you to organize your code into a reusable component, which is excellent for optimizing things like game performance. Underneath Unreal is built in this language, but it is not a necessity to learn this in order to use Unreal Engine."},{"start":"1:02","end":"1:36","startSec":62.9,"text":"That's where Blueprints goes in, so we're going to talk about. As we mentioned, when creating a project, you can select it to be an either Blueprints or C++. It doesn't matter terribly, but if you're in C++, you are going to have to work with an IE, such as Visual Studio. So C++, very powerful, compiles down to be very fast, but it is a complicated programming language and there is a bit of a barrier to entry that you have to learn how to program."},{"start":"1:36","end":"2:07","startSec":96.1,"text":"It also isn't directly in the editor, which means once you compile something, you're still going to have to go back into the editor in order to implement its usage. Blueprints are our visual scripting language. This was added to the engine quite a while ago. When it was clear on computer games, you tend to have a lot of creative, non-coding people, stuff like level designers and artists, that you would still like to expose some of the"},{"start":"2:07","end":"2:41","startSec":127.3,"text":"power of the code to. It is in a visual plug and play setup, allowing you to place nodes down, and it is much quicker to learn and to get up and rolling. As far as powerful, it does actually compile down to be C++, so when a program is packaged, it can be pretty much as fast and it's often not the coding which will be your bottleneck. But the other excellent thing about this is because it's in editor, it's very quick to"},{"start":"2:41","end":"3:12","startSec":161.7,"text":"make code changes and see them reflected within the editor sort of immediately, which is great for an artist's workflow, even though it might not be as fast as C++. It is fast enough that many, many computer games have been released almost entirely in Blueprints, so it is powerful enough for you to release something as a program. Just going to show this in the engine quickly."},{"start":"3:12","end":"3:42","startSec":192.7,"text":"As you can see here, I've got a third person character. If I drag this into the world, it looks like this. If I was to also open this up, who would open up and it would show us the Blueprint coding language here. So we can see that it has a number of functions such as being able to jump when a specific key is being pushed. And so this is where we would find it in something that's called an actor or a Blueprint."},{"start":"3:42","end":"4:13","startSec":222.9,"text":"Of course, but we can also find that we have an equivalent in the level Blueprint. So this would allow us to code stuff into a specific level. Or we could find them all across the engine. Most of the elements of the engine have Blueprints attached to them. And this is why it is something that's really important to learn. Even if you are not a coder, it is worth knowing the basics of Blueprints because it really"},{"start":"4:13","end":"4:49","startSec":253.0,"text":"can be a force multiplier on whatever your workflow it is from animation to rendering to materials. Blueprints touch almost every part of the engine. Even though it is a coding language, I do recommend you learn a little bit of it. It's easier than you'd imagine. And it is incredibly powerful no matter what your role is. Next up, we have Sequencer. Now Sequencer allows us to use a timeline to control what's going on within the engine."},{"start":"4:49","end":"5:20","startSec":289.6,"text":"Now this is most commonly used for things such as cinematics or rendering out animations. But it can be used for a lot of different things within the engine. And it's whenever you want something to be controlled over a timeline. As a quick demonstration of how Sequencer would work, there is a flapper board icon pop on the toolbar here. I always press that and select Add a Level Sequence."},{"start":"5:20","end":"5:51","startSec":320.3,"text":"It's going to ask me to save something. But after I do that, it will bring up a Sequence panel like this. Now if there was to find a Skeletal Mesh, I'm just going to search for Skeletal Mesh. And I'm going to bring him the Manny and rotate him to place the camera."},{"start":"5:51","end":"6:19","startSec":351.2,"text":"I was to go back to my Sequence and add him, selection from Content Browser. You can see that we would get something that's called the Control Rig Rotom. This is something that needs to be set up. But it allows me to do stuff such as very simple animations. And I can get a lot better. And see if I start with the arm in the air here."},{"start":"6:30","end":"7:04","startSec":390.3,"text":"Can I just key that? And then I will key it again over here. And in the middle, I'll move his arm to the other side and key that. And now you can see we've got a very simple straightforward animation. I'm just doing that quickly to sort of demonstrate what it does. You can also add cameras in and then you can use the Movie Rendering Queue to render stuff out."},{"start":"7:04","end":"7:36","startSec":424.9,"text":"And the system gets incredibly complicated with different shots and stuff like that. So it's very powerful. But this just gives you an idea of if you are looking to generate animations, you really want to learn about Sequencer. And that's where you're going to get that from. Finally, I'd like to talk about Materials. So Unreal runs with a PBR workbook,"},{"start":"7:36","end":"8:08","startSec":456.2,"text":"which means we do something that's called physical-based rendering. You try and discern how light would interact with the surface so that we can create something as realistic as possible. Now, we create Materials. And this is very similar to how it is done in a lot of other programs. As you can see here, I have filtered the Content Browser by Materials. If I just drag them in, lay some on here,"},{"start":"8:08","end":"8:39","startSec":488.3,"text":"you can see that we get a very different effect dependent on what material is added to our mesh. Now, if I was to open up one of these Materials, this would show us an example of a Material Graph. But the main thing to know about a Material Graph is we have the Output here, where what is plugged in to any of these settings"},{"start":"8:39","end":"9:09","startSec":519.0,"text":"is going to determine how it looks. So for example, we have the Base Color is going to determine the color. Roughness is going to determine how much light is diffused off of a surface. So lower a Roughness, the more reflective it is, emissive will make it grow. Normal is going to fake geometry to add sort of shadow and elements to something where we don't have the geometry. And there are a number of other ones here."},{"start":"9:09","end":"9:42","startSec":549.8,"text":"We are able to change the Material domain, Blend Options and a whole load of other different elements. But in this case, we are plugging textures into the Output, which would then be stretched across the Material based on how we use it in the coordinates. And this same workflow can be used for post-process Materials, for magic effects, numerous different elements."},{"start":"9:42","end":"10:07","startSec":582.0,"text":"But again, if you're a technical artist or working Materials, this would be where you'd go to put together your Materials. And with that, we have come to the end of our course. Hopefully that has given you a good foundation and allowed you to know what sort of things you would like to go into more depth into. Thank you very much."}]},"100.03":{"01_FirstProjectInUnreal_Intro":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Greetings everybody, my name is Sam Diter and I'm a senior Unreal Engine instructor with Epic Games. In the following video tutorial series, we're going to be taking a look at creating your first Unreal Engine project for games. And what that is going to entail is we're first going to take a look at Unreal Engine 5, just a quick recap, by looking at the user interface, viewport navigation, and working with actors, just to refresh us on how these systems work as we're going to be using them to create some new levels."},{"start":"0:32","end":"1:06","startSec":32.0,"text":"Which brings us to the next part of this tutorial series, levels. We're then going to talk about level concepts and how we create levels, as levels are a key component of any Unreal Engine 5 project. Then we're going to move on to the exercise portion or the hands-on portion of this. This is going to entail us first taking a look at the project we're going to be working with. We're then going to look at how we set up an initial level. Then we'll take a look and add some actors to that level. We'll then add some visual effects as well as some background props to really bring the level to life."},{"start":"1:06","end":"1:26","startSec":66.0,"text":"Then once we're done with all of that, we'll go over how we can publish this level to windows, so that when we're done we have an executable that can be given to anyone that can play our project. We've got a lot to cover, so let's go ahead and get started with our Unreal Engine 5 recap."}],"01_TOC":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Greetings everybody, my name is Sam Dider and I'm a senior Unreal Engine instructor with Epic Games. In the following video tutorial series, we're going to be taking a look at creating your first Unreal Engine project for games. And what that is going to entail is we're first going to take a look at Unreal Engine 5, just a quick recap, by looking at the user interface, viewport navigation, and working with actors, just to refresh us on how these systems work as we're going to be using them to create some new levels."},{"start":"0:32","end":"1:06","startSec":32.0,"text":"Which brings us to the next part of this tutorial series, levels. We're then going to talk about level concepts and how we create levels, as levels are a key component of any Unreal Engine 5 project. Then we're going to move on to the exercise portion or the hands-on portion of this. This is going to entail us first taking a look at the project we're going to be working with. We're then going to look at how we set up an initial level. Then we'll take a look and add some actors to that level. We'll then add some visual effects as well as some background props to really bring the level to life."},{"start":"1:06","end":"1:26","startSec":66.0,"text":"Then once we're done with all of that, we'll go over how we can publish this level to windows, so that when we're done we have an executable that can be given to anyone that can play our project. We've got a lot to cover, so let's go ahead and get started with our Unreal Engine 5 recap."}],"02_FirstProjectInUnreal_ReCap":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"So before we go any further, I want to have a real quick recap of Unreal Engine 5 just to interface, movement, and what actors are just so that we're all familiar with different terms and things like that. So let's go ahead and just take a look at the user interface. So across the top here, we have our file menu. So this is going to be the same file menu that we see throughout the editor. We're going to access things like editing new levels or creating new levels for us to"},{"start":"0:34","end":"1:07","startSec":34.9,"text":"edit from up there. We're going to look at things like documentation reference, project settings, editor settings, and things like that. Now two is going to be our main toolbar. This is we're going to be creating new types of content or actors to add to our levels. We can also adjust our tool set to further refine the types of tools that we're using here in the selection mode. We have the ability to play and then adjust for our platform that we want to quickly launch"},{"start":"1:07","end":"1:38","startSec":67.6,"text":"on as well as some settings to deal with rendering. So three is going to be our level of viewport. This is where we're going to spend most of our time editing things and adding things and moving them around as well as adjusting our lighting and things like that. So for here, this is our tabbed drawer system. These menu options can be moved around and things like that. The Outliner allows us to look at things that are placed in the level and the Details panel"},{"start":"1:38","end":"2:10","startSec":98.8,"text":"allows us to get more information about anything that we click on. So the Details panel is context sensitive, meaning that when we click on it, different things are going to show us different items in the Details panel. Five is our content drawer. This is where we can access the content browser. And then six, this is going to be where we access our output log or enter any console commands. And this is particularly important if we're doing any type of a debug information or anything like that. So next on our list, we have viewport navigation."},{"start":"2:10","end":"2:40","startSec":130.0,"text":"So remember, you can view navigate the viewport in Unreal two different ways. You can use the WASND key along with the QE to move the camera up and down with Q and E or holding down the right mouse button. You can use WASND to move the camera forward, backwards, left and right. You can also navigate through Unreal using just the mouse by holding down the left mouse button."},{"start":"2:40","end":"3:18","startSec":160.6,"text":"You can move the mouse forward, backwards, and turn left and right. But holding down the right mouse button, you can drag the static POV around the scene. And by holding down the middle mouse button, you could actually track the camera. A couple of other things that are important, F to focus in on an object makes it extremely useful. Should you lose that object or you maybe get thrown out of the scene really far away and you need to get your way back in, F can be a great way to focus in on stuff. You can also use ALT and the left mouse button to drag and orbit or tumble around the object."},{"start":"3:18","end":"3:49","startSec":198.6,"text":"And then ALT right mouse button will drag and dolly the camera further away from you. Alright, so working with actors. So actors again are objects that can be placed or spawned into a level. And we're going to be working with a bunch of different actors. So it's important to know what they are. And here's actually just a collection of actors and basically the stuff that we are going to be working with. So that's it."},{"start":"3:49","end":"3:54","startSec":229.5,"text":"That wraps up our Unreal Engine recap. We will see you in our next section."}],"03_FirstProjectInUnreal_Levels":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Now, before we jump into building levels, let's quickly talk about levels and what they are as understanding this is very important. So an Unreal Engine project is not made up of a single file, but rather a collection of source code, content assets, plugins, configuration files, and other support files, right? So one Unreal project is actually a collection of a bunch of different things."},{"start":"0:30","end":"1:04","startSec":30.7,"text":"Now in order to see what you interact with, we need a way to link all of these various things together and that's where levels come in. Levels allow us to add or spawn actors. And these actors are what are used to help bring life to our creations. Now when you are dealing with levels, there is this concept of a sub-level that would"},{"start":"1:04","end":"1:34","startSec":64.3,"text":"be a level inside of a level. And while this is possible, the main thing to take away from this is that no matter what you are trying to display, you are always going to need some type of level in order to display that information. Now Unreal has a number of tools that make it easy when you create a new level."},{"start":"1:34","end":"1:53","startSec":94.4,"text":"So to make a new level, all we have to do is go to File, New Level, and this will invoke the New Level Creation Wizard. Then from there we can select any of the templates, Open World, Empty Open World, Basic, or Empty Level, press Create, and we will have a new level created."}],"03_Levels":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Now, before we jump into building levels, let's quickly talk about levels and what they are as understanding this is very important. So an Unreal Engine project is not made up of a single file, but rather a collection of source code, content assets, plugins, configuration files, and other support files, right? So one Unreal project is actually a collection of a bunch of different things."},{"start":"0:30","end":"1:04","startSec":30.7,"text":"Now in order to see what you interact with, we need a way to link all of these various things together and that's where levels come in. Levels allow us to add or spawn actors. And these actors are what are used to help bring life to our creations. Now when you are dealing with levels, there is this concept of a sub-level that would"},{"start":"1:04","end":"1:34","startSec":64.3,"text":"be a level inside of a level. And while this is possible, the main thing to take away from this is that no matter what you are trying to display, you're always going to need some type of level in order to display that information. Now Unreal has a number of tools that make it easy when you create a new level. So to make a new level, all we have to do is go to File, New Level, and this will invoke"},{"start":"1:34","end":"1:48","startSec":94.6,"text":"the New Level Creation Wizard. Then from there we can select any of the templates, Open World, Empty Open World, Basic, or Empty Level, press Create, and we will have a new level created."}],"04_Exercise_55-":[{"start":"0:00","end":"0:08","startSec":0.0,"text":"We have now reached the hands-on or the exercise portion of this tutorial."}],"04_FirstProjectInUnreal_Exercise":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"We have now reached the hands-on or the exercise portion of this tutorial. And to do that, what we're going to be working with is a project called Box Hunter. So Box Hunter is a game where the player is trying to collect boxes for points before the time runs out. And there's pickups that will give you more time, score, or jump ability. There's also platforms that can be set up to move when the user steps on them or fall or rotate. And there's also logic that makes a full game loop."},{"start":"0:31","end":"1:03","startSec":31.8,"text":"So let's take a look at this now. So if I come up here and press play, we can see here, here's my player. I have a timer so I can grab time. You can see the platform, that jump one will move, or I shouldn't say move, but it will fall if I stay on it for too long. The time one rotates. So there's all types of different things that we can do here. You can see, oh, it didn't make it. So I have something that happens. If I don't make it, I can go to the main menu here. I can also start, or if let's just jump off the platform again really quick, I can go"},{"start":"1:03","end":"1:36","startSec":63.2,"text":"to quit. There we go, quit. And it will actually quit the game for me. So again, this makes an entire game loop. And this is going to serve as the example project that we build off of. Because oftentimes when we're working on game projects, we don't start from absolutely nothing. We have something to work with. So we're working with actors that we pull into the world and we manipulate their properties. So this is a really great example of that. Now that we know a little bit more about the project we'll be working with, let's go ahead and create a new basic level."},{"start":"1:36","end":"2:06","startSec":96.8,"text":"And when we do that, we're going to want to also delete the static mesh actor that's added. So let's pop over to the editor now. So what I'm going to do is come up here to file, new level, and then we're going to select this basic right here and hit create. Now as soon as it does that, we're going to take this bottom floor right here and press delete to make sure that we've deleted that because we don't actually need that. So the next thing we want to do here is press the save button up here."},{"start":"2:06","end":"2:36","startSec":126.8,"text":"And we're going to look for our levels folder. And we're going to call this, let's say level underscore zero two. And then once that is done, what we're going to do next is we're going to come over to our world settings here. And we're going to make sure that our game mode is set to BP box. Now the reason that I want to do that is because if I was to play this now, notice I don't"},{"start":"2:36","end":"3:12","startSec":156.8,"text":"have anything. I have no UI. I don't even actually have a character. I'm just kind of floating around in the air. So what I'm going to do is come up here to my window and then we're going to come down to world settings. Now with that window selected, it's going to come up here in my tab drawer system right beside my details panel. And then we're going to look for our game mode. And right here under game mode override, we're going to put this to BP box hunter game mode."},{"start":"3:13","end":"3:44","startSec":193.2,"text":"All right. So just to recap, we came here to window world settings. The reason we did that is because this window wasn't open and we needed access to it. Once we did that, we came to our game mode override and then we selected the BP box hunter game mode as our game mode override. And that is going to give us a player and a UI. So now we're going to start adding actors to our project. Before we can add them, we need to be able to find them first."},{"start":"3:44","end":"4:17","startSec":224.1,"text":"So you can find actors a number of different ways. First off, from the quickly add to your project, from this dropdown, we can do things like place basic actors like blueprints or things like that. We can place lights or basic shapes like a box or a cube. We can also find actors using the filters inside of our content browser or the very powerful search functionality. So we can search for something by a name or we can enable the filters and we can also"},{"start":"4:17","end":"4:47","startSec":257.4,"text":"enable the filters and use the search feature. Now no matter what we have searched for, we are going to need to add it to our project and we add things one of two ways. The first way is if we're using the quickly place, once we've searched for something in this example right here, we've searched for light, we then just click on the object or I should say the actor that we want and it will be placed inside of the level viewport somewhere in a relative location to our current camera."},{"start":"4:47","end":"5:19","startSec":287.8,"text":"When we are working with stuff in the content browser, once we find something that we want, we simply drag and drop it right into the level. Now once we have that actor placed, we're going to need to move it around and we can do this a couple of different ways. We can use the gizmo to position it in the world or we can select what we want in the outliner and then in the details panel, we can use the location, rotation and scale. So what we are going to do at this point is we are going to set up our level by making"},{"start":"5:19","end":"5:51","startSec":319.8,"text":"sure that we have a player start, a platform, a depth volume and a wind volume. So let's pop over to the editor now. So we're going to hit control space and oops control space here and from our content, I'm going to come down to blueprints and I'm going to grab my blueprint platform right here. I'm just going to drag that in and with that in here, I'm going to take its location and just set it to zero, zero, zero and all this is going to ensure is that when I press play, the platform is right there ready for me to go."},{"start":"5:51","end":"6:26","startSec":351.4,"text":"Alright, so what we're going to do next is we're going to grab this wind volume and then we're going to do the same thing. We're going to take its location and set it to zero, zero, zero and then we're just going to drag it over here like so. I'm going to hit control space and then with the depth volume, something similar, I'm going to go to zero, zero, zero but we're going to bring the depth volume down a little bit and then we're going to hit space bar twice. We're just going to scale this out like so and then scale it out like so and this is"},{"start":"6:26","end":"7:03","startSec":386.2,"text":"just going to ensure that if the player happens to fall, you know, if I come here and I'm, whoops, I fall off of this, there's a way to trigger the restart. Okay, so next what we're going to do is we're going to talk now a little bit about our actor details. So each actor has a details that contain its properties. For us though on the platform, we have some different actor details like on our pickup"},{"start":"7:03","end":"7:35","startSec":423.1,"text":"types, we have a time, a score and a jump. So the time will give us time to the timer score, will give us a score and jump will increase or decrease the power of our jump. Now we change those using this pickup type, we can click on the drop down menu and select none or select any one of these pickups. There's also some things here for rotate, duration falling and enable platform movement. So down at the bottom we have our score, jump and time amounts so we can adjust these to"},{"start":"7:35","end":"8:06","startSec":455.1,"text":"adjust the various score, time and jump amounts that our awarded player runs into those. For rotate when the user jumps on this, it's going to make it actually rotate the platform. We'll talk about that in just a second but I want to get to falling. So falling when enabled will make this platform fall in between about half a second and a little bit under a second. One thing to note, you cannot have a falling and rotate enabled at the same time, it will"},{"start":"8:06","end":"8:36","startSec":486.0,"text":"rotate but it will not fall. What platform movement does, it actually works in conjunction with duration and platform movement when enabled allows the platform to move in between two points. So we'll see here in just a second, we have these points 1 and point 2 and when we enable platform movement it's going to move between these two points based on the duration right here. So let's go over to the editor now and what I'm going to do is I am going to grab this"},{"start":"8:37","end":"9:07","startSec":517.4,"text":"first blueprint, I'm going to make sure it just says none because that's the spawning one there. Then I'm going to hold alt and drag out one, I'm going to just hold down, oops, didn't mean to do that, hold down alt again and drag out and add another one. So this one we're going to set to jump, this one we're going to set to score and then let's hold down alt and move like that. We'll set this one to time and then I'm going to do this one more time, something like that,"},{"start":"9:07","end":"9:41","startSec":547.9,"text":"maybe pull the wind volume up, there we go. So what we have now is when I press play, I've got my score over here, I've got a jump over here and then you can see I jumped really high and then I've got the time and then there we go, I can win and things like that. So what I'm going to do next is let's take a look at some of these platform properties. So we're just going to grab this platform right here and I'm going to change this platform"},{"start":"9:41","end":"10:14","startSec":581.2,"text":"type to none for the time being so we can have a look at it. So let's take a look at what rotate does. If I click rotate and press play and we jump onto this platform over here, you can see the platform starts to rotate. Not anything too crazy, just a cool little thing that the player has to account for. And then if we do falling, what falling is going to do, oops, wrong one, let me just play that again here, falling, it's this platform over here, is going to make the platform fall,"},{"start":"10:14","end":"10:46","startSec":614.2,"text":"there we go and that can make a really great, you can have a bunch of these together so that's a risk versus reward like there could be three or four of them and the player can run across them and they have just enough time to get across them and before it falls so it can be really fun. And then we have this enable platform movement. So to get the movement to work, we need to click on these little L1 so you can just click on them and these represent the location. So it's going to move between these. If I press play here, we'll see here, see it's moving like that."},{"start":"10:46","end":"11:22","startSec":646.6,"text":"The other cool thing we can do with these two is we can also bring them up like that. So it can go diagonally and then if I was to bring this down to say like one, bring it down to one, oh my number lock wasn't on, there we go, to one, there we go. You see it goes really fast or if I was to set it to like 15, it would go very slow. So with that said, what I want everybody to do, I'm going to pause this tutorial for now"},{"start":"11:22","end":"11:54","startSec":682.1,"text":"and make a little course. So we want to have something that has a, you know, a starch, a few little obstacles to the player to navigate around and when we come back, we will finish up with adding some backgrounds and some additional things to make this look super unique and finish up with publishing. I will see you back here once you have added a few more platforms. All right, so now that you have added a few boxes or I should say mini boxes to simulate"},{"start":"11:54","end":"12:27","startSec":714.3,"text":"kind of a city or whatever futuristic landscape or environment you have envisioned, the next thing that I want to talk about is adding some Niagara VFX admitters to simulate traffic as this is going to be pretty common throughout any project workflow. Now with our admitter, it's actually been set up so that when we placed it in the world and we go over to the details panel, we're going to have some things like mesh scale, the plane size, spawn count and velocity that we can adjust. So what these do is the mesh scale scales the size of the box."},{"start":"12:27","end":"12:59","startSec":747.1,"text":"So it's going to give us a larger box on one of these axes, the X, Y or Z. The plane size, this represents the size of the spawnable area that this is going to cover. So if we want to spawn over a larger area, we're going to make this a much bigger number. If we want to spawn over a smaller area, we're going to make this a much smaller number. Spawn count affects how many of these are spawned and then velocity controls how fast this is going to move in a given axis. And you'll see we can use velocity to kind of make these look like they're starting in one direction, kind of drifting off to another."},{"start":"12:59","end":"13:31","startSec":779.6,"text":"So let's pop over to the editor now. Take a look at how we would add these. So for this level here, what I'm going to do is maybe add some going across the back here. So I'm going to hit control space and we're going to come to our effects. And right here we have our NS floating traffic. So we're going to bring that in to, remember it's drag and drop. And what I'm going to do now is I'm actually going to hit F to kind of focus in on this because it was a little far away and kind of hard for me to see. So it looks like it actually got placed kind of far away from me. So I'm going to use my axes to kind of bring it in."},{"start":"13:31","end":"14:04","startSec":811.4,"text":"My play area is way over here. So it actually got moved really far away from me. So I'm going to just try to bring that back in like so. There we go. Let's go. So this is my play area here. So yeah, there we go. Maybe we have some traffic like that. Now it does, when this spawns in, it just spawns in. It has no fade in or anything like that. So you want to make sure that you're not showing necessarily the spawn in with these. And the next thing that we're going to do is come down to its user parameters."},{"start":"14:04","end":"14:38","startSec":844.7,"text":"And let's like maybe adjust some of this. So let's set that to like. These are going to be some really big ones. They should look really large. I'm going to hit G here. There we go. We should have some really large looking flying bits of traffic there. And then what we can do here is let's set our spawn count. Maybe we set it to like 15. So there's a bunch of them."},{"start":"14:38","end":"15:08","startSec":878.1,"text":"Okay 15 is maybe a little bit too much. So we'll set that down to like maybe seven. We might need to set this to like five. Make them a little bit shorter. Okay and then what we'll do is let's do this to like 3500 for their velocity or not their oops. Let's reset that. I meant to change their velocity here to 3500 or I think that needs to be at 3500."},{"start":"15:08","end":"15:40","startSec":908.5,"text":"And then one of the other cool things we can do with this is like let's set this to 150. So what's going to happen is they should end up looking like they're going up. We might need to actually just increase this to like maybe. Yeah there we go. So now what I want everybody to do is just do something similar. Spend some time now and you can see here that we've added a couple of traffic effects"},{"start":"15:40","end":"16:14","startSec":940.6,"text":"to this level. So just spend some time now adjusting the traffic to get something that you like, something that looks kind of cool with your particular project. And when you're done we will talk about working with the level lighting. Now that you've added some visual effects and background objects let's talk about working with our level lighting. Now for this particular project the level lighting is fairly simple in its setup. It makes use of a sky atmosphere, an exponential height fog, and a post processing volume as"},{"start":"16:14","end":"16:50","startSec":974.2,"text":"well as a directional light to simulate the sun and a skylight to help with the bounce light or the indirect light. All of these things are needed to work together in order to give you the best result. However that's not necessarily the way that you have to go about it. In some instances such as if you were using say baked lighting and you had a light mass importance volume or you were using a skydome actor. You might not be using say volumetric clouds or be relying more on post process or properties"},{"start":"16:50","end":"17:23","startSec":1010.1,"text":"in the skydome to represent things like the atmosphere or the cloud interaction. The setup that we're using in this particular project is going to result in the most accurate form of lighting but that's going to come at a direct cost of performance. So while this is going to look really great and be easy to work with it is going to be expensive in terms of performance. Let's just pop over to the ender now and see what we have to work with. So easiest thing to do is hold down control alt and L. That's going to access a little"},{"start":"17:23","end":"17:56","startSec":1043.0,"text":"lighting gizmo that you can then manipulate by moving the mouse around. And this is the method that I prefer working with when it comes to positioning my skylight, getting that really cool lighting angle that I want. If we kind of look up while we do this we can see that as I start to position it towards the horizon I can get these really really great looking low cast light here. And I'll just say that it is also going to be working with our shadows. Clouds in the background we can see the clouds picking up those subtle colors and even right"},{"start":"17:56","end":"18:30","startSec":1076.4,"text":"there the shadows look really really the shadows. The clouds are looking as though they are shadowed and they're picking up those darks really really really well. So some of the other things that we can adjust in this system so I'm going to come all the way back up to the top here. We can go to our exponential height fog. So the exponential height fog is going to control well the fog. So if I was to maybe turn the density of this down you can see here I'm making the fog less dense. I can also adjust the height of it as well so I can bring it up and make things below"},{"start":"18:30","end":"19:03","startSec":1110.9,"text":"a little bit harder to see or a little bit more included. I also have a secondary fog here that I can do to add some more fog effects somewhere else. I can enable my volumetric fog which is going to give me this just really great and interesting looking fog overlay on top of it. It's also going to give the fog a more 3D look and make it appear more that it looks like inside of nature. We also have our post processing so one thing to know about post processing there are a"},{"start":"19:03","end":"19:35","startSec":1143.6,"text":"ton of settings in here but the most important one is going to be down here and it is called and I am just not seeing it somewhere. There we go. Right underneath post process volume settings. Infinite extent unbound. So by enabling this what we do is if this is disabled which is the default it will this post process volume will only work if the camera is inside of the post process volume. That would mean we would have to scale the volume to fit this entire scene."},{"start":"19:35","end":"20:06","startSec":1175.0,"text":"If we enable this what that means is that now this post process volume will be applied to the scene no matter where we are in the scene and then by setting this this means that I can now come up here and basically set anything that I want. I can come up here to my temperature and adjust this however which way that I want and so on and so forth. Our sky atmosphere one of the things we can do is we can adjust things like the ground radius or the atmosphere height to give us some different colors or a little bit more"},{"start":"20:06","end":"20:36","startSec":1206.9,"text":"control. The only thing that I would really suggest you adjust in here is with the artistic direction unless you are setting something up for some different type of planet or atmosphere that is different than Earth. If you are trying to adjust these properties up here like the atmosphere height or the atmosphere ray length or something like that you might not get the results that you want if you are trying to adjust the color."},{"start":"20:36","end":"21:07","startSec":1236.9,"text":"Better results are going to be down here in the art direction by changing like the luminance factor the height fog can contribution and things like that. The sky light is going to control again our bounce light so we could increase the intensity on this to give us a little bit more detail in our we can see it here in the building is in the background it is just going to make them a little more intense. Then our volumetric cloud this has a couple of controls that are in the actor here so this is going to allow us to control like the layer height and things like that."},{"start":"21:07","end":"21:41","startSec":1267.7,"text":"If we come over here to the material double click on it you can see here in the material we have a whole bunch of other parameters that we can enable and adjust including things like enabling storms and we have our cloud general layout and then the actual shape and look of the cloud so a lot of parameters and things that we can adjust right here when it comes with working with lights because again when we are working with lights especially in an outdoor environment it is more than just working with a directional light it is working with all of these different things in conjunction together to give us the final"},{"start":"21:41","end":"22:17","startSec":1301.5,"text":"image. Alright so before we finish up the last thing that we need to do is modify some of our blueprint code to point to our level that we want to load because right now if we were to play this or publish it it is going to use the default level so this is pretty simple to do what we are going to do is over here inside of the editor I am going to hit control space and then I am going to look for our UI and we are going to look for our UB for widget blueprint main menu we are just going to double click on that to open it up."},{"start":"22:17","end":"22:46","startSec":1337.3,"text":"Once that is open we are going to come over here to the graph and the graph is pretty simple we have a start and a quit so the start if we zoom in on it we have on start and then open level and we have this by object reference so right here we are just going to click the level that we want to open which is going to be level 2 or whatever your level name is once you compile and save this that is the level that will be open so this is the last thing that needs to be done in order for our project to be ready to publish."}],"05_FirstProjectInUnreal_Publishing":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"All right, now that we have added some gameplay, we have added background objects, adjusted our visual effects, our lighting, and set up our project to make sure it loads the level we created. We're now going to take a look at publishing our project for Windows. But before you do that, there is a few things that we need to do. First off, if you haven't done so already, you'll need to install Visual Studio Community in order to continue the publishing process."},{"start":"0:30","end":"1:03","startSec":30.9,"text":"This is because we need a couple of updated SDKs and .NETs updates in order to get the required files to successfully create a Windows executable. So again, just look for Visual Studio Community in your favorite web browser, and then download it, install it. Once you've installed it, make sure you restart your computer, then launch your Unreal Engine project, and go up to platforms, Windows, and package project. Once you've done that, it is going to take a little time,"},{"start":"1:03","end":"1:34","startSec":63.8,"text":"depending on the size of your project. It could take a few minutes, it could take a few hours, really depends on how much content is going to be packaged. But once it is done, you're going to get something like this. You are going to get a executable, an RK is going to be boxhunter.exe, and when somebody launches that, they're going to be able to play your game from the beginning, the middle, to the end. So let's go ahead and pop over to the editor and check this out now. So again, to publish this, we're going to go up to platforms, we're going to go to Windows and package."},{"start":"1:34","end":"2:06","startSec":94.0,"text":"I'm going to come up to here, I'm just going to hit delete because I've packages before, but I have my desktop and then you'll need to make a new folder, and there's our boxhunter, so we're just going to say select folder, and now it's starting to package. And if we do our show log here, we're going to see the log of our package. So we'll be back right in just a few minutes once this is finished. All right, now our project has finished packaging, so let's go ahead and take a look at the ending result here. So we're going to open up my explorer here,"},{"start":"2:06","end":"2:37","startSec":126.9,"text":"and we're just going to look for our boxhunter. Going to go to Windows, and there we go, look, we have our boxhunter, our engine, and our EXE. So there we go, we're going to double click on that, and let me just bring this over to this other monitor over here because it opened up on my secondary monitor. So let me just bring this over. There we go, there's our boxhunter, and when I hit start, there we go. We have our project here, and I have mine with the default level, but you should now have the level that you created,"},{"start":"2:37","end":"3:09","startSec":157.6,"text":"and you should be able to play it just like I'm doing now. And when we do this, we should be able to go to the main menu, we can start, or let's just do this one more time, and we can come here and we can actually quit, which will end the project. So with that said, that is actually going to wrap everything up. So in today's talk, we started off with looking at an Unreal Engine 5 recap, going over the user interface, viewport navigation, and working with actors. We then moved on to talking about levels,"},{"start":"3:09","end":"3:37","startSec":189.9,"text":"we talked about level concepts and how we create levels, and then we dove into our exercise with our project introduction, then we set up our levels, we worked with actors, we added visual effects and background props, and then finally we published four windows. So that is all that I have for you in this tutorial series. I hope you enjoyed watching it as much as I enjoyed presenting to you, and I will see you next time."}],"05_Publishing":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"Alright, now that we have added some gameplay, we have added background objects, adjusted our visual effects, our lighting, and set up our project to make sure it loads the level we created. We're now going to take a look at publishing our project for Windows. But before you do that, there is a few things that we need to do. First off, if you haven't done so already, you'll need to install Visual Studio Community in order to continue the publishing process. This is because we need a couple of updated SDKs and .NET updates"},{"start":"0:36","end":"1:09","startSec":36.7,"text":"in order to get the required files to successfully create a Windows executable. So again, just look for Visual Studio Community in your favorite web browser and then download it, install it. Once you've installed it, make sure you restart your computer, then launch your Unreal Engine project and go up to platforms, Windows and package project. Once you've done that, it is going to take a little time depending on the size of your project. It could take a few minutes, it could take a few hours, really depends on how much content is going"},{"start":"1:09","end":"1:42","startSec":69.8,"text":"to be packaged. But once it is done, you're going to get something like this. You are going to get a executable, an RKIS is going to be boxhunter.exe and when somebody launches that they're going to be able to play your game from the beginning, the middle to the end. So let's go ahead and pop over to the editor and check this out now. So again, to publish this, we're going to go up to platforms, we're going to go to Windows and package. I'm going to come up to here, I'm just going to hit delete because I've packaged this before but I have my desktop and then you'll need to make a new folder and there's our boxhunter."},{"start":"1:42","end":"1:52","startSec":102.3,"text":"So we're just going to say select folder and now it's starting to package and if we do our show log here, we're going to see the log of our package. So we'll be back right in just a few minutes once this is finished."}]},"100.07":{"01_Introduction":[{"start":"0:00","end":"0:29","startSec":0.0,"text":"Hello and welcome to your Unreal Engine training course on the first project you're creating in Unreal Engine for AEC. So just to give you a quick start about the topics that we're going to be covering today, we've got the Unreal resources and we'll talk a little bit about the Epic Games launcher. We'll talk to you about the basics of Unreal Engine and how to navigate the different parts of the engine. We'll talk about how to import data and we'll talk about how you can improve your scene."}],"02_Unreal Resources":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"So just to touch upon some Unreal Engine resources, you can find the Epic Games launcher on your installer and it will give you a nice overview of everything that the engine has to offer. There is a samples tab where you can download different projects and break them apart. Sometimes that's the easiest way to really get into the depths of learning Unreal Engine. You get the engine updates as well through this launcher. So if you're using a current engine version and there's a new one out, you can always download that through the launcher."},{"start":"0:34","end":"0:47","startSec":34.4,"text":"We've got the marketplace and some free items so you can jump into the marketplace and grab some free content for your projects. And then we've also got the library files on the seconds last tab where your projects will be stored."}],"03_Unreal File Structure":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Probably useful to touch upon the Unreal Engine file structure to give you a little bit more idea about how the projects are stored and saved. So to give you a brief overview, Unreal Engine has projects and templates. Within that you have project files. Within the project files you have the folders and also the project structure. So breaking apart each one of these points here. When we refer to projects and templates we're talking about when you load the launcher and"},{"start":"0:31","end":"1:02","startSec":31.5,"text":"you want to create a new project, you can see the different series of templates that we can choose from on the left hand side. So we can either pick a games based project, film and video based project, architecture in this instance and then automotive, product design and manufacturing. So essentially each one of these categories gives you a series of different templates to pick. Now it actually doesn't matter which project you pick if you want to change."},{"start":"1:02","end":"1:34","startSec":62.0,"text":"Unreal Engine can accommodate just because you pick one template doesn't mean that you're committed to that one specific approach. However it just pre-builds in some quality of life settings. It kind of sets all the different features and functionalities you might need with that given project. So it's just useful to be able to pick the template from the get go when you're creating your projects. So when we talk about file saving and copying you have the traditional apps used for a single"},{"start":"1:34","end":"2:09","startSec":94.7,"text":"project to visualize the scene. So in this instance we have the piece of software, we click save and we have a file that is created. So you know when you're working in Photoshop you have PSDs, Word, you have Docs, you may have made binary files and so you're essentially in the traditional apps. You have a piece of software and you are saving this file to visualize your scene. When we talk about UE5 all important assets you know this is models, textures, audio, anything along those lines are stored in a content folder as UAsset."},{"start":"2:09","end":"2:43","startSec":129.3,"text":"So essentially UAsset is just an Unreal Engine asset and it allows you to see things on an individual basis. So levels are saved as UMaps which essentially is an Unreal Map and projects are saved as U projects. So to give you a better idea about that the project is the main thing that you have created. It is what stores all the individual assets below that. So the project is the thing that embodies everything else. When you create your scenes or levels they are saved as UMaps so they're saved as map"},{"start":"2:43","end":"3:15","startSec":163.3,"text":"projects. So all the content is stored separately outside the map for easy access and you can access them through the map which is inside the project. So it's kind of a tiered approach there. So with UE5 we have the level editor, the asset editor, the material editor, just looking at this diagram here and each one that you save creates a different asset essentially. So when we talk about aggregating the files in Maya or Photoshop you have FBXs and PNGs."},{"start":"3:15","end":"3:51","startSec":195.9,"text":"So these raw data files, the FBXs or the PNGs, they will then get transferred into a UAsset, so an Unreal Asset. So instead of using the raw naming convention then everything gets turned into a UAsset. So when we look at the project folder structure generally you'll see these folders. If you have a C++ engine version or anything like this you might see a few extra folders in your file structure but these are the main folders to look for when creating your project."},{"start":"3:51","end":"4:24","startSec":231.6,"text":"So wherever you decide to store your projects maybe the defaults of the documents in Unreal Projects sorry but essentially we've got the config folder here at the top which is, houses all your configurations for the project. So any kind of inputs or different post process settings maybe that you've saved, anything that you've configured for that specific project are in the config folder. The content is where all of these UAssets get stored which we were referring to before whether a UAsset or maps and assets are stored in your content."},{"start":"4:24","end":"4:59","startSec":264.8,"text":"So essentially any content that you can edit at real time is in your content folder. Intermediate and saved are more of the cached folders so intermediate just saves a bunch of information that lets your engine run a bit faster and then saved if you have any auto saves or maybe you've saved some screenshots in the engine, maybe you've saved some movie exports that will generally all go into saved. And then your UProject which is the blue icon is what you would load to load up the larger project. It's quite a small file size and that houses all of the folders above it."},{"start":"4:59","end":"5:28","startSec":299.2,"text":"We can access them through the UProject. So to give you a little bit of a better idea about that you know the project encases everything else the project is this holistic thing that holds all the information. You will create levels within the project so that you can access through the editor window and then each of these levels will have some form of actors which are these UAssets inside of Unreal Engine that you can use to create the content that you desire."}],"04_Content Workflow":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Moving on to your content workflow inside of Unreal Engine, the things I want to cover here are working with the assets, so whether they're ready-made assets or custom assets, importing FBX files and importing Datasmith files as well as the static mesh editor. So a few useful shortcuts and hotkeys for viewport navigation inside of Unreal Engine might be useful to either screenshot or just write some of these down."},{"start":"0:33","end":"1:05","startSec":33.6,"text":"Again, you'll probably get very familiar with Navigator Unreal pretty quickly, but these are just some good navigation options to use when interfacing with Unreal Engine. So when we're talking about readily available data, we have a starter content that's built into the engine. Now when we were creating these project templates before in the previous slides, there is an option to include starter content or not include starter content. So if you do include starter content, it comes with a whole bunch of assets that you can"},{"start":"1:05","end":"1:40","startSec":65.9,"text":"use and edit in any way you like, and it contains a selection of sample assets such as meshes, materials, textures, etc. to get you started. These are all included within Unreal Engine, and they can be added when you create the project and can also be added to the project at a later time. So again, if you don't select that tick box that says include starter content, you can add these at a later point. Again, as we were referring to when we were talking about templates and, you know, maybe selecting a template and you wanting to change certain configurations of the template, you"},{"start":"1:40","end":"2:16","startSec":100.4,"text":"can still do that. It just takes a long, it's more of a roundabout way of doing it. We also have the marketplace, which we mentioned in the Epic Games launcher at the start of this course. Commercially available asset data, even though it contains lots of free packs. So you can download marketplace packs from your vault and add them to any of your Unreal Engine projects. So once you actually have found a marketplace asset, you can either just click add to project from directly in the marketplace or when you're in your library, you'll see all the packs"},{"start":"2:16","end":"2:49","startSec":136.1,"text":"that you previously downloaded or purchased and you can add those to the project at any point. So it's a really good way to just pull apart other people's content and figure out how certain people have approached different things. We also have Quixel Bridge inside the engine. So this is free data accessible directly from the engine. You can see on the top right here, we have an option on the drop down to go directly to Quixel Bridge. So there's an enormous library of assets, 3D assets, materials, textures, and you can"},{"start":"2:49","end":"3:22","startSec":169.4,"text":"use them effortlessly in your projects. And when we talk about custom content, a few things to do before you export from your DCC app. So you want to make sure you use descriptive names for objects and materials, just keeping things really organized. When we talk about things like collisions and hierarchies, it's just really, really good practice to keep things. Whatever naming convention you're using, just keep things organized and combine meshes wherever possible. Make sure all the meshes are clean and consistent with proper UVs."},{"start":"3:22","end":"3:53","startSec":202.3,"text":"When we're talking about clean, we're making sure that all our geometry is correct. We've not got any inside faces or flip normals or anything like this. Just make sure everything's clean and consistent with your proper UV layout and pay attention to objects that have been scaled, especially in a non-uniform way. Everything ideally is just a scale of 1, 1, 1 inside your DCC app. And then when you import it, everything works as intended there. Keep the scene as close to the origin of the world, which is 0, 0, 0 as possible."},{"start":"3:53","end":"4:25","startSec":233.3,"text":"As scenes move further away from world 0, the greater possibility for rounding errors to happen. So you may get graphical glitches and it's hard to reproduce those bugs, especially when you're not sure what's causing it. So again, when we talk about our custom content, just maintaining this good workflow is really important. And then check your pivot points and ensure they're in the right place. So whether they've been center pivoted or maybe you have some building structures that need their pivots on a certain corner to snap together, just make sure you're checking"},{"start":"4:25","end":"4:55","startSec":265.3,"text":"all your pivot points before you export. We can update pivot points in Unreal Engine, but it's better to have the actual data coming in as you intend it to be. So which road to take, whether we take FBX or Datasmith? With FBX, mind your system units. If you are planning to use FBX workflows, we use centimeters as a base unit in the DCC app to match Unreal Engine's unit system so that your scales aren't off here."},{"start":"4:55","end":"5:28","startSec":295.6,"text":"And make sure your objects are centered in the world like we mentioned before with 0, 0, 0. With Datasmith, you need to ensure that you have the Datasmith exporter for your DCC of choice. So you can find a link here to all the different plugins that are available and just make sure you download the relevant one for the software that you're using. Don't worry about your DCC C units. The Datasmith converter already takes care of everything on that front and it reads and ports CAD formats natively. Datasmith also works well with fully assembled scenes and large data sets and it's compatible"},{"start":"5:28","end":"5:43","startSec":328.2,"text":"with more material types than FBX can provide. And we can also export full scenes or partial ones. The simple export UI defaults to export where it's only visible on the screen. So again, when you're making your choice between FBX and Datasmith, it's worth keeping those things in mind."}],"05_Unreal Engine Interface":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"Now that we understand files and content workflows a little bit better, let's talk a little bit about the Unreal Engine interface. So we have UI and components here made up of the toolbar, the modes panel, content browser, viewport, world outline and details panel. So just to touch upon what each one of these is, on the top we've got the toolbar here and you can select the different modes that you want to edit your scene in. So whether you want to be in content editing mode with the assets that you're placing down,"},{"start":"0:35","end":"1:06","startSec":35.6,"text":"whether you want to be in landscape mode or foliage mode, and we have a few different modes to select from here. And then we can also open the blueprints from this toolbar, we can create cinematics from this toolbar and we can also play through the experience or package the project from this toolbar as well. So and also just save the project, which is a good habit to get into. And we've got the modes pane on the left hand side here and then depending on which mode you had selected from the toolbar, it will give you relevant options."},{"start":"1:06","end":"1:37","startSec":66.7,"text":"So as you're cycling through the different modes, this window will be updating with the tools that are available at your disposal when going through the modes. When we talk about the content browser at the bottom, this is where you're housing all of your content that you've imported from your DCC app. So depending on your naming conventions and your file structures, you'll be able to find the relevant information. And it's also worth noting that we have a filtering out of content. So I'll just show you that quickly in the engine so you can see the filter because I"},{"start":"1:37","end":"2:07","startSec":97.7,"text":"think that's useful to touch upon. So if we're trying to find certain content inside of our content browser, there is a favorites tab, first of all, which you can add favorites to. That's quite a useful functionality. Specifically on the filtering that I was talking about, if you're trying to find a level to open which is inside your content, maybe you can scroll through to the relevant folders and find the information that you need. Maybe you go to the levels tab and this is a level that I currently have open."},{"start":"2:07","end":"2:38","startSec":127.8,"text":"But if, for example, you've got your level saved in multiple places, I can actually filter out this content either through searching the content, if you're using consistent prefixes with your files, maybe you can search the prefix and find the content or you can actually filter out the content based on the content type. So you could select a blueprint to find blueprints. I've selected level here and if I click level, it actually creates this level filter here and it shows all the levels."},{"start":"2:38","end":"3:12","startSec":158.8,"text":"And because I've got content selected, which is the parent folder, it actually shows me all the levels that are present within this project. So if you need a quicker way to find your content, obviously good naming convention and folder structure is the primary thing. But if you are struggling to find certain bits of information, do consider using the filter tab because it's very powerful and very useful when you're trying to find certain bits of content. And hopefully that gives you a little bit more idea about how to navigate the content browser. On the top right, we have the world outliner, which you'll see all the actors that are"},{"start":"3:12","end":"3:42","startSec":192.4,"text":"in your scene will be present here, which you can scroll through. You can create hierarchies here where you can child other actors to parents and just also add folders and collect everything together and name everything correctly so your scene is well organized. You'll see that there's a layers and levels tab next to the world outliner there. You can find these from the window option, sorry, at the top left of your editor next to file, edit and then window. And you can open different windows depending on what you need."},{"start":"3:42","end":"4:14","startSec":222.9,"text":"The layers tab, essentially you can add actors to layers that you can set the visibility of so you can hide and unhide content at runtime. And then levels tab is if you have streaming content, maybe if you want to stream in a whole lot of content at a certain point through the experience, you can do that using levels. But yeah, the world outliner is the main thing that we're highlighting there. Then you've got your details panel at the bottom right here. Again, you've got world settings next to the details panel, which you can find from the"},{"start":"4:14","end":"4:45","startSec":254.8,"text":"window setting at the top left of the editor there. But to specifically focus on the details panel, whenever you select an actor inside this scene, inside the viewport, you can see the relevant details that you can edit. So say for example, if you selected a static mesh in your scene, you'll be able to set the material or the scale. Maybe you want to set something specific to its rendering properties. You can find all these options in the details panel. And then finally, we've got the main viewport here."},{"start":"4:45","end":"5:16","startSec":285.4,"text":"So you navigate the viewport and again, using those hotkeys and quick tips that we had displayed before, you'll be able to navigate through the scene. We have viewport settings, which I'll touch upon in more detail in a second at the top left of the viewport there where it says viewport settings. And then you got your transform tools and snaps in the top right of the viewport where you can cycle through scale, rotation and movement. And so you can actually toggle through those transforms just pressing spacebar in your"},{"start":"5:16","end":"5:49","startSec":316.4,"text":"editor. So if you have a static mesh selected and you tap spacebar, you can cycle through the location rotation and scale widget. It helps you really quickly manipulate the content there. And you've also got different grid snapping properties, which you can change the grid from 10 units to 5 units depending on the snapping. And to give you a little bit of idea about this widget that I was referring to, if I go over to a chair, for example, and I can see the pivot and again, just to navigate touching on these hot tips that I was using before, I'm using right mouse button to pan"},{"start":"5:49","end":"6:20","startSec":349.6,"text":"my camera. So just pressing and holding right mouse button. I'm using my left mouse button to go backwards and forwards. I'm holding down both mouse buttons to go up and down. So you can see that as I move around, I'm just holding left click. Now I'm holding right both and now I'm holding right mouse button. So again, just cycle through the left mouse button, right mouse button and then both mouse buttons to get a feel for navigating the scene."},{"start":"6:20","end":"6:50","startSec":380.2,"text":"But the specific toolbar that I was talking about is if I press spacebar, I can cycle through the widgets here. I can also set the snap sizes to 10, 5 and you'll see that 5 updates to 10, updates to 15 and I'm actually using the bracket keys next to the enter key on my keyboard to actually cycle that grid size, which I think is a really quick and useful way, especially when you're working with a modular content that needs to snap together. That can be really helpful when you're using the bracket keys."},{"start":"6:50","end":"7:24","startSec":410.8,"text":"And then you got rotation snapping, scaling snapping and also the camera speed. So if you're navigating around your viewport, I'm holding down W, A, S and D on the keyboard at different points to navigate around the scene. If you feel like your camera is moving too quickly, you can bring the camera speed down. Alternatively, you can see I'm now moving quite slowly around the scene. Alternatively, you can drag it up. If you want something a little bit more dynamic as well, as I'm right, I'm pressing and holding"},{"start":"7:24","end":"7:49","startSec":444.4,"text":"my right mouse button to pan around the scene. I'm also pressing W, A, S and D to move around. If I'm trying to get to a certain part, I can actually use my mouse wheel to zoom faster and slower. So if you're navigating around and you use your mouse wheel button, it can actually really help you move around the scene a bit quicker. So just a few tips there of navigating the editor just in case they were useful to you."}],"06_Unreal Engine Interface Continued":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Coming back to the user interface, the customizable UI that we've got here, we've got a default interface that favors a large viewport. We can also, all panels are dockable and collapsible, and so we can move those into the real estate that we want to on the screen. We can also make parameters more accessible by adding them to a favorites list. So you can, on the top right hand here, you can dock the outliner and the details panel,"},{"start":"0:33","end":"1:05","startSec":33.4,"text":"and then also on the content browser at the bottom, you can hit control and space to open that. So let's just jump in the editor and I'll show you the favorites and the docking. I'm going to hit F10 and that puts everything to the side so you can see everything is docked. I can hit F10 again on my keyboard if I want to bring everything back out, or I can select the individual options here and the outliner will pop out and the details panel will pop out. It depends on how you want to work. When we talk about the content drawer, I'm going to hold control and hit spacebar to"},{"start":"1:05","end":"1:35","startSec":65.9,"text":"bring up my content drawer, and I can hit control and spacebar again to drop everything down. I generally work with everything out, so if I hit F10 again, I generally work with everything popped out just because it's easy to visualize everything. The content browser is a really nice thing to have that can pop down and drop out again though, just because it saves a bit more real estate space. Then also on the favorites panel that I was referring to in the PowerPoint, say I navigate"},{"start":"1:35","end":"2:08","startSec":95.9,"text":"myself over to a chair and you can see that I have favorites here that is cast shadow. So on any of the properties, we can actually add as a favorite. So you can just right click any property and click add to favorites and then that will favorite it up here. So if I wanted to have the static mesh property as a favorite for example, I right click add to favorites and it pops to the top there. So I can still have all my properties down there."},{"start":"2:08","end":"2:45","startSec":128.1,"text":"It doesn't remove any properties from down here, but they will pop them up to the top and you just want to make sure this toggle favorites button is there and you can just essentially add any variables that you're constantly editing and if you find yourself scrolling up and down to certain properties, just add them to your favorites list and they'll appear at the top for easy editing. It's probably also worth highlighting on the favorites panel here as well. If I go to edit, editor preferences and I'll add editor preferences and I type in favorite."},{"start":"2:45","end":"2:58","startSec":165.6,"text":"There's also context menu, show favorite selection and also flatten favorite menus. So if you wanted to flatten the favorite menus, for example, you could just tick that tick box and that might be a useful setting for you to have."}],"07_Transforming Objects":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Moving on to transforming objects, we can use the translate, rotate, scale tools on the viewport to move objects around the scene which I briefly spoke about in the viewport overview. You can toggle between world and local transforms as well. So that is actually the little widget that's just here around my mouse next to the location, rotation and scale widgets. And then you can also use the details panel to enter transform values as we saw on the"},{"start":"0:32","end":"1:05","startSec":32.7,"text":"options in the details panel, sorry, in the editor overview. So you can just transform those values either through the widget or you can type in specific values with each of the actors that you have selected. So to give you a little bit idea about the viewport menu, so you can find these menus at the top left of your viewport that we went over before, you'll see these four sections here and each one contains a whole host of different settings that you may want to use just to touch upon a few briefly."},{"start":"1:05","end":"1:36","startSec":65.4,"text":"Real time, generally you would have this enabled most of the time unless you didn't want the scene in real time for some reason, maybe your computer can't support it or maybe you just don't want to view the scene in real time. So the good thing about all these settings is anything that you use frequently, they have little hotkey shortcuts next to each property. So if you want to learn a few of them for things that you use quite frequently, that's a good practice to get into. But yeah, essentially we can just show a few different options here, you know, allow cinematic"},{"start":"1:36","end":"2:08","startSec":96.2,"text":"control, do you want to show the toolbar, different properties that just create your editing experience, make your editing experience a bit more user friendly. In the perspective tab, generally we're working a lot of time in perspective, but if you want orthographic viewports, for example, you can select through the different orthographic viewports there and you can also have a viewport layout that can house all four orthographic viewports, for example, if you wanted the three orthographic viewports plus a perspective. If there are any cameras in your map, you'll be able to select your cameras from here."},{"start":"2:08","end":"2:41","startSec":128.3,"text":"I generally don't use this setting too often, I generally go and locate the camera in the scene, but it's also worthwhile just to know that these cameras are placed here as well. And then depending on if you want a default viewport or a cinematic viewport, majority of people will be using a default viewport. However, a cinematic viewport gives you some nice cinematic controls, it gives you some nice overlay masks, it gives you a third grid for your window if you're wanting to work on cinematic. So definitely worth toggling on and playing around if you're making cinematics."},{"start":"2:41","end":"3:14","startSec":161.4,"text":"And then on the next button across, you've got the different view modes and render modes and they have loads of different view modes that help with visualization of the buffer, Nanae, optimization view modes. If you're trying to get your project to a more optimized approach, you can toggle through the different view modes here. A lot of really useful things. And it's worth noting that you can toggle a lot of these view modes using console commands, which are opened by pressing the tilde key on your keyboard, which is more often than"},{"start":"3:14","end":"3:44","startSec":194.8,"text":"not next to the number one key on your keyboard. So much depth and complexity to the different view modes that are available inside of Unreal Engine. And if you're interested in any of those, it's definitely worth following up on the documentation of those. And then you've got some exposure settings if you want to override any exposure and then your color management. On the show tab next, this is just per editor viewport what you want to be displaying inside your scene. So if you want to hide certain elements or features, it might be worth toggling some"},{"start":"3:44","end":"4:16","startSec":224.8,"text":"of these options. A nice little hotkey that isn't displayed here, I think is by pressing the T key, it toggles transparency. So if you have a lot of transparent surfaces in your scene, maybe you have a lot of windows or god rays that are static meshes coming through, maybe there's just some kind of transparency going on, which you just keep selecting the transparent objects instead of the actual object you're trying to select. You can hit the T key to toggle between transparency modes, which I find quite useful a lot of the time."}],"08_3D Environment- Landscapes and Foliage":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Next up, talking a little bit about 3D environment, the landscapes and the foliage. In Unreal Engine, we have a very powerful landscape tool and as well a foliage tool that you can add terrain, trees, shrubs, other types of vegetation to. Again, touching upon the modes tab that we were talking about before, you can select these directly from this tab at the top left of your editor. You'll be able to find that and you can also see the hotkeys for shifting between them."},{"start":"0:32","end":"1:04","startSec":32.5,"text":"So we have specific courses on this but you can sculpt the terrain, vary the foliage, you can scatter foliage. They're very intuitive tools and there is a lot of documentation on using them as well if you like but sometimes it can be nice to just jump in and play around with those tools yourself. Like I said, they are very intuitive and you can get a lot of really powerful results in a really short space of time. We can also just delete and move foliage around if you've accidentally put it in the wrong place. So many powerful options in landscape and foliage so they're worth checking out if you"},{"start":"1:04","end":"1:05","startSec":64.0,"text":"need those for your projects."}],"09_Working With Materials":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"So we'll talk a little bit about working with materials in Unreal Engine and if you're unsure what materials are we'll dig into exactly what their role is inside of Unreal and then after this section we'll jump into a little workshop where I'll show you actually how to create a material. So essentially what are materials in Unreal Engine and what is PBR? So a material is essentially an asset that's applied to a mesh to control the visual look."},{"start":"0:30","end":"1:04","startSec":30.3,"text":"So if you see from this diagram here at the top maybe from the player's camera or the viewer's camera we see some glass inside the editor. Now the glass is reacting in a certain way, it's maybe causing a reflection, this is all the job of the material. So the texture wouldn't be causing the reflection, it'd be the glass material which is causing reflection and then the material also has some properties such as how the surface should react so in this instance we're going to be bouncing light off the glass because it's"},{"start":"1:04","end":"1:35","startSec":64.5,"text":"reflecting this sunlight in this figure. And then for figure two for example if we want chalk which is more matted and it's absorbing a lot more of the light you'll see that it's not bouncing off the surface as much and so we can actually set the properties of the material inside of Unreal Engine to get the desired outcome that we want. So the simplest form is we think of it as paint with various properties such as the colour and the finish and the material defines how light interacts with the surface and it's"},{"start":"1:35","end":"2:06","startSec":95.9,"text":"applied to. So PBR is a unified lighting and shading system, it's a better approximation of light and materials, physical interaction and hopefully you find it very intuitive and consistent to use, it's physically accurate especially when you're working on these AAC projects, it's very powerful in that respect and uses real world physical measurements. So PBR is a combination of your material setup, what lighting setups you have in the scene"},{"start":"2:06","end":"2:41","startSec":126.1,"text":"and also exposure. So when we talk about PBR we'll talk about primary PBR inputs, material settings and textures. And so when we look at the PBR material setup and again we'll jump into the engine in the next section just to actually create a material but to give you an idea when we open the material editor we have a base colour, some form of base colour that we plug in and say this is a blue material in this example. We also can plug in a numerical value into a metallic value and a roughness value again"},{"start":"2:41","end":"3:13","startSec":161.5,"text":"to say how metallic is this surface, how rough, how much is it absorbing light, how much is it reflecting light and just controlling these properties give us a really powerful output for our material setups. So our base colour when we're plugging it into our materials is called an albedo map which is a flat colour without any specularity or shading, it's linear RGB which is a vector 3 and values are between 0 and 1, avoiding a pure black which is 0 and pure white as"},{"start":"3:13","end":"3:45","startSec":193.1,"text":"they don't really exist in nature, it's always going to be some variance of between 0 and 1. When we talk about the metallic ranges it's a grayscale value that ranges between 0 and 1, most common usage is on or off so we either set metal on which is 1 or off which is 0 and when it's 1 it yields 100% specular reflection so you can see the transitioning value between 0 and 1 in the image below just to give you an idea of that. When we talk about roughness, roughness is essentially a grayscale value that ranges"},{"start":"3:45","end":"4:22","startSec":225.8,"text":"from 0 to 1 as well, it ranges from a smooth mirror-like surface from 0 so you can see that on the bottom left hand side of our image here to a rougher matte surface which is 1 on the bottom right. Unlike with metallic you're encouraged to fine tune the roughness between 0 and 1 so just play from your senior albedo map which is your base colour going into your metallic map and then dialing in your roughness is a good workflow to look at there. There's supported texture formats, so Unreal can handle many different file formats, for"},{"start":"4:22","end":"4:53","startSec":262.3,"text":"optimisation purposes it's best to work with PNG when using image texture due to its lightweight file size and its ability to have transparency info when needed but you can use uncompressed file types, BMP, Targets, PSDs, it's good to note that Targets, depending on how you save them in your editing suite, they can have the alpha channels with Targets which is useful, PNGs are more compressed however they can support alpha as well as mentioned"},{"start":"4:53","end":"5:29","startSec":293.9,"text":"before. You can also import JPEGs, DDS and HDR. So a few guidelines to keep in mind when you're importing your textures, textures should always be a power of 2, so 16 by 16 all the way to 8192 by 8192, just keep them uniform there and textures don't have to be square as long as they are a power of 2, so 16 by 128 is completely fine, just making sure they are following that previous rule as a power of 2 and textures can affect streaming and memory management, so you know making sure, depending"},{"start":"5:29","end":"6:02","startSec":329.3,"text":"on your optimisation, if you only need a small texture that's on this one small object in the scene, maybe don't import it as 8192 by 8192, thinking about the scaling of the resolutions there will help with memory management and high frequency textures can cause anti-aliasing artifacts so you'll see when you import textures you get a few settings to show you how it's been imported, how it's been displayed, different MIPS and formats and all these kind of properties"},{"start":"6:02","end":"6:38","startSec":363.0,"text":"you can see the difference between streamed and un-streamed as well in those two dialogue boxes there. So when we talk about texture pyramids which are MIPS maps and custom settings you can set these directly in the material editor and also from the texture, and again we'll be jumping into the editor in a second, but the MIPS value mode is in the material editor there which you can change the setting for and then if you double click the texture from the content browser you can actually change the texture group if need be there, so there's"},{"start":"6:38","end":"7:11","startSec":398.2,"text":"a couple of ways to use MIPS maps. When you're importing the textures you can use the import button to simply drag and drop in the Windows Explorer so you can either go through the method of clicking import and adding content to your scene or you can just drag and drop them directly into the content browser and they'll import fine. Textures are converted to the U assets like we said at the outset here and you can open a texture in the texture editor with a simple double click so from your content browser just double click the texture that you've imported and you'll get this window on the"},{"start":"7:12","end":"7:23","startSec":432.0,"text":"right hand side and here you can change the compression settings which we were referring to before if need to and you can also enable or disable the linear colour space, the sRGB there."}],"10_The Material System":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"So, looking at the material system in a little bit more depth here, we've got the material editor overview which you can see which is just a buildup of the base color, the metallic and the roughness that we were looking at previously where you can see some text quads going on with texture samples and roughness values and we've got normal maps going on with some baked ambient occlusion as well and so I'll jump into the editor and show"},{"start":"0:30","end":"1:06","startSec":30.4,"text":"you a basic material set up in a second and just to talk to you about the parent materials and the material instances, essentially we can have this parent material which is from the slide previously that can be a parent material so we can say this is a parent rock material and these are all the properties that we want and as you can see roughness for example is a value here which we'll actually be able to manipulate in a child version of the material so we can have parent materials and material instances which are child versions"},{"start":"1:06","end":"1:42","startSec":66.1,"text":"of that material so we could set a roughness value in the parent material for example and then using that same material we can create instances of that to have you know materials with different roughnesses for example which is really powerful and it gives it a better more optimized workflow as well. So material instances come with all the same properties as a parent material and you can you know enable and disable them and right now we'll jump into the editor and to show you a basic material set up, how to author a material"},{"start":"1:42","end":"1:46","startSec":102.7,"text":"and get it working with a material instance inside your editor."}],"11_The Material System- Workshop":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"With my editor open, I'm just going to create a new folder for this. You can put the material wherever you'd like but for this purpose I'm just going to create a new material folder here and hit materials. So all I've done here is right clicked on the content folder, new folder and it's created a materials folder. Alternatively, I can also in the root just right click new folder as well if you prefer to take that approach."},{"start":"0:31","end":"1:02","startSec":31.5,"text":"So inside my materials folder on the bottom left here, I want to create a new material. So I'm just going to right click in this empty space at the bottom. So right click material and I use the naming convention m underscore and then whatever the material is. So let's just call this rock. So m underscore rock is my naming convention. Some people put mat underscore for material. Whatever you'd prefer, again from the outset we were talking about good naming conventions and being consistent with naming conventions."},{"start":"1:02","end":"1:37","startSec":62.5,"text":"I think just pick a naming convention that works for you or your team and then just keep that consistent. So I've just hit enter there and it's opened my material. If you didn't have, again just open my content drawer by pressing control and space bar. If I didn't have this material selected already, I can double click it as well to open it. So we see the material editor and the slide that we're referring to before and this is the basic outline. So the first thing we'll do is we'll hold the number 3 key down and left click and that"},{"start":"1:37","end":"2:14","startSec":97.9,"text":"will create a vector 3. So holding down 3 on your keyboard and left clicking will create a vector 3 and I'm just going to plug this into base color. I'm going to click on the constant value on the left hand side. So constant, this black box and we'll just give it a color, whatever color you like. I'm going to create a purple rock today or a pinkish rock shall we say. I'm just going to save that. It's always good to just save as you go. Just keep working as you're iterating and I'll also change the property here just so"},{"start":"2:14","end":"2:52","startSec":134.7,"text":"I can see my material a little bit better. So I'm going to set it on the preview mesh here and then using the exact same editor viewport navigation that I was using before, so right mouse drag goes in and out, left mouse drag pans around and both zooms in and out. So in case you want to do that. So you can toggle the different view modes if need be and just make sure if it goes invisible that you're not right next to it. So next I'm going to hold down 1 and left click to create a numerical vector here and"},{"start":"2:52","end":"3:24","startSec":172.1,"text":"I'm going to plug that into metallic and I'm going to press 1 again, hold that down and I'm going to plug into roughness. So I'm just holding down 1, left mouse clicking to create these values. Now you'll see my color here. I'm going to right click on the color and convert this to a parameter and I'll call this rock color and I spell color the British way, apologies for that and I'm just going"},{"start":"3:24","end":"4:01","startSec":204.1,"text":"to move that into location. I'm just left mouse dragging and holding these into position. So left mouse click and hold down to move them into position. I'm going to right click this next metallic one and you can probably guess what's going to happen next. I'm going to convert to a parameter and go to metallic and we all spell that the same way and then the same thing again. So I'm going to right click on roughness, convert to a parameter, call that roughness."},{"start":"4:01","end":"4:31","startSec":241.1,"text":"Now I'll save again just to make sure everything's lined up and I think what I'll do is I'll change the roughness metallic value by default. So metallic value we mentioned is either 0 or 1 in the previous slide. So let's go to the default value here and let's just hit 1 for now and you'll see that it changes to a more metallic looking material. So just to show you the before and after, 0 and 1. So we've got a much more metal looking surface which we probably don't want for rock but"},{"start":"4:31","end":"5:06","startSec":271.3,"text":"I'll just show you in this example anyway. Maybe it's a precious type of rock. And then roughness, let's put the roughness value at 0.5. Somewhere in the middle gives us a bit more roughness. So you can see as the roughness is dialing up it looks, it still looks metallic but it's got a rougher surface so it's not as shiny which is probably what we want for an unpolished rock anyway. So we've got rock color, we've got metallic and we've got roughness. Now I can close this and if I open my content browser by hitting control and space bar,"},{"start":"5:06","end":"5:37","startSec":306.1,"text":"I might actually apply this to a surface here. So if you've just got a default surface in your scene, if you've created just an empty scene you could go to your shapes tab and drag and drop in a cube maybe if you wanted to drag and drop a cube in. We've got some basic geometry in the place actors here. So shapes, cubes, sphere, whatever you want to do. I'm going to press control and space bar and I'm going to get the rock material, I'm going to drag and drop it."},{"start":"5:37","end":"6:09","startSec":337.8,"text":"And you'll be able to see we've got this material inside the editor here. You'll see it preparing shaders on the bottom right hand side here and that's just figuring out how it's rendering this object. You can also see that there's a materials section here whenever you select a mesh. Now I could have quite equally if I just clear out this value by resetting this value, you don't need to do this but it goes back to its default value. I can make sure I select rock in my content browser, go back to select this and just plug"},{"start":"6:09","end":"6:40","startSec":369.9,"text":"it in using this and it assigns it as well. So whether you drag and drop or you assign it here, it's completely up to you. Maybe if you're assigning it here we can go back and add it to the favorites at the top, that would also be okay. But for now I think that's fine. The power now comes in material instances. So we've got our main material which is our parent material, we've not really defined it as parent, it's just inherently a parent because it's a material. Now let's create a child from this parent."},{"start":"6:40","end":"7:10","startSec":400.7,"text":"So I'm going to right click the rock and go to create material instance. So I'm going to create material instance and you can go with the naming convention that gives you. So it goes m underscore rock underscore inst or you could rename it. I sometimes go mi rock underscore o1 for example. So mi for material instance, rock for the rock and then o1 because I might be creating multiple of these."},{"start":"7:10","end":"7:44","startSec":430.7,"text":"Now if you want to rename something you can hit F2 with it selected or right click rename as well if you wanted to rename it from its default value. I'm going to double click the material instance now and we'll see that this is a condensed version of the material editor. We can see our material here. We don't have the node graph but what we do have are these vector and scalar parameter values that we added previously through the rock color, the metal and the roughness."},{"start":"7:44","end":"8:18","startSec":464.2,"text":"So we can actually tick the rock color, tick the roughness, tick the metallic. Well actually let's not tick the metallic for example because we know metallic either wants to be one or zero and I don't think I'm going to edit this. I think I'm going to leave all my material instances at one as metallic. So I don't, I mean you can leave it ticked to never change it but I'm just for demonstration purposes I won't tick metallic just because we're not going to edit that. So let's go to rock color and maybe we found instead of an amethyst style rock maybe we found a different, maybe you get rubies or whatever color you feel like going to and"},{"start":"8:18","end":"8:50","startSec":498.7,"text":"hit OK. And maybe I ramp that roughness up to make it more rough and I'll save that. I'm going to close it and maybe I duplicate this object by holding down Alt on my keyboard and left mouse dragging. Alternatively I could drag and drop another cube in but just to get familiar with these shortcuts it might be worth doing. So I'm going to open my content drawer again. I've got my rock here. Maybe I'll drag and drop it onto this object and you'll see that now I've got two different"},{"start":"8:50","end":"9:23","startSec":530.3,"text":"color of rocks and the power now comes. I can just right click duplicate and it goes to rock 02. It automatically names it the next one. I'm going to double click this. Maybe I'm going to click the color. Maybe I'll go to blue. Maybe I'll hit OK. Maybe I'll change the roughness to zero and it's a really shiny rock. I'm going to save it, close it and duplicate holding Alt and left mouse drag and you can see that I've got my rock selected there. Maybe this time I'll just plug it in through here."},{"start":"9:23","end":"9:56","startSec":563.7,"text":"So again I'm just trying to move faster now just so you can see that once you've got that base material set up you can start working very quickly and very efficiently using these material instances and the reason why the material instances have these editable properties if I go back into my main rock is because we created these scalar parameters. So again just a reminder I held down one and left clicked and by default it hasn't got"},{"start":"9:56","end":"10:27","startSec":596.0,"text":"anything. So I'm going to right click, convert it to a parameter which then allows you to give it a name. This name doesn't have to be roughness. That roughness doesn't need to align. If I called this roughness value for example and press save I wouldn't even need to call it roughness value. I could call it anything I wanted. I could call it zebra if I wanted and if I double click the material instance you can see roughness value now. So the name doesn't have to correlate with the actual thing that you're editing."},{"start":"10:27","end":"10:40","startSec":627.4,"text":"It's more just so you know exactly what you're editing. So hopefully that gives you a good idea about materials and material instances and then the power that you can get out of them by instancing and changing the properties per instance."}],"12_Lighting":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"So to close out this course, let's talk a little bit about lighting in Unreal Engine. So we have some lighting definitions and types. We talk a little bit about static versus dynamic and then also the different lighting types that you can see inside of Unreal. So the lighting definitions might be useful to start off with here. So direct lighting is light that falls onto a surface without any interference. Light travels directly to the surface and the surface receives a full color spectrum"},{"start":"0:32","end":"1:06","startSec":32.9,"text":"of light. So that's direct lighting in Unreal Engine. Indirect or balanced lighting is lighting that has been then reflected by the surfaces nearby. So you can see in the bottom right hand corner here, we've got some indirect lighting that is almost lifting that backside of the sphere to give it a bit of balanced light off the floor onto the sphere to give you a nicer more realistic effect. So as light bounces off these surfaces, light waves are absorbed or reflected based on the surface properties and passed to the surface you're looking at."},{"start":"1:06","end":"1:38","startSec":66.1,"text":"So again, when we're talking about PBR and we're talking about surface properties, this all plays a part in getting your realistic lighting and how much metallic and roughness and the bounce lighting that you have going on. All these properties work together to get your desired lighting result. So indirect lighting contributes to the mood and overall light intensity. When we talk about shadows, shadows happen when Unreal Engine takes a snapshot of a mesh from a light's point of view and projects that information onto another mesh actor on"},{"start":"1:38","end":"2:08","startSec":98.6,"text":"the opposite side. So you can toggle lights between static and dynamic lighting. Bait lighting is pre-computed rendered lighting. Bait lighting is created using Unreal Lightmass, a radiosity baker. And similar to rendering lighting in V-Ray or Corona or any of the other lighting tools that you might be used to, it's used to create high quality indirect lighting using light and shadow maps and it's baked lighting cannot be altered at runtime."},{"start":"2:08","end":"2:41","startSec":128.8,"text":"Because it's been pre-computed, you can edit that at runtime because all the light maps and shadow maps have been baked in pre-rendered. It has little impact on real-time performance with that. So if you're worried about performance and you want all the lighting controlled and baked, that's the route to take. Your real-time, in quotations, dynamic lighting is a type of lighting that is updated with each frame. It's fully dynamic and can be moved around and modified at runtime. Historically it has no global illumination component, only a direct light."},{"start":"2:41","end":"3:11","startSec":161.2,"text":"It can also be really expensive. You want to make sure there's not too many overlapping real-time dynamic lights. Unreal Engine can use both static and dynamic lighting in comparison. You don't have to pre-select whether you want all static or all dynamic. You can have, say, 85% you've seen static with 15% dynamic lighting where you might need it. So for archviz projects, typically stationary, which is kind of an intermediary between static and dynamic."},{"start":"3:11","end":"3:42","startSec":191.4,"text":"So stationary lighting inside of Unreal Engine is baked lighting that can accommodate dynamic actors. Ray tracing is a type of real-time lighting. Its global illumination is updated with all lights set to movable. If they are animated, the global illumination updates on the fly. But ray tracing is worth noting, requires advanced GPU hardware. So when we have our different light types that we're talking about, this place actors"},{"start":"3:42","end":"4:16","startSec":223.0,"text":"tab in our editor, as we saw when we were looking at the geometry tab before, you have a light tab and you can see all the different lights that you can select from. So when we're talking about directional light, which is essentially a sunlight or a moonlight source, you can drag and drop directional lights into your map. You've got point lights, which are omni lights, spotlights, rectangle lights, skylights. Laser can catch in the environment, HDR image based ambient light. HDR backdrops, which is a blueprint that helps you set up the light in your scene based on"},{"start":"4:16","end":"4:49","startSec":256.7,"text":"a HDR image. And the sun sky, which is a new feature in Unreal Engine, is a blueprint that automates the sun position in the sky based on geographical location. So if you want realistic time of day, that sun sky tool will really help you out very quickly. So the data and components, all the things that we require in the scene, we have a light source for the sun, generally a directional light, atmosphere, preferably linked to the sun to adapt its position. And then we also have a post-process volume, which is around the scene that can adjust"},{"start":"4:49","end":"5:22","startSec":289.4,"text":"the lighting solution, another end in aspects. So the post-process volume, again, we have courses on this in more detail, but essentially a post-process volume can be placed around a scene if you want it just within this specific place to affect the rendering aspects. You can actually, on the post-process volume, if you have one in your scene and you type unbound, you can actually say this post-process should impact the entire world if you wanted to. So have a play around with post-processing. There's a lot of powerful functionality there."},{"start":"5:22","end":"5:53","startSec":323.0,"text":"And then optional things are skylights to contribute to global illumination, a sky dome for a backdrop visual. You can have volumetric clouds. And if you want to use a light mass importance volume, you can. It's only needed for baked lighting and not needed when using lumens. So if you want to control your scene with static lighting, light mass importance volume will really help those bake times and give you the best quality static lighting. But essentially you can see all the different components in this diagram to help you set"},{"start":"5:53","end":"5:55","startSec":353.4,"text":"up the scenes in the way that you would like."}],"13_Outro":[{"start":"0:00","end":"0:25","startSec":0.0,"text":"So I hope you found that useful introduction to Unreal Engine and creating your first project. We've covered a lot of ground in terms of just the hierarchy of Unreal Engine, the different file types and then jumping into the editor, navigating the interface and talking about material setups and just different things you can do inside of Unreal Engine when you're creating your first scenes. So I hope you found value with that and thank you for watching."}]},"100.08":{"01_IntroAgenda":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Hello everyone, and welcome to today's class on transitioning from legacy production to Unreal Engine. My name is Brian Poole, and I'll be your guide throughout this course. Here's a quick look at what we'll be covering today. We'll start with you are here, and this will be a brief overview of a traditional production workflow, exploring its pipeline and understanding its strengths and weaknesses. Then we'll move on to where you need to be, and we'll define what makes an effective"},{"start":"0:31","end":"1:06","startSec":31.0,"text":"next generation pipeline. You'll learn how Unreal Engine meets those needs, and then take a look at real world productions who have successfully adopted Unreal into their studios. As we move on to our production overview, we'll break down a typical real-time pipeline, discuss its advantages and challenges, and look at the tools used for data management and team collaboration. Next, in exploring Unreal Engine, we'll dive deeper into Unreal's technical capabilities by examining project structure and Unreal's animation support tools."},{"start":"1:06","end":"1:20","startSec":66.0,"text":"And then finally, in final recommendations, we'll wrap up and I'll share some tips on optimal hardware setups, best practices within Unreal, shot planning strategies, and asset organization techniques. Alright, let's get started."}],"02_YouAreHere":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Traditionally, classic animation and visual effects production takes a waterfall approach to creating content. Generally that means that each siloed department produces a series of products that are published for the next department to use in order to create their content. This sets up a series of dependencies that limits a production speed based on the previous department's output. Think of it as an assembly line approach to creating content. While these siloed departments are capable of working nonlinearly, it's difficult to"},{"start":"0:31","end":"1:06","startSec":31.7,"text":"see the big picture without long waiting periods. And what if a director wants major change? The number of dependencies increases further down the waterfall. The compounded time and effort required to make those changes becomes even more complex when multiple software applications are needed to make the change. The traditional pipeline usually contains these departments or silos. Product development and pre-visualization, production design and look development, rough and final layout, performance capture and animation, effects and simulations, cinematic"},{"start":"1:06","end":"1:38","startSec":66.6,"text":"lighting, rendering, and editorial. These departments still exist in a real-time pipeline, but now we must improve how they work together, especially in a nonlinear workflow. In this slide, we can see a typical animation studio flow chart. It shows how data moves from one silo and its departments to another. While this is a simplification of everything that is going on, it's fairly universal to most pipelines. So let's take a look at these one by one. Number one, story development and editorial."},{"start":"1:38","end":"2:10","startSec":98.9,"text":"Here the story department creates a series of storyboards and scene descriptions that feed the production design team. They'll also work with the editorial and sound departments to produce a story reel from said storyboards and feed those sequences as reference to the layout team for blocking and shot production. Number two, production design and asset construction. The production designer and his or her team of art directors and concept artists will implement designs for various sets, props, characters, and other items for the film which"},{"start":"2:10","end":"2:43","startSec":130.4,"text":"are handed off to the modeling team where they are built, rigged, surfaced, and put into a scene assembly. Number three, blocking. Commonly known as rough and final layout, these teams are concerned with character blocking, shot and sequence construction, integrating animation, and placing the camera. Number four, performance. Here we obtain either classic key frame or mocap performance capture to animate our characters. Once shots are completed, they're sent back to the final layout team for camera refinement."},{"start":"2:43","end":"3:13","startSec":163.9,"text":"Number five, shot enhancement. This is a collection of multiple departments that produce necessary image enhancements to bring the shot to life. Number six, image output. Here lighting, rendering, and compositing are applied to shots to sweeten and finalize their appearance. And number seven, final editorial. This is where all rendered shots are assembled into a cut with finalized audio and sound effects."}],"03_WhereYouNeed":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"If it's your goal to build an effective next-generation animation pipeline, my first suggestion is to look at Unreal Engine for its ability to be an open platform. Unreal provides access to its entire source code. It possesses an extensive C++ API with support for many third-party extensions, and Epic remains committed to open standards so you can future-proof your data as you see fit. This ability to customize Unreal sets it apart from other applications. In addition to its entire source code, access to third-party libraries is happening every day."},{"start":"0:35","end":"1:12","startSec":35.0,"text":"Plus, if you aren't as skilled with coding as you'd like to be, artists can leverage a friendly visual scripting solution known as Blueprints to create advanced behaviors and interactions. There's also a Python scripting system to help automate tasks. This results in Unreal being a comprehensive toolset. It's designed to provide an effective solution for all departments so teams can come together under a single production hub. Whether it's traditional production, virtual production, interactive or immersive, Unreal has a solution for the most complicated projects."},{"start":"1:12","end":"1:46","startSec":72.0,"text":"Let's take a look at some of the recent technology upgrades in UE5. First off, we have Nanite, Unreal's virtualized geometry system which allows access to billions of triangles where poly budgets don't apply and normal maps are no longer necessary. Lumen, a fully dynamic global illumination system, removes the need for light map baking and provides real-time lighting interaction. Virtual textures are capable of leveraging 8K cinematic assets and spatialized audio is now able to create realistic sound fields for increased immersion."},{"start":"1:47","end":"2:06","startSec":107.0,"text":"The results speak for themselves with animation companies like RealFX and Braun Animation producing entire episodic productions within the engine. Epic has also produced its own example of what can be accomplished with Unreal Engine, Sequencer and its animation toolset. Check out the Mercat short film example for more."}],"04_RTPipeline":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"So how does this compare against the classical pipeline? Well, the story process is integrated and can be more easily modified throughout the production allowing directors to leverage a more live-action shot construction process. Next, Sequencer becomes the production hub and can even act as the editorial system if desired. This creates a very director-centric solution where the revision process is more interactive and the creative team can view final pixels directly in engine and in real time."},{"start":"0:30","end":"1:04","startSec":30.8,"text":"To help supplement Unreal's ability to work with other applications, Epic supplies Datasmith, a series of conversion libraries to help translate and test late incoming CAD and spline-based data into Unreal. This is a major benefit for members of the art department who heavily rely on CAD-based tools to construct concept art and precision models for physical set construction. These actions are further enhanced by Python to help automate these translations. This ability to aggregate data from multiple sources allows Unreal the ability to act as"},{"start":"1:04","end":"1:15","startSec":64.2,"text":"your central hub of production. If you have a need to work in another application, support is present to allow these applications to do what they do best and bring that work into Unreal if needed."}],"05c_DataManagement":[{"start":"0:00","end":"0:39","startSec":0.0,"text":"Alright, if you've downloaded the 100.8 zip file and did a right-click extract all, you'll get a folder that if you open it, you'll find an Unreal Project file, a source files folder, content folder, and config folder. I've got some extra folders in here, saved, intermediate, and derived data cache. These are generated when you launch the Unreal Project file, and they're used by Unreal to store various bits of technical and temporary data while the application is running. Whenever Unreal creates a zip file, it will remove these three folders for the sake of saving space. So double-click on the project file, and we'll go into Unreal."},{"start":"0:39","end":"1:13","startSec":39.0,"text":"Now that we're in Unreal, you'll find that we're inside of a third-person template. If you look around, you'll see that it looks pretty familiar. I'm sure you've seen it many times before. But what's different is that we have this generator in the center of the stage. This generator was built in a third-party DCC application, namely Maya. What we're going to do is take a look at the process in which Maya exports out an FBX file, and we take that FBX file and import it into Unreal. We'll also take a look at how all of the imported data correlates to what's saved on your hard drive."},{"start":"1:13","end":"1:47","startSec":73.0,"text":"When you open up this project, you're going to see that we have some folders inside of the content folder here. The content browser and this hierarchy over here on the left reflects everything that's on your hard drive. These four folders normally come with a template, third-person, splash, level prototyping, and characters. But this asset folder is something we've added. If you open this, you'll find that there is a generator folder, and inside of that, you'll see that there's a blueprint, which if you bring in, you'll see that we can add additional generators to the stage."},{"start":"1:47","end":"2:22","startSec":107.0,"text":"But we also see that there is a texture folder, a mesh folder, and materials folder. These contain all of the various textures associated with the geometry, the meshes that make up this object, and this set of materials. Now, all of this, like I said, is reflected on the hard drive of your computer. So if you go to your file explorer and we go inside of the content folder, which is here, content folder, you'll find that there is an asset folder here."},{"start":"2:22","end":"2:59","startSec":142.0,"text":"And if you double-click on this, there's the generator folder. And inside of that, here's the UAsset for the blueprint and the UAsset stored in the respective folders here. All of these UAssets are basically extracted from the FBX file, converted into UAssets, and they're optimized for performance. They're Unreal's proprietary format. Now we're going to take a look at where this generator came from. It was built in Maya. So if you go into your file explorer, source files folder, generator, you'll find a Maya scene directory here."},{"start":"2:59","end":"3:32","startSec":179.0,"text":"Inside of scenes, you're going to find that there's a generator.ma file here and a generator.fbx file that it was exported from. Don't double-click on this yet. What we want to do is we want to launch Maya and we want to do what's called setProject. When you set project and point to the folder where that scene directory exists, generator, it will set the workplace root. So when you do a file open scene, it'll point specifically to the scene directory and show you where the generator.ma file is."},{"start":"3:32","end":"4:02","startSec":212.0,"text":"It'll also let Maya know where all the source images and textures are. So let's take the generator and say open. Once this is open, you'll find that it looks pretty much like the generator that's in Unreal. It has all these various pieces of geometry associated with the generator. It also has inside of HyperShade all of these individual materials that are associated to the project."},{"start":"4:02","end":"4:36","startSec":242.0,"text":"And Unreal allows you to export data multiple ways. You can do a file export all in which it exports all the contents within the scene. You can select specific objects and just do a export selection. Or you can do a send to Unreal, set a specific Unreal project and point to its content folder, and it will save all the associated data in there. I'm just going to do a traditional select all of the objects I want and do file export selection."},{"start":"4:36","end":"5:07","startSec":276.0,"text":"This brings up a dialog box and it allows you to choose between what kind of file format you want to export. You've got a bunch of them that are in here, but what we want is fbx click export selection. And now you'll get another dialog in which you can set some options. We're going to leave all these general options alone. But if you go under geometry, you want to make sure smoothing groups is turned on smooth mesh and referenced asset content. No need to select triangulate here."},{"start":"5:07","end":"5:39","startSec":307.0,"text":"Everything coming into the engine is automatically triangulated so you don't need to do it here in Maya. We don't have any animation. We don't have any lights, but you do have textures. So you'll likely want to embed media to include those textures in the fbx file. Once we have that we select a name. So I'm going to call mine generator to an export. Once you're back in Unreal, I want you to right click in the content browser and create a new folder."},{"start":"5:39","end":"6:14","startSec":339.0,"text":"We'll call this new folder gen2 for our second generator. We're going to look at some of the ways that you can import fbx files into Unreal. So the first and most direct way is to just simply go into your file explorer, find the generator-2.fbx file that you exported out of Maya, and drop it into the gen2 folder. This will come up with an import dialog box, but before you click on import, I want you to notice something. If you scroll down to the bottom, you're going to get some extra information, and it will tell you this is a Maya 2025 file,"},{"start":"6:14","end":"6:51","startSec":374.0,"text":"and it's in a YUP world coordinate system. Now if you remember, Unreal is a ZUP coordinate system. So the importer will automatically apply a 90 degree rotation so that it's properly oriented. So let's click import. Once everything is imported, you'll see that we have all of our materials. We have our static mesh components of the geometry, and we have our textures down here at the bottom. If we were to grab all of our static meshes and drag them into the level, you'll see that we have our generator,"},{"start":"6:51","end":"7:26","startSec":411.0,"text":"and we can rotate this around and take a better look. You'll notice that all the individual component parts of the geometry are in the proper place, and if you look over here in the Outliner, everything is listed as a separate actor, but there's an issue here. This model was built at 000, and all of the pivot points of the separate component parts are also down at the base. This might not be what you want. If you want to have all of the pivots centered to the individual components, you're going to have to bring these into Unreal's modeling tools"},{"start":"7:26","end":"8:00","startSec":446.0,"text":"and re-center all of those pivots. That can be time-consuming. You might also notice that the geometry is almost fully white. There's a number of reasons for this. It could be that the FBX exported from the DCC might be trying to export shaders that are not compatible with Unreal's material system. If that's the case, you're going to have to reassign those materials. But don't worry. The material IDs and the individual UVs for the object are still intact, and those textures will pop into place really easy."},{"start":"8:00","end":"8:30","startSec":480.0,"text":"If you want a further explanation of how this is done, we have some other classes that talk about this. Check those out if you're interested. Now this import method does come with a few caveats. As mentioned, everything is brought in as individual actors. As long as all of these actors are selected, if you move the generator throughout the scene, everything is fine. But if you were to deselect and try to reselect, you're only going to grab one actor at a time."},{"start":"8:30","end":"9:10","startSec":510.0,"text":"You'll either have to select all of the actors again in the Outliner, or you'll have to select them in the viewport. And that can be a little bit challenging. So we can address this in a couple of different ways. The first off is we can right-click inside of the Outliner and create a group. Once a group is created, I can move the generator throughout the scene, deselect and reselect with ease. And it will select all the individual actors here. The other option is to take all the selected components, go up to this icon, click, and say, convert selection to Blueprint class."},{"start":"9:10","end":"9:48","startSec":550.0,"text":"I'll normally use Harvest Components, and I will call this Generator Blueprint. Once done, you'll be greeted with a viewport from the Blueprint, and everything looks great here. So we can close this window. And you'll find that you'll have a Generator Blueprint class item in your Content Browser. From here, I can just drag instances of this Blueprint into the level, and instead of getting all of those individual actors, you'll get just a Blueprint inside of the Outliner."},{"start":"9:48","end":"10:19","startSec":588.0,"text":"And if you look at the Details panel for that, you'll also notice all of those individual components are maintained here in the Blueprint. Now, the method that we just used to import in FBXs was fairly quick and efficient, but has its issues. It's a multi-step process. You have to create Blueprints separately. Your pivot points might not be in the exact place that you want them to be. So we're going to use a different tool called Import into Level."},{"start":"10:19","end":"10:53","startSec":619.0,"text":"And to do that, we're going to have to get rid of these guys first. So we'll go ahead and delete them. And I'm going to get rid of all of this geometry as well. For this next process, go up to File and choose Import into Level. Select the Generator 2.FBX and place it in an appropriate folder."},{"start":"10:53","end":"11:25","startSec":653.0,"text":"This will bring up a new Import dialog box, and underneath the Scene tab, you're going to find the Root node. If you open this, it's going to show you the hierarchy as it's depicted in the FBX file and in Maya. There are no groups here, but if there were, you could turn on the Create Content Folder hierarchy, and Unreal will create a series of folders in the Content Browser that reflect those groups and all of the objects inside of them. I also usually turn on Import as Dynamic. This will set the mobility of the incoming actor to Dynamic so that you can move it around on the stage."},{"start":"11:25","end":"12:01","startSec":685.0,"text":"There's also hierarchy type. There are three. There's Create Level Actors. That's where all the components will be listed as level actors in the Outliner. I don't want that. So we have Create One Actor with Components. That sounds promising. And then there's Create One Blueprint Asset. This will be similar to the demonstration that we previously gave, where the Import into Level command will actually create the blueprint for you and place the individual objects into them. I also will usually turn on Bake Pivot in Vertex. This will bake the pivot as it's seen in Maya."},{"start":"12:01","end":"12:34","startSec":721.0,"text":"So I'm going to go with Create One Actor with Components and Bake Pivot into Vertex. The Static Mesh options here basically allow you to turn on and off different component parts of the geometry. I just usually leave this all on. You don't need to change anything over here on the right. For Skeletal Meshes, we don't have any joints or any deforming geometry, so we can skip this. And for Materials, I want to make sure that all my Material IDs are turned on so that when I Import this, I can reassign Textures as needed."},{"start":"12:34","end":"13:08","startSec":754.0,"text":"So let's Import. Upon Importing, you're going to see something similar. You're going to find your Materials, all your Static Meshes, and down at the bottom will be your Textures. However, if you look over in the Outliner, you're going to find an Actor called Generator 2. If you select it, you'll find our Generator hiding in the middle of the stage here. We can go ahead and pull this out. And we'll rotate it around. And you'll find that the Actor has all of its individual component parts in the right place."},{"start":"13:08","end":"13:42","startSec":788.0,"text":"But if you go to the Details, you'll find that under the Actor are all the individual components, the Generator, Display, Modules, and so forth. What's nice about this is that all the individual PIVots are now where they're supposed to be. So if you do need to make some modifications or changes, the PIVots will be where you expect them. Now, if you wanted to do something different, you could import this in as a Blueprint. And instead of having a Generator 2 Actor, you'd have a Blueprint down here in your Content folder that you could bring into the scene."},{"start":"13:42","end":"14:10","startSec":822.0,"text":"Now, you'll also notice that there are a bunch of stars here. This just means that all of these items have not yet been saved. So if I do a File, Save All, all of that will go away. And now all of these files are written to the hard drive. And if we go to our File Explorer, we can go in and find in the Content folder under Assets, a Gen2 folder, where all of those UAssets have now been written."},{"start":"14:13","end":"14:46","startSec":853.0,"text":"Alright, let's continue. Let's go ahead and conduct a little practical demonstration. Say, for example, you want to change the appearance of the original Generator that's up on stage. Maybe you want to alter its geometry. If we go back to the original Asset folder for this Generator, we want to change something within its Meshes. So we're going to look for what we want, and it would be, say, this Generator Static Mesh. If we go back into Maya and select the Generator and switch over to Face Mode, and we can grab some individual faces here,"},{"start":"14:47","end":"15:18","startSec":887.0,"text":"and pull them upward and say that's the change that we want to make. We're going to save everything again, just so that we have a full version. We do a File, Export Selection, and we'll do a Generator V3, and click Export Selection. And now we go back into Unreal. And we select this Generator and right-click and do a Import with New File."},{"start":"15:18","end":"15:35","startSec":918.0,"text":"We can select the V3 version of the Generator and click Open. What this will do now is it will rewrite the UAsset file with the new data and the appearance of the Generator has changed. Alright, this concludes this demonstration. Thanks again."}],"06_Collaboration":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"When it comes to working with others, Unreal takes a different approach to sharing data and collaborating with teammates through an embedded source control system. In traditional workflows, the data pipeline is usually decentralized and frequently spread across multiple servers and departments, each having their own ways of handling data and their unique files. DCCs are usually dependent upon using a referencing system to pull data from a central server through the network in order to work on your file. If your network is slow, or is being accessed by dozens or even hundreds of personnel, your"},{"start":"0:34","end":"1:06","startSec":34.9,"text":"productivity can be negatively impacted. Comparatively, Unreal utilizes an optimized asset file known as the UAsset. All imported data, whether it's animation, model files, textures, or other pieces of information are converted into UAssets and stored within the Artist's local content folder. Since the data is local to the Artist's machine, access to that data is substantially improved. So how do you get one teammate's UAsset files to everyone else on the project?"},{"start":"1:06","end":"1:39","startSec":66.6,"text":"You utilize a central database program like Perforce, Subversion, Git, or Plastic to fetch or push data back and forth between each artist and a centralized depot. The epic preferred standard is to use Perforce. Perforce control prevents any two artists from working on the same file at the same time, and version control is handled through atomic transactions that prevent data loss. All alterations or new data is recorded and stored in a change list so that it can be accessed at any time to recover or revert data."},{"start":"1:39","end":"2:11","startSec":99.8,"text":"All of this can be greatly simplified by using Epic's supplied tool known as Unreal GameSync to help manage change lists and automate many of Perforce's functions. In traditional pipelines, it's common to see models and animation files tracked by version numbers. This is recommended for the original files produced by your DCC, but the exported FBX data that is brought into Unreal can remain a versionless Source Master. Unreal is capable of monitoring if the file is updated and can automatically update for"},{"start":"2:11","end":"2:42","startSec":131.8,"text":"any new exports if they're placed in a folder which is tracked by Unreal, or you can update it manually. Your source control system and Perforce will track the changes made to any U asset in Unreal. If you need to make alternate levels or level sequences, Unreal provides options like duplicating the level or using the take system in Sequencer. Just be sure to keep your leads informed. For dedicated shot tracking, Unreal integrates with Autodesk's Flow Production Tracking,"},{"start":"2:42","end":"3:11","startSec":162.1,"text":"formerly ShotGrid, or some of you may know it as Shotgun. Edit plugins will need to be activated within Unreal, and a Flow subscription will need to be purchased. USD integration is also available in Unreal through a series of plugins. Once activated, these plugins will provide access to the USD Stage Actor and Stage Editor. With Python support, this Pixar-based exchange format will help control selective loading and unloading of scenes with greater efficiency."}],"06_Collaboration_56":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"When it comes to working with others, Unreal takes a different approach to sharing data and collaborating with teammates through an embedded source control system. In traditional workflows, the data pipeline is usually decentralized and frequently spread across multiple servers and departments, each having their own ways of handling data and their unique files. DCCs are usually dependent upon using a referencing system to pull data from a central server through the network in order to work on your file. If your network is slow, or is being accessed by dozens or even hundreds of personnel, your"},{"start":"0:34","end":"1:06","startSec":34.9,"text":"productivity can be negatively impacted. Comparatively, Unreal utilizes an optimized asset file known as the UAsset. All imported data, whether it's animation, model files, textures, or other pieces of information are converted into UAssets and stored within the Artist's local content folder. Since the data is local to the Artist's machine, access to that data is substantially improved. So how do you get one teammate's UAsset files to everyone else on the project?"},{"start":"1:06","end":"1:39","startSec":66.6,"text":"You utilize a central database program like Perforce, Subversion, Git, or Plastic to fetch or push data back and forth between each artist and a centralized depot. The epic preferred standard is to use Perforce. Perforce control prevents any two artists from working on the same file at the same time, and version control is handled through atomic transactions that prevent data loss. All alterations or new data is recorded and stored in a change list so that it can be accessed at any time to recover or revert data."},{"start":"1:39","end":"2:11","startSec":99.8,"text":"All of this can be greatly simplified by using Epic's supplied tool known as Unreal GameSync to help manage change lists and automate many of Perforce's functions. In traditional pipelines, it's common to see models and animation files tracked by version numbers. This is recommended for the original files produced by your DCC, but the exported FBX data that is brought into Unreal can remain a versionless Source Master. Unreal is capable of monitoring if the file is updated and can automatically update for"},{"start":"2:11","end":"2:42","startSec":131.8,"text":"any new exports if they're placed in a folder which is tracked by Unreal, or you can update it manually. Your source control system and Perforce will track the changes made to any U asset in Unreal. If you need to make alternate levels or level sequences, Unreal provides options like duplicating the level or using the take system in Sequencer. Just be sure to keep your leads informed. For dedicated shot tracking, Unreal integrates with Autodesk's Flow Production Tracking,"},{"start":"2:42","end":"3:11","startSec":162.1,"text":"formerly ShotGrid, or some of you may know it as Shotgun. Edit plugins will need to be activated within Unreal, and a Flow subscription will need to be purchased. USD integration is also available in Unreal through a series of plugins. Once activated, these plugins will provide access to the USD Stage Actor and Stage Editor. With Python support, this Pixar-based exchange format will help control selective loading and unloading of scenes with greater efficiency."}],"07_ProjectLogic":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Now we're going to examine Unreal's project logic and its approach to shot production. It's not a coincidence that Unreal Engine's project structure bears a certain similarity to the structure of film production organization. The Unreal Engine project is designed with progressive layers of complexity controlling scenes, actors, and various technical capabilities. Like nested containers, each entity handles a specific function and communicates with each other to help you produce your final film."},{"start":"0:32","end":"1:03","startSec":32.0,"text":"This film analogy continues to integrate the way Unreal refers to its sequence terminology. While there are many new game-centric terms and tools that a user will have to learn, sequencer can accommodate more common workflows like accessing specific scene assemblies, supporting multiple performance takes, camera layouts, shot construction, and sequence organization. This brings us to sequencer, one of the central tool sets in Unreal for creating linear animated content."},{"start":"1:03","end":"1:39","startSec":63.0,"text":"Sequencer is designed to function as a non-linear editing and assembly tool. Actors from the viewport or assets from the content browser are added into sequencer to create level sequence assemblies. The best way to think about a level sequence is to think of it as a virtual container that holds 3D animated footage that's spread across time. Level sequences can be nested inside of one another through the use of a shot track to insert shots into longer sequences and beats of action. Combined with sequencer's take system, the user is capable of creating sophisticated nested hierarchies similar to the way films are organized."},{"start":"1:39","end":"2:12","startSec":99.0,"text":"Films contain sequences, sequences contain shots, and shots can have various takes. Sequencer's UI is fairly simple. There is a toolbar where all of your primary tools and settings are located. There is also the track outliner that stores the items that you wish to animate. There is the timeline where the shots, keyframes, and animation sequences in sub-scene tracks reside. And finally, there is a set of playback controls down in the left-hand corner. Sequencer can also access two very important sets of tools."},{"start":"2:12","end":"2:43","startSec":132.0,"text":"The event manager used to trigger specific events and blueprints at specific points of time on the timeline, and the curve editor, a traditional editor used to modify keyframes, their curves, and tangents. Another crucial tool is the level editor. Project organization is critical for organizing your environment through various sub-levels. The primary level that pairs specifically with your master level sequence contains the persistent level. By default, anything added to the level will be placed here."},{"start":"2:43","end":"3:13","startSec":163.0,"text":"By double-clicking on any additional sub-levels, actors can be placed on that sub-level to be used for specific purposes. Depending upon your particular project, levels and sub-levels can be used to organize your environment, lighting, effects, or whatever you need. Within Sequencer, these levels can be turned on or off by using visibility tracks. The sub-scene track is a specific sequencer entity that allows you to layer level sequences within a level sequence for the sake of departmental organization."},{"start":"3:13","end":"3:43","startSec":193.0,"text":"Please note, this feature is different from nesting level sequences together through the shot track, which is used to insert shots into a longer sequence. Sub-scene tracks are level sequences that handle very specific types of animation. For example, a specific sub-scene track can be devoted to handling various effects that you wish to layer into your shot, like Niagara particles. Sub-scene tracks can be nested as many times as necessary to separate work between various departments or artists."},{"start":"3:43","end":"4:19","startSec":223.0,"text":"Since they are level sequences, they are saved as separate files that can be checked out via source control for work without interfering with other artists working on your sequence. The next concept we're going to explore is actor persistence. In Unreal, actors are one of three types, possessibles, spawnables, or replacables. Possessible actors persist in a level indefinitely, and they can be controlled or shared by multiple level sequences. If you know you have specific actors or characters that will be used regularly, keeping them as possessible makes sense for ease of access and repetitious use."},{"start":"4:19","end":"5:00","startSec":259.0,"text":"Spawnable actors only exist within the active level sequence. They're identified within Sequencer and the Outliner by a lightning bolt icon. This type of persistence is excellent for temporary actors who are needed for specific needs within the shot. Perhaps some extra lights, or a background actor who shows up just for the shot and then is no longer required. The idea of spawnables is appealing because it can keep your level and its environment free of unnecessary actors when they're not needed. The final form of persistence is replaceable actors. This blueprint-driven form of persistence is dictated by the binding lifetime track and allows you to swap out actors as needed."}],"08_AnimSupport":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Thanks to its acquisition of 3Lateral, Epic has advanced its digital human initiative through the creation of MetaHumans. The latest version of MetaHuman Creator is now embedded into Unreal Engine 5.6 for better functionality and project integration. This allows for faster turnaround times and better ease of use. Updates to LiveLink Face and MetaHuman Animator allow you to take advantage of your iOS device to stream data directly into Unreal with your phone in real time."},{"start":"0:31","end":"1:03","startSec":31.0,"text":"These tools, when combined with regular body motion capture devices, will allow users to animate humans on an unprecedented level. For traditional-based DCC animators working in Maya, Maya LiveLink is now available on the Autodesk website. This tool will allow users to connect both applications together to take advantage of their Maya skill sets while simultaneously seeing animation and rendered content in Unreal. As of the creation of this slide deck, Maya LiveLink currently supports Unreal Engine 5.5.4."},{"start":"1:04","end":"1:43","startSec":64.0,"text":"Another important tool for any animator or cinematographer's arsenal is Unreal ViewCam. This tool leverages an iPhone or an iPad to transmit position and rotational data via LiveLink to drive the camera in real time. This capability allows the user to capture that handheld feel, or when paired with some sort of camera rig, the user can create more controlled shots. For those of you worried about not having an Apple product, ViewCam is now available for Android. It's required that you use Unreal Engine 5.4 or later and have an Android device 7 or greater with the Unreal ViewCam app installed."},{"start":"1:44","end":"2:08","startSec":104.0,"text":"There are also a number of fantastic third-party companies that provide excellent motion capture, animation, and production tools for Unreal. Many of their software products or plugins can be found on FAB. If you're looking for mocap solutions or related tools, you have plenty of options to choose from. Thanks for watching."}],"09_FinalRec":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"When working an Unreal Engine, it's important to have the right hardware for the job. If it's your intent to animate within the engine and leverage tools like MetaHumans, LiveLink, ControlRig, or other processor and GPU intensive tasks, Epic recommends an Intel i9 or AMD Ryzen 9 5950X or better processor. Gets 64GB of RAM and a solid state hard drive as well. It's also important to choose a proper GPU."},{"start":"0:30","end":"1:00","startSec":30.2,"text":"By examining your role in production, you can make a solid choice of which car to buy. Modellers, shading artists, and animators can be served very well by an RTX 4080, 4090, 5070 Ti, 5080, or 5090 GPUs. Whereas lighting artists, rendering specialists, and virtual production teams are required to use powerful GPUs with higher-end GPUs like the RTX Pro 5000 and 6000 Blackwell, RTX"},{"start":"1:00","end":"1:32","startSec":60.6,"text":"6000 and 5000 Aida, or the RTX A6000 or A5000 Ampere-based cards. When it comes to level management and organization, the best practices dictate placing all of your commonly shared global actors into the persistent level while dividing up your action into beats. These beats can have their own dedicated level. Once that's accomplished, sub-levels can help manage your scene assembly organization. Be careful not to have too many sub-levels because that can be difficult to manage."},{"start":"1:32","end":"2:04","startSec":92.9,"text":"Level visibility can turn on and off sub-levels as the shot requires, and when rendering, it's wise to change the streaming method for your sub-levels to Always Loaded. This will place the sub-level into active memory for faster access. When planning your shots, consider optimizing your foreground, mid-ground, and background elements to ease your rendering burden. Single-level sequences with a single camera cuts track can be great for setting up master shots with multiple coverage cameras. Plus it's great for simple editing."},{"start":"2:04","end":"2:38","startSec":124.9,"text":"For distinct shot-based workflows, it's recommended that you nest your level sequences together with a shot track. This will provide greater organization and accessibility for non-linear workflows and makes your team work easier. Try not to exceed more than three levels of nesting, and if you need alternates to your shots, use the Take system to swap between level sequences. Many people wonder what are the best practices for using actor persistence. Choose spawnables for temporary background actors, custom shot-specific lighting, or"},{"start":"2:38","end":"3:10","startSec":158.8,"text":"one-off effects. Make sure you're not parenting to the spawnable actor because those actors will disappear after the level sequence ends. This will kill any parenting setup for those spawnable actors in the level. Attached tracks or constraints might be a better idea. Spawnables also have the advantage of reducing memory overhead for those actors who are not in use. As for possessibles, use these actors for fixed assets, scene environments, or characters planned to be used throughout all shots."},{"start":"3:10","end":"3:36","startSec":190.9,"text":"Unlike spawnables, possessibles are not destroyed after the shot completes, so they're always accessible. We also have some resource links available for you. These white papers, communities, and online documentation will help guide you through potential questions you might have. Okay, this concludes our lecture on transitioning from legacy production to Unreal Engine. Thank you."}]},"100.09":{"01_Introduction":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hello, and welcome to today's training on the first project in Unreal Engine for Automotive. And today we're going to be breaking this into two parts. We'll go over UEFI basics in part one, which includes how to open the launcher, projects and templates, the UI of the engine and the navigation of the engine, and placing and transforming objects. Just basically getting familiar with the engine and learning how to place and move things around. And then we'll go over importing some data."},{"start":"0:30","end":"0:35","startSec":30.3,"text":"Then in part two, we'll cover some lighting materials and the landscape and foliage tool."}],"02_Unreal Engine Resources":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Just to touch upon some Unreal Engine resources, we have two main places to go for the topics here which is the Learning Library and the Epic Games Launcher. The Learning Management System is a recent addition and here you can follow a guided learning path. There's plenty of content here to dig into and it's also connected to the community which is great because you can get feedback on certain information you might need. You can also learn from industry experts here, so people will be putting tutorials"},{"start":"0:33","end":"1:04","startSec":33.3,"text":"and project samples down here so you can pull them apart and learn for yourself. It can also test your knowledge so you can complete the courses and just upskilling the areas that you need to. And you can also build a learner profile used for the same login on the Unreal Engine Launcher which I'll get into in a second but it's a really nice centralized place for your learning resources here. And then the Epic Games Launcher, so you can learn about upcoming features, you can see the live streams that are currently happening."},{"start":"1:04","end":"1:23","startSec":64.0,"text":"We've got featured content that might inspire some of your projects. You can access the Marketplace from here which is a tab at the top of the Launcher there in the middle section of the tabs. You can install engine updates so get the latest version of the Unreal Engine and you can also access your Marketplace downloads from here for use in your own projects."}],"03_Overview of File Structures":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"So it's probably worth touching upon the file structure of Unreal Engine just to get yourself familiar with how Unreal handles different files and folder structures. So we'll go over projects and templates to show you how to set them up. I will also talk about the files and folders and then the overall structure of your projects to give you a better understanding. So first off, tackling projects and templates. So we have our project browser here where you open the projects."},{"start":"0:31","end":"1:01","startSec":31.1,"text":"You'll always start a new project from this location. And so essentially what we have is you can see the different tabs on the left hand of the image. So you have recent projects, games, film, video, live events, architecture and automotive. And these are almost different presets that you can select that give you some prerequisite information on your projects and how to use different features and functionality. It is to say that if you select one project type over the other and wish to change, you can do that inside the engine."},{"start":"1:01","end":"1:34","startSec":61.6,"text":"However, some of the default configurations will be different and you'd have to go through and change them all. So it's not to say that it can't be done, but it's probably an easier starting point to pick the relevant prefab here. And then you have a series of projects that you can choose from depending on the different topic area. So maybe you just want a blank project that has none of the content in. Maybe you want some kind of different preset setup so you can get straight into the work that you want to create. And then you can do that through the different configurations here."},{"start":"1:34","end":"2:07","startSec":94.8,"text":"It's also worth noting that just give yourself a good project name in the bottom right so that instead of my project, it's named something you'll remember later. It's always good to save the project location on an SSD drive if you have that to hand because that's going to be the fastest way to access Unreal Engine. When talking about project files, so essentially if we go over the traditional app workflow here, we have our software and we save a scene. Maybe it's in Maya, so we save the scene as a Maya binary file and then it just saves"},{"start":"2:07","end":"2:38","startSec":127.6,"text":"as a single file. So whether you're using Photoshop or Word or Maya, each one has a kind of relevant file naming system. So Photoshop or PSDs, Word, doc files, and then Maya, Maya binary files. And that's how a traditional app would save to visualize your scene inside of the relevant software. In Unreal Engine, all assets are imported, whether that be models, textures, audio, animations, they're all stored in a content folder as UAsset."},{"start":"2:38","end":"3:12","startSec":158.7,"text":"So UAsset just means a real asset and they're all stored as individual files that you can access. Levels are saved as UMaps, so the scenes that you are creating are called UMaps, Unreal Maps, and then the projects are saved as UProjects. And we'll go over this in a second in terms of the hierarchy here, but they're useful things to just consider for now. So if we're looking at the Unreal Engine section, we have the level editor, we have the asset editor, we have a material editor, and each time you save a file, it will go to its relevant"},{"start":"3:12","end":"3:46","startSec":192.9,"text":"Unreal Assets. If you're using the level editor, you've got a Maya level. If you're using the assets, it's Maya model, or maybe a material, Maya material. And again, you change these naming conventions, but essentially you're seeing the asset extension, so UAsset or UMap. So that's a useful thing to consider here. Again, when you're using Maya or Photoshop, you'd export from Maya to an FBX, and then the FBX comes into Unreal still as a UAsset. Even though you export it as an FBX, it'll turn into a UAsset."},{"start":"3:46","end":"4:20","startSec":226.6,"text":"Same with PNGs or PSDs or anything like this. They'll, well, PSDs won't import, but PNG will go in as a UAsset. So then talking about the folder structure, where all your files are stored, you'll see that we've scrolled to our Unreal Projects section in our Documents folder, which is the default location. You may have picked a different location, but you'll see there's a config folder, content, intermediate, saved, and then the UProject. So the UProject is this blue icon that you'll always double-click to open your project."},{"start":"4:20","end":"4:52","startSec":260.5,"text":"And so this will house all the information above, and the UProject is more of a director to access all these files. Going through step by step, the config folder stores, as you'd expect, all your configurations of your project. So if you've changed any settings in the engine, whether it be project settings or engine settings, maybe you've set up certain inputs for your projects, they'll all be housed in the config. And you can access these directly from the engine, but the files are stored in the config"},{"start":"4:52","end":"5:25","startSec":292.3,"text":"folder. Content is where all the assets are being stored that we were referring to on the previous slide. So whether that be animations or models or textures or anything like this, they're all stored in your content folder. The intermediate and saved folders, the intermediate is more of a cached folder. You don't have to take this with you to make your projects work. Sometimes it can be a lot of gigabytes of information. And if you didn't copy this across and you only had your config and content folder plus your UProject, your UProject would likely load."},{"start":"5:25","end":"5:55","startSec":325.5,"text":"The saved folder, however, has maybe some saved data in there that you need. Maybe it's only got auto saves, but if you have exported any movies or you have saved any screenshots directly from the engine, all this saved information will go into the saved folder. So your actual saved files, your saved maps, they are all in the content folder. Like the main bits of content is still in the content folder. Saved is just for if you've exported anything from the engine and you've not moved it out"},{"start":"5:55","end":"6:26","startSec":355.9,"text":"of that directory. So just make sure you don't lose any information there. Again, if it's only auto save data, then you don't necessarily need it for the project to run. So, and then you can see the windows of the materials and meshes folder. So you can see that they're essentially all just UAssets at this point. So for the naming convention, we do M underscore for a material, which you see in the middle window there. And at the bottom window, you see SM underscore, which just means static mesh underscore, and then you'll see all the meshes."},{"start":"6:26","end":"7:00","startSec":386.0,"text":"So essentially, you can see the folder structure and you can see all the individual assets listed there, which is a really useful viewer, but they're all UAssets. So they're not their FBX exports or whatever you might have exported these files as. So it's just useful to consider those. And then the folder structure, the project structure, sorry. So the project, that blue icon, the U project that we showed you in the previous slide, that houses all of this information. So the project is a container. It's almost like a wrapper for everything that goes on inside the project."},{"start":"7:00","end":"7:25","startSec":420.2,"text":"So then you'll have levels stored where the scenes that you open that you use to edit the content that you've got in those levels and then act as all the individual assets, whether they be audio files, animations, static meshes, they're all actors placed in the scene. So that's just hopefully a useful representation of the project structure and a useful overview of how the files and projects work."}],"04_Content Workflow":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Let's talk a little bit about content workflow now. So the topics we want to cover here are working with the assets inside of Unreal, whether we use ready-made assets, which are Starter Pack or the Marketplace or Quixel library, or we have custom assets that you're importing yourself via FBX or Datasmith. And then we'll discuss the Static Mesh Editor. So some useful hotkeys to use for your viewport navigation. It might just help to either screenshot this screen or write them down."},{"start":"0:32","end":"1:05","startSec":32.8,"text":"Just some useful buttons here to click whilst navigating the interface. And we'll dive into the editor as well later on as well. So the content workflow, we have starter content, which on the bottom left-hand side here you can see that when you select some of the project templates, in the bottom right-hand side you'll see starter content tick box. So that will include any content that you might want to use by default for your scenes, just to edit content, move them around, manipulate them in your own way."},{"start":"1:05","end":"1:36","startSec":65.0,"text":"But it just gives you a library of assets to start with there. We also have the Marketplace, which we referred to on previous slides. On the top right-hand side here, we have the Marketplace tab on the launcher, where you can find different files and templates to add to your own projects. If you see anything on there that you want to add, you can just click the button add to project. You might have to purchase it first, but there's a lot of free content on there as well. And they're easily integrated into your projects."},{"start":"1:36","end":"2:08","startSec":96.1,"text":"And it's worth noting that even if you've already got a project and you may want to add some Marketplace content to that, you can always add it to the project after the fact. So you can always add more content if need be. The Quixel library is accessed through the editor as well. And you can see this on the bottom right-hand side. And there's lots of information on Quixel and lots of great assets to download, all high-quality assets and free to use for Unreal Engine users. And we can also migrate assets from one project to another."},{"start":"2:09","end":"2:42","startSec":129.6,"text":"So it's worth noting that maybe you have some content you've got in one project that you want to move to another project. We can actually migrate this information from one project to the next. And I'll show you how to do that in a few slides as well. So before you export your DCC or your CAD app, we want to make sure we're using descriptive names for the objects and materials. So make sure everything is named what it should be. Make sure they're not just, you know, a geometry shape underscore 01 or any default name and just objects or something like this."},{"start":"2:42","end":"3:14","startSec":162.8,"text":"Make sure you have everything named correctly and the materials assigned how you intend them to be inside of Unreal. You want to make sure the scene is well organized and combine any meshes together that you don't need all individualized. You want to make sure your meshes are clean and consistent with proper UV layout. You also want to pay attention to objects that have been scaled. So you want to make sure that everything is just a scale of 111. And especially so for non-uniform geometry as well. So ideally everything's coming into the editor at a scale of 111,"},{"start":"3:14","end":"3:45","startSec":194.9,"text":"which is your scale and your transform and your rotation in a world zero essentially. And we want to make sure the scenes, if they're not at world zero, just move them as close to world zero as you can because the further out you get, we get some rounding errors happening. So just yeah, X, Y, and Z zeroed out there and then reset pivot points and ensure they're in the right place. So you can actually reset the pivot points in Unreal Engine."},{"start":"3:46","end":"4:15","startSec":226.1,"text":"And there is a tool to do that. However, it's always good just best practice, have your assets in the stage that you want them to be at when they come into Unreal Engine. You can make edits and manipulate the content inside of Unreal Engine, but it's best to have them from your DCC app or CAD app as you intend them to be from the get-go. So which world to take? We can use either FBX or Datasmith. So with the FBX exporter, you manage your system units if you are planning to use FBX workflows."},{"start":"4:16","end":"4:46","startSec":256.3,"text":"We use centimeters as a base unit to match on Unreal Engine system. So in your DCC app, just make sure your units are set up in centimeters and make sure your objects are centered to the world and that their pivot is zero zero as we mentioned before. However, with Datasmith, first of all, you need to make sure you have the exporter for your DCC of choice. So there's a hyperlink here which you can go to the website and it has the exporters for 3ds Max or SketchUp or whatever DCC app you're using."},{"start":"4:46","end":"5:12","startSec":286.7,"text":"So you don't need to worry as much about the scene units here because the Datasmith converter takes care of everything and it also reads and imports your CAD formats natively. It works well with fully assembled scenes and large data sets. It's also compatible with more material types that FBX can provide and you can export full scenes or partial ones. The simple exporter in the UI can also default to what is only visible on the screen."}],"05_Unreal Engine User Interface":[{"start":"0:00","end":"0:20","startSec":0.0,"text":"So, I think it's about time we jump into the editor to show you the user interface and how to manipulate the content inside of Unreal. So we'll talk about the engine interface and the different components. We'll talk about object control and transforms, and we'll also talk about the toolbar."}],"06_Workshop- User Interface":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"And so as we start using Unreal Engine, I've just selected a third person example map from the launcher and from the games tab as well. You can select whichever project. I'm not going to be using anything specific to this project, but just in case you did want to follow along, I've launched the launcher and selected games and then third person template. So and yours may look a little bit different depending on which Unreal Engine version you're"},{"start":"0:32","end":"1:03","startSec":32.4,"text":"using as well. It's worth noting there. But yeah, today we're covering the actual overview of the editor, so nothing should be changing and you can also just watch along if preferable. So let's talk about the UI and the overall layout of Unreal Engine. So at the top here, we've got a few different buttons you'd maybe expect with most pieces of software. You know, in the file menu, you've got a few save and export and options in edit. It's useful to highlight the editor preferences and the project settings here."},{"start":"1:03","end":"1:33","startSec":63.1,"text":"If you want to change any editor functionality, you can go there, say, binding hotkeys to certain buttons or anything like this. And any project settings you may want to change when it talks about cooking your projects or editing the maps or anything like this. And then also your plugins can be accessed through here if you're downloading any external plugins for use inside of Unreal. On the window, if you lose any of the side windows that are found around the outside of the screen here, they can be found from this tab."},{"start":"1:33","end":"2:03","startSec":93.5,"text":"So say we didn't have a levels tab open, for example, I could select levels and the levels tab appears here. I can drag and drop it around, but I can also dock it into any of the windows that I want here. So it's a really nice snapping system. I generally put levels up here. It depends if you work with levels, for example, but like I said, you can find all your windows here and you can also find your Quixel Bridge and your marketplace here and also save certain"},{"start":"2:03","end":"2:38","startSec":123.8,"text":"layouts depending on how you're editing your content. Maybe you want a viewport configured for a certain type of project and you want to change different layouts. That's also found in here as well. So I won't go through every option, but just so you know, you can scroll through those lists and find a good overview. This is your main toolbar here for use inside of Unreal Engine. So you can save your map, selecting the modes. When we talk about foliage and landscape later on, we'll be finding them in this browser here and you can also paint meshes, fractured meshes and also do some BSP editing, which"},{"start":"2:38","end":"3:12","startSec":158.9,"text":"is your binary space partition brush. I believe that's what it stands for. And it's just some basic brush geometry that you can use. You can also find your animation tab here. We can also quickly add actors to the scene, although you'll notice that we can also see these actors here as well, but you can add things quickly here. This is where you will start doing your blueprint visual scripting. If that's something you need for the use inside of Unreal, you can create cinematics from this button and I can also press play and I can jump straight into the game here and"},{"start":"3:12","end":"3:44","startSec":192.7,"text":"hit escape to come back out as well. So a few different properties for when you actually want to play the experience and then you can also package for the different platforms that you want to package there. On the left hand side, we've got our different tabs here. By default, we've got our place actors selected. So say we wanted to place a point light, we could just drag and drop this point light across and it'd be there. I'll just hit that delete for now. Some of these actors you'll use frequently."},{"start":"3:44","end":"4:17","startSec":224.7,"text":"You've got specific tabs just for lights or basic shapes that you want to drag in. So if you want a cube, again, it comes with some basic functionality, cinematics, visual effects, geometry, et cetera. So a lot of this content can be found that you're placing in the maps here. Now in terms of your either starter content or content that you're importing directly inside of Unreal, they can be found in the content browser or the content drawer. I'm going to find the content drawer now because it's a nice little shortcut inside of UE5."},{"start":"4:17","end":"4:49","startSec":257.0,"text":"So I'm going to press control and space bar and it pops up this drawer here, which is a really nice functionality. So this is essentially your content browser. You can find all the content that you've imported here. So if you did click starter content, for example, you'll probably see all this content. And if we went to say props, I can double click that folder and I can find a chair, for example, and place the chair in the scene. So it's a really nice quick draw to access the content. And I'm just hitting control and space bar to find that."},{"start":"4:49","end":"5:19","startSec":289.0,"text":"You can also have your content browser here, which is pretty much looks the same as a content drawer. So again, you can find the window and then your content browser up here. You can have multiple versions of your content browser as well. So if you can't see that content browser window, you can add it from there. But getting into the habit of hitting control and space bar to find your content drawer, that really gives you a lot more real estate to work with, especially if you're limited on screen space. You can just pop it open, find the thing that you want and pop it down."},{"start":"5:19","end":"5:51","startSec":319.9,"text":"It's worth noting that that can be found inside the blueprint editor, in the material editor. You can find this window in all the different editors, whereas the content browser is mainly just in this viewport. So moving over to the right hand side here, we've got our outliner, which lists every single actor inside of this map. So when I select the stairs, it will show the stairs that are selected. And if I just give this a bit more real estate by scaling it down, you can see everything is here and everything is labeled inside of subfolders."},{"start":"5:51","end":"6:22","startSec":351.8,"text":"And it's just a really nice way to organize everything that is in your scene. And then showing the details panel here. So because I've selected some stairs, for example, I can see the static mesh. I'll just turn this off for now and I'll come back to this favorites thing. So by default, you'll probably see this screen here. So you've got transform, location, rotation, scale. So I can move these transforms here if I wanted to and move that stairs left and right. I'm just clicking and dragging on those values."},{"start":"6:22","end":"6:52","startSec":382.0,"text":"I've just hit undo to undo that by hitting control and C. But you can see the material that's been assigned. And essentially, the details panel will give you a good overview of everything that is in the properties that pertain to this specific actor. So if I select the character, for example, the character will have different properties, although some common like the transforms, they'll have different properties pertaining to that specific actor. So the details panel is a really nice way to access anything you want to configure per"},{"start":"6:52","end":"7:27","startSec":412.8,"text":"actor. Then just coming back to this favorites tab here, it's a really nice feature of Unreal where you can see there's hundreds of options given on different actors. And sometimes you just use the same same property by default all the time. So when I selected the stairs, I favorited the static mesh and the cache shadow properties, for example. I don't currently have anything favorited for my character. So I'm just going to select my character. You'll see there's nothing in my favorites tab right now. Say I want to select the skeletal mesh and right click on the skeletal mesh and add to"},{"start":"7:27","end":"7:55","startSec":447.2,"text":"favorites, you'll now see that the skeletal mesh is in my favorites section. So if I'm constantly, maybe I'm allowing cloth actors, for example, and I'll scroll up and now it's allow cloth actors. If I'm constantly finding details that I want to edit and I have to keep scrolling up and down, you want to save some of that time, you can add those to your favorites. So now that we've covered the basic editor overview, let's go into some actual content editing and using the grid."}],"07_Workshop- Working with Actors":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"So let's learn how to edit content directly in the browser. So you can either follow along one to one with this if you have the Unreal Engine open or you can just watch completely up to you. But for now I'm just going to find an asset in my content drawer. So I'm going to hit control and space bar and I'm going to scroll to the starter content because I included starter content and I'm going to go to the props folder. Now what you could do is to get used to some of this functionality you could select content"},{"start":"0:33","end":"1:03","startSec":33.1,"text":"for example, go over to the filter button and click that and then go to static mesh. And if I click static mesh it will show all the static meshes that are available to me inside the browser. So you might already have some interesting meshes to work with. You might have say for example this damage cart which when I drag it in it's going to prepare the shaders and build everything and so you might have some more interesting meshes than I have at hand. But I'm just going to delete that."},{"start":"1:03","end":"1:35","startSec":63.6,"text":"I'm going to go to starter content, I'm going to go to props and I'm going to go to the basic chair. Now the chair by default faces away from me. So the first thing I want to do is rotate it towards me. So you'll see this widget here which is a transform widget so I can move up, down, left, right. So I'm going to move around my viewport by right mouse buttoning and panning my camera. So holding right mouse button pans the camera. Left mouse button goes backwards and forwards and holding both mouse buttons goes up and"},{"start":"1:35","end":"2:06","startSec":96.0,"text":"down. So right mouse button plus left mouse button and then just getting the viewport into position you want it to be. I don't want to move the location of this, I want to move the rotation. So I'm going to press spacebar and you'll see that I have the translate widget here and when I hit spacebar it will go to rotate. So spacebar is going to rotate and if I press spacebar again it goes to scale. So you can see it toggling through these three widgets."},{"start":"2:06","end":"2:37","startSec":126.7,"text":"So I always use spacebar rather than going up to the top here but that covers these three widgets here. So I'm going to go to rotate, I'm going to click left mouse button, drag and rotate the chair to a nice angle. Maybe I want to scale it down, let's go to the middle of the scale and let's scale it down. Now that chair went way too small for the purposes here. So this lets us introduce snapping. So you'll see we've got grid snapping at 10, we've got rotation snapping at 10 and"},{"start":"2:37","end":"3:12","startSec":157.4,"text":"we've got scale snapping at 0.25. Now the scale at 0.25 was way too severe so I want to maybe bring it to 0.625 and then now when I scale it will scale much more gradually and I can get a much nicer result. So that's about right. So it's just below one and it's just like that's the perfect size for me. So when I'm snapping whether on the rotation or the grid you can edit each one of those dependent on the values here. Now grid snapping is really useful and so I'm going to press spacebar and you'll see"},{"start":"3:12","end":"3:45","startSec":192.0,"text":"that my chair moves and it feels like it's snapping and that's because of the grid snap 10. Now another good functionality of the Unreal Engine is to toggle the grid snapping. You'll be doing this more frequently I think than the rotation scale but I'm going to hit the brackets keys next to the enter on my keyboard. So I'm going to do close bracket for larger and open bracket for smaller. So just toggle between the two grid sizes and you can see the grid size going up and down and again I'm just using the brackets keys on my keyboard next to the enter key."},{"start":"3:45","end":"4:17","startSec":225.8,"text":"And so now if I set that to 100 it's going to be snapping at 100 and if I set it to 500 it's going to be snapping at 500 units. So very powerful functionality. I'm going to snap it here but the one last thing that's frustrating me about manipulating this content is that it's transforming it in world location. It's just going left to right up and down but I rotated this chair on an angle. So how do I change my widget to match the angle? And that's the last button here that I want to cover which toggles between world transform"},{"start":"4:17","end":"4:49","startSec":257.8,"text":"and local transform. So I'm going to toggle this to the local transform and now you'll see it gives me much better control because it's moving the chair forwards and backwards depending on where I want it. So hopefully that gives you a good overview of how to add an asset to the scene or you can use the different widgets to get the content working exactly how you want it to and that's how to essentially place actors and start manipulating the content. One last tip though might be worth covering is the camera speed."},{"start":"4:49","end":"5:21","startSec":289.5,"text":"So as you're getting more familiar with navigating the interface your right mouse button into pan around, left mouse button in to dolly backwards and forwards and then both mouse buttons to move around. You can also be pressing W, A, S and D on the keyboard. So W to move forward, S to move backwards, A to move left, D to move right and these are more traditional PC based controls for editing viewports."},{"start":"5:21","end":"5:55","startSec":321.3,"text":"So W, A, S and D I'm now flying around the scene holding right mouse button down. So again it might take a little bit of time to get used to it but just getting familiar with that it'll become second nature in no time. But you'll see as I'm flying around the camera is moving a little bit quick for me. I want to get a bit slower into this chair so I'm going to select the camera speed, I'm going to bring the camera speed down to two and now you'll see I'm moving much slower. So that's really useful to know. And then a little bonus tip rather than keep going back to the camera speed I always like"},{"start":"5:55","end":"6:26","startSec":355.8,"text":"to scroll the middle mouse wheel on my mouse so that when I'm moving around I'm scrolling it up and I'm going faster. So I've scrolled my mouse wheel up and I'm moving faster. If I scroll it down it'll really make me move slower. So editing the content, scrolling the wheel and just getting really familiar with the W, A, S and D on the keyboard, the left and right mouse buttons on your mouse and then the mouse wheel will really help you edit your content much faster when you get familiar with that workflow."}],"08_Working with Materials":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Now that we're familiar with placing actors and navigating Unreal Engine, let's talk about working with materials and how we actually get some desired results from Unreal Engine. So the topics we'll cover here are the real-time material concepts, we'll talk about what PBR is and we'll also talk about parent materials and also material instances. So parent materials being the primary PBR inputs, the node settings and exposing the different parameters and"},{"start":"0:32","end":"1:04","startSec":32.7,"text":"then with material instances, it will talk about almost being a childhood version of this parent material which is a more simplified interface and we can create multiple versions of lighter, in this instance, more optimized materials based on that parent. Real-time material concepts, essentially starting off as what is a material? It is essentially an asset applied to a mesh to control its visual look. In its simplest form, think of it as paint with various properties such as color and finish. So if we see on the right"},{"start":"1:04","end":"1:40","startSec":64.1,"text":"hand side here, we'll see our paint brush and our bucket and tin, should we call it, and we'll be able to paint a certain surface and let's say we decide that this surface is glass. Now the eye looks at the glass and glass has reflective properties and it reflects a lot of light as well. So you'll see the surface next to it bounces off that light and it creates some reflection and inside of Unreal Engine, we define these properties of what we want glass to look like. Whereas when we have chalk, if we set certain parameters on the material to say we want this to"},{"start":"1:40","end":"2:13","startSec":100.4,"text":"be chalk, it disperses the light, it's much more of a matte material, there's not as much bounce going off the light and especially in one direction. So there's a clear difference between how we want glass to look and how we want chalk to look and we can define that all within Unreal Engine. So material defines how the light interacts with the surface it is applied to essentially. And then talking about PBR, PBR is a unified lighting and shading system. So it's a better approximation of light and materials for physical interaction. So it's very intuitive and consistent, you get"},{"start":"2:13","end":"2:48","startSec":133.9,"text":"specific results from using PBR, it's physically accurate and uses real-world physical measurements. So PBR is a combination of you creating the materials, setting up the lighting how you want it to be set up and also the exposure used within the scenes which is controlled through the post-process. Looking at the material editor as an overview, you'll see a whole bunch of nodes here connected into this master section here. So we can set up various parameters, maybe we want to change the texture coordinates of a texture and we want to offset the texture maybe"},{"start":"2:49","end":"3:23","startSec":169.1,"text":"and then maybe we want to add some contrast through a linear interpolate and we want to set a base color for certain samples and maybe we want to add a normal map to it. Again these materials can get super complex, we'll go over a basic material setup in a few slides here. But you can see there's a lot going on under the hood when we can set up materials, a lot of power and flexibility. You can also decide on certain material properties down on the bottom left heel. So what type of material domain is it, is it a surface, what type of blend mode"},{"start":"3:23","end":"3:56","startSec":203.6,"text":"do you want, do you want an opaque material, do you want a transparent material, what kind of material do you want to set up and then also what shading model do you want it to use and there's a lot more functionality as you scroll down the list in the material editor to get the desired results of what you want there. When we're talking about PBR, the primary inputs you're talking about are base color, metallic and roughness. So base color is some kind of flat color without specularity, it's a linear RGB which is a vector 3 and the values are between 0 and 1. The metallic"},{"start":"3:56","end":"4:28","startSec":236.2,"text":"input, so you'll see these base colors, you'll see metallic and you'll see roughness down here on the right hand side but the metallic is a grayscale value that will range from 0 to 1 and more often than not you really want the metallic value to be either 1 or 0. So when 1, its specular reflection is at 100% so it's the most metallic version, 0 is the least metallic version. And then roughness, grayscale value that ranges from 0 to 1 and you can actually transition through this area on 1"},{"start":"4:28","end":"5:02","startSec":268.4,"text":"in the roughness so you could have you know 0.35 for example but it ranges from smooth, mirror-like to a rougher more matted surface. So depending on the roughness of the material that you want you can manipulate that property to have the desired result that you want. We have a lot of different parameters available to us, we can right click anywhere in the material editor and again I'll be creating a basic material in a few slides here but you can right click anywhere in the material editor and create you know vector parameters, anything you need"},{"start":"5:03","end":"5:38","startSec":303.4,"text":"as well as change the parameter values on each of the nodes that you create. So say you created this vector 3 parameter here, you could select it and then set the colour, a lot of powerful functionality which I'll be going through in a second and so and then you can create a material instance that we spoke about at the start. So material instance is still a version of this master material but it's got certain parameters exposed like brightness for example which we can manipulate based on the parent properties but it's just a much more optimized unified way of"},{"start":"5:38","end":"5:56","startSec":338.5,"text":"working. So let's go into Unreal, let's create a basic material, let's show you the different options and then let's create a material instance for that as well. you"}],"09_Workshop- Working with Materials":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"So we're back in our editor now and we're going to create a basic material maybe for this chair that we've already got in the scene. It doesn't matter what actor you've got in the scene but for now I'm going to create a material for a chair. So I'm going to hit control and space bar to bring up my draw. I'm going to go into my materials folder and if you were following along and you have a static mesh filter or any kind of filter enabled here you can just click that off and you can see that there's a whole bunch of materials in here."},{"start":"0:33","end":"1:08","startSec":33.1,"text":"So I'm just going to create a new one. I'm going to right click in some free space. I'm going to go to select material. So just click in material from the empty space and just following the same naming convention I'm just going to go M underscore chair and then I'll hit enter and then hit enter again and that opens the material editor. Now I want to pin this window next to my third person map just so I can toggle backwards and forwards and it's also worth noting if this material didn't open by default for you,"},{"start":"1:08","end":"1:39","startSec":68.0,"text":"if you had it deselected you can just hit control and space bar to open your drawer again. I'm going to go back to material and just double click it and then that will open the material for you. So before we were talking about base color we were talking about metallic and we were talking about roughness. So let's start with the base color. Now the base color as we saw before was a vector 3. So let's press 3 on our keyboard and left mouse click and that creates a vector 3. So again 3 and mouse click and you can right click anywhere like we said in the example"},{"start":"1:39","end":"2:14","startSec":99.8,"text":"and type in vector and try and find a vector parameter but I'm just going to show you some shortcuts to make this workflow really work for you as you progress with your material creation. So first thing I want to do is I want to left mouse drag from this pin to that pin and so we create a connection. Next I want to select the node and I want to go to the color and just pick a color, any color that you want from the color wheel. So I'm just going to go there, I'm going to find a nice lilac pink type color and hit"},{"start":"2:14","end":"2:44","startSec":134.1,"text":"OK. And I'm going to save my material and let it save and then essentially we've just created our first material. So if I go back into my third person map I find the actor that I want and I hit control and space bar and I can get this chair material and just drag and drop it over the chair and now I have a pink chair. Now you'll see that the material element has updated on the chair and I could have also applied the material."},{"start":"2:44","end":"3:17","startSec":164.7,"text":"Say I want to favorite this material so I want to right click, I can't favorite the material element right now but I could also if this, if I reset this value back to its default value and that's just using this button I could also open my content drawer, have this chair material selected, go back to here and plug that in there and it also works. So that's our basic material right now set up but that's not really PBR, it's not getting metallic and it's not getting roughness so let's go back into our material and now let's"},{"start":"3:17","end":"3:49","startSec":197.0,"text":"add a metallic and roughness. So I'm going to press and hold 1 and left mouse click and I'm going to drag that into metallic. I'm going to press and hold 1 and left mouse click and go into roughness. Now you'll see on this window I'm going to right click to zoom in and out, left mouse click to rotate but you can see this roughness at 0 and the metallic being at 0 is quite a nice shiny material."},{"start":"3:49","end":"4:26","startSec":229.9,"text":"I'm going to first of all change this to 1 so you can see the result that happens there. So you can now see it's gone very reflective and again metallic should really be between 0 or 1, the roughness could be a different value so we could put like 0.35 for example and we bring down that roughness so going from 0 to 0.35 you can see it getting a little bit more matted and if I went to 1 you could see it even more. So depending on what value you want you can edit those, again this one more often than"},{"start":"4:26","end":"4:59","startSec":266.2,"text":"not is 0 to 1, this one can be any version between 0 and 1. If I save and I go back into my map you'll see that my chair looks a little bit cooler now it's got a little bit more texture to it, it feels a bit more realistic which is nice but I still want to edit some more properties maybe on the fly, maybe I want 2 or 3 chairs. So I'm going to go to my material, first thing I want to do is right click on the colour and I'm going to convert it to a parameter. So right click on the actual node and I'm just going to type colour and I'm going to"},{"start":"4:59","end":"5:32","startSec":299.6,"text":"type it the British way, you can type it whichever way is relevant to you. I'm going to right click on metallic, convert to parameter, I'm going to type metallic and we all spell that the same way and I'm going to right click on roughness and you guessed it we spell roughness the same as well. So roughness, metallic and colour, so right click on each one, convert to parameter, you can convert it back to a constant if you want but these all need to be parameters so right click and make sure you select convert to parameter on the top."},{"start":"5:32","end":"6:05","startSec":332.5,"text":"Now I'm going to save it and I can actually close this material now, so I'm going to close it and nothing will have changed on the actual chair yet but the power comes in creating these child material instances that we were referring to before. So again I'm going to hit control and space bar, I've got the chair here, I'm going to right click on the chair and create material instance which is the top. So make sure you select the actual relevant material and create a material instance and it just calls it m underscore chair underscore inst."},{"start":"6:05","end":"6:36","startSec":365.1,"text":"I tend to name my material instances mi underscore so I'm just going to rename this to mi underscore chair and then I'm going to call it inst01 as well. So completely up to you which naming convention you go for, you can see that it separates the chairs out from the material as well because it's got mi instead of m but I prefer that approach to have my material instances all in one place so I know that they're an instance. When you hover over it as well it'll say in brackets material instance."},{"start":"6:36","end":"7:08","startSec":396.6,"text":"If you didn't have an opportunity to rename that you can either right click and select rename or you can press F2 on the keyboard to rename it as well. So I'm going to file save all right now just to make sure I have all my content saved and now I want to show you the power of material instances. So I'm going to select this chair, I'm going to hold down alt on my keyboard and left mouse drag to create a duplicate. I'm going to hold alt again and left mouse drag to create another duplicate."},{"start":"7:08","end":"7:39","startSec":428.5,"text":"Now what I want to do is I want to press control and space bar, I'm going to open up this instance so double click the instance and you can see that I've got a metallic which I'm going to select on, I've got a roughness and I've got a colour value. This is all the condensed information of a material instance, this is just a childhood version of that parent material and you can see that because I converted them to a parameter they've now got their exposed values and the parent here is that chair."},{"start":"7:39","end":"8:11","startSec":459.8,"text":"So I could have called these values anything. If I went back into the chair and if you're following along you don't need to do this but I'm just showing you the relationship. If I open the chair material, I'll just pin this here, if I hold down 1 and call this hello and plug it into specular for example and I save, I went into here, I'll have a"},{"start":"8:11","end":"8:44","startSec":491.5,"text":"hello variable. So again the name doesn't specifically matter, it's good to keep things named consistently but it's more just to demonstrate that there's a relationship now between this instance and that big material. And so now this is a really nice way to work. So depending on your real estate you can move the windows wherever you want but I'm just going to show you that by, I'm going to select this material, I'm going to make sure it's selected in the content browser which is a quick draw."},{"start":"8:45","end":"9:17","startSec":525.5,"text":"If you have a second screen you could put this on a second screen. So I'm going to select the material instance and I'm going to go to the chair, select the chair and assign that. So it's the new instance version of the chair. Now the chair by default will look exactly the same because all these properties are the same but what I can do now is maybe I want a blue chair or I want a green chair or a gold chair or whatever colour I want I can now manipulate inside of this material instance. Maybe I want the metallic to actually be zero in this instance and maybe I want the roughness"},{"start":"9:17","end":"9:54","startSec":557.4,"text":"to be one and I just want that chair to have that desired property. And so that's a really powerful instance because if you look at the content browser I've not edited this main material, this still houses all the information but the instance is now having its own functionality. So I'm going to right click on the instance, I'm going to click duplicate and it's going to call it 02. I'm going to duplicate it again and get an 03. So 02 I'm going to put there, 03 I'm going to select there and let's edit 02 for a second."},{"start":"9:54","end":"10:30","startSec":594.1,"text":"So again I'm just bringing my window down so maybe I want a blue chair, maybe I do want metallic on full and maybe I want zero roughness so it's just a nice reflective chair. And then maybe the last one I want a, let's call it a red chair again with metallic and maybe going back down to 0.3 on the roughness. Let's save that and let's close it and you can see very quickly I can get very different effects and so the material editor can have a whole bunch of parameters that you can change."},{"start":"10:30","end":"10:48","startSec":630.2,"text":"We've just done basic base colour roughness and metallic but you can imagine the powerful functionality that's involved in creating these materials and then material instances for you to edit content. So hopefully that was a useful explanation of the material editor and then material instances so that you can dive into the content yourself and start creating your own."}],"10_Lighting Terminology and Types":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"As we close out the course, we thought it might be useful to go over some lighting terminology and the types of lighting so that it gives you a better idea about this PBR workflow and how you can use it in your scenes. So the topics will cover the lighting definitions and the behavior of the lights, we'll talk about static versus dynamic and the different light types you can have in your scenes. So lighting terminology, we essentially have three different types of lighting definitions"},{"start":"0:33","end":"1:05","startSec":33.4,"text":"and behaviors. We have the direct lighting, we have indirect or bounce lighting and then the shadows. So if you look at our top right hand image here, the direct lighting, you'll see that the light is directly falling upon the surface without any interference and the light travels directly to the surface that the surface receives the full color of spectrum of light. So the indirect lighting therefore is if you drop down and you see the second image, you'll see that there's some indirect lighting going on just on the underside of that surface."},{"start":"1:05","end":"1:38","startSec":65.6,"text":"So lighting that has been reflected by other surfaces nearby, as light bounces off these surfaces, light waves are absorbed or reflected based on the surface properties and passed onto the surface you are looking at. So indirect lighting contributes to the mood and overall light intensity. So when you have this balance between not only the direct lighting and the indirect lighting, you get a much nicer result. But then let's talk about these shadows a little bit on the underside here. So shadows happen when Unreal Engine takes a snapshot of a mesh actor from the light's"},{"start":"1:38","end":"2:09","startSec":98.6,"text":"point of view and projects that information onto another mesh on the opposite side. So we still have control and functionality assigned to shadows and we can change the properties of shadows inside the engine as well. So that's just an overview of the different types of lighting we're looking at. So when we're talking about static versus dynamic lighting, we have a few different options available here. So the bait lighting is pre-computed rendered lighting. So we bake lighting using Unreal Engine's Lightmass Radiosity Baker."},{"start":"2:09","end":"2:43","startSec":129.4,"text":"It's similar to render if you've used V-Ray or Corona, anything like this is similar to those types of approaches where it's pre-baked and it is used to create high quality indirect lighting using lighting shadow maps. So it's always baked lighting and it cannot be altered at runtime and it has little impact on the real-time performance. So if you want the most optimized scenes, the bait lighting is the approach you want to take there. Real-time or dynamic lighting is lighting that is updated each frame."},{"start":"2:43","end":"3:15","startSec":163.0,"text":"So it's fully dynamic and can be moved around and modified at runtime. It has no global illumination component, only the direct light and it's also expensive to use because it affects the real-time performance because we're rendering each frame. So Unreal Engine can use a blend of both static and dynamic lighting for archviz projects or where assets are typically stationary, the bait static lighting is mostly used. So say you had a scene where you used 85% static lighting, maybe 15% dynamic lighting"},{"start":"3:15","end":"3:48","startSec":195.2,"text":"and then you can have those little bits of dynamic effects where you need them, but the majority of the scene might be static. And then touch upon ray tracing, this type of lighting is used as real-time global illumination updated with all lights to set to movable. So if they are animated, the global illumination GI updates on the fly. The main lighting types, when we were looking at our place actors tab, which is the place actors section, you'll see that the lights has its own tab as we touched upon before where you can find the directional lights, point lights, spotlights, rect lights, just"},{"start":"3:48","end":"4:19","startSec":228.5,"text":"a rectangle light and a skylight. So these are the main different types of lighting that you'll have access to. You can use a directional light for something like a sunlight or a moonlight. And again, with each one of these light properties in the details panel, then you can modify any properties. Maybe you want to change the color or the shadow color that they're creating. Maybe you want to change the intensity or even the rotation of the sunlight. You can do all that through the details panel. The point lights, single points of light in a scene."},{"start":"4:19","end":"4:50","startSec":259.1,"text":"And you can also edit these to extend the capsule. So by default, point lights come with a spherical radius and you can actually change the point light to be more of a cylindrical radius if you want it to be more like a fluorescent tube light, for example. So point lights have their own functionality and very powerful. And maybe for a lot of the time, you might have lots of point lights in a scene. Maybe you have a hundred point lights in the scene and maybe, you know, eighty five of the point lights are statically lit."},{"start":"4:50","end":"5:27","startSec":291.0,"text":"And then you have, you know, the fifteen remaining that are dynamically lit. And the important thing about both point lights and spotlights as we move on to spotlights, you don't want too many overlapping dynamic spotlights or point lights. So if you're using dynamic lighting, make sure the dynamic point lights are spaced apart and they're not all too crumped together and overlapping each other with their radiuses. So talking about spotlights, spotlights are very similar functionality as point lights, but they just are more in a cone shape and they spot the light and then similar with"},{"start":"5:27","end":"6:00","startSec":327.1,"text":"a rectangle light. So you can have this box light that is useful for maybe archviz projects or anything that you're doing that you need a big wall light essentially. And then you got the skylight, which is a HDR image based ambient light, which just gives you an overall lift to the scene. So if we're looking at a daylight setup, the main components here, we have direct light, we have sun, we have skylight and we have the sky sphere or dome mesh visuals. So other components might be a light mass importance volume, a post-process volume,"},{"start":"6:00","end":"6:32","startSec":360.6,"text":"atmospheric, you know, the fog or sky atmosphere or the sphere reflection captures, which will process any reflective surfaces and create the relevant reflections for those surfaces. So you can see a really nice diagram here of all these different components kind of layered in to create the intended result that you want. And so you use a combination of all the different lights to create your scenes. So just to give those lights a little bit more context, if we're in our scene here,"},{"start":"6:32","end":"7:03","startSec":392.6,"text":"I'm going to speed up my camera and I'm going to zoom out a little bit to give us more view here. So you'll see that the angle of the shadows, for example, is coming from this chair. Now in your outliner, you'll be able to find the different lights if you've choose a custom preset. You might have more properties than this depending on the Unreal template, especially in Unreal 5, you'll have the daytime real time components here as well."},{"start":"7:03","end":"7:35","startSec":423.0,"text":"But if we're just looking at the light source, for example, for now, which is a directional light, which we can drag into the scene with a directional light, just drag and drop. For example, you can see the rotation on the yaw. So as I change the rotation, you'll see the sky, the sun moving rotation. So I could rotate this to a different direction, for example, if I wanted to change the pitch to get deeper shadows, for example, I want to just undo that value."},{"start":"7:35","end":"8:07","startSec":455.5,"text":"It's on 66, so let's call it minus 80 for now. And then you'll see the sun rising, so minus 40 might give a deeper shadow. So you can see already that the sun is almost setting in the sky. And then maybe I scroll down and change the light color to more like a warmer evening hue, for example. So that's essentially a directional light. And then we've got the skylight here, which again, we can give it an overall color, we can show how it affects the world."},{"start":"8:07","end":"8:39","startSec":487.1,"text":"You can change the intensity in any one of these. We've got the post-process volume as well, if you want to change any post-processing effects. And then a light mass importance volume can be found from the place actors. And you only really need to use a light mass importance volume if you're using baked lighting. So if you want your scene to be baked and pre-rendered, what you can do is you can place this volume in your scene. So you can just drag and drop the importance volume. It comes in as a small cube for now."},{"start":"8:39","end":"9:13","startSec":519.7,"text":"And if you scroll down to the brush settings here, you can make these boxes bigger, depending on the scene, and only highlight the main bits of areas that you need lighting in. And it basically says to Unreal, control this scene and just only focus on the lighting within this box, and everything else can just be rendered usually. So including your light mass importance volume for baked lighting is also useful. And then just touch upon the point light and the skylight here. I'll zoom in, and we have a point light, which we can move around the scene."},{"start":"9:13","end":"9:45","startSec":554.0,"text":"It's dynamic by default, and it's casting nice shadows. We can maybe change the intensity or the color or the radius. So you may want to bring the radius down so it's a smaller light or a bigger light. Again, just playing with some of these properties will be the most beneficial, I think. And so the main thing to take away from these lights are the mobility here, which we were referring to before. So you can either have static lighting where it gets baked in, and this light will then"},{"start":"9:45","end":"10:15","startSec":585.8,"text":"not be able to move at runtime. If I have movable, this is fully dynamic so I can animate this in my scene. For example, I can move it around and create real-time shadows, again, based on those lighting types that we spoke about. But the important note here is a stationary light option. And if we hover over it, a stationary light will only have shadowing and bounce light from static geometry baked by light mass. So part of this light is baked, but all of the lighting will be dynamic."},{"start":"10:15","end":"10:50","startSec":616.0,"text":"So it can change color, it can change intensity. So it can't move, but it can allow partially-baked lighting, and it can also change at runtime. So if we wanted to move this light... So say we didn't want to move the light around the scene, but it was just there, but we did want to change this light from orange to blue at runtime, we could do that with a stationary light. It's worth noting the three different light types, and by default, you probably want static. If you do want movable, just make sure you're using these sparingly."},{"start":"10:50","end":"11:02","startSec":650.7,"text":"And stationary is a nice balance between the two if you want some dynamic elements, but you don't need to move it around. So hopefully that helps give a good overview of the different lighting types inside of Unreal."}],"11_Outro":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"So thanks for following along with this course today. I hope you found it useful as a nice editor overview and navigating the view part and the different buttons that you can use to access, creating new materials and just editing the content to give the visual representation of how you want things to look as well as touching upon lighting and knowing how to manipulate the scenes with the different parameters and properties. Hopefully it was a really good overview and then you can of course continue on the course"},{"start":"0:30","end":"0:34","startSec":30.6,"text":"journey and learn all the more detailed features of Unreal Engine."}]},"100.10":{"01_Intro":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Welcome to the Introduction to Automotive Visualization class. By the end of this class, you should be familiar with the core principles to create a production-ready automotive project from start to finish. It's important to note that this course will introduce and discuss many topics pertaining to automotive visualization. However, many of these topics are discussed in greater detail in other classes. During this class, we'll cover how to create a new project using the Unreal Engine Automotive template, how to assemble our scene for cinematic quality lighting, how to light our scene with"},{"start":"0:31","end":"0:40","startSec":31.3,"text":"various lighting techniques and post-processing effects, and finally how to quickly add a turntable animation to the scene for our final render. So let's get started."}],"02_ProjectCreation":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"So let's dive in and create our new project. Now to do this, we're going to be using our Epic launcher. We need to make sure that we have our engine version installed, which in this case we're going to be installing 5.3. From there, you will have a launch button. This will launch a separate window. And inside of this window, we can open up recent projects or create projects based off of various templates. Now for our project, we're going to be using the automotive product design and manufacturing"},{"start":"0:30","end":"1:01","startSec":30.5,"text":"templates and we're going to use the blank to start with. We'll cover here in just a little bit about what these templates do, but just know that this is going to serve as our starting point. Next we'll want to set our project location. So this is where your project files will be stored. And then we'll also give our project a name. Now it's important on both of these, both on your project location and your project name that you keep those file paths short. Ideally, you should keep these well with under 20 characters."},{"start":"1:01","end":"1:35","startSec":61.7,"text":"The shorter the better. To explain in a short, very quick, concise summary, the engine, in particular when working with operating systems like Windows, there is a character limit of 255 characters, which can quickly be overtaken with several different files that ship with the engine. So in short, just keep your file path short. Keep your project name as short as possible and then click create. So let's go ahead and just step through that process real fast. So here I have our launcher and you can see that I have 5.3.2 installed."},{"start":"1:35","end":"2:07","startSec":95.1,"text":"I'll click launch. And we'll give it a second to pop open the window. All right. So after about 30 seconds of the engine installing everything that it needed to, you can see that we now have our Unreal projects browser window. So I'm going to select the automotive product design and manufacturing section. And you can see here we have that blank project. So all I need to do is go ahead and put in my project location and give my project a name and then hit create. That will go ahead and create our project."},{"start":"2:07","end":"2:37","startSec":127.1,"text":"To better understand what templates are, it's important to understand that templates aren't actually using a special version of the engine or opening special things that you don't otherwise have with the engine. In fact, every template that ships with the engine utilizes the exact same underlying core engine. The difference is when we use any of these automotive templates, they will often preset certain values or enable certain plugins that that project or that template was designed to use."},{"start":"2:37","end":"3:08","startSec":157.2,"text":"So in the case of our automotive project, there are a few things that turn on, for example, such as our sudden position calculator plugin, the data Smith importer we even have. And you can see here's a couple of settings in the project. Our reflection capture resolution has been bumped up to 2048 and our default RHI has been changed to DirectX 12. Every single one of these settings, every single one of the plugins that is utilized by those templates, you absolutely can go in, enable yourself, change those settings"},{"start":"3:08","end":"3:19","startSec":188.3,"text":"beforehand, change them after. Again, it's important to understand that the template is just pre-setting these things for you so you have a good starting point, but you absolutely can modify them. And that's the lead point thereafter."}],"03_BaseSceneAssemblyStepA":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Now that we have our project set up, it's time to start creating our neutral baseline. Now, to cover kind of the principles of what a neutral baseline is, it's very simply put that we are trying to remove any and all artistic effects in our scene and work from a calibrated baseline. This is very important because without a calibrated baseline, we may be chasing our tail artistically. We're trying to over adjust or under adjust lightings. So having that calibrated baseline is very critical."},{"start":"0:33","end":"1:05","startSec":33.0,"text":"Now, some of the things that we're going to do in this scene is disable our auto exposure. We can do that either on the project settings or in our post processing volume. Now we'll opt to use the post processing volume as I find that that's much more flexible than setting it just project wide. We're going to also disable all of our artistic effects, again, also through our post processing volume. We're going to use some various calibration tools, some that ship with the engine and a few that actually come with our automotive materials pack."},{"start":"1:05","end":"1:42","startSec":65.0,"text":"And then the important things that we want to adhere to is avoid colorizing our lighting or adding any really crazy effects in our post processing. Again, we will do this later in later stages of this class. We'll actually go back in and add some of those artistic effects. So this entire process is completely non destructive. And then finally, a another important principle about having a very good neutral baseline is making sure that the materials pack is completely non destructive. And making sure that the materials that you use to check your scene, to check your lighting are as high quality as possible."},{"start":"1:42","end":"2:12","startSec":102.0,"text":"And same thing with your models. So to start, we're actually going to open up our zero zero start map, which is in our content classrooms and walkthrough. Now, if you open up this file and it looks blank, don't worry. In fact, we go up to lit, unlit mode, and you'll see that, in fact, the car is there. So everything is fine. Included with the project is a series of collections. Now, collections are just a handy way of organizing content in your project."},{"start":"2:12","end":"2:44","startSec":132.0,"text":"They don't necessarily move any of your content. They simply just help you to store these content based on various different things. Now, if you don't see the content now, as of five dot three, I believe this is default. It should be docked in the lower left here under collections. And if you just expand it out, you should see the collections that we've included. Now, with this, I'm just going to select the calibration and you can see that we have some assets in here. Now, an important thing to distinguish here is that these assets haven't been moved to the separate folder."},{"start":"2:44","end":"3:16","startSec":164.0,"text":"In fact, some of these exist in the project. Some of these exist in the actual engine itself. But a collection is just a handy way of earmarking or bookmarking this content for ease of dropping it in your scene or using it. So again, if you don't see collections, it should be rolled up in the lower left here. Just expand it out and you see all the content that we're going to be working with. And then finally, the other thing to keep in mind is that we're going to be using some engine content such as our skylight, direction light and post processing volume. And all of those can be found from the place actors panel."},{"start":"3:16","end":"3:48","startSec":196.0,"text":"So if I go back to the engine and you don't have this place actors panel, in fact, if it's closed, we're going to go up to window place actors. And it should dock in the left. As a point note, too, you can absolutely drag any of these windows off and dock it wherever you see fit. So we're going to be using this along with some of our collections to pre populate or populate our scene with what we're trying to build. So the first thing that we want to do is remove all of these artistic effects. We also want to clamp our exposure compensation."},{"start":"3:48","end":"4:20","startSec":228.0,"text":"So to do that, we're going to do that through a post processing volume. So I'll jump back over to the engine real fast. And again, I'll go to unlit mode so we can see what we're working with here. Go to your place actors. Easiest way is just to start typing in post and we'll grab this post processing volume. So we'll drag this into our scene. I'm going to go down to my transformations and just click the little loop back arrow here to reset our settings. So if I jump back, you can follow along in these slides for the different settings that we're going to use."},{"start":"4:20","end":"4:50","startSec":260.0,"text":"But essentially we are going to recreate what we see here inside of our scene. All right. Now, because we don't have any lights, it's going to be rather difficult to kind of see what's happening. But essentially, our post processing is going to control a host of different artistic or visual effects into our scene. And we will see that later exemplified when we actually have some of our lighting. But for now, we can just follow along with this. So the first thing that I want to do is with my post processing volume selected, go over into my details panel."},{"start":"4:50","end":"5:25","startSec":290.0,"text":"I'm going to scroll all the way down until I see the post processing volume settings. And the first thing that I want to do is check the infinite extent unbound. Now, there are situations where you may want to localize or control your post processing effects within just that volume or that shape. And that is the default nature and behavior of our post processing volumes. However, for this, we don't want it to we don't want those effects to be contained just to the post processing volume shape. We want them to continue to propagate no matter where the camera is positioned."},{"start":"5:25","end":"5:55","startSec":325.0,"text":"And that's what infinite extent unbound is going to do. All right. So with that checked and we have enabled, we're going to scroll back up. And the first thing I'm going to look for is my exposure tab. So if I expand this out, anytime that we have a setting and we check the box, we are now overriding whatever the default behavior or the current setting is based off a priority, which in this case, as we only have one post processing volume, we are simply just going to change this setting."},{"start":"5:55","end":"6:28","startSec":355.0,"text":"So on our exposure compensation, I'm going to change this to negative five point five. What does that number come from? Simply just because of the light values that we're using, the fact that we're trying to adhere to more realistic values. We'll find this later with our directional light. A value of negative five point five is going to give us correct or at least visually correct exposure in our scene. However, note that this particular parameter you can adjust up or down if your scene is too bright or too dark. That's not the most critical component. The next component that we actually want to change is our min and max."},{"start":"6:28","end":"7:00","startSec":388.0,"text":"In fact, this is going to be directly correlated with our exposure compensation. So if we clamp these both at one and one or zero and zero or whatever the same value is, this essentially fix the auto exposure. So now the engine won't try to adjust the exposure of our in-game camera or how we're viewing based off of these numbers. So those few settings right there should be all that we need to disable our auto exposure and allow the post processing volume take effect across the whole scene."},{"start":"7:00","end":"7:30","startSec":420.0,"text":"Now, we could go in as well, as you had heard me mention, too, about adjusting some of our artistic effects. For example, I could take chromatic aberration, check the intensity to make sure it does, in fact, overwrite at zero. We could change our bloom intensity to zero as well. So again, anything artistic related, disabling it. Of course, we can always re-enable these later through a secondary post processing volume, but simply just check the parameter itself and go ahead and set the value to zero."}],"04_BaseSceneAssemblyStepB":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"So the first thing that we want to do is remove all of these artistic effects. We also want to clamp our exposure compensation. So to do that, we're going to do that through a post-processing volume. So I'll jump back over to the engine real fast. And again, I'll go to unlit mode so we can see what we're working with here. Go over to your place actors. The easiest way is just to start typing in post, and we'll grab this post-processing volume. So we'll drag this into our scene. I'm going to go down to my transformations and just click the little loop back arrow here to reset our settings."},{"start":"0:36","end":"1:06","startSec":36.0,"text":"So if I jump back, you can follow along in these slides for the different settings that we're going to use. But essentially, we are going to recreate what we see here inside of our scene. All right. Now, because we don't have any lights, it's going to be rather difficult to kind of see what's happening. But essentially, our post-processing is going to control a host of different artistic or visual effects into our scene. And we will see that later exemplified when we actually have some of our lighting. But for now, we can just follow along with this."},{"start":"1:06","end":"1:40","startSec":66.0,"text":"So the first thing that I want to do is with my post-processing volume selected, go over into my details panel. I'm going to scroll all the way down until I see the post-processing volume settings. And the first thing that I want to do is check the infinite extent unbound. Now, there are situations where you may want to localize or control your post-processing effects within just that volume or that shape. And that is the default nature and behavior of our post-processing volumes. However, for this, we don't want it to we don't want those effects to be contained just to the post-processing volume shape."},{"start":"1:40","end":"2:15","startSec":100.0,"text":"We want them to continue to propagate no matter where the camera is positioned. And that's what infinite extent unbound is going to do. All right. So with that checked and we have enabled, we're going to scroll back up. And the first thing I'm going to look for is my exposure tab. So if I expand this out, any time that we have a setting and we check the box, we are now overriding whatever the default behavior or the current setting is based off of priority, which in this case, as we only have one post-processing volume, we are simply just going to change this setting."},{"start":"2:16","end":"2:48","startSec":136.0,"text":"So on our exposure compensation, I'm going to change this to negative five point five. What does that number come from? Simply just because of the light values that we're using, the fact that we're trying to adhere to more realistic values. We'll find this later with our directional light. A value of negative five point five is going to give us correct or at least visually correct exposure in our scene. However, note that this particular parameter you can adjust up or down if your scene is too bright or too dark. That's not the most critical component. The next component that we actually want to change is our min and max EV."},{"start":"2:48","end":"3:19","startSec":168.0,"text":"In fact, this is going to be directly correlated with our exposure compensation. So if we clamp these both at one and one or zero and zero or whatever the same value is, this essentially fix the auto exposure. So now the engine won't try to adjust the exposure of our in-game camera or how we're viewing based off of these numbers. So those few settings right there should be all that we need to disable our auto exposure and allow the post processing volume to take effect across the whole scene."},{"start":"3:19","end":"3:49","startSec":199.0,"text":"Now, we could go in as well, as you had heard me mention, too, about adjusting some of our artistic effects. For example, I could take chromatic aberration, check the intensity to make sure it does, in fact, overwrite at zero. We could change our bloom intensity to zero as well. Again, anything artistic related, disabling it. Of course, we can always re-enable these later through a secondary post processing volume, but simply just check the parameter itself and go ahead and set the value to zero."}],"05_BaseSceneAssemblyStepC":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this next step, we're going to be adding a shader preview ball, the SM shader sphere, to our scene and apply various materials to the scene. Now, an important thing to note here is that we are using materials from the automotive collection which have been fully calibrated against their real world counterparts. Loosely translated, these are very high quality materials that we can compare our lighting against to make sure that we're staying as physically accurate as possible with our scene."},{"start":"0:31","end":"1:03","startSec":31.7,"text":"So to do this, I'm going to jump back to our project. Now inside of our collections, we have calibration. You see we have the SM shader ball. Now I'm going to move around my scene real quick, still saying in unlit mode, and I'll just drag the shader ball into our scene. And then I can duplicate it a host of ways, Ctrl C, Ctrl V, right click, duplicate, or I can just hold down the Alt key and drag to whatever direction that I want to and just get myself a few variations of this shader ball. Now this shader ball does exist inside of the engine."},{"start":"1:03","end":"1:37","startSec":63.7,"text":"In fact, it's shipped with the engine for quite a while. You can highlight over it and you can see where it's located. But in this case, again, if we use our collections, it's just handy and preset there. The other thing that I can do is I can actually go down to various materials. So inside of our classroom, I've got things like car paint and then a couple of ways that we can add this simply drag and drop it onto the shader preview ball. Or if we reset that, we can actually just select our material, drag and drop into our element zero or with a selected hit our little arrow."},{"start":"1:37","end":"2:07","startSec":97.1,"text":"Either way, very quick way to do this. Now for the purposes of our class, I'm just going to add a few materials that I do want to compare against. Ideally, giving myself a broad range of things to compare against. So for example, I may take our glass or add this on there. I may go down into some various metals like chrome or our iron. Now if you do want to pursue other materials that are in here, we've got the automotive materials folder and inside of this, you'll see that we have various different materials"},{"start":"2:07","end":"2:39","startSec":127.8,"text":"based off of interior and exterior to compare against. The point here is that we really just want to have a good range of different materials to compare our lighting against. So I may go in and add, actually you know what, let's look for some leather. So in here and maybe I'll just find something like this orange, drag this on there as well. And then again, just make sure that you have at least a good, we'll use this floor mats as well, why not? We'll have a good variation of materials that we can compare against."},{"start":"2:39","end":"2:46","startSec":159.8,"text":"Now if I do go to lit mode, you'll see again, we don't have any lighting, so these will continue to stay in the shadows for lack of better terms."}],"06_BaseSceneAssemblyStepD":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"Now the next part of this process that we're going to be building out is by adding our skylight. Now the skylight, you can think about this as kind of the the general ambient light that would be reflected off of the sky itself. So if you think about the earth, naturally we have an atmosphere which does reflect light back. But of course, it's a massive, massive dome. That's essentially what we're recreating here with our skylight. Now the difference is we are going to be specifying our lighting again with this whole idea that we are wanting to control our lighting and the effects 100%."},{"start":"0:36","end":"1:07","startSec":36.0,"text":"We're going to do that through using a very specific cube map. Now in this section here, there's something that's not quite accurate to what I said before, but that is an intentional thing here that we're actually going to talk about. So we're going to go ahead and set up these settings in our project. So if I jump back to our scene now, in this case, I can go to lit mode because we're actually going to start adding this light so we can see what's happening. I'm going to go up to my place actors, clear my search, and I'm going to look for sky. What I'm looking for is the skylight component."},{"start":"1:07","end":"1:42","startSec":67.0,"text":"So if we drag this into our scene, we won't really see a whole lot happening right now. And that's totally fine. All right. So the settings that we want to change, the first thing is we want to switch the mobility of our skylight to movable. Now, in this case, the position of my skylight doesn't matter. It's fine. We could reset it if we want to maybe pull it up above the vehicle so we can see it. So I'm going to change my mobility to movable. And then the next thing that I want to do is change my source type. Instead of SLS captured scene, I want to change this to SLS specified cube map."},{"start":"1:42","end":"2:16","startSec":102.0,"text":"Now, from this cube map, we could select our drop down and see all the various ones that are available. The one that we are looking for is this small hanger, 01, 4K. So if we add this to our scene, now I'm going to go ahead and bump up our intensity to that 30 so we can start seeing some effects. I may take it up to 120 just so we can see what's happening. In fact, let's go ahead and bump this up to 600. And you can see now we're getting that ambient light reflected in our scene. Now, just to cover a brief point that I mentioned before about this, not necessarily being the accurate way that you want to do this,"},{"start":"2:16","end":"2:51","startSec":136.0,"text":"but for the purposes of this class, this is important. So if you remember that what we're building towards is a neutralized scene, a neutralized baseline. And one of the sins, if you will, that I've done with using this particular cube map is you'll notice when I open up the cube map and look at the actual texture itself, it has a lot of more or less like creamy kind of skin tones within it. This is ideally not what we want to use, right? We would want to use an HDRI that is for lack of better terms as desaturated as possible."},{"start":"2:51","end":"3:21","startSec":171.0,"text":"So I could use this HDRI, maybe go desaturated, do some post settings inside of the engine. In fact, I will move this off screen real quick and just show you if I go down to saturation and change this to zero. And I click save. We should get an update. We'll go ahead and actually just disable this, re-enable it. And you'll see how quickly our scene changes. So again, this is an important note to keep in mind that if you're going to be using an HDRI,"},{"start":"3:21","end":"3:55","startSec":201.0,"text":"try to use the most desaturated as possible for your scene to, again, to keep that neutralized baseline. So I'll go ahead and keep this as is and we'll close it and we'll continue to use this skylight. All right. The next thing that we're actually going to change here is our cube map resolution. And obviously we've adjusted the intensity scale. So what we're going to do is with the cube map resolution, this is going to be visible. In fact, let's go up to the vehicle here. Some kind of move up a little bit and we can see within the reflections here, the the sky map itself."},{"start":"3:55","end":"4:25","startSec":235.0,"text":"So the actual cube map being reflected off of this. So right now, the default resolution is 128. But if I change this to something like, say, for example, 512, you'll see we start to get a lot crisper reflections in here. In fact, you could bump this up to 1024, although at this point we're kind of introducing more of a placebo effect. 512 is fine. You'll see some other things that are happening. But be careful with this. You don't want to adjust this too high. So above 8K or 16K, that gets very expensive and might cause some instability."},{"start":"4:25","end":"4:57","startSec":265.0,"text":"So with your cube map resolution, we just want to bump that up to get a higher value. And then finally, you saw that we have our intensity scale. I have it set at 600 right now, but we will adjust this down as we start having more lights into our scene and we start to see the effects of those lights. But again, keep in mind that this is just our general ambient light within our scene. So keep this as is now and adjust this a little bit later. And finally, one of the other settings that I want to change is this lower hemisphere is solid color."},{"start":"4:57","end":"5:34","startSec":297.0,"text":"So by default, in fact, if we expand out our advanced underneath our light, you'll see that we have this lower hemisphere color and lower hemisphere is a solid color. This is the default behavior. But because we're using this cube map. So if we imagine just a invisible line that goes halfway through the engine by default is going to basically discard the information that is the lower half of this HDRI. And we can re enable that by simply just unchecking lowest hemisphere is solid color and that will get the additional information from our cube map to project basically into our world."},{"start":"5:34","end":"5:37","startSec":334.0,"text":"So we'll go ahead and uncheck that lower hemisphere is solid color."}],"07_BaseSceneAssemblyStepE":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"And lastly, we want to add our directional light, which is going to be our main light in our scene. Now, for this example, we can essentially view our directional light as, say, for example, the sun. We will change this a little bit later as we start doing more artistic and very specific kind of staged lighting. But in this case, we want to replicate the sun. So to do that, we're going to use our directional light. And then we'll keep these settings in mind here that we're going to change."},{"start":"0:30","end":"1:02","startSec":30.0,"text":"Let's go ahead and jump back over to our project. All right, so from here, we're going to go to our Place Actors panel, and I'm going to search for directional light. We'll just drag this into our scene. And we won't see much of an effect, and a big part of that is because our post-processing volume is controlling that exposure. So underneath our intensity, we're actually going to use a more realistic value of 300 lux. And then we're also going to go down to our mobility settings and change this to movable, which will get rid of our big lighting area."},{"start":"1:02","end":"1:31","startSec":62.0,"text":"And then you can see if I move this light around, you'll see we actually do have that directional light occurring. And then there are a few other settings that have been noted here, in particular about disabling distance field shadows or unchecking atmospheric sunlight. These are for more advanced topics, but in this situation, again, if I'm actually trying to recreate the sun, I may want to put on like light shaft occlusion, light shaft bloom."},{"start":"1:32","end":"2:05","startSec":92.0,"text":"There are other things as well that we can do within our shadows, distance field shadows, turn those off and on. For the purposes of this example, all we really need to be concerned about is changing our mobility to movable, the intensity set to 300 lux, and we should be good thereafter. So this should get all of our lighting set up, and you can see, in fact, we are now actually, you know, again, referencing and comparing against our various different materials that we have in our scene. You can see that we start to get a fairly good look at our scene,"},{"start":"2:05","end":"2:35","startSec":125.0,"text":"and things are actually shaping up really well. And then lastly, one of the other things that I do want to mention here is you can see from this particular scene that we have set up, we have our preview spheres with various different materials. Of course, we have our vehicle in the middle. And there are a couple other tools that I want to make mention real quick as you're building out this neutralized scene. So if I go back to our classroom underneath the calibration collection, we have this BP calibration, which is included with the automotive materials,"},{"start":"2:35","end":"3:08","startSec":155.0,"text":"and this SM color calibrator, which is a part of the core engine content. So if I drag these into our scene, so I'll kind of move this up, and then I'll drag this calibration into our scene, and I'm going to go ahead and just scale this down, just slightly lift it up and rotate it. So the important thing to note about both of these assets is they include some very convenient and very standardized, various different references for building out various different lights,"},{"start":"3:08","end":"3:38","startSec":188.0,"text":"coloration, et cetera. So both of these include a Macbeth chart. So that's what this middle color swatch is, and these do correlate with a real world chart. So the Macbeth chart has very specific color values, hex values, luminous values, et cetera. So by dropping this into our scene, in particular if we look at our color gradation or at least our luminous gradation here, we can quickly see that, for example, in this lower right, the white cube and then the not as white cube beside it,"},{"start":"3:38","end":"4:08","startSec":218.0,"text":"we can still see it, meaning that our scene is not overexposed or underexposed. Now to show a good example of where you would want to compare your lighting against these particular tools, if I select our directional light and change our intensity, let's say, to something like 150, or let's even go down something like 50, you can see things start to get a lot darker. And again, we can reference these specific color values to find out if we're within range or out. And then conversely, if I change our intensity to say something like 1200,"},{"start":"4:08","end":"4:20","startSec":248.0,"text":"you see it start to blow out our upper end of our values, which is again not exactly what we want. So I'll go ahead and change this back to 300 lux, and you see we fall well within the range that we were looking for."}],"08_MainLightingPartA":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"For this next section, we are going to be primarily focusing on lighting our scene as if we were on an actual stage. Indoors, no exterior lights, very controlled lighting. Now there are a couple things as we go about lighting this scene that I want you to keep in mind. Some of these core principles. The first one that I want to address is this idea of trying to add too much light or trying to add too many lights at once. And balancing them all at the same time."},{"start":"0:32","end":"1:04","startSec":32.0,"text":"One of the approaches that I recommend the most when it comes to lighting is using more of an isolated approach. And the idea basically behind this is add a light, adjust the values to where it looks fairly balanced. Again, coupled with the fact that we've disabled auto exposure and we have essentially controlled the environment in which we're building our lights. We can add those lights, adjust as needed, and then disable them temporarily. Continue to add lights as necessary. And then in the end, come back and balance all of those lights together."},{"start":"1:04","end":"1:39","startSec":64.0,"text":"Ideally, this is going to avoid us adding so many lights that things get either too bright or too dark. And then we're essentially running circles around adjusting light values, coloration, et cetera, over and over and over again. So for this particular section, we're going to disable all of our lighting except the skylight. We are going to create our light stage. Again, I've got some things within the collections parameter that you can use to make this process easier. And again, using that isolation approach, we're going to add our lights, adjust values, disable those lights and then move on to the next light."},{"start":"1:39","end":"2:13","startSec":99.0,"text":"And then finally, and turn all of them on and then balance them just with their intensities as needed. Now, one of the recommendations that I do have when it comes to building your lighting is, again, because we're trying to adhere to more realistic values, is using something that does have a real world counterpart, such as candelas or lumens. I'll show you how to do that. And then finally, the last thing, because we are using Unreal Engine 5, we're going to be using fully dynamic lighting, meaning we don't have to bake our lighting. So we want to make sure that any light that we add to our scene is set to movable."},{"start":"2:13","end":"2:46","startSec":133.0,"text":"So to start, we want to open up our zero one neutral level, which is going to be in our content classrooms walkthrough. And within this particular map, we've added some different callouts just to show you the things that we have changed or how we've gotten to this point. Now, again, all of these bridge off of what we had just talked about. So, for example, if I select our PPV neutral, which is our post processing volume, neutralize the light and then we can add some more light. So we're going to go ahead and select our post processing volume neutralizer."},{"start":"2:46","end":"3:20","startSec":166.0,"text":"You'll see here we have our bloom disabled, our exposure compensation set, Minimax CV. Now, one thing to note is as you're working with this, you can. So, for example, this one is calibrated. The exposure compensation, if you adjust this up or down to make it brighter, that's not necessarily bad. But again, we use our tools to make sure we stay within value. So you can see that even though it looked brighter, if I adjust this, you'll see that I've clearly blown out the upper range of my values. So, again, I'll set this back to negative five point five and we're looking pretty good."},{"start":"3:20","end":"3:56","startSec":200.0,"text":"So with our directional light, you can see here that we have some values here. For example, our sunrise, typical overcast day, bright sunlight, brightest sunlight. You can see where we have that correlation with our lux. So, again, I could also check we don't have the lights in here. So we can change this value again from using unit lists, deluxe or candelas. We'll change that in a little bit. And the same thing here, we have some correlations to again, some real world counterparts. So, for example, a hundred watt bulb incandescent bulb is going to be roughly around sixteen hundred lumens."},{"start":"3:56","end":"4:26","startSec":236.0,"text":"All right. So to get started, I'm going to select my directional light. I'm going to go ahead and just turn off the effects world. So this should be disabled. I'm going to use my skylight to make sure that this is still enabled. We're unmovable. This should still be the same. Our cube map and our source type. You see this is fairly good. Again, with intensity scale, if I were to bump this up to say something like three hundred. Again, just be very careful with this because this is the only light in our scene. We don't necessarily want to adjust this too much right now."}],"09_MainLightingPartB":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Next, we'll wanna drop in our overhead diffuser, which will kind of act as our global stage light. So this is gonna be our Chimera 10 by 30 foot light white diffuser. And this is gonna be within our collections underneath the light stage. So we'll jump back over to our scene. And I'll go ahead and clear up my place actors, go down to my collections, and we're gonna look for our light stage. And here is that Chimera 10 by 30 foot white light. So I'll go ahead and drag this into our scene. I'm actually gonna go up to the light stage, I'm actually gonna go up into unlit mode real fast,"},{"start":"0:31","end":"1:03","startSec":31.4,"text":"just so I can see placement. We're gonna move this up, kind of move this around, rotate it, and move it into place. I'm gonna press G to go into game mode. And I'm gonna go to lit mode. And now you can see we're actually starting to get some effects. Now it's important to note real fast here, a couple of things that are occurring. Because we are using Unreal Engine 5, we have Lumen enabled. So this light panel, which actually doesn't have a light in it of itself, but rather is using the material emissive properties"},{"start":"1:03","end":"1:36","startSec":63.7,"text":"to cast light into our scene. And then secondly, because we are using DirectX 12 and we have those higher quality reflections, you'll see that we start to see them within the actual reflections of the vehicle. And of course, any object that has anything that's not rough, we start to see those reflections. So again, no lights per se within our scene right now, outside of just our skylight, but rather just the emissive material from this particular panel. So with that being said, we actually want to add a light into our scene."},{"start":"1:36","end":"2:07","startSec":96.4,"text":"And in particular, we're gonna be using what is called a rec light or a rectangle light. Now it's important to note that rectangle lights are probably the most expensive type of light that you can use in our scenes, just because of the nature of how they're built. And that is totally fine for what we're doing. For real time applications, I would say just be mindful that if you're adding a ton of rectangle lights into your scene, that's where you may notice a dip in performance. But again, for this scene, we should be totally fine to add several rec lights and still run fairly well."},{"start":"2:07","end":"2:38","startSec":127.3,"text":"So if I jump back to our scene, I'm gonna go to our place actors. I'm just gonna type in rect, which will give me my rec light. If you're curious too, you can actually just click the little lighting light button here. And we can see here as a rec light, get us to the same spot. So I'm gonna drag one of these rec lights into our scene. I'm gonna press G to go back into game mode. And essentially what I wanna do is just rotate this into place where it's fairly aligned with our light panel. So I'm just kind of setting this up a little bit."},{"start":"2:38","end":"3:09","startSec":158.1,"text":"And there are a few settings that I wanna change. The first thing is we are setting candelas. Here you can see that we can change exposure value, lumen or unit list. For this case, I will just continue to use it. Actually, let's go and change it to lumens. And then I wanna go ahead and set my intensity here to 12,000 lumens, which should be fairly bright. In fact, we can see that exemplified on the ground. So we'll turn this off and on. You will notice we have this preview shadows indicator and that's because we are in stationary mode."},{"start":"3:09","end":"3:41","startSec":189.5,"text":"So again, all of our lights are gonna be fully dynamic. So we'll switch it to movable. All right, so I'll come back down here a little bit so we can see what's happening. So the next thing that I wanna do is adjust a few properties. So the first is attenuation radius. So if I drag this all the way down, I can take a look here, you'll see that this is effectively the influence of that light. So within this outer sphere, this is the full extent or how far the light can affect something. So in this case, because this is a very large primary source,"},{"start":"3:41","end":"4:11","startSec":221.2,"text":"I'm gonna change our attenuation radius to something like 2,500. And you can see this encapsulates our entire scene, which is exactly what we want. All right, the next thing that I wanna do is actually adjust the width and the height. So the way that erect light works is we essentially have these barn doors. So if I kind of take this down, you'll see, kind of like they're flaps, they're doors on the side of the light. But in particular, this main center square that we have here, this is essentially where the light is being projected from."},{"start":"4:11","end":"4:43","startSec":252.0,"text":"So we want to match that inner square to essentially the projection zone or where our light panel is. So to do that, I'm actually gonna change our source width to 850, our source height to 240. And you can see that I've actually got this rotated 90 degrees. Let's go ahead and rotate this back. And then again, I could go into here real fast and just essentially try to get this aligned to our panel as much as possible."},{"start":"4:43","end":"5:13","startSec":283.1,"text":"And that should be good enough. There we go. So this better, more closely matches our actual Chimera panel that we have here. And finally, the last thing is we could take our barn door angle down just a little bit. So we can set it to something like, for example, 55. And we could, if we wanted to adjust our barn door lengths, although in this scene, we won't particularly notice it, but I'll go ahead and just set that to 40. All right, cool. So that should get us all set up on our light panel."},{"start":"5:13","end":"5:44","startSec":313.5,"text":"And then lastly, if we wanted to, we could essentially just duplicate this light panel to give us just a little bit more effect. So I'm gonna take both of these. So just hold down Shift and Select. I'll move these up. And you can see with our real world lighting values, again, because we're using energy conservation the way light works, is if I push this closer to the surface, you'll see we get much brighter, much brighter highlights of the light. So I'll kind of move this up a little bit, move this off to the side. And then again, you could do Ctrl C, Ctrl V."},{"start":"5:45","end":"6:17","startSec":345.9,"text":"But in this case, with both my light and my panel selected, I'm just gonna hold down Alt and drag off and duplicate. So there you go. Now we have some lighting that's occurring in our scene that looks more natural. I'm always gonna go back to my calibration tools and find out, hey, this may be too bright. I'm gonna go ahead and just select both of my rec lights. And maybe what I do is, I'm gonna go ahead and just deselect. There we go, our rec lights. And maybe instead of 12,000 lumens, I drop these down to 8,000."},{"start":"6:18","end":"6:29","startSec":378.9,"text":"Compare against my calibration tools. And you can see that, okay, we are sitting much nicer and our results are actually speaking for themselves, looking very good, very realistic."}],"10_AccentLightingPartA":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Now that we have our overhead lighting established, we want to start going in and adding various different accent lightings to this vehicle. Now if you've ever seen an actual photo shoot of a vehicle on a stage like this, you'll know that there's various different lights that are placed throughout the different scenes. We'll have various bounce light. With all of the beautiful curvature of the automotive surface, we want to call out particular highlights to various different things, whether it's new product shots, etc."},{"start":"0:33","end":"1:07","startSec":33.0,"text":"So to do that, we're going to use various different techniques of adding accent lighting to our scene. Now again, going back to some of these principles we've already been talking about, really this is where the approach of isolating our lighting, testing it, disabling it temporarily to continue, this is where it's very important. We're going to be adding various different lights throughout our scene, and if our eye is competing against lights that are turned on versus the specific light that we're looking at, it's going to be very difficult to get that controlled look that we want."},{"start":"1:07","end":"1:40","startSec":67.7,"text":"So again, with this isolation method, we're going to disable our overhead lighting and our skylight, and we're going to create our lights one by one. Now if we do find that we put a lot of time and effort into creating a very beautiful looking light, it's absolutely fine to go ahead and duplicate that and move it around. Absolutely fine. Once we're finished though, we want to make sure that we disable that light or those series of lights that are closely related, and then continue to build onto our next. Finally at the end of it, we're going to re-enable all of our lights and then balance our intensities"},{"start":"1:40","end":"2:11","startSec":100.6,"text":"to bring them within tolerance. Now again, we're going to use those calibration tools to make sure we're not overexposed or underexposed with our lighting intensity. And then lastly, we're going to use some various different fills and what we call kickers, or just little lights to help bring attention. There's a couple of little techniques I'm going to show you to be able to do that where we don't inject too much specularity. Yes, it is breaking some rules of science in convention, but that's absolutely fine because we're working in digital medium, which means we can break the rules and it's absolutely"},{"start":"2:11","end":"2:44","startSec":131.0,"text":"fine. So for our scene, this is essentially what we want to build. So you can see that we've we still have our overhead lights up above and we have various different rec lights all around to kind of give these really nice, interesting highlights and also driving various different intensities in our scene to accent our vehicle in the middle. So we'll go ahead and jump over and start building that now. All right, so jump back over to our scene now to just help better visualize what we're doing. I'm going to go up to our outliner and I'm actually going to hide our calibration as"},{"start":"2:44","end":"3:17","startSec":164.6,"text":"well as our notes folder. And that should give us a fairly clean scene that we have here. All right, so for this one, I'm essentially going to position my camera, you know, somewhere relative to where I think maybe the final shot will be. So we'll kind of use this, you know, semi low shot that we have as this. So now what I want to do is go ahead and add some rec lights to our scene. Now I'm not going to cover too many basic principles about lighting, whether or not you use like three point lighting, Rembrandt lighting, all various different things."},{"start":"3:17","end":"3:48","startSec":197.9,"text":"It's really whatever medium or whatever your intended vision is. But essentially, I'm going to reference a few key things here. In particular, I want to make sure that I don't have super dark shadows. And I also want to make sure I don't have too many lights. So I'm going to do essentially what is a three point lighting setup. So a light, our main light that kind of gets cast from our camera, maybe a side light from our left and then a rim light on the back just to help separate the subject, which in this case is our vehicle from the background."},{"start":"3:48","end":"4:21","startSec":228.2,"text":"All right, so I've dragged my rec light into the scene. I'm going to press G to go into game mode. I'll kind of move this rec light into place, kind of fly around here. It's going to rotate and I'm going to go ahead and set it to movable just like we need to. And I'm going to go ahead and adjust the width and maybe the height just a little bit. Check where we're sitting. All right. And then maybe my barn door angle a little bit so we can see that in fact I'm rotated 180. So we'll get this turned around. And of course, this is very, very, very weak right now on our intensity."},{"start":"4:21","end":"4:53","startSec":261.2,"text":"So if I turn this off and on, you see we don't really notice much of anything. All right, so I'll go and change this back to lumens and let's go ahead and change this to something like let's just say a hundred thousand as our starting point. Okay. Clearly too bright so we can drag this up or down. Maybe we'll do something like let's go like six thousand lumens. Okay, that's still probably a little bright, but let's go ahead and get the light set up and then we'll do a little bit of the balancing in a minute. All right. So if you recall with our principles of lighting, right now I'm trying to light the front of"},{"start":"4:53","end":"5:23","startSec":293.2,"text":"this vehicle while I still have my overhead lights on. So I'm going to select my two rec lights and then just disable them with the effects world or I can simply hide them and see now all I have is this one. Now we also have our panels illuminating so I can also hide these and now you can see the actual light itself. So with our overhead lighting on, you can see that it was quite deceptive in that the light so this light that we're adjusting right now looked way brighter than it actually was. So again, this is why we want to use that isolation approach."},{"start":"5:23","end":"5:54","startSec":323.6,"text":"All right, so I'll just go in here and just kind of adjust this light. Now at this juncture, I could go in and I could add some color. So if I select the color picker wheel, you see I can do this. If you do decide to use colors, my best recommendation is avoid overly saturated colors because that's really not natural. But again, we're working a digital medium so if you want to, absolutely fine, break the rules. That's absolutely fine. But for this one, I'm actually going to use the use temperature and you'll see here that I can maybe warm it up."},{"start":"5:54","end":"6:26","startSec":354.2,"text":"This uses our Kelvin scale or cool it down. I'm going to go something with let's say like 6000 Kelvin should be fine. All right, so if you recall in our setup, so this is going to be like our main key light. I could go in here, hold down alt and just drag this way. Going to rotate this on the front of the vehicle and maybe I want to move this up. Maybe I want to adjust this panel just a little bit more to give myself some height. Again, the key is I'm looking for my reflections and the actual light intensity in the world."},{"start":"6:26","end":"6:59","startSec":386.5,"text":"And how I want to use that. I will say that the energy fall off does look a little weak so I'm actually going to select both of my rec lights and I'm going to go to my attenuation radius. Let's go ahead and bump this up to 2500 and see starts to fill the scene a little bit more. All right, and then lastly, I'm going to go ahead and take this same light, duplicate this, put it behind our subject and you can see we get that really sharp highlight. Maybe I want to take this up a little bit and rotate it."},{"start":"6:59","end":"7:31","startSec":419.3,"text":"Now I'm going to switch from world units to local space. I'm going to take this down, tilt it a little bit and maybe I want to move this up a little bit more and maybe bump up our intensity to say something like 8000. There we go. So now we're starting to get some separation on the vehicle. At this juncture, it's simply just a matter of balancing so I could go into here and maybe move this light a little bit closer, something like this. And now I'm starting to accent the vehicle a little bit more."},{"start":"7:31","end":"8:03","startSec":452.0,"text":"I can go back in, turn on my overhead rec lights and maybe my chimera panels and you'll see now things are starting to really shape up in terms of accenting this vehicle. Now just to show real quick, so I'm going to select the three lights that we just placed and pressing G to go into game mode. And if I hide these, you see this is what we started with and then this is with those lights added. So again, I could go back in here with my calibration tools, just double check that you know, I'm within tolerances, I'm within the ranges that I need to and then make any"},{"start":"8:03","end":"8:28","startSec":483.6,"text":"adjustments as necessary. Now as a key learning point, if you did find that your scene was overexposed and what I mean by that is with the lights being overexposed, it's just simply a matter of going in and adjusting their intensity, right? So each one is about 6,000 and our back one is at 8,000. We could just lower those and then same thing with our overhead panels, adjusting those as necessary."}],"11_AccentLightingPartB":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"And finally, moving on to the last point that I talked about was this idea of kicker lights. So it's important to make note here that there's a couple different techniques that we can use for our kicker lights, or essentially just to draw some accent to our scene or our subject. But in particular, we're still going to adhere to the same principles. We want to make sure that we don't have too many lights or too many high intensity lights within our scene. We also want to take full advantage of our attenuation radius."},{"start":"0:31","end":"1:01","startSec":31.5,"text":"In particular, as you'll notice in the screenshot on the right, how we have various different point lights within the vehicle. These point lights are really just designed to accent various features of the vehicle, right? If we're selling this vehicle, we want it to look good, we want to draw the eye in. So by setting our attenuation radius low, that light will only affect a very small part of our scene. So jumping back into our scene, I'm actually going to move our camera towards the interior"},{"start":"1:01","end":"1:34","startSec":61.7,"text":"of the vehicle. So with our current lighting setup, it really doesn't look bad at all, but it also doesn't really draw my eye or my attention to various features of the vehicle. So let's take a look actually in this lower section here by the floorboards, which is actually pretty dark. So I'm going to use this principle of adding various different kicker lights to basically highlight that section. So I'm going to go ahead and just kind of zoom down into here in the passenger side. And let's go ahead and drag in a point light from our scene."},{"start":"1:34","end":"2:05","startSec":94.2,"text":"And you can see that it's actually snapping above. So I'll press G to go into game mode. Now at this point, if you have snapping turned on, this may actually be a little detrimental trying to get this thing in the exact position. So I'll go ahead and turn off my grid snapping here for my translation. Now you can see that I can move these things into place. And again, I'll get this light relatively within the location of where I want it. OK, so we'll do the same thing. So I'll go ahead and switch it to movable. And you'll see my intensity right now is at eight in candelas."},{"start":"2:05","end":"2:38","startSec":125.2,"text":"If we want to stay consistent, let's go and switch it to lumen. And I'll set this to something like, I would say like, let's go like 50. In particular, I'm looking on the dashboard here where you can see, I can see the light a little bit. Because again, all I want to do is just essentially draw some attention to our scene. All right, so I'll go ahead and set my attenuation radius fairly low. So I'll go something like, let's say like 60. You see now we're starting to affect just that area and kind of move this around. Maybe I'll adjust this down to 50."},{"start":"2:38","end":"3:09","startSec":158.0,"text":"All right, so I'm going to go back to G, go into game mode, and I'll kind of zoom back to our perspective that we looked at before. And I'll go ahead and turn this off and turn it on. Off and on. So you see here with that kicker light, I'm actually drawing some attention to maybe the speakers. Maybe this is, you know, an amazing stereo system and we want everybody to notice it. Right? So this is a perfect place for those kicker lights. So I'll go ahead and go back into game mode. And essentially this junk track could go in and I could duplicate this light."},{"start":"3:09","end":"3:42","startSec":189.1,"text":"I could move this around here. I could, let's say that we want to add another light up here by the steering wheel or, you know, maybe bring some attention to the dashboard like this. I'll move this other one down here, maybe to the console. Right? And then maybe we'll do a couple in the rear as well. And maybe I'll set their attenuation radius up to something higher, maybe like 120. Right. And now I'm starting to get these accents. So again, let's go back from our perspective. I'm going to select all of my point lights and just really quickly group them."},{"start":"3:42","end":"4:15","startSec":222.6,"text":"And we'll just call these kicker lights. And then I'll turn these off and on. And it's very subtle. You can kind of see what's happening. But I'm going to go ahead and just go to these real quick. And I'm going to adjust their intensity from 50 to 200 just so we can better see on the video what's happening here. So again, off, on, off, and on. All right. So now we're starting to fill out light. Now, one quick little trick that I do want to show here is if you notice that we've got"},{"start":"4:15","end":"4:48","startSec":255.2,"text":"these specular highlights occurring wherever the lights are in kind of the tangent angle of the camera to the light itself, and we can actually remove some of that effect by if we scroll down. So in the point lights themselves, so in this case, I have all of them selected. We have this specular scale. So I can take the specular scale of the light and let's say we drop it at something like And you see now it basically starts to act like a diffuse light. So we still have the same intensity, but you can see in the reflections, it's much smaller."},{"start":"4:48","end":"5:18","startSec":288.9,"text":"It's much more mitigated and really helps to not detract the eye, but rather just help to accent some of the various different things that we wanted to show in our in our scene. So at this juncture, really, this now boils down to artistic interpretation or what you're trying to create with your scene. So by placing these lights, isolating them, creating our kicker lights and viewing from our different angles, we can start to light our scene artistically to whatever vision that we've set out."}],"12_PostProcessing":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"At this juncture, you should have had enough time to go in, add all of your various different lights, add your kicker lights, change your colorations, right? Essentially build out the scene that you want and you want to achieve. And now we're going to start getting into adding back in some of those artistic effects that we removed with our neutralized scene. So if you recall, when we set up our scene, we created a neutral baseline, right? We removed any of the post-processing effects, anything like bloom, et cetera."},{"start":"0:30","end":"1:02","startSec":30.6,"text":"Well now we can go in and actually add these back into our scene. And through that, we're actually going to use a process that I really like, which is just called layered post-processing. So rather than go back into our post-processing volume that we first set up, we can keep it there. In fact, we can just add a secondary post-processing volume and start overriding some of those various different settings that we want to bring back. Now the key here is our priority. So if you recall, inside of our post-processing volume settings where we set the infinite"},{"start":"1:02","end":"1:34","startSec":62.7,"text":"extent unbound or enabled or disabled, we can also give that post-processing volume a priority. Now the higher the priority, right? So one is higher than zero means that that post-processing volume, any setting that we check will override whatever is below it. So let's jump back into our scene real quick. And if you want to start on this one, we can just go to content, classrooms, walkthrough, and we'll start on the post-processing volume. Now just a quick note, feel free to dissect this entire scene."},{"start":"1:34","end":"2:06","startSec":94.9,"text":"Now this is obviously outside of the time that we have for this particular training module, these videos. But in here you'll see that I've used all of the various different techniques that we've covered in the previous videos. So here are overhead lights. Here you can see that three-point lighting we set up. In fact, I added a fourth for kind of a nice little fill on the bumper. And then we've also added our kicker lights on the inside here. So again, feel free to select the lights and you can go through the various different settings that I use to achieve this."},{"start":"2:06","end":"2:39","startSec":126.4,"text":"And then lastly, while we didn't cover how to use spotlights, essentially the principles are exact same. We can go to our place actors, drag in a spotlight. In particular, the difference between a spotlight and say a rec light or a point light is we actually have a cone. So in this case, I've added two spotlights onto the logo because why would it be a car commercial if we didn't have our logo? So here you can see that I'm adding just a little splash of light to the logo. So from whatever direction the vehicle is being viewed, very prominent here on the front."},{"start":"2:39","end":"3:13","startSec":159.2,"text":"So we turn it off, on, off on. Same principle here as the kickers on the inside. We're simply just adding some accent lighting to our scene. All right. So that should bring us to where we're at. Okay. So now what we want to do is go in and actually add some post-processing effects back to our scene. So then I'm going to go back to my place actors and just search for post-processing volume, drag this into our scene. And again, this doesn't necessarily matter where we place it. I'm going to go ahead and reset it to zero. I'll select off of it, select it again so it should highlight within."},{"start":"3:13","end":"3:46","startSec":193.9,"text":"I'll go ahead and just roll up some of these things in our. There we go. So underneath environment, we have our PPV neutral and here is our new post-processing. So I'm just going to rename this to PPV and then we can call this artistic. And again, this is just going to be all of our artistic settings that we want to override. So I'll go ahead and drag this up to environment just to stay nice, neat and tidy. So with my post-processing volume, the artistic one selected, I'm going to scroll down, do"},{"start":"3:46","end":"4:22","startSec":226.1,"text":"our same thing, make sure infinite extent unbound is checked. And then again, we just want to make sure that the priority is higher than whatever our baseline is, which if we select the neutral, you'll see we set it. We're set at zero. So my artistic, I'm going to set at one. And basically just to show the way this works is right now I have a bunch of various different settings, but you'll notice that nothing really changed within our scene and nothing will change until we actually go in and adjust one of those parameters. So for just ease of viewing what's happening here, I'm going to check my exposure compensation."},{"start":"4:22","end":"4:52","startSec":262.1,"text":"And if you recall from our neutral, it's set to negative 5.5. So as soon as I uncheck this, whatever is below it, so whatever the next presiding value is, which in this case is 5.5 from a neutral, that's what will take effect. But by checking it, now I have the ability to override that value. So I'll go ahead and just reset it and uncheck it. All right. So now again, I'm going to press G just to go into game mode so you can see it's happening. This is where we can go in and start adding our artistic effects back in. All right."},{"start":"4:52","end":"5:25","startSec":292.9,"text":"So I could turn on bloom again. So we get that nice bloom. We can adjust our threshold. I could take my intensity. Right. We could do whatever it is that we wanted to. We could also go into different lens flares. We could change various different vignettes, do something like this. We can even go as far as actually doing color grading within the editor itself. So I could go something like my temperature, so I could tint it, maybe do something ultra warm or maybe we drop it down. I could tint the effect as well."},{"start":"5:25","end":"5:57","startSec":325.5,"text":"I can even go into my various different highlights and shadows. So maybe on my shadows, I want to bump up the gain a little bit, or maybe I want to make it really noir-esque. Whatever you decide that you want to do. At any point, I can just disable these and again, retain whatever is below it. Okay. All right. So once you go through and you add all these different settings, again, the important part to keep in mind here is we haven't lost our calibrated baseline effect. All I have to do with my artistic is either hide it or I could simply just go down into"},{"start":"5:57","end":"6:19","startSec":357.8,"text":"the post-processing volume settings and just disable it. And now we're back to our neutralized baseline. But of course, if I disable both, you'll see now this is just the engine doing its thing. There's auto exposure in place. So by having both of these on there, that allows us to achieve whatever artistic look that we want to and still maintain that neutralized baseline."}],"13_TurnTable":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"As a final step to this class, we're going to go in and actually just add a small turntable rotation to the vehicle just to give it a little bit of movement and see our lighting in action as it kind of glances over all the various different surfaces. So if I jump back to our scene, so I'm going to open up this 06 final, which should have everything involved. Now on the Audi A5, you may see a rotational component. So if we just select that vehicle and in the route here has like a rotation movement, go"},{"start":"0:30","end":"1:05","startSec":30.3,"text":"ahead and select it, delete it, and we'll start from there. So just to recap in our scene what we have happening, so we've got our neutralized baseline. We've got our artistic effects added over the top. Now if you want to see what's been modified, great and easy way to do this is select this little settings cog. I apologize, this is off screen, but there should be a show only modified properties and this will show you everything that's been changed over the base. So you can see how we achieve this visual look by simply using this artistic effect. So again, if I turn it off, there's our neutral, turn it on, you see now we have these effects."},{"start":"1:05","end":"1:38","startSec":65.1,"text":"All right, so with the Audi A5 DS selected, I'm actually going to go to this component here and what I'm going to do is click the little add button and I'm going to search for rotation. So I'm going to do add, add rotation movement, it's fine like that. And I'm going to go ahead and turn off my show only modified properties and underneath the rotation movement, simply put, all I got to do is go down to rotation movement and instead of 180, which is going to be very fast, let's change this to something like 15. All right, now what I can do is go up to my settings."},{"start":"1:38","end":"2:12","startSec":99.0,"text":"Now in this case, I'm going to use simulate. You could use selected viewport, but I'm going to use simulate. And as soon as we do that, you see our vehicle now starts to rotate. And there we have it. That's going to conclude what we've built in this introduction to automotive visualization. With our lighting, again, just to recap real quick what we've covered. We've established our scene, we've put in all of our different components, all of our different calibration tools. We've then gone in, we've used a isolation approach to our lighting to add our lights,"},{"start":"2:12","end":"2:39","startSec":132.8,"text":"add our artistic effects or whatever we want to with those particular lights, hide them at all in the rest, balance, and then finally go in and add a post-processing volume to be able to add back some of those visual effects that we're looking for. And then lastly, by simply just adding a little bit of raz and dazzle to this, by adding a rotational movement to our actual Audi itself to be able to see the thing rotate in our scene. And that will conclude this course."}]},"100.14":{"01_Unreal Engine for Non-Developers":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Hello, and welcome to Unreal Engine's training for non-developers. Today we want to cover a few different areas to just give you a good overview of what Unreal Engine is, what kind of terminology we refer to whenever you're working in the collaborative teams. We're going to talk about using the Unreal Editor and where you can find certain features and functionality. We'll also talk about how assets and sub-editors are handled, whether it be through the rendering pipeline, animations and sequencer, which is Unreal's cinematic tool."},{"start":"0:34","end":"0:53","startSec":34.0,"text":"I will be talking about other additional tools that are also in the engine. And then we'll be diving into Blueprints. Blueprints is just a visual scripting language which uses code concepts from C++, but it's just a more visual way of communicating the moment to moment interactions inside of Unreal Engine. So let's get started."}],"02_What is Unreal Engine- Everything starts with U":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"So what is Unreal Engine? The best way to start thinking about this is that everything starts with you. Inside of Unreal we have something called a U project, which is the project that you will load to create your Unreal Engine project. In Unreal Engine's content browser we have assets that are named U assets and essentially anything that starts with U is centralized from Unreal Engine."},{"start":"0:31","end":"1:06","startSec":32.0,"text":"So in Unreal Engine we create projects. This will house any of your interactive cinematic animation driven experiences. We create projects from these files so that you can access all the individual information within these projects. Unreal Engine is also made up of editors, tools and systems. So whether it be an animation editor or a cinematic editor, maybe you're trying to do some real time lighting information."},{"start":"1:06","end":"1:37","startSec":66.7,"text":"Essentially we're using multiple different types of inbuilt tools and editors to create these projects from. It also manages assets and logic so Unreal Engine can house the raw data that you bring in from external packages and creates U asset from it and that's what we'll use to build our projects with. And when we refer to logic we're referring to the visual scripting language and also the C++ language."},{"start":"1:37","end":"2:10","startSec":97.3,"text":"We also can plug extra additional functionality into the engine via a plugin. So there's many different plugins already supported and you can also code your own plugins, which we'll talk about in a few slides as well. Unreal Engine can also package and executable and essentially packaging and executable will take your project, it'll wrap it up into a file that doesn't require the end user to have Unreal Engine installed and instead they can load the experience or project, whatever"},{"start":"2:10","end":"2:41","startSec":130.2,"text":"you've created from an executable. So when we say Unreal Engine we're not thinking about a car engine in that respect. It's more like a car assembly line. It's multiple facets to Unreal Engine throughout the development process that can be used. So it's not an all-in-one closed system as it were. It's more like a continuous assembly line. So the main questions we get around when starting with Unreal Engine, what is the difference"},{"start":"2:41","end":"3:15","startSec":161.2,"text":"between the project editor versus the engine? So the engine holds all the systems and tools. It processes the information that's sent to it behind the scenes and it's indirectly used. The engine is the under the hood stuff that you don't necessarily need to interface with. The editor exposes all this powerful functionality. It visualizes the systems, sub editors and tools to the user. It allows for asset creation and manipulation. So when we refer to importing your raw assets into Unreal Engine, whether they be video"},{"start":"3:15","end":"3:49","startSec":195.3,"text":"files, CAD files, any other 3D asset types, it could be music, it could be a whole host of assets. But you can also create assets directly from Unreal Engine as well. And it sends information from the project to the engine. So the project is housing all of your important information that you have for the project and the engine is presenting that project's information. And the editor is directly used. So you will be interfacing with the editor when using Unreal Engine. So when we talk about projects versus a U project, the project is the self-contained"},{"start":"3:49","end":"4:19","startSec":229.5,"text":"unit of files. So whenever you open the editor through the launcher, which we'll be talking about again in a few slides time, the project will house all of this different information. So when you install it to your hard drive, you'll see a config folder, a content folder, which we'll talk about and it includes all the bits that the engine really needs to work. The U project, however, you'll see at the bottom of this slide, which is the blue icon"},{"start":"4:19","end":"4:52","startSec":259.9,"text":"on the bottom left hand side, is a specific executable. It's what you'll use to launch the project and it references all the files within this folder. So if you think about the example project here as the launcher for the project, it tells Unreal Engine what content you want to load. The actual project folder contains all the actual information that you need to have inside that project. And as we referred to before, everything starts with U. So U asset is just an Unreal Engine"},{"start":"4:52","end":"5:25","startSec":292.4,"text":"readable file extension. It's as straightforward as that. It's any item that you find within the engine, whether you've imported a static mesh, like you can see in this example, maybe it's been an audio file or a texture, any kind of imported objects get turned into U assets. And things that you've made in Unreal, for example, materials, blueprints, any kind of particle systems, they all become U assets as well. So most things in the content browser, unless there's some uncompressed raw file, we've"},{"start":"5:25","end":"5:56","startSec":325.2,"text":"got very few exceptions inside the Unreal Engine. So more likely than not, you'll see everything coming through as a U asset. Moving on to the engine launcher. As promised, we can choose an engine version from the launcher. So when you first load Unreal Engine, especially when you're wanting to select Unreal Engine 5, multiple different engine versions to choose from, more often than not, you want to pick the latest engine version that if you're working on a commercial project, you probably want"},{"start":"5:56","end":"6:27","startSec":356.6,"text":"to use the latest stable engine, not the early access version of the engine. You have choice over what engine you do install. And it's also worth noting that everyone on the project should be using the same version of the engine as well to prevent any conflicts of information or data. Once you pick an engine version to use, you should stick with that unless everyone updates. And then when you choose to install the engine, it will give you a series of options, whether"},{"start":"6:27","end":"6:57","startSec":387.2,"text":"you want to install some additional content, some C++ content, you've got options to kind of configure your Unreal Engine install there. Unreal Engine via P4V is the source built version of the engine. And we follow some internal guides here. It does require approval from Unreal Engine and it has got global protect on there. So if you are using Unreal Engine via P4V and instead of via the launcher, you would"},{"start":"6:57","end":"7:28","startSec":417.7,"text":"expect to see the additional folders here. And when we're putting our projects on Perforce, when we're storing the projects, all the green files should be added to the depot. The green files highlighted here, so you've got the config, content, source, you project, and then just a preview of the projects image. Those files all want to add into your repository because everyone can then build the project based on those files."},{"start":"7:28","end":"7:55","startSec":448.2,"text":"The build, derived data cache, intermediate and saved, they're all temporary files that can be local to that individual's computer. So the binaries folder is optional. It's a large file. Some people want to upload that for posterity to share along the team. You don't have to do this all the time. You may find instances where you choose to do that, but the main folders that you do want to put on Perforce are highlighted in green here."}],"03_Using Unreal Editor- Basics and Navigating the UI":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"So now that we have a good understanding and overview of what Unreal Engine is and how the engine affects the editor, we're going to go over the basics and navigate in the UI. So you can think about the flow of the use of Unreal Engine starting from the left-hand side here. We import all the files. They turn into this big project, which is housed of a series of UAssets."},{"start":"0:32","end":"1:03","startSec":32.3,"text":"And then the editor, the interface that you'll be using, plugs into that project. So you can interface with all the files. You can have some tools plugins, as we referred to before, that can supplement the engine's use. It may give you some more custom functionality over certain properties and features that you need for your project. And then the engine compiles everything. It cooks to what we refer to as cooking the files and creating an application from all"},{"start":"1:03","end":"1:38","startSec":63.7,"text":"of these files. So if we look at the engine versus editor again, the engine accessed via the editor of Visual Studio. It contains core tools and systems. The engine manages all the moving parts, all the under the hood stuff that we referred to before. And it also packages the project. Whereas the editor, it is your interface for adding, editing any of the content that is there. There is also sub editor interaction through different windows and browsers."},{"start":"1:38","end":"2:10","startSec":98.4,"text":"And it also visualizes all the project's content. So if you've employed the 3D assets or the particle systems or anything that we were referring to before, you can visualize all of these with inside the editor as well. To access the editor, we want to download and launch a project file. So we want to select the engine version. You can select the project. And also there is a vault section along the bottom which will house any kind of free content"},{"start":"2:10","end":"2:23","startSec":130.0,"text":"that you may have downloaded. And there is more documentation for reference, but it's sometimes useful to just get a practical example. So let's load the launcher ourselves and let's get stuck into a third person template and show you exactly what we referring to here."}],"04_Launching the project":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"So, the first thing we want to do is load our launcher and on the top right hand side here you can see launch Unreal Engine and again you can pick the version that you want to have there. You can go into your library and select the engine version from this tab as well if you've not got it installed we can just click plus engine version and you can install a new version of Unreal and you can select the drop down options from the engine version selector there."},{"start":"0:33","end":"1:04","startSec":33.0,"text":"So I'm just going to go ahead and launch Unreal Engine. I've got 5.0.2 here but it's completely up to you which engine version you're using. Ideally to follow along with this it would be Unreal Engine 5 but the actual 0.2 does not matter in this instance. So Unreal Engine will initialize and we'll just let it build and compile everything that it needs to and then we're going to load into a project of our choosing."},{"start":"1:04","end":"1:36","startSec":64.8,"text":"So the first screen that we see here will be our recent projects. We'll have games, film, video, live events and these are all prefabs for your project to give you some default properties to set up inside your engine so you don't have to do all the heavy lifting yourself. For today's example we're going to go over to games. I'm going to select a third person running game and we're going to keep blueprint selected here we don't need the C++ files."},{"start":"1:36","end":"2:07","startSec":96.4,"text":"I'm going to choose the target platform as desktop. I'm going to keep quality preset at maximum and I'm going to maybe include some starter we want any assets to play with which are 3D meshes or any things like that. I'll leave ray tracing on tick for now. If you have a ray tracing enabled computer feel free to enable that but I'm just going to call this let's call it running game. Whatever name and convention you go for it's fine."},{"start":"2:07","end":"2:41","startSec":127.5,"text":"Generally my project would be okay but we just want to try and avoid any projects that we're not sure what the actual project would be. So it's always best to name it something that you intend it to be. Project location doesn't matter too much however I would recommend having the projects if you have an SSD installed on your computer or laptop it's always better to run Unreal Engine projects off an SSD just because the information is accessed much faster there. So we'll create this project and we'll let it create everything again Unreal Engine is"},{"start":"2:41","end":"3:15","startSec":161.2,"text":"going to make certain assumptions for us to get us up and running faster. We can still manipulate all these settings and we can actually change the game type from inside the project if we decide that we no longer want it to be a third person template we can change this inside of Unreal Engine. However it's just much quicker time of saving of time if you start with the template that you intend to use. So you can see we have the engine open here. First of all we can look around this main scene and we'll go over the UI in more detail"},{"start":"3:15","end":"3:48","startSec":195.9,"text":"but I'm just going to hold my right mouse button in this viewpoint and I'm going to press and hold right mouse button and you can see that I can look around here. I'm going to press and hold left mouse button and I can move forwards backwards and I can just pan around this scene. Now I can hold left and mouse right mouse button sorry to move up and down. So again right mouse button to look around left button to navigate through the scene"},{"start":"3:48","end":"4:18","startSec":228.6,"text":"and then both mouse buttons to move up and down and you can just get yourself familiar with this type of navigating the scene. You can also as a quick shortcut hold right mouse button and use W, A, S and D on your keyboard to navigate through the scene. So if you're familiar with WASD controls generally found in PC interactive experiences you can"},{"start":"4:18","end":"4:49","startSec":258.8,"text":"use those to navigate the scene as well. So we'll go over more detail of the rest of Unreal Engine. I'm just going to tick that off there and all we really want to do now is just check how to load up a project and run into the game. So I'm going to click this big green play button here. I'm going to click play and you'll see that I'm instantly inside the game. So I'll click into the screen and you can see that we're running around pressing W and panning our camera using our mouse and we can press S, we can press A, we can press"},{"start":"4:49","end":"5:03","startSec":289.8,"text":"D and instantly straight out of the box we've got an example running game. No coding required just clicking a few buttons to get started. So that's how powerful Unreal Engine can be just straight out of the box."}],"05_The Editor- Navigating the UI":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"As you're looking around the editor, we just want to highlight a few key areas that you may want to look for when interfacing with the Unreal Editor. So at the top, we've got the menu bar. You'll see that green play button there, which is what we use to jump into our experience. And you can also select a few different modes. You may be wanting to place content in your scene. You may want to be adding foliage or landscape."},{"start":"0:33","end":"1:05","startSec":33.6,"text":"That's where you'll select the different modes from. That will also be where we can compile our blueprints. We can create cinematics and we can also create an executable, depending on the platform that we want to, whether we're packaging for a PC or a mobile or some other platform, which is your intended output. So the menu bar is at the top there. The main viewport here is in number two, which we were navigating before. I'll put some useful prompts on the screen in a second to help you navigate through the"},{"start":"1:05","end":"1:36","startSec":65.8,"text":"editor. The World Outliner is essentially a list of all the content that is within the scene. So you'll see everything selected there. If I jump back over to my editor, you'll see in the World Outliner, you'll see everything listed. And as I click the cube, it selects the cube inside the map. So it's just a big list of everything that's inside of the scene. If you double click anything, you'll go straight to it inside the editor."},{"start":"1:36","end":"2:08","startSec":97.0,"text":"So very powerful. It houses all the information that is part of your project to look through. And it's just a very useful list to be able to navigate. And then we've got the details panel, which will give you details of any specific actor. If I hop on over to my editor again, you'll be able to see that we've got a whole bunch of properties here based on the location, the rotation, what static mesh is being used, the material, all these lists of properties that come as standard inside of Unreal Engine,"},{"start":"2:08","end":"2:44","startSec":128.2,"text":"which will allow you to create the content in the desired effect that you want it to be. When we're navigating the viewport, as we mentioned previously, you can use mouse navigation. You can use it to look around. You can also change the camera speed, which is useful if you're moving either too quickly or too slowly. And to do that in the editor, you can select the camera on the top right-hand side here and set the camera speed to whatever you would like it to be, along with the camera scalar there."},{"start":"2:44","end":"3:19","startSec":164.4,"text":"We can also use the WSD keys to move around, which I was referring to before, and the Q and E keys to go up and down. If you didn't want to use your mouse to move up and down, you can use Q and E. And then C and Z controls the field of view to get the desired effect that you may want. We've got mayor style controls, so F is to fit to frame, Alt and Left mouse button to tumble in orbit, and Alt and Right mouse button to dolly. And again, some just useful viewport navigation hotkeys here in case you wanted to save their"},{"start":"3:19","end":"3:23","startSec":199.1,"text":"and just remind yourself of navigating the interface."}],"06_Assets _ Subeditors- Creating and changing objects":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"So it's probably useful to give you a bit of an idea about what assets and sub editors are available and how you can create and change objects inside of Unreal Engine. So the subsystems that we're talking about in Unreal Engine today, we're talking about rendering, lighting and materials. We're talking about particles that you can create inside of Unreal Engine through the use of Niagara. We're talking about Unreal Engine's new audio system for Unreal Engine 5, physics and destruction,"},{"start":"0:33","end":"1:05","startSec":33.8,"text":"animation, control rig and sequencer. And again, sequencer being the cinematic tool that Unreal Engine has built in and the control rig being the animation tool that allows you to create animations directly inside of Unreal. We're talking about blueprints, which are the visual scripting software built into Unreal Engine. And we're talking about UMG, which stands for Unreal Motion Graphics, which you can create all your UI and interactive content from. And we'll also be touching upon AI and lots more."}],"07_Rendering- How do we see-":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"So when we're talking about rendering, we're talking about how do we see things inside of Unreal Engine. We have multiple buffer views as a visualization inside of Unreal. So in the middle, you can see the main interface screen that you would generally see for most of your projects. However, we can separate these buffers from base color to specular."},{"start":"0:30","end":"1:07","startSec":30.4,"text":"We can even check normals, world tangent, opacity. There's many different views that we can see at real time inside of Unreal Engine, which you can select from inside the editor. When we talk about lighting, we can have different lighting shapes. We can have point lights and spotlights and skylights. There's a whole different range of lights that you can use to get your real time effects looking exactly how you want them. We can change the type of light from static to stationary to mobile or dynamic, which"},{"start":"1:07","end":"1:42","startSec":67.5,"text":"means you either bake the lighting or maybe it's partly dynamic or maybe it's fully dynamic. We have features inside the engine such as lumens, global illumination and reflections, which is Unreal Engine 5's real time lighting. We have ray tracing built in that you can use for your projects. And also we can select between forward and deferred rendering methods depending on what you would like to use there. So you can update the global illumination directly from the project to use the lumen"},{"start":"1:42","end":"2:14","startSec":102.4,"text":"illumination. And you can set a whole different bunch of properties here. When you're digging into the projects and the content yourself, you can select between the different rendering methods you would like to use there. When we refer to textures, we're talking about images that hold visual data. Textures inside of Unreal Engine have RGB and A channels, so the red, green, blue and alpha channels. And you can make tweaks to each of the textures on the right hand side details panel here."},{"start":"2:14","end":"2:44","startSec":134.7,"text":"You'll notice the details panel becoming a common theme throughout the use of Unreal Engine's editing through the tools and the systems that we're using. Details panel is always your go-to of where to edit this content. So you do have adjustments that you can make with inside the textures of Unreal Engine. When it comes to materials, we can create materials directly inside the editor. We can create instructions for how you want that material to be rendered."},{"start":"2:44","end":"3:18","startSec":165.0,"text":"We can have material layers. We can also create dynamic materials that can be affected at runtime, depending on your desired outcome. So we can change the shading models and the blend modes and different properties of materials all directly inside of Unreal Engine and again through the details panel. We also have meshes inside of Unreal Engine. So NaNi is Unreal Engine 5's new virtualized geometry system. So you can have millions of polygons being rendered on the screen at the same time to"},{"start":"3:18","end":"3:51","startSec":198.6,"text":"a very high fidelity. And we also have a static mesh editor built in, which you can use to edit the content before it goes into your scenes. To import meshes, you can go to the content browser and you can just go to add and import or you can drag and drop the content in. So if we just hop over to our editor again, you'll see there's content already here. And because we clicked start a content and we'll go to the props folder."},{"start":"3:51","end":"4:25","startSec":231.0,"text":"So we've got some static meshes here. So we have, imagine you had imported these static meshes. This is where they would be. So you can drag and drop your FBXs into the empty space here and that will import them. You can click the import button and add files directly to your projects from there. We also have a particle system called Niagara, which is Unreal Engine's new particle system. You may see reference to Cascades sometimes and that's Unreal Engine's deprecated particle"},{"start":"4:25","end":"4:55","startSec":265.2,"text":"system. So you want to be using Niagara for all your particles moving forward. And essentially this is an emitter's, a module's tool that you can use to create the desired functionality. You can animate the particles in there. You can add scripts in. Again, it's all very modular based to get the desired outcome that you would like there. We can also support virtual productions. So we have cinematic cameras built inside of Unreal Engine."},{"start":"4:55","end":"5:25","startSec":295.3,"text":"You can use composition to maybe have green screen performances composed in real time inside of Unreal Engine. So you can see everything updating based on the current frame inside of Unreal Engine rather than waiting for it to render out. We can do motion facial capture, sequence editing, and again, sequence being the cinematic editing tool, and the in-camera VFX is also supported. So more rendering features to maybe look into through the documentation."},{"start":"5:25","end":"5:57","startSec":325.5,"text":"The post-processing. You can create film effects directly through the post-processing. So whether that be lens flare or any other type of effects you'd like to add to your scenes, you can do that through the post-process chain. We have real time reflections supported, height and atmospheric fog, sky atmosphere. So you can change the time of day, add clouds, the sun position, and this all gets added under the hood inside the engine so that you can very quickly get different atmospherics"},{"start":"5:57","end":"6:03","startSec":357.6,"text":"for your scene. And then we have light mass tools which are the baking tools inside of Unreal Engine."}],"08_Workshop- Create a new material":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"So what we'll do is we'll create a new material just as a little trial just to get us used to creating content inside of Unreal Engine. We'll create a shiny material that has a dynamic instance to it and show you how to apply that to a mesh inside of Unreal Engine. So let's jump into our editor and we're going to go to our materials folder. What I'll do is instead of going into the starter content, I'll just collapse that file"},{"start":"0:34","end":"1:06","startSec":34.3,"text":"there. I'll click on content and I'm going to right click new folder and I'll just create a folder called materials here just to keep things organized. You can put your materials folder wherever you'd like and then we want to right click in the empty gray space here and we want to select material from the list here, the green icon. So good naming conventions are always useful to follow whenever you're working in projects. For materials we like to use the M underscore naming convention and I'll just call this"},{"start":"1:06","end":"1:39","startSec":66.3,"text":"M underscore base color and I'll hit enter on my keyboard and that will load this up. So I'm going to get the base color and I'll show you again how to load that in case you've not been able to load that but I'm just going to get this base color tab and pin that up there. Now if you had selected off it before hit and enter, you can just double click the file as well and that will load as well. So I've just pinned this to the top of my screen here. I'm just going to go to file, save all just to make sure everything is always up to date."},{"start":"1:39","end":"2:10","startSec":99.8,"text":"Now the first thing we want to do is we want to add color to this material. So I'm going to hold three on my keyboard and left click and that creates this node here. I'm going to right click the node, I'm going to convert it to a parameter and I'm going to spell color the British way here. So apologies for anyone that I've spelt it wrong for and I'm going to drag out and go into base color. So I'm just going to get my left mouse button and drag across into base color."},{"start":"2:10","end":"2:44","startSec":130.3,"text":"I'm going to save again just to make sure everything's running okay and I want to select a color for my color. So let's go to the default value. Again the details panel is where we're going to be editing a lot of our content. So the default value I'm just going to select there on the black and I'm going to pick a nice value. Maybe that looks good. So whatever color you'd like to pick, feel free to pick that and we will give our materials"},{"start":"2:44","end":"3:18","startSec":165.0,"text":"From our workshop we'll give it a metal value and a roughness value just so we can affect these at runtime. So metal and roughness is where we're going. So we'll press number one on the keyboard and left click to create these new nodes. So before we clicked three and now we're going to click one. So one into metal and then another one into roughness. Now I want to right click again the node, convert it to a parameter and I call that"},{"start":"3:18","end":"3:51","startSec":198.8,"text":"metal and I'm going to right click on this one, convert it to a parameter and call roughness and you'll see why we're converting these to a parameter. You'll see before we converted them they still had the same effect and everything would still work without us converting them but as I save and I've got my basic color set up I'm going to go into my third person map. I'm going to navigate just using my left and right mouse buttons here."},{"start":"3:51","end":"4:27","startSec":232.0,"text":"I'm going to drag, get my color, drag and drop it onto here. So you'll see that we've got a shiny material and that's because our metal value if I go back to my color is zero and the roughness is zero. And so if I close this now I don't need this editor anymore and I'm going to get this base color, I'm going to right click on the base color so make sure you're on the base color. I'm going to create a material instance and I'm just going to select off that."},{"start":"4:27","end":"4:57","startSec":267.4,"text":"Now what this has done is it's instanced this material so it's almost like a child. If you think about this as a parent, this is a child. I'm going to double click the child and I'm going to tick these three boxes here. I'm going to tick metal, I'm going to tick roughness and I'm going to tick color. And you'll see that these are the properties that we created parameters for. So say for example we change the metal to one, it makes it way shinier."},{"start":"4:57","end":"5:28","startSec":297.7,"text":"So if I save this and close the material, you'll see that I've got a really shiny version there and you can just keep creating. Once you've got the base material set up, you'll see that I can just duplicate this for example, double click it, maybe I change the color of this one, hit okay and save and maybe I drag and drop that on the floor and you'll see now we've got this orangey color that's reflecting from the sky."},{"start":"5:28","end":"5:59","startSec":328.7,"text":"Now this clearly looks awful and terrible. I'm just trying to show you the intended result for what you can do with just basic functionality and then you can edit the content based on those dynamic instances from the main material. So that's just a quick example of how you might use the material editor inside of Unreal Engine. So that's it for this video."},{"start":"5:59","end":"6:26","startSec":359.1,"text":"I hope you enjoyed it. If you did, please like and subscribe. I'll see you in the next one. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye."}],"09_Physics- Chaos _ more!":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Physics is another really powerful tool inside of Unreal Engine. So what are physics inside of Unreal Engine? So we can create collisions and responses from a physics model. You'll see on the screen here you have some form of character mesh and you'll see there's almost a pinkish-purpleish opaque material around the skeleton."},{"start":"0:30","end":"1:07","startSec":30.4,"text":"And that will show where the collisions and responses should be for this particular skeletal mesh. All skeletal meshes can have these constraints and physics built into them. So you have components which are constraints. You can also have vehicles inside of Unreal Engine. So we can have accurate tire data and wheel blueprints. You can get the car's feel and exactly how you'd like them to feel. And also you have a skeletal PHAT, which is just the physics system for skeletal meshes."},{"start":"1:07","end":"1:38","startSec":67.8,"text":"Chaos is a big feature of Unreal Engine's physics tools. And we can do geometry collections. We can fracture meshes at real time. You may have seen some demos of real time buildings crumbling from the different demos, the various demos we've released. We can cluster objects. We can connect certain fractures to others. So there's connection graphs and we can show the knock-on effects of these fractures happening in real time."},{"start":"1:38","end":"1:42","startSec":98.5,"text":"And also you can create fields from these chaos destruction fields."}],"10_Audio- Synthesized Power":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"So the audio system in Unreal Engine 5 is something that the team has been working on for a very long time. It's a very powerful tool. Synthesize power is how we're referring to it. The audio engine inside of Unreal has had a big overhaul since the previous versions of Unreal. And we can, on the base level of Unreal Engine 5, you can support sound waves. And that sound wave is essentially the default data imported, maybe imported, maybe created"},{"start":"0:33","end":"1:07","startSec":33.9,"text":"directly inside the engine. But we've got the wave data and the sound cues will hold these waves and you can edit the waves through controls. So in the previous workshop, we created a quick material with a metal and roughness. And we created a base material and created a material instance from that material. I like to think of sound cues as that base material and the waves are the kind of child to that. So in the sound cues, you will add waves."},{"start":"1:07","end":"1:37","startSec":67.5,"text":"So it's that kind of relationship. All waves can be found in sound cues, but not all waves need sound cues. I hope that's a useful way to describe it. We have Quartz inside of Unreal Engine, which is sample accurate to all the timings that are happening inside of your interactive experiences. We can create music systems through clocks and metronomes. And it also has full blueprint integration."},{"start":"1:37","end":"2:12","startSec":97.7,"text":"So you can, if you're doing any kind of real time interactions and you want certain inputs to be registered to create SFX or music from, you can do that through the visual scripting tool, which is a really powerful feature. When we're thinking about meta sounds, we're thinking about replacing the sound cues and having these larger meta sounds, which can have as simple or as complex scripting as you need. But essentially meta sounds are digital signal processing, a DSP, rendering graph, which"},{"start":"2:12","end":"2:26","startSec":132.9,"text":"has a complete synth creation. There's many demos out about meta sounds. It's a really powerful tool for users of Unreal Engine to be digging into. And it's something very exciting to look forward to developing more in the future."}],"11_Animation, Control Rig _ Sequencer- Get things moving!":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"On the animation, control rig and sequences side, this is essentially how we can get things moving inside of Unreal Engine. So the Skeletal Mesh Editor that we were referring to before, all editors can be accessed from these editor windows. And so this is the mesh layout version of the Skeletal Mesh. And you can see that we have settings pertaining to the mesh, such as the materials that the"},{"start":"0:31","end":"1:05","startSec":31.5,"text":"Skeletal Mesh is using on the left-hand side there and the material slots. You can set the level of detail, which is an LOD. Morph targets can be used here and then can be accessed via the editor. The animation blueprints are the event graph for the logic. So you can, it's almost like a state machine type setup here, where if you want to transition your character from a run to a walk animation, for example, you could do that through the event graph in the animation blueprint and event graphs for animation."},{"start":"1:05","end":"1:38","startSec":65.6,"text":"You can control it and blend the different animations inside of here as well. Control rig, as I said before, is how you can create tools and controls for animators to animate directly inside of Unreal Engine. So it is through a plugin, which is automatically on by default. So you can access this inside of Unreal. We build automated rig with familiar functionality and you can expose the controls for animators to use. It's a very powerful procedural animation tool as well."},{"start":"1:38","end":"2:15","startSec":98.7,"text":"And we can also write scripts to automate the workflow. So we have Python support. So if you want to use any Python tools, that kind of workflow is exposed to you inside of Unreal Engine. And Sequencer is Unreal Engine cinematic tool where it is essentially a nonlinear animation system. So we can animate assets inside of here. We can use control rig assets inside of here to animate as well. We've got editable tracks, which you can add keys and different data, such as animations"},{"start":"2:15","end":"2:45","startSec":135.1,"text":"and audio files to. You have sub sequences, which keep things nice and organized, controllable assets and the cinematics tool, which you can add cinematic cameras and create different cut scenes, which you can either then run in real time or you can render out as a pre-rendered video. Other animation tools to consider here are the retargeting of IK retargeting. So if you want to use a series of animations across multiple characters, you can do that"},{"start":"2:45","end":"3:11","startSec":165.8,"text":"inside of Unreal Engine. We also have face capture, which is the iOS app for FaceAR, which you can get data and project that onto your mesh inside of Unreal Engine. Live link, so any mocap systems you're using, you can create a live link between Unreal Engine and interface that so you get the data directly into the engine. And also there's the Alembic geometry cache."}],"12_Blueprints, UMG _ AI- Combine logic and components":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"So when we're talking about Blueprints, UMG and AI, we're combining logic and components to create some kind of outcome. So the Blueprints is Unreal Engine's visual scripting language. UMG is Unreal Motion Graphics, which you'll be creating a lot of UI from. And the AI systems we'll discuss inside of Unreal Engine. So Blueprint, Blueprints and Blueprinting. Easy for me to say."},{"start":"0:30","end":"1:03","startSec":30.7,"text":"Class. A Blueprint class basically is a C++ class. So the visual scripting is just housing all of this C++ under the hood. So it's a core concept of an object inside of Unreal and primarily used to combine scripts and other components. So a class is what you will be building a lot of your functionality out of. An instance is a spawned object of a class that exists within the level. So you may have created a class and added an instance of that class to the level."},{"start":"1:03","end":"1:34","startSec":63.8,"text":"These can be changed without changing their instances or the core class. So you can edit on a per instance basis. In the previous workshop example, when we created a material instance of the other material, we could edit that color without changing the parent property there. And that's what we talk about when we're referring to instance. When you select a Blueprint in the Viewport, its data appears in the details menu. So you can edit all of this functionality with inside the editor as well. And it's a visual scripting tool."},{"start":"1:34","end":"2:08","startSec":94.9,"text":"So Blueprinting is the act of writing logic via Blueprint script. It's visualized C++. So again, when we're talking about C++ being under the hood, it's all C++. It's just a nice visual representation of it. And Blueprint can be baked during the packaging process to optimize it. So some people prefer to do a lot of their projects inside of Blueprinting. C++ is a faster language, just direct inside of Unreal. But through using Blueprints, we can actually bake those Blueprints to get more efficiency"},{"start":"2:08","end":"2:39","startSec":128.9,"text":"through the packaging process there. A difference between the Blueprint class and the C++ class is C++ is faster. Exactly like we were referring to before. This can be up to 10 to 13 times faster. So it's better to do functions in C++, a better online replication controls and processing math loops. It's the low level language of the engine. So if you can put stuff into C++, definitely do that."},{"start":"2:39","end":"3:16","startSec":159.3,"text":"But Blueprints have their benefit, especially when working in teams and collaborating. We can prototype very rapidly. So even if you have programmers on the team, you may find that programmers are still using Blueprints a lot of the time just for rapid prototyping. It's a very visual script that a lot of the team members can get behind and understand how to debug their own information. And there's better connections with the subsystems and tools. So as we were talking about in MetaSounds, for example, which is the audio system or the Niagara system, we can interface with other tools and subsystems via Blueprints."},{"start":"3:16","end":"3:49","startSec":196.1,"text":"And it's also a component answer window. So it's just very easy to edit. But definitely worth diving into the documentation on Blueprints to learn more about Blueprints and their pros and cons over using C++ classes. When we talk about Unreal Motion Graphics, UMG, we're talking about HUDs, like any menus that we want to display in the game, any user information that we want to present on the screen. UMG has a designer where you can drag and drop text boxes and images and you can animate"},{"start":"3:49","end":"4:19","startSec":229.3,"text":"elements directly through UMG. And it also has a graph, a Blueprint graph, which you can create Blueprint functionality from to say, when I click this button on the menu, for example, create this kind of functionality. So very powerful tool to kind of create a interface for your user or viewer. And when we talk about AI, we have built-in tools for AIs to kind of query their environments and understand how to navigate the space."},{"start":"4:19","end":"4:50","startSec":259.6,"text":"We have environmental queries, which is relatively powerful, not relatively powerful, it is a powerful system for AI to understand their surroundings. They understand when they're visible, when they're not visible, how far they are away from the player, for example, if you're making a game. We also have NavMesh, which you can see on the bottom image here, which will allow anywhere in the green space for the AI to walk around and they'll just try and navigate around this green space."},{"start":"4:50","end":"5:23","startSec":291.0,"text":"And also, as you can see, it becomes darker green the higher up you go, which creates certain conditions for the AI to think, okay, I want to reach high ground, for example, so they'll try and find the darker green areas. We have behavior trees, which you can see in the top right here, and it is almost like a state machine in the respect that you can create conditions for AI to walk around, but it's not useful to think about it as a state machine. Behavior trees are their own concept, which you can automatically create conditions from"},{"start":"5:23","end":"5:56","startSec":323.5,"text":"in order for the AI to navigate the space in a way that you intend them to do. In these behavior trees, you've got all the things you'd expect from a behavior tree, such as blackboards and decorators and sequences and selectors, all these kind of tools built directly inside of Unreal Engine. We've got a perception system, so you can add a perception component to the AI, which allows them to see and hear and create different perceivable events based on that component."},{"start":"5:56","end":"6:26","startSec":356.1,"text":"And we've also got mass AI, so if you're trying to create a lot of AI in a scene, there are ways to do that in quite a straightforward way directly inside of Unreal Engine. So it might be useful now to give you a better idea about Blueprint and how to create a basic Blueprint so that we can understand the value and just how quickly you can get something set up. So in this instance, we're just going to create a basic Blueprint that we can place in the level."},{"start":"6:26","end":"7:00","startSec":386.5,"text":"We're going to put a box around the Blueprint to say, when you overlap this box, just destroy it. And it's almost like creating a little pickup or something like this. So let's jump into our editor. We're going to find some empty space in the map, probably where the player starts running from so we can be quite close by. We're going to go to the content folder. I'm going to right click and select New Folder. And I'm going to call this Blueprints."},{"start":"7:00","end":"7:34","startSec":420.8,"text":"And we'll right click in the empty space, Blueprint Class, which is the blue icon. And we'll be given a series of options. In other tutorial videos, we'll go through each one in other courses, sorry. And we'll go through each one. But for now, just select Actor. And again, thinking about naming conventions, we'll go for BP, which is Blueprint underscore, let's call this a pickup. So BP underscore pickup. So if you file, save all, and then we'll dig into the actual functionality into the next"},{"start":"7:34","end":"7:34","startSec":454.1,"text":"video."}],"13_Workshop- Creating a pickup":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"We want to create a blueprint pickup and we want to double click the pickup to create some data and to edit. First thing we want to do is we want to add a mesh to our pickup. So I'm going to hit control and space bar to open my quick draw. I added starter content so we can go to starter content props."},{"start":"0:31","end":"1:03","startSec":31.2,"text":"If you don't have starter content installed you could do one of two things. You could just go to the all content, you could select your filter from here and you could click static mesh and that will filter all the static meshes in your project so you can select whichever static mesh you would like. I'm just going to clear that static mesh filter out because it's always good to remember to do that just in case you can't find the information you want. I'm going to go back to the props section and I'm going to say add this statue here"},{"start":"1:03","end":"1:34","startSec":63.1,"text":"sm underscore statue for my prop. Again you can add any mesh you would like. I'm going to go to add the green plus button here and you'll see static mesh and it says sm statue because I've got the statue selected. Now if you don't have anything that you can see the file name for there make sure you select it through that quick draw by pressing control and space bar and selecting it. So I've got the statue and I'll navigate around there."},{"start":"1:34","end":"2:05","startSec":94.5,"text":"Again same navigation tools as you're using with inside of Unreal viewport so right mouse button to look around, left to go back and forth, both mouse buttons to go up and down. So we'll add another component this time we'll type box into the search list and I want to create a box collision. I'm going to drag this box collision up and on the details panel you'll see box extent here."},{"start":"2:05","end":"2:37","startSec":125.3,"text":"So the box extent I'm just going to make a little bit bigger in Z and I'm going to make a little bit thicker in Y and a little bit thicker in Z just so it houses the pickup nicely. So I'm going to compile, I'm going to save and I'm just going to put this pickup into my map so I know where it is. So I'm going to get the pickup window, I'm going to pin it up there for my blueprint, I'm going to go back into the third person map, I want to select my pickup from the content"},{"start":"2:38","end":"3:11","startSec":158.1,"text":"browser and just drag it into the scene. If I look at it there, looks pretty good, the size is okay, that works for me. So if the size of the asset that you picked isn't correct you can just scale that up by going back into your blueprint window, selecting that and then selecting the scale of whatever scale you want that to be, you can change those numbers. So let's create a basic blueprint script just to pick up this pickup. So we're going to select the event graph up here, I'm going to navigate to some free"},{"start":"3:11","end":"3:46","startSec":191.7,"text":"space by right mouse dragging, I'm moving downwards. I'm going to select our box from the box collision that we added before, I'm going to go back over to the right hand side of the screen, I'm going to scroll down to the bottom and you'll see on component begin overlap. So I'm going to click begin overlap. So you'll see on component begin overlap and in brackets you'll see box and that is the box up there. So I know that that box is talking to this event."},{"start":"3:46","end":"4:16","startSec":226.3,"text":"So when I overlap the box, I want something to happen. So I'm going to drag out, I'm going to type destroy and select destroy actor. So I just left mouse dragged out, a new menu popped up, I type destroy and you just select destroy actor. Now what this is essentially doing is saying I have overlapped this box, now destroy this"},{"start":"4:16","end":"4:50","startSec":256.8,"text":"entire blueprint. So I'm going to go to compile at the top left here, I'm going to save, I'm going to go back into my third person map, I'm going to press the play button, I can see my pickup over here and it just destroyed as I ran over to it. So I'll hit escape and press play again, looking at the pickup, I run over to it and as soon as I hit the box which is surrounding the pickup, it destroys."},{"start":"4:50","end":"5:17","startSec":290.4,"text":"And that in essence is the start of your blueprint journey where we can add much more functionality into a pickup, you could spawn a particle that shows that you picked it up, you could add a score to the pickup so that the player can start adding score. From there you can start building these interactive experiences depending on what you want. Hopefully that was just a useful quick example of what a blueprint can do and the power of them."},{"start":"5:20","end":"5:25","startSec":320.4,"text":"Thanks for watching!"}],"14_Other Features- But wait! There_s more!":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Before we wrap up this course, I thought it might be useful to just go over a few other features that you can maybe dig into and research through the documentation or directly through the engine, just playing around and digging into the different tools. So we can do landscape. We have a landscape tool. So if I just jump over to the engine from the select modes, you can select landscape and edit vast landscapes."},{"start":"0:30","end":"1:04","startSec":30.6,"text":"And there's many powerful tools there to dig into. There is paper 2D, which is a 2D engine of Unreal Engine, where you can create your own 2D games. There are virtual production tools, which we briefly touched upon before, but there's a lot going on in the virtual production space that are definitely worth digging into. We've got end display. We've got geometry editors, accessibility tools, take recorders, which are take recorder is it can record a performance inside of Unreal Engine and create its own asset"},{"start":"1:04","end":"1:37","startSec":64.5,"text":"type from that recorded performance for use for however you want to use those tools. We've got automation tools and many, many more. So it was a very kind of quick overview of everything Unreal Engine 5 has to offer. There are plenty of avenues to go down, plenty of powerful tools for you to pick for your project, depending on its needs and capabilities. And hopefully from demonstrating here today, even though it can feel sometimes overwhelming"},{"start":"1:37","end":"2:05","startSec":97.0,"text":"loading a new piece of software and there's so many buttons to click, you generally find yourself getting into your own workflow, the things that you want to create, and it becomes second nature. So definitely worth just getting stuck in from the different touch points today. Maybe there are a few different tools that really look interesting to you that you want to explore further through the different courses that we have to offer or through the documentation. But I hope this was a useful overview of what Unreal Engine 5 has to offer."}]},"101.01":{"01_Intro":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hi everyone, in this lesson we're going to take a look at the introduction to materials and look at several different features such as what is a PBR material, how does it work with its primary nodes, how to set it up, the connections involved in organizing, as well as building your materials and creating material instances, animating materials, and finally a cloth material. So let's go ahead and take a look at the full outline for this course and we're going to go ahead and dive right in."},{"start":"0:30","end":"0:31","startSec":30.3,"text":"So let's get started."}],"02_RealTimeMaterialConcepts":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Hi everyone. In this lesson, we're going to go ahead and take a look at the outline for this series of videos in which we're going to be discussing how to tackle materials in Unreal. And then from there, we're going to go ahead and dive in and talk about what exactly is a Material, PBR, in Unreal in general. So let's get started. So one of the first things we'll talk about is real-time material concepts. What are materials in Unreal and what is PBR, physically based rendered material? We'll then look at primary nodes and textures,"},{"start":"0:33","end":"1:08","startSec":33.5,"text":"look at primary PBR inputs, material settings, and also textures. From there, we're going to take a look at material editor and parameter materials, look at material editor overview, hotkeys, preview window, material system, blend and light modes, and parent materials and instances. From there, we'll also look at making materials and parameters, editing materials, animating materials we'll go to. And from there, we'll look at diffuse and spec setup for those animations, pattern node and blending, rough setup, normal setup, and AO setup. And then finally, we'll look"},{"start":"1:08","end":"1:40","startSec":68.5,"text":"at the cloth material options and how you can use them to your advantage and how to navigate. All right, let's go and dive right in. Real-time material concepts. So what is a material when it comes to real-time and working with Unreal? It is essentially an asset applied to a mesh to control its visual look. In its simplest form, think of it as paint with various properties such as color and finish, and the light reacts to"},{"start":"1:40","end":"2:10","startSec":100.2,"text":"those properties. A material defines how light interacts with the surface it is applied to. You can see here a little demonstration how there'll be some materials that will absorb more light, and there'll be others with more rough detail added, and there'll be others which are smoother and more reflective, and which the light will bounce off in on that object. So what is PBR? And this means a physically based rendering material when it comes to Unreal, and you'll hear me say this"},{"start":"2:11","end":"2:46","startSec":131.8,"text":"off and on. So it's a unified lighting and shading system that we've developed for Unreal. It has a better approximation of light in materials and physical interaction, so it really tries to capture what's happening in the real world. It's intuitive and consistent, physically accurate, and uses real-world physical measurements. So PBR is a combination of the materials, the lighting, and the exposure, and they all come together to sell the idea that this object is living in this particular virtual world or space. Basically, we've made it so powerful that"},{"start":"2:46","end":"3:18","startSec":166.2,"text":"we're really trying to push that suspension of disbelief. So you really feel you're there, and I'm sure you've felt that at times when you play a video game, and you'll notice looking at the product of what Unreal brings to the table, and you're like, wow, this looks super hyper-realistic. And that's kind of what we want to go for. But we also compare things down and make things simplistic when needed. Well, that's it with this particular video. Here's a link to allow you to dive right in and get a little bit more understanding of how materials work. And in the next video, we're"},{"start":"3:18","end":"3:26","startSec":198.6,"text":"going to take a look at the primary nodes and textures and how to work with them in Unreal. Thanks again."}],"03_PrimaryNodesTextures":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Hi everyone, in this lesson we're going to look at some primary nodes and textures when it comes to working with materials in Unreal. So let's get started. So some of the primary nodes we're going to be looking at is the base color, metallic, specular, and roughness. Later on we'll talk about emissive and we'll talk about some of the others like ambient occlusion. But for the most part we're going to focus on these four initially. And you'll see in our little sample image here that we have some little numbers here."},{"start":"0:33","end":"1:03","startSec":33.1,"text":"These are our constants. These constants are punched into each one of these particular variable options inside of our material. Now the thing about these is these can be constants where they're just a singular number, they're just resting in here, something you set and just keep on going on with your material workflow, or they can be turned into a exposed as a scalar parameter or create a scalar parameter out to get go and plug it in. Now I'll show you how to do that because there's a quick way to do it where you just promote"},{"start":"1:03","end":"1:34","startSec":63.4,"text":"a parameter for each one of these. But this is the initial ones we'll be looking at within our material editor and then we're also going to be looking at some textures here in just a second. So let me point this out real quick in Unreal and we'll go back into the texture concepts. So in Unreal we're just going to click on this material, one pic on this guy, and I'm going to double click on it and bring him up. This is a thing called a material instance. This is just a child of the parent. We'll talk about that concept in just a bit. But I want to go ahead and go into the parent material here. I'm going to double click on it."},{"start":"1:34","end":"2:07","startSec":94.8,"text":"And you can see now we have these base materials active. You'll see we have a base, we have a metallic, we have a specular and we have a rough. But you'll also see that there's a number of variables so you can punch in those ahead of time if you wanted to. And you wouldn't even have to actually connect anything. Now what I meant by promoting, you can simply right click and say promote to parameter. This turns it into a scalar parameter. And when you do, this scalar parameter has a definite default, a slide minimum, and a slider maximum, as well as you can categorize it into a particular group."},{"start":"2:07","end":"2:39","startSec":127.1,"text":"And you'll see there's groups already have set up here. But I just wanted to point that out what that's all about. I'm going to disconnect this by simply clicking on the connection node and keeping my finger on the Alt key and that actually automatically disconnects. We're going to do a full walkthrough of the interface here in just a bit, but I wanted to show some things quickly in context. Let's go ahead and talk about texturing and we'll get back to these concepts later. So our base color, Elbido, is a flat color without specular or shading. We have a linear RGB vector three values of zero to one."},{"start":"2:39","end":"3:10","startSec":159.4,"text":"And we want to avoid pure black and pure white because they just don't show up in nature. Now then again, if you have a stylized piece you're working on, you may lean in that area because you just need to push those values. But for the most part, for realism, you're not going to you're kind of kind of shy away from that. We're there. We're trying really hard with science seems to be getting closer to pure black and pure white. But for the most part, you're not going to see that. Metallic here is a grayscale value that ranges from zero to one. Most common usage is an honor off state. So one or zero."},{"start":"3:10","end":"3:42","startSec":190.0,"text":"When I want one, it deals 100% specular reflection and zero is going to be zero going to be none and anything in between is going to be a variant of them. And you can see the full scale spectrum here. You can see it has hardly any and then we can see that it's fully metallic. Actually not, I should say. And in the middle, it's kind of in between. And then we have roughness grayscale value that ranges from zero to one also, but it ranges from smooth mirror like surface zero to a rougher matte surface, which is one. Unlike both metallic, you're encouraged to fine tune the roughness value between zero"},{"start":"3:42","end":"4:16","startSec":222.5,"text":"and one or use a texture to that effect. So using no texture keeps the material slightly lighter. Again, this depends on resolution. This depends how many times you're using input values versus an actual texture. This really just depends on what your overall scene is going to be. They can add up after a while if you decide to just use numbers. But for the most part, you're going to use roughness as a texture. Let me give you an example. If I had a really old piece of leather, I would have a high roughness value in there to demonstrate how the variance change between the light and the old dollar parts of that"},{"start":"4:16","end":"4:47","startSec":256.9,"text":"leather. And the same thing with rusty metal versus shiny metal, you can use roughness values for that. Using a range, obviously it's not a specific, but using a texture is going to be very specific to sell the concept. So specular grayscale value that ranges from zero to one. So good rule of thumb is to set the specular value to 0.5 and fine tune it. Now a lot of times what I'll do is I'll turn my specular all the way to zero. I'll turn it off and let my roughness push the values. The only time I'd fire up my specular, if I need to push a particular look, which we're"},{"start":"4:47","end":"5:20","startSec":287.6,"text":"going to do later, such as super shiny, over the top wetness, that's where you can actually bring in specular. But you've got to be careful because roughness and specular can influence each other and they can turn each other off or mute each other if you're not careful. So what I like to do just for a good rule of thumb, I turn specular to zero and I focus mostly on my rough. So guidelines. When you're building your texture, you want to try to use a power of two. The reason why you want to is that makes it so the Mipmaps are working accordingly."},{"start":"5:20","end":"5:50","startSec":320.6,"text":"And the Mipmaps are kind of your LOD, you can think of it that way, level of detail for your texture. And you can do 16 by 16 or you can even go as high as 8,000, 8K if you wanted to. And the textures don't have to be squares, you can have something like a 2048 by 1024 or a 2048 by 4096, you can definitely do that. And that's really up to you. But you got to keep that thing, you got to keep that in mind that power of two is what you want to hit, because then you can control that Mipmap if you need to edit it, like smooth it out, make it blurry."},{"start":"5:50","end":"6:23","startSec":351.0,"text":"And for some reason you have a repeating pattern and it isn't quite reading right and you're getting more patterns happening. So texture pyramid, let's look at speaking of Mipmaps. Let's talk about that for a second. So let's jump into Unreal. I'm going to go ahead and take a look at this Megascans material. Just click on the magnifying glass for the folder if you're wondering how we got here. And I'm going to double click on the salt mine here, wall, I'm going to double click on the texture for it. And I'll just pick on the albedo so you can get an idea of what we can do."},{"start":"6:23","end":"6:53","startSec":383.2,"text":"Now obviously I can roll mouse in and out with my wheel mouse here. You'll notice we have RGB channels that we can take a look at. This is super helpful if you're inheriting a texture you may not be familiar. And you know that they've painted in the channels you can see where the channels are at and what they do. This again just shows us all the different channels for that particular piece of texture. And over here you'll see that we have our Mipmap Gen settings. And you'll see it says texture group. Now the time that you would mess with these or edit these if you're getting some display"},{"start":"6:53","end":"7:26","startSec":413.4,"text":"issues that aren't quite working out. Case in point say you have a chain link fence or you have a roof that is a repeating pattern you might want to blur it or sharpen it. If you're getting a more a pattern or a very weird distortion happening, you can actually use these settings here to be able to change that if you need to. Now you'll notice there's an LOD bias. We're not going to really mess with this one, but as the bias is to the index of the top MIP level to use, that is the number of MIP levels to drop when cooking. So overall you have a zero by default and you kind of want to keep it there, but you"},{"start":"7:26","end":"7:59","startSec":446.3,"text":"do have the option to change that if you need to. And for some reason you need to customize it for a particular device such as a phone or iPad and those change whether they're high level iPads or lower level. You have the options to be able to customize all of this to be able to do so. You'll notice there's a texture group though. This is a world because this is a texture that's isn't particular to a set of UVs. This is something you put on the wall so it's considered world. And you can change this. You can say, hey, this goes to weapon. This goes to vehicle. And the reason why you do this is helps with compiling your shader."},{"start":"7:59","end":"8:30","startSec":479.6,"text":"And ultimately when you send things out the door to be packaged, you're actually telling Unreal what to look at first. So it doesn't have to pick walk through everything else. So you're kind of just isolating. So we got an advanced area here too. This allows you to control some of your downscaling if you needed to. And again, all of these are mainly to control whether you're going to, you know, maybe you need to adjust the compression. You know, maybe you need to never stream this. Maybe it doesn't need to stream. All these things are in here so that when you build out your texture and you need to"},{"start":"8:30","end":"9:01","startSec":510.6,"text":"edit things by default, all this should work just great. But there are times when you will need to change things such as compression. Now later on in another class that we have, I'll demonstrate and point out that there's an option to be able to change these if you need to say, hey, I need something to be really high end HDR, maybe have a series of images I want to project on a wall or on a geometry, you can actually choose that. And also you can say I want to clean it up a little bit so there's less blurring on some"},{"start":"9:01","end":"9:36","startSec":541.6,"text":"of my alpha areas. So you can choose any of these to be able to help out what you want to do for your particular texture. And these really do come in handy after a while. You notice there's more advanced here. We can control some of our maximum texture size for this. You're like, hey, I don't want this texture to go any higher than this. You can control kind of a compression setting if you need to. And that actually makes it so that you're resolutionally hits a particular amount. So there's a lot of options. Now I'm not going to go into about knowledge here because not all of these will necessarily"},{"start":"9:36","end":"10:08","startSec":576.3,"text":"be necessary, but they are available for you to explore more if you need to customize your texture and make sure everything is performant. For the most part, if you're keeping in mind what your hero objects are and your objects in the background and you're keeping those resolutions maintained and using virtual texturing, you may not even have to dive into these very much at all. But they are available because we want you to feel drunk with power. We want you to be able to customize things the way that you need for your project. So these are available here. You'll notice there's also a brightness and brightness curve, vibrance and saturation."},{"start":"10:08","end":"10:43","startSec":608.2,"text":"We have these set here. I recommend if you are going to mess with these. Now you do get an arrow that says, hey, send me back to default, but I would recommend you make a copy of your texture and then try to play with these. That way you can do a comparable between whether you like the new version or the old version. And that can be pretty helpful. And at the end, you'll see here there's file path compositing and a few other advanced things, but we're not going to get into those just yet, but they are available here for you again for full customization. Now we can use the import button in our scene if we want to, but we can also go in here"},{"start":"10:43","end":"11:15","startSec":643.5,"text":"and you can simply drag in a texture that you need. Let me demonstrate and unreal really quick because there's several ways to bring in what you want. Say in my scene, I need to bring in a emergency sign. I need to bring it in and I need to use it for my scene. Now I can do an import here. You'll see here I can look for it on fab if I need to also. There's a hot key for fab or hot button, I should say, or I can simply just open up the folder where that icon is at and just simply drag it into my scene."},{"start":"11:15","end":"11:48","startSec":675.7,"text":"So. And it import is done. You can see, hey, look, now I have a sign in here. Now I do need to change the unreal is nice and will order any kind of weird name. I just got this from the internet, but you do want to try to name this so that it's a little bit more catering to unreal's naming scheme. And I mean that by putting underscores where you can. And we can just put this as a T for texture in the very front. Cool."},{"start":"11:48","end":"12:08","startSec":708.3,"text":"So there's a couple ways that you can import things and those are two of them and makes your life a bit simpler. That's it with this lecture. Here's a link below to dive deeper into this particular topic. In the next video, we're going to take a look at material editor overall and we're going to look at parent materials and how to work with those workflows. Thanks again."}],"04_MaterialEditorsParentMaterial_Interface":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hi everyone, in this lesson we're going to go and take a look at the material editor and parent materials by starting out taking a look at the interface and how to organize your workflows as well as looking at the interface later on and we're going to look at material editors and how to work with instance materials and how that whole system lines up. So let's get started. So you'll see in the material editor overview window we have many things to look at here"},{"start":"0:30","end":"1:07","startSec":30.8,"text":"and this can get a little bit daunting so we're going to jump into Unreal and I'm going to walk you through some of these things. Once we do that we're going to talk a bit about organizing and then we'll make a have another video for you in which we'll look at making a parent material and then working with those nodes and then creating an instance material. Let's go and dive right into Unreal and take a peek. So let's go ahead and I'm going to pick on this particular material here. So in this material you'll see that we have an instance material. Now typically by default what happens is let's go ahead and go to the parent material first"},{"start":"1:07","end":"1:42","startSec":67.7,"text":"and let's double click on this instance material and you'll see with this instance material open, let me pull it over to off screen, you'll see that we have a parent material. Now you're probably wondering what is an instance material? It is a child of a parent material. It's inheriting all the aspects of the parent material but encapsulated in such a way we can quickly make changes without having to recompile the texture. And what I mean by that is I can go in here and change my albedo intensity, I can change"},{"start":"1:42","end":"2:12","startSec":102.2,"text":"my albedo color if I wish, like hitting that tick box on and I can change all different types of aspects if they're open as in the parameters are open to be able to be changed in the parent material and I can then do so in the instance material. And it gives you a quick and efficient way to change things the way that you need without having to recompile. So I'm quickly just changing the normal intensity here and you can see it change on the fly in"},{"start":"2:12","end":"2:44","startSec":132.9,"text":"3D and it's pretty cool, pretty nice to be able to work like this. So let me go and set these back to default. And let's go to the parent material. In the parent material, let's talk about what we're looking at here because there's a lot to unpack and I want you guys to understand all the tools at your disposal. Number one we can see that we have over here on the left is our viewer. Now this viewer gives us a quick preview of what our material is going to look like in"},{"start":"2:44","end":"3:14","startSec":164.0,"text":"our final output. If you ever want to change the lighting and you want to check the normal roughness or spec, you can keep your finger on the L key and you can left mouse click and get that to update just by moving your mouse around. You'll see here you can choose if you wanted to epic headquarters, which we have, which is fine, or just gray wireframe. It's up to you. We'll leave it at epic headquarters, but we can show things just like we would normally with unreal here in the viewer, such as what is it?"},{"start":"3:14","end":"3:46","startSec":194.6,"text":"Do we want lids? And we can look at our path tracing. You can look at these. Now some of these may take a little bit to refresh and you may not always say, you know, I can't quite see if this is a complicated material or not. You're going to mainly do that within your editor and you're going to be able to look at your optimization. Optimization view modes a bit more efficient because some things which may have shader complexity may not necessarily update and display here, but they definitely will inside of your editor. But these are ways you can check. So if for some reason you see that something isn't quite lined up, just keep that in mind."},{"start":"3:47","end":"4:21","startSec":227.0,"text":"That's something we are making it so it lines up a bit better. But there may be moments where you will see that, hey, that's not as complex as I thought it was, but the editor will tell you different. You'll notice we can also change your shape here, any shape that we want to preview that material in 3D space. You can also, if you select, say this, say the item that you want in your scene, let's choose this guy. With that selected, I'm going to go to that piece of geometry, hitting that magnifying"},{"start":"4:21","end":"4:57","startSec":261.9,"text":"glass with a folder, and it's now has that geometry selected in a content browser. I can now click on the Cinderbock block here and it will load that into my scene. And that's really helpful because now you can kind of get a one to one of the shape object that has that material. Down below, you'll see that we have a parameters area here that shows us some of the things we have loaded and some of the organization we have in place. We have our details here, which shows us how and what we use to choose how this material"},{"start":"4:57","end":"5:27","startSec":297.1,"text":"is going to be digested with an Unreal. Now you'll notice our blend mode is opaque, shading model is default, but you can change these based on your needs. Now we dive into this later in more advanced material classes, but you can do everything from a deferred decal if you just want like a sticker effect on a piece of geometry. There's a light function to project light, which we'll go over later in the class. Volumes we'll talk about later in post process volumes, which allow you to change your overall visual look using a loading the material in a post process volume."},{"start":"5:27","end":"5:59","startSec":327.7,"text":"You'll notice there's also blend modes. We can choose mast for alpha, which we'll talk about later on to translucency, additive, modulate in law. All of these you can change based on what you want. Like, hey, I want my alpha to look a certain way. I want to look masked. So we have like maybe some torn cloth, which we'll do later on. You can choose these things depending on the look and the visual representation you need. And there's also shader model. This allows us to also choose such things as cloth, hair, eyes, as well as two sided"},{"start":"5:59","end":"6:29","startSec":359.7,"text":"foliage in here and subsurface objects, which we'll also talk about later on. So this gives us a lot of things to choose from. Now, if you're noticing your shadows aren't correct when you move your light around, you can also turn on, especially if it's a thin piece of geometry, two sided geometry so that it is calculated correctly within the shader itself. You can also use a thing called use material attributes, which we'll talk about later. That allows you to encapsulate the final output here and redirect it so that you can"},{"start":"6:29","end":"7:00","startSec":389.9,"text":"now make a thing called make attributes, which we'll talk about again later on. And make attributes, it pretty much just substitutes this guy and turning it on that tick box causes it to encapsulate. You'll see that collapsing on itself and then it can redirect things as needed. We'll turn that back on and get rid of this. So there's a lot to choose from here. I'm not going to get too much into buttonology because some of these are content heavy as in context, I should say, as in having to do with particular classes, which we'll cover it."},{"start":"7:00","end":"7:30","startSec":420.6,"text":"But I wanted to point that out. You have a lot to choose from here. So let's go ahead and talk a bit about the interface. So here we have our save button as well as finding that material in the content browser. You say quickly clicked on that, took us there. We can apply any changes if you want to test them out first. I typically hit apply before I hit save because I may not like them or I may suspect that there might be some errors if I'm doing something a little bit complex and experimenting. You can also search here. You can search a particular node."},{"start":"7:30","end":"8:00","startSec":450.9,"text":"You say, Hey, I want to look for the albedo. I can choose that. Make sure I spell it correctly. It'll show me where it's at. And if I double click, it'll take me there. Pretty nice to be able to do that, especially if you have a complicated material you're having to deal with. Now I can turn off the results here. Stats will let me know how my shader is being processed. If there's any, you know, if there's any heavy tasks I'm noticing, maybe I put a lot of custom nodes in here. This will show us some areas of instruction and also give you the errors if they occur."},{"start":"8:01","end":"8:31","startSec":481.1,"text":"I'm going to close that too. You'll notice there's a thing on the right hand here called palette and the older versions of Unreal, this would be on by default. You can turn that on, but now we kind of have it. So it's like a shelf, which is kind of nice. And you can go in here and look up anything that you need node wise. And we have a lot of defaults you can choose from, especially if you're jumping into the unknown and experimenting, you can play with these and research them some more. They're pretty great. I do warn you, it's kind of addictive working with materials. It's one of my favorite things to work with."},{"start":"8:32","end":"9:03","startSec":512.1,"text":"And if you watch some of my other videos, I get pretty deep into them. It's a blast. Now you can go home if you're too far away from the final execution string here of our nodes, you'll take you right there. Right clicking on the home button. There's also a hierarchy here. So you can actually take a look at some of these. It'll take you to that concrete floor or another particular thing that's actually connected to this parent. It's just showing us everything connected to this parent material. It just opened it up quickly for us."},{"start":"9:03","end":"9:32","startSec":543.9,"text":"We have a live update. So we have preview material on. We want to have that on. But if you have real time nodes and other things that maybe some emotion in movement, you want to test it out, you can have that on. But by default, I typically just leave this on and should be fine. You can clean up your graph. And what that means is if I have any nodes floating around such as these guys, I can say, Hey, man, clean up my graph, my graph here, and I'll clean it up and it'll remove anything that doesn't have a connection. I'm going to hit control Z. I left those in there. So if you wanted to play around, you can."},{"start":"9:34","end":"10:06","startSec":574.5,"text":"You'll notice here we have preview state, hide unrelated stats, as well as platform. So you can actually choose what you're looking at your platform stats here. And you can choose where you're going to be sending things out the door. Is it Xbox is an iPad? There's a lot of analyzing that can occur here. And that's just based on your needs. Well, that's it with this one. It gives you a little preview of the interface. We're going to talk a little bit more of it in the next video."},{"start":"10:06","end":"10:12","startSec":606.2,"text":"And we're also going to talk about how to organize things when it comes to working within the grid. Thanks again."}],"05_MaterialEditorsParentMaterial_Organizing":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Hi everyone, in this lesson we're going to go and take a look at ways to organize your materials in the material graph and how to keep things nice and clean as well as later we're going to look at creating an apparent material and an instance material. So let's go and dive in and get started. One way that you can get organized when working with your materials and how to get things in the right spot to prevent over trafficking your noodles basically your strings crossing each other and being all over the place."},{"start":"0:32","end":"1:03","startSec":32.0,"text":"Don't cross the streams as they say in Ghostbusters. You can use add named reroute declaration nodes as well as add a reroute node. And let me show you how to do that as well as look at some comments that you can actually put into your scene as you're working with your material nodes. So in real say I have this group of nodes that I've built and we're going to build these later on in another class. We're primarily going to be focusing on these when we do build them out later."},{"start":"1:03","end":"1:43","startSec":63.0,"text":"But I'm going to pick on these guys for a second because they're a group of nodes that have an ends to a means or I should say a particular node output that we want to convey. Now instead of pulling all the strings to all these different areas we can actually make it go to one particular node and that one particular node can then rest and sit in front of each one of these. And it's basically naming and rerouting them so you don't have a lot of wires everywhere. You can easily do so by right clicking and in here you can type in named reroute declaration node and we can say and call this one UVs."},{"start":"1:44","end":"2:15","startSec":104.0,"text":"This UV node can now sit here and I can punch everything into here and then from here I can actually call up the one we made it'll show it right here with Unreal. And I'm just simply left clicking to get this or right clicking I should say to get this to come up and then we're going to click on the name to reroute and click on UVs. And then now if I wanted to I can disconnect this line and go directly into here like so and it does pretty much the same thing. So that's super helpful and convenient."},{"start":"2:15","end":"2:50","startSec":135.0,"text":"You can also say I'm going to just copy these for a second and do control D. Get them in place and I can also collapse nodes whenever I want to. So I can right click and say collapse these nodes and then you can actually name them whatever you need. You can say UV set control and that also is very helpful. Now just be aware when you do collapse your nodes and you decide you want to send this material to somewhere else like another project."},{"start":"2:50","end":"3:20","startSec":170.0,"text":"If you right click and you say hey man I want to go to asset actions and migrate. These may not stay together. They may either be unrecognized or they will just unfold themselves and go back to the original state. So just be aware that sometimes I get that happening. It does happen a good amount of time when you go into a new version of Unreal. So just triple check your workflow. I think it's less of a problem now but previous versions it kind of was a little bit of an issue."},{"start":"3:20","end":"3:54","startSec":200.0,"text":"So we have a way to collapse it. We can do a name reroute. We can also reroute in general like say I wanted to connect this particular node to another maybe emissive. Maybe I like my normal route. There's no way out. In God's green earth there's no way I would do this but if I wanted to I can double click on any string. I can move it if my move icon shows up as I float over. And what this does is it allows me to run another reroute node if I wanted to."},{"start":"3:54","end":"4:28","startSec":234.0,"text":"So if I wanted to put this into my emissive it would look horrible. I can and then you have a glowing normal emissive. But this allows me to do a simple reroute. Not a named reroute but a simple one. And it is a pretty darn good job of being able to do that. I'm going to undo that for a second. You can also group your materials which we'll get into later. That allows me to select a particular material. And I can go in here and say hey I'm going to choose a group that I wanted to have. You can type in here under groups in any exposed texture here."},{"start":"4:28","end":"5:01","startSec":268.0,"text":"We can actually have that. Let me show you what I mean. So I'm going to hit the T key here for a second and left click. This is the hot key to be able to give me my texture. If I wanted a UV texture to show up or UV node I should say it for control. That's the U key and you left click also. There's also a constant you can pull up. I keep my finger on the one key. That's a one constant. That's a two constant. And then this is a three. Simply by me hitting one, two, three and left click. You keep my finger down on those particular numbers."},{"start":"5:01","end":"5:33","startSec":301.0,"text":"Now I did this for the texture sample here. In this texture sample we'll just get something simple. We'll just pull up the gray. Now by himself you'll notice there is no area to group. But if we go to the other one, this is called a parameter that's been exposed here, which allows me to not only change its name but also group it. So to be able to do that you click on any texture, right click, and you say convert to a parameter. And then we can give it a name. We'll call this gray texture."},{"start":"5:33","end":"6:04","startSec":333.0,"text":"So there's now gray texture allows me to go in here and if I wanted to type in or give it no group, but type in, I can type in any group right here and it will now create a new group for this particular texture. Pretty cool. Now I'm going to go through as we build our material, our parent material, and our instance material. I'll walk you through some of the hotkeys to build some of these out just as a reminder. And so you can get a little more familiar with how to work and build things in Unreal. And that's about it with this video."}],"06_MaterialEditorsParentMaterial_Creation":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hi everyone, in this lesson we're going to look at some primary hotkeys working with the Material Editor. From there we're going to go ahead and look at some different ways you can organize even more using Unreal. And then we're going to create a parent material and some instance materials and open up some parameters for editing. So let's get started. Here are some primary hotkeys we're going to be mainly working with in this particular lesson as well as other lessons when it comes to talking about materials."},{"start":"0:30","end":"1:00","startSec":30.4,"text":"Now you heard me talk about how the number one key gives us a variable constant. We have a number two gives us another variable constant. This gives us color information on this particular one. And three and four as well as a power node. There's a reflection vector as well as a texture sample which you saw me also hit the T key to get a texture sample to come up. The U key for texture coordinates. We have a B for Bump Offset node which will go over in other classes. We have a Normalize node and M for Multiply which you'll see me use quite often in this"},{"start":"1:00","end":"1:35","startSec":60.7,"text":"series of classes. And we have a Duplicate. We have a L for the LURP which we'll talk in more detail about how the LURP works later on in other classes and a little bit in this one. And then we also have the Paner as well as the Scalar parameter which is basically a exposed parameter of a simple variable constant. The one key. Alright, let's go and jump into Unreal and I'm going to show you some other things you can do to organize your scene as well as let's go ahead and make a parent material and then"},{"start":"1:35","end":"2:07","startSec":95.3,"text":"convert that parent material or I should say create an instance material from it. Now let's go ahead and jump into Unreal here and take a look at creating our own parent material. This is the one we're going to reference. Now you'll see in our content drawer we have a series of ones that you can also look at too underneath our intro to materials. You'll see there's a step one, step two, step three and they just give you the basic structure or you can simply just open up the one that I'm working with in particular this one and"},{"start":"2:07","end":"2:38","startSec":127.2,"text":"you can just double click on this material and pull it up and you can follow along as I work in the scene. We're going to go ahead and build them out. I'm going to explain how these systems work as well as show you how to create these things, comment boxes and to be able to help you organize things a bit better. First up we want to go in here and build our own material. So I'm going to go to the content drawer. You'll see in our class folder we have a folder called in class mat. In here we can simply just go ahead and make a new material."},{"start":"2:38","end":"3:09","startSec":158.0,"text":"So I'm going to go and right click in here as I go and right click I'm going to go up to material. There's also another section which allows you to get to the more advanced options for materials which we get into in other classes. But for now we're just going to go straight up here right where the material rests and I'm going to click on that. I'm going to say M underscore which is a good habit to get into for your prefects and I'm going to just call this sample parent and you can call it whatever it is."},{"start":"3:09","end":"3:41","startSec":189.1,"text":"Just don't call them late for dinner. I know really bad joke. So I'm going to go ahead and double click on this guy and we're going to move this over into my scene and I should say into the view so you can see it. So let's go ahead and open this up. Now you can have any texture you want when you're creating your parent material because you want to expose those textures and swap them out later on. But for the sample purposes and so that you can follow along we're going to use the same"},{"start":"3:41","end":"4:15","startSec":221.4,"text":"textures that I am working with so we're going to be using the ones from the wet stone underneath the mega scans. So if we go to our content drawer you're going to see mega scans and you're going to see underneath their surfaces and towards the bottom and I'll pulse my cursor you're going to see wet stone ground and this is the one we're primarily going to work with. So I'm going to go ahead and grab the albedo. You don't need the AO for this example. We'll grab the over here the normal and the rough and I think that's pretty much all we"},{"start":"4:15","end":"4:47","startSec":255.6,"text":"need right now. And if you wanted to we could even do use the AO as metallic and for this example we'll do that. We'll we'll grab the AO and we'll use it as a cheap metallic. This obviously is a metallic surface but we're going to I'm going to show you how to get that set up properly and how that works in Unreal. So we'll keep that for now. Let me go and drag them into our scene and you can simply do this whenever you have a texture. So I can pull the textures in from my content drawer. Whenever you import a texture you can right click and import a texture."},{"start":"4:47","end":"5:18","startSec":287.9,"text":"You can even grab any texture which I showed before and you can grab it from say your library. I'll grab these pictures here and say I want to grab you know like we did before you can grab this and grab an illustration. Pull it in here. You can also do that too. So just a quick reminder on that. There's multiple ways to be able to get them into play. So now let's go ahead and go in here and build out what we need. But before we get too far into that let me talk to you about organization."},{"start":"5:18","end":"5:51","startSec":318.5,"text":"Now whenever you're building out your scenes you want to be able to organize things and put comments and descriptions where needed. One way to be able to do that is I can go in here and I'm going to move this normal over here. I'm going to highlight him and hit the C key. And if I want to I can call this normal and typically you would but I can change the color of this comment box to whatever color I need. And this particular case will choose blue seems appropriate for normal and we'll hit OK. And then now whatever I have in this box is going to come along for the ride."},{"start":"5:51","end":"6:32","startSec":351.5,"text":"If I move this box over here next to this texture here is also going to come along for the ride but is non destructive so I can remove anything at any time and I can also delete it if I wanted to or change its name. Pretty cool pretty convenient to be able to work with that. You can also continually add some more description information here with there's a little dot dot that shows up at the top and you can say hey Tom. Save my normal alone and my sandwich can't spell sandwich sandwich a sandwich a sandwich"},{"start":"6:32","end":"7:04","startSec":392.6,"text":"my burger alone. So you can put all sorts of notes in there and you'll see it show up in the details here underneath description. You can also pin that note so that it actually does not lose or scale down to become a very hard to read. You can see it from a distance. It's actually pretty cool to be able to do this and it's just another added way to keep things organized. So let me actually attach a few things in here in unreal and build some stuff out so I can"},{"start":"7:04","end":"7:38","startSec":424.4,"text":"talk a little bit about the string organization options that you have. First up we have in our texture here let's actually expose this. We want to expose this so that when we make a child it is actually it can be seen and edited after the fact and you want to do that going to convert to parameter. I'm going to call this one the albedo and again these textures can be anything because in the parent if you obviously if your UVs are matching or you know its destination in the parent if we have them exposed later on in the instance we can swap them out to"},{"start":"7:38","end":"8:12","startSec":458.5,"text":"whatever texture we need for that particular scenario of workflow. I'm going to keep my finger on the M key. I'm going to hit multiply. Now multiply and add I'm going to hit A key and do add each one of these kind of acts like a Photoshop filter. They work under the same type of principle where you're adding or you're multiplying you can do this through an inconstant if you want to number wise or you can also do it via image. It allows you to multiply the textures between each other and you also have the add so kind of layers them on each other also."},{"start":"8:12","end":"8:44","startSec":492.7,"text":"And we'll talk a little bit about more about that later in the next class where the difference between them specifically when it comes to UV layout. So I'm going to go ahead and hit the four key here. Those could be the three key to this is basically showing you again this is a for constant vector. You'll see constant for vector there. This gives us color information so we can start this out as white that works best with multiply in this particular case."},{"start":"8:44","end":"9:15","startSec":524.1,"text":"And it gives us a nice neutral place to be at we want to convert this to parameters so it actually can be edited after the fact. So let's convert that to a parameter and we'll call this albedo tint. And we're going to pull that execution string to the beach. And I'm going to pull this albedo to the channel here. And I'm going to grab this multiply and pull that into the base color."},{"start":"9:15","end":"9:47","startSec":555.4,"text":"Now you have some even further ways to keep things organized. If I select these group of nodes, I can right click in here and you'll see there's an alignment area underneath the alignment area can align to the top if I wanted to now them kind of stack on top of each other. Or you can have it so you can keep things a little more straight. So if I went in here, I can do alignment and we'll say, Hey, you know what, I want to let's align to the left. Let's center this. Let's straighten connections. You have all options to be able to do that."},{"start":"9:47","end":"10:25","startSec":587.0,"text":"Now we don't really have these guys set up in an extreme of a setup here. So you'll notice the connections aren't really straightening too much here. And you can also, like we said before, do reroute nodes. If you need them, move things around. This allows you to go in here and you can do whatever you want when it comes to building your stuff out. Now I don't use them too often. Typically I'll use a reroute and I just put things in the right area. I'll use a name to reroute node, which we talked about, which you can go in here and do so."},{"start":"10:25","end":"10:56","startSec":625.6,"text":"And that keeps also things a little bit cleaner as well as collapsing, which we talked about. But I just wanted to point that out that those options are there to be able to do so. Well, it looks like I double clicked. So feel free to actually play with those if you need them. They can be pretty helpful. Let's go and build out the rest of our nodes here. Next up we have metal. Now again, we're not working with metal, but we're going to add it in here so you can just see me build the system out. Remember, metal works out as zero to one."},{"start":"10:56","end":"11:27","startSec":656.4,"text":"So if I wanted to, I could simply just plug in Metallic in here. I could also go in here, right click and say, hey, promote the variable and just have my metal information driven by numbers. But specifically when you're working with textures and you want a little more visual fidelity, high quality, you want to try to plug in metal if you have it in your texture wise, and then we can create a system to be able to control how much that's coming in. But again, you can promote variable to any of these. So I'm going to go here under texture sample."},{"start":"11:27","end":"11:58","startSec":687.2,"text":"I'm going to go ahead and create, hit my finger, the M key or multiply that's M key left click. And I'm going to keep my finger the S key left click. And this is a constant, a constant with an exposed parameter that makes it so that I can control values. So I'm going to call this metal ness intensity. There we go. Sweet. And I'm going to set this to one so it's on. Now you'll notice off to the right or the left here, we have a default value control,"},{"start":"11:58","end":"12:28","startSec":718.5,"text":"we have a slide minimum and slide max. So our slide max can still be set to one. And typically with metal, it's going to be that because it's a zero one scenario. We can choose the grouping here. So let's group this so you can at least get an example of it. I'm not going to necessarily group all of them going forward. But for the most part, you're going to see it here in this particular example. So we're going to say metal group as I say group by type group metal. And we're going to punch this into the B channel."},{"start":"12:28","end":"13:00","startSec":748.8,"text":"And then we're going to punch this RGB execution string to a channel. And we're going to drag this over to metallic. Awesome. Great work so far. You've built your first connection note, or at least I should say the second. Now let's go ahead and slap the others together and I'm going to explain some of the workflows for them. So the next thing we want is roughness. Let me pull up this guy here. And again, we want to convert to parameter. We're going to call this rough. We're going to convert this to parameter. We're called this metal. I'm going to right clicking convert to parameter metal."},{"start":"13:00","end":"13:34","startSec":780.2,"text":"And again, we're doing this so that they're exposed. And in the children, we can change things as we need. Now the nice thing about working with roughness and it doesn't quite work the same way with metal. I'm not sure why does it. It's kind of interesting and a little happy accident found a while back. I can use a multiply for it and I can use a scalar parameter for rough intensity. And that's the S key if you're not remembering."},{"start":"13:34","end":"14:04","startSec":814.5,"text":"And I can drag this rough intensity inside of the B channel. I'll set this to five with a maximum of five. And you'll say, well, Sean, how come it's one here, but why is it five here? Well, the cool thing about the rough here is you can use this multiply to your advantage. It will actually go in here and make it so that you can have a higher value versus the metal one, which is strictly kind of stuck between one zero. Now typically this is also one zero, but in this particular case, when it comes to the"},{"start":"14:04","end":"14:36","startSec":844.7,"text":"rough, having this multiply gives us a little bit of a luxury. It's kind of a sneaky trick. So we go to roughness here. And notice we got a roughness values in here. Oh, looks kind of nice, slightly shiny in some areas. Pretty cool. Now, finally, we're going to go in here and build out our normal map. Now the normal map in Unreal, there's a couple ways you can handle this. And you'll see some of our sample content have the same look and feel. Sometimes when you're working with a normal map, you may decide that you want to invert"},{"start":"14:36","end":"15:12","startSec":876.3,"text":"it. So to be able to have that option, you want to actually work with a thing called a flatten normal. This will make it so the normal is at an even plane field and at a zero and a proper zero area. Unfortunately, though, the default state of this, if we left it here will be slightly off. So it needs a little bit of help the way that our flat numbers made at this time. In other words, it shuffles from one side to the next and pushes a little bit too much into the negative in the very beginning. And what we have to do for a flatness is go in here and type in a minus one."},{"start":"15:12","end":"15:43","startSec":912.9,"text":"And I can pull this minus one into my flatness here. And then I can make a scalar parameter just by pulling the string and we'll just type in scalar. And the scalar parameter is going to be our normal control. And I'm going to set this to a value of five, we'll do a max of five, and then we'll also make a normal group."},{"start":"15:43","end":"16:14","startSec":943.9,"text":"And rough, we can also make a rough group on him with him to is exposed. I'll do rough. And then now we grab that flatness normal and put it in here. Now if you didn't want to do that, say you never wanted to invert your normal, we'll have that option. You can simply just do I'm going to duplicate this normal. Let's actually expose them real quick, convert parameter normal. We can simply just go in here and do control D for a second with it selected."},{"start":"16:14","end":"16:44","startSec":974.1,"text":"It'll appear where my cursor is at. I can simply just hit the M key and have a normal control do control. You just can be super lazy here. And you can have something like this if you want it and simply just plug that into the normal if you want it to. I'll actually like having the option to be able to invert my normal if I wanted to. But this is the more simplistic way to do it. This is the way you'll see on many of our example content, giving you the option to be able to invert things if you needed."},{"start":"16:44","end":"17:14","startSec":1004.2,"text":"So once we've made this, we're now going to go ahead and we're going to go to where it lives. Let's hit apply. Make sure everything updates. And we're going to right click on it and go to create an instance material. This instance material here. Now again, you can leave INST at the suffix or put an MI for material instance. It's up to you. But Unreal at the bottom will let you know what it is too."},{"start":"17:14","end":"17:45","startSec":1034.2,"text":"It's better to keep things organized the way that works for your workflow. I can now double click on this material instance. And you now see the exposed parameters. Now you'll notice I don't have some of these grouped. And if they not catching the first time, I did hit apply. So if you do go to the rough, you only will see a rough, but for some reason it didn't update, just hit save. And it should update accordingly. And if it doesn't, just close it out. Mind it, mind it, no, I don't want to."},{"start":"17:45","end":"18:17","startSec":1065.7,"text":"But we also want to make sure that these guys also have a parameter. So let's go ahead and do rough. That's mainly what's sticking out here awkwardly. And metal has a group. Let's put this in the metal group. There we go. Elbido doesn't have a group. Let's give it a group. And it's always good to group things. Get in that have as much as possible. There we go. And normal. He doesn't have a group."},{"start":"18:17","end":"18:48","startSec":1097.4,"text":"Let's put him in a group. There we go. And we're good. Now these guys don't have to be grouped. You can leave them alone because they don't have that option. So Unreal understands that these are part of the workflow and knows that these primaries are the main concern. So now when I hit save, now when I go to the instance material, you're going to see these populate accordingly. There we go. There's the Elbido. There's the metal. There's the normal. And again, all these can be updated on the fly."},{"start":"18:48","end":"19:13","startSec":1128.2,"text":"And what I mean by that is like we can lower the normal. We can increase the normal. And it doesn't have to recompile a shader. We can control the tint if you wanted to. We can do this all on the fly. Kind of like what I demonstrated to you earlier. Well that's it with this video. In the next video, we're going to dive a little bit deeper and play with some animated materials and processes when working with the material editor. Thanks again."}],"07_AnimMaterials_55":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hi everyone, in this video we're going to go ahead and animate a material in Unreal. I'll show you how to connect all the nodes and get everything set up so we can have a nice believable animation in our scene. So let's get started. So in this video we're probably going to break this up in a couple of videos here because it is a few things you need to consider and there's a lot of options I want to be able to point out so you can actually see the power and the ability you have to create what you need in Unreal."},{"start":"0:30","end":"1:02","startSec":30.4,"text":"So we do have a sample material so anytime you are following along and you're like, hey I want to see where Sean connected that and how did he get that to work, you can simply go to this material here or this one that they're both the same and select them in our Details panel and click on the magnifying glass to the folder. This will take you directly to the sample material. See it says it is under the folder called step 5. So you can go ahead and double click on that and you can get an idea and pull up the material as I'm working and you'll be able to follow along and you'll see that I have active notes"},{"start":"1:02","end":"1:35","startSec":62.3,"text":"in here. So let's go ahead and build a similar material. We're going to be using kind of the same textures and that's fine within our scene. So I'm going to go ahead to our content folder and I'm going to go ahead and go into our class materials and we're going to make a new material. So I'm going to go ahead and create material here. I'm going to go and click on this and in material we will call this one M underscore animate in CLL."},{"start":"1:35","end":"2:06","startSec":95.2,"text":"There we go. So we're going to go ahead and animate this guy and let's go and double click on that material. Let's drag him into our view here so we can see the whole thing and we want to go ahead and grab the textures that we need. Now some of the textures we're going to need, it can be any texture that you choose. It doesn't have to be the ones that I have, but you'll notice in the Megascans we have several different surfaces we can choose from. If we open up surfaces you'll see we have wet stone ground. You can use that one if you want to. There's river stone and that's pretty much the one we're going to be focusing on is the"},{"start":"2:06","end":"2:37","startSec":126.6,"text":"river stone. So I'm going to go ahead and grab a few things here. I'm going to grab my albedo. I'm going to grab my AO just in case you want to punch some things into the AO as well as maybe even mess with some metallic because this thing really doesn't have metallic, but we could use the AO for that slot in this particular case just to fake a few things. So I'm going to go ahead and for that note I'm also grab the cavity because maybe I want to use that one instead and I could even use this place which is a little more dramatic"},{"start":"2:37","end":"3:09","startSec":157.3,"text":"than the two. I'm going to go ahead and grab the normal and I'm going to grab the roughness and I'll also grab the specular because I might want to make this a little more highlighted to make it a little more wet and we're going to go ahead and pull those into our scene. Now you'll see there's a few others. You'll see like there's gloss which can be used for spec. You'll see that there's bump and this also could be used in different a variety of things depending on how strong it is. You could even have that as your AO. Say you forgot to bake out the AO, you could use bump."},{"start":"3:09","end":"3:43","startSec":189.6,"text":"It's really up to you how you produce your textures and how what your DCC is for your texture development like maybe you're using maybe Substance 3D. We do have a plugin for that too so you can go into the plugins and pull and turn on our Substance 3D but you got to make sure you go to their website to make sure you're getting the latest one to be able to get that to work and make sure you're installed into Unreal. Just want to give that quick call out to that because we do have tools to be able to accommodate because not everything's built exactly the same. When it comes to Megascans you can choose different things that you want like you could load your"},{"start":"3:43","end":"4:14","startSec":223.3,"text":"cavity map and you can combine it with your AO to exaggerate some highlights and etc. So you can set this up anyway that you see fit. Alright so now that we have that stuff set up here let's go ahead and get our initial texture set up the way that we want. So we're not going to do anything fancy with the Elbido so I'm simply just going to grab this and punch it right into the base color. We just need this guy present and let's set this to a cube. Now you'll notice my interface here in the previous videos that we had we were working"},{"start":"4:14","end":"4:46","startSec":254.7,"text":"in 5.5 and this one I just kind of shifted to 5.6 just for the ending part so just so you can get familiar to some of the icons I'm referring to. In 5.5 you'll find out that the icons were down below when it came to your view are a little 3D interactive viewer in here but you'll find them up here now when it comes to 5.6. And that's okay they're just small minor changes but I just want to point that out if you are following along and you'll see that this hey wait a minute this isn't 5.5 well I'm kind of doing this one this section in 5.6."},{"start":"4:46","end":"5:17","startSec":286.8,"text":"Alright so we have this texture here let's go ahead and bring in the appropriate texture that we can work with and in this case we can use gloss. Now if you didn't grab gloss initially you'll see that we have cavity and you'll see that we have roughness and you'll see that we have specular. You can simply just go down here and it doesn't you don't have to have the same one to one that I have if you don't for this particular slot where we're messing with metallic so if you wanted to use gloss you can you don't have to you can use any one of these like"},{"start":"5:17","end":"5:49","startSec":317.8,"text":"maybe even displacement so I'm going to pull up gloss and pull them in here and again the thing you have to keep in mind if we are putting metallic on a non-metallic surface just be aware that you can exaggerate things in in an area that you may like but it also may push and pull things in an area you may not like and what I mean by that is you may get too too much reflectivity so you can dumb that down and adjust your values accordingly. Alright so let's go in here and plug this in so we're going to move albedo up a little"},{"start":"5:49","end":"6:24","startSec":349.8,"text":"bit higher we're going to move this one over and again you can I'm not for this particular lesson going to convert to parameter because you get the idea how to do that but you can do that if you and I do recommend if you want to make changes on the fly let's go and keep my finger on the M key in the child instance and let's go ahead and keep my finger on the S key and left click so I'm I'm I'm again keeping my finger on that key and left clicking to pull those up and I called up a scalar parameter which you saw me do earlier so let's get the scalar parameter and set this to metal amount and again you don't have to do metal but I'm"},{"start":"6:24","end":"6:59","startSec":384.3,"text":"going to show you the values of width on without and that can complement things depending on the surface and the color values and the dark and light on an object some things may not eat it some things may you may need to push that that little reflectivity a little bit farther so I'm going to go ahead and grab this texture sample and I'm going to pull that string into the a channel I'm going to grab that metal value and I keep it at zero for now I'm going to pull that into the B channel now what we want to do is make some movement going on here so we're going to have to grab another texture now this can be any type of"},{"start":"6:59","end":"7:36","startSec":419.4,"text":"raindrop raindrops that you've chosen that you've made maybe you've edited on your own it's up to you but I'm going to show you where you can get ours because we do have them available you'll see underneath our folder underneath step five we have a folder called raindrops so in raindrops we're going to go ahead and grab a few things for one we're going to grab this particular one if we wanted to we could even grab this darker one if you wanted to it's really up to you but I found this one that's a little more grayed out kind of a smoother kind of drop effect here this one works a little bit better than this one and"},{"start":"7:36","end":"8:07","startSec":456.3,"text":"it makes it less harsh between the contrasting and that's one thing you also have to be careful and keep in mind if you're combining textures and stacking them on top of each other and then plugging them into like a stronger value which maybe didn't exist in a rock such as metal you might want to consider smoothing some of the values out and maybe using lighter contrasting black and white textures so that's what I'm doing here so I'm going to go and create an ad keep my finger the a key left click and I'm going to pull this string from"},{"start":"8:07","end":"8:37","startSec":487.2,"text":"this particular raindrop into the B channel and I'm going to go ahead and grab the multiply and put it into the A channel and we're going to have to need some movement here so let's go ahead and create a panor so if you're not familiar with the panor node the panor node allows us to be able to actually make motion from up down and even sideways if we punch in the correct X and Y type of coordinates so I keep my finger the peakie left click there we go we got panor now if I again if I wanted to move a little bit more to the side I would mess with both these values but I really just want to be messing with the"},{"start":"8:37","end":"9:12","startSec":517.6,"text":"Y channel value and in this particular case you can choose the speed I'm going to choose a negative one there you go and I'm going to go ahead and punch that into my raindrops if you want you can preview by right clicking and we can start preview mode to see what it's going to look like that's a pretty good pace and I have it so that it's tiling so we can go ahead and stop the preview and then we can go and punch that right into the metallic and see what we get now we see this is what I like about it using it if I'm using a metallic"},{"start":"9:13","end":"9:44","startSec":553.1,"text":"here that smooth makes it so it's not so harsh on the stone but you'll see movement over the stone of the dark and light and you can change that if you wanted to if I wanted to maybe I want the gray to be on the drops versus the white being on the surface and you got to be careful with that because I want the white to be more reflective and you can see it's slightly reflective in here not a whole lot because I don't have other values you see a little bit better on the darker side but it's really up to you and this is what"},{"start":"9:44","end":"10:15","startSec":584.8,"text":"you could do you could do like a one minus if you wanted to you can do one minus and then we can flip that value now we get get into the one minus note a little bit more in the other class after this but this shows you what you could do if you wanted to flip it a little bit more and you can see that you can have it so actually that's actually not too bad it gives you more of a higher reflective maybe type of look to it there but again it's trying to use the texture that we have set in and it's really up to you what"},{"start":"10:15","end":"10:43","startSec":615.2,"text":"you want to produce in your scene and that's actually not too shabby I think I kind of like that alright so we'll leave that in there for now but we do get into that a little bit more use of that into the other class so this is our initial setup what we want to do in the next video is we're going to go ahead and elaborate on this a little bit farther and we're going to push things a little bit more so we can get kind of the water effect that we want to need thanks again"}],"08_AnimMaterials2_55":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Hi everyone, in this video we're going to go ahead and continue what we were doing with animating materials and jump in and show some of the options in which we can edit things and get the look that we need. So let's get started. So jumping back into Unreal, we can see that we have our nodes set up here like we did before. I'm going to shuffle some of these things down a little bit. We're going to kind of repeat what we did before and get things in the order that we need. This is all up to you visually how you want things to look."},{"start":"0:32","end":"1:03","startSec":32.8,"text":"We can combine looks, we can add things to make things a little bit more exaggerated. And what I mean by that is maybe highlight the water a little bit more by pushing some values and we can do a little bit of that when it comes to our loading things in to our specular and our rough, which we're going to do here. So first up, let's go and take a look at some of the options and some of the things we can do for the specular slot. Now we've put stuff in the middle slot and you don't necessarily have to do this for this particular material."},{"start":"1:03","end":"1:36","startSec":63.1,"text":"But if you want to exaggerate things, you can add that. It just depends how, what kind of values you want from the rock. Now what I can do right now is maybe turn this off, disconnect this temporarily. And we're going to go ahead and bring in and just move this off to the side. So we'll do a comparable later. And let's go ahead and bring in the other textures that we need for the specular. Now for the specular, what we're using is that smooth texture again. So let's go ahead and I'm going to select it. I'm going to minimize this just a little bit here, pull this in so we have a little more"},{"start":"1:36","end":"2:07","startSec":96.0,"text":"real estate. I'm going to close my stats little window there and that actually tells me if things are not connecting correctly. So I grabbed my smooth and do control D. It'll actually duplicate it right where my cursor is at, which we talked about before. And we're going to go ahead and start connecting a few more things. So let's go ahead and go in here and add the raindrops, but we're going to get the raindrops that are a little bit more exaggerated dark and light."},{"start":"2:07","end":"2:39","startSec":127.4,"text":"So if we go back into our raindrops folder, let's go ahead and grab that one that says metallic 02. And we'll put that one up in here. Now again, this isn't necessarily have to be connected to metallic. I just did that for experimentation purposes. So it's up to you how you want to do that. And I'm going to go and combine these with a Lerp and I'm going to actually control how strong that value comes through. I'll show you what I mean. So I came up here with a Piki again, but I make sure I do a negative one again for going downward on our motion."},{"start":"2:39","end":"3:13","startSec":159.7,"text":"It's the same as we had before in the other pattern. And I'm going to go ahead and punch this in to the UVs for the metallic raindrops and for the more smoother one. I'm also going to do it. Now what can be helpful is we can use alert. I keep my finger the L key and this linear interpret node takes 50% of each one of these, kind of like 50. 50 does a nice little blend and gives us an alpha for overall control. So I'm going to go and push these into one, the B value for the bottom one and the A value"},{"start":"3:13","end":"3:43","startSec":193.0,"text":"for the top one. And then we're going to get a water spec control. And I'm going to keep my finger on the S key and I'm going to left click and this will be our scalar parameter and we'll call this spec control right there. And we'll keep that value at zero and that's fine for the default because we're going to make an instance material. I'm going to move that right into the alpha and then I'm going to move that right into the spec. So now we can kind of get a little bit of the same thing we had before, but favoring the spec."},{"start":"3:43","end":"4:15","startSec":223.6,"text":"So overall we can avoid maybe some of the unnecessary shininess that may occur from using a metallic material. The add does help mute things a little bit, but in this particular case, this should be just fine. And I'm going to move some of these textures down. Let's move these down temporarily for a second. And let's go ahead and fill out some of these other values. Now what we can do with a rough is we can do a nice little experimental hybrid to get maybe a little bit more wave movement going on."},{"start":"4:15","end":"4:46","startSec":255.9,"text":"What I mean by that is I'll show you that we can add another texture layer in here. Now what I mean by layers in this particular case, I made it pretty loose. We're going to just pretty much lay them on top each other in this case. So first up, what we want to do is let's go ahead and make a roughness strength. So I'm going to give my finger the S key and left click. There we go. And we'll call this rough strength. There we go."},{"start":"4:46","end":"5:17","startSec":286.5,"text":"And then we'll go ahead and keep a finger the M key left click and do multiply. And then let's go ahead and pull in some roughness for the stones, the overall texture. So we'll go back into that mega scans stone one, river stone, and we'll pull in the roughness that we have. Now if you already have it, I think in our case, we may have already have it. There we go. I think I pulled it in earlier. No, that's the AO. There's the roughness."},{"start":"5:17","end":"5:49","startSec":317.2,"text":"So we already have that in place. So I'm going to move this guy away. And this roughness, we're going to go and punch set into the B channel. I'll multiply. I'm going to put the rough strength into the E channel. And we're going to now use a blend overlay. Now typically what you can do, you can swap these out. This basically uses a multiplier. You multiply as one against the other. So again, like we talked about before, it's similar to working with Photoshop. So if I wanted to, I could even flip these and still kind of get the same effect in this particular case."},{"start":"5:49","end":"6:25","startSec":349.5,"text":"And I'll leave those up there for now. So let's go ahead and keep my finger the P key again. And oh, my bad, I had a different key on that particular case. Let's actually even duplicate so we can grab our pattern and keep my finger on control D. And then we'll just go ahead and just duplicate what we have before. That makes things a little bit easier. So let's go ahead now and plug this into an overlay, blend overlay in which we can add"},{"start":"6:25","end":"6:56","startSec":385.0,"text":"the raindrops. So we'll call a blend overlay underscore overlay. There we go. Always forget there's underscore. There we go. Right there. And we're going to grab the raindrops and let's go ahead and grab the ones that we need. In this particular case, we're using that metal ones again that we pulled in."},{"start":"6:56","end":"7:27","startSec":416.8,"text":"And we'll go control D to get it. Pull the panor in there and pull this into the blend overlay. And we're going to go ahead and add another layer of extra wave movement. So move this down. Move this down too. So let's go and get that extra wave movement going. So we're going to grab another texture. This particular texture is called water waves."},{"start":"7:27","end":"7:59","startSec":447.6,"text":"And you'll find that under step five. So if we go down here, go to step five, you'll see water waves right there. And I'm going to go and pull that into my scene. Let's duplicate that pattern one more time. So do control D and it'll show up wherever my cursor is at. Reach that right into the UVs there. And then now let's go ahead and blend this over all and bring it into our roughness. So we've got a few more nodes. One will do multiply."},{"start":"7:59","end":"8:31","startSec":479.1,"text":"Again, keep my finger the M key and left click there. And then we'll do like a wave opacity. So if we want to control this wave opacity, let's do a scalar parameter. And we'll call this wave opacity. Now again, you can type it in or you hit that S key. And I'm going to pull that right into the B channel. And I can keep that as a default as 0.5 and I can choose whether I want to max that out."},{"start":"8:31","end":"9:03","startSec":511.1,"text":"So let's go ahead and get the texture sample. We just need the alpha information. We don't need it on top of it. So we're going to go and pull that into the A channel here. And we'll get the add. So let's get that add in there. So I keep my finger the A key. Add. This is going to make it a little bit more brighter of a highlight. I'm going to pull the multiply into the B channel. And then I'm going to grab that blend overlay and pull it into the A channel. And then now I can move that right into our roughness."},{"start":"9:03","end":"9:36","startSec":544.0,"text":"Now it can give us a little bit like an extra like it's like a wet. Just a little more cartoony and that's fine. And we can choose how that speed is going to go. So this can give you a little bit more of that almost like that irregular pulsating feel that you get from water. The ripples basically is what we're trying to imitate. And we can add that if we wanted to make a normal for that and add that in there too. That's really up to you how you want to approach that."},{"start":"9:36","end":"9:44","startSec":576.4,"text":"That's it with this video. And in the next video, we're going to wrap things up with a little more AO and some normals to be able to animate. Thanks again."}],"09_AnimMaterials3_55":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Hi, everyone. In this lesson, we're going to go ahead and wrap up animating our texture. So let's get started. So in Unreal, we have our scene set up here. So we have a specular, we have a little bit of exaggeration, a little bit of wave movement. Now, again, we can dumb this down for the opacity. So if we need this to be a little bit lighter, we can go from and we can do this also in the instance material. As we talked about that concept, we can do 0.2 if we wanted to. It's a little bit more subtle. And that actually might work pretty"},{"start":"0:34","end":"1:07","startSec":34.3,"text":"well. All right, so let's add or finish up the rest of this. And then what we can do for fun is add that normal map of that wave when we just made. Now, I didn't give this to you in the class, but you're more than welcome to make your own normal, whatever you want, and put it in. And we're going to look at the different ways you can do that. So first up, let's go ahead and add our normal. And we're going to keep it pretty straightforward. We're not going to get into inverting things and making sure that we can do so if we wanted."},{"start":"1:07","end":"1:40","startSec":67.2,"text":"We're going to keep things pretty simple, where we're just going to layer the normals on top each other. And one of the ways to do that, again, we can use the blend angle. And you'll see it's called blend angle corrected normals. And again, this guy allows us to be able to have two normals on top of each other. And it honors them so they don't get too muddled, they actually blend correctly. And there's no distortion between them. Now, it does a pretty darn good job of keeping that from getting too distorted. And I actually"},{"start":"1:40","end":"2:13","startSec":100.7,"text":"like it pretty well. It's pretty great. I'm going to keep my finger on, I'm going to click on the pattern out here, and do control D and duplicate that what we already have. And we're going to pull up the we need the raindrop normals. Now, if we go back to raindrops, you'll see that I already have a normal built for you. And we can pull that right into our scene. So let's pull that normal right here. And we can connect our painter to it. And then we can put this into our additional normal. And this is the rock normal, and we can make"},{"start":"2:13","end":"2:47","startSec":133.4,"text":"that our base normal. And then we can set that right into our scene. Now, if we wanted to add even more, we can bring in that wave normal that I made. And if we go back up into step five, you'll see that wave one. Now I made this on my own, you do not have access to this one, you can simply take him into Photoshop, make a black layer, make him white, and convert him to a normal. So I'm going to drag him into the scene, I'm just showing you what you can do if you wanted to stack these. And I can keep these things a little"},{"start":"2:47","end":"3:20","startSec":167.1,"text":"bit more simple with a multiply. Now, you do want to be careful when doing this, because if I just kept that as a multiply, the problem we can run into is where our control how strong that normal is is going to come through. So we would have to go in here and use a lurp again. And that can be very helpful. So we'll grab this normal put an A channel, put him into the B channel. And then we can try to go in here and use air, create a scalar parameter."},{"start":"3:20","end":"3:50","startSec":200.8,"text":"And we can control that way. Now it's going to overall kind of mute things. So you got to be careful with that. So another way you can do it is we can bring this into this particular one into a multiply. And in that multiply, then make a scalar parameter and call this wave normal amount. Got to be able to type that. There you go. So we can even call it large wave if you want to do we'll just leave it like wait for now, put it into the B channel,"},{"start":"3:50","end":"4:20","startSec":230.8,"text":"put this in the A channel, then create a multiply and bring it into here. And that's going to be a little bit more macro control versus micro. Now I like having this little micro control because then I can choose and isolate an effect. Maybe I don't like this as much. Maybe I like this a bit more. And I want this to be muted compared to it. And that can be helpful. And then now we can pull this right into our normal and see what we get. And you"},{"start":"4:20","end":"4:54","startSec":260.8,"text":"can see we get kind of it's a little dark, right? So we are multiplying pretty heavily on here. If it helps, we can go in here and keep our finger the L key and change our lighting. So it's a little less harsh. You can see the wave effect we got going on when light hits at a certain way. So we're like, hmm, that waves a little strong. So we'll go in here with this wave amount. And actually, he's zero right now, let's put one and see what you get. That's much better. I thought he was already active. There we go. That looks much better. It is dark because they were overall multiplying a zero, which was given"},{"start":"4:54","end":"5:27","startSec":294.5,"text":"us like kind of darkness. Actually works pretty well. That's actually not bad. So again, you can experiment with this any way that you want. We have our drips going through here and overall kind of wave, you don't necessarily have to have drips with wave. But that's up to you. So let's go ahead and wrap things up. So a few more things we need to do. Let's go ahead and kind of do a little bit of the same concept, but a little more simplistic without obviously the corrective blend, we're going to get these two guys into play and"},{"start":"5:27","end":"5:58","startSec":327.2,"text":"one of them being the AO and one of them being the cavity. There's the AO, there's a cavity. And you can determine how you want to stack these, but we can go ahead and move this out of the way for a second. I'm going to keep my finger the M key and we'll multiply. And we'll have these guys kind of magnify each other. And what I mean by that is you get a higher contrast with both of them together and you can see that change here as we zoom in. So you can get a stronger if you're if you're noticing your AO is not as strong as"},{"start":"5:58","end":"6:29","startSec":358.0,"text":"you need, but mega scans you notice gave you gave you a cavity map to you can combine them via the multiply. That's pretty convenient. So let's go and grab the raindrops that we need. So we need some raindrops that are we able to work well with ours. So let's see, did I bring in the AO raindrops? Maybe I didn't. Let's go and grab those. And let's pull this in. And you don't necessarily have to do this last step. But that is up to you how you want things how strong you want them to be. If you want the raindrops to look like"},{"start":"6:29","end":"7:04","startSec":390.0,"text":"they have a little bit of a shadow, you can maybe go this route. I'm going to go ahead and keep my finger on control D at the same time and keep my cursor at the area I want it and we'll duplicate what we need. Oops, I grabbed the wrong thing. Let's go back to Panor is what I meant to do. Control D. We're going to duplicate him over here. And we're going to move that right into the raindrops, pull that in. And then we'll move and make we'll make one more multiply, give me a finger the M key left click and pull a string into the B channel and then pull this texture sample on a channel. And then from here, we can take"},{"start":"7:04","end":"7:38","startSec":424.3,"text":"this into the AO ambient occlusion. And you can highlight some of the dark regions of your texture and your object. Pretty sweet. We made some moving water texture. And again, it's up to you if we in this case, we don't really need the metallic. But if you wanted to exaggerate things a little more, you could put the metallic in there. You just got to be careful because you know, the stone isn't really metal. And it may end up being way too reflective. It may look like 10. So let's disconnect that real quick, you can see the"},{"start":"7:38","end":"8:01","startSec":458.7,"text":"difference. And it's a little more realistic without it. But I left it in our scene. So you can do a comparable if you wanted to. So that's it for animating the materials. Hope you enjoyed that part of the lecture. And the next video, we're going to talk about you working with alphas and bringing things such as torn clothes into a scene and some of the nodes and options we have for that. Thanks again."}],"10_ClothMaterials_55":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hi everyone, in this lesson we're going to go ahead and take a look at how to create a cloth material and create materials with textures that have alpha information. So let's get started. In our scene in Unreal, on the last part of our lecture, you'll see that I have an object in our 3D space here, in Unreal that actually has some alpha information in it. I'm going to show you how to get this to be active, and some of the other options you"},{"start":"0:30","end":"1:03","startSec":30.9,"text":"can do to be able to make this a cloth alpha object in which you get the settings for a fuzz color and a cloth option. Now each one of these gives you the ability to be able to change things a little bit, but you don't necessarily have to use it, but the option is there. We're going to talk a little bit of the difference between them. You'll see that cloth is an input that enables you to control the strength of the fuzz color as a mask. The fuzz color, which you'll see in just a minute, this enables you to add color to"},{"start":"1:03","end":"1:36","startSec":63.4,"text":"your material, to simulate shifts in color when light passes through. Now again, you're simulating it, so it's not going to necessarily be 100% true, and also you have to be careful these two can mute each other out. I'll do an example as you can see it up close. Let's go and take a look at this material. Then we're going to go ahead and make a simplified version of this material. We're going to go back and look at some of the dependencies this material may run into. I'm going to go and click on this object in 3D space, and I'm going to go to my cloth completed and double click on that."},{"start":"1:36","end":"2:06","startSec":96.2,"text":"We see that our material pops up. We already have it active, but you can go in here and find the textures for cloth that we have in place, and you can find some of the materials that we have active. You can simply do that by hitting the magnifying glass, and you'll see under step four, it says cloth sample. Let's go ahead and look at this up close. So to be able to make this material, I've selected the blend mode of masked."},{"start":"2:06","end":"2:36","startSec":126.2,"text":"This is used whenever we want to have alpha information to be read, and we can punch it into our opacity mask. But I've also added shading model cloth. Now this is an option which gives you again that same fuzz color option as well as cloth option. Let's go to the slides for a moment, and we'll talk about this a little bit more in depth. So the shading model cloth simulates a fuzz layer and will produce more realistic results for cloth."},{"start":"2:36","end":"3:07","startSec":156.6,"text":"Now you do got to be careful because fuzz color and cloth can mute each other, so you have to get the values just right. So we're going to get a simplified version up close and compare it with this more complicated version. Again, the fuzz color, this input enables you to add color to your material to simulate the shifts of color when light passes through it. And cloth, although you know you're like wiser cloth note inside of cloth might seem a little bit redundant, but this input enables you to control the strength of the fuzz."},{"start":"3:07","end":"3:38","startSec":187.3,"text":"It probably should be called fuzz color, but we left it as cloth and uses it as a mask and value of zero indicates no fuzz color contribution to the base color, whereas a value of one blends fully over the base color. Now you can put color information in here if you wanted to, but primarily you're going to probably want to use a scalar parameter to be able to get more out of it because it's a very it's a very linear node. Let's go and jump it back into Unreal and take a look at this up close."},{"start":"3:38","end":"4:11","startSec":218.6,"text":"So in our material, this is the one that's already in the scene. I have things pretty set up, set up pretty simple. And I'm just pulling color information into the fuzz color and fuzz cloth. If I disconnect some of these, say we'll disconnect cloth, you'll notice that a whole lot happens, right? Because it's looking for a number value. This is what I meant before, but we also have fuzz color. So if we go down here and say we get fuzz color information and bring this up, we can now punch this into our fuzz color."},{"start":"4:11","end":"4:43","startSec":251.8,"text":"And you'll see if we increase the strength a bit more, you'll see these values get a little bit strong over the surface. Now our cloth, remember when I said they depend on each other and they can mute each other out. Well, if I go in here, I could either put a scalar parameter like say I'm going to detach this and bring this around. I can punch it in here or put in a scalar parameter, just put the numbers in or just do it this way. And then you'll see the strength kind of shine through."},{"start":"4:43","end":"5:14","startSec":283.1,"text":"So this is what I meant that you got to kind of find a happy medium of what you want. I'm going to set this to one and maybe even a point five, but you'll notice it is muted in a little bit, but not maybe to the amount that we want. That's when we have to go into the fuzz color and go in here and maybe lower this at least half or at least down to maybe 10. Then we can even go to like two and maybe even one. Now this color is making it so that we're imitating a fuzz type of look."},{"start":"5:14","end":"5:46","startSec":314.0,"text":"So if you need to mute things even more, you can do it with the amount or just simply change the color closer to your original object. So if I move this a little more closer to blue and hit OK, you can see that it's a little bit closer to what we have. And it has kind of almost like a haze fuzz look on here as it relates to the light. So it's almost like using kind of a Furnal Index type of approach to give us a simulated fuzz look to our object. Our fuzz color then can go in here and we can set this maybe 0.2, lower that, and you"},{"start":"5:46","end":"6:21","startSec":346.6,"text":"can see now it's muting things a little more believable and the fact that we can see the results a little bit clearer. And we can go to maybe five if you wanted to. All this we can use with a scalar parameter. And the cloth primarily is going to be driven by numbers. Now if we went in here and said, Hey, man, I'm going to go and put a color in here. You'll notice that information is going to be kind of muting each other. And this is what I meant by you probably just want to put some numbers in here because these dependencies will influence each other. And this is primarily being driven by numbers as it says in my notes."},{"start":"6:21","end":"6:50","startSec":381.1,"text":"Now if we look at a simplistic version, if I go to my content browser, we can go in here and underneath our intro to materials, we're going to go and go to our in class material, we're going to right click in here and make a new material. I'll keep this pretty simplistic. So I'm going to go M underscore cloth. Got to be able to spell cloth. That was class. I think that's like Scottish for cloth. So cloth sample."},{"start":"6:51","end":"7:24","startSec":411.5,"text":"And I'm going to double click on that. So again, we're messing with blend mode and shading model. Now you don't necessarily have to use the shading model. Again that gives fuzz and cloth to be able to be accept accessible. But I'm going to switch this mainly blend mode into our mask. And that mask is now going to give us an opacity mask. Now it doesn't open up opacity. It does if we go to the previous material, you'll see we do have an opacity set in here"},{"start":"7:24","end":"7:58","startSec":444.7,"text":"that controls a translucency of the material when substrate is enabled. This actually can work with substrate as well. So you have kind of like an alpha composite blend situation that you could use this if you needed it. But over here, we just need it because we simply just turn on mask. We have our opacity mask active. Now we can drive this with numbers or even try to drive it a little bit with a texture. But for the most part, you're going to see some values on some of these by default. But obviously just like rough and spec, you can put in a black and white kind of value"},{"start":"7:58","end":"8:30","startSec":478.7,"text":"in there. And we can do the same with some of those. Now right now, again, we're just using simple mask. And we just have an opacity mask set up and ready to go. What I'm going to do now is go in here and go to my control, go to my content browser, excuse me, and we're going to go ahead and get that cloth texture that we need. Now this is where our cloth is at, but we need to go ahead and grab that rip cloth or materials at we need to grab that texture. So I'm just going to pull on these simple PNG that I have."},{"start":"8:30","end":"9:03","startSec":510.5,"text":"It has already has an alpha embedded. So I'm going to pull in the RGB to the base color and then I'm going to grab that alpha information and put it right into the opacity mask. So I'm not driving numbers for this one. I'm simply pulling in my health information to it. Now you'll notice it's not rendering on both sides. So when that happens, especially if you have a draped cloth or maybe your character has a cape of some kind, you want to be able to see both sides. So in that, let's click on the grid and in this material, we want to go to the details"},{"start":"9:03","end":"9:35","startSec":543.5,"text":"and turn on two sided. And that'll give it so that we have both sides to our cloth object. In more advanced classes, we talk about how to actually have it so you can render two different types of textures on either side of that. But in this case, such as like with a leaf, but in this particular case, we just want to keep it simple. So you can get a little info on the introduction of this. And you can see that we've made a simple masked object, our texture. And then we open up the parameters in the material to be able to get that texture that"},{"start":"9:35","end":"10:06","startSec":575.1,"text":"read make the material to be able to read that textures alpha information. And we have it all set up pretty quickly. In the lecture notes, I walk you through step by step how to mess with these and to plug them into where you want them to be. It's really up to you how you want to play and experiment with Unreal. But we give you the tools to be able to you to be able to customize any look that you want and feel as necessary for your game or linear content."},{"start":"10:06","end":"10:30","startSec":606.9,"text":"In the slides, you'll see a link to get more information on this. And you'll find this also not only with 5.5, but 5.6 to get a breakdown of how to work with these materials and textures and to get things in the right direction. That's it with this lecture. In the next video, we're going to do a little bit of a recap, talk about everything we've looked at and wrap things up. Thanks again."}],"11_Outro_55":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Thanks again for joining us on learning more about how to create materials in our introductory course on creating them and using them in Unreal. We covered different aspects of materials to consider and think about when it comes to roughness and metallic, grouping those materials and putting them in the appropriate areas for organization and some of the tools to be able to view things the way that you would want. We also talked about looking at animated materials, how to animate them in a scene,"},{"start":"0:32","end":"1:04","startSec":32.9,"text":"how to get them to look and feel a bit more realistic based on your settings and the inputs you put in. And then finally, we looked at creating alpha information or getting alpha information from our textures and punching them into a material in Unreal to get the believability of cloth and things with alpha data that we can use and manipulate to the looks that we need. Thanks again for joining us on this little adventure and learning about Unreal and getting"},{"start":"1:04","end":"1:11","startSec":64.0,"text":"an introduction to materials. I'm sure you're going to have a blast and trust me when I say it's pretty addictive. Thanks again."}]},"101.02":{"01_Overview":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hello and welcome to today's Unreal Engine training on materials which is an introduction for AEC. So let's talk about the introduction. Let's go over the topics that we'll be covering today. So we'll be talking about real-time material concepts which is the PBR pipeline. We'll be talking about the primary nodes and textures, so PBR inputs and texture guidelines. We'll be going over the material system and talking about how parent materials and instances of those materials works."},{"start":"0:30","end":"0:50","startSec":30.8,"text":"We've got ready-made materials and textures, so we'll go over where you can find starter packs and marketplace assets and the Quixel Megascans library. And then we'll go into authoring your own materials. So we'll talk about the material editor. We'll create a parent material and then we'll create an instance from that and show the power of the material instance in."}],"02_Real-time Material Concepts":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"So to go over the real time material concepts, what are materials in Unreal? What is PBR? Especially if I mention PBR in that intro and you're like, what's PBR? Well we'll go over that and we'll talk about Fresnel effects and also the view modes inside of Unreal that you'd expect to see. So what is a material? So a material is essentially an applied asset to a mesh that controls its visual look essentially."},{"start":"0:30","end":"1:02","startSec":30.7,"text":"So in its simplest form, think of it as paint within the various properties such as the colour and the finish. So a material defines how the light interacts with the surface it is applied to. So you can see on these example materials here, if it's something very porous and seems to absorb the light, the material can actually set the parameters of how that should look As well as if it's more of a reflective metallic surface and you want the light to bounce off it instead of get absorbed, the material can define that inside of Unreal."},{"start":"1:02","end":"1:34","startSec":62.6,"text":"The PBR pipeline is a unified lighting and shading system essentially. So it's physically based rendering is what PBR stands for and it's a better approximation of the light and material physical interaction. So it's very intuitive and consistent. It's physically accurate. It uses real world physical measurements and a PBR is a combination of the material, which we spoke about in the previous slide, lighting setups inside of Unreal Engine and then also the exposure that you use in."},{"start":"1:34","end":"2:05","startSec":94.4,"text":"And then Fresnel effect. So the Fresnel effect states that the amount of light you see reflected from a surface depends on the viewing angle in which you perceive the surface. So you can see if you're dead on, 2 to 5% reflection there and on the 90 degree angle, you've got 100% reflection. So it creates this nice kind of outlining effect, the Fresnel effect that you see on the material there. And the unified shading model within Unreal Engine handles this for us. So you don't have to do anything custom there."},{"start":"2:05","end":"2:36","startSec":126.0,"text":"Unreal Engine's shading model just handles that for you. And then the different view modes that we can touch upon inside of Unreal. You can go to the view mode, the view part, sorry, in the middle window and you can select lit from your editor scene and you can select between a few different things. There's some optimization and things like this, but the ones that we care about are along the top here. So lit, you can see everything within the scene. Unlit will just show the colors and the textures."},{"start":"2:36","end":"3:07","startSec":156.9,"text":"So that might be useful for just previewing if you don't want any lighting information to be seen. You could have light ink only, which also just shows the lighting of what you have in your scene. And then you can have a detail lighting, which is light and reflections there. So it might be useful to play around with some of these lighting only or detail lighting. And you can also toggle through these using alt plus, you know, other different relevant numbers if you're previewing that content a lot."}],"03_Example of View Modes":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"So just to give you a quick example of those view modes, when we're inside of Unreal, so you can see by default we've opened in lit mode. So we can see we've got shadowing going on, we've got the global illumination system working. So we're in lit mode right now. So let's go to unlit and see that. So because there's no other materials on these walls, it's very hard to see any definition because a lot of the definition was being caused by the lighting."},{"start":"0:30","end":"1:02","startSec":30.9,"text":"But if I pan around, you can see the different material that might be being used and essentially it's color and textures only. And then we could see lighting only for example. So we can only see lighting information. So now we can't see any of the coloring on the textures, but we can see the shadowing that's happening with the lighting and we might just care about how the light is impacting the scene. And then we could also go to detail lighting just to see that extra view mode there. So again, there's a lot of view modes to play with depending on the work that you're currently doing. You might find some more useful than others,"},{"start":"1:02","end":"1:06","startSec":62.6,"text":"but that's just to give you a quick explanation of what's happening inside of Unreal."}],"04_Primary Nodes _ Textures- Parents and Instances":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Next up, let's go over the primary nodes and textures you'll be using in your projects. So we'll talk about the primary PBR inputs here, the base color or Albedo maps, metallic roughness and specular, and also talk about the textures, what Unreal supports and what the kind of best workflow is for using textures inside of Unreal. We'll talk about texture pyramids or MIP maps as they're referred to, and then import in your textures how to get your content into Unreal."},{"start":"0:32","end":"1:05","startSec":32.8,"text":"So the primary PBR inputs are the base color, and we'll go through creating a material at the end, so you don't need to worry specifically if you're unfamiliar with this interface, but essentially we've got a base color going in, which is just this blue color, and then we can set some metallic specular or roughness values depending on how we want this material to look. So this is all handled on the editor side. So the base color or Albedo map, as we refer to it, is a flat color without specularity or shading. So roughness is key to define the look of a material, and it's selling the real world"},{"start":"1:05","end":"1:35","startSec":65.4,"text":"equivalent. So the Albedo map is a linear RGB, which is a vector 3, which is actually what we saw in that previous slide. So this is a vector 3, so it has three numerical values. So that's a vector 3 going in there, and the values between 0 and 1. So we want to avoid any pure black in Albedo, and we want to avoid any pure white, as they don't really exist in nature. So to get the metallic feel, essentially metallic is a grayscale value that ranges from 0 to"},{"start":"1:35","end":"2:10","startSec":95.7,"text":"1, and really it's either 1 or 0. It's either on or off. You don't really use any mid-grounds here, but when on, which is number 1, it yields 100% specular reflection. So you can see the sliding scale of 0 to 1 there, 1 being the most specular and 0 being the most absorbent of the reflection. And then the roughness map is a grayscale value again that ranges from 0 to 1, but the ranges from smooth is like a mirror-like surface, which is 0, which you can see on the left"},{"start":"2:10","end":"2:41","startSec":130.0,"text":"here, to a rougher matte surface, which is on the right side there. So unlike with metallic, this really can be dialed into whatever value you'd like. As long as that value is between 0 and 1, you can say 0.35, for example, and really dial in that roughness for whatever you're trying to achieve there. So specular then is a grayscale value that ranges from 0 to 1, and it's a good rule of thumb is to set the specular value to 0.5 and fine-tune it from the roughness value"},{"start":"2:41","end":"3:16","startSec":161.1,"text":"instead. Have it on by default and set it to 0.5 so no node connection is needed for it. And in some cases, you may decide to edit the roughness value or use a bitmap to that effect. So you can achieve this by using stylized looks over the top of glossiness. It's not always needed when using a roughness value, but it's worth considering the specularity in balance with the other inputs of your material there. And so Unreal Engine supported formats. In an uncompressed file format, Unreal does support BMPs, Targets, PSDs."},{"start":"3:16","end":"3:50","startSec":196.0,"text":"It's worth noting that depending on the export of the Targets, if you're setting a 32-bit there, you can get an alpha out of that Targets. And then compressed versions, you can have a PNG, JPEG, DDS, and HDR. For optimization purposes, it's best to work with PNG due to its lightweight file size and the ability to have transparency info when needed. But it's worth considering the different formats depending on the project's requirements there. And so when looking at guidelines, textures should always be a power of 2."},{"start":"3:50","end":"4:21","startSec":230.7,"text":"So when we import our textures, maybe it's 16 by 16 or 8192 by 8192, and any variation, you know, 64 by 64, et cetera. But the textures don't have to be square. It's mainly that they're a power of 2 that's the important point. So if you wanted 16 by 128, that's fine. So they're all acceptable examples as long as they're power of 2. And textures can affect the streaming and memory management. So it's important to keep this in mind, especially on that previous slide where we were talking"},{"start":"4:21","end":"4:52","startSec":261.8,"text":"about the different file formats. Making sure you're considering the memory management of what the project's output is. That's super useful, especially at the start of the project when trying to define your pipeline there. And high frequency textures can cause anti-aliasing and artifacts. So a couple of examples of the different import settings used for maybe streamed or non-streamed textures and also how to scale the number of mipmaps, for example. So whether you have alpha channels or not, the size of the textures, the method that"},{"start":"4:52","end":"5:24","startSec":293.0,"text":"they're imported at, they can all be dialed in for the project's requirements essentially. And on the texture pyramid side, which is the mipmaps, mipmaps are another custom setting. So we can set these, when you use the textures inside the material editor, you can see that you can set these values on the material editor in the expression sample. And then you can also double click any textures and set the texture group from here as well."},{"start":"5:24","end":"5:55","startSec":324.2,"text":"So useful to keep in mind when working with texture pyramids. And then when you're importing your textures, so you can see from the previous slide, we have this drop down here. That's what we're referring to on the mipmap side. But then also when we import the textures, you can either use the import button in the content browser or you can go to file, import, or you can simply just drag and drop the file from the Windows Explorer into the content browser and that will import it just fine. All textures are converted to UAssets."},{"start":"5:55","end":"6:27","startSec":355.8,"text":"So when we're looking at Unreal file formats, even if it was a PNG that you're importing, the PNG then gets turned into a UAsset on the import. You can open a texture using this texture editor that you can see on the right hand side here with a double click of that texture that you've just imported. And so here we can change any compression settings, anything we need to. There's a lot of just scalability optionality here that you can dial in for your relevant projects and you can even import at higher resolution and downscale it inside the engine"},{"start":"6:27","end":"6:38","startSec":387.9,"text":"if you need to. So we can also enable or disable linear color space here, which is the sRGB as well. So all these things hopefully useful to keep in mind when starting your projects."}],"05_The Material System":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Next, let's touch upon the material system and the parents and instances that encompass that. So, the topics here are the material editor, parent materials, and material instances. And so, the material editor is an intuitive node-based editor. We can create HLSL shaders without any need for any kind of coding. It's all represented through the visual node graph that you can see on the right hand side"},{"start":"0:30","end":"1:04","startSec":30.4,"text":"here. We can organize the material graph with comments and descriptions and make it very clean and easy to read and you can kind of pick apart the flow and understand exactly what's going on in material editors, which again, like I mentioned at the start, we'll touch upon towards the end in the material editor section. So when we're talking about material, a parent material, a parent material is an asset that you end up with when you save the node tree from the material editor. So the image that we saw on the previous slide, if we saved that, that would become a parent"},{"start":"1:04","end":"1:40","startSec":64.8,"text":"material. And you typically adjust a parent material to behave based on a series of criteria and properties you define such as input options for whether it be base color, which is the albedo, metallic, roughness, normal, you know, et cetera. Any of those inputs would list it above. So even though you can apply a parent material directly to an object, you can usually create an instance derived from it that you apply instead on the scene. So the parent material houses all the instructions and the instance can then be a more optimized"},{"start":"1:40","end":"2:11","startSec":101.0,"text":"way of using that because parent materials are essentially heavier to use. They require recompiling every time you change them. Whereas an instance, you can edit on the fly and you can change different parameters and you don't have to recompile the entire shader because the shader already knows what it needs to do. The main thing to take away though is to adopt a naming convention when naming your parent material so you understand in the editor, you know, whether you want to use M underscore for material or mat. Some people use mat underscore."},{"start":"2:11","end":"2:41","startSec":131.6,"text":"Just whatever name and convention you think of, keep it consistent so that everyone can understand the difference between a material and a material instance. Unreal does have a way of filtering these things out, but it's sometimes just easier to see from the naming convention what this material type is. And so giving you some hot keys for your material editor, maybe you want to take a screenshot of this or note them down. There's some useful node shortcuts here to take away. It will create them, especially if you're using the material editor a lot."},{"start":"2:41","end":"3:15","startSec":161.7,"text":"These kind of things will save a lot of time. And then talking about material instances, instance materials inherit the properties of a parent material they are based upon. So you can set the parent material in such a way to have total control over the parameters and expose them in the instance. And we'll talk about what this looks like at the end of the course when we actually create our own material instance, but it essentially means that you can have any number of material instances based on a single parent and have totally different looks and finishes."},{"start":"3:15","end":"3:45","startSec":195.0,"text":"So it really helps you dial in the different values that you want using the instance instead of that parent material. So material instances, as mentioned, are much lighter to work with and can change at playtime without the need to recompile the parent material. And a material instance UI is simpler to use. It's just a much more streamlined set of commands that you can use over the node-based material editor. As mentioned previously, you just want to make sure that naming convention is set when"},{"start":"3:45","end":"4:13","startSec":225.7,"text":"you're using material instances. So we use MI for material instances. So M underscore for material and MI underscore for a material instance really just helps people, well yourself as well, but people on the project understand what the different materials material types are and how to use them without having to hover over to find the information or double click it to open it up. It's just a much more streamlined way of working."}],"06_Readily Available Materials- And textures":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"It's also worth highlighting some readily available materials and textures that you can use to just get started with your project. So the starter content is the first thing to highlight here, which contains a selection of sample meshes and assets, but also lots of materials and textures to get you started. So whenever you create a new project in Unreal Engine from the launcher, it'll say, do you want to include starter content?"},{"start":"0:30","end":"1:01","startSec":30.6,"text":"And you can decide whether to tick that box or not tick it. It is loaded default by most templates, but you can also add it to the project at any time. And if you need any kind of prototyping assets to get started with, the starter content is a really great inclusion to a project. That being said, you know, if you don't need it, just you don't need to add it to begin with. And if you feel like you don't need it, but then need it at a later point, very easy to migrate into the project at any later date."},{"start":"1:01","end":"1:31","startSec":61.1,"text":"So just gives you a few tools to get started with that. And then we also have the marketplace. So marketplace can be found through the launcher, the Epic Games launcher. And you can find this on the marketplace times here. So say we wanted to add some automotive materials to our projects, we could click add to projects and it says, you know, which project do you want to select here? And you can add them after the fact. So these are all commercially available data, although they do contain a lot of free"},{"start":"1:31","end":"2:03","startSec":91.2,"text":"packs on there. So you can actually filter through the free content as well if you wanted to. And you can download marketplace packs through the vault, which is down here and access them from any system using your Epic launcher credentials. So very nice, flexible way of working. And especially some other people might have done a lot of groundwork that you need to just add to your project and get going with. Very useful for that kind of thing. And then also Quixel Bridge. So you can find Quixel Bridge through the content menu here and inside the editor."},{"start":"2:04","end":"2:37","startSec":124.0,"text":"And this is all free data accessible directly from the engine. There's a whole host of high quality assets here that you can use to just get your projects up and running. It's an enormous library of 3D assets and materials and textures and very easy to use in your projects. Use them effortlessly. Just drag and drop and start working with the content. It's a really, really powerful resource there. But some other resources if you if you wanted to search for some more. So lots of lots of content on the Internet."},{"start":"2:38","end":"2:52","startSec":158.3,"text":"Some notable examples are Texture Haven, which a URL for is there. You also have the free PBR website, which is also see a URL for and then Ambient CG. In case any of those additional resources were useful to you."}],"07_Authoring Materials- Create a Parent Material":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"So, as promised, we're going to learn now how to create a parent material. And to give you a bit of an overview of how I'm going to do this, again, I'll talk you step by step through the editor if you're unsure of the process here. But I'm just going to walk through the steps in case you just wanted to know the TLDR version of this. But we want to create an opaque parent material. So start simple and move away up. We can add constant nodes to primary inputs."},{"start":"0:31","end":"1:04","startSec":31.4,"text":"Like we said, we can add the base color, the metallic, the roughness, and just get started from there. And then we'll add some parameters. So we'll add a parameter to our material and we'll make sure that we can adjust the values then using a material instance. So we can add vector parameters. We can add names to these parameters and then edit them in the instances after. So when I create a material instance, I'll be able to check that those parameters are exposed and I can edit them correctly."},{"start":"1:04","end":"1:11","startSec":64.2,"text":"So let's dive into the editor and let's create a material plus a material instance to really describe exactly what we're talking about here."}],"08_Workshop- Creating a Material":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"So back in my editor, I'm just going to go to the content folder. I'm going to right click in the empty space here in the lighter gray space. I'm just going to create a new folder. I'm going to call this materials. It just keeps things nice and organized and in its own space. And then I'm going to hit enter with it selected. And then that just goes to the materials folder. You can of course just go through the content folder file structure and select materials."},{"start":"0:30","end":"1:03","startSec":30.4,"text":"I'm going to now right click and I'm going to select material. Now thinking about naming conventions before, I'm going to say m underscore color material and I'm going to spell color the British way. I'm probably not going to call it material actually because the prefix at the start denotes that it's material. So I'm just going to call it m underscore color. I'm going to hit enter and then enter again and that will load up the material editor. Now I'm just going to pin this at the top of the window here."},{"start":"1:03","end":"1:35","startSec":63.9,"text":"And if I go back to the editor, if that didn't open for you, you can just double click it as well. That also will open it. I'm just going to shut this plugins by middle mouse button in on the wheel and that shuts any windows there. You can also just hit there close. You may not even have that plugins open. So the first thing I want to do is using our shortcuts before that we showed on the slides, I'm going to hold the number three on my keyboard and left mouse click and that will create"},{"start":"1:35","end":"2:10","startSec":95.8,"text":"a vector three. And I'm just going to drag into the base color and then I'm going to hold down wall one, the number one on the keyboard, sorry, and left click and put that into metallic. I'm going to hold down one again, left click and go into roughness. So we should have something that looks like this. Now first thing I want to do is change this color. So I'm going to select the vector three node. I'm going to click on the color constants here. I'm just going to pick a color, whatever you prefer and just hit OK."},{"start":"2:10","end":"2:40","startSec":130.2,"text":"And that gives us some kind of color value here. Now, depending on how we want this material to look, we can set some default values. I'll set one on the metallic just to give it a metallic look for now. We'll be editing this, but that gives it a nice metallic look. Just hit one. Now, if I save this material, that material is good to apply to an actor in any of the"},{"start":"2:40","end":"3:10","startSec":160.4,"text":"maps that we've got. However, we want a more streamlined way of working with material instances. So first thing I'll do here is I will right click. I'm going to convert to a parameter. I'm just going to call this color. And again, spell color, however you would normally spell color. I'll spell it the British way. And I'm going to hit save. And that's going to save the material. And then I'm going to actually close the material."},{"start":"3:11","end":"3:42","startSec":191.8,"text":"Now, what I want to do now is selecting the material, I'm going to right click and create a material instance. I'm going to call this MI underscore color. And I'm going to call this underscore 01 as well. So I'm going to be creating multiple instances of these. Now, I'm going to hit enter again to open this. I'm going to pin my window. Now, if you notice, if I double click this, now it's a condensed version of that material that we saw."},{"start":"3:42","end":"4:16","startSec":222.6,"text":"I'm just holding down right click to zoom in and out. You can also change how the material looks in the preview there if you so wish. But you'll see now we have this color parameter, which we can tick and actually change the color directly. So again, as we were talking about, this is a condensed version of the nodes. This is a really nice, powerful way to edit the material instance. Now, what we can also do, you'll see color is here, but none of the other properties are. What we can do is we can go back into our content library and we can double click the"},{"start":"4:16","end":"4:52","startSec":256.5,"text":"color and we can actually right click on these as well to convert them to parameter. So I'll right click there and type metallic. I'm going to right click on this, convert to a parameter and call it roughness. And I'm going to save and then I will close the material. And now we can see we've got a metallic and roughness value. So if I want to select these and say, well, I actually want metallic to be zero now, or"},{"start":"4:52","end":"5:25","startSec":292.1,"text":"I want roughness to be, you know, point four, for example, we can actually do this and start creating materials that we want. Now, if I save and close, I can actually duplicate this and it'll call it 02. I can duplicate it again and call it 03. And now we have really powerful functionality going on. We can have metallic surfaces with more roughness. Maybe I want to change the color here. And you can just start playing around and dialing in all the different properties that"},{"start":"5:25","end":"6:00","startSec":325.4,"text":"you want. Again, I'm just paying windows and loading the instances. And you can see instead of creating this graph every time and I'll leave metallic at zero there, roughness one. And you'll see that very quickly we now have three different materials based on this parent material, which have a powerful functionality of customization. They're much lighter weight. Using these material instances is just much lighter weight than using this parent color. So hopefully that gives you a good idea about how to use parent materials and material instances."},{"start":"6:00","end":"6:18","startSec":360.6,"text":"And the main thing you've taken away here is that when you have these materials, you right click convert to a parameter. It says convert back to a constant because it's already a parameter. But if you create a node and you right click to a parameter, you can actually convert that to a parameter and make it editable within that material instance."}],"09_Authoring Materials continued":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"So the material that we set up is great for if you just want a basic color implementation, but what if you want to add textures to your material? So for this we can use placeholders. So we can actually expose texture parameters such as the albedo maps, normal maps we need to account for in the parent material and use placeholders in place of that and then you can apply your own textures on the actual instance."},{"start":"0:33","end":"0:46","startSec":33.5,"text":"So these could be any textures in your system, but we're going to include some neutral textures which is the white square texture, a black texture and also the T normal texture. So we'll jump into the editor now and get that set up."}],"10_Workshop- Texture Parameters":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"So, we will just create a new material for this which I will right click, I got some material I'm going to call this M underscore, I'm just going to call this master, let's say master for now and I'm going to hit enter and then enter again and so I want to actually hold down T this time so I'll go to T and press left click, I'm going to create four"},{"start":"0:31","end":"1:04","startSec":31.9,"text":"of these so T left click, T left click, T left click and T left click, I mean alternative you can just copy and paste so I could hit control C, control V if I wanted to copy and paste but because it's T and left click it's quite a straightforward command to use, I'm going to plug one into my base color, I'm going to plug one into my metallic, going to get a roughness and I will use a normal map in this instance so we're going to normal."},{"start":"1:04","end":"1:35","startSec":64.3,"text":"Now you can see that we're error in red so let's just plug in some textures here so let's go back to our content browser and actually the thing that I keep just not getting used to in Unreal Engine 5, let's make use of it now, in our material we can hit control and space bar and we can open the drawer here which is a really really handy tool for those of you who used previous versions for Unreal Engine that didn't have this, you can see what kind of lifesaver it is but let's go ahead and add this white square material first so we want to go to engine content and so instead of the main content you want to go"},{"start":"1:35","end":"2:08","startSec":95.8,"text":"to engine content now and for whatever reason you can't see engine content you can come over to settings on the right hand side here and just make sure you show engine content so we're looking out for the engine content here and then I believe it's called white square texture so we can use either one of these I think they're both the same, yeah well let's go for the first one I think you'll be fine with either but let's just go with the first one for now so we can plug that in there we can select this texture sample"},{"start":"2:08","end":"2:43","startSec":128.3,"text":"and under texture we can just plug that in because we've got it selected in our previous window we'll also apply that to the roughness as well now we want to find a black texture so we'll type in black and I think it's that first one yeah let's go for the black one by one let's put that in there and let's assign that so we're just because we've got it assigned in a quick draw by pressing ctrl and spacebar we are then oh there's two more up here let's"},{"start":"2:43","end":"3:15","startSec":163.3,"text":"go with the first one I think that's going to be the safer one to pick so let's just hit black there that's good and then ctrl and spacebar and now let's type in T underscore normal make sure we spell that correctly and then we want this T underscore normal and then we'll go back here select the last texture sample plug that in and then we'll hit save so what we've got here is we've got a placeholder materials placeholder texture sample sorry for"},{"start":"3:15","end":"3:52","startSec":195.5,"text":"our material and then what we'll do in a similar way that we did the the previous material instance with the colors we can just right-click and convert this to a parameter so we'll call this albedo texture we'll right-click the next one convert to a parameter and call this metallic texture and you can imagine what the next one is going to be so right-click convert to parameter"},{"start":"3:52","end":"4:25","startSec":232.5,"text":"we'll call this roughness texture and then last one we'll call this one normal texture so convert to parameter normal texture and so if we save and then go to our content browser which again I'm just going to open my draw here which goes ctrl and spacebar I'm going to zero out any such bar information I'm going to go back to my materials folder on my master material I'm going"},{"start":"4:25","end":"5:01","startSec":265.1,"text":"to right-click create a material instance I'm just going to call this mi master maybe I'll call this mi underscore master this is where you probably want a prefix of like m underscore master underscore would underscore o1 for example so then you can have this big parent material and then you can define based on the material type but I'm just going to call this o1 for now just so we get an idea I'm going to hit enter to open it and you'll see that we now have some global texture parameters"},{"start":"5:01","end":"5:15","startSec":301.5,"text":"so we can actually enable all these and we can now plug in whatever textures we want into these different values and that will then create a different material based on that so really nice quick way to have this master material and to create some instances from that"}],"11_Adding a Tint Color":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Now, what we can also do is we can combine some nodes maybe to create a tint in this example. So, we can have a tint color which again we just create a vector 3 and then we'll right click to a parameter call it tint color and then we'll multiply this holding down M on the keyboard and left clicking for a multiply node and then we can define its role based on this tint color. So, let's jump into the editor again and do that now."}],"12_Workshop- Tint Color":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"So we'll go back to our master material. We will find some empty space here. We will hold down M and left click and have it for multiply. Again these are from the hotkeys that we set at the start but you can just right click in the menu as well and type multiply and find it there. But we want to use shortcuts wherever we can. We want to hold down 3 on the keyboard and left click to create a vector 3."},{"start":"0:35","end":"1:07","startSec":35.8,"text":"We want to convert this to a parameter. Call this tint. If I can spell color. I'm going to plug this node into here. Plug this node into here. Because it's multiplying it doesn't really matter which way around it goes. I'm just going to plug it around into there. And then tint color. Let's just have a default value of like a bluish type of color just to make sure that it's got some kind of nice default value and then we'll save that."},{"start":"1:07","end":"1:29","startSec":67.6,"text":"And so now because we've saved it and because it's a vector 3 parameter we can actually hop back into our material instance and you'll see that we've got a nice tint color here which we can then do whatever we want with. So slowly we're just layering in the complexity of the materials and adding nice subtleties and a nice customization for use in our worlds."}],"13_Grouping Material Parameters":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"A really nice customization as well of these materials is to actually sort the parameters and keep things organized into parameter groups. So we can control the order in which information is displayed. So instead of a generic expandable rollout, we can create a specific group for the various defined parameters and sort it any way you see fit. So we can select a node and add it to a group, which we'll do in the editor right now, and set the sorting parameter and groups are sorted alphabetically."},{"start":"0:33","end":"1:07","startSec":33.1,"text":"So you can force them into a particular order by adding a numerical value. So let's go ahead and do that. And let's sort our albedo, metallic, roughness, and normal into their own groups here. So back in our editor here, we will first do the albedo texture sorting group. We can just type in one albedo and do sort priority as one here. And then maybe let's do tint color. We use a drop down and now we can select albedo because we had it typed in before."},{"start":"1:07","end":"1:40","startSec":67.8,"text":"Now let's do two there. And then we'll do the same for metallic. So we'll type in two dash metallic. We'll do three dash roughness. You can probably guess where we're going with the normal. So four dash normal. Save this."},{"start":"1:40","end":"1:57","startSec":100.5,"text":"And then we can see our groups here and we can see the tint colors below the texture because we did the sort priority. I didn't set any sort priorities for these other properties here, but you can obviously do so depending on the complexity of your material there. So really nice way to keep things organized and categorized."}],"14_Parameter Switches":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"So, stepping our materials up a little bit more, we can actually have parameter switches to our materials as well. So we can essentially get an either or scenario with a branch. We can set the switch to choose between two different directions and whether to use maybe this texture map or whether we use the base color and we can set a static switch to say true or false. We'll do a switch called use albedo texture question mark and if true we'll use albedo,"},{"start":"0:34","end":"1:05","startSec":34.5,"text":"if false we'll use a base color. So let's jump into the editor and do that and get that hooked in now. So we'll find some empty space up here, we'll drag these to the side, we'll right click add a switch parameter, so right click, switch parameter and we'll say use albedo texture question mark and you'll see that you can also, if you didn't click the description"},{"start":"1:05","end":"1:42","startSec":65.8,"text":"you can change it on the parameter name down here if you prefer. I just type everything directly into the box there. So you can also just select and then select again, not double click but select and select again to edit the text. So use albedo texture, if true well we want to come from the albedo texture so that makes sense and if not we want to use a base color. So I'm going to hold down three, left click, I'm going to right click on the node, I'm going to convert to a parameter, I'm going to call this base color and then go into false"},{"start":"1:42","end":"2:13","startSec":102.6,"text":"and let's just set a base color whilst we're here of maybe an off, just off white kind of color just to make sure there's something there and then we can go directly into the base color. So now what we'll have is we'll have a parameter switch, if I save the material we've also got a base color and a switch. So when we go into our material instance now we'll actually see that we've got use albedo texture and use base color. Now the only two things I really want to change here which is technically one thing but let's"},{"start":"2:13","end":"2:48","startSec":133.6,"text":"get this categorized back into our parameter group because it just looks way cleaner. So let's jump back in here, we've still got our parameter group set up there so I'll use parameter group. So no parameter group for that one but we can definitely get a parameter group in with So let's say albedo and we can sort that as number three which is underneath tint color and then we can save it and therefore now we've got the static switch, use albedo texture,"},{"start":"2:48","end":"3:18","startSec":168.9,"text":"we've got a base color there if we want to set a base color and whether we set the switch to true or false gives us the optionality which is really really nice so it's like okay you want to use this, that's base color, use albedo texture true, well now we can see the other properties so not only does it categorize things it also tells you what options are currently being used which is such a powerful feature of the material editor and really really nice quality of life thing."}],"15_Commenting Materials":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"And then possibly one of the most satisfying things you can do in the material editor is to get things organized by adding comments. So I come from a very blueprint driven background in Unreal so it's very nice that the material editor now has this functionality to comment and give things descriptions and comment colors. And so we can add a comment by pressing C. So let's jump into the editor again and let's just get everything cleaned up here."},{"start":"0:30","end":"1:03","startSec":30.1,"text":"So we will drag let's say the base color into some different real estate and let's hit C on our keyboard and let's type base color, well let's call this albedo, it makes sense albedo. And you'll see by default we get a little comment box above. I generally don't like the comment box above there but you can keep it if you want. Just sorry I got rid of that."},{"start":"1:03","end":"1:38","startSec":64.0,"text":"So when we select the comment color we want to go to maybe say TLE or turquoisey kind of color. I generally like dropping the alpha down to maybe a 0.4 or something like that, it just gives it a little bit of a softer feel, kind of nice. So we'll go to font size, if you have a big material graph maybe you have size 40 on like some kind of key information up here but then maybe you don't need as much for say metallic there, maybe it's even a 12 instead."},{"start":"1:38","end":"2:16","startSec":98.0,"text":"Maybe metallic is a darker color again maybe dropping that alpha down just to soften it. You can also copy and paste these so I'm just going to select metallic, copy and let's go roughness, let's maybe change this to a different color, you can just drag and drop that in and as soon as you drag and drop it in then it moves it around which is really nice. And then let's do normal and I think normal has to be blue probably, well a bluish purple."},{"start":"2:17","end":"2:51","startSec":137.7,"text":"Deep blue. Again you could spend a lot of time trying to clean this stuff up but that's good for now, it just shows you how to keep things organized, you can of course go out to town on this kind of thing and yeah if you want to do anything like that you can. The only last thing I like to do is double click on any of these wires and you can kind of add these re-root nodes that you can also move around with your keyboard as well. So you just double click on the wire and it just creates a nice satisfying flow of information"},{"start":"2:51","end":"3:14","startSec":172.0,"text":"if you so wish, in case you've got any like tangling of wires and just keeping things nice and organized I just like to double click, create re-root nodes and like I said move them around on your keyboard or do that. It just you know especially if you bring information out here just keep things nice and clean and organized so good way to keep things tidy in your material editor."}],"16_UV control":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"If you want control over your UVs, you can actually control this through the material editor as well. So we can add a text quad using the U shortcut and you can drag and drop the text quad in there, maybe set the UV tile into one and one. And then we can also multiply that text quad to get some UV scaling going on. And that will expose that parameter, which gives you a lot of functionality and control"},{"start":"0:31","end":"1:07","startSec":31.8,"text":"over the UV. And we can even add a custom rotator as well. So again, custom rotator node is here and then we can divide that by whatever numerical value, maybe it's 360 and then use UV rotate as one there to add a custom rotator. So let's jump into the editor. Let's get that set up. Again, we're getting some more advanced functionality now over the material editor. So in our material editor, we want the texture coordinate and maybe you want it on the albedo"},{"start":"1:07","end":"1:42","startSec":67.0,"text":"texture for example. So let's add a text quad. We can do this holding U and left clicking. So that's our texture coordinate. We also want to multiply this texture coordinate, just making sure the UV tile is one and one. Scroll down M to multiply. So we'll multiply this and then we'll add a one and left click for a constant, convert this to a parameter and let's go for UV scale on this one. So UV scale, I'll set the default value to one on the UV scale."},{"start":"1:42","end":"2:14","startSec":102.9,"text":"There we go. And then let's multiply this into the custom rotator. We could add this directly in if we only just wanted to use the UV scale, but let's get the custom rotator in here as well. Let's do custom, custom rotator. So we want to plug the UVs into here like that. The rotated value that can then go into the UV there."},{"start":"2:14","end":"2:50","startSec":135.0,"text":"And now let's add the UV rotate. So we'll hold down one and left click and convert to a parameter. Again you start finding you're doing the same process over and over again, which is good habit to get into. So UV rotate, we'll do a one there and then we will divide this. So we will divide and we'll make sure coordinate B is 360. So divide that by 360 and then rotation can go into the rotation angle."},{"start":"2:50","end":"3:21","startSec":170.4,"text":"So now we can have control over the UVs, the scaling of the UVs. If you want to give the grouping to these texture coordinates, you can. So the UV scale and that I think would be four. Yeah, that would be four. And then we want to do rotate as well. So that could be five. So you can see things getting organized here, which is really nice."},{"start":"3:21","end":"3:52","startSec":201.9,"text":"Nice way to add some UV control over your albedo texture. And of course you can do this for other textures. You could drag it out into multiple outputs and copy that setup. However you would like to then start authoring these materials. So the first thing we want to do now and now that we got our material set up is to actually give it a test drive and let's see how it's looking. So let's go into our scene."},{"start":"3:52","end":"4:27","startSec":232.5,"text":"You can have any basic geometry. You don't have to have this scene. You could just have a cube if you wanted to from the shapes palette. It can be anything you would like. I'm just going to maybe scale it up as well. So I'll create, I'll get the material instance and I will apply this to the mesh. I can either plug it in here under the material or I can drag and drop it as well, whichever one you'd prefer to, whichever approach you prefer to take. And let's make sure we have our UV scale turned on and let's try and find some kind of rock"},{"start":"4:27","end":"5:00","startSec":267.4,"text":"or some other type of texture. Doesn't matter what texture it is, but just make sure you have some kind of texture going on here. I'm going to change this tint color here just to make sure that it's easier to see on the screen. Maybe I'll look at this here. So we've got some kind of rock going on here. Let's make sure this gets saved and updated."},{"start":"5:00","end":"5:33","startSec":300.9,"text":"Let's make sure we're in the lit mode as well. So if you turned off the lighting previously, make sure you're in lit mode. And now let's play around with some of these scale values. So I'm just going to bring this into some kind of real estate that you can see. So first of all, we've got the UV scale. Again, I'm just trying to organize my window so you can see a little bit. So let's scale it by two. You can see it's scaling by two. If I want it to repeat less, you can have a scale of 0.1."},{"start":"5:33","end":"6:05","startSec":333.8,"text":"And you can just keep scaling and scaling. I think the larger you scale, you start to see the repeating patterns. But you get the idea of the scale working. And then UV rotate. If you, I mean, we can see this happening in real time. But if you want to type whatever values in, you can see that rotating. So we know that our properties are working, which means we're in a really good place. Maybe I want to save these values. I'm not sure. But I think the last thing I want to do is because we're going to be plugging normal"},{"start":"6:05","end":"6:38","startSec":365.1,"text":"maps in and because we're going to be using certain textures, let's actually jump back into the material. And let's actually say this isn't just for the Albedo. Let's say I'm going to drag the comments in here. And I'm just going to drag down here and say hit comment and say, let's say, text texture coordinate, something like that. You can call it whatever you'd like. But essentially what we want to do, maybe just add a bit of alpha just whilst we're"},{"start":"6:38","end":"7:17","startSec":398.3,"text":"here or remove a bit of alpha. But I think we want to do this for all the UVs because we're going to be using normal maps and especially different texture maps. You probably want to be, if you're scaling one, you probably more often than not want to be doing all of them uniformly. Now, if for whatever reason you don't, you can obviously just copy and paste that information. But I think I'm going to plug that into all four in this instance. And if I am doing that, I'm going to remove the group. Well, maybe not remove the group, maybe add a five and text co-ord, something like that."},{"start":"7:17","end":"7:49","startSec":437.6,"text":"You can call the group whatever you'd like. So I'll call, I'll set the priority of two for that. And then I'll set the priority of one for this one. And I'll save it. And now in our material instance, we should be able to see these texture coordinate values now here. And again, we can scale it. And this will mean that the normal map is scaling and the roughness maps or whatever maps we're using, they're all being scaled uniformly, which I think is the desired result"},{"start":"7:49","end":"8:08","startSec":469.4,"text":"that we'd want in this instance. So yeah, hopefully that shows you a really nice power of the material editor and just add in the customizable functionality of whatever you would like. Again, how to save the materials, making sure you're consistently saving. Just all these elements will help build out your material libraries."}],"17_Workshop- Creating an emissive material":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Now the last thing we'd like to cover before we close out today is creating emissive materials. And essentially emissive material can help with the global illumination of the scene as well. So we still start with a basic material and we just change the shading model to unlit. The unlit shader model uses fewer instructions than a default lit model and is often enough to define an emissive material. So we just want to multiply a color node and a constants mode which essentially gives us"},{"start":"0:34","end":"1:05","startSec":34.4,"text":"the intensity. Convert them both to parameters, create a material instance and then we'll test out the material. So that's the last kind of workshop for the day. Let's jump into the editor again and let's set this up before we close out. So back in our materials folder, I'm going to right click, I'm going to go to material, I'm going to call this M underscore emissive and hit enter. Enter again to open it up."},{"start":"1:05","end":"1:40","startSec":65.6,"text":"Now the thing that we do here differently than what you've done previously is without anything selected, you want to go to the shading model on the left hand side, go to default unlit. That will take off certain values here. So we want three nodes here. We want a vector three which hold down three on your keyboard. We want a constants one just to multiply this. So hold down one and then we also want a multiply. So hold down M on your keyboard for multiply. So three and left click, one on left click, M for multiply and left click."},{"start":"1:40","end":"2:14","startSec":100.2,"text":"Let's drag these into here. Let's create this basic setup straight into the emissive color. Now I'm going to convert this to a parameter and call this emissive color. I'm going to right click, convert to a parameter and call this intensity. I'll set the intensity to one by default and then I'll just create some kind of color just as our nice emissive color. Hit okay. Now let's just save this. Now we'll create an instance of this just because good workflow will keep maintaining"},{"start":"2:14","end":"2:44","startSec":134.5,"text":"what we've previously spoken about. So even though it's a quick example, we'll create a material instance. I'm just going to call this mi underscore emissive. Let's just call this, I might even just call this pink instead. You might call it 01, you might call it pink, whatever you'd like to call it. And we just want to make sure these are all ticked. Let's see what's happening here. So let's go inside. Let's go to our shapes panel."},{"start":"2:44","end":"3:16","startSec":164.9,"text":"Let's drag in a sphere here. Let's scale it into position. Let's drag and drop this emissive. And you'll see we're getting some illumination bounce. And that's a really nice feature of Unreal Engine 5 with the lighting system. So we're getting some bounce off the emissive here. So we might want to change this intensity to maybe make it a ball of light, like a sunlight or something like this. And you'll see that we instantly start getting this flood and this fill of color in the scene. So I'm just going to create a bit more real estate here just so you can see what's happening."},{"start":"3:17","end":"3:50","startSec":197.3,"text":"So again, because it's a material instance, we can change this at runtime. So if you wanted to change this in your scene at runtime, you could do so. Green is not the nicest color, but we'll go with it for now. But you can see scaling the intensity, really nice power over the scene or control over the scene, depending on what you like. And just using on the emissive materials, really nice way to just add a bit of flavor to your scene. So hopefully that's a useful little tip for creating unlit emissive materials."}],"18_Outro":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"So we've covered a lot of ground today. We've set up materials inside of Unreal. We've gone through the PBR pipeline and explained how to import content into the editor and talked about adding existing content from different sources. And then we've really deep dived into the material editor showing you just a Vector3 color material setup all the way into creating just this big pair of material that can house Albedo maps and specular maps, normal maps, etc."},{"start":"0:31","end":"0:48","startSec":31.2,"text":"As well as then having control over the UV functionality and even creating basic conditional statements using the switcher. And then we showed you a quick emissive tip as well. So a lot of ground covered. Hopefully it was all useful and interesting and we'll see you on the next course."}]},"102.03":{"01_Introduction":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Hello and welcome to today's Unreal Engine training, which is a quick start to blueprints for virtual production. So to give you a bit of an overview of the blueprints that we're going to be covering today, we'll be talking about blueprint usage and what blueprints are. We'll dive into the editor and talk about the different interfaces you'll expect to see within blueprints. We'll talk about the types of blueprints. We also have a concept called level blueprints, which we'll give more context to. And then we'll talk about blueprint classes along with other classes."},{"start":"0:32","end":"0:40","startSec":32.0,"text":"We'll talk about some basic scripting terms. We'll talk about interfaces and how you communicate between different blueprints. And then we'll also finish up with some inheritance."}],"02_Blueprint Usage":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"So we'll start off by talking about blueprint usage and blueprints are used to drive level based events. So they control internally scripted behaviors for in game actors and you can even control complex animations for game characters. So the blueprint system, you'll see these windows across many different editors, whether or even Niagara audio blueprints can be used to be the code driven driving block behind"},{"start":"0:34","end":"1:09","startSec":34.3,"text":"different real time interactions. So what are blueprints? So in their basic form blueprints are visual scripts that use to add new functionality to your game by connecting the nodes, events and functions, which is what you see in the images here with wires. So you can create some kind of intended interactive outcome. So you'll see that we have events which are setting these red nodes on the right hand side and then you'll see some kind of function based gameplay."},{"start":"1:09","end":"1:39","startSec":69.0,"text":"So the functions are the blue node on the top right hand corner, for example, connected to some kind of variable data. So you'll see these wires connecting and it's almost like a chain of events. You can follow the logic from left to right and get the intended outcome of what you want your blueprint to be. So we'll dive into the editor later in this course, but just to give you a bit of an overview of the interface you may expect to see inside of Unreal."},{"start":"1:39","end":"2:09","startSec":99.1,"text":"So when we open our blueprint editor, which you can do by clicking the node graph on the top of your editor and just go to open level blueprint, you can see that. But just to dig into a bit more detail here, so we have the text menus on the top, which you'd expect to see across all of Unreal Engine. But the bar that you'll be using a lot is on this number two section here. So you have compile, which every time you're editing a blueprint or changing the functionality,"},{"start":"2:09","end":"2:43","startSec":130.0,"text":"you want to make sure you compile and save and it just keeps the iteration going. You can ensure that although the code is working correctly and of course saving your work at frequent stages because especially when you're first getting familiar with blueprints and maybe you connect some nodes that may end up crashing or failing, you just want to keep that information safe so that if the editor does shut for whatever reason, you've not lost any work. We can browse content and find content and change settings slightly more complex."},{"start":"2:43","end":"3:13","startSec":163.6,"text":"A good thing to point out on the right hand side here is you can debug information as well. So when we get into the workshop, we can show you how to do that, but you'll very commonly be using the compile and save a lot in this section. Number three is where your components live. So a blueprint, say it houses multiple components. So say you had a vehicle in your production and you wanted to add some headlights to that vehicle. So you'd add maybe two spotlights to that vehicle."},{"start":"3:13","end":"3:46","startSec":194.0,"text":"Now the spotlights would be in this component list. So not only would the vehicle be there as a static mesh, the two headlights would then be there and you can see that any extra elements you're adding to that vehicle are all components. So say you added a separate door mesh or some kind of information inside the vehicle like some boxes or anything like this. These would all be components within this blueprint. Then you've got number four, which is your blueprint panel. So this is where all of your functions live."},{"start":"3:46","end":"4:16","startSec":226.3,"text":"It's where all the inputs. So we've got both an event begin play, which fires at the very start of the game. And again, I'm just giving an example here. We'll get into much more detail later on, but this fires at the start of the game and you can see the F key being pressed on the keyboard. So we can see event begin play on the left hand side and F as they're both inputs that fire during runtime. You've got your functions that live here and your construction script, which we'll be going into again in this course. And then this is where your variables live."},{"start":"4:16","end":"4:50","startSec":256.8,"text":"So you can create different variables, booleans, integers, floats, whatever kind of variables you need to drive some kind of gameplay conditions. Event dispatchers also live here and event dispatchers help with blueprint communication. It's almost like a message that gets sent out to another blueprint, which we will of course dig into. Number five is where all the main action is happening. This is where you're connecting your wires and your nodes to get the desired outcome. A few important things to point out here. Viewport will go to the visual view of what the blueprint is."},{"start":"4:50","end":"5:23","startSec":290.2,"text":"So say going back to this vehicle example from your components on the left hand side, if you go to viewport, you can then view that vehicle. The construction script is something that fires every time you compile the blueprint. So if you want any kind of custom editor functionality or some default property setting, the construction script is a great way to do that. The event graph will always be at runtime. So whenever you've got your main bit of the interactive experience that you're creating, that's where all of the blueprint will live."},{"start":"5:23","end":"5:56","startSec":323.1,"text":"And you'll see that we have almost like functional blueprints and then an arrow saying event graph. Each you can create sub layers and sub layers of blueprints. So you can almost nest blueprints within other blueprints. So you may even see multiple graphs appear in here as well. And then also you can open up your function, which is a print text function. So you can see this function over here, which says print text. And that also lives up there. So number six, this is where we can change all the details of the content that we've"},{"start":"5:56","end":"6:28","startSec":356.5,"text":"created. So in this example, we've created a new Boolean value down on the bottom left here. And then by selecting this Boolean value, you'll see that it's got a great naming convention new var underscore one. But then you can edit new var underscore zero, sorry, no, one here. So you can see that the variable types of Boolean, you can change a bunch of properties here, which again, we'll be digging into in more detail throughout this course. But that's just to give you a basic overview of the editor."}],"03_Types of Blueprints":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Next, let's go over the types of blueprints you may expect to see inside of Unreal. So there are several types of blueprints. You've got the level blueprint, which we referred to before. We've got blueprint classes, which are almost like a modular way to start building out your code. If you put it into a blueprint class, it means you can use it in many different areas, whereas a level blueprint is very specific to that one level that you're working on. You have data only blueprints."},{"start":"0:30","end":"1:01","startSec":30.8,"text":"Say you want to store some data, but you don't necessarily need the interactivity behind it. You can get that data only blueprint. You have blueprint interfaces, which we briefly touched on a couple of minutes ago, but a blueprint interface essentially allows you to communicate from one blueprint to another. You've got blueprint macros, which is almost like a wrapper for some scripting that you might have inside of a blueprint. So a macro can be repurposed in multiple blueprints if you wanted to."},{"start":"1:01","end":"1:34","startSec":61.8,"text":"The way to think about macros over functions, because functions and macros can be similar. You might see those terms quite frequently. Macros can actually house latent functionality. So what I mean by that is if you wanted to create this bit of code that you want to reuse in multiple places, it may have some kind of delay. You may have an event fire, say an explosion goes off and you want to wait five seconds and trigger a vehicle moving across the scene."},{"start":"1:34","end":"2:08","startSec":94.7,"text":"That can be stored in a macro because it has latent functionality. It has a delay in there, whereas a function would not be able to house a delay. A function has to fire through and process the code, but it can't wait for any kind of dependency on the functionality. So hopefully that does give you a bit of context over what macros might be. And then you've got animation blueprints, which again, very visual driven and it's almost like a state machine setup. And you can even communicate with animation blueprints into your level blueprint or another"},{"start":"2:08","end":"2:41","startSec":128.6,"text":"blueprint class. Say you want to trigger some certain code on maybe a character that's moving around the scene. You can do that through animation blueprints as well. So level blueprints and blueprint classes are what you're going to be using most commonly. So they're the top two examples. So again, level blueprint is very context specific to that level. So if you've got very specific functionality that's going on in that level, you can house that in the level blueprint. The way I like to think about it though, is if you're maybe making, again, going back"},{"start":"2:41","end":"3:15","startSec":161.6,"text":"to this vehicle moving across the scene or a door opening and closing, if you're going to reuse that door opening and closing across many different levels, you probably want to make a blueprint class for it because otherwise you'd have to keep remaking it every time on the level blueprint. Whereas a blueprint class, you make it once and then you can use it multiple times. So a level blueprint provides a control mechanism for level streaming, binding events to actors placed in the level. So again, we're doing some scripting that's very context specific to this level."},{"start":"3:15","end":"3:45","startSec":195.8,"text":"So it's a specialized type of blueprint that acts as level wide global event graph. Each level in your project has its own level blueprint created and is there by default and it's automatically saved when the level saves. So when you go to file save all, the level blueprint will remember all the data. And again, just as a reminder, you can click on the blueprint window here in your editor and go to open level blueprint. Blueprint classes on the other hand, often just referred to as blueprints."},{"start":"3:45","end":"4:17","startSec":226.0,"text":"When you hear people talking about using Unreal and blueprints, this is what they're referring to. So a blueprint class is an asset that allows content creators to easily add functionality on top of existing gameplay classes. So blueprints are essentially a defined new type of class or actor that can then be placed into different maps. So there's a door here, for example, that door can be its own blueprint actor. So you could duplicate that door and use it in many different places. You could even use it in different levels and that functionality would preserve and"},{"start":"4:17","end":"4:48","startSec":257.7,"text":"it would be housed inside of that actor rather than on the level blueprint. So a blueprint class is created and stored in the content browser and a blueprint actor is an instance of a blueprint class placed in the level. So you create all the functionality, you create the code inside of that blueprint and that houses inside of your content browser, which is your library of assets. And then when you drag and drop it into the scene, that has created an instance."},{"start":"4:48","end":"5:19","startSec":288.8,"text":"So if you edit that door inside of the scene, it won't actually edit the main version of the content browser. If you want to make any global changes to that blueprint, you'd edit the content browser version and not the version that's placed in the level. So when we're thinking about common classes in blueprints, you want to be thinking about what is childhood and what type of framework you're trying to create with your blueprints."},{"start":"5:19","end":"5:54","startSec":319.7,"text":"So if we take a basic framework here, which shows the hierarchy of common classes, the arrows indicate that the classes on the right is inheriting from the class on the left. So it's each one from objects. So if we take object on the left hand side, each one of them has been childhood from the object class. So object is at the top of the hierarchy and then you can create an actor based from an object and then just following the bottom flow, for example, a character."},{"start":"5:54","end":"6:26","startSec":354.1,"text":"So on the bottom right is charted from the porn class, which is charted from an actor class, which then is charted from an object class. So the object is the end point of where the character would have been created from and then you can get more specified functionality as you go down the chain to get the character actor. When you're working with blueprints, you should have a basic understanding of these scripting terms. When we referred to before compiling your code, that's got some kind of compiler built into"},{"start":"6:26","end":"7:00","startSec":386.9,"text":"it. So when a blueprint script has been created, it needs to be compiled. Going back to those two buttons that I said you'd be using frequently, compile and save, compile and save. So compiling is a process of turning this source code, which in our example here is the visual scripting. So we want to turn the source code into the machine language that can be executed by the CPU. So compiling requires the change depending on the hardware and operating system and a compiler is the software used to compile source code written in a programming language."},{"start":"7:00","end":"7:36","startSec":421.0,"text":"Blueprints are compiled to the bytecode level and processed by a virtual machine instead of the hardware. So a virtual machine is software that translates bytecode into instructions at the hardware you can understand and process and then you can also nativeize that code, which inside of Unreal if you ever need to nativeize blueprints, blueprints run slightly slower than C++ code. So if you really need to get maximum performance out of your production, you can actually convert blueprints to C++ by nativeizing these things."},{"start":"7:36","end":"8:10","startSec":456.8,"text":"Blueprint interface is a collection of one or more functions that can be added to other blueprints and then blueprint interfaces allow different blueprints to share the data to send from one another. So before I was referencing this blueprint interface and talking about how you can get an interface, you can implement an interface on two different actors. Say you have a light switch on the wall and you have a door that you want to open, you can actually add an interface both to the light switch and the door and then that will"},{"start":"8:10","end":"8:44","startSec":490.4,"text":"create a communication channel. Say you want to get some kind of value from the switch and pass it over to the door, you can do that through the use of interfaces. So a blueprint interface is an asset that's created in the content browser and you can edit it in the Blueprint interface editor. So I'll just show you quickly how you go about creating an interface as well. So to create your Blueprint interface, again you probably want to organize your content and put it inside of a Blueprint folder or sometimes I even create a Blueprint interface"},{"start":"8:44","end":"9:01","startSec":524.2,"text":"folder so if I just right click BPI, so I give it a capital B, capital P and then lower case i for Blueprint interface. So again this is just a quick example but you just right click in the empty space, go to Blueprints and select your Blueprint interface and that's how you get to the interface window."}],"04_Inheritance":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Moving from interfaces into inheritance. So a child class inherits all the variables, components, functions, events of the parent class. So a child class can override the settings and functions of the parent and change fundamental behavior. So a child class can also implement new functionality in addition to what inherits from a parent class. Let's think about a parent class as a vehicle."},{"start":"0:30","end":"1:06","startSec":30.1,"text":"So you've got a default template vehicle, it's just got a standard body shape, shall we say. It's got four wheels. You want some kind of driving functionality and you've housed all the default basic functionality of a vehicle and you can see that as a parent class. What you can do from here is you can right click on that blueprint, create a child class from that blueprint and then a new class will be created and it will house all of that parent functionality. But maybe now you want to add some car headlights or you want to create some additional behavior"},{"start":"1:06","end":"1:38","startSec":66.0,"text":"for this child class that wasn't in the parent class. So you can go ahead and do that. But now what if you want some additional functionality to this child? So you can create another child class of this child and maybe duplicate that three times and maybe now child A still has the headlights and it still has all the parent functionality but maybe you want to change the chassis now. Maybe you want to change the type of vehicle it is by changing the static mesh. You could change that on child A and it wouldn't change on child B. So you can maybe think of a different car type or a different body type on child B"},{"start":"1:38","end":"2:08","startSec":98.2,"text":"and it would still drive. It would still have all this parent functionality. It would still have its car headlights created in the child class but then you can then keep adding customized functionality. So whenever you find yourself creating maybe a type of interaction in a world or a certain thing that you might be using multiple times but then changing small bits of functionality on each one, it's a good practice to start thinking about housing something in a parent"},{"start":"2:08","end":"2:38","startSec":128.2,"text":"class and then creating child classes from that so that you can work efficiently. And also if a bug is in one for example, say you want to change the vehicle handling in this example, you can change it in the parent class and then that change would still migrate through to all the child classes as well. So instead of maybe if you had ended up with four different car types, instead of going in and changing each one four different times to fix this issue, you can just change it"},{"start":"2:38","end":"3:10","startSec":158.7,"text":"in the parent class and then that updates for everything else as well. So really powerful functionality. And then Unreal also uses inheritance in almost all aspects of design. So the actor class is a base class for all the objects that can be placed or spawned in the level. So lights, pawns, meshes are all child classes of the actor superclass. So going back to our example of the object before in previous slides, objects is the highest level in Unreal and then we go to actor and then say you're using point lights"},{"start":"3:10","end":"3:39","startSec":190.0,"text":"in your Unreal Engine scene. Well, a point light is inherited from a light class, which is inherited from an actor class, which is inherited from the object class. So you'll see this throughout Unreal. You can keep moving up through the inherited classes if you need that intended functionality. And then there's some additional resources on the documentation. So if you just look for Blueprint visual scripting in Unreal Engine, you'll be able to find many more resources there and these pages were put together by Sean."}],"05_Workshop- Working with Construction Scripts":[{"start":"0:00","end":"0:29","startSec":0.0,"text":"So, let's dig a little bit deeper into blueprints and let's talk about construction scripts. So, a construction script is a type of automation, which is a reason for a construction script. It's part of the event graph. It's got use and limitations and we will also put these lessons into practice in a workshop example just to really drive home what a construction script is."},{"start":"0:30","end":"1:02","startSec":30.4,"text":"What is a construction script and why should we use it? So, construction script is a special event that actor-based blueprints inherit and allows them to perform logic before being visible. So, whenever we compile our blueprint, the construction script will fire. So, it can fire at editor time as well. This means that when we have editable variables that are exposed and you can edit in the blueprint classes, it allows you to dynamically modify this blueprint based on"},{"start":"1:02","end":"1:35","startSec":62.8,"text":"logic and exposed parameters. So, in this example here, we're creating a series of conditions that when we hit compile and we move the blueprint, we can actually add some mesh functionality in the editor rather than at runtime. So, construction scripts can take a little bit of getting your head around, especially if you're not from a programming background, but they have some really, really powerful outcomes especially when building scenes and building sets and trying to think about how"},{"start":"1:35","end":"2:04","startSec":95.3,"text":"to speed up the workflow. Construction scripts can be a really powerful way of just really optimizing these pipelines. So, the visual script and event graph is the event graph that runs during gameplay including play and editor. So, as we were referring to before, these three windows in your blueprint graph, you've got your viewport, which you can see the visual representation of the blueprint. You've got your event graph, which houses all the main blueprints in this firing at runtime."},{"start":"2:05","end":"2:37","startSec":125.3,"text":"Your construction script is where you'll be putting any code that you want to happen every time you interact on the editor level as well. So, we can look at collision damage, movement, player interaction, events, spawning actors in the event graph. So, this is all stuff that's happening at runtime. So, when the players are interacting with things, firing off events, spawning things, these are all happening during the experience that you're creating."},{"start":"2:38","end":"3:08","startSec":158.1,"text":"The construction script, however, runs before the game is running. Including in the level editor viewport. So, we can add components here, we can change parameters, we can assign asset reference, we can build geometry and other components. When I was talking about improving processes and pipelines and thinking about tools that you can use at editor time to improve your pipelines and processes, the construction script is a really, really strong way of doing this."},{"start":"3:08","end":"3:41","startSec":188.8,"text":"So, by default, the construction script runs at the following time. When the actor is first placed in the level, so if you drag and drop a blueprint into a level, the construction script will fire. So, by dragging and dropping from the content browser, that's what will happen. When the blueprint class is compiled, so again, when we compile and save, the construction script will fire. And even when you instance the actor is moved around the level, talking about that inheritance from before, the construction script will fire across these instance actors."},{"start":"3:41","end":"4:15","startSec":221.1,"text":"So, you can stop this by setting a run construction script to false in the class, if you don't want that construction script firing, but it will by default fire on instance actors. And then when the level is loaded with an instance actor in it. So, it will also fire when you hit play, but the powerful functionality is strong during editor time. So, it's one thing talking about the functionality of construction scripts and especially knowing"},{"start":"4:15","end":"4:46","startSec":255.1,"text":"how complex they can be. The theory is great and good to know, but let's dive into creating a blueprint with some construction script functionality so you can see exactly what's happening here. So, we're in our editor, we're just in a default map. It can be whatever map you need. What we're going to do though is we're going to create a new blueprint class. So, I'm going to in my content, I'm going to have a BP folder. Again, just to keep organized, you don't need to do this."},{"start":"4:46","end":"5:15","startSec":286.3,"text":"It's not going to break anything if you don't, but I like to have a blueprint folder. I'm going to right click inside of this empty space. I'm going to go to blueprint class at the top here. And I will select actor, which is going to be nine times out of ten, most likely the type of functionality. You just want an actor-based blueprint for this example. And I'm just going to call this BP underscore construction example."},{"start":"5:16","end":"5:52","startSec":316.8,"text":"It doesn't matter what you call this. Something to highlight is I like to use BP underscore as a naming convention. And again, whatever prefix you want for your blueprints, that's fine. As long as they're consistent across the team that you're working with or across the projects that you're working on, I would keep a consistent prefix there. But either way, we'll double click this blueprint to open it. And then the first thing we want to do is go to our construction script. So, our construction script is on the top of the window here, just inside this viewport."},{"start":"5:52","end":"6:23","startSec":352.8,"text":"So, clicking construction script and you should see this construction script. So, I'm just left mouse dragging over that. Now, to move around my blueprint, I'm just holding down right mouse button. I want to create a variable, first of all. So, I'm going to go to my variables tab on the left-hand side here. I'm going to click plus. And I'm going to call this how many bushes. So, I'm not going to put a space in my variable name. But what I am going to do is I'm going to capitalize each letter."},{"start":"6:23","end":"6:55","startSec":384.0,"text":"And I'll show you why I do that in a second. So, I've just hit enter and then click on Boolean. And what I want to do is I want to make sure it's an integer. So, just an integer there. Now, what I'll do is I'll hold down control while hovering over the variable. And then I'm going to go into left mouse drag and let go. Now, you'll see that it's got spacing between how many bushes. And it makes the naming convention easy to read. Now, you could do spaces."},{"start":"6:55","end":"7:27","startSec":415.3,"text":"You don't need to do this, by the way. But just to show you, you could do a space of how many bushes and hold control and drag it across. And that's still fine. But it's just good practice not to have spaces in your variable names. It'll still work, but it's just not really good practice. What you can also do is just not capitalize it. But what you'll see very quickly, if I just say how many bushes, one. And I'll drag and drop that in. It just makes it harder to read."},{"start":"7:27","end":"8:02","startSec":447.5,"text":"So, that variable versus that variable, it's just better to capitalize, in my opinion. So, just some good naming conventions there. I'm just going to delete what I created. And again, let's just compile and save. Just let's get into the habit of compiling and saving. So, what we want to do, we first want to make sure it's visible. So, we're going to click this variable and then compile and save. And then what I'm also going to do, just for organization, I'm going to create a category. And maybe I'll call this construction script."},{"start":"8:04","end":"8:39","startSec":484.7,"text":"And now it's got a category called construction script here. So, if you start creating blueprints, you'll find yourself creating maybe 20, 30 variables. And if you don't start organizing from when you first create a blueprint, and get some weirdly, excuse me, and you just want to keep things organized as you go. So, again, let's compile and save. And let's just get into the habit of compile, save, compile, save. And then what we want to do is on our variable, we'll type 5. So, in this example, we're going to create a series of bushes from a construction script."},{"start":"8:39","end":"9:09","startSec":519.3,"text":"And so, I want to create 5 in this example. So, let's drag off and create a for loop. So, from this execution pin on the constructor, I'm just going to left mouse drag and type for loop and select the for loop. I'm going to move that into position. And on the first index, I'll type 1. And on the last index, I'll drag and drop how many bushes into that. So, it's between 1 and 5 because 5 is on our variable here."},{"start":"9:09","end":"9:40","startSec":549.6,"text":"So, what we want to do is we want to add some kind of random vectors to these bushes. So, they get randomly placed around. So, I'm going to right click in empty space. I'm going to type random unit vector. Select that first one, random unit vector. I'm just going to hit enter on my keyboard. And then, I'm going to multiply this. So, I'm going to drag off the yellow pin. I'm going to hold down shift and number 8 on my keyboard for a multiply sign."},{"start":"9:40","end":"10:11","startSec":580.7,"text":"It's a little star sign on my keyboard. And then, multiply. You can type in multiply. But for any kind of math driven stuff, if you want to type, you know, equals or hold down shift and equals, which is a plus key, you can do the math base command. So, I'm just going to hold down shift and number 8, which is the star key on my keyboard. I'm going to multiply there. And then, we want to create a float to a variable and call it modifier."},{"start":"10:11","end":"10:41","startSec":611.2,"text":"So, I want to then right click the node here on the bottom left. I'll convert the pin and I'll convert it to a float, which is a single precision one. So, there we go. We got our float variable here. Now, what I'll do is I'll get my green float box here. I'm going to drag off it to the left. I'm going to create a variable. So, I want to promote it to a variable. So, I'll click that and it's automatically highlighted this text here."},{"start":"10:41","end":"11:20","startSec":641.6,"text":"So, if you've clicked off it, just click on it again or right click to rename. But I'm just going to call this modifier. And again, I'm going to set this category just to keep things organized. So, I'll just go to construction scripts. I'll compile and save just to make sure we're still happy here. I'm going to move this modifier. And that's our getting to our basic functionality now. So, keeping things organized, compiling and saving. And then, what we want to do is we want to find the different x, y, and z values of this vector."},{"start":"11:20","end":"11:51","startSec":680.4,"text":"So, I'm just going to drag off here. I'm going to break the vector. I'll just create a break vector here. You don't need the 3f. I'll just break the vector and move that into position. And now, what I'll do is I'll drag off x and make vector as well. So, I just want to make the vector again. Now, why am I breaking and then making it straight back? So, if I drag and drop into the y here, now I've got my x and y coordinates. What you'll notice is we've broken the z."},{"start":"11:51","end":"12:23","startSec":712.0,"text":"We don't want to connect the z because if we're placing these brushes, we want them placing along a flat surface. In Unreal Engine, x and y are the two horizontal vectors. z is the vertical vector. So, we don't want anything being changed in z. So, we've got that set up and then we want to create an add static mesh component. So, off the loop body, I'm going to drag off here. I'm going to add static mesh component."},{"start":"12:23","end":"12:53","startSec":743.0,"text":"So, again, this is a construction script. Sorry. We can add static mesh components at compile time. So, we can see these appearing in the editor without playing, which is really powerful functionality. So, from relative transform, we can go into the return value of the mate vector and it will automatically convert that for us. So, we want to make sure that. So, it goes from a yellow pin, which is a vector. Into an orange variable, which is the transform value."},{"start":"12:54","end":"13:26","startSec":774.8,"text":"And then that sets up our basic construction script. So, we'll still need to assign a mesh. So, let's save, compile. And let's make sure our modifier is at least one, for example, let's say. We'll expose this as well, just in case. Well, actually, I'll show you what happens if we don't expose it. So, let's just save. I'm going to drag and drop this next to my map example,"},{"start":"13:26","end":"14:01","startSec":806.3,"text":"just so it's easy to switch between the two. I'm going to find a static mesh in my content browser. So, I'm just going to go to the content. You can pick whichever mesh you'd like to use here. I'm just going to filter by static mesh. I'm just going to find something to use. Maybe it's a pillar. Let's use a bush, for example. This will work with any static mesh, though. I go back into my construction script. I go to the add static mesh component, and I'm going to put a mesh into here."},{"start":"14:01","end":"14:36","startSec":841.2,"text":"And then I'll compile and save. Now, what I'm going to do is I go back to my blueprint folder. If you've added any filters here, you just want to remove them by clicking them. And then what you can do is you can drag and drop into the scene. So, what we'll do is we'll duplicate this. And so, you'll see that, first of all, how many bushes is five here. And what you'll notice is we don't see the modifier functionality."},{"start":"14:36","end":"15:07","startSec":876.1,"text":"So, if I go back into the construction script, on modifier, I can promote this variable and expose it. So, variable is now public. If I compile and save, now you'll see that modifier value, which is going to be really powerful because now we can add light color properties, or we could change many different variables at runtime. You can change these per instance. So, if I say how many bushes and I want two, for example,"},{"start":"15:08","end":"15:39","startSec":908.4,"text":"that still stays at five. Five is still there because it's an instance. When we're talking about instancing on the level script, each one of these can house its own variable data now, which is really cool and powerful functionality. Then the last thing we want to do is just change the modifier value. So, say you want two bushes and say the modifier is 50, for example, or maybe 100. That will still have two bushes, but now there are 100 units apart."},{"start":"15:39","end":"16:13","startSec":939.7,"text":"So, for example, in this five-bush one, let's say 300, and that will make five bushes 300 units apart. So, you can see all the powerful functionality. And the constructor will fire every time we move the blueprint around, which we mentioned in our previous slides. The constructor fires whenever you move it in the blueprint. So, this is really powerful functionality, especially when you're trying to place grass along a hill. You can just keep duplicating. So, I'm going to hold Alt and left mouse drag on the widget."},{"start":"16:13","end":"16:44","startSec":973.4,"text":"And you can imagine the powerful use here, where maybe you have exposed the static mesh property, for example, or maybe you expose the scale. So, you can, as they're constructing, maybe you scale a mesh between 0.2 units and maybe three units. So, not only are they randomizing the location, but they're also randomizing the scale. You could even randomize the rotation so they get different values."},{"start":"16:44","end":"17:10","startSec":1004.5,"text":"You could add slight pitches and change the yaw so that they just have a very random feel to the place in the bushes. So, again, constructor can be super powerful. I hope that was a good introduction to the construction script. It's definitely worth playing around and really figuring out how to use that construction script because, again, it can improve those processes massively."}],"06_Workshop- Working with Camera View Targets":[{"start":"0:00","end":"0:29","startSec":0.0,"text":"Next up, let's create a camera switch blueprint and with the blueprint what we'll do is we'll set up a view target with some kind of blending going on so you can figure out how to set cameras and blend from one camera to another. We'll use a flip-flop node which is essentially a pick A and then pick B output and then repeat itself so it goes A, B, A, B. We'll talk about arrays and how to use arrays so that's"},{"start":"0:30","end":"1:00","startSec":30.1,"text":"a series of cameras in an array and then we'll talk about the multi gate node which can essentially fire a different output with each input coming in. So say you have a flow of information coming into a gate you can say okay output gate one, output gate two, output gate three and it's essentially just helps figure out your flow within Blueprint. And again we're going to create a new Blueprint so I'm just going to right click and going"},{"start":"1:00","end":"1:35","startSec":60.6,"text":"to go to Blueprint and I'm going to select actor first and I'm going to type BP underscore camera switch. Then the name doesn't necessarily matter so whichever you'd like to do I'm going to hit enter to open it or you can double click. I'm just going to make sure I save it first and foremost. So the first thing we want to do is figure out how to change the view target with a blend. So we want to blend maybe from the player character to a different camera that's based"},{"start":"1:35","end":"2:05","startSec":95.4,"text":"in the scene. So I'm going to go to the event graph. I'm going to find some new space just right clicking and moving around. I'm going to first get player controller and the player controller so this bottom option here get player controller. Want to select that and the camera data for the player inside of Unreal is housed on the controller so whenever you want to interact with the player's camera you want the controller"},{"start":"2:05","end":"2:39","startSec":125.6,"text":"here. So we're going to drag off the blue line here and we'll type set view target with blend. So I'll hit enter there and so we've got a view target from there. Now what we want to do is we want to figure out what camera we want to be setting the blend to. Now if I had done this in the level blueprint I could just directly select a camera from the level but there's no way to select a camera currently. If I go into my map and if I go to the cinematics tab here on the place actors so make sure"},{"start":"2:39","end":"3:12","startSec":159.5,"text":"you have place actors which is just a select mode. I can find a camera actor, I can right click, I can pilot the camera and I can just put it into some kind of location where I say I want to blend to this camera. Now if I want to eject out of there now just by pressing that eject button on the top left I'll call my camera something I'm going to call this wide shot even well it's a medium close up but let's call it a wide shot on the bushes."},{"start":"3:12","end":"3:44","startSec":192.5,"text":"So I've given my camera a name but even if I have this selected I can't now add it to my blueprint. If I right click I can't add it to my blueprint whereas if I went to my level blueprint so I go to blueprints up here open level blueprints and if I right click in some empty space I have a direct reference to the bushes camera because this is the level blueprint. This untitled here is referencing this untitled map name and so I have direct control so if"},{"start":"3:44","end":"4:16","startSec":224.0,"text":"you're only doing something level specific it's a much cleaner and faster workflow just to start adding stuff inside of this blueprint whereas if you want to do it through a blueprint we're going to have to create a reference inside of this camera switch. So what I'm going to do is I'm going to open up the BP camera switch if you don't already I'm going to go to variables I'm going to click plus variable here and I'm just going to call this maybe camera ref one it doesn't matter necessarily what you call this as long"},{"start":"4:16","end":"4:51","startSec":256.3,"text":"as it's a consistent name so I'm just going to go to camera ref one as we've done previously let's just give it a category straight away so I know I can keep everything organized so I'm just going to give it a category of cameras and what I want to do is change the variable type to a cine camera so the cine camera variable type is this actor and now what I'm going to do is I'm going to create a soft object reference so if I hover over cine camera actor you can create an object reference I prefer to use soft object reference"},{"start":"4:51","end":"5:27","startSec":291.8,"text":"the reason for that is because the top object reference is a hard reference. takes longer to process hard references and if the hard reference gets broken it can crash your projects whereas if you use a soft object reference Unreal knows which reference it should be using but it won't cause as many issues so moving forward just a good tip and workflow practice is to create soft object references where you can so I'm going to click create soft object reference I'm going to expose this variable as we did on our bush blueprint so"},{"start":"5:27","end":"6:02","startSec":327.2,"text":"and then I'm going to compile and save and now if I go back into my map and I say let's drag and drop the camera switch actor in here I just move it into a location and sometimes what I do as well this isn't functional this is purely aesthetic so it's up to you if you do this but the BP underscore camera switch I'm going to add a component on this component I'm going to type billboard I'm going to add a billboard and by default it's called billboard I'm just going to"},{"start":"6:02","end":"6:37","startSec":362.9,"text":"call this icon now if you want to assign custom sprites you can do by default this is a dinosaur head which is a legacy Unreal Engine sprite but what I'm going to do is oh I'm going to drag and drop the icon over the default scene root so I want to replace the scene root with this icon now when I compile and save I have this little dinosaur head in my map so again you could create your own icons for this camera switch blueprint and so you know exactly where this blueprint is placed completely optional has no functional consequence other than usability but"},{"start":"6:37","end":"7:15","startSec":397.7,"text":"that's a really good good tip to use what we'll see here though is we have a camera ref one here which is what we called our first variable and it's got non selected now it's going to be very easy to select the the first wide shot from this list if I click down the list because I've only got one camera if you've got a map with say a hundred cameras you could search the specific reference but if you're not sure what name you need you can also just pick the actor from the scene so I'm going to select the pick actor from scene and I'm going to click that so now we've assigned wide shot bushes to camera ref ref one what we want to do now is we want to add some kind"},{"start":"7:15","end":"7:50","startSec":435.2,"text":"of event that fires when we load up the level so for now what I'll do is I'll just go and begin play so if I actually just play this map to show you what happens first and foremost if I click play nothing happens I've just got a fly around viewport I've just got some default game mode if I go back and I've just hit escape there just to come out of it so if I go to BP camera switch I'm going to right-click type begin play hit enter and then I'm going to drag off begin play set view target"},{"start":"7:50","end":"8:22","startSec":470.7,"text":"which is I'm going to compile and save now we just need to set a new view target now I'm going to hold ctrl and left mouse drag to camera f1 and because it's a soft reference we could create a hard reference which would have been blue to blue but because it's a soft reference we first need to drag off and resolve this so just type resolve hit enter now it creates a blueprint blue pin sorry so this soft object reference resolves itself to say yes I exist now this is"},{"start":"8:22","end":"8:53","startSec":502.2,"text":"the reference if it was a hard reference you could get validity issues if the camera reference gets lost at any point by that I mean if that for example doesn't get filled out by someone and it says a none that's a hard object reference to no cameras which can cause a project to crash whereas if it's a soft object reference even if it was none you'd be fine unreal would just it wouldn't work because there's nothing plugged in but it also would prevent stability issues but we"},{"start":"8:53","end":"9:28","startSec":533.7,"text":"do know what our camera is we want to create wide shot bush we have a camera f plugged in here we have our set view target I'm going to compile and save and now I'm going to play and we instantly have that wide shot of the bushes and that's because it's fired on begin play so we can add some more complex functionality for now but for now it's quite a lot of powerful blueprint functionality going on we've got some kind of camera switch manager going on we've created a camera reference and we've also got variables connected to this blueprint which can add some"},{"start":"9:28","end":"9:31","startSec":568.7,"text":"starting functionality for a camera switch blueprint"}],"07_Workshop- Working with Flip Flops":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"So next up we'll add some flip-flop node functionality. So unlike a gate function this allows you to only cycle through two options. Whenever there's an input execution on this left hand side it'll fire out A and then it'll fire out B and then it'll return to A so it'll go A B A B every time it's entered. So there's some more documentation on flow control if you'd like to follow up but let's"},{"start":"0:30","end":"1:03","startSec":30.6,"text":"go ahead and add some flip-flop functionality into our project. To start thinking about how we will use a flip-flop we need a way to have multiple inputs instead of a single begin play. So we'll replace begin play with a keyboard input instead. I'll right click and for this I'll just use a hash key because it's easy to find. You can add any keyboard event you want. It's sometimes hard if you wanted like the C key for example you'd have to scroll through all these to find an input called C but a quick way as well is if you right click hit"},{"start":"1:03","end":"1:36","startSec":63.3,"text":"hash key and add a keyboard element hash you can also click this button here and then say C from there and it'll override to C. So that's just a quick way I always just right click add a hash key and then change it to whatever I want because it's the quickest way to get there. So completely up to you what workflow you use I'm just going to delete C and keep my hash key. I'm going to move the hash key to the left a bit. If you have these around I'm just going to select them and delete and next I want to"},{"start":"1:36","end":"2:08","startSec":96.1,"text":"add a flip-flop. So I'm going to drag off pressed and type flip and then you'll see a flip-flop so I'm going to hit enter with it selected there at the bottom. So we've got a flip-flop we'll go from A into the first view target and we'll go B into the second view target. Now we can change the blend times if we want or the blend exponents they will edit the blend time so you'll transition from one camera to another instead of snap. For this example I'm just going to keep the snap functionality though."},{"start":"2:08","end":"2:38","startSec":128.1,"text":"So I'm going to copy which is ctrl C and ctrl V for paste. I'm going to drag the controller into the target here. I'm going to go from B into the execution input. I'll drag the controller somewhere which is a little easier to see and just so we keep things nice and organized. Now the next thing I will do is add another camera reference actor. So you can right click and duplicate."},{"start":"2:38","end":"3:10","startSec":158.1,"text":"I like to just create a new variable and call it camera ref 2. I'm going to give it a category and you want to make sure that the variable type is that cine camera again. Again I'm going to use a soft reference. The reason why I don't duplicate and I instead opt to create a new variable. I've just found in the past if I duplicate some variables with soft references and when we package them into projects I just end up with some bugs sometime in the referenced"},{"start":"3:11","end":"3:41","startSec":191.0,"text":"variables here. So not quite sure what workflow that is but I always just create a new one. You'll see that it's not got camera ref 2 there. So I'm just going to jump back in. I'll expose that property then compile and save. Now the last thing we want to do is add well I guess before that we need to add our camera reference. I've just noticed that so I'm going to hold ctrl and mouse drag. The reason why I hold ctrl is just if I just left mouse drag it says get offset."},{"start":"3:42","end":"4:17","startSec":222.1,"text":"If I hold ctrl and drag it it'll get it and if I hold alt and drag it'll set. So that's like a nice little tool tip. You just want to make sure that's resolved again. So drag off there hit resolve. Go to new target. Now by default actors don't consume input so you won't be able to press this button by default. If I compile and save and I go into my map and I hit alt and p to play and I hit the hash key I can see nothing is happening. Now the benefit over a level blueprint is if I and this is again just found by going"},{"start":"4:17","end":"4:48","startSec":257.5,"text":"to the level blueprint. If I added an input here that would work perfectly fine. And so if you want some kind of user input the level blueprint can sometimes be the easiest approach. But because I want to keep this contained within this blueprint what I'm going to do is I'm going to right click add another begin play event. I shouldn't say another. You can only have one begin play event but because in a blueprint sorry but because I deleted it previously for the hash key I can now use it for something else."},{"start":"4:49","end":"5:20","startSec":289.3,"text":"I'll get a reference to the player controller. So I'll just control C and control V. I could have dragged a wire up there but it's just going to get turned into spaghetti. And then on the player controller I just want to enable input. Now this is a little bit of a hacky solution. I'll just hold down control and move that input to player controller. Just to make sure. There we go. So I've dragged that. I've got a wire going into player controller. Compile and save. And it is a hacky solution."},{"start":"5:20","end":"5:51","startSec":320.8,"text":"For these kind of projects it's fine because you're not going to be relying on any kind of game architecture. But in a video game for example you wouldn't want to do this. This just would override it in ways that wouldn't be reliable when moved into the code. So we just want to test this now. So I'm just going to make sure you compiled and save. I'm going to jump into my map. I'm going to hit alt and P or you can press the play button at the top. I like alt and P just gives a quick shortcut."},{"start":"5:51","end":"6:25","startSec":351.0,"text":"And now what I want to do is I want to press hash on the keyboard. And so we have got functionality. The main remaining thing to do now is just add a second camera. So I'm going to select my camera that I have. I'm going to hold down alt and drag. I'm going to right click. I'm going to pilot it. I'll just put it into a new location. Maybe this is extreme close up. I'm going to eject. Maybe I'll call this close up bushes now. Again the naming for this specific project isn't necessary but just to keep things organized."},{"start":"6:25","end":"6:55","startSec":385.8,"text":"It's good to just organize as you go. I'll set my dinosaur head. I'll go to my camera ref 2. I will assign the camera ref 2. And let's hit escape just because I don't like having things selected whilst in editor. I'm going to hit alt and P to play. I'm going to hit the hash key. And there we go. And if I hit hash again it snaps to the second camera. And the great thing now about the floor control is if I hit hash again so it keeps flip flopping and flip flopping."},{"start":"6:55","end":"7:27","startSec":415.9,"text":"So a bit of bonus for you now. Not mandatory but in case you didn't have anything working for example we can go into the camera switch. I can drag and drop the window down into some different real estate. I go back into my map and depending on where you've got your window you might be able to see this drop down. Or if it's a smaller window you can just go to the arrow keys and make sure that this down here. I'll just try and select it."},{"start":"7:27","end":"7:58","startSec":447.6,"text":"The property at the bottom says BP camera switch. Again just dragging it out here. The real estate of my screen isn't allowing that interaction but if I just drag it out here I want to make sure BP camera switch is selected which the debug object is in this dinosaur head. This is called BP camera switch and debug is on BP camera switch. Now what I can do is I can zoom out and just again I'm just trying to fight with the real estate of my window here but I care about this section here."},{"start":"7:58","end":"8:29","startSec":478.1,"text":"So you'll see now when I jump in I can debug this and show that the inputs are firing. So if I hit Alt and P now if I press hash you'll see that first line firing out to the set view target in the bottom of my screen here. Second line is flowing out to the B and so we keep going A B A B A B. So we can see that control working and it's also just a nice way to introduce debugging into your scenes if something isn't working."}],"08_Workshop- Working with Arrays":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Next up, we'll talk about arrays. So just with the variable values, blueprints can store data within arrays. So if you're not versing programming, you can think of an array as a collection of variable all housed within a single unit. So whereas a single integer was just able to store one number, an array of integers would be able to store multiple values. So an array can only hold values of a single type. So if we've created an integer, you can only hold integers in here."},{"start":"0:33","end":"1:03","startSec":33.0,"text":"And array variables will contain 3 by 3 color grid, which is what you can see in the image here to show that they are arrays and not regular variables. So in the case of a disconnected array, that gray will have a darker center. So once centered, once connected, sorry, the entire grid will be visible as seen below. And then to create them, we can just click on this variable icon, drop down to array. So let's go ahead and add some more functionality to our camera switch mechanic now."},{"start":"1:03","end":"1:36","startSec":63.4,"text":"And once back in the editor, I can full screen this window again, drag it up to the top. And let's create an array from this switch here. So instead of flip flop in between the two, now let's try creating an array of cameras to view our lens through. So I'm just going to remove the flip flop for now. I'm just going to click it and delete it. I'll just be focusing on this one view target for now. And instead of connecting to a single camera, I'm going to hold down alt and disconnect"},{"start":"1:36","end":"2:10","startSec":96.9,"text":"this camera ref one. I am just going to drag it over here. I'm going to hold down alt on camera ref two and just drag it over there as well. You can also just right click and break links if you need to break a link. Now what we'll do is we will make an array from these cameras. So I'm going to drag out of this camera. I'm going to do make array. So let's just try array. So you just want to select make array there."},{"start":"2:10","end":"2:41","startSec":130.9,"text":"Drag that into place. And we want to add a pin. So I'm going to use maybe three or four different cameras for this. So let's just add pin, add pin, add pin. I'm going to drag this into here. And now let's create a few more, well, two more camera reference. So camera ref three and then camera ref four. I'm going to make sure I categorize these into the cameras."},{"start":"2:41","end":"3:11","startSec":161.2,"text":"Again not necessary, but it just helps keep things organized. And you want to make sure you click the little i to expose them as public variables. So I'll compile and save. And then the first thing I'll do is I'll just create a couple more cameras. So I'll maybe create a top down shot here. So pilot. I'll eject here. I'll just rename this. Top down bushes."},{"start":"3:11","end":"3:42","startSec":191.6,"text":"And then maybe just do an extreme close up for some reason other than non practical purposes. So it's even out of focus, but extreme close up bushes. And I'll also click my dinosaur head. And then I'll select my top down camera as my next camera. And I'll select my extreme close up as my next camera."},{"start":"3:42","end":"4:12","startSec":222.2,"text":"So got four camera references, four cameras assigned. Now we can jump into doing the array. So I'll go back into my camera switch. I've made my array. I can drag out these references holding down control on my keyboard. I'll just copy and paste these resolves. Not with extra variable selected, so just variable copy and paste, copy and paste, which is just control C, control V on the keyboard. Drag out here."},{"start":"4:12","end":"4:42","startSec":252.3,"text":"We've got our array connected up. So you should see something like that. Then what we'll do is on the array, we'll get. So we'll get a copy. So what this get will do is it will say from this list of cameras, get a specific variable. So what we want to do is we want to promote this one now to get camera. So I'll drag off here, promote it to a variable and I'll call it get camera."},{"start":"4:42","end":"5:14","startSec":282.7,"text":"And now this is actually an integer and we want it to be an integer. So that's fine. And I'm just going to give it a category of cameras. So it keeps things nice and organized still. Now because we're getting a specific camera reference, we can say new view target is this one. That will actually say, depending on the list of what you want to do, you can get a specific camera from this list. So if I put this in here and I tested it out and I said, say I wanted to expose this, get"},{"start":"5:14","end":"5:44","startSec":314.2,"text":"cameras, compile and save. And you could say in your blueprint, get camera two, for example, and it would only display camera two. So that's pretty powerful functionality in itself. And so let's just test that out. Let's do, let's connect this in. Let's do this. Compile, save. I'll click number two on here and it'll set a specific camera for us when we hit the hash"},{"start":"5:44","end":"6:14","startSec":344.5,"text":"key. So there you go. It's got camera two from the list, which is our top down camera. Just worth noting in mind, camera ref three is our top down camera. Number two, you might be thinking that it should have been the close up. Now, a thing to note about arrays is that it actually starts at zero. So it goes zero, one, two, three. So if it helps name things in your head more clearly, if you put camera ref zero, camera"},{"start":"6:14","end":"6:48","startSec":374.6,"text":"ref one, two and three, that's fine. But in case your integers are off by one, that'll be why, because arrays start at zero. If we go back into our camera switch, you'll see make array is zero, one, two, three. That's just something to keep in mind there. And then finally, we'll talk about multi gate cameras. So instead of using an array, we can use a multi gate, which is essentially just a flow of information. A gate will choose which camera to set. So I'm just going to hold down alt and drag out, move this into its own space."},{"start":"6:48","end":"7:18","startSec":408.5,"text":"We'll be using multiple set view targets again. So I'll keep that here. I'm just going to copy and paste that third view target just so we have more to play with. And I'm just going to drag that into the target just so we can see that happening. I'm just going to get organized here. So what we want to do is we want to add a multi gate node now. So we'll type in multi and we'll select the multi gate from the list."},{"start":"7:18","end":"7:51","startSec":438.7,"text":"We'll add a pin. So we've got out zero, out one, out two. And we'll just select these two, the desired cameras, the desired view targets, shall we say. And then I'm going to copy and paste the camera references that we had before and just plug them into their respective view targets. So again, you can drag out each variable individually if you wanted. I'm just going to copy and paste them since we have them from the previous example. And then what we want to do is after we've plugged them all in, create a switch camera"},{"start":"7:51","end":"8:32","startSec":471.2,"text":"from the loop. So if we drag off the loop here and then we want to promote it to a variable, we can call this switch cam. Again, I'll just keep it in its category so we know what this is. And then we want to create a scene switch from this float value here. So I'll drag off again from the index and we'll promote this to a variable and we'll call this scene switch and I'll assign it a category again and then compile and save."},{"start":"8:32","end":"9:02","startSec":512.0,"text":"And then I'll expose these just as we had before just in case we need extra functionality And we could do our event. Instead of cameras, we could try assigning multiple categories. Could even call this something like multigate. And so I know that these variables are connected to the multigate just in case that separation is of use to you. And then we just want to compile and save. So we can do that and then we'll jump into our level."},{"start":"9:02","end":"9:33","startSec":542.4,"text":"Once you've saved and compile, you'll see that the multigate heading is here. So we've not got switch cam or we've not got scene switch set. So we can again use that blend time if we wanted to between the cameras. If we just go ahead and set this actually, let's set this to a value of one, value of one, value of one. We can use a blend time for motion between cameras. So we could even just test that out in this example."},{"start":"9:33","end":"10:04","startSec":573.1,"text":"So if I hit Alt and P now and press hash, we then pan to that one and then we go to the next target and then we go to the next one. But now if I press hash again, it's not going to work because what we did was the switch cam was not ticked, which if I go into here and I go into my multigate, the loop was not ticked. I can do this loop as well, but call it switch cam for now."},{"start":"10:04","end":"10:36","startSec":604.2,"text":"But if we want to tick switch cam, which I'll do in here. And again, you saw the blending, which was a good example of the camera blending as well. But if we hit hash, first camera, second camera, third camera, and then back to the start as well, which is a really nice, powerful functionality. And then you've also got the start index where, you know, if we wanted to start one, for example, compile and save. And again, we could have changed that on the actual actor as well."},{"start":"10:36","end":"11:10","startSec":636.4,"text":"If we hit Alt and P, we hit hash, we can start at a specific part of the chain. So we're starting here on the second camera, third camera, back to the first one, second one, et cetera. So multigates again, pretty powerful functionality. If you're trying to have multiple outputs, you can start at a specific index and you can also keep looping through. And we could add things like re-triggerable inputs where it's just constantly firing. But hopefully all of these different examples just gave you a good idea about Blueprint"},{"start":"11:10","end":"11:14","startSec":670.1,"text":"and the functionality that you can have when working inside these tools."}],"09_Creating BPs for Precomputed Lighting":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Next up we'll talk about creating a blueprint for pre-computed lighting and what we'll cover here is we'll talk about some level streaming and we'll give you an overview of the walkthrough and how you may go about setting up different lighting scenarios. So in an empty map here I've just called my map level streaming and for this purpose it's important to know about naming conventions and what we're streaming here."},{"start":"0:32","end":"1:05","startSec":32.9,"text":"It's completely up to you what you call them but you just need to make sure they're consistent. So the first thing I'll do just to show you an example of this even though this isn't necessarily lighting I'm going to show you a post-process example here. So what I'll do is I'll just make sure this isn't ticked by default, yours shouldn't be ticked by default and then I will first type unbound into my post-process and I will tick that and it essentially just means the post-process affects the entire world and"},{"start":"1:05","end":"1:35","startSec":65.5,"text":"then I will go to scene color tint which is under the miscellaneous tab inside of color grading I'm just going to give this a color say of pink and then just so you know what properties have changed what's a useful button to click is the settings option here and if you show only modified properties I like this functionality when you're trying to dial in certain properties that you've already adjusted it kind of cleans up the menu a little bit so up to you if you want to use that."},{"start":"1:35","end":"2:09","startSec":95.7,"text":"What I will do is I will go to the levels tab and if you don't have this levels tab open by default you can just go to a window and then you just want to make sure levels is selected there and you can drop it in whichever window you would like and then I will go to levels and create new I'm going to create an empty level and I'll create it and my first map was called level streaming which you'll see at the top there so I'm still going to call this level streaming and then I'll call this underscore pink for example"},{"start":"2:09","end":"2:46","startSec":129.5,"text":"which is the pink level. Now I've got this level currently selected you can see this highlighted blue now if you think about this in terms of like almost like a layer in Photoshop or any other program that you use this is the currently selected layer if I double click the persistent level again which is our level streaming we've got a persistent level here so now I've got almost like a sub layer of this persistent level so with it double clicked I'm going to select my post process volume I'm going to hit ctrl and m and that actually moves the volume onto"},{"start":"2:46","end":"3:18","startSec":167.0,"text":"the pink level streaming if I change the visibility of this level now if I hide it that's removed that post process volume so if I toggle it on and I toggle it off that will hide and unhide it. Now if I go to file save all even if this level is visible when I click play so I'm just going to hit alt and p I'm playing this level now but you can't see the pink now that's because this level is not loaded by default if you wanted it loaded by default you could right click change"},{"start":"3:18","end":"3:52","startSec":198.3,"text":"the streaming method and go to always loaded and therefore it removes the little dot next to it and when I hit alt and p to play it's now loaded so I don't want this loaded by default so I'm just going to right click change streaming method and go back to the blueprint version of streaming method because that's what this tutorial is about and you'll see the little dot there and whenever you're working with lighting as of course this is a post process volume at the moment but if you're working with lighting it's good to take the toggle lighting scenario and that makes Unreal account"},{"start":"3:52","end":"4:23","startSec":232.7,"text":"for some pre-computed lighting scenarios and so if you had like a daytime scene a nighttime scene a golden hour scene for example you could toggle the different lighting scenarios and it would be pre-baked into that and all light maps would be stored inside of this stream level instead of baking it on the asset so if you're wanting to just toggle lighting scenarios that's a really powerful tool to have. I'm just going to file save all and now what I want to do is I want to"},{"start":"4:24","end":"4:59","startSec":264.3,"text":"create maybe two or three more versions of this pink level so I can show you how we're toggling through these different scenarios so I'll again go to levels I'll create a new level I'm going to select empty level again I'll pre-select something that was a pink one and I'm just going to rename it to green for example and I'll do that and then I'll do a last one create new empty level I'll again get the naming convention and what colors should we go for there let's go for orange"},{"start":"5:01","end":"5:35","startSec":301.1,"text":"so I'll save that and I go to file save all and then we want to go back and find our post-process volume so if I go to the outliner and I find the post-process volume sometimes it's good just to create a naming convention as well so maybe I'll call this pp underscore pink so I know which post-process volume it is now the pink post-process volume is on the pink level as we saw before now if I have say a different level selected so now the orange level is selected and I duplicate"},{"start":"5:36","end":"6:06","startSec":336.3,"text":"this post-process volume and if I hide now the pink level you'll still see that post-process volume quite faintly here on the left hand side if I turn off the visibility on that pink level that post-process volume disappeared and because I duplicated this post-process volume with the orange level selected this post-process volume is now on this level so instead of hitting control and m like we did before I've just duplicated it onto the current streaming level so I'll go to"},{"start":"6:06","end":"6:40","startSec":366.8,"text":"my scene tint I'll go to orange select new and then what I'll do is I'll duplicate this again by holding down alt on my keyboard and I'll do the different method this way so I'll double click now on my green level and I'll hit control and m to move it onto the green level I'll change this to green and if I hide my orange level now I've got my green post-process volume so let's just save all and let's just check these are working so I've got my green I'll hide my green I've got"},{"start":"6:40","end":"7:13","startSec":400.7,"text":"my orange and I've got my pink so this is just a really nice way of just pre-visualizing these level streaming methods that we're going to be using now they're all going to be blueprint driven so again just right click you don't need to change this it should be there by default but change streaming method just make sure they're all on blueprint we don't want them loaded by default so if I went to file save all and I just hit alt and p to play again no no colors are currently selected so now let's jump into blueprints and actually get some streaming setup we will go to"},{"start":"7:13","end":"7:43","startSec":433.6,"text":"blueprints at the top here and we will open our level blueprint and we will just pin this to the top bar now it's important to note that each one of these levels also has its own level blueprint if you wanted to house any code on there we're going to put all the code on the persistent level this persistent level is loaded and visible by default so you generally want to put any key information onto this persistent level streaming level but you can house blueprint code on level"},{"start":"7:43","end":"8:17","startSec":463.6,"text":"streaming if you want I've also just quickly noticed that the toggle lighting scenario so if these were all three lighting scenarios that you had lighting on that you wanted to bake you just want to make sure those three are toggled there but let's jump into blueprints now we can just delete what's currently there we don't need that and I'm just going to right click and press the hash key on my keyboard you can press whatever input type you like but I'm just going to use the hash key and again like previous examples you can change the input key if you want by selecting"},{"start":"8:18","end":"8:49","startSec":498.4,"text":"this button here it goes orange and if I press c on my keyboard for example that input would change to c so I always just start with hash just because it's the quickest input to find and then you can change it from there pretty pretty easily so I'll just save and compile just make sure everything's still working now the two functions that we want to be working with today is unload which is unload stream level by name so this unload stream level by name and then we also want to"},{"start":"8:49","end":"9:24","startSec":529.5,"text":"have a load stream level by name so if you type load you'll have load stream level by name as well so these are the two levels that we want to be working with here so this will unload a stream level this will load a stream level and the level name that it will load and unload is if we go back into our tab it's these levels that aren't currently loaded so let's start with the green example so the way I like to do this I like to right click on the stream level I like to find it in the content browser when it finds it in the content browser I'll single click just to go into rename"},{"start":"9:24","end":"9:55","startSec":564.5,"text":"mode or you can right click rename or you can even hit f2 on it but I'll hit ctrl c to get the name and I'll go back into the level streaming and in load I'll go to a paste there so ctrl and v just to paste that name in I copy and paste the names rather than manually typing them out because these level names need to be exactly what the other level name is called so if you misspell anything it could break your game so I'm just going to go to"},{"start":"9:56","end":"10:30","startSec":596.8,"text":"unpressed hash key I'm just going to load this level just see let's see what it's doing you can play around with the make visible after load I like to tick that and just compile and save and if we go to level streaming now hit alt and p we're playing the game now I'm going to hit the hash key and now I've loaded the green level in and you'll see that on this side here the level is now visible so we've got the persistent level still loaded and now we're streaming in this sub data so you can imagine now quite quickly that if you had a nighttime scene"},{"start":"10:30","end":"11:02","startSec":630.0,"text":"a daytime scene and a golden hour scene you could then cycle through these different levels to test out the different lighting scenarios that you might have in your experience here so we'll use a multi-gate to toggle through each of these level streaming functions now so I'll just give myself a bit of space and going back to a multi-gate that we've used previously I'll select multi-gate here so I've got a multi-gate and I will load first the green and then I'll copy"},{"start":"11:03","end":"11:34","startSec":663.5,"text":"by ctrl c ctrl v and I'll ctrl c ctrl v again I'll add a pin I'll go to the different out outputs so again we're just reusing functionality that we've used previously now I will promote the loop output to a variable as well we'll call this scene switch and again we can just rename this variable up here if you want to rename it I'll give it a category I like to always keep things"},{"start":"11:34","end":"12:07","startSec":694.7,"text":"organized here especially as your level blueprints start getting bigger so we'll just call this streaming and you can also I just control uh compile and save sorry and then you can also promote this to a variable we'll call this starting scene index or you can call this whatever makes most sense to you in your level here and then we'll give it the category as well streaming so again"},{"start":"12:07","end":"12:37","startSec":727.5,"text":"we're just repeating a lot of functionality we previously learned here and so we've we're streaming the green level in first and then we'll go back into our level streaming we'll find our orange level next I'm going to ctrl c and I'll ctrl v the next name into there and of course because we've kept the same naming convention I could just type pink in here but just for uniformity I'll just copy the pink name and I'll paste this name now an important key to note to"},{"start":"12:37","end":"13:10","startSec":757.9,"text":"make here is we're loading in the levels but we're not unloading the previous level so let's go ahead and use this unload stream level by name function now so I just want to drag that in there I'm going to ctrl c and ctrl v and the reason why I need two is because I just want to make sure if the green is loaded orange and pink are not loaded so I'm just going to grab orange paste here and again copying and pasting will save you a lot of time and misspellings and then I'll just ctrl c"},{"start":"13:10","end":"13:43","startSec":790.9,"text":"ctrl v and now it's just trying to work as efficiently with the keyboard as we can by ctrl c ctrl v so if orange is loaded we want to unload the green and the pink if pink is loaded we want to unload orange and green so green visible orange and pink not orange visible green and pink not and then pink visible orange and green not and so as long as you have the loop"},{"start":"13:43","end":"14:13","startSec":823.1,"text":"selected by default again you don't have to but what it will do is it'll make that infinitely repeat itself so I just want to compile and save I go back into my level streaming I'll hit alt and p now there's nothing loaded by default and you could set something on begin play if you wanted but I'm just going to press the hash key I'm going to press the hash key again I'm going to press the hash key again and we'll just keep cycling and so that's a really nice functionality"},{"start":"14:13","end":"14:44","startSec":853.9,"text":"to test different lighting scenarios out within your maps the last thing I'll do just as a bit of bonus cleanup I'm just going to select everything I'll hit ctrl I'll just hit c on the keyboard sorry and we'll just call this level streaming setup or something like that it gives it a title I can move this title around I'll maybe give it a bit of a comment color I'll maybe drop the alpha just to make things look a little bit nicer maybe I'll change the font size as well because"},{"start":"14:44","end":"15:08","startSec":884.9,"text":"this is quite a big powerful functionality in the level it just keeps things nice and organized so hopefully that gives you a good idea about how you might use level streaming and a pre-computed lighting within your levels"}],"10_Blueprints for Ray Tracing":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"To close out this video, let's talk about creating blueprints for ray tracing. So we'll talk about the level blueprint for real-time tests and then also talk about editor utilities with widgets, which really powerful functionality that you can make use of even outside of ray tracing. So the first thing we want to touch upon is that console commands can be used with blueprints to help optimize visuals such as ray trace reflections, the max distance."},{"start":"0:33","end":"1:04","startSec":33.4,"text":"You can use these in the level blueprint to execute the console command and it's just this execute console command function that you can see in the editor here. Now a really nice useful tip is that you can dump console commands into the output log, which will show you all the commands that you can use. So I'll just show you an example of that now. So if we're back in our editor, you have a console window at the bottom here. So you can just type dump console commands and you'll start seeing it up here at the"},{"start":"1:04","end":"1:37","startSec":64.9,"text":"top. Now you can go ahead and select that or you can just type in the whole thing. So I'll just press the up key to go and select it, hit enter. And then if we go to our output log along the bottom, you'll see everything that's just been dumped. So you'll see the command dump console commands and you'll see everything that you have access to inside of Unreal. So if you were in your level blueprint, say we just had the previous example, if we had a begin play and console command, execute console command, you could type whatever console"},{"start":"1:37","end":"2:10","startSec":97.3,"text":"commands you want that are relevant to your scene in there and they'll fire off when the level loads. The last thing to mention in this section is that you can also use the help with console variables which will give you a complete list of definitions opening inside of a hyperlink. So a lot of these console commands can be found online as well. So that should help just really refine what you want your scene to be doing. We can also use editor utility widgets, which as I mentioned just a couple of minutes ago,"},{"start":"2:10","end":"2:44","startSec":130.5,"text":"they're very, very powerful and can house a lot of information inside of Unreal. So we can create editor utility widgets through right clicking in the content browser and going to editor utilities and then editor utility widget. So they can be powerful for linking control and editor of the editor itself. Once opened, the UMG has its own blueprint as well and it allows for custom buttons we can link in console command. So to give you an example of this, we can open an editor utility, select some buttons"},{"start":"2:44","end":"3:16","startSec":164.3,"text":"and assign some console commands to this button. So if I jump back into the editor and then just go into my blueprint folder, I have this editor utility here, which I can double click for now. And you'll see that in the designer at the top right, so this is just the Unreal Motion Graphics window, the UMG window. We've added two buttons here, which we've just created from the common palette here. We've got button zero and button one."},{"start":"3:16","end":"3:48","startSec":196.5,"text":"And what we can do in our graph, if we go over to our graph and we see our buttons and what we can do is we can select the first button. And then if you see the events tab down in the bottom left hand side here, you can see the on clicked. So we'll just click on clicked. That says on click to button zero. And then we see button one as well. Repeat that process on clicked. And then you can fire off whatever console commands you'd like. I mean, you can fire off any scripting really."},{"start":"3:48","end":"4:24","startSec":228.1,"text":"That's what makes editor utility so powerful. But in this example, if you wanted to run two different ray tracing console commands, for example, you could do that. And then you could just compile and save. And then in the editor window, if you right click this editor utility and just go to run editor utility, you've got this little box that appears and you've got these two buttons. Now you can imagine the functionality where you can pin these editor utilities into your editor and they have really powerful functionality where you could toggle between different outputs."},{"start":"4:24","end":"4:54","startSec":264.1,"text":"You can double click this. You could add names onto these buttons by adding a text render into there and calling them, you know, set ray tracing to three or, you know, whatever variables you're playing with on the console commands. And then with this functionality, you would have some customizable windows inside of Unreal just editing the content in a more efficient and streamlined way to try out different variations"},{"start":"4:54","end":"5:04","startSec":294.9,"text":"for your project. So hopefully that gives you a good idea about console commands and also using editor utilities, especially in relation to ray tracing."}],"11_Wrap Up":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"So, we've covered a lot of ground here today. We've talked about the introduction to blueprints and the blueprint usage and the flow of blueprints. We've even jumped in to create our own blueprints and set up some camera switching functionality. And then we've dove into editor utilities and really gained a little bit more advanced functionality especially in regards to working with virtual production and working with our precomputed lighting setups and really getting the most out of our scenes to create the most"},{"start":"0:34","end":"0:40","startSec":35.0,"text":"efficient workflows possible. So, really hope you found benefit from this course and we'll see you on the next one."}]},"103.02":{"01_Overview":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Hello, and welcome to another Unreal Engine training session. This time we're going to take a look at lighting, specifically an introduction for architecture, engineering, and construction industries. My name is James Burton, and I'm an Unreal Engine instructor. And in this course, we're going to be taking a look at the following topics. First of all, we'll be covering lighting terminology and types, so the types of lights that you have available in Unreal Engine, as well as going over some basic concepts to make sure that we have some common ground and understand what we're talking about when referring to lighting."},{"start":"0:33","end":"1:07","startSec":33.8,"text":"We'll be taking a look at how we can control exposure and what tools we have to our disposal. Then we'll be taking a look at Lumen, which is Unreal Engine's default lighting system, which is a dynamic global illumination system that's really, really cool. And then we'll be taking a look at creating some specific examples. So since we're looking at architecture, engineering, construction, we're going to look at how to make natural exterior lighting. We'll also take a look at Lumen's reflection system and how we can get the most out of it, as well as creating some examples of interior lighting to make sure that we cover the whole spectrum."},{"start":"1:07","end":"1:10","startSec":67.6,"text":"So I hope you have fun with me, but let's go ahead and get started."}],"02_Lighting Terminology":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Okay, so before we get into the engine, I want to go over some basic terminologies and concepts that you'll be hearing me use throughout the duration of the course. And I just want to make sure that we have a common language and ground when I talk about these things. So we'll be taking a look at what direct lighting versus indirect lighting and shadows are. So in this case, direct lighting is the light that goes directly from the light source onto"},{"start":"0:32","end":"1:03","startSec":32.0,"text":"the surface without any interference, which means that it receives the full spectrum of the light in terms of color. Now indirect lighting is slightly different to that. It's when lighting's been bounced off a surface and lights another object. Now when lighting hits that surface, that surface absorbs some of the light and the light that gets bounced out is actually tinted. So indirect lighting contributes to the overall mood and light intensity of the scene and color as well."},{"start":"1:03","end":"1:38","startSec":63.7,"text":"And then the shadows are important to understand that it's essentially a real engine takes a snapshot of a mesh from the light's point of view and projects the shadow information onto another surface from that point of view. So as long as we're all agreed on this, I think as I start talking about these concepts when we talk about lighting later down the line, I think we'll all understand what it is I'm referring to. And I also want to take a look at the types of lighting systems that exist in the engine. For this course, we're going to be using real time dynamic global illumination since Unreal"},{"start":"1:38","end":"2:10","startSec":98.6,"text":"Engine 5 comes with Lumen, which is an incredibly powerful and strong real time global illumination system. But I just wanted to go over the other options that you have as well to make sure that you understand everything that's available. So Unreal Engine has a baked or static lighting system, which is pre-computed. This is created using Unreal Engine's Lightmass system. And it's similar to rendering with lighting setups like V-Ray, Corona, et cetera. And it's really high quality, but it's baked."},{"start":"2:10","end":"2:42","startSec":131.0,"text":"So it cannot be altered at runtime. So once you bake it, it takes quite a long time to bake if you're using the CPU. And then once that's done, you cannot edit it at runtime, which means you can't have a light swing, for example, and update lighting in real time if you were using a purely static system. There's other systems like real time dynamic lighting, which is what we're going to be using. Now, historically, this had no global illumination system. So you only had direct light. So there was no bounce light effect in the scene or anything like that for this type"},{"start":"2:42","end":"3:14","startSec":162.9,"text":"of lighting. But nowadays with Lumen and Unreal Engine 5, we do have that. So we're going to be sticking to this sort of method, which means no baking times, nothing to wait for, everything you see is happening in real time, and it's final straight away. Now, as I say, Unreal Engine can use both static and dynamic lighting. Traditionally, for architectural visualization and AEC industries in general, these projects were typically stationary and baked. But again, nowadays with Unreal Engine 5, we're going to be using Lumen, so we don't have"},{"start":"3:14","end":"3:45","startSec":194.2,"text":"to worry so much about that. The last type of system is hardware ray tracing. So it's a lighting type that it's real time, just like the dynamic stuff. However, it uses hardware ray tracing to calculate global illumination. So all that bounce light and indirect lighting can also be calculated at runtime. It requires very strong GPUs. So you might have heard the Nvidia RTX card. So that's something you're going to require if you're going to be using straight up ray"},{"start":"3:45","end":"4:16","startSec":225.9,"text":"tracing. Lumen uses software ray tracing, which means you don't need such a high end GPU. So that's what we're going to stick to. So those are the concepts that we need to go over. In terms of terminology, I also want to take a quick look at the types of lights that we're going to be seeing inside of the engine. So the types of lights that we have available to us are directional lights, point lights, spot lights, rectangular lights."},{"start":"4:16","end":"4:49","startSec":256.4,"text":"And now we start to get into the more interesting ones, which are the skylight, which will be able to capture the scene as a whole and provide indirect lighting for the entire scene. And then these last two, HDRI backdrops in sun and sky, they actually are plugins that you have to enable, but they give you essentially a set of blueprints that combine a few lighting concepts that we see here to give you a particular setup that might be useful for you. So we will take a look at how to enable these and load them, but we'll be doing that inside"},{"start":"4:49","end":"4:50","startSec":289.2,"text":"of the engine."}],"03_Light types in UE5":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Okay, now that we've had a look at some basic concepts and the light types that exist in Unreal Engine, I think it's time for us to open up the engine and look at them inside of Unreal Engine 5 itself. To that avail, I've loaded up the project that was given to you with this course. In order to open the level up that I have here, all you have to do is go into the content folder, levels, and open up bunker start. Now you don't actually have to follow along with this particular level for this video,"},{"start":"0:32","end":"1:03","startSec":32.7,"text":"but if you just wanted to get a look at exactly the same as I do here, that's what you need to open. Another note that I want to take before we get into it is that you will notice that the layout I have here might be different to the one you have in UE5 by default. I'm using the UE4 classic layout because I think it's a little bit more clear because everything is in view instead of the content drawer popping up in and out. For these videos, instructionally, I think it's a little bit easier to be able to see everything at a glance. Although while you're working, once you get good with the engine, you might find that"},{"start":"1:03","end":"1:34","startSec":63.3,"text":"actually the UE5 default setup is much nicer and faster and lets you focus a lot more on the scene that you're working on yourself. However, again, if you want to just load this layout, just to be able to follow along with me one to one, all you have to do is go to Window, Load Layout, and UE4 classic layout. If you just click that, it'll load up the layout that I have here. So once again, just open the level, go to levels, bunker underscore start."},{"start":"1:34","end":"2:05","startSec":94.4,"text":"Okay, with that said, let's take a look at how we actually find the lights that we were talking about just before. I'm going to go to the lights section here inside of the Place Actors tab. And you see here we have all the lights that are available to us, including the HDRI, Back Delving Sun, and Sky, which are plugins that we'll have to load. But again, I'll show you how to load those up later down the line. The first thing I'm going to do is delete the lights that we see here, just so that"},{"start":"2:05","end":"2:36","startSec":126.0,"text":"we can actually see what the impact of each one of them is individually. And let's go through them one by one. So the first one is the Directional Light. All I have to do to bring a light in is click, drag into the level, and you see the light comes in. And you'll notice that by default, we're already using Unreal Engine 5's default Lumen Dynamic Global Illumination system. So we're getting some beautiful bounce lighting already from the get-go. But the Directional Light, as we spoke about before, is just a light that is a bunch of"},{"start":"2:36","end":"3:11","startSec":156.3,"text":"parallel rays from an infinite distance, essentially. So it acts like a sun. And I can go ahead and rotate this. You can see Lumen doing its work already, bouncing that light and showing us some indirect lighting here. So that's the Directional Light. The next one I'm going to look at is the Point Light, or you might know this as an Omni Light from other packages. And I'm just going to scale down the attenuation a bit. And you can see it's just light going in all directions from a point."},{"start":"3:11","end":"3:43","startSec":191.3,"text":"Then we have a Spot Light. I'll delete the previous one. So Spot Light. And then we have a Rectangular Light, which essentially emits the light from a rectangular shape and not just one point. Last but not least, we have a Sky Light, which will be able to look at the scene as a whole and essentially generate a cube map that contributes to that indirect lighting as a whole."},{"start":"3:43","end":"4:14","startSec":223.8,"text":"So usually for daytime settings, this Directional Light and Sky Light are going to be really essential to get a good look. But we'll take a look at that in a proper example later down the line in this tutorial session. What I want to go over now is the type of lights that we can use and what we can actually access and change in them as a rule or as a whole. So let's go ahead and bring a Spot Light in here. And you'll notice that the first thing that I'm going to talk about here is the mobility."},{"start":"4:14","end":"4:46","startSec":254.0,"text":"Now this is going to relate to the type of lighting that you're going to actually use. So if you're using a Static Lighting setup, Static is the type of mobility you want. And you'll notice as soon as I click it, the engines tell me already that lighting needs to be rebuilt. Remember Static Lighting needs to be baked the same way you do in Corona or V-Ray. But the good thing about it is that it's very cheap in terms of runtime performance since it's all pre-calculated and nothing has to be calculated on runtime. So that's very cheap light."},{"start":"4:46","end":"5:18","startSec":286.8,"text":"The next one is Stationary, which is a mix in between Static and Movable. It gives you some really sharp direct shadows and direct illumination, but it's limited in mobility and also limited in terms of how many stationary lights you can have overlap in the same point. So if I have one, two, three, and four, you'll notice that fourth one now comes up with the next. And that's because we have all these four overlap in the same point."},{"start":"5:18","end":"5:48","startSec":318.2,"text":"Now this essentially gets turned into a Movable light, so you don't get the performance benefits from using the stationary light. So just something to keep in mind. As I say, we will always in this case be using the Movable light since we want to take advantage of Unreal Engine 5's real-time global illumination system. So we're going to stick to Movable and you'll notice that your lights are Movable by the fact that they have a little sort of four arrow icon here that let you know that it's Movable. And that's the same for every type of light."},{"start":"5:48","end":"6:19","startSec":348.5,"text":"So if you drag this in and make it Movable, you'll notice that Movable icon will appear. So let's go ahead and make our directional and skylights Movable as well. And let's take a look at some of the other settings. Now before I touch on the other settings, I'm just going to quickly jump back into my slides and talk about some of the settings that we're going to look at. So we're going to take a look at Intensity. Importantly, and with point and spotlights, you can either use unitless Unreal Engine"},{"start":"6:19","end":"6:55","startSec":379.3,"text":"units, candelas, or lumens. It's important to know that 100 watt light bulb is 1600 lumens. And the directional light or the sunlight, as we just covered a second ago, is actually going to be measured in lux. And it's going to have the default value of 75. So because we are doing architectural engineering construction, it's probably best to stay away from using the light color and stick to temperature, which is going to be measured in Kelvin. So if you have a light bulb that you know runs at 3500K, then you can change that value"},{"start":"6:55","end":"7:27","startSec":415.2,"text":"and expect exactly the same results inside of the engine itself. We'll also take a look at affecting the indirect lighting intensity, so how much a light contributes to that indirect lighting. The attenuation of lights, the difference between or the effect that change in the source radius and length will have. One thing to note is that all the lights will be using the inverse square falloff system. So the lighting from the point that actually emanates light to the end of its attenuation uses the inverse square falloff rule."},{"start":"7:27","end":"7:59","startSec":447.0,"text":"So it's exponentially brighter towards the point of emission of light. And then we'll also take a look at IES profiles and how that helps us control the distribution of light. So if you say, for example, have a light bulb that you want to use and know the manufacturer, usually they'll have their IES profiles available to download and download those and have the same exact light distribution that that light bulb would have in real life. So we're going to take a look at all of these and let's go ahead and take a look at them."},{"start":"7:59","end":"8:31","startSec":479.0,"text":"So intensity, I can just access the bottom here and you can see it right now is set to 8 candela. So I can bring this up or down. If I click and drag or you can manually enter a number, that's no problem whatsoever. Set this one to 16. We can also take a look at the temperature. Now by default, the temperature isn't enabled. You'll encourage to use light color. So again, for AEC industries, I think it's best to just use temperature and try and match"},{"start":"8:31","end":"9:05","startSec":511.3,"text":"some manufacturer light bulbs that you might actually know you're using in a particular space. So let's say, for example, you know a light under 3500 K, then you can change it to that. Next thing I want to take a look at is the indirect light and intensity. So how much this light contributes to the indirect light and in the global illumination. So let's, for example, set this up as such. So I look up like that and if I change the indirect light and intensity to something, let's go quite ridiculous, like 10, you can see it's contributed more in its bouncing."},{"start":"9:05","end":"9:43","startSec":545.6,"text":"So that indirect lighting gets contributed more by this light. So you can sort of increase this to change how much that light is actually bouncing. Again, the default is one, but you can change that manually yourself. The attenuation of the light is essentially how far the light reaches. So let's go ahead and change that with, in this case with spotlights, you can change it with the outer and inner cone angles. So the outer cone and then the inner cone, if you want to make a harder or softer light"},{"start":"9:43","end":"10:16","startSec":583.4,"text":"distribution, you'll see actually called attenuation in here. There we go, attenuation radius. And I'm actually, I think I'm mistaken. We do have attenuation here, which is how far from the point it actually goes. Okay. The next thing is the source radius and length. So I'm going to go once again, just bring this light in here and I'm going to use temperature,"},{"start":"10:17","end":"10:49","startSec":617.4,"text":"bring it down to 3500, just like in the other one. We'll bring the attenuation down a little bit just so we can see things a bit more clearly. I'm just going to bring this light a little bit up here so we can see more information. And if I change the source radius and the source length, you'll see it changes the actual source of the light, which means that when you take a look at the shape of the specular highlight, you'll see a change in the actual reflection."},{"start":"10:49","end":"11:20","startSec":649.6,"text":"Okay. If we change the length, this changes that distribution length and we can always rotate the light if we wanted to change its direction. Now if you were trying to make a fluorescent tube light, for example, I'd actually recommend to use a rectangular light here. Since you have a little bit more control and it's set up already more to work with particular shapes, in this case rectangular, so that's a recommendation that I would give you. But the last thing I'm going to take a look at is the IES profiles and you'll notice,"},{"start":"11:20","end":"11:56","startSec":681.0,"text":"let me go ahead and bring the source length to zero here, and you'll notice that we have a section in here inside the light profiles, which is the IES texture. Now we have provided some IES profiles, so we'll actually use them with a spotlight. So we'll bring this here, make it dynamic, we'll use temperature and once again bring it to 3500, just for the sake of seeing the changes as we had them before."},{"start":"11:56","end":"12:29","startSec":716.2,"text":"And then essentially what I want to do is add a light profile. So all I need to do is grab this and drag it into that shape. And you can see it now follows the light distribution that that particular light bulb would have. And that's really it for this section. We haven't looked at HRI, Backdrop and Sun and Sky."},{"start":"12:29","end":"13:00","startSec":749.2,"text":"We're going to take a look at those in a little bit more of an isolated case, since they essentially are blueprints that encompass a lot of information on how to set up or encompass a particular setup for their particular use. So I'm going to take a look at them individually, but we'll take a look at them down the line. They're a little bit more advanced than these since they're a blueprint setup. This is just a quick overview of the actual lighting tools that you have in Unreal and how you can edit the particular properties. So quick overview."},{"start":"13:00","end":"13:08","startSec":780.7,"text":"I think after this, it's worth getting into an actual example. So we'll start taking a look at some natural light setups. So we'll see you there."}],"04_Lumen":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Okay, so before we hop into actually setting up our natural light and scene, I wanted to give an overview of Lumen and essentially take a look at and highlight some of the features that it comes with. So Lumen is a default lighting system inside of Unreal Engine 5, which is a fully dynamic global illumination system, like I mentioned before. It gives us performance reflections and they're actually supported in clear coat materials,"},{"start":"0:33","end":"1:08","startSec":34.0,"text":"which are important for car paint. It's compatible with large open worlds, and as I said before, it's all real time, so there's no light baking, everything happening and streaming on the GPU. It works really well on both outdoor and indoor scenes. And one thing that's actually really nice is that emissive materials can contribute to lighting the scene itself. One of the limitations of Lumen is that the global illumination and sky shadowing will give you lower quality with translucent materials and volumetric fog. If you use world position offset in a material to displace some verts on a mesh, it can cause"},{"start":"1:08","end":"1:41","startSec":68.8,"text":"artifacts. There's no support for lighting channels. It gives you poor mirror-like reflections, so that's something where you'd want to turn on hardware ray tracing specifically for, which we'll take a look at. This deformation in general with hardware ray tracing will give you high cost with skeletal mesh, so anything like skeletal mesh animations, it'll have a high cost rendering those out. And it's really only supported on high end PCs and next-gen consoles and not supported"},{"start":"1:41","end":"2:13","startSec":101.3,"text":"on mobile or VR. So that's something to keep in mind if you wanted to move your project to Lumen-based scene, stuff to keep in mind in terms of the limitations. Lumen will be enabled by default, but if for whatever reason you're changing from an old project that wasn't using Lumen or for whatever reason it wasn't set up as default by Unreal Engine, we're going to take a look at how we actually set this up. So once again, hop back into the project and see how we'd enable these settings."},{"start":"2:13","end":"2:43","startSec":133.8,"text":"So to enable Lumen, all you'd have to do is go to Edit Project Settings. Inside of this window, I'm just going to maximize it. We're going to go to the Render tab inside of Engine. I'm going to scroll down to Global Illumination. So the Global Illumination setting needs to be set to Lumen if you want to use it, but here's where if you wanted to use any other system, like standalone ray tracing or anything like that, you could use that."},{"start":"2:43","end":"3:14","startSec":163.8,"text":"It's important to note as well that the reflection method in this case is set to Lumen. And one thing that you want to do to make sure that Lumen works correctly is make sure that Generate Mesh Distance Fields is turned off. Now some additional settings that might give you some better results. Within Lumen, you'll want to use hardware ray tracing when available. So this is important to note that if you have a high-end GPU like an RTX card, this is somewhere where you can use it."},{"start":"3:14","end":"3:46","startSec":194.2,"text":"If not, it's not worth digging this. And inside of the hardware ray tracing, make sure that Support Hardware Ray Tracing is actually ticked so that you get all the benefits from that as well. Now importantly, you can change the behavior of all these things using post-process volume so you don't have to change them project-wide every time. So in order to do that, all we have to do is create a post-process volume. So I'm going to go to the Place Actor tab here. I'm going to search for Post, and I'll drag in a post-process volume."},{"start":"3:46","end":"4:20","startSec":226.0,"text":"Now in order, we already have one here, so I'm just going to go ahead and quickly delete that. And actually, that's actually changing some of our lighting settings here. So let's go ahead and just use this one. And there's a couple of things that you need to know to make sure that this post-process volume actually affects your entire scene and not just the volume that it's represented. So I'm going to go ahead and search here for Unbound. And you can see here there's a tick box for infinite extent. So make sure that that's ticked to ensure that that post-process becomes a global post-process"},{"start":"4:20","end":"4:53","startSec":260.1,"text":"and affects the entire scene. So in the case of the edits that we want to do for Lumen, or if you wanted to change any of the settings, you want to go to the Global Illumination tab here. And if you wanted to change it for other reasons, you could change it here. And if you want to change the Insider Reflections, you can change the method as well to Lumen. Okay. And one last thing is that if you want to improve some of the quality of your scene,"},{"start":"4:53","end":"5:27","startSec":294.0,"text":"and we're going to be talking quite minimized gains here as we go, but if you wanted to update the final gather quality, if you want to bring this number up, it will reduce the noise that you see in the scene, but it will greatly increase the cost. So if you want to set this to 2, make sure that maybe the graininess that you might see if you get really close gets fixed. And really, I doubt it'll be easy to appreciate inside of the video that I'm making here."},{"start":"5:27","end":"5:57","startSec":327.0,"text":"But if you bring this value up, you'll see better quality and reduction of noise. But again, just make sure you understand that this will significantly increase the cost of rendering the scene and thus give you better, or sorry, poorer frame rates. One last thing to note is that this is going to be mostly like the look of how Lumen actually works. It's going to be dictated by both the quality of the materials, the rest of the scene, and"},{"start":"5:57","end":"6:27","startSec":357.1,"text":"also your exposure. So if you, for example, have different exposure settings, you'll see Lumen adjust to that. So just keep in mind that your exposure settings are going to affect the way the lighting scene works as a whole. So by default, I'm just going to tick game settings so it adjusts for me. But just something to keep in mind once again. Okay, I think we've covered everything we need to cover for Lumen. I think we're ready to actually start setting up a natural lighting scene. So let's go ahead and do that."}],"05_Natural Lighting":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"So I think we're now ready to tackle natural daytime light and scene. So let's take a look at the things that we're going to have to have required versus some of the things that are optional to get a good setup for natural lighting. And the elements that you're going to need are a light source for the sun. So generally, this is going to be a directional light. An atmosphere will be linked to the sun and adapt to its position. A post-processing volume, which will allow us to tweak part of the lighting settings,"},{"start":"0:31","end":"1:03","startSec":32.0,"text":"as well as other rendering aspects like exposure and bloom and things like that. And then optionally, we can add a skylight that will contribute to the global illumination, which I actually think is a really nice touch on your scene. So we'll be adding one of those to our scenes. A sky dome for background visuals if you need them. Some volumetric clouds. And if you need to, because you're using a static lighting solution, you will need a light mass importance volume. So again, we're not going to use this since we're going to be using Lumen, which is all"},{"start":"1:03","end":"1:35","startSec":63.8,"text":"real time. But if you are using a static solution, understand that you will need a light mass importance volume to get the most out of the scene. Now one other thing I want to touch on before we jump into the engine is that different templates are made for different needs. So if you're starting your project and you're in the AAC industry, make sure you do go to the AAC tab and start your project from there because it will have some more advanced lighting setups than say some of the game systems or templates that we have. So yeah, not all templates are created equals and the levels within them use different setups"},{"start":"1:35","end":"2:07","startSec":95.2,"text":"depending on the level that you start using. So you have like the basic level, which uses a legacy daylight setup, the time of day, which uses a newer approach, and then empty levels in case you want to start things from scratch. Now in our case, we're going to start things from scratch. So let's go ahead and pop into the engine. And essentially, we're going to recreate this. So I've loaded up the Corbero Day map. If you want to access that, all you have to do is go to levels and then open up Corbero"},{"start":"2:07","end":"2:38","startSec":127.2,"text":"Day. And you see we have a nice little setup that we're going to delete and recreate. So I'm going to go ahead and delete every single one of these actors that contribute to the lighting. There we go. We are lightless. Let's go ahead and start looking at how we can add all the things that we need. So I'm going to go to the place actors tab here. And first and foremost, we're going to need sun direction or sunlight. Let's go ahead and drag a directional light. I'm going to rotate it to make this a little bit more interesting, like so."},{"start":"2:38","end":"3:09","startSec":158.9,"text":"There we go. We have a directional light. That's a good start. Now you'll notice that by default, Lumen is doing a lot of stuff already calculating our global illumination, indirect bounce lighting, all of that good stuff out of the box from Unreal. Now, the next thing I'm going to need is an atmosphere. So I'm going to go ahead and add an atmosphere since you can see the backdrop is very dark. So we add an atmosphere here. And you might notice it tells you, hey, you need to rebuild lighting. And that's because I haven't changed this light here to moveable. So I'm going to go ahead and do that."},{"start":"3:09","end":"3:40","startSec":189.4,"text":"But also I'm just going to refresh this by just going inside the scenario and moveable just so that it actually understands that the directional light is actually moveable. It's just a quick refresh. The next thing I'm going to do, I'm just going to bring that up there. The next thing I'm going to add is an exponential high fog. So let's go ahead and search for high fog. There we go. Got it there. The next thing I'm going to add is a skylight."},{"start":"3:40","end":"4:13","startSec":220.7,"text":"Once again, I'm going to set that to moveable. That's what I'll leave at the bottom, actually. And last but not least, I think I'm going to add some volumetric clouds to get some nice clouds looking here. And there we go. We have our entire setup that we had before. And it's just incredibly easy. Out of the box Unreal Engine handles all of this for us. So one thing to note is that, as you can see, I had to manually drag all of these out."},{"start":"4:13","end":"4:45","startSec":253.4,"text":"Now there's an easier way to actually build all of this. So we're going to go ahead and delete everything once again and use the environment light mixer. So it's a really nice little system that allows you to create everything that you need for a natural lighting setup within one window. So I'm going to go to window, environment light mixer. And here I have essentially nothing yet because we have nothing that contributes to that global lighting system. So let's go ahead and start by creating a skylight, creating an atmospheric light."},{"start":"4:45","end":"5:19","startSec":286.0,"text":"We'll create a sky atmosphere, volumetric clouds, and a height of fog. So we literally just created everything that we had before. And you can see everything's kind of stacked up here, but you can see we've got everything that we created earlier. But one thing I am going to add is a little bit of rotation to this light once again, just to get to the same place that we were. So you can see with the environment light mixer really quickly without having to know the names of all those things. And Real already has a little setup for you. Now what I really love about the environment light mixer is that in the past I would have"},{"start":"5:19","end":"5:52","startSec":319.5,"text":"had to actually start clicking around these and changing the values individually to adjust the scene to my taste. Now what I love about the environment light mixer is that everything is here at a glance. So I can change the intensity of the directional light if I want to. I can change the color of the directional light. All the properties that contribute to the lighting of this light can be edited within the environment light mixer and can be seen at a glance with all the other things that contribute to the overall lighting of the scene. So this is something that I really love because I get to just not have to click around as"},{"start":"5:52","end":"6:21","startSec":352.6,"text":"much and edit everything at a glance. So really, really cool little system there with the environment light mixer. Once again, we're going to delete because we're going to take a look at some of the other setups that we have. So let's go ahead and delete this. And the next one I'm going to drag in is one of the ones that we talked about we were going to take a look at, but we didn't look at earlier. So this one's the Sun and Sky Blueprint. So I'm going to go ahead and drag it in and you might be blinded by the strength of the light. And the reason for this is that if we look at the actual blueprint under the details"},{"start":"6:22","end":"6:53","startSec":382.8,"text":"Oh, sorry, it's the direction that I'm looking for. And the intensity is 75,000 lux. It's trying to emulate the Sun essentially. But the default exposure settings that we have here, we go to lit, you'll notice that by default we had game settings. And if you untick it, by default you have an EV100 of zero. So I'm actually going to go ahead and bring this all the way up and I'm going to move to about 12. And now you'll be able to see that our lighting makes a little bit more sense and we can see"},{"start":"6:53","end":"7:32","startSec":413.7,"text":"what we're doing. Now you can actually change these values inside of the post process volume under exposure. We'll take a look a bit more depth, a little bit more in depth later along the line. I just want to show you how to actually use these tools right now. So when it comes to the Sun and Sky, one thing that's really cool about it is that it's set up as an actual geographical analog of the real world. So you'll notice that we have a latitude and longitude here and also a time zone, date"},{"start":"7:32","end":"8:04","startSec":452.9,"text":"and solar time. So what's really nice about this is that if you say, for example, want to recreate the lighting at a particular point on Earth, let's say Chicago, a certain latitude and longitude, you could enter those values and the Blueprint is going to update and change everything about the atmosphere, directional light and skylight that is inside of this Blueprint to match the lighting conditions of that latitude and longitude at that day, at that time. So it's a really, really nice system."},{"start":"8:04","end":"8:36","startSec":484.3,"text":"Let's say again, you live in Chicago and want to get the lighting right for the same thing that's outside your house on the 21st of September, this Blueprint has you covered for that. It's actually really, really nice to be able to have essentially a digital analog of the lighting setup of a particular location on Earth. And I guess really useful for the AEC industry. Now, the last thing I wanted to look at is the HDRI backdrop. Once again, I'm going to delete and you'll notice that when I drag the HDRI backdrop,"},{"start":"8:36","end":"9:09","startSec":516.8,"text":"I can't see anything. Remember, we edited the exposure to be much, much darker to compensate for that. Since guys, I'm just going to click back to game settings and you'll see I've dragged in my HDRI backdrop. I'm just going to move it down a little bit so we don't get that crazy Z-fighting. But you can see here that by default, I get the lighting contribution from this HDRI image to my scene, which is really, really nice. Now, one problem with this is that it does not come with a directional light setup."},{"start":"9:09","end":"9:39","startSec":549.8,"text":"So that's something that you have to do manually. So if you bring in a directional light, you can rotate it, get essentially the right light you need. I suggest you try to sort of follow the direction that the scene is actually telling you to do. So it'd probably be something more like this. Assuming the sun's about that direction. I can't actually see it on the scene, so I presume that's actually where it is. So now we actually have a directional light."},{"start":"9:40","end":"10:11","startSec":580.7,"text":"Now, importantly, if you wanted to change the actual backdrop that you're using, you can use your personal texture that you have yourself. In our case, we're using this cube map. If we go to the HDRI section here, we can drag in a different one to get different results. Now, this is a nighttime setup, so it's essentially a moonlit scene, which means that we would have to manually adjust it once again, our directional light to match the values of the HDRI."},{"start":"10:11","end":"10:43","startSec":611.4,"text":"So in our case, we're just going to change the intensity to something like one, to something more akin to moonlight, and maybe change the color. We might even sample some of the colors of the scene here to get the correct look. So this now feels like a moonlit environment using that information from the HDRI. So they're the two sort of more out there blueprints in terms of lighting setups."},{"start":"10:44","end":"11:18","startSec":644.6,"text":"Let's go ahead and recreate that original lighting setup manually. So let's go ahead and delete the HDRI backdrop. And with the environment light mixer, we'll do it really quickly. So create skylight, atmospheric light, sky atmosphere, volumetric fogs, volumetric clouds, and high fog. And I'm just going to quickly select my directional light here and rotate it till we get a nice look. There we go. Perfect. So the last thing I want to take a look at here is some settings to improve"},{"start":"11:18","end":"11:51","startSec":678.6,"text":"your reflection information inside of your scene. Now, by default, the setup that Lumen has might not give you the best reflections for AAC work. So let's go ahead and take a look at this. I'm going to bring a sphere in. Bring it up. And I'm going to go ahead and assign a material to it. It's going to be a Chrome ball. If you don't have access to this, it might be because you don't have access to engine folders. In order to access the engine folders, all you have to do is go to the settings"},{"start":"11:51","end":"12:24","startSec":711.4,"text":"here and make sure that show engine content is available. Now, I have a Chrome ball here and you see the reflection that I'm seeing here. It is reflecting what's behind me. So that's a good start. You can see the quality of the reflection isn't exactly amazing. So if you have a good, powerful GPU that can handle hardware ray tracing, there's some settings that you can actually change to make this much better. So let's go ahead and take a look at those. So I'm going to go to my project settings. I'm going to make them a little bit smaller so we can see what's actually happening when"},{"start":"12:24","end":"13:05","startSec":744.1,"text":"we change things. But we're going to go to the rendering tab. There we go. I'll actually change the scene a little bit so we can see. And I'm going to scroll down until I get to my glowing illumination system, which is going to be set to lumen. And then my reflections here, which are set to lumen. So I'm going to go to the render tab. And I'm going to go to the reflections here, which are set to lumen. Now, you'll notice that under the lumen setup, we want to be using use hardware ray tracing"},{"start":"13:05","end":"13:37","startSec":785.6,"text":"when available. Let's go ahead and tick that. And you'll notice that instantly increases the quality of our reflection quite drastically. And there's another couple of things that we can do to gain a little bit of quality here. First of all, is that the ray light in mode here is set to surface cache. I actually want to hit light in for reflection so you can see a little bit of a better result here. And next is the software ray tracing mode. I'm actually going to change this to detailed tracing. And once again, you might see a slight gain in the quality of the reflection."},{"start":"13:37","end":"14:11","startSec":817.4,"text":"So much nicer reflection than what we had by default. That's something to keep in mind. When using lumen for AUC. Now, these settings that I've just changed here, some of them can actually be accessed directly through the post-process volume. So if I scroll down and find my reflection settings. Same thing here, right? You can change your reflection method, the quality of the reflections and the ray light in mode, which is set by the project default, which is what we just set earlier."},{"start":"14:11","end":"14:38","startSec":851.2,"text":"But if you wanted to change it to surface cache or hit light in from the post-process volume, you can do that from here. OK, so I think that about does it for this natural lighting setup. After this, we're going to look at some additional tools that will help us debug and visualize our scene in different ways to help us kind of read what might be wrong or what might be able to be enhanced. And then we'll take a look at some artificial lighting as well. So stay tuned for that."}],"06_Additional Tools":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"Okay, so before we move on and start looking at interior lighting, I wanted to go ahead and show you some of the additional tools that Unreal Engine has that might help you when lighting a scene. So the first of which is going to be changing your view mode. So when debugging and trying to figure out what's actually going on, it can be handy to change your view mode to different modes, for example, to an lit mode where you're actually able to see just perfect color data information. You also have modes like Light and Only, which allow you to just see the lighting with no"},{"start":"0:35","end":"1:05","startSec":35.0,"text":"reflections or normal information, just what the light itself is doing. You also have Detail Lighting, which includes reflections and normal information. These are some of the view modes that essentially can be helpful when trying to devote what might be going wrong or just help you get that extra little nudge where you need it to get the right realism for your scene. I'm going to go back to lit mode. And another one of the things that I want to touch on is the scalability tools. These are usually designed to bring stuff down in quality if your machine's struggling"},{"start":"1:05","end":"1:36","startSec":65.7,"text":"with rendering the scene. However, for architectural engineering and construction industries, we might want to crank these all the way to the top since usually we have high-end PCs. So I'm going to go to Settings here. And under Engine Scalability Settings, I'm going to set everything to cinematic. So you'll see you'll get a little quality bump right there, which is really handy. One other thing I wanted to show is sometimes you'll notice that by any accidental change that you might have done, you'll be missing certain things from the scene."},{"start":"1:36","end":"2:06","startSec":96.2,"text":"So the show flag here might be handy. Say, for example, you accidentally turned off anti-aliasing. All this information is all the way over here in the Show tab. And here you can also turn on stuff like motion blur and things like that if you so desire. Now one last thing that I wanted to check in order to get that extra little bit of performance out of the engine is if you go to Window and Project Settings, sorry, Edit Project Settings, we're going to go to the Render tab again. We're going to change our G-Buffer format. So we're going to Render in."},{"start":"2:06","end":"2:37","startSec":126.3,"text":"This time I'm looking for the Optimization tab. So I'm going to scroll all the way down. And here under Optimizations, I'm going to take a look at the G-Buffer format. I'm going to set this to high-precision normals. So this will encode the normals in 16 bits per channel, and it will give us higher and better detail. Now the next tool I want to take a look at, the Calibration tools. So sometimes we're going to want to start working from a calibrated scene that's matching something in the real world."},{"start":"2:37","end":"3:10","startSec":157.6,"text":"So what I'm going to do is access the Calibrator. To do this, I actually need engine content available. If you missed that earlier on, you could just enable it by going to Settings, Show Engine Content. And in here, I'm going to search for Calibrator. Now with this, I can actually drag in my color calibration tool. And this essentially gives me a few bits of information and color that I can calibrate"},{"start":"3:10","end":"3:41","startSec":190.4,"text":"against in the real world. So an important step to do is to just set the Calibrator to face the sun. And then what we're going to do is use a little tool called the Pixel Inspector, and we're going to calibrate this square here, the third gray square from the right, to be perfect gray essentially. So in order to do that, all I'm going to do is go to Tools, Debug, Pixel Inspector. And the way you use this tool is really simple."},{"start":"3:41","end":"4:17","startSec":221.0,"text":"You just click the little search button here, and now you hover over the pixel that you want to sample. Once you hover over that pixel, you can press Escape to freeze that pixel essentially. And what we're looking for is this luminance value here, so enter a value of 0.18. Now mine's already calibrated. However, if, say for example, your lighting was at 10, you might want to now start adjusting things to get the right value. So if we go to Debug once again, Pixel Inspector, we'll find that pixel once again."},{"start":"4:17","end":"4:48","startSec":257.7,"text":"And you can see my luminance here is now set to 2.2. Now usually what you want to do is bring this down to 0.8 with the dominant directional light and then start adjusting your exposure later on to actually get the right level of light that you want. So in order to do this, I'm just going to go ahead and inspect the one that I want, press Escape, and now bring the strength of my directional light down. So let's try it with full."},{"start":"4:48","end":"5:18","startSec":288.3,"text":"Once again, we can inspect it. We're at 0.19, so we're close. So once again, Escape, set this to 3.8, and that's how you sort of hone in on the value that you need. So essentially that gives us a, in the linear scale, it creates to 50% gray, but since we have sRGB going on an HDR, it's something that adjusts the curve of the value. So illuminance of 0.18 is the correct sort of 50% gray."},{"start":"5:18","end":"5:52","startSec":318.6,"text":"So from here, we now want to tweak our exposure. So to tweak our exposure, we've got a few methods. If you want to do it just on the viewport, you can go to the Lit tab here and just untick game settings and start editing the exposure through here. Now, it's important to know that this only really affects it for the viewport, so it's not really handy when actually going into the game. To do that, you actually want to do changes based on the post-process volume. So I'm going to select that post-process volume. I'm going to scroll down until I find the exposure settings."},{"start":"5:57","end":"6:27","startSec":357.0,"text":"Now, if you're struggling to find it for whatever reason, you can always just use the search tab. Search exposure. In our case, I just found it right there. So we've got it right here. So we have three ways of measuring exposure, and you can control them using the post-process volume, as I mentioned. So the three modes are auto-exposure histogram, which provides a lot of control with advanced settings, and it's constructed on a 64-bin histogram."},{"start":"6:27","end":"6:57","startSec":387.0,"text":"And it's the default exposure setting the Unreal Engine comes with. Then there's a basic, if we change this to basic auto-exposure, it provides fewer settings for us to actually change, and it computes single values by downsampling exposure itself. And then a manual mode, which actually enables us to change this based on the camera itself. So in our case, we're going to keep it to auto-exposure histogram. And essentially, what you want to be changing more than anything is the minimum and maximum"},{"start":"6:57","end":"7:28","startSec":417.0,"text":"brightness that you have in your scene. So you can bring these values down or up to suit your needs. And these will affect how the auto-exposure changes depending on what you're looking at in the scene. Now, remember that this has to be set to game settings to see the changes that you're making here. For me, we can leave them as default. Or what I like to do is, as I'm working, I like to lock my exposure. So I set this to one and then this to one."},{"start":"7:28","end":"8:02","startSec":448.9,"text":"And once I'm happy with the way everything feels, I can then maybe go to the default or edit them slightly. Because if you can see here now, we'll get eye adaptation to adjust for the darkness on the inside here, which blooms out the outside. So I generally like to work with this set to one and one to lock it in. And then go from these values to edit things afterwards. So I could go to minus five and ten instead so that it never goes that bright or that dark."},{"start":"8:02","end":"8:13","startSec":482.9,"text":"So it's something for you to play with and get the right look for your scene. But I just want to go over these additional tools before we jump into going to artificial lighting, which we're going to go ahead and do next."}],"07_Artificial Lighting":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"We're now ready to take a look at some interior lighting or artificial lighting. And just like I did with the natural daytime lighting, I wanted to go ahead and take a look at some of the required versus optional tools they might have to use. So in the case of man-made lighting, we will need at least one or more man-made light sources, so a point light, spotlight, or rectangular light, or a rect light. And then optionally, depending on your setup, a daylight type setup adjusted for moonlight,"},{"start":"0:34","end":"1:05","startSec":34.0,"text":"so this would require at least directional light and a sky atmosphere. A sky lighting to contribute to the rest of the global illumination. A sky dome for backdrop visuals and volumetric clouds. As well as if we want to use IES profiles for our man-made lights, should we need it. So I think let's go ahead and open up our level here. And just like I've been doing before, just so you know, I'm opening the bunker underscore night level."},{"start":"1:05","end":"1:38","startSec":65.5,"text":"And just like I did with the other levels, I'm going to go ahead and delete most of the lighting in here. So let's go ahead and delete all these. Delete all this lighting information. And in this case, you can see we still have some lighting information coming from this sign. And this is because we're using emissive materials that contribute to lighting. One of them is on a decal, so let's go ahead and delete that."},{"start":"1:38","end":"2:10","startSec":98.2,"text":"And we'll assign the red material that we have here to the Bernese image here, just so we get rid of most of the lighting. Now, one thing I'm not going to do is recreate the daylight setup, because it's just essentially a daylight setup like we did before, but with moonlight. Now, one thing that is slightly unique about this is that the sky atmosphere is accommodating right now for two directional lights, one for the moon and one for the sun. And by default, when we create an environment light mixer setup,"},{"start":"2:10","end":"2:40","startSec":130.3,"text":"it just gives us something that's like nice daytime around 2 p.m. In this case, if you were to create it, you might have noticed that while I was creating it, I was skipping one of the atmospheric lights. That's the one that you add to include a moon in there. So you can see we've got one directional light for the sun and one directional light for the moon. Now, the only thing that's really important for you to know if you're going to go for a setup like this is that the moonlight needs a different index to the sunlight. So all you need to do is select the light search index"},{"start":"2:41","end":"3:12","startSec":161.4,"text":"and make sure that the atmosphere sunlight index is set to one for your moon and set to zero for your sun. Okay, once you've done that, we're ready to go. So let's go ahead and let's take a look at some of the options or tools that we have to light interiors. So first of all, we've got a point light, which is another light. I know I've kind of gone over this a little bit before, but let's go ahead and go over it again. So our point light emits light from a point in all directions."},{"start":"3:14","end":"3:44","startSec":194.1,"text":"And let's go ahead and bring the attenuation down on this one. I'm going to bring it to like 300. I'm going to bring it close to the wall so we can take a look at. We're going to go ahead and change the temperature here to make it a lot more blue. And ways in which we can control the look of this is of course the source radius. So we can change the size of that specular highlight. If you go bigger than the actual bounds of the attenuation, you'll notice that it's suffering some ugly pixelation. So try to avoid that."},{"start":"3:45","end":"4:19","startSec":225.4,"text":"But with this size, let's go ahead and set it to the size of two or something like that. And then we can also change the source length. So the length of the actual source of light. So if I rotate this 90 degrees, we can bring it over to the wall and get a sort of tube lighting setup. Now the intensity of this is way too strong, so let's change it to something like one. So now you can sort of see I've got a tube light setup with a point light. Now remember, this is a light that's shooting light, sorry, light in all directions."},{"start":"4:19","end":"4:52","startSec":259.5,"text":"So it's a little bit more expensive than if you were using something a little bit more directional. Say for example, a spotlight. So if I add a spotlight in here, and sorry, I'll re-add that since it went somewhere a little bit weird. So I've got a spotlight in here. And you can see the tool that I have in my disposal to edit this. First of all, let's go ahead and make it moveable since we're using Lumen. And second of all, we can change the outer cone angle to change the actual shape of the light."},{"start":"4:52","end":"5:29","startSec":293.0,"text":"You can change the inner cone angle to change the hardness of the light. So this is a little bit like that inner radius or source radius, but defining the cone itself alone. You can also change the source radius, so the actual source of the light. Let me bring this a little bit closer to the wall so we can see the difference there properly. You can see how it changes the source radius, changes that specular highlight once again. And you can also change the source length. Let's go ahead and we're actually going to use this to start lighting this since this is a little bit of a spotlight."},{"start":"5:30","end":"6:02","startSec":330.4,"text":"So I'm going to change the temperature here to maybe 4000 Kelvin. I'm going to move it around there. And I could start editing the outer cone and inner cone to get some nice results. Oh, what I think I'm going to do, I'll make the outer cone a little bit wider. But what I think I'm going to do is actually use an IES profile. So let's go ahead and scroll down to the IES section and under IES, I'm going to grab this number 10."},{"start":"6:03","end":"6:35","startSec":363.7,"text":"It's a pretty nice shape. Let's try with this one. And I think these are all a little bit dark on one side. So I think I'm going to go with this number 10 one here. And let's go ahead and change the attenuation of the light to make sure that we're reaching the right amount. So the attenuation is quite big here. So let's go ahead and maybe try with 550. And now what I'm going to do is duplicate the lights and place it around. So I'm going to hold Alt and then move it around. So I'm going to hold Alt and then move."},{"start":"6:39","end":"7:09","startSec":399.1,"text":"And then Alt again to duplicate and move the light. There we go. It's time to get some some lighting in our scene. I'm also going to add a spotlight for this light over here, this big one in the middle. So let's go ahead and add a spotlight there. And then I'm roughly placing these. In this case, I think I'm going to get rid of the IES profile. So I'm going to clear it here."},{"start":"7:10","end":"7:40","startSec":430.2,"text":"I'm just going to make the outer cone much wider. Like so. Same for the inner cone. Just to give it a bit more strength. And I'll bring the attenuation radius up so it's a little bit stronger. Just might bring the intensity down to something like five. So we don't flatten the scene out too much. Maybe three. There we go. Now we have a little bit of lighting information for everything. So that's how we can control spotlights. The next light that I want to take a look at is a rectangular light."},{"start":"7:40","end":"8:09","startSec":460.4,"text":"And we're going to take a look at it with this TV thing that we've got going on here. But for that, I'm going to delete these two lights. Just so that we have a little bit of a darker scene to play with. And for something like this, we want to be using a rectangular light or a rec light. So let's go ahead and drag this in. And I just rotate it and essentially make it match the actual shape of the TV. So let's go ahead and bring it closer to the TV."},{"start":"8:12","end":"8:48","startSec":492.6,"text":"Place it as central as I can. I'm just eyeballing this. And in this case, I can change the source radius. Sorry, the source width and height to edit the way this looks. So let's go ahead and just roughly make it the size of the TV here. And now depending on the light that you have, you can actually change some attributes of this rectangular light to be more interesting. So for example, the barn door angle, if the light needed to be kind of contained a little bit to"},{"start":"8:48","end":"9:18","startSec":528.5,"text":"change its shape and the barn door length. So you can sort of see how you can affect the light there. In our case, I think we actually want these to be flattened since it's just a flat screen TV. It's got a little bit of an angle, so let's try and match that. We'll turn off the angle snap. Match the angle. There we go. Turn these back on. So now, okay, we have something that's pretty good, but the light color is not matching the actual light of the color of the image."},{"start":"9:19","end":"9:51","startSec":559.5,"text":"And the intensity as well. So let's go ahead and change the intensity to something like four. And then I could manually change the color to something close. I could even color pick a color from there and match as good as I can. I could also just manually match the color myself to something that makes a little bit more sense. But actually, one of the nicest features about this rectangular light is that you can actually use a source texture to texture the light itself. So I'm going to go ahead and use the texture that is being used on that screen."},{"start":"9:51","end":"10:21","startSec":591.4,"text":"Let me go ahead and show what happens. So this is the texture that's on the screen. I'm going to go ahead and drag it into source texture. And you'll see it's lighting, but it's actually almost too perfect, right? It gives us too much of an accurate representation of the image. So usually what we do is use a blurred light texture. So it's the same texture as the original, but it's blurred. And using that, you can see we get a really nice realistic effect of what the TV is actually lighting up. And again, this still works with all your intensity controls,"},{"start":"10:21","end":"10:54","startSec":621.5,"text":"so you have nothing to change there. There we have it. We've looked at all the sort of man-made light systems that we have. Now, the last thing that I wanted to cover is emissive lighting. So I'm going to go ahead and once again, just delete all of our work and get rid of these lights. We'll leave these. And take a look at how we can use emissive materials to change lighting. So for example, if we go to the material section here,"},{"start":"10:54","end":"11:23","startSec":654.2,"text":"you'll notice that we have an emissive material here that's emissive. If I drag this onto the object, you can see that it starts emitting light. Now, there's a couple of things that you need to worry about with emissive lighting is that the quality isn't as good as using the emissive material. It's as good as using actual lights. So it's best to actually rely on proper lights to do the work for you. But it might be handy in a couple of different situations."},{"start":"11:25","end":"11:56","startSec":685.2,"text":"And by the way, of course, this is all dynamic and works exactly the same as you'd expect. So in this case, I'm going to go ahead and keep that with the red color and I'm going to assign this material to our burnie sign. Now, you'll notice that this does affect things and it is lighting things up, but you might not be getting the full effect that you need. So in some cases, you need additional information to actually get the final result that you want. In our case, we're going to need a rectangular light to project a little bit more light coming out of this. So let's go ahead and add a rectangular light."},{"start":"11:58","end":"12:31","startSec":718.6,"text":"I'm going to turn it around just like before. Place it in the correct place. I think this might actually be rotated a bit. Place it here. And again, I'm just going to roughly match that shape. And I will be changing the attenuation. So it's not strong. Say something like this. And we'll change the color to this sort of neon red"},{"start":"12:31","end":"13:03","startSec":751.2,"text":"that we've got going on here. So we have the light that it's producing. But you can see we don't have any lighting information on this side here. And for this, we might actually have to use a decal actor. So I'm going to go ahead and bring a decal actor in. And a decal just allows us to project a material or an image onto a surface. Now, they're really good for things like dirt and things like that,"},{"start":"13:03","end":"13:30","startSec":783.9,"text":"but they can also be used as lighting if they use a massive material on them. So let's go ahead and put the emissive material on it for the decal that we have here. And we're just going to project it, if I rotate it here, onto our image. And I'm just going to essentially rotate it and scale it to the right position."},{"start":"13:38","end":"14:09","startSec":818.2,"text":"Go a little bit smaller. And you got to be careful when scaling because you might scale it too much and you won't be able to actually see it on the wall. So you just have to keep nudging. There we go. We have something that matches our image here and starts to produce light as well. So that really is all the techniques that we need to color for interior lighting. And really all the techniques that we need to cover for this whole introductory video."},{"start":"14:10","end":"14:15","startSec":850.5,"text":"So I hope that you've learned a lot and I hope that you had fun with me and I'll catch you in the next one."}],"08_Recap":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"Okay, so that's going to be it for this Unreal Engine training session. We did an introduction to Lighting for architecture, engineering, and construction industries. The topics we covered were Lighting terminology and types. We had a common language for stuff like Direct Lighting and Indirect Lighting, and the types of lights that we actually use. We took a look at how to control exposure and the tools that we have available to that. We looked at Lumen as the default rendering engine in UE5. And then we went ahead and set up some Lighting scenarios for natural exterior lighting."},{"start":"0:35","end":"0:46","startSec":35.5,"text":"We took a look at reflections and how to optimize them, as well as some setups for interior lighting inside of the Unreal Engine. I hope you had fun, and I'll see you in the next training session."}]},"105.01":{"01_Introduction":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hello everyone, and welcome to today's Quick Start class on Sequencer Shot Creation. My name is Brian Poole, and I'll be your authorized Unreal instructor throughout this course. Here's a quick look at what we'll be covering today. In exploring Sequencer fundamentals, we'll examine some core concepts of Sequencer's capabilities like what is Sequencer, what's a level sequence, and we'll discuss actor persistence types. That will be followed by an examination of core structures in Sequencer, we'll define"},{"start":"0:30","end":"1:02","startSec":30.3,"text":"a few terms, and we'll compare Unreal Sequencer to the structure of film production. In Sequencer features and tools, we'll take a look at Sequencer's interface, discuss event management, curve editing, and set up a level sequence template. Plus, we'll spend some time learning about Unreal cameras, their components, and primary feature sets. In hands-on shot creation and assembly, this section will focus on how to actually set up a level sequence assembly and how it ties into the camera cuts track, followed by a"},{"start":"1:02","end":"1:35","startSec":62.2,"text":"practical exercise. And in final recommendations, we'll talk about level organization, folder structures, and Sequencer best practices. And then we'll look into some potential tips and resources. Alright, let's get started. Today's class will be utilizing the SEQ-10501 map level. In the SEQ-90501-55 project file, it can be downloaded under content, courses, course maps. The project file you've downloaded contains items associated with four different courses."},{"start":"1:35","end":"2:07","startSec":95.9,"text":"We'll be examining the course SEQ-10501. Our goal for this course is to start familiarizing ourselves with Sequencer and understanding the basics of creating multiple shots within a single level sequence. This project will utilize a level, contain a character, two cameras, and a camera cuts track. This first approach is the more simplistic of two Sequencer assembly methods, where the second method leverages multiple nested level sequences. We'll get into more in-depth on nested level sequences during another course."},{"start":"2:07","end":"2:39","startSec":127.1,"text":"However, I'll promise you a sneak peek into what a nested level sequence setup looks like just so you can understand the difference. Once you've downloaded the zip file and extracted its contents, you should see the SEQ-90501-55 project file. This file was created in Unreal 5.5, so if you have an earlier version of the engine, you should upgrade. If you have a later version of Unreal, you'll have to convert the project file to Unreal 5.6 by following the prompts Unreal provides for you upon launching this project."},{"start":"2:39","end":"3:11","startSec":159.0,"text":"Now the primary map should load automatically, but in case it doesn't, let's take a look as to where you can find it. Inside the contents folder, there is the courses folder. This folder contains the course maps folder. Within here, you'll find maps for all four courses within this project. In case your level didn't open upon launch, let's double click on the SEQ-10501 map. This will bring you into rural Australia. Now if you take a look around, this is really a great map, and it has some very realistic"},{"start":"3:11","end":"3:44","startSec":191.7,"text":"models and textures. What's even better is that it's highly optimized to run on most computers and GPUs with ease. This map can be found in FAB in case you're interested in having it within your own library. Now if you're curious as to where the assets are for this level, they're located within the assets folder. There is a rural Australia folder, and it contains all of the individual component parts. If we look over here in the outliner, everything is nicely organized into folders and named"},{"start":"3:44","end":"4:17","startSec":224.1,"text":"beautifully with a dedicated naming convention. Now the level sequence we'll be examining and ultimately recreating is located in the course folder. You'll navigate to the SEQ-105 folder, and then open course topics, and finally the camera cuts folder. The level sequence is seq-cinicam-ex. Now if you'd like to take a look, double click on the level sequence icon."},{"start":"4:17","end":"4:49","startSec":257.0,"text":"This will open the sequencer UI and allow you to view the sequence by clicking on the camera icon in the camera cuts track, and then by pressing play. So click on this button, and press play. Now this will show you two cameras being tied together through a camera blend in the camera cuts track, but more on this later. In our next module, we'll take a look at some core concepts behind sequencer and understand"},{"start":"4:49","end":"4:54","startSec":289.5,"text":"the theory of how sequencer fundamentals operate."}],"01_Introduction_55":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hello everyone, and welcome to today's Quick Start class on Sequencer Shot Creation. My name is Brian Poole, and I'll be your authorized Unreal instructor throughout this course. Here's a quick look at what we'll be covering today. In exploring Sequencer fundamentals, we'll examine some core concepts of Sequencer's capabilities like what is Sequencer, what's a level sequence, and we'll discuss actor persistence types. That will be followed by an examination of core structures in Sequencer, we'll define"},{"start":"0:30","end":"1:02","startSec":30.4,"text":"a few terms, and we'll compare Unreal Sequencer to the structure of film production. In Sequencer features and tools, we'll take a look at Sequencer's interface, discuss event management, curve editing, and set up a level sequence template. Plus, we'll spend some time learning about Unreal cameras, their components, and primary feature sets. In hands-on shot creation and assembly, this section will focus on how to actually set up a level sequence assembly and how it ties into the camera cuts track, followed by a"},{"start":"1:02","end":"1:35","startSec":62.2,"text":"practical exercise. And in final recommendations, we'll talk about level organization, folder structures, and Sequencer best practices. And then we'll look into some potential tips and resources. Alright, let's get started. Today's class will be utilizing the SEQ-10501 map level. In the SEQ-90501-55 project file, it can be downloaded under content, courses, course maps. The project file you've downloaded contains items associated with four different courses."},{"start":"1:35","end":"2:07","startSec":96.0,"text":"We'll be examining the course SEQ-10501. Our goal for this course is to start familiarizing ourselves with Sequencer and understanding the basics of creating multiple shots within a single level sequence. This project will utilize a level, contain a character, two cameras, and a camera cuts track. This first approach is the more simplistic of two Sequencer assembly methods where the second method leverages multiple nested level sequences. We'll get into more in-depth on nested level sequences during another course."},{"start":"2:07","end":"2:37","startSec":127.2,"text":"However, I'll promise you a sneak peek into what a nested level sequence setup looks like just so you can understand the difference. Once you've downloaded the zip file and extracted its contents, you should see the SEQ-90501-55 project file. This file was created in Unreal 5.5, so if you have an earlier version of the engine, you should upgrade. If you have a later version of Unreal, you'll have to convert the project file to Unreal 5.6 by following the prompts Unreal provides for you upon launching this project."},{"start":"2:37","end":"3:11","startSec":157.8,"text":"Now, the primary map should load automatically, but in case it doesn't, let's take a look as to where you can find it. Inside the contents folder, there is the courses folder. This folder contains the course maps folder. Within here, you'll find maps for all four courses within this project. In case your level didn't open upon launch, let's double click on the SEQ-10501 map. This will bring you into rural Australia. Now, if you take a look around, this is really a great map, and it has some very realistic"},{"start":"3:11","end":"3:44","startSec":191.7,"text":"models and textures. What's even better is that it's highly optimized to run on most computers and GPUs with ease. This map can be found in FAB in case you're interested in having it within your own library. Now, if you're curious as to where the assets are for this level, they're located within the assets folder. There is a rural Australia folder, and it contains all of the individual component parts. If we look over here in the Outliner, everything is nicely organized into folders and named"},{"start":"3:44","end":"4:17","startSec":224.1,"text":"beautifully with a dedicated naming convention. Now, the level sequence we'll be examining and ultimately recreating is located in the course folder. You'll navigate to the SEQ-105 folder, and then open course topics, and finally the camera cuts folder. Our level sequence is seq-cinicam-ex. Now, if you'd like to take a look, double-click on the level sequence icon."},{"start":"4:17","end":"4:49","startSec":257.1,"text":"This will open the Sequencer UI and allow you to view the sequence by clicking on the camera icon in the camera cuts track, and then by pressing play. So click on this button, and press play. Now this will show you two cameras being tied together through a camera blend in the camera cuts track, but more on this later. In our next module, we'll take a look at some core concepts behind Sequencer and understand"},{"start":"4:49","end":"4:52","startSec":289.6,"text":"the theory of how Sequencer fundamentals operate."}],"02_CoreConcepts":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Welcome back. Let's take a little time to explore some sequencer fundamentals. First up, some core concepts. So what is sequencer? Simply put, it's Unreal Engine's non-linear editor and animation assembly tool designed to supply users with the production tools they'll need to produce animation, trigger various events like blueprints code, and smoothly transition between gameplay and linear animated content. Sequencer is commonly deployed to build shots, generate pre-visualization, manage animation"},{"start":"0:33","end":"1:07","startSec":33.9,"text":"in Unreal, and construct film sequences and game cinematics. From a workflow perspective, sequencer leverages actors on the level and gives them a set of instructions. But as the director, you must cast which actors are going to be used. Actors can be added to sequencer through the Outliner or Content Browser to create level sequence assemblies. A level sequence assembly is essentially a populated level sequence. So what's a level sequence? Essentially, it's a virtual data container. It stores various"},{"start":"1:07","end":"1:42","startSec":67.1,"text":"actors and their associated attributes, keyframe data, lights, cameras, and other edit information. Level sequences can also contain other level sequences to create nested hierarchies capable of replicating film sequences, shots, and departmental organization. They're represented in the level as a traditional clapboard icon, and in sequencer itself, level sequences are represented as traditional film strips similar to what you'd see in a non-linear editing application like Adobe Premiere. Speaking of non-linear editors, sequencer is also capable of exporting edit decision lists"},{"start":"1:42","end":"2:14","startSec":102.2,"text":"and XLM data to synchronize sequencer and your third-party non-linear editor together. As you begin your journey into creating content and Unreal, one of the first concepts you'll need to learn is the idea of actor persistence within your environment, or in Unreal what we call the level or sub-level. Essentially, Unreal has three different ways actors can be controlled in sequencer. This control determines when actors are available to the animator for animating and how long they'll persist in the level over time. Today, we're going"},{"start":"2:14","end":"2:49","startSec":134.0,"text":"to primarily examine two forms of persistence, possessibles and spawnable actors. Possessible actors persist in the level indefinitely and can be controlled or shared by multiple level sequences. If you know you have specific actors or characters that will be used regularly, keeping them as possessibles makes sense for ease of access and repetitious use. It should be noted, however, that possessible characters can only be controlled by one level sequence at a time. Spawnable actors only exist within the active level sequence. They're identified"},{"start":"2:49","end":"3:21","startSec":169.2,"text":"in sequencer and the outliner by a lightning bolt icon. This type of persistence is excellent for temporary actors who are needed for specific needs within the shot. Perhaps some extra lights or a background actor who shows up just for that shot and then is no longer needed. The idea of the spawnable is appealing because it can keep your level and its environment free of unnecessary actors when they're no longer needed. The last type of persistence is replaceable actors. This is a blueprint-driven form of persistence and it's dictated by"},{"start":"3:21","end":"3:53","startSec":201.2,"text":"the binding lifetime track and it allows you to swap out actors within sequencer as needed. So let's switch over to the engine and take a look at how these concepts work. Alright, if you haven't loaded SEQ-10501's map, go ahead and do so at this time. And when you do, you'll find that this level has a number of actors in it. We have a road, a road sign, a fence, some trees, and even a motorcycle. Anything that's been placed into this level has the potential of becoming a possessible actor if it's brought into"},{"start":"3:53","end":"4:23","startSec":233.3,"text":"sequencer. Whatever it is, sequencer can possess that actor and give it instructions beyond the actor's original attributes when in this level. Once the level sequence is done with it, the possessible actor returns to its default state as it originally was within the level. So take this road sign, for example. In the level, it's located in a very specific place. I can take this level actor and bring it into sequencer as a possessible, so let's do that."},{"start":"4:23","end":"4:53","startSec":263.5,"text":"We'll go to content, we'll create cinematics, level sequence, and we'll call this LS test. Double click on the icon and you'll bring up the sequencer UI. Now what I'm going to do is I'm going to add a shot track. Now I'm getting a little bit ahead of myself in that the shot track is a little bit more of an advanced concept. It allows you to nest level sequences inside of a level sequence. I'm going to show it to you for the sake of understanding persistence. So I'm going to"},{"start":"4:53","end":"5:32","startSec":293.6,"text":"click on the button and say create new shot. This will be called shot 1001 and I'll click save. Now you'll get this film strip looking thing here inside of the level sequence. This represents the level sequence shot 0010 underscore 01. And I'm going to retime this level sequence, trim it down a little bit, make it a certain length. And then I'm going to press the shot button again and create another shot. This one will call shot 20. Again, I'm going to retime this and put it later"},{"start":"5:32","end":"6:02","startSec":332.1,"text":"in the LS test level sequences timeline. Alright, so these two level sequences now exist, but they're currently empty. There's nothing in them. So if I were to basically double click on this level sequence, we'll enter it and you can see there's nothing in here. But I'm going to take the road sign. I'm going to add it actor to sequencer. And now it is going to be able to be possessed by this"},{"start":"6:02","end":"6:35","startSec":362.9,"text":"level sequence. And I'm going to give it a set of instructions of what I want it to do. So in this particular case, all I want to do is just push it down into the ground. And if I go back to level sequence test, as long as my time marker is in this level sequence, the road sign will be down in the ground. But if I go outside of this level sequence, it'll return back to its default position. Alright, so let's go over to shot 20. And if I double click on this, take the road side again,"},{"start":"6:35","end":"7:07","startSec":395.8,"text":"and add it to this level sequence. I'm going to do something different. So I'm going to basically give it some animation. I'll move it to the middle of the road. I'll rotate it 180 degrees. And I'll set a keyframe. Alright, and then I'll move the time marker down. And I'll push the road sign down the road and set another keyframe. So now I have some animation. So when I go back to level sequence"},{"start":"7:07","end":"7:40","startSec":428.0,"text":"test, these two level sequences now have active components in it. And it will possess this road sign to tell it what to do. So here we are in shot 20, it's animating. In shot 10, it's pushed down into the ground. So if I move these level sequences into an order that I want. And I press play, we'll see what happens. Down, default, down the road. Now, these level sequences can be shuffled. I"},{"start":"7:40","end":"8:13","startSec":460.3,"text":"can move them into a different order. I could place shot 20 first. And we'll go down the road first, go back to default, and then go down into the ground. The other thing about these level sequences is whatever level sequence is on top takes priority. So in this particular instance, the level sequence shot 20 may be animating it down the road. But as soon as it hits shot 10, it will jump down and be pushed into the ground. So this is how possessibles work. The level sequence"},{"start":"8:13","end":"8:46","startSec":493.0,"text":"basically possesses the level actor and gives it a set of instructions on what to do. Now, let's take a look at something different. If we go into courses, Seq 105.01 and go to course topics, camera cuts, and we load the Seq Sync cam example level sequence. Immediately, you're going to see that we get a mani and two sync cameras. Now, where did they come from? Well, if you look down in"},{"start":"8:46","end":"9:17","startSec":526.1,"text":"Sequencer, you can see that they have the lightning bolt icon next to them. This means that they're spawnable. And in this case, for this level sequence, they've been spawned into existence. And they're here to do whatever it is they're going to do. For mani's case, he's going to animate, walk towards the sign. And these cameras have some specific camera blends that are happening, which we'll see soon in a minute. So this level sequence, let's see what happens when we put"},{"start":"9:17","end":"9:54","startSec":557.8,"text":"this level sequence into another level sequence. Let's go back to the content browser. We'll go and load the LS test. And we'll get rid of these two level sequences. And in this case, we'll add the Seq Sync cam example. Now, here is that level sequence as if it were a shot. And if I move my time marker, there's nothing in this level that I see so far. But as I move, and it hits that level"},{"start":"9:54","end":"10:25","startSec":594.0,"text":"sequence, mani and the two synic cameras are spawned into this level. And they'll remain there until this level sequence is complete. And then they'll just go away. Now this can be at a big advantage in the sense that spawnables can keep my level free of clutter. And they are good for adding in actors or extra lights or extra cameras, as you need them for the specific shot. So they"},{"start":"10:25","end":"10:40","startSec":625.0,"text":"can be a big advantage that way. All right, so this concludes this particular demonstration of what a possessible is and what a spawnable is. We're going to move on now to our next module, which is going to be on core structures within Unreal Sequencer."}],"03_CoreStructure":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Using a game engine for linear animation can be intimidating for the uninitiated. It requires learning new terminology that the average DCC software user is unlikely to be familiar with. Being very modular in nature, Unreal breaks down its world construction and animation features with an array of new technical engine terms that unfortunately have no equivalent in classical digital film production. These terms are directly related to the process of building a game, but once you learn them,"},{"start":"0:31","end":"1:06","startSec":31.7,"text":"you'll come to appreciate their capabilities and logic. Static meshes and scale meshes describe different types of actors based on whether they have a joint-based deformable geometry. Unreal also uses different terms for objects in the scene, like actors, pawns, and characters. The environment is described in terms of the world, maps, levels, and sub-levels. Control rigs are like animation rigs. Terms are used for triggering specific actions or different visual looks. Blueprints are a visual scripting system, and source control is a way to check data in and"},{"start":"1:06","end":"1:37","startSec":66.1,"text":"out of your project using a server depot. However, Sequencer's feature set attempts to mirror some of the terminology you're more familiar with in film production, like scene assemblies, takes, layout, shots, and sequences. It's not a coincidence that Sequencer's level sequence and assembly structure bears a certain similarity to the organization of film production. A typical film is broken down into acts, sequences, scenes, shots, and takes."},{"start":"1:37","end":"2:08","startSec":97.9,"text":"Each unit is smaller than the last, and they effectively are nested inside of one another. On the Unreal side, Sequencer is designed to replicate film structure by using level sequences. These actors can create levels of organization through nesting level sequences into one another. This will allow organizational control over scenes, actors, cameras, lights, keyframes, and other technical capabilities. Since level sequences are essentially virtual containers, they are capable of handling"},{"start":"2:08","end":"2:42","startSec":128.7,"text":"greater and greater orders of animation complexity as more level sequences are added to them. For new users, it can be confusing to realize that the level sequence actor can accommodate so many different tasks while still being called a level sequence. You may hear me say things like level sequence shot, or level sequence sequence, but they're all level sequence actors being used in different ways. Try not to be confused by the words level sequence. As promised, here's an example of what a nested level sequence looks like so we can"},{"start":"2:42","end":"3:17","startSec":162.4,"text":"compare it to what you'll be constructing in a single level sequence during the hands-on exercise. It consists of a parent level sequence with multiple level sequence shots inside of it. The parent level sequence can possess multiple level sequence shots through the use of a shot track. Level sequence shots can be moved, they can be trimmed, or have their play rate altered. You can even generate new takes of shots by using our take system."},{"start":"3:17","end":"3:48","startSec":197.6,"text":"And if you'd like, you can add a fade track to fade up from black. The structure of a nested level sequence can be nearly anything, especially for game construction purposes, but for cinematics and linear content creation there are usually some core ingredients. Inside each level sequence shot, you'll have level actors like props or characters to animate. A minimum of one camera per nested level sequence is needed, whether it's spawnable or possessible."},{"start":"3:48","end":"4:19","startSec":228.0,"text":"And most importantly, you'll need a camera cuts track to generate footage. When played in sequence, the parent level sequence pulls camera binding data from each shot's camera cuts track so it knows which camera it's looking through and what needs to be rendered. The result is a continuous sequence when played back through the timeline. As impressive as nested level sequences are, you might not need so much complexity. With a single camera cuts track and a single level sequence, users can construct long animated"},{"start":"4:19","end":"4:52","startSec":259.7,"text":"takes and assign cuts to the camera cuts track to meet their needs. If multiple cameras are added into the level sequence, that long animated take can easily turn into a master shot with coverage cameras being placed throughout the scene and bound to the camera cuts track to create an engaging sequence where continuity is easily preserved. Let's take a look. Now inside of this 105.1 example, you'll see that I have three cinematic cameras."},{"start":"4:52","end":"5:23","startSec":292.1,"text":"You'll only have two. I've added the third for demonstration purposes. But these three cinematic cameras, camera one, camera two, and camera three, they're all bound to the cinematic camera cuts track at specific points in time. Camera one, camera two, and camera three. If I want an additional fourth shot, it's just a matter of clicking on the plus button and adding a new binding. I'll go to camera one. Now you'll also see that I have this gray box in here."},{"start":"5:23","end":"5:57","startSec":323.3,"text":"This is what's called a camera blend and it can be activated here. The camera blend basically blends the position of two cinematic cameras between shots and the camera cuts track. Let's take a look and see what this looks like. Now this method of level sequence assembly does have its trade offs. The level sequence can become crowded with so many actors and cameras and other effects"},{"start":"5:57","end":"6:20","startSec":357.2,"text":"that it can become cumbersome to organize. Plus in animation and VFX workflows, it's usually necessary to break down things into separate shots for logistical purposes. So a lot of times it all depends on what you're trying to accomplish. Okay, this completes this demonstration. Let's move on to our next module."}],"04_Features":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Welcome to Sequencer Features. The Sequencer UI is straightforward and seems very familiar. Its design is reminiscent of Adobe After Effects and Premiere, but instead of editing rendered movie footage, Sequencer edits footage containing animated 3D assets. The toolbar houses all of the primary settings, menus, render options, and breadcrumb indicators to help the user navigate between level sequences. The Outliner on the left adds actors and organizes tracks."},{"start":"0:30","end":"1:03","startSec":30.3,"text":"You can drag actors into this area from the Outliner or use the green plus add button. The timeline manages the playhead, defines track content, and gives a visual display of what's happening from audio waveforms to setting keyframe indicators. The selection details pane displays properties and binding information, and the playback area allows sequence, transport controls, and time range sliders for defining your work area. Working in combination with Sequencer's Outliner, the event manager and its triggers can be added"},{"start":"1:03","end":"1:35","startSec":63.3,"text":"to a sequence and tied to specific blueprint endpoints. This function allows precisely to control when specific events occur within a level sequence. These triggers could initiate particle systems or tell Unreal when to jump out of Sequencer and into gameplay. The Sequencer Curve Editor is a helpful feature for traditional 3D animators. Specific tracks can be identified, isolated, hidden, or shown within the controls on the left. Keyframes can be moved, scaled, tweened, and tangents can be weighted or broken as needed"},{"start":"1:35","end":"2:08","startSec":95.8,"text":"by the artist to control animated motion. The Sequencer Template is a feature that is intended for ease of use and quick shot creation. If you know how many shots you'll need and approximately the average length of each shot, this template can construct a parent level sequence with as many nested level sequence shots as you require. This makes the organization of shots easy, and it can create identical shot parameters for each nested level sequence. In this demonstration, we'll take a look at how event management is handled in Sequencer"},{"start":"2:08","end":"2:41","startSec":128.6,"text":"with a simple example. By adding an event track into Sequencer, the user can create dedicated triggers that execute specific functions in what is known as the Director Blueprint. The Director Blueprint is a special type of blueprint that's tied to your specific level sequence. When bound to an actor like a particle system, Sequencer can execute the trigger at a specific point in time to activate the particle system. So I have a particle system here. It's an explosion that I got from the starter content. If I click on the Admitter and go over to the Details panel, I'll search for Auto-Activate"},{"start":"2:41","end":"3:12","startSec":161.8,"text":"and I want to turn this off. I don't want the explosion just going off by itself. Next I'll need to take the explosion and the Admitter and add it into Sequencer. Actor to Sequencer, Add P Explosion. Now I'll click on the plus track button and I want to add an event trigger. This event track will allow me to set keyframes anywhere I want, so I'll just create one here. Now this keyframe doesn't do anything yet, and the reason for that is it's not bound"},{"start":"3:12","end":"3:42","startSec":192.1,"text":"to the specific Director Blueprint yet. To do that you can do it in one of two ways. You can either right click over the keyframe itself, go to Properties and click on Unbound, or you can double click on the keyframe itself. This will open up the Director Blueprint and you can see our specific P Explosion event. I'm going to create a toggle active node and make sure that everything is tied together."},{"start":"3:42","end":"4:15","startSec":222.4,"text":"I'll compile and I'll go back to our example. Now we still won't have an explosion yet, there's one more thing that we have to do. Right click over the keyframe, go to Properties and say Call in Editor. And once you do that, anytime that you drag the time marker over the keyframe the explosion will happen. So there you go. Anytime that you drag this over there you'll get another explosion, and you can set as many of these keyframes throughout the event track as you wish."},{"start":"4:15","end":"4:46","startSec":255.7,"text":"Next up is the Curve Editor, which is launched within the Sequencers UI and is capable of refining animation curves, keyframe placements, and tangent settings to achieve the desired results. With its unique set of keyframe scaling tools, animators have very precise control over anything animated within Sequencer. So I have Manny here and he has a control rig, and I've placed some animation on his arm to do a little wave. And if I want to look at those curves, it's just simply select the IK handle and go into the Curve Editor."},{"start":"4:46","end":"5:16","startSec":286.2,"text":"Now we can see all of the individual keys and the individual curves. You can view these curves with different viewing modes. You can use the Transform tool to select curves and scale them from different pivot points. So right now this is all scaling from the center. If I put the pivot point down into the corner, I can scale this by that. There is also the Retime Lattice tool, which is a way to basically retime curves based"},{"start":"5:16","end":"5:48","startSec":316.3,"text":"off of a two dimensional lattice. So by double clicking here, I can add lattice points inside the Curve Editor in order to scale and modify keyframes. There's also the Multi-Select tool, which is another mechanism to scale individual curves or multiple sets of curves, which is also pretty nice. You can scale horizontally, vertically, etc. Finally, there's a number of different tangent tools across here."},{"start":"5:48","end":"6:20","startSec":348.1,"text":"Using these, you can go and put them onto AutoCubic or you can break tangents, you can weight tangents, make them constant or linear. There's a number of different functions here within the Curve Editor that are pretty effective. Alright, let's move on to our last feature. The last feature I want to demonstrate in this module is the Sequencer Template. Select the function in the Create Level Sequence button and it will allow you to set the number of shots, their duration, and other specifics like directory placement and numbering settings."},{"start":"6:20","end":"6:57","startSec":380.7,"text":"Once it's executed, you can find the parent level sequence and the shots you specified in the folder of your choice. So here's the Create Level Sequence button and we'll go up here to Add Level Sequences with Shots. I can give it a specific name, I'll call it Test, and it'll be saved in the root path of Game Cinematic Sequences. I'm going to ask for five shots and each shot will be five seconds in length. So when I say Create Level Sequence with Shots, it will create the level sequence and you can see that I have one, two, three, four, five shots and that's located here in Cinematics"},{"start":"6:57","end":"7:08","startSec":417.9,"text":"Sequences Test. Alright, this concludes our brief overview of some of Sequencer's features. Let's move on to our next module that covers some powerful tools."}],"05_Tools":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Unreal has a number of powerful tools, but probably the most important one to emphasize for Sequencer is its camera tools. Unreal leverages two primary types of cameras. The Cinemate Camera Actor is the camera of choice for creating sequences and shots for cinematic creation or film production. It's designed to emulate a physical camera while maintaining features that allow control over the film back, lens, focus, tracking, and post-processes. The Game Camera Actor is the preferred camera for games because of its simplicity."},{"start":"0:32","end":"1:05","startSec":32.2,"text":"Intended for use as the player's view camera, additional cinematic controls are unnecessary. To place a cinematic camera into your level, go to the Place Actors tab, choose Cine, and then drag a Cinemate Camera Actor into your scene. This will give you a possessible camera. If you're wanting a spawnable camera, you can choose to use the Create Camera button in Sequencer's UI. Once available, you'll be able to see the range of cinematic settings in the Details Editor. Camera binding information can be found by looking in the priority information within"},{"start":"1:05","end":"1:36","startSec":65.5,"text":"the Camera Cuts track or by using the Selection Details window. The primary settings of the Cinemate Camera that are important to note are, film back presets with options to manually alter the sensor size, lens settings like focal length, f-stop, squeeze factor, and diaphragm blade count. These settings are available for setting manual focus distance, a debug focus plane, and focus offsets, and tracking settings allow for look at tracking."},{"start":"1:36","end":"2:10","startSec":96.1,"text":"Finally, post-process settings allow the camera to have specialized effects like color grading, film grain, and other more advanced render settings. You might have noticed that whenever a Cinemate Camera Actor is added to Sequencer for the first time, a Camera Cuts track is automatically generated. The Camera Cuts track is responsible for binding specific cameras to edited cuts within Sequencer's timeline. Remember that the Selection Details panel or the property settings within the Camera Cuts track can give you access to the binding ID or special blueprint conditions."},{"start":"2:10","end":"2:41","startSec":130.7,"text":"There are also different variations of camera components. The Scene Capture Component 2D captures a live snapshot of the scene from any camera and feeds it to a rendered target texture. Think of it like a broadcast camera that beams an image to a receiving television set. The Cinic Capture Component 2D is just like the Scene Capture Component 2D, but includes all the powers and capabilities of a Cinematic Camera. Things like post-processing, OCIO, and lens distortion are supported."},{"start":"2:41","end":"3:16","startSec":162.0,"text":"The VCAM Actor is used to transmit camera motion and control settings remotely through the LiveLink plugin, and lens components are used to create calibrated lens files to match physical camera conditions and apply lens distortions. Welcome to my camera demo. In order to access the Cinematic Camera, go to the Place Actors tab and choose Cine. Here you'll find several tools associated with the Cinematic Camera, including the Cinematic Camera itself. If you click and drag a Cinematic Camera into your level, you'll create a possessible"},{"start":"3:16","end":"3:49","startSec":196.6,"text":"camera that you'll have to separately add into Sequencer. If you only need a spawnable camera, then click on the Create Camera button in the Sequencer UI, and a camera will be added along with its Camera Cuts track. I've created a quick little demo to showcase some of the most used camera settings. You won't have this level in your file, but it's quite easy to set up. Just a couple of cubes and a few keyframes, and you're done. Now I've split the viewport into two panes. The pane on the left is what is known as the Cinematic Viewport."},{"start":"3:49","end":"4:23","startSec":229.6,"text":"This viewport shows you exactly what the camera or camera cuts track is seeing. It also provides you with some extra functionality, like some overlays, some masking features, and transport controls to help you with your cinematic choices. The view on the right, this is the default viewport. This viewport I've set up as my God Camera, and it allows me to observe the entire scene objectively, so it can be very helpful when planning out my action. And if we select on a camera, over here on the right, we'll find the Details panel where"},{"start":"4:23","end":"4:54","startSec":263.7,"text":"all the settings are located. We'll take a look at the focus settings, the look at settings, the focal length, and current aperture fields. Okay, let's get started. All digital cameras use an electronic sensor to capture images, and those sensors are measured in millimeters. Unreal provides you with a range of different camera options in this drop-down menu. By selecting a different setting, you're altering the dimensions of the camera sensor. This will result in a different aspect ratio."},{"start":"4:54","end":"5:25","startSec":294.3,"text":"If your camera isn't listed, you can simply insert your camera sensor measurements in the custom height and width fields. If you're attempting to replicate a traditional film camera's aperture dimensions, remember, they're measured in inches, so you'll have to convert to metric. For lensing options, Unreal does have a small selection of primes and a universal zoom setting. The custom setting allows you to set your min, max, focal length, and f-stops. A squeeze factor and diaphragm blade count settings are also available if you're trying"},{"start":"5:25","end":"5:55","startSec":325.2,"text":"to emulate anamorphic lenses or attempting to modify the bokeh. Also, the current focal length field allows you to change your focal length and the resulting horizontal field of view accordingly. Unreal supports four different focus modes. Use Do Not Override to prevent altering post-process volume settings. Manual focus for setting a specific focus distance. Tracking for tracking actors and disable to turn everything focus-related off."},{"start":"5:55","end":"6:26","startSec":355.9,"text":"If you happen to be looking for that fancy depth of field effect, a lot depends on which film back you're using, the focal length, and the value of your current aperture setting. However, in general, the lower the aperture number, the shallower the depth of field. The higher the number, the deeper the depth of field. If you're focusing on something close to the camera, the aperture will dictate how in-focus things will be in the distance. I'd recommend using values aligned with the classic F-stop numbers, F1 through F22, F1"},{"start":"6:26","end":"7:01","startSec":386.7,"text":"for a blurry background, and F22 for the sharpest. Regarding focus, we can manually set our focus distance by typing in a distance measurement or by using the eyedropper tool. You can select actors in your level and the focus distance will be changed. Be sure to do this in the window that is actively piloting your camera, otherwise this functionality will not work. If you turn on the Debug Focus Plane option, you can see exactly where the focal plane will be placed. Next, focus tracking can be used to track an object in order to set the focus."},{"start":"7:01","end":"7:34","startSec":421.9,"text":"Simply activate Focus Tracking and select your focusing object to track. In my animated example, the cube remains in focus as it travels up and down the road. Look at tracking is also available. Just select your desired actor to track and this function will lock on to its pivot point. If necessary, you can supply offset values to move the look at point if required. The Cine Camera is a very robust tool and there are so many settings that we could explore,"},{"start":"7:34","end":"7:42","startSec":454.4,"text":"but for now, you have some of the most important basics to start creating some interesting shots. Let's move on to our next module."}],"06_ShotCreation":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Creating a level sequence is a straightforward process and there are three methods you can deploy. By using the main toolbar and the Cinematics Clapboard button, you'll create a new level sequence, place that level sequence icon into your level, and it will open the level sequence in Sequencer for you automatically. The next option is using the plus add button in the Content Browser. Browse up to the Cinematics option and choose Level Sequence. This will create a new level sequence, only place it in the Content Browser where you specify,"},{"start":"0:32","end":"1:03","startSec":32.0,"text":"and not immediately save the level sequence to your hard drive. The final method is simply right-clicking in the Content Browser and creating a level sequence in the folder you're currently viewing in the Content Browser. Like the previous method, Unreal will create the level sequence, but not immediately save the file. Whether or not to add a level sequence to your actual level is a matter of choice. If you do, they'll appear in the level as a clapboard to give an indication to other teammates working on your project that this level sequence is tied to a particular level."},{"start":"1:03","end":"1:33","startSec":63.0,"text":"Selecting it and seeing the details in the Details window will allow you to open the level sequence and do other additional tasks. Once a level sequence has been created, you can populate Sequencer with Skeletal or Static Mesh Actors, Lights or Cameras, and provide animation sequences to your actors and keyframes on control rigs and transform tracks. Fade tracks are also available to fade in and fade out of your sequence from any color you choose."},{"start":"1:33","end":"1:52","startSec":93.0,"text":"Right-clicking over the fade track will bring up the Properties field to set various attributes, or you could use the Select Details menu. With all of this information, you're armed and ready to start creating something amazing. Let's move on to our next module where we'll conduct a practical exercise."}],"07_CCExercise":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"To best utilize Sequencer for creating linear animation, you must understand what the Camera Cuts track is used for. In a nutshell, the Camera Cuts track is responsible for binding specific cinematic cameras to the level sequence, so Unreal knows which camera to render. It can also act as a simple non-linear editor. In our example, we have a simple two-camera sequence with a camera blend. We're going to take this one step further by adding a third camera and a cut on the Camera Cuts track."},{"start":"0:33","end":"1:04","startSec":33.4,"text":"Any time you start a new project, its success or failure largely depends on how organized you are. Sequencer is no different. To start, let's make sure you have the 105.01 map properly loaded. This is your level. Go to the course maps folder to find the file and double click on it to load it. Next, you'll need to make your working directory. To do this, right-click in the course topics folder and select create new folder."},{"start":"1:04","end":"1:38","startSec":64.4,"text":"Since there is already a Camera Cuts folder present, make another folder and call it something similar. Double click on the folder and it will immediately open. Next, you're going to need a level sequence. Inside the content browser, right-click and go to cinematics in the pop-up contextual menu. Select create level sequence. Call this seq cinnyc underscore ex2. Once that's done, double click on the icon and open Sequencer."},{"start":"1:38","end":"2:15","startSec":98.6,"text":"Next, you're going to need to create a new Cinic Camera. Use the Camera Create button in Sequencer's toolbar and add the camera. This will generate a Camera Cuts track and a spawnable camera. Rename the camera cinicam underscore 01 underscore sh01. You can pilot the camera by pressing the Camera Pilot button. It will turn blue when it's active. Next, you'll need to add actors to Sequencer."},{"start":"2:15","end":"2:51","startSec":135.0,"text":"Since the original 101 map doesn't include an SK mannequin in the level, we must find one and place it there. Go to the content browser and navigate to the assets folder. Open it and then continue to the mannequin folder and inside that you'll find a character and mesh folder. You want the SK mannequin mesh in the mesh folder. Click and drag this into your level. Return to Sequencer and with Mani selected, click the plus add button. Then go to add actor to Sequencer and choose add SK mannequin."},{"start":"2:51","end":"3:26","startSec":171.6,"text":"Once in Sequencer, right click over Mani in the Sequencer Outliner and convert the selected binding to spawnable. Next we need to add animation to the actor. Since we'll be using animation sequences, we must remove the control rig. Select the control rig and delete it. Don't worry, you can always get it back later. Next we'll want to zero out Mani's transformations in the details panel. We need to do this because the motion capture data is offset by several units from 000."},{"start":"3:26","end":"3:56","startSec":206.7,"text":"Click on the plus button in the animation track and add the animation sequence called ManiAnimTrack. Mani should pop into place near the road sign. Now we need to adjust the staging and shot duration. This will extend our sequence length. Click in the range slider field on the right and change the value to 350. This is a little bit more than what we need, but we'll fix that."},{"start":"3:56","end":"4:29","startSec":236.9,"text":"Next enter the frame value in the time slider or scrub the slider to frame 256 and click on the red right bracket button. Our sequence is now 256 frames long. To accommodate this, the camera cuts track must also be extended. Grab the right side of the film strip and drag it out to the red out marker. Finally, press the home button on your keyboard to center the timeline."},{"start":"4:29","end":"5:02","startSec":269.8,"text":"Now we need to create some additional cine cameras. We're going to need a second and third camera so you can use the create camera button again to create two more spawnable cameras and name them Cinecam02 underscore SH02 and Cinecam03 underscore SH03. Once that's done, you're going to have to move your cameras into place. Pilot your cameras 1, 2, and 3 into position."},{"start":"5:02","end":"5:07","startSec":302.3,"text":"Make sure you're using the pilot button so you can fly your camera directly into position and frame accordingly."},{"start":"5:36","end":"6:09","startSec":336.2,"text":"Next, we must bind the cameras to our camera cuts track. The first camera you created is automatically bound to the camera cuts track. We need to bind the other two. Shot one is approximately 52 frames long, so move your time marker to frame 52 and press the plus button on the camera cuts track."},{"start":"6:09","end":"6:39","startSec":369.2,"text":"Select camera two. Shot two runs about 130 frames, so move your time marker again and press the plus button to add camera three. Finally, you might want to make a decision regarding focus. You can choose to disable your focus on all cameras to keep everything in focus, or you can use the manual focus feature and the eyedropper tool to select Manny and keep him in focus. Once you're satisfied, we'll move on to the final step."},{"start":"6:39","end":"7:12","startSec":399.2,"text":"To create a camera blend, right click over the camera cuts track and sequencers outliner. Go up to the camera blend feature and activate it. Now, go back to sequencer and click and drag on shot two and drag it over shot one. This is going to take some experimentation to get right, but find your timing and choose an option blending curve that meets your expectations. To review your work, click on the camera icon in the camera cuts track and you'll see exactly"},{"start":"7:12","end":"7:32","startSec":432.5,"text":"what the cameras are seeing in the sequence. That's it! Great job! You've constructed your first sequence. Imagine all of the possibilities you can now create. Okay, it's time to move on to our final mod and discuss some recommendations."}],"08_FinalRec":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"As we wrap up this course, I'd like to point out that animation production with a game engine is a challenging but rewarding process. Sequencer's feature set is designed to address many production requirements, however, there are many things that you can do to make your experience in engine a more productive one. The first thing you can do is to concentrate on project and level organization. Unreal, as a game engine, is designed to achieve real-time results within the limits of existing GPU hardware."},{"start":"0:30","end":"1:09","startSec":30.0,"text":"Unlike traditional production that usually has much more computational resources, you should go into your project prepared with a plan to optimize your environments and animation performances for greater efficiency based on your GPU's capabilities. By learning how to use a game engine, you're effectively becoming a better production artist. Most linear content projects rely on large environments and multiple scene setups for shot-based workflows. One of the ways that Epic addresses this issue is by using levels and sub-levels, whereas game productions will likely use world partitions for open-world game play."},{"start":"1:09","end":"1:40","startSec":69.0,"text":"The level editor is a critical tool for organizing your environment by creating specific sub-levels. The primary level or map that pairs to your master level sequence will contain what is known as the persistent level. By default, everything resides here, including anything new added to the level, but once artists start creating additional sub-levels, they're more free to assign different purposes to them. By double-clicking on any one of these additional sub-levels, newly added actors can be placed within them."},{"start":"1:41","end":"2:16","startSec":101.0,"text":"Depending upon your particular project, levels and sub-levels can be used for environmental organization, sequence lighting setups, effects, special camera moves, or whatever you need. Then within Sequencer, these levels can be turned on or off by using visibility tracks. The result allows the artist to selectively visualize portions of the environment on a scene-by-scene basis. Another technique to help keep yourself and your project running smoothly is to create a logically organized nested folder structure within your content browser and project outliner as much as possible."},{"start":"2:16","end":"2:50","startSec":136.0,"text":"While some studios do have their own organizational techniques, many do not. Lack of a common folder structure can make it difficult to hand off projects to other members on your team. A considerable amount of time is wasted by artists trying to dissect other people's work. Make it easier on them and adopt this technique, especially if you're working within a group. Project organization remains one of the most important aspects of any production. In order to improve your chances of success, Epic has collected a number of relevant production tips and resources that can help you along the way."},{"start":"2:50","end":"2:53","startSec":170.0,"text":"We'll take a look at those in our next session."}],"09_Outro":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"As of the date of this recording, Epic has assembled a number of tips and resources that can provide you with the extra technical information and workflow suggestions designed to improve your knowledge of the engine. When you factor in third-party websites, authorized Unreal instructor platforms, and Unreal partners, the number becomes far too many to list in this presentation. However, here are a few simple sequencer tips and resources that you can use to get yourself underway."},{"start":"0:31","end":"1:02","startSec":31.8,"text":"Within Sequencer, the following tips will help improve your efficiency. Right middle mouse button and drag will pan the timeline horizontally and vertically. Shift and scroll will also pan the timeline. Control and scroll is used for zooming the timeline. Alt shift right mouse drag can be used for freeform zooming around the time marker, and pressing the home key on your keyboard will reset the range slider bounds."},{"start":"1:02","end":"1:37","startSec":62.1,"text":"Control drag on the time bar and moving the mouse to the right will define a specific zoom region, whereas control drag on the time bar to the left will reset the zoom region. There are also a number of hotkeys that can come in handy for setting keyframes, centering your timeline, and duplicating selected items. If you have specific technical questions, the Unreal developers website is a great place to start in order to find a number of resources including engine documentation and video-related"},{"start":"1:37","end":"1:54","startSec":97.0,"text":"content. Epic also provides a number of links within the slide deck for you to explore. Take some time and take a look. This concludes our quick start for Sequencer Shot creation. I hope you learned something and enjoyed this class. Thank you."}]},"105.02":{"01_Intro":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hello everyone, and welcome to today's class on Sequencer, Introduction for Linear Content. My name is Brian Poole, and I'll be your authorized Unreal instructor throughout this course. This class is a follow-up from the Quickstart Sequencer class on shock construction. We will readdress some of the content from that class, but we'll also go beyond those lessons by examining more advanced workflows. Here's a quick look at what we'll be covering today."},{"start":"0:30","end":"1:05","startSec":30.0,"text":"In overview, we'll begin by asking the question of what is virtual production, and what are the benefits of using Unreal Engine for linear content. Then we'll re-examine some of the core concepts of sequencer's capabilities like what is sequencer, what is a level sequence, and we'll discuss actor persistence types. That will be followed by an examination of core structures in sequencer, define a few terms, and compare Unreal Sequencer to the structure of film production. Next we'll take a look at sequencer's interface, discuss event management, curve editing, and"},{"start":"1:05","end":"1:36","startSec":65.2,"text":"setting up level sequence templates. Plus, we'll spend some time learning about Unreal cameras and their components, take recorder, live link face, and VCAM. In hands-on, shock creation and assembly, we'll focus on how to actually set up a nested level sequence assembly, how it's different from using just a single camera cuts track alone, and how it ties to the shot track, sub-scene tracks, and other advanced functionality. This will be followed by a practical exercise."},{"start":"1:36","end":"2:09","startSec":96.6,"text":"And then finally, in final recommendations, we'll talk about level organization, folder structures, and sequencer best practices, and then look into potential tips and resources. Alright, let's get started. These class will be utilizing the SEQ-10502 map level in the SEQ-90505 project file. It can be downloaded under content, courses, course maps. The project file you've downloaded contains items associated with four different courses."},{"start":"2:09","end":"2:42","startSec":129.5,"text":"We will be examining the course SEQ-10502. Our goal for this course is to expand our knowledge of sequencer by understanding the basics of creating multiple shots using nested level sequences. This project will utilize a level, multiple level sequences, and contain a character, multiple cameras, camera cuts tracks, and a shot track. This approach is the more advanced of two sequencer assembly methods, whereas the first method only leverages a single level sequence and a single camera cuts track, this version"},{"start":"2:42","end":"3:12","startSec":162.4,"text":"showcases nested level sequences for more advanced shot creation and flexibility. After you've downloaded the zip file and extracted its contents, you should see the SEQ-90501-55 project file. This file was created in Unreal 5.5, so if you have an early version of the engine, you should upgrade. If you have a later version of Unreal, you'll have to convert the project file to Unreal 5.6 or higher by following the prompts Unreal provides for you upon launching this project."},{"start":"3:13","end":"3:43","startSec":193.0,"text":"The primary map should automatically load, but in case it doesn't, let's take a look as to where you can find it. Inside the content folder, there is a course folder. This folder contains a course maps folder. Within here, you'll find maps for all four courses within this project. In case your level didn't open upon launch, let's double click on the SEQ-10502 map. This will bring up Rural Australia. This is a really great map with some very realistic models and textures."},{"start":"3:43","end":"4:15","startSec":223.4,"text":"What's even better is that it's highly optimized and can run on most computers and GPUs with ease. This map can be found on FAP in case you're interested in having it in your own library. If you're curious as to where the assets are for this level, they're located in the assets folder inside Rural Australia. And if we take a look over here in the Outliner, everything is nicely organized into folders and named beautifully with a dedicated naming convention. The level sequence we'll be examining and ultimately recreating is located in the course"},{"start":"4:15","end":"4:50","startSec":255.6,"text":"folder inside of the SEQ-10502 folder. Then open course topics, shot creation folder, and finally the multi-shot EX folder. Our level sequence is SEQ-multi-shot EX. If you'd like to take a look, double click on the level sequence icon. This will open the Sequencer UI and you'll be allowed to view the sequence by clicking on the camera icon in the shots track and then pressing play. This will show you the three level sequence shots being played back-to-back in sequence."},{"start":"4:50","end":"5:04","startSec":290.3,"text":"In our next module, we'll take a look at a brief overview of using Sequencer for virtual production and for the creation of linear content. Then we'll move on to core concepts and structure behind Sequencer and understand how Sequencer fundamentals operate."}],"02_Overview":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Virtual production is commonly thought of as an umbrella term that encompasses a wide range of technologies and digital production techniques. It's also directly associated with a set of technologies known as in-camera visual effects. Here practical content is married directly to digital content on a physical stage using an LED volume. This form of virtual production allows directors to view and interact with virtual environments and characters in real time."},{"start":"0:31","end":"1:03","startSec":31.4,"text":"Through the use of Unreal Engine, virtual production allows for some interesting tool sets, including smart animation construction tools such as Sequencer, iPad-based virtual cameras or VCAMs, a data recording tool set known as Take Recorder, LiveLank, data transmission protocols, remote API, performance capture, and ARKit face tracking. There are also workflows enabling real-time editing and scouting, which allows multiple users to manipulate the scene in real-time."},{"start":"1:03","end":"1:22","startSec":63.6,"text":"Combined with VR scouting-based tools, directors have the opportunity to examine the virtual world in headset. Finally, Unreal provides an all-in-one solution by recording, editing, and integrating post-production inside of Unreal Engine, thus reducing the need for external 2D and 3D applications."}],"03_CoreConcepts":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"For those who watch the Quick Start class on Sequencer, this will seem a little familiar, but for those who have not, let's take a little time to explore some Sequencer fundamentals. So what is Sequencer? Simply put, it's Unreal Engine's non-linear editor and animation tool designed to supply users with the production tools they'll need to produce animation, trigger various events like luprinse code, and smoothly transition between gameplay and linear animated content. Sequencer is commonly deployed to build shots, generate pre-visualization,"},{"start":"0:31","end":"1:05","startSec":31.0,"text":"manage animation in Unreal, and construct film sequences in game cinematics. From a workflow perspective, Sequencer leverages actors from the level and gives them a set of instructions. But as the director, you must cast which actors are going to be used. Actors can be added to Sequencer throughout the Outliner or Content Browser to create level sequence assemblies. These level sequence assemblies are essentially a populated level sequence. So what's a level sequence? Essentially, it's a virtual data container. It stores various actors and their"},{"start":"1:05","end":"1:39","startSec":65.1,"text":"associated attributes, keyframe data, lights, cameras, and other edit information. Level sequences can also contain other level sequences to create nested hierarchies capable of replicating film sequences, shots, and departmental organization. They are represented in the level as a traditional clapboard icon, and in Sequencer itself, level sequences are represented as traditional film strips similar to what you'd see in a non-linear application like Adobe Premiere. Sequencer is also capable of exporting edit decision lists and XML data to synchronize Sequencer"},{"start":"1:39","end":"2:11","startSec":100.0,"text":"and your third-party non-linear editor together. As you begin your journey into creating content for Unreal, one of the first concepts you'll need to learn is the idea of actor persistence within your environment, or in Unreal what we call the level or sub-level. Essentially, Unreal has three different ways actors can be controlled in Sequencer. This control determines when actors are available to the animator for animating and how long they'll persist in the level over time. Today, we're going to primarily examine two forms of persistence,"},{"start":"2:11","end":"2:44","startSec":131.6,"text":"possessibles, and spawnable actors. Possessible actors persist in the level indefinitely and can be controlled or shared by multiple level sequences. If you know you have specific actors or characters that will be used regularly, keeping them as possessibles makes sense for ease of access and repetitious use. It should be noted, however, that possessible characters can only be controlled by one level sequence at a time. Spawnable actors only exist within an active level sequence. They're identified within Sequencer and the Outliner by a lightning"},{"start":"2:44","end":"3:14","startSec":164.6,"text":"bolt icon. This type of persistence is excellent for temporary actors who are needed for specific needs within the shot. Perhaps some extra lights, or a background actor who shows up just for the shot and then is no longer required. The idea of spawnables are appealing because it can keep your level clean and its environment free of unnecessary actors when they're no longer required. The last type of persistence is replaceable actors. This blueprint-driven form of persistence is"},{"start":"3:14","end":"3:48","startSec":195.0,"text":"dictated by the binding lifetime track and allows you to swap out actors within Sequencer as needed. Let's switch over to the engine and take a look at how these concepts work. Alright, we'll begin inside our SEQ-105-02 map. Once it's loaded, you'll see that we have a lot of actors inside this level. There's a road, a road sign, a really nice landscape and some trees, and then there's a motorcycle. Anything placed into the level has the potential of becoming a possessible actor by default when it's brought into Sequencer. Whatever it is, Sequencer can"},{"start":"3:48","end":"4:23","startSec":228.6,"text":"possess that actor and give it instructions beyond the actor's original attributes in the level. Once the level sequence is done with it, the possessible actor returns to its default state as it originally was within the level. So let's take a look at this in a demonstration. So we'll go and create a level sequence. We'll call this LSTest. Now this is a parent level sequence, or what Epic likes to call it, a level sequence with shots. You can double-click on the icon and go into the Sequencer UI and we're going to add a shot track. Now the shot track is unique in that"},{"start":"4:24","end":"4:54","startSec":264.1,"text":"it allows you to nest level sequences inside of a level sequence. So to do that, just click on the plus button and we'll say create new shot asset. This is shot 0010 underscore 01 or just shot 10 for short. Now this will create this filmstrip icon inside of your level sequence. This is basically an empty level sequence and we're just going to trim it down a little bit, maybe make it 65 or so odd frames long, move it over just a touch, and then we'll create a second level sequence and we'll"},{"start":"4:54","end":"5:30","startSec":294.2,"text":"call this one shot 20. We'll do the same thing. We'll trim a little time off of it here and at the end. Now these two empty level sequences can be entered by double-clicking on the filmstrip icon. So if I want to go into shot 10, it's just double-click. And you can see that we're inside of shot 10, nothing's in here. It's empty. But if you look at the breadcrumbs over here on the right, you have LS test and shot 10. Now at this point, you're going to want to start to add actors into your scene"},{"start":"5:30","end":"6:05","startSec":330.7,"text":"and I'll go ahead and select the Unreal bike and say add actor to sequence. So now that the Unreal bike is in here, it's been possessed by shot 10. And I'm going to go and just lay it down on its side, raise up the front just a little bit. And I don't even need to set a keyframe on this. But when I go back to the LS test master, as long as my time marker is inside this level sequence, the bike will be on the ground. But as soon as the time marker goes"},{"start":"6:05","end":"6:36","startSec":365.5,"text":"outside of the level sequence, the bike returns back to its original state. Now, I'll go into shot 20. And I will add the bike again to this shot. I'm going to do something a little different with this one. I'll go ahead and bring it to the center of the road, bring it closer to camera. And I'll rotate it around and stand it upright. And I'll set a keyframe"},{"start":"6:39","end":"7:12","startSec":399.5,"text":"and another keyframe. And I'll push it down the road. I'll also go and change these keyframes to linear. Now if I press play and play this level sequence, you'll see that the bike animates down the road. Now, when we go back into our master, you can see that the bike is being possessed by the individual level sequences that are active. So"},{"start":"7:13","end":"7:47","startSec":433.0,"text":"here, at the beginning of the sequence, the bike is in its natural default state. As soon as it hits shot 10, it lays down on its side. Here it goes back to its default state. And then in shot 20, it travels down the road. Now, these level sequences can be moved any point in time. So if I want to make shot 21st, I can do that. And if I press play now, we'll have the shot going down the road and then laying down on its side."},{"start":"7:47","end":"8:20","startSec":467.1,"text":"Now, something else to remember is that these level sequences, if they're stacked on top of each other, the shot that's on top takes precedence. So in this case, shot 20 has the bike traveling down the road. And then as soon as it hits shot 10, it goes and lays down on its side. And then when the shot 10 is over, again, back to its default state. Now, when it comes time for spawnables, it's a little bit different. Spawnables, if I go inside of this level sequence,"},{"start":"8:21","end":"8:53","startSec":501.4,"text":"all we have is the Unreal bike. But I want to go ahead and add in another character or another actor that I eventually want to turn into a spawnable. Well, if we go into the content browser, and we go to say, our assets, characters, actually, we'll go into mannequin here. Characters mesh, and we'll put mannequin into the level. Now, this has been added to the persistent"},{"start":"8:53","end":"9:25","startSec":533.4,"text":"level. And if we look inside of sequencer, and we press play, he will just be there throughout all shots. He's in the level just like the road sign is, the road, the trees, and so forth. But if I go into shot 10, and I select mani, and I say add actor to sequencer, now mani has been possessed by shot 10. I'm going to delete the control rig. And I'm going to move"},{"start":"9:25","end":"10:00","startSec":565.5,"text":"mani into place. So I'll just rotate him around 90 degrees. I'll move him over next to his bike. Now, in order to change this into a spawnable, you need to right click over mannequin and go to convert selected bindings to spawnable actor. Now you'll see that mannequin has a little lightning bolt icon next to him. And I can proceed by giving him some animation. So I'll click on the plus button here and I'll look for a walk cycle and stretch it out."},{"start":"10:01","end":"10:32","startSec":601.1,"text":"And then I'll set some keyframes on mannequin as well. And you know, he's walking down the road because maybe he's run out of gasoline for his motorcycle. And we'll convert this to linear. So if I press play here, mani will be walking down the road. Now let's go back again to the level sequence with shots."},{"start":"10:33","end":"11:10","startSec":633.8,"text":"You can see that mani is now disappeared out of the level. It's because he's been converted to spawnable. So as the time marker moves, shot 10, mannequin manifests for shot 10. And he has been spawned and he'll continue to be there as long as shot 10 is active. But as soon as the time marker leaves shot 10, mannequin disappears, everything goes back to its default state. And in shot 20, the motorcycle drives down the road. Now this is an advantage of spawnables in that you can see it keeps our level clear of unnecessary actors. You know,"},{"start":"11:10","end":"11:47","startSec":670.7,"text":"if you have a bunch of possessibles inside of the scene, they may clutter up, you know, what you can see or what you're viewing inside of your level sequence. And you might have to turn them on or off, shut off their visibility or move them out of the way of the camera. And that can be a little bit annoying at times. So using spawnables is a direct way of just basically turning them off for only what you need. And you can use spawnables for anything. You can use it for actors like Manny, or you can use them to generate spawnable lights, additional cameras, and so forth."},{"start":"11:48","end":"11:57","startSec":708.3,"text":"All right, this completes this individual demo. And we're going to move on to our next module in which we're talking about some core structures within Sight of Sequencer."}],"04_CoreStructures":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Using a game engine for linear animation can be intimidating for the uninitiated. It requires learning new terminology that the average DCC software user is unlikely to be familiar with. Being very modular in nature, Unreal breaks down its world construction and animation features with an array of new technological engine terms that unfortunately have no equivalent in classical digital film production. These terms are directly related to the process of building a game, but once you learn them, you'll come to appreciate their logic and capabilities."},{"start":"0:33","end":"1:04","startSec":33.4,"text":"Static meshes and scale meshes describe different types of actors based on whether or not they have joint-based deformable geometry. Unreal also uses different terms for objects in the scene, like actors, pawns, and characters. The environment is described in terms of the world, maps, levels, and sub-levels. Level sequences are where you control and keyframe your actors in Sequencer, and control rigs are like animation rigs. Games are used for triggering specific actions or for different visual looks."},{"start":"1:04","end":"1:37","startSec":64.3,"text":"Blueprints are a visual scripting system, and source control is a way to check in data in and out of your project using a server depot. However, Sequencer's feature set attempts to mirror some of the terminology you're more familiar with in film production like scene assemblies, takes, layouts, shots, and sequences. Unreal's project structure and logic has been designed to essentially replicate the operations of film production. The project is the film, and each layer of complexity in Unreal replicates the specific"},{"start":"1:37","end":"2:08","startSec":97.9,"text":"set of responsibilities in the film and its crew. Large sophisticated structures within Unreal are broken down into smaller and smaller components, which grant the user the ability to replicate the intricate requirements of production. Sequencer is also capable of replicating different shooting styles. Classical cinematography recognizes the master scene technique, which can be directly replicated in Unreal using a single level sequence, multiple cameras, and a camera cuts track."},{"start":"2:08","end":"2:40","startSec":128.3,"text":"Whereas the triple take technique is matched by what you're learning today, using nested level sequences and layered sub-scene tracks to create the illusion of continuity by the editing of multiple level sequence shots and having your actors hit specific marks. Each methodology works to organize the necessary roles in production ranging from lighting to set construction to performance. So it's not a coincidence that sequencer's level sequence and assembly structure bears a direct similarity to the organization of film production."},{"start":"2:40","end":"3:10","startSec":160.4,"text":"A typical film is broken down into acts, sequences, scenes, shots, and takes. Each unit is smaller than the last, and they're effectively nested inside of one another. On the Unreal side, sequencer is designed to replicate film structure by using level sequences. These actors can create levels of organization through nesting level sequences into one another. This will allow organizational control over scenes, actors, cameras, lights, keyframes, and other technical capabilities."},{"start":"3:10","end":"3:40","startSec":190.5,"text":"Since level sequences are essentially virtual containers, they're capable of handling greater and greater orders of animation complexity as more level sequences are added to them. For new users, it can be confusing to realize that a level sequence actor can accommodate so many different tasks while still just being called a level sequence. You may hear me say a level sequence shot or a level sequence sequence, but they're all level sequence actors being used in different ways. So try not to be confused by the word level sequence."},{"start":"3:40","end":"4:14","startSec":220.6,"text":"Here's an example of what a nested level sequence looks like. I've loaded the SEQ multi-shot EX level sequence that we'll be recreating during the hands-on exercise. It consists of a level sequence with shots with multiple level sequence shots inside of it. The level sequence with shots can possess an array of shots through the use of a shot track. Level sequence shots can be moved, trimmed, or have their play rate altered."},{"start":"4:14","end":"4:47","startSec":254.0,"text":"You can even generate alternate takes using the take system, or fade up from black using the fade track. The structure of a nested level sequence can be nearly anything, especially for game construction purposes. But for cinematics and linear content creation, there are usually some core ingredients. Inside each level sequence shot, you'll have level actors like props or characters to animate. A minimum of one camera per nested level sequence shot is needed whether it's possessible or spawnable, and most importantly a camera cuts track is required to generate footage."},{"start":"4:48","end":"5:19","startSec":288.6,"text":"Another option is to use what is known as a sub-scene track. This is another form of nested level sequence that functions like a layer. If you're familiar with After Effects, it's very similar to a pre-composition or pre-comp. Sub-scene tracks can be used for animation, camera moves, effects, or specific lighting setups. When played in sequence, the level sequence with shots pulls the camera binding data from each shot's camera cuts track, so it knows which camera it's looking through and what needs to be rendered."},{"start":"5:19","end":"5:42","startSec":320.0,"text":"The result is a continuous sequence when played back through the timeline. This completes this brief examination of a nested level sequence. Let's move on to our next module, where we'll take a look at some sequencer features and tools."}],"05_Features":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Welcome to Sequencer Features. The Sequencer UI is straightforward and seems very familiar. Its design is reminiscent of Adobe After Effects and Premiere, but instead of editing rendered movie footage, Sequencer edits footage containing animated 3D assets. The toolbar houses all of the primary settings, menus, render options, and breadcrumb indicators to help the user navigate between level sequences. The Outliner on the left adds actors and organizes tracks."},{"start":"0:30","end":"1:03","startSec":30.4,"text":"You can drag actors into this area from the Outliner or use the green plus add button. The timeline manages the playhead, defines track content, and gives a visual display of what's happening from audio waveforms to setting keyframe indicators. The selection details pane displays properties and binding information, and the playback area allows sequence, transport controls, and time range sliders for defining your work area. Working in combination with Sequencer's Outliner, the event manager and its triggers can be added"},{"start":"1:03","end":"1:35","startSec":63.4,"text":"to a sequence and tied to specific blueprint endpoints. This function allows precisely to control when specific events occur within a level sequence. These triggers could initiate particle systems or tell Unreal when to jump out of Sequencer and into gameplay. The Sequencer Curve Editor is a helpful feature for traditional 3D animators. Specific tracks can be identified, isolated, hidden, or shown within the controls on the left. Keyframes can be moved, scaled, tweened, and tangents can be weighted or broken as needed"},{"start":"1:35","end":"2:08","startSec":96.0,"text":"by the artist to control animated motion. The Sequencer Template is a feature that is intended for ease of use and quick shot creation. If you know how many shots you'll need and approximately the average length of each shot, this template can construct a level sequence with shots with as many nested level sequence shots as you require. This makes the organization of shots easy, and it can create identical shot parameters for each nested level sequence. In this demonstration, we'll take a look at how event management is handled in Sequencer"},{"start":"2:08","end":"2:41","startSec":128.4,"text":"with a simple example. By adding an event track into Sequencer, the user can create dedicated triggers that execute specific functions in what is known as the Director Blueprint. The Director Blueprint is a special type of blueprint that's tied to your specific level sequence. When bound to an actor like a particle system, Sequencer can execute the trigger at a specific point in time to activate the particle system. So I have a particle system here. It's an explosion that I got from the starter content. If I click on the Admitter and go over to the Details panel, I'll search for Auto Activate"},{"start":"2:41","end":"3:11","startSec":161.5,"text":"and I want to turn this off. I don't want the explosion just going off by itself. Next I'll need to take the explosion and the Admitter and add it into Sequencer. Actor to Sequencer, Add P Explosion. Now I'll click on the plus track button and I want to add an event trigger. This event track will allow me to set keyframes anywhere I want, so I'll just create one here. Now this keyframe doesn't do anything yet, and the reason for that is it's not bound"},{"start":"3:11","end":"3:39","startSec":191.9,"text":"to the specific Director Blueprint yet. To do that, you can do it in one of two ways. You can either right click over the keyframe itself, go to Properties and click on Unbound, or you can double click on the keyframe itself. This will open up the Director Blueprint and you can see our specific P Explosion event. I'm going to create a toggle active node and make sure that everything is tied together."},{"start":"3:42","end":"4:14","startSec":222.1,"text":"I'll compile and I'll go back to our example. Now we still don't have an explosion yet. There's one more thing that we have to do. Right click over the keyframe, go to Properties and say Call in Editor. Once you do that, anytime that you drag the time marker over the keyframe, the explosion will happen. There you go. Anytime that you drag this over there, you'll get another explosion. You can set as many of these keyframes throughout the event track as you wish."},{"start":"4:15","end":"4:46","startSec":255.9,"text":"Next up is the Curve Editor, which is launched within the Sequencers UI and is capable of refining animation curves, keyframe placements, and tangent settings to achieve the desired results. With its unique set of keyframe scaling tools, animators have very precise control over anything animated within Sequencer. So I have Manny here and he has a control rig and I've placed some animation on his arm to do a little wave. If I want to look at those curves, it's just simply select the IK handle and go into the Curve Editor."},{"start":"4:46","end":"5:16","startSec":286.7,"text":"Now we can see all of the individual keys and the individual curves. You can view these curves with different viewing modes. You can use the Transform tool to select curves and scale them from different pivot points. So right now this is all scaling from the center. If I put the pivot point down into the corner, I can scale this by that. There is also the Retime Lattice tool, which is a way to basically retime curves based"},{"start":"5:16","end":"5:48","startSec":316.8,"text":"off of a two-dimensional lattice. So by double clicking here, I can add lattice points inside the Curve Editor in order to scale and modify keyframes. There's also the Multi-Select tool, which is another mechanism to scale individual curves or multiple sets of curves, which is also pretty nice. You can scale horizontally, vertically, etc. Finally, there's a number of different tangent tools across here."},{"start":"5:48","end":"6:22","startSec":348.6,"text":"Selecting these, you can go and put them onto AutoCubic or you can break tangents. You can weight tangents, make them constant or linear. There's a number of different functions here within the Curve Editor that are pretty effective. All right, let's move on to our last feature. The last feature I want to demonstrate in this module is the Sequencer Template. Select the function in the Create Level Sequence button and it will allow you to set the number of shots, their duration, and other specifics like directory placement and numbering settings."},{"start":"6:22","end":"6:59","startSec":382.3,"text":"Once it's executed, you can find the parent level sequence and the shots you specified in the folder of your choice. So here's the Create Level Sequence button and we'll go up here to Add Level Sequences with Shots. I can give it a specific name. I'll call it Test and it'll be saved in the root path of Game Cinematic Sequences. I'm going to ask for five shots and each shot will be five seconds in length. So when I say Create Level Sequence with Shots, it will create the level sequence and you can see that I have one, two, three, four, five shots and that's located here in Cinematics"},{"start":"6:59","end":"7:10","startSec":419.5,"text":"Sequences Test. Alright, this concludes our brief overview of some of Sequencer's features. Let's move on to our next module that covers some powerful tools."}],"06_Tools":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Unreal has a number of powerful tools, but probably the most important one to emphasize for Sequencer is its camera tools. Unreal leverages two primary types of cameras. The Cinemate Camera Actor is the camera of choice for creating sequences and shots for cinematic creation or film production. It's designed to emulate a physical camera while maintaining features that allow control over the film back, lens, focus, tracking, and post-processes. The Game Camera Actor is the preferred camera for games because of its simplicity."},{"start":"0:32","end":"1:05","startSec":32.2,"text":"Intended for use as the player's view camera, additional cinematic controls are unnecessary. To place a cinematic camera into your level, go to the Place Actors tab, choose Cine, and then drag a Cinemate Camera Actor into your scene. This will give you a possessible camera. If you're wanting a spawnable camera, you can choose to use the Create Camera button in Sequencer's UI. Once available, you'll be able to see the range of cinematic settings in the Details Editor. Camera binding information can be found by looking in the priority information within"},{"start":"1:05","end":"1:35","startSec":65.5,"text":"the Camera Cuts track or by using the Selection Details window. The primary settings of the Cinemate Camera that are important to note are, film back presets with options to manually alter the sensor size, lens settings like focal length, f-stop, squeeze factor, and diaphragm blade count. These settings are available for setting manual focus distance, a debug focus plane, and focus offsets, and tracking settings allow for look-at tracking."},{"start":"1:35","end":"2:10","startSec":95.8,"text":"Finally, post-process settings allow the camera to have specialized effects like color grading, film grain, and other more advanced render settings. You might have noticed that whenever a Cinemate Camera Actor is added to Sequencer for the first time, a Camera Cuts track is automatically generated. The Camera Cuts track is responsible for binding specific cameras to edited cuts within Sequencer's timeline. Remember that the Selection Details panel or the property settings within the Camera Cuts track can give you access to the binding ID or special blueprint conditions."},{"start":"2:10","end":"2:41","startSec":130.5,"text":"There are also different variations of camera components. The Scene Capture Component 2D captures a live snapshot of the scene from any camera and feeds it to a render target texture. Look if it like a broadcast camera that beams an image to a receiving television set. The Cinic Capture Component 2D is just like the Scene Capture Component 2D, but includes all the powers and capabilities of a Cinematic Camera, things like post-processing, OcIO, and lens distortion are supported."},{"start":"2:41","end":"3:12","startSec":161.9,"text":"The VCam Actor is used to transmit camera motion and control settings remotely through the LiveLink plugin, and lens components are used to create calibrated lens files to match physical camera conditions and apply lens distortions. Welcome to my camera demo. In order to access the Cinematic Camera, go to the Place Actors tab and choose Cine. Here you'll find several tools associated with the Cinematic Camera, including the Cinematic Camera itself."},{"start":"3:12","end":"3:42","startSec":192.2,"text":"If you click and drag a Cinematic Camera into your level, you'll create a possessible camera that you'll have to separately add into Sequencer. If you only need a spawnable camera, then click on the Create Camera button in the Sequencer UI, and a camera will be added along with its Camera Cuts track. I've created a quick little demo to showcase some of the most used camera settings. You won't have this level in your file, but it's quite easy to set up. Just a couple of cubes and a few keyframes, and you're done."},{"start":"3:42","end":"4:14","startSec":222.5,"text":"Now I've split the viewport into two panes. The pane on the left is what is known as the Cinematic Viewport. This viewport shows you exactly what the camera or camera cuts track is seeing. It also provides you with some extra functionality, like some overlays, some masking features, and transport controls to help you with your cinematic choices. The view on the right, this is the default viewport. This viewport I've set up as my God Camera, and it allows me to observe the entire scene"},{"start":"4:14","end":"4:44","startSec":254.3,"text":"objectively, so it can be very helpful when planning out my action. And if we select on a camera, over here on the right, we'll find the Details panel where all the settings are located. We'll take a look at the focus settings, the look at settings, the focal length, and current aperture fields. Okay, let's get started. All digital cameras use an electronic sensor to capture images, and those sensors are measured in millimeters."},{"start":"4:44","end":"5:19","startSec":284.4,"text":"Unreal provides you with a range of different camera options in this drop-down menu. By selecting a different setting, you're altering the dimensions of the camera sensor. This will result in a different aspect ratio. If your camera isn't listed, you can simply insert your camera sensor measurements into custom height and width fields. If you're attempting to replicate a traditional film camera's aperture dimensions, remember, they're measured in inches, so you'll have to convert to metric. For lensing options, Unreal does have a small selection of primes and a universal zoom setting."},{"start":"5:19","end":"5:49","startSec":319.0,"text":"The custom setting allows you to set your min, max, focal length, and f-stops. A squeeze factor and diaphragm blade count settings are also available if you're trying to emulate anamorphic lenses or attempting to modify the bokeh. Also, the current focal length field allows you to change your focal length and the resulting horizontal field of view accordingly. Unreal supports four different focus modes. Use Do Not Override to prevent altering post-process volume settings, Manual Focus for setting a"},{"start":"5:49","end":"6:21","startSec":349.5,"text":"specific focus distance, Tracking for tracking actors, and Disable to turn everything focus related off. If you happen to be looking for that fancy depth of field effect, a lot depends on which film back you're using, the focal length, and the value of your current aperture setting. However, in general, the lower the aperture number, the shallower the depth of field. The higher the number, the deeper the depth of field. If you're focusing on something close to the camera, the aperture will dictate how in-focus"},{"start":"6:21","end":"6:52","startSec":381.3,"text":"things will be in the distance. I'd recommend using values aligned with the classic F-stop numbers, F1 through F22, F1 for a blurry background, and F22 for the sharpest. Regarding focus, we can manually set our focus distance by typing in a distance measurement or by using the eyedropper tool. You can select actors in your level and the focus distance will be changed. Be sure to do this in the window that is actively piloting your camera, otherwise this functionality will not work."},{"start":"6:52","end":"7:24","startSec":412.7,"text":"If you turn on the Debug Focus Plane option, you can see exactly where the focal plane will be placed. Next, focus tracking can be used to track an object in order to set the focus. Simply activate Focus Tracking and select your focusing object to track. In my animated example, the cube remains in focus as it travels up and down the road. Look at tracking is also available. Select your desired actor to track and this function will lock on to its pivot point."},{"start":"7:24","end":"7:44","startSec":444.9,"text":"If necessary, you can supply offset values to move the look at point if required. The Cine Camera is a very robust tool and there are so many settings that we could explore, but for now, you have some of the most important basics to start creating some interesting shots. Let's move on to our next module."}],"07_Enhancements":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Epic has provided a series of enhanced tools for Unreal Engine that directly integrates with Sequencer to allow more advanced users the opportunity to expand their creative workflows. These tools are designed to bridge the missing gaps many productions face when working in virtual production. Intended to promote digital connectivity, enhance performance capture, and improve cinematography capabilities, these enhancements are a must for your workflow. First up is Take Recorder."},{"start":"0:30","end":"1:05","startSec":30.4,"text":"This tool is like having your own recording studio in your back pocket. Designed to record gameplay animation, live performances, camera data, and other sources of input, Take Recorder allows artists to leverage their recordings directly in Sequencer. By layering captured recordings together via sub-scene tracks in Sequencer, sophisticated performances can be accomplished with a minimal crew in a highly iterative workflow. Live Link Face and MetaHuman Animator are next. Built around the Live Link data transfer protocol, users with an iPhone and a reasonably powered"},{"start":"1:05","end":"1:35","startSec":65.0,"text":"computer can stream facial capture data directly into Unreal Engine. When paired with MetaHuman Animator and MetaHuman Creator in Unreal Engine 5.6 or above, these tools can generate live performances for a number of applications like digital avatars, high-end facial capture, or streaming. iOS devices with true depth cameras can find the Live Link Face application on the Apple Store while other vertically head-mounted professional camera systems are also supported with Live Link Face."},{"start":"1:35","end":"2:09","startSec":95.7,"text":"Finally, for all of you aspiring cinematographers out there, Epic's Unreal Vcam app allows you to connect your iOS device to Unreal in order to leverage the device's AR kit capabilities. By transmitting the iOS device's internal accelerometer data back to Unreal via Live Link, Unreal will in turn update a virtual camera inside the Engine scene and pixel-stream the live feed of the CG environment back to the user. The result is a real-time virtual camera that allows the user to frame up shots by hand."},{"start":"2:09","end":"2:39","startSec":129.0,"text":"When paired with other practical camera equipment like gybs or a steadicam, professional shots can be constructed that would be difficult to accomplish by keyframing alone. The Unreal Vcam is compatible with iOS version 16 or higher. And if you happen to have the Nintendo Joy-Con controllers, you can use this for camera control as well. And for those Android users out there, you're no longer left in the dark. Epic has released Vcam for Android in Unreal Engine 5.4, and as long as you're running"},{"start":"2:39","end":"2:53","startSec":159.2,"text":"Android device 7 or later, you'll be able to enjoy the same capabilities as your iOS coworkers. You can also leverage multiple Vcam users to control multiple Vcam devices in a single session. Okay, let's move on to our next topic."}],"08_ShotCreation":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Creating a level sequence is a straightforward process and there are three methods you can deploy. By using the main toolbar and the Cinematics Clapboard button, you'll create a new level sequence, place that level sequence icon into your level, and it will open the level sequence in Sequencer for you automatically. The next option is using the plus add button in the Content Browser. Browse up to the Cinematics option and choose Level Sequence. This will create a new level sequence, only place it in the Content Browser where you"},{"start":"0:30","end":"1:03","startSec":30.5,"text":"specify and not immediately save the level sequence to your hard drive. The final method is simply right clicking in the Content Browser and creating a level sequence in the folder you're currently viewing in the Content Browser. Like the previous method, Unreal will create the level sequence but not immediately save the file. Whether or not to add a level sequence to your actual level is a matter of choice. If you do, they'll appear in the level as a clapboard to give an indication to other teammates working on your project that this level sequence is tied to a particular level."},{"start":"1:03","end":"1:33","startSec":63.8,"text":"Selecting it and seeing the details in the Details window will allow you to open the level sequence and do other additional tasks. Once a level sequence has been created, you can populate Sequencer with Skeletal or Static Mesh Actors, Lights, or Cameras, and provide animation sequences to your actors and key frames on control rigs and transform tracks. Fade tracks are also available to fade in and fade out of your sequence from any color you choose."},{"start":"1:33","end":"1:51","startSec":93.8,"text":"Right clicking over the fade track will bring up the Properties field to set various attributes or you could use the Select Details menu. With all of this information, you're armed and ready to start creating something amazing. Let's move on to our next module where we'll conduct a practical exercise."}],"09_Exercise":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"When using Sequencer to create linear content, you must fully understand what the Camera Cuts track is being utilized for, along with comprehending the idea of using nested level sequences. In a nutshell, the Camera Cuts track is responsible for binding specific cameras to the level sequence so Unreal knows which camera to render. Level sequences that are used as shots are brought into the parent level sequence via the Shot track, and each shot must have its own dedicated camera and camera cuts track. As you build your parent or master level sequence, Sequencer takes on its non-linear"},{"start":"0:34","end":"1:06","startSec":34.2,"text":"editor role to allow you to move your shots into any order you see fit. In our demo, we'll be recreating an even simpler three shot sequence that leverages these concepts. Please understand that there are multiple ways to go about this process. The style in which you build your shots will ultimately be what works best for you. Anytime you start a new project, its success or failure largely depends upon how organized you are. Sequencer is no different. To start, let's make sure you have the 105.02 map properly loaded."},{"start":"1:06","end":"1:40","startSec":66.9,"text":"The level will be located in the Course Maps folder within the Courses folder. Find the 105.02 level file and double click on it to load it. This is your level. Next you'll need to make your own working directory. To do this, navigate to the Courses folder and then open the SEQ 105.02 folder. In there you'll find the Course Topics folder. Open that and proceed on to the Shot Creation folder and finally create your own folder. Since there is an existing Multi Shot EX folder, call your folder something else in order"},{"start":"1:40","end":"2:11","startSec":100.1,"text":"to store your files in it. Double click on the folder and it will immediately open. Now you're going to need a level sequence. Inside your Multi Shot EX folder, right click and go to the Cinematics pop up contextual menu to create a level sequence. Call this SEQ underscore cine underscore EX. This is ultimately going to be your parent or master level sequence. Create three folders and name them cinexshot1, cinexshot2, and cinexshot3."},{"start":"2:11","end":"2:48","startSec":131.3,"text":"These folders will hold the necessary level sequences for your shots. It's best to break out shots into separate folders for the sake of keeping things organized. Next enter the folder for your first shot. Create a level sequence and name it ms underscore ex underscore shot1. This is your first shot. Don't create extra shots yet though. We'll save that for another step. Once you've created your shot, double click on the icon and open Sequencer."},{"start":"2:48","end":"3:19","startSec":168.2,"text":"Once your shot is open, you'll need to create a new cine camera. Use the create camera button in the sequencer toolbar to add a spawnable camera. This will also generate a camera cuts track. Rename the camera cinecam underscore 01 underscore shot1. You can pilot the camera by pressing the camera pilot button. It will turn blue when it's active. Next you'll need to add an actor to sequencer."},{"start":"3:19","end":"3:52","startSec":200.0,"text":"Since the original 105.02 map doesn't include an SK mannequin in the level, we must find one and place one there. Go to the content browser and navigate to the assets folder. Open it and then continue to the mannequin folder. Inside you'll find the character and mesh folders. You'll want the SK mannequin mesh in the mesh folder. Click and drag this into your level. Return to sequencer and with mani selected click the plus add button. Go to add actor to sequencer and then choose add SK mannequin."},{"start":"3:52","end":"4:23","startSec":232.9,"text":"Once in sequencer, right click over mani in sequencer's outliner and convert the selected binding to spawnable. Now it's time to add some animation to our actor. Since we'll be using animation sequences rather than directly keyframing mani's control rig itself, we must remove or mute the control rig to allow the animation sequence to function. Select the control rig and delete it. Don't worry, you can always get it back later."},{"start":"4:23","end":"4:55","startSec":263.6,"text":"Now to get your animation on your actor, click the plus button for mani in the animation track. This will bring up a menu for you to choose an animation sequence. Search for mani underscore anim underscore track and add it to sequencer. Once loaded, make sure the sequence starts at frame zero. Next we must adjust our actor's position, animate the camera and modify our shot's duration. Whenever you add an animation sequence to an actor, please be aware that the animation"},{"start":"4:55","end":"5:31","startSec":295.0,"text":"data might move your character to a different location. If you noticed, by adding the mani anim track to mani, he's moved way past the scene where we're filming. This is because the animation sequence's animation was offset from zero zero zero when it was exported. To correct for this, all we have to do is zero out mani's transformations and he should pop into place. If you want him precisely in front of the sign, move him plus 50 units on the y axis."},{"start":"5:31","end":"6:04","startSec":331.5,"text":"Next we'll need to reposition the camera. Click on the camera pilot button so you can see what the camera is seeing or if you prefer, you can switch over to a two pane window layout and drag the camera into position. If you're feeling adventurous, you can animate the camera by setting a few keyframes to push in or boom up. Finally, we must trim down the first shot to approximately 105 frames. Move your time marker into position and press the right bracket key. This will create an out point for your level sequence while the in point will remain at"},{"start":"6:04","end":"6:38","startSec":364.1,"text":"zero. Please realize that some studios will choose to start their sequences and shots at frame one thousand one rather than at zero. It's easier to leverage warm up frames and back time the shot if necessary. But for now, zero is fine. Finally, make sure that the camera cuts track runs the length of the entire shot. If necessary, adjust its in and out points accordingly. Our next step is to create our second shot, but we're going to do something a little different."},{"start":"6:38","end":"7:20","startSec":398.9,"text":"Instead of creating everything again from scratch, we're going to duplicate shot one and use it as the basis for our next shot. Once duplicated, rename it properly to shot two and move it to the appropriate shot folder. Now that we have our second shot created, we'll need to modify our camera's position and alter the animation track accordingly. Delete any existing keyframes you might have created from shot one and move the camera into a new position."},{"start":"7:20","end":"8:03","startSec":440.8,"text":"Secondly we're going to have to adjust and reposition the animation track for shot two's performance by sliding the action we want towards frame zero. Once you've retimed the animation track, be sure to adjust the camera cuts track and the sequences out point accordingly."},{"start":"8:03","end":"8:43","startSec":483.1,"text":"For shot three, repeat steps six through eight, or if you'd like, you can just right-click over the shot in Sequencer to duplicate and save your shot to the appropriate folder. If you wish to explore different camera placements for shot three, you can either duplicate the shot as an alternate take and manually replace it in your edit, or utilize Sequencer's take system once you're in the level sequence with shots. Now it's time to put everything together. Go to your level sequence with shots and add a shot track."},{"start":"8:43","end":"9:16","startSec":523.5,"text":"This will allow you to bring your shots into Sequencer. Place them in the appropriate order and adjust your level sequence with shots out point as necessary. Don't forget to add your duplicated third shot to the sequence, especially if you've made some changes."},{"start":"9:16","end":"9:50","startSec":556.2,"text":"Click on the shot track's camera icon to review the sequence when you press play. If you need to trim your shots to improve continuity, feel free to do so. Once your shots are in the shot track, you can utilize Sequencer's take system to right-click over the shot and create a new take."},{"start":"9:50","end":"10:22","startSec":590.3,"text":"This will also duplicate the shot and make it accessible in the take systems menu. Once you make the shift, you can alter the take however you wish. If you don't like it, you can always switch back to take one. What I've just presented to you is just the beginning. There are so many different ways shots can be constructed and modified. You could leverage a subscene track for Manny's animation, or you can alter camera settings, add some depth of field, or read time shots using various time remapping tools."},{"start":"10:22","end":"10:40","startSec":622.4,"text":"The options are up to you. If you're curious about subscene tracks, the original SEQ Multi-Shot EX level sequence includes the usage of a subscene track for your review. Take a look and see how it might change your shot setup. Now let's move on to some final recommendations."}],"10_Organization":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"As we wrap up this course, I'd like to point out that animation production with a game engine is a challenging but rewarding process. It allows for instantaneous feedback at a level of visual quality that most DCCs can't match. Plus, Sequencer's feature set is designed to address many production requirements. However, if you need more help, there are many things you can do to make your experience in engine a more productive one. The first thing you can do is to concentrate on project and level organization."},{"start":"0:30","end":"1:05","startSec":30.0,"text":"Unreal, as a game engine, is designed to achieve real-time results within the limits of existing GPU hardware. Unlike traditional production that usually has more computational resources, you should go into your projects prepared and with a plan to optimize your environments and animation performances for greater efficiency based off of your GPU's capabilities. By learning how to use a game engine, you'll ultimately become a better production artist. Most linear content projects rely on large environments and multiple scene setups for shot-based workflows."},{"start":"1:05","end":"1:37","startSec":65.0,"text":"One of the ways that Epic addresses this issue is by using levels and sub-levels, whereas game productions will most likely use world partition for open-world gameplay. The level editor is critical for organizing your environment by creating specific sub-levels. The primary level or map that pairs with your master level sequence will contain what is known as the persistent level. By default, everything resides here, including anything that is newly added to the level, but once artists start creating additional sub-levels, they're more free to assign different purposes for them."},{"start":"1:37","end":"2:06","startSec":97.0,"text":"By double-clicking on any one of these additional sub-levels, newly added actors can be placed within them. Depending upon your particular project, levels and sub-levels can be used for environmental organization, sequence lighting setups, effects, special camera moves, or whatever you need. Then within Sequencer, these levels can be turned on or off by using visibility tracks. The result allows the artist to selectively visualize the portions of the environment on a scene-to-scene basis."},{"start":"2:07","end":"2:40","startSec":127.0,"text":"Another technique to keep yourself and your project running smoothly is to create a logically organized nested folder structure in your content browser and your project outliner as much as possible. While some studios do have their own organizational techniques, many do not. Lack of a common folder structure can make it difficult to hand off projects to other members of your team. A considerable amount of time is wasted by artists trying to dissect other people's work. Make it easier on them and adopt this technique especially if you're working within a group."},{"start":"2:41","end":"3:15","startSec":161.0,"text":"Of all the organizational tools in Sequencer, sub-scene tracks unquestionably remain one of the most powerful tools you can use. This particular type of track is designed to take nested level sequences and use them as a potential layering source inside your parent level sequence. Depending upon your needs, sub-scene tracks can be used to separate out specific creative tasks like animation, effects, camera, lighting, and sound. By individualizing your creative requirements into separate tracks, you permit artists to work more collaboratively with one another."},{"start":"3:15","end":"3:47","startSec":195.0,"text":"Since each sub-scene track is a separate level sequence, departments or individual artists can check out the sub-scene via source control while still allowing other artists to work within the parent level sequence. Sub-scene tracks can be edited, retimed, shuffled, or turned on and off if needed. When combined with a level editor, projects can be highly organized and yet remain quite flexible for large or small teams working together. Project organization remains one of the most important aspects of any production."},{"start":"3:47","end":"3:57","startSec":227.0,"text":"In order to improve your chances of success, Epic has collected a number of relevant production tips and resources that can help you along the way. We'll take a look at that in our next section."}],"11_TipsResources":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"As we wrap up this course, I'd like to point out that animation production with a game engine is a challenging but rewarding process. It allows for instantaneous feedback at a level of visual quality that most DCCs can't match. Plus, Sequencer's Feature Set is designed to address many production requirements. However, if you need more help, there are many things you can do to make your experience in Engine a more productive one. The first thing you can do is to concentrate on project and level organization."},{"start":"0:30","end":"1:05","startSec":30.0,"text":"Unreal, as a game engine, is designed to achieve real-time results within the limits of existing GPU hardware. Unlike traditional production that usually has more computational resources, you should go into your projects prepared and with a plan to optimize your environments and animation performances for greater efficiency based off of your GPU's capabilities. By learning how to use a game engine, you'll ultimately become a better production artist. Most linear content projects rely on large environments and multiple scene setups for shot-based workflows."},{"start":"1:05","end":"1:37","startSec":65.0,"text":"One of the ways that Epic addresses this issue is by using levels and sub-levels, whereas game productions will most likely use world partition for open-world gameplay. The level editor is critical for organizing your environment by creating specific sub-levels. The primary level or map that pairs with your master level sequence will contain what is known as the persistent level. By default, everything resides here, including anything that is newly added to the level, but once artists start creating additional sub-levels, they're more free to assign different purposes for them."},{"start":"1:37","end":"2:06","startSec":97.0,"text":"By double-clicking on any one of these additional sub-levels, newly added actors can be placed within them. Depending upon your particular project, levels and sub-levels can be used for environmental organization, sequence lighting setups, effects, special camera moves, or whatever you need. Then within Sequencer, these levels can be turned on or off by using visibility tracks. The result allows the artist to selectively visualize the portions of the environment on a scene-to-scene basis."},{"start":"2:07","end":"2:40","startSec":127.0,"text":"Another technique to keep yourself and your project running smoothly is to create a logically organized nested folder structure in your content browser and your project outliner as much as possible. While some studios do have their own organizational techniques, many do not. Lack of a common folder structure can make it difficult to hand off projects to other members of your team. A considerable amount of time is wasted by artists trying to dissect other people's work. Make it easier on them and adopt this technique especially if you're working within a group."},{"start":"2:41","end":"3:12","startSec":161.0,"text":"Of all the organizational tools in Sequencer, sub-scene tracks unquestionably remain one of the most powerful tools you can use. This particular type of track is designed to take nested level sequences and use them as a potential layering source inside your parent level sequence. Depending upon your needs, sub-scene tracks can be used to separate out specific creative tasks like animation, effects, camera, lighting, and sound. By individualizing your creative requirements into separate tracks,"},{"start":"3:12","end":"3:41","startSec":192.0,"text":"you permit artists to work more collaboratively with one another. Since each sub-scene track is a separate level sequence, departments or individual artists can check out the sub-scene via source control while still allowing other artists to work within the parent level sequence. Sub-scene tracks can be edited, retimed, shuffled, or turned on and off if needed. When combined with a level editor, projects can be highly organized and yet remain quite flexible for large or small teams working together."},{"start":"3:42","end":"4:17","startSec":222.0,"text":"Project organization remains one of the most important aspects of any production. In order to improve your chances of success, Epic has collected a number of relevant production tips and resources that can help you along the way. We'll take a look at that in our next section. As of the date of this recording, Epic has assembled a number of tips and resources that can provide you with the extra technical information and workflow suggestions designed to improve your knowledge of the engine. When you factor in third-party websites, authorized Unreal instructor platforms, and Unreal partners,"},{"start":"4:17","end":"4:49","startSec":257.0,"text":"the number becomes far too many to list in this presentation. However, here are a few simple sequencer tips and resources that you can use to get you underway. Every artist has their own preference when working in Unreal. Therefore, Epic has ensured that you're able to configure your workspace however you wish. By customizing your user interface, you can set up a layout that works best for your hardware's capabilities. Single, dual, and widescreen monitor configurations can be used to best accommodate single and multiple disciplines"},{"start":"4:49","end":"5:18","startSec":289.0,"text":"based on your individual preferences and skill sets. Within Sequencer, these UI shortcuts will make navigating around Sequencer considerably easier. Right mouse button and drag will pan the timeline horizontally and vertically. Middle mouse button scroll will move the timeline up and down while shift and scroll will also pan the timeline left and right. Control and scroll is used for zooming the timeline."},{"start":"5:19","end":"5:52","startSec":319.0,"text":"Alt-Shift, right mouse button drag can be used for free-form zooming around the time marker, and pressing the Home key on your keyboard will reset the range slider bounds. Control plus drag on the time bar to the right will define a specific zoom region, whereas control drag on the time bar to the left will reset the zoom region. In addition to Sequencer-based shortcuts, Unreal has some universal shortcuts that will help you with your general ease of use. There are also a number of white papers available for your educational benefit,"},{"start":"5:52","end":"6:21","startSec":352.0,"text":"including a white paper detailing the breakdown of Epic's Fortnite cinematic trailer. While the paper is somewhat dated by referencing Unreal Engine 4, the white paper highlights processes and workflows as much as tool sets, which can be very beneficial for the beginner. If you have a specific technical question, the Unreal developers website is a great place to start in order to find a number of resources, including in-engine documentation and video-related content."},{"start":"6:23","end":"6:39","startSec":383.0,"text":"Epic also provides a number of links within the slide deck for you to explore. Take some time and take a look. Alright, this concludes Sequencer. Introduction for linear content. I hope you enjoyed the class, and we'll see you the next time. Thank you."}]},"105.04":{"01_Intro":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Hello, and welcome to this session on Cinematics for Architecture in Unreal Engine. My name is Amer Yasin, and I will be your instructor. This is a follow-up to the Sequencer for Architecture introductory class. Make sure you have familiarized yourself with the process of using Sequencer in UE5 before tackling this one. Here you'll learn about creating cinematic shots in Sequencer by experimenting with cine cameras and what they have to offer."},{"start":"0:31","end":"0:48","startSec":31.4,"text":"You'll learn how to create and set up such cameras, how to animate them in different ways, and ultimately how to output high-quality stills and animations to disk using various techniques, including Movie Render Queue. Let's start."}],"02_CineCAMS":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Make sure you have downloaded and extracted the zip file provided for this class. Open the project named Cinematics Arc if you'd like to follow along. The project is mostly the same one that you used in the Sequencer for Architecture class and contains several saved levels. If you load the final scene, the level named 04 Cinematics Render, you see an architectural dwelling with a few characters in a plaza."},{"start":"0:31","end":"1:02","startSec":31.0,"text":"If you go into Play mode, you get a sense of what you are trying to achieve. The previous Sequencer class takes care of the character animations, as well as the animated time of day and the lights coming on towards the end of the animation. In this class, you learn to set and animate various camera shots and arrange them to play in a certain order in Sequencer, as seen in the playback."},{"start":"1:02","end":"1:38","startSec":62.0,"text":"Exit Play mode when done and load the map named 01 Cinematics Cam Pan. You still have the characters and light animations, but this will be your starting point to create various camera shots. Select and load the level sequence. You can see the current animated tracks, but nothing that relates to camera shots just yet. To create these camera shots, you first need to create physical cameras. In Unreal Engine 5, you need to create Cine Camera Actors."},{"start":"1:38","end":"2:10","startSec":98.0,"text":"Cine cameras are a relatively new addition to Unreal Engine. They are meant to replace the older camera system that had less to offer. In the Add to Project panel, if you do a search for camera, you'll see multiple options. Note the two options that read Camera Actor and Cine Camera Actor. Camera Actor is the older method of working. You can still use it, but as stated before, it's old technology that has less to offer."},{"start":"2:10","end":"2:43","startSec":130.0,"text":"As you place a camera actor in the scene, you can see a preview of the camera shot, but in the Details panel, there's very little in terms of parameters. You can switch between perspective and orthographic projection modes, change the field of view,"},{"start":"2:45","end":"3:20","startSec":165.0,"text":"and fiddle a bit with the aspect ratio, but that's about it. Delete this camera and try the same with the Cine Camera. Placement is just as easy, but note how many more properties are available in the Details panel. You have Tracking settings that enable you to follow another actor,"},{"start":"3:23","end":"3:56","startSec":203.0,"text":"you can set the film back to match real-world cameras, choose from various lens settings, and adjust their parameters, adjust focal length and f-stops, and even manually adjust the focus settings for specific shot types."},{"start":"3:56","end":"4:26","startSec":236.0,"text":"To test it out, you can right-click the camera and pilot it to place it in the right spot. You'll notice that you have focus effects already, but you can adjust them further to your liking. At any time, you can exit or eject Cinecam mode and go back to your perspective view. You can go back to it by piloting the camera again or by using the viewport menu."},{"start":"4:27","end":"5:05","startSec":267.0,"text":"The focus method can be set to Do Not Override and let the post-process handle focus for you. It can be set to Disable to completely turn it off. It can be set to Tracking and thus be dependent on an actor you're tracking in the scene, or it can be set to Manual which arguably gives you the most freedom. In that mode, you can set the manual focus distance or use the eyedropper to pick a point on screen."},{"start":"5:07","end":"5:45","startSec":307.0,"text":"Enabling the Debug Plane makes it easier to view the focus plane. Right now, the focus is on the background and the dancing mannequin is blurred. You can change that by adjusting the focal distance, bringing the dancing mannequin into focus and blurring the background. With cameras in the scene, you can use them to override the post-process volume effects. For example, you can set the camera exposure to be different from the rest of the scene or maybe decide on a black and white or a stylized shot."},{"start":"5:48","end":"6:19","startSec":348.0,"text":"You'll notice that this effect will only influence this camera and nothing else in the scene. You can toggle the camera effect to see the results or even eject the camera view altogether. The perspective view and the camera thumbnail show two totally different results. Now that you have covered the basics of a cine camera, it is time to animate its motion. In the next section, you'll animate a simple panning motion."},{"start":"6:19","end":"6:24","startSec":379.0,"text":"Delete this camera before moving on, you won't need it in the next section."}],"03_CamPAN":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Continue your work from the last section. If you have just opened your project, you will need to load the level named 01 Cinematics Cam Pan. You'll also need to select and open the level sequence in anticipation of more animation work. You'll start with a simple motion, with a camera panning in the scene, essentially moving in a straight line from point A to point B. In the last section, you learned how to place a camera in the scene and adjust its transforms."},{"start":"0:31","end":"1:05","startSec":31.8,"text":"Sometimes, an easier way to place a camera is to adjust your perspective view, and then choose the Create Camera Here option in the Viewport menu. You can then switch to the Camera View to fine-tune it. For a bit of housekeeping, you can rename the camera to Cam Pan,"},{"start":"1:08","end":"1:41","startSec":68.7,"text":"and place it in a new folder called Cameras. If you scrub the animation at this stage, you'll notice it is about 1000 frames long, with a few characters animated and others posed. The time of day is also animated, as are some lights in the scene around frame 600. If you want to mute some of these animations, such as the time of day or solar time, you can do so with a right-click on the track."},{"start":"1:41","end":"2:17","startSec":101.5,"text":"To animate the camera, you need to add it to Sequencer. This is easily done with a click and drag from the Outliner. It adds a camera track with the core properties that can be animated, and then adds a camera track with the same properties. You can also add a camera track to the sequence, and then add a camera track to the sequence. You can also add a camera track with the core properties that can be animated, such as Transforms, Aperture and Focal Length."},{"start":"2:18","end":"3:00","startSec":138.1,"text":"But it also adds a Camera Cuts track, where you can define various camera shots to be played in sequence. The little camera icon in the camera track lets you toggle between what the camera sees and a regular view. The same icon on the Camera Cuts track will let you view the camera shots as you define them in the track. Currently, it is hard to see, as you only have one camera, so we'll revisit this one. For now, let's animate the camera. At frame 0, make sure the camera is active, ensure it is in a starting spot you like and create a Transform keyframe for it."},{"start":"3:00","end":"3:28","startSec":180.7,"text":"This will simultaneously create location, rotation and scale keyframes. We don't really need a scale keyframe, so an alternative would have been to create keyframes for location and rotation only. This will do fine though. Scrub through to about frame 300. That's about a third of the current animation length. Move the camera to the right by driving it, and set another Transform keyframe."},{"start":"3:31","end":"4:00","startSec":211.2,"text":"Scrub between these two keyframes to see the end results. You can also playback the animation using the playback controls. To restrict the playback between frame 0 and 300, you can adjust the playback range. You can define the range by dragging the green and red markers,"},{"start":"4:06","end":"4:49","startSec":246.5,"text":"or by using the square brackets as specific frames. In this case, using the left bracket at frame 0, and the right bracket at frame 300. If you want the animation to loop, you can adjust the last icon in the playback controls accordingly. Note the ease-in, ease-out nature of the camera pan. I actually like this, but if you prefer to fine-tune that effect, or indeed eliminate it and replace it with a linear motion, you can certainly do that."},{"start":"4:50","end":"5:21","startSec":290.4,"text":"You can select the Transform track, and open the Curve Editor to adjust the tangents. But for a linear effect, you can simply select all keyframes and turn their interpolation to Linear. If you don't need the power of the Curve Editor, you can make keyframe interpolation changes directly in Sequencer."},{"start":"5:21","end":"6:06","startSec":321.9,"text":"So now we have our first camera animation. Before we move on to the next, there's one last viewing mode to mention. We talked about Cinematic View versus Array View. There's also the option to use a Cinematic Viewport, which adds playback controls to the view. You can also use the"},{"start":"6:09","end":"6:40","startSec":369.9,"text":"You can use it in conjunction with the Camera Cuts track to view what the cameras are looking at. The advantage of this mode is that it still gives you access to playback controls if you go full-screen using F11. This will give you more real estate to view your camera compositions and better analyze your shots. Save your work. In the next section, you create a dolly shot using a Rig Rail. Thanks for watching!"}],"04_Cam_DOLLY":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Continue from the last section or load the level named 02 Cinematics Cam Dolly. Earlier, you animated the camera by moving it linearly from point A to point B. If you need the camera to follow a particular path, you could theoretically create multiple keyframes along a trajectory, but that seldom translates into a smooth transition. In the real world, you'd usually rely on a dolly or a rig rail. You have such a tool in Unreal Engine."},{"start":"0:34","end":"1:08","startSec":34.0,"text":"Let's animate a camera across the grass looking at the plaza. Using the Add to Project icon, look inside the Cinematics section and drag Camera-Rig Rail Actor into the scene. Reorient it towards the plaza. The rig has a path. Select the endpoint and move it across the grass."},{"start":"1:10","end":"1:40","startSec":70.0,"text":"Holding Alt down, move it again to create an additional point on the path. All three points can now be adjusted for locations and tangents. You can add more points if you need to. Now that you have the rig in place, you can create a camera actor to link to it."},{"start":"1:40","end":"2:11","startSec":100.0,"text":"Keep in mind it can be a different actor, like a car or a character. But for now, we need a camera to follow the rig. Add a cine camera to the scene. Name it Cam Dolly. Name it Cam Dolly. But before you move it to the cameras folder, link it first to the rail rig."},{"start":"2:15","end":"2:43","startSec":135.0,"text":"Zero out the camera coordinates to match the rig's position in space, but then move it up in space to a human height level. Reorient it to look at the plaza. At this point, you can move both the rig rail and the camera to the cameras folder."},{"start":"2:46","end":"3:22","startSec":166.0,"text":"You may need to relink the camera to the path. If you select the rail and change its current position on rail value, you can see the camera traveling alongside it. The Lock Orientation to Rail option enables the camera to rotate as it travels, but this may be more suitable for a vehicle traveling along a path than a camera, as a good camera shot typically needs a focal point."},{"start":"3:22","end":"4:00","startSec":202.0,"text":"So instead, we'll set the camera to track a focal point, something to look at as it travels through space. This is done by selecting the camera and enabling the Look At tracking feature. By selecting an object in the scene, such as the dancing character, and then scrubbing through the rail position, you'll see the camera focusing on one subject. However, the dancing character may not be the best focal point as it's bouncing up and down like a bunny rabbit, and that could ultimately ruin the camera shot."},{"start":"4:00","end":"4:32","startSec":240.0,"text":"Instead, simply create a non-renderable actor to act as a focal point. This way, you can place it in the scene exactly where you need it, and even possibly animate it for subtle focal point changes. You are now ready to animate the camera in Sequencer, but first, a word of warning. The rig rail itself is by default visible in the scene and will render if seen in a camera shot."},{"start":"4:32","end":"5:10","startSec":272.0,"text":"To prevent that from happening, make sure you disable the Render Render button. This will allow you to render the scene in a single shot, and the camera will be able to see the scene in the same way. To prevent that from happening, make sure you disable its Show Rail Visualization option. If your Level Sequence is not open, select it in the viewport and open it. You can minimize all the existing tracks and then add both the Camera Rig Rail actor and the Dolly Camera itself to the Sequence."},{"start":"5:10","end":"5:45","startSec":310.0,"text":"For now, we are mostly interested in the Current Position on Rail option of the Rig Rail, so add the track for that. We already have a camera pan animation running between frame 0 and 300. We'll ensure the next animation runs between 300 and 600 or thereabout. Go to about frame 270. This will ensure a small one-second overlap between the previous and the new camera shots. At frame 270, create a keyframe with the rig camera at 0 or at the beginning of the rail position."},{"start":"5:45","end":"6:18","startSec":345.0,"text":"At around 630, create a keyframe at position 1 or the end of the rail position. Scrub the animation to see the camera move along the path. Somewhere around frame 300, maybe around frame 295, you need to switch the cameras from one cut to the next."},{"start":"6:18","end":"6:45","startSec":378.0,"text":"If you activate the Camera Cuts track, it is currently viewing the camera pan shot only. But at frame 295, you can easily add a different shot by using the Plus button. In this case, we need a cut to the Dolly Cam. As you scrub through the animation, you are now transitioning between the two shots."},{"start":"6:49","end":"6:57","startSec":409.0,"text":"Save your work. In the next section, you'll add the third shot, one that is created with the help of a crane."}],"05_Cam_CRANE":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Continue from the last section or open the level named 03 Cinematics Cam Crane. Here you'll experiment with yet another animated camera option by using a crane. The workflow is similar to what you did in the last section, but you'll be using a crane rig instead of a ray rig. Make sure your level sequence is accessible in the level. You will need it to animate the rig later. To create a rig, use the Cinematics menu like you did before."},{"start":"0:35","end":"1:04","startSec":35.0,"text":"It looks different from the ray rig obviously, but it operates just as easily. Move it into the Cameras folder. Note that you can control and later animate options like Pitch, and Yaw, and Arm Length as you see fit."},{"start":"1:06","end":"1:38","startSec":66.0,"text":"Much like you did before, you can easily create a new camera, name it adequately, and link it to the rig. By resetting its location, it will match the head of the rig arm. The camera is currently fixed on a single point,"},{"start":"1:38","end":"2:08","startSec":98.0,"text":"but as earlier, you can pick a point of your choice by using a non-rendered actor in the scene. You can create and rename such an actor Crane Focus, move it to the Cameras folder, and then set its location at a point of interest in the scene, maybe near the penthouse. You can always adjust it later."},{"start":"2:08","end":"2:42","startSec":128.0,"text":"Once you have done that, you can use the camera's tracking options to look at the null actor. This will ensure the camera is looking at a fixed point once you start adjusting or animating the rig's features. To animate this rig and create a camera shot, let's add both the crane rig and its associated camera into the level sequence."},{"start":"2:46","end":"3:19","startSec":166.0,"text":"There's a chance the Solar Time Track may be muted currently. You may want to unmute it at this time. The same is true for the Materials Parameter Collection which controls the exterior lighting. Let's animate the crane shot somewhere between frames 500 and 1000."},{"start":"3:19","end":"4:00","startSec":199.0,"text":"Scrub to frame 500 or thereabout. At frame 500, you need to pin the crane in place. For that, you need to keyframe the pitch and yaw values as well as the arm length. If you've already set these as an animation start, you're good to go. In Sequencer, you need to create tracks for all three values. But you can also use the Details panel as a shortcut. Using the Details panel, you can add a keyframe for the crane pitch, the yaw and the arm length and that also creates the necessary tracks in Sequencer."},{"start":"4:01","end":"4:44","startSec":241.0,"text":"Go to the end of the animation and fiddle with these three values to result with a different camera position. I prefer to use Sequencer to update the keyframe values. If you need to, add another set of keyframes midway through for better interpolation."},{"start":"4:47","end":"5:22","startSec":287.0,"text":"Do not worry about the light flickering, these artifacts will not show in the final rendering. When you're done, you can activate the Camera Shots track and add the crane shot for the last part of the sequence, at around frame 580."},{"start":"5:22","end":"5:55","startSec":322.0,"text":"Scrub or playback the animation to view the results. We'll cover rendering starting with the next section but before you go, note that the crane may be visible in some camera shots. To prevent that from happening, you can go to the beginning of the animation at frame 0, enable the option Hidden in-game"},{"start":"5:56","end":"6:17","startSec":356.0,"text":"and keyframe it. This adds a visibility track which now has a small keyframe set to black, which means the object will be invisible throughout. It has indeed disappeared from the camera shots. Save your work before you move on to the next section."}],"06_LegOut":[{"start":"0:00","end":"0:29","startSec":0.0,"text":"Continue from the last section or open the level named 04 Cinematics Render. If you need to, select and open the level sequence that is in this level. Now that we have the animation sequence defined, it's time to output the results to disk. Mainly you have two ways of doing this. One is to use Movie Render Queue or MRQ for short, and this method delivers the best outputs. We'll cover it in the next section."},{"start":"0:30","end":"1:08","startSec":30.0,"text":"The other method is to use a legacy output, and as the name implies, it is older technology with less quality and fewer features, but its simplicity can be used for fast previews. For still renderings or essentially screenshots, you can go to a frame you like, and then use the Viewport menu to access the High Resolution Screenshot option. Here you can define a Screenshot Multiplied value, but be careful not to go overboard. If your current screen is set to HD, a 2x multiplier will give you a 4K resolution."},{"start":"1:08","end":"1:41","startSec":68.5,"text":"In general, try to restrict yourself to a maximum of 3x for a preview. You have some additional features to choose from, but for now, click the Capture button to save this frame to disk. The image is saved to the Project Saved folder, and you can open it in File Manager. You can view its properties, and note that in my case, the resolution is set to 2432x1368. That's double the resolution seen in my current viewport."},{"start":"1:42","end":"2:12","startSec":102.5,"text":"Note that the Multiplier works on the viewport resolution, and not on your Windows desktop resolution. View the image. You'll see that it has some anti-aliasing issues that you can greatly improve later in MRQ, but for a preview, it's acceptable. You'll also notice that any non-renderable icons in the viewer are also saved as part of the image. After all, it's just a screen capture. So you may want to hide these with the G key prior to exporting the image."},{"start":"2:12","end":"2:47","startSec":132.5,"text":"To render animation previews, you can use the Movie Screen Capture, and the G key to export the image. You can also use the G key to export the image. You can also use the G key to export the image. You can also use the G key to export the image. To render animation previews, you can use the Movie Screen Capture, Legacy option, from the Sequencer toolbar, and then click the Render button."},{"start":"2:48","end":"3:21","startSec":168.5,"text":"A dialog opens giving you various output options including AVI files. You can change the frame rate, or the resolution, or the resolution. You can also change compression quality, although you cannot change the codec. A higher compression quality results in a bigger AVI file. There are some additional options to choose from but none that affect the quality of the output."},{"start":"3:22","end":"3:53","startSec":202.5,"text":"As you click the Capture Movie button, you can save your scene and wait for the AVI output to compile. You will see it render in a preview window. Once it's done, it will be saved to the Project Save folder under a dedicated Video Captures subfolder. From there, you can double-click it to play it back with your assigned movie player."},{"start":"3:53","end":"4:10","startSec":233.5,"text":"This would work fine as a quick preview to share with clients and colleagues but when it comes to creating high-quality outputs, you had better rely on Mover in the queue, which we'll learn about in the next section."},{"start":"4:23","end":"4:26","startSec":263.5,"text":"Thank you for watching!"}],"07_MRQ":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Continue from the last section or load the level named 04 Cinematics Render. If you need to, select and open the level sequence that is in this level. As you may have noticed it from the last section, Movie Render Queue is accessible from Sequencer, but it is also available in the Windows menu under Cinematics. If these options are not present when using a different project, make sure you visit the Plugins dialog,"},{"start":"0:34","end":"1:10","startSec":34.0,"text":"and ensure Movie Render Queue is active. The Additional Render Passes option is currently in beta and is used to create mats, which is not needed for this project even though the plugin is enabled. When you start Movie Render Queue from the Windows menu, it starts with a blank job list. But if you start it from within Sequencer, it picks up the level sequence you have already defined, in this case Sequencer Render."},{"start":"1:10","end":"1:45","startSec":70.0,"text":"Otherwise, you can add the sequence using the Render button, thus creating a batch render job. If you expand the job entry, you'll see the three camera shots defined in the level sequence. All three are active, but you can disable one or more that you don't need to render. For this demo, I'll keep all three active, although it will take longer to render. To adjust render parameters, you can click on Save Config. Ultimately, you'll be able to save and load your own presets."},{"start":"1:45","end":"2:21","startSec":105.0,"text":"Here you can start making adjustments such as the output type, currently set to JPEG Sequence. You can opt for something better such as a PNG or EXR sequences, but JPEG will be fine for now. You can edit the parameters of the deferred rendering or add to them. This is where you could add path tracing to your render queue, for example, as long as ray tracing is enabled in your project. Another option would be to add a lighting-only entry to the queue to render a sequence like the style you see in Viewport mode."},{"start":"2:21","end":"2:56","startSec":141.0,"text":"This could potentially be used later as a multiplier layer in the compositing software. Under Output, you can set things like an output folder, resolution and frame rate, among other options. Perhaps more importantly, you can add parameters to control quality such as anti-aliasing."},{"start":"2:56","end":"3:27","startSec":176.0,"text":"You can override the default anti-aliasing and increase the temporal count substantially to increase anti-aliasing quality. I'll go with a value of 32. This will increase render time significantly, but will provide higher quality renders. This number, like many numbers in UE5, should be kept to a power of 2. Another quality control settings you can add is Games Override."},{"start":"3:27","end":"4:07","startSec":207.0,"text":"If nothing else, this option ensures Lot 0 for all meshes is active all the time, so meshes will remain in high quality display even if you're not close to them. This entry also sets shadows in high quality mode, among other options. Finally, add a Console Variables entry to the queue. This allows you to specify console variables that will affect the rendering process only, not the project itself. For example, you can add a couple of variable entries, one for the Bloom quality by entering r.bloomQuality,"},{"start":"4:07","end":"4:40","startSec":247.0,"text":"and then setting its value to 5, the range being from 0 to 5. I add another for Motion Blur quality by entering r.motionBlurQuality, and setting its value to 4, this variable ranging from 0 to 4. Once you have made your adjustments, you can opt to save the preset so you can use it again at a later time."},{"start":"4:40","end":"5:15","startSec":280.0,"text":"You can then accept the changes and go back to the main window. At this time, you can elect to render locally or remote to send the job as a separate process and free your local resources. For now, go ahead and render locally. The render will be slow but mostly because it's rendering all 32 anti-aliasing subframes of roughly a thousand frames as defined by the Playback Area and Sequencer."},{"start":"5:15","end":"5:53","startSec":315.0,"text":"The estimated render time for the current camera shot is shown in the Preview window. I'll speed up the process. The Low Quality label only refers to the current Preview window and does not denote the quality of the rendered frames to disk. As it renders the sequence, you can view the results by visiting the Output folder and viewing one of the images. You'll find out that the anti-aliasing is of far better quality than the screenshot tool gave us earlier."},{"start":"5:53","end":"6:33","startSec":353.0,"text":"Once all images are saved to disk, you can compile them together into an animation by using programs like Adobe Premiere or even Photoshop. In Photoshop, you only need to open the first image and select the Image Sequence option."},{"start":"6:37","end":"6:52","startSec":397.0,"text":"Once loaded, make sure the timeline is displayed. And then click the Play button to view the animation."},{"start":"7:16","end":"7:25","startSec":436.0,"text":"This brings us to the end of this class. Make sure you save your work and exit the project."}],"08_Outro":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"In this follow-up to the Sequencer for Architecture introductory class, you have learned how to create cinematic shots by experimenting with cine cameras and what they have to offer. You have learned how to create and set up such cameras, how to animate them in different ways using simple motions but also dolly and crane rigs, and ultimately how to output high-quality stills and animations to disk using various techniques, including using Movie Render Queue."},{"start":"0:30","end":"0:38","startSec":30.0,"text":"I hope you have enjoyed this class and learned something that you can apply to your own work. I will see you again very soon."}]},"105.05":{"01_SequencerStoryboarding_5.1":[{"start":"0:00","end":"0:29","startSec":0.0,"text":"Hello and welcome to today's Unreal Engine training with Sequencer and today we'll be looking at storyboarding with E-POS. And today you can see the topics discussed here. We'll talk about the different tools that are available to us in Sequencer. We'll talk about how to get started with the Odyssey brushes and then also how we approach storyboarding within Unreal Engine and then talking about some rendering and some tips to close out here. So let's jump in."}],"02_StoryboardingInEngine_5.1":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"So let's first look at what tools we have at our disposal when looking at storyboarding. So you can see here the typical storyboarding workflow. We may have had some kind of idea and then we're going to some kind of previous department and then go through the various departments and iterate on that through the pre-production cycle. So the storyboards here are created with some kind of hand-drawn drawings created with the various 3D packages and then we iterate on them through this cycle."},{"start":"0:35","end":"1:06","startSec":35.2,"text":"So we go through story dev, production design, interblocking, create some form of story reel from that. Maybe we go back into blocking based on some feedback that we get and then through to the editorial. Now, the interesting thing about the approach that we're looking at today is that it's a much more iterative process through each of the different cycles that we're looking at. We're constantly kind of iterating based on the storyboards that we can see within the"},{"start":"1:06","end":"1:41","startSec":66.5,"text":"different shot setups and the way we kind of construct this whole pipeline here. So by introducing the E-Pars and Iliad tools from Praxinus, we will move the pre-production workflow for story and layout almost entirely into Unreal Engine. So you can see the kind of more purple based icons where we would have traditionally kept this offline from Unreal Engine where you can see now we've got some storyboard via the"},{"start":"1:41","end":"2:14","startSec":101.2,"text":"use of the plugin which we'll jump into in a few moments here. You can see that the storyboarding is able to be done in Unreal. We now have modeling tools and with the Iliad plugin as well and some rigging tools, we were able to do some production design inside of Unreal Engine. We're also just able to block whether it be performance capture, level layout and the assembly tools using a sequence of which we'll jump into. You can see there's a whole host of breakpoints in the cycle where we can have just this live"},{"start":"2:14","end":"2:28","startSec":134.5,"text":"iteration via the use of Unreal Engine and some of the additional plugins that we'll be looking at. And so hopefully you'll be able to see that that whole cycle and process is much more iterative. So let's jump into what that looks like now."}],"03_EPOS_5.1":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"And the two tools we'll be looking at most of here are the E-POS and ILLIAD tools. So they're used for storyboarding within Sequencer. We have an Epic MegaGran recipient and partner with Praxinus, which provides additional tools that expand Unreal Engine capabilities, including using Sequencer to generate content for storyboards and animatics. So to get started, we need to grab the free E-POS and ILLIAD plugins from the marketplace on the Epic Games launcher."},{"start":"0:31","end":"1:02","startSec":31.4,"text":"We want to make sure they're enabled. To open the plugins window, you just go to edits at the top of your editor, go down to plugins, which is at the bottom of the page. And then you just want to enable these two plugins. Potential recommendation here as well is you could enable the stylus and tablet plugin when using either Wacom or non-wacom tablet devices and it'll make that storyboarding process much more straightforward. You may have to restart your editor as well and then upon restarting, you'll have access"},{"start":"1:02","end":"1:33","startSec":62.6,"text":"to the tools that we'll be talking about here today. So a few editor preferences that you might want to set here. If you just go to your editor preferences, again found under the edit bar at the top of your editor, go down to editor preferences and if you just type in Sequencer in that search bar at the top, you'll be able to find some shortcuts that we're wanting to set here. And so we want to disable the up, down, left and right movements in the shortcut settings"},{"start":"1:33","end":"2:06","startSec":93.9,"text":"and just kind of try and mirror your settings as what we have here. And then we also have the project setting where you can get fine project settings. Again alongside where the plugins and editor preferences are, go to edit, project settings and we want to enable the support UV from hit results. So if you just type in hit in the project settings, you'll be able to find this setting here and then you'll just want to restart your editor again."},{"start":"2:06","end":"2:38","startSec":126.3,"text":"So Sequencer is a non-linear editing assembly tool. You can create shots through the use of Sequencer. We can create full film creation via Sequencer. We do a lot of pre-visualization, which we'll be talking about here today. And we also use it for game cinematic creation. So if you're unsure what Sequencer is, it's a really powerful tool. It's well worth knowing and diving into for what you might need for your projects."},{"start":"2:38","end":"3:12","startSec":158.2,"text":"If you are unfamiliar with what Sequencer is, definitely check out that documentation link at the bottom of the page here. There's a whole host of documentation sub pages there and a lot of tutorials to go from with Sequencer. And essentially what we can see here is we can see we've got a series of actors from our scene that we've created. So if we've got an eagle in the scene and we've got a meerkat in the scene, you can see that we've added our actors from the scene into Sequencer."},{"start":"3:12","end":"3:42","startSec":192.3,"text":"And we'll maybe play an animation on those actors. You can see that there's an animation track. We also can set some kind of events from here. So we're setting the visibility of the eagle for certain shots here. So we can add and compose all these different actors essentially into the Sequencer to create level sequence assemblies, which is the kind of key phrase that we're looking at here today."},{"start":"3:42","end":"4:14","startSec":222.6,"text":"So then when we look at this sequence in relation to how we might be approaching today's session, you'll see that we have the eagle and the meerkat in the scene here. And you can see as we scrub through, you can see the animation, the camera, the different shots that set up. And so that is the overall cinematic. So that's the overall level sequence. And what we can do here, we can nest the different sequences in a certain hierarchy for either"},{"start":"4:14","end":"4:45","startSec":254.4,"text":"multiple people to be editing, to keep the content modular so you can move it around. And so if you think of your overall film as this master sequence, this overall level sequence, which is what we can see on the left hand side here, we can have some sequences, sometimes referred to as sub sequences, which is maybe certain characters in a subsequence. Maybe you can have a subsequence for all the audio that you put into the level."},{"start":"4:45","end":"5:18","startSec":285.7,"text":"You can have a subsequence for all the visual effects that you put in. You can have various types of sequences, and it's up to you how you kind of handle and organize that content. But essentially it keeps it more modular and keeps it able to multiple people to work on the same kind of film in one session. So you can have multiple people per department, for example. And then we can be working per shot where you can see we've got certain naming convention"},{"start":"5:18","end":"5:50","startSec":318.0,"text":"set up so that people can be then double clicking on each one of these shots to open up the expanded editor to really dial in a certain performance or we need some key audio add-in, something like this. So there's kind of a nested hierarchy going into this. We can use this all in the take system, which we'll talk about in a few moments here. So you can see how previously we were looking at sequencer without the E-POS tools available."},{"start":"5:50","end":"6:28","startSec":350.6,"text":"Now let's look at sequencer with the E-POS as a storyboarding generator tool. So actors in the viewport or assets in the content browser are generated directly from the sequencer to create level sequence assemblies. So as before, they were added if we look, actors from the viewport or assets from the content browser added into the sequencer. So here we say they are generated. So we add them all within sequencer to be viewed with this E-POS storyboard generator."},{"start":"6:28","end":"6:42","startSec":388.5,"text":"So we can see per shot here, we are generating various assets for the sequencer, again, for this pre-visualization kind of storyboarding iterative approach."}],"04_ShotCreation_5.1":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"And so with that context in mind, let's look at how we might approach some shot creation. So first of all, we want to add a level sequence. We want to go to the drop down. We can add level sequence and we can just put that in a new folder here. So from the main toolbar, we can click that Cinematics button, add level sequence, and then we can click on the Add Import button, go to the Animation option, find level sequence as well."},{"start":"0:31","end":"0:58","startSec":31.4,"text":"Or you can just right click in the content browser, go to Animation Level Sequence. So there's two or three different ways you can actually add the level sequence, but essentially all routes lead to just creating a level sequence within your content browser, which we can open up. So once you've got a level sequence, maybe name it master underscore sequence or something along those lines of the naming convention, and then we're okay to get started."}],"05_CineCameras_5.1":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"To work with these storyboarding tools, we also need to understand how to work with cameras inside of Unreal Engine. So we have two different types of cameras. We have the Cine Camera Actor, which is the most commonly used. It's a camera that emulates real-life cameras, not unlike a game camera, but we have more options such as the film back, lens, focus, and tracking options. So if you're unsure what Cine Camera Actors are, plenty of documentation on these, and"},{"start":"0:33","end":"1:05","startSec":33.3,"text":"it's definitely worth looking into all the different options that they have, you can just find that from the Place Actors window in the Cinematics tab, and you're looking for the Cine Camera Actor there. We also have Scene Capture Component 2D, which is used to capture a snapshot of the scene from a single plane and then feed that into a render target. So if you're trying to render just a certain frame, this may be the option to go to there. So with the Cine Cameras, we have these film back settings, which essentially sets the"},{"start":"1:05","end":"1:37","startSec":65.0,"text":"aspect ratio. So you can see the film back here with the sensor, width and height, and then it gives you some form of aspect ratio based on the width and height values. You've got your lens settings where you can set focal lengths and S-stops, focus settings where you can track certain actors, whether it be a manual tracking or an actor tracking, and then just a whole host of other properties. So again, if you're unfamiliar with what Cine Camera Actors are, it's definitely worth checking out the documentation."},{"start":"1:37","end":"1:47","startSec":97.0,"text":"Also just dragging and dropping a Cine Camera Actor into your scene, playing around with the different properties can help you understand exactly what the different properties are doing within your project."}],"07_Odyssey_5.1":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Now let's look at working with the Odyssey brush debug. So to get started, before creating the brushes, sorry to use the E-Post in Iliad, we need to make sure everything works first by creating a debug stamp. We just wanna make sure all of our settings are set in our project correctly before moving on because you wanna introduce breakpoints into this working method because if you get too far in and then realize something's breaking, you've gotta go back up the chain."},{"start":"0:31","end":"1:03","startSec":31.1,"text":"So let's just first start by creating an Odyssey brushes folder. We'll add two more folders, which is the brush library and the stamps. And that's where we'll store any custom stamps from the custom brushes. So just a note here that the debug stamp is a temporary brush to ensure that your tablet is working properly in Unreal Engine. So what we can do, we can right click in the Odyssey brush folder to create a texture asset. So if we can't see this Iliad menu,"},{"start":"1:03","end":"1:35","startSec":63.1,"text":"it means that the plugin isn't installed. So just double check, go back to the top of the course here, make sure that Iliad plugin is there, restart your editor if need be, and then you should be able to find this Iliad option with the texture. And we can rename this texture T underscore draw pad, set the width and height to 1920, 1080, change the color to white. And then if you double click to open the T underscore draw pad texture, once you've created it,"},{"start":"1:35","end":"2:06","startSec":95.1,"text":"that's where we'll be able to test our brush from. So we can also repeat this step in the brush library, right click Iliad, and then we wanna get the Odyssey brush here. So we can rename the texture first brush, so you can see a file type like this, then double click to open it, and that's where we'll modify those parameters as well. So the Odyssey brushes are used in the Blueprints Editor Event Graph to modify the parameters of your brush, and you will be able to modify, customize,"},{"start":"2:06","end":"2:39","startSec":126.6,"text":"you know, rename the brush you create at any time, just like any other U asset, which is an Unreal asset inside the editor. So we want to now, in the Event Graph of this basic brush, we want to right click and type debug stamp, which you can see the debug stamp there, and then we can right click event on step, which you can see here, and then we just want to connect those two together."},{"start":"2:39","end":"3:09","startSec":159.0,"text":"You want to compile and save that blueprint, and they, if you're unsure what they are, they're the top two icons at the top left of your editor, you'll find one compile, one save, and you just want to make sure that's set up. So to test the brush, we can open the T-Basic stamp texture, just by double clicking it, select the debug brush in the brush selected tab, and then we can just draw in the viewport, and you should be able to see that drawing."},{"start":"3:09","end":"3:27","startSec":189.9,"text":"Now, if you're unable to see it, maybe your Wacom driver's out set up, so again, you could go back to the top and enable that plugin that we mentioned, but essentially you should be able to draw and edit directly inside of Unreal Engine using these tools."}],"08_SequencerStoryboarding_5.1":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Now that we have our tools set up, now let's look at how we might begin the storyboarding process inside of Unreal Engine. So let's look at how we create this first storyboard. So to get started, we want to create a board. So we have this drop-down option here, and we want to start storyboarding. Again, if you can't see these options, it may be because you've not got the correct plugins enabled. So you just want to restart your editor. Again, if your plugins aren't there, and then select Start Storyboarding to create"},{"start":"0:33","end":"1:07","startSec":33.5,"text":"a new board sequence asset. So additionally, we can also import the image sequences directly to Unreal. But for this purpose, we're just going to drop down from the cinematic and start storyboarding. So in starting out with a new board sequence, there are a few settings you want to change here that can modify. And then once you get familiar with those, you can dial them in for whatever you would like for your given project. So we want to adjust the root board for your project. So the name and path you want to set those into the desired locations."},{"start":"1:07","end":"1:39","startSec":67.6,"text":"And then in the naming conventions tab, you have the global settings here, and then also the board naming convention fields. So however you would like to set those up for your projects needs, you can use those. And then we also have the shot plane and the camera naming within these different headings here. And then starting out, it is OK to leave these as defaults. But as you get more familiar with these tools, you'll be able to dial them into exactly what"},{"start":"1:39","end":"1:58","startSec":99.6,"text":"you need. So you have a couple more options here in the sequence and sequence r tabs. If you do want to update any of these settings here. So that's it. Thank you. Bye. Bye. Bye."}],"09_HandsOnStoryboarding_5.1":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Now that we've gone over the Brush Setup properties, let's get hands on and talk about layout and storyboarding inside of Unreal Engine. So let's open our editor and then inside our editor, I want to create a new folder. It's up to you how you organize these folders. The folder name isn't necessarily relevant here. I've just called it EPOS. I'm going to right click in some empty space. I'm going to go to Animation and Level Sequence. These are the steps that we spoke about at the start of the course here."},{"start":"0:32","end":"1:05","startSec":32.6,"text":"I'm just going to call it SEQ for Sequencer, underscore master, underscore 01, something like this. Again, the naming convention doesn't really matter for this purpose, but I'm just going to create a new level sequence and then I will open that up. I will also go to the drop down at the top and I will click Start Storyboarding. So we'll click this. And this is our properties that we spoke about before. So you can name it My Storyboard 01. You can call it the name of whatever project you're currently working on."},{"start":"1:05","end":"1:38","startSec":65.8,"text":"You can set a desired path. If you want, I'm going to select the EPOS path. But again, wherever you would like to put these files, studio name, you've got board naming conventions. Feel free to go into any of these properties as we spoke about earlier in the course and edit those to whatever you would desire. I'm just going to go ahead and click Create Storyboard for now though. So we've got our storyboard. We've got our boards here. We can start thinking about adding a new shot."},{"start":"1:38","end":"2:10","startSec":98.2,"text":"So let's go ahead and click New Shot on the plus shot. And we've got our shots here. So we've still got our scene. We've got our sequence, the layout, but we've not got any cameras. The first thing we want to do is to go ahead and add a camera. So we can do that by clicking this button here, Create New Camera. And you can name your camera, whatever name and conventions you like to use. You can change the film back settings. You can give the plane a name. Again, I won't worry too much about naming conventions for this quick demonstration."},{"start":"2:11","end":"2:42","startSec":131.2,"text":"But of course, when you're working on a larger project, you'll want to set up naming conventions in advance. I'm going to go ahead and create a new camera and its plane here. And you can see that we're piloting the camera. And we can see the camera here. I'll just zoom in on this storyboard sequence by holding down Control and mouse wheeling over there. I can also hold Shift and mouse wheel backwards and forwards. That helps navigate the space. But essentially, this is our this is our shot here."},{"start":"2:42","end":"3:12","startSec":162.7,"text":"And now we want to start thinking about how to draw using this plugin. To do that, we go to the top left here on Select Mode. And you'll see that we have this now shift to Iliad as an option. So we can select here. By default, this is the window that opens. You want to give yourself a bit of real estate. On in your editor, because we want a few different options open here. So by default, we've got top bar that we want to click open."},{"start":"3:12","end":"3:44","startSec":192.9,"text":"And that will give us access to a few useful properties here. We've got the brush selector that we want to add. And I just I normally pin these down here. This is the way I learned how to use the program. And then also the layers tool, which I generally stack below the top bar on the brush selector. You want the layers to be in its own panel really, because you want the ability to quickly switch between layers. And then also tools is a useful window to have open."},{"start":"3:44","end":"4:17","startSec":224.6,"text":"Maybe just pin that on the right hand side for your fill tool and to undo any other elements that you want to undo. So these are generally the windows that you may use most often. Again, figuring out the real estate. And maybe if you have a second monitor, you can create a better layout. But overall, this is these are the tools that you want open to start creating. And then when we have our plane, we can actually just start the drawing process from whichever frame we want to look at."},{"start":"4:17","end":"4:50","startSec":257.3,"text":"So again, if we drew a little stick figure, I don't have a tablet plugged in. So mind my mouse skills here. You can see that I've drawn a little figure here. And if we want to then add a new shot here, you can click the drawing. And so I just click the drawing here. And maybe you've got someone over here. Maybe that's the same person we want to show movement like like the ball over the net or something like this. And what's interesting is then you can see the frames switching."},{"start":"4:51","end":"5:23","startSec":291.3,"text":"And what's a really useful feature as well, if you click this little light bulb icon, you can actually see the previous drawing you want. So if you want to. Kind of toggle between a few frames and know where the previous frame was, you can use that light bulb mode there. So of course, you can get into way more detail. There's a lot of different options to jump into diving to all these different properties. And also if you are painting, you can show the background. If you're in a quite a busy scene, this scene is quite straightforward."},{"start":"5:23","end":"5:55","startSec":323.7,"text":"But if you've got a busy scene and you want to alpha out more of the scene and you want to block it out so you can really just focus on your drawings, you can go ahead and do that. You can drop the alpha back down to see more of the screen. And of course, you can change the grid as well, either the grid type. If this blue grid isn't what you want, you can change it into the third grid. You can even change the grid color. But there's so many properties in this plugin. You can really go to town on creating various shots, as we spoke about earlier"},{"start":"5:55","end":"6:07","startSec":355.0,"text":"in the tutorial, but they're the quick settings to get up and running with drawing directly into your storyboard. And so hopefully that added some clarity on a bit of a hands-on demonstration of how to use this plugin and now we'll move on to the next section."}],"10_Rendering_5.1":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"And then before we get on to any tips and tricks, we'll talk about how to render your sequences out. So let's look at rendering in sequence now. So the animatic creation is super straightforward. We can just drag the board sequence actor into an empty level sequence and it will automatically add the board sequence to a shot track that you're ready to render the finished animatic with. So we have two different tools that I'd disposal here. We have the movie render queue and the movie scene capture, which is a legacy tool which"},{"start":"0:34","end":"1:09","startSec":34.7,"text":"is being deprecated, but it is also great for rendering out videos with AVI format. So it's a general purpose capture for cinematic output supports custom render passes HDR export but doesn't support high resolution scaling. So it's currently the only the option for AVI files. So that's what we'll go ahead and use that being said, if you're using future versions of Unreal Engine.amp 5.1, just go ahead and check out what the current movie render options are and use a tool that's most appropriate for what you need there."},{"start":"1:09","end":"1:40","startSec":69.4,"text":"So with the HDR exporting, we have got export HDR data in open EXR files. We've got specify the HDR compression quality and then the capture gamut depending on what you need. And then also with the render passes, we limit render pass options. So it is not render layers. And then just a quick note on the bottom here, at least one render pass must be selected"},{"start":"1:40","end":"1:49","startSec":100.2,"text":"or all render pass options will be rendered. So this is what we end up with here. I'll just play a quick sequence for you to see."}],"11_UsefulTips_5.1":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"And then before we close out, let's look at some useful tips for getting started with your project. So as we spoke about before, creating subscene tracks is going to be super useful for working with multiple people on these shots and these sequences. So whether you want to organize per department, maybe have character animation effects, lighting, etc. You can essentially nest the storyboard sequences into a standard level sequence. Then we can kind of go through the layering, almost like bread crumb in to get the functionality"},{"start":"0:36","end":"1:07","startSec":36.5,"text":"quickly moving between the subscene tracks. So trying to open an sd storyboard sequence will crash Unreal Engine. So that's also worth noting. So just check your current engine version. This may not be the case, but just make sure you're saving your content as you go will be something good to do moving forward. So the subscene tracks can then be expanded into given sublayers. So you may have, as we said before, this character animation track, for"},{"start":"1:07","end":"1:40","startSec":67.1,"text":"example, and then you may have sub sequences that are per character type, for example, you can get as granular or as high level as you want. So we just want to consider subscene tracks for the various elements. Just don't add subscenes for your storyboards. As we mentioned before, that could cause some crashing for you. It's also worth noting that E-Post storyboard does not support spawnable actors at this time. So if you see actors in your content browser or your"},{"start":"1:40","end":"2:15","startSec":100.6,"text":"world outliner that are like this, they've not got the lightning icons, then that's what you want. If you see any kind of cameras that are being spawned at runtime, which is what this lightning icon means, then E-Post isn't going to be aware of them. So you just want to add all the actors into your scene to be using with these sequences. And then maybe you want to set some useful hot keys here. As you begin working with these tools more, you'll find your own workflow,"},{"start":"2:15","end":"2:49","startSec":135.4,"text":"but here are a few to get you started. And then we've got a couple more here. So just a quick note here, E-Post storyboarding requires the highlighted shortcut keys to be disabled or remapped. As we said at the start, it may just cause some conflicts with the default functionality. And then we've also got a couple more timeline tricks here. If you want to just get more familiar with using a sequencer, and especially when you're editing a lot of shots, these kind of tools might"},{"start":"2:49","end":"3:23","startSec":169.5,"text":"help on that journey. So there's a good white paper to read here, creating the Fortnite trailer. It just helps you understand the virtual production process of how these cinematics are created. And a few extra resources here for you to dig into, some getting started guides and some documentation. And all this course today was credited by Kevin Miller, Brennan Carroll, Elodie Moog, and Fabrice DeBarge. So thank you again for those."}],"12_ThankYou_5.1":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"And then just to close out here, a big thank you for watching today's course. Hopefully it just was a good getting started guide on the E-Pass and Iliad tools, allowing you to start thinking about how you would storyboard your projects, especially in this kind of pre-production at this period of a project maybe. You just want to figure out what tools were at your disposal, how to just get a very quick iteration process going on in your project."},{"start":"0:30","end":"0:38","startSec":30.8,"text":"So hopefully that pointed you in the right direction. Some cool tools to get you started. So thanks again for watching and we'll see you on the next course."}]},"106.01":{"01_Intro":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hello, and welcome to this course on FBX data ingestion for Unreal Engine version 5.6. My name is Alex Coulomb, I'm an Unreal Engine authorized instructor, course author, and I run the XR Creative Studio Agile Lens immersive design. In this course series, we'll be looking at static mesh ingestion using the FBX file format. For our agenda, we'll begin with the simplest way to import FBX files and other assets,"},{"start":"0:30","end":"1:04","startSec":30.0,"text":"which is actually to use FAB, taking data from the cloud. Then as we consider bringing our own assets from our DCC tools into Unreal Engine, we'll begin to explore a number of considerations, such as units and scale, naming conventions, how to combine objects, setting up material IDs, and looking at pivot points, which can be changed both in the DCC tool and in Unreal Engine. From there, we'll look at triangle count, both an LOD level of detail approach, as well as nanite. After that, we'll explore adjusting assets in Unreal Engine using the modeling tools,"},{"start":"1:04","end":"1:20","startSec":64.4,"text":"considerations for UVs, especially when baking lightmaps, setting up collisions, best practices for importing skeletal meshes, and then we'll wrap up with some future considerations for your FBX workflow. In the next video, we'll look at how to import FAB assets from the cloud."}],"02_ImportingWithFab":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In this video, we'll explore importing FAB assets from the cloud. Before we dive too deep into importing our own custom FBX assets from our DCC tools, it's good to know how to get data from the web. FAB is a one-stop shop that uses Unreal Engine directly in the editor to add a wide variety of assets, meshes, textures, etc. directly into your project. When you find a FAB asset you like, you can add it to your library or just temporarily"},{"start":"0:32","end":"1:04","startSec":32.0,"text":"add it to the project to see what you think of it. For example, as long as I have the FAB plugin active, if I pull up my content drawer, I can go to the FAB icon here, click on it, and see FAB load not in a separate web browser but directly inside of Unreal Engine. Then if I wanted to find, for example, some animations and sort only by free options, I might find something useful for my particular project."},{"start":"1:04","end":"1:37","startSec":64.2,"text":"Maybe we want to make sure that these are relatively recent files, and then we could grab something like these nice free zombie animations from QuackAvoid. I can add to my project without adding it to my library if I just want to test them out and see what I think of them."},{"start":"1:37","end":"2:10","startSec":97.2,"text":"Now without actually having to go through a more traditional import process, I now have a folder called Zombie Animation Pack full of animations with that nice handy FAB icon to show us where these came from. Be careful when downloading potentially large files like Megascan assets. If you choose something like raw data, it's likely to be 8K and very, very huge files. You'll see oftentimes when downloading you actually have options for things like an"},{"start":"2:10","end":"2:52","startSec":130.4,"text":"FBX file format versus GLTF, and in many cases you'll get little previews of their sizes. This is if you want the raw data. This is if you want the file types directly, including zip folders of various textures. But again, this is only if you need that source data and don't want to bring it directly into your project. For example, if I search for Quixel African, I can see the African slate query here."},{"start":"2:52","end":"3:22","startSec":172.5,"text":"And if I go to the website, I can access these direct raw files. From over an Unreal Engine, I only have access to add this directly into my Unreal Engine project, not to download it directly. And yes, note again that over in my FAB settings, I can choose my preferred quality tier when adding directly into my Unreal Engine project. Keep an eye of course on your cache directory size. If this number becomes too large for your taste, you can clean that directory at any time"},{"start":"3:22","end":"3:29","startSec":202.8,"text":"or move the location to a larger drive. In the next video, we'll go over some DCC considerations."}],"03_DCC-Consideration":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this video, we'll explore some considerations for preparing your assets in your DCC Tool of Choice. Before exporting, you're going to save yourself a lot of headaches on the Unreal Engine side if in your DCC Tool, by the way, DCC stands for Digital Content Creation, you set up things with clear names and materials. We recommend looking at Michael Aller's UE5 Style Guide, which is a perfect example for a wide range of naming conventions that are actually quite well accepted throughout the"},{"start":"0:31","end":"1:03","startSec":31.8,"text":"industry now. Be sure your scene is well organized and combine and attach meshes ahead of time when you can, which will simplify how they get imported into Unreal. Pay attention to any objects that have been scaled, especially in a non-uniform way. Look for tools that reset the scales, x-forms, etc. whenever you can. Keep the scenes as close as possible to the world origin of 000 as when they get too far away it can start to create floating point errors. And then whenever it makes sense, set up your pivot points ahead of time so when they come"},{"start":"1:03","end":"1:36","startSec":64.0,"text":"into Unreal Engine, they're not far away. Basically a similar comment to what we're saying about the origin of the world, but on a per-object basis instead of for the entire scene. A reminder that Unreal Engine uses the Z-axis for up and the unit type is centimeters, and whenever possible you should try to set this up in your DCC tool before exporting, although Unreal Engine is getting better and better at identifying the up direction as well as the unit type from a variety of sources and converting them on the fly."},{"start":"1:36","end":"2:10","startSec":96.6,"text":"Still, this remains a best practice, especially if you don't want to deal with scaling issues. If we take a brief look at the Forklift Scale Map found in Content Maps Forklift Scale, we can see an example of our little Forklift brought into Unreal, and we might not know right away that it's little without context. Standing next to it is a third-person character at its normal scale, and we can see of course this feels a lot more like a child's toy now. The problem here was that this was imported with inches instead of centimeters, whereas"},{"start":"2:10","end":"2:44","startSec":130.5,"text":"the correct imported Forklift is over here, and as we can see next to our character, it is at the correct scale because it was imported with centimeters set up correctly. You'll find that when you first bring in an FBX file into Unreal, you'll be presented with a wide range of options for how you would like that FBX data ingested, including things like whether or not you would like to generate collisions, combine meshes, whether or not you want to convert to Nanite, what you want to do with normals, if you'd like to change the units, if you'd like to generate light maps, if you'd like to set up LOD groups,"},{"start":"2:44","end":"3:18","startSec":164.9,"text":"if you'd like to convert the materials, and the list goes on and on. And so again, before this all comes to Unreal, in your DCC tools such as 3ds Max, it's good to set up things like a standard naming convention. Here is the current state of the Michael Aller style guide. It says UE4, but it works exactly the same for UE5. You'll see some basic principles in here, and then some very direct approaches for how things get named, for example a prefix of SK for skeletal mesh, M underscore for material,"},{"start":"3:18","end":"3:48","startSec":198.0,"text":"T underscore for texture, and so on and so forth. Here we see the example of ensuring that you don't just have a bunch of objects named box rectangle shape, and instead they're named things like bench, handle, floater, etc. As we see that those translate over into the Unreal Engine Outliner. Keep in mind that if you have an object with multiple materials, that object will translate into Unreal Engine with those same material slots listed as different elements."},{"start":"3:48","end":"4:21","startSec":228.4,"text":"These material IDs will determine which faces get which textures and materials, and the more material IDs that a mesh has, the more expensive it'll be to render as every single one of those materials will create an additional draw call, also known as a rendering pass. Then the raft map, which we can find under maps raft, we have a simple example of different material IDs set up as they came into Unreal via an FBX import, and we have gray, brown, black, red, silver, and then we have a hey raft that seems to have come in at the wrong"},{"start":"4:21","end":"4:58","startSec":261.8,"text":"scale, and then over here one where all those materials have been combined to reduce draw calls and add additional optimization. This could be done in a DCC tool, though it could also be done directly in Unreal Engine via something like actor merge actors simplify. And then we have this other version of the raft, which actually has combined all those"},{"start":"4:58","end":"5:30","startSec":298.8,"text":"materials together, reducing from five draw calls to one. Pivot points determine where an object will get placed in a level, as well as how it will scale and rotate relative to that pivot point. Typically you want a pivot point to be located at the ground level of an asset so that it will easily place on the floor of your project and somewhere near the center. By default, if the pivot point is centered to the object but the object is offset from the center of the world, that pivot point will be relocated"},{"start":"5:30","end":"6:04","startSec":330.5,"text":"to Unreal Engine's origin, zero, zero, zero, but you can prevent that from happening by activating the bake pivot in vertex option when you import through the FBX dialog box. Let's take a look at our pivot points by opening up the pivot map in our content maps folder. And from here we'll see two forklifts, one with the name pivot bad, and one with the name pivot good, hopefully for obvious reasons. We can see that pivot bad has its pivot all the way over here and is a little bit awkward to move, and once you start to rotate it,"},{"start":"6:04","end":"6:35","startSec":364.2,"text":"things get very confusing very quick. Over here on the other hand, much easier to move, and rotation makes a lot more sense. So how do we fix the bad pivot forklift to make it closer to the good one? Well, if we go into our modeling tools here, which also have the shortcut of shift F5, we can go down here to X form, edit pivot, and we have a number of different options here where we can center, put it up top, put it to the right, put it"},{"start":"6:35","end":"7:09","startSec":395.9,"text":"over in the world origin, or put it in the bottom. We can adjust all this manually of course as well. If we think that we want it to be near the front of the vehicle, for example, or if we're thinking about how the vehicle might begin to rotate, whether it's a front wheel drive or rear wheel drive, that might actually start to influence what we do as well. Now that I'm looking at the forklift, I realized I was looking at it backwards, front wheel drive, rear wheel drive, and once I accept that, so for example, if it has rear wheel drive, we could have something like that happening. And this doesn't affect just"},{"start":"7:09","end":"7:44","startSec":429.0,"text":"this one instance of the model. If I go and I find the pivot bad model here, we've actually adjusted it at its base mesh level. As we can see, this new one we've just dragged in also has the pivot in that location. So this is different from the option of right clicking and going to our pivot and doing a pivot offset, right? That is something that is temporary, and we'll go away once we click on the object again. Also note that when you import into Unreal Engine, you can import an entire scene instead of just an individual object. Nowadays,"},{"start":"7:44","end":"8:15","startSec":464.8,"text":"we're seeing this done even more and more, not just with FBX, but also GLTF, GLB, and USD files as well. What's quite nice about this is you can actually get a preview of the hierarchy before you import it. You can import components and preserve the hierarchy and pivot points of individual actors. You can import components into a single blueprint actor class. You also have separate tabs for static meshes and skeletal meshes if they're part of the same scene, and you have a robust materials menu to adjust how those all come into your project."},{"start":"8:15","end":"8:50","startSec":495.8,"text":"If we take a brief look at our forklift hierarchy scene, we can see that an entire blueprint has been generated that contains the entire hierarchy of the FBX scene as it came into Unreal. So if I open up that blueprint file, I will see all the geometry in here set up very similarly to how it was created in its original DCC tool, clearly with some attention paid to things like pivot points and even how the tire would rotate. If you like, we could test this very briefly in a level"},{"start":"8:50","end":"9:36","startSec":530.6,"text":"sequence by bringing in our forklift, adding in a transform track, changing where it moves from here to about frame 150, setting this to be a linear speed and seeing if we can get the tires to rotate appropriately. Double clicking on a blueprint will actually bring you right to the child"},{"start":"9:36","end":"10:09","startSec":576.5,"text":"component. Here though I have the wheel selected, I probably actually want to have the rear right and the rear left control points selected. I could set their rotation, move forward a little bit, and then bring their rotation perhaps to something like 180 degrees. And we can see those tires in the back are moving. Now note I can't actually do this with the other"},{"start":"10:09","end":"10:40","startSec":609.1,"text":"wheels directly because they do not actually have these same control points. And if I click on the wheels directly, the pivots are not in the center of the wheels, they're over here. So I could continue to work with this and modify it here in Unreal, or I could change it back in my DCC tool. But here's just a very quick example of what I was able to do just by bringing this over into Sequencer and working with the existing hierarchy. In the next video, we'll explore Triangle Count."}],"04_TriangleCount":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"In this video, we'll explore Triangle Count with both LODs and Nanai. Oftentimes, when using TCC tools that aren't designed for a real-time environment, we can end up with very complex geometry. Perhaps it's coming from a program like Revit where construction is the goal, or 3ds Max where perhaps it's going to render with an offline tool such as V-Ray, and therefore the size of the scene is not as important as it might be in a real-time environment like Unreal Engine."},{"start":"0:30","end":"1:04","startSec":30.0,"text":"Be careful of the level of detail you actually need before you bring your assets into Unreal. If we don't need to see every tread on a tire on a forklift, for example, perhaps those tires could be simplified, similar when it comes to things like nuts, bolts, screws, things that might be important for a manufacturing process, but not necessarily for a real-time visualization of those products. And yes, we will discuss Nanite where you can have millions of triangles at a time, but for the moment, let's assume we're developing for a platform that does not support Nanite, like a mobile phone."},{"start":"1:04","end":"1:38","startSec":64.0,"text":"LODs stand for Level of Detail. Starting with LOD 0, we have the highest polyversion of this equipment, going down to LOD 3 where we can see that it becomes simpler and simpler. The idea of Levels of Detail is that you change the level of detail you're seeing as you get further away from the object, meaning that something that is only taking up a few pixels on screen will not be rendering at the same level that it would be if it is taking up most of your monitor. There are a number of ways to generate LODs. You can do them, of course, in your DCC tool and import them."},{"start":"1:38","end":"2:13","startSec":98.0,"text":"You can do it manually in Unreal. We can set up the number of LODs we want, change the triangle percentage, set up a few LOD groups, which already have certain settings for how they're set up, and then we can even get into details related to screen size and when we switch from one LOD to another. There's a handy Mesh LOD coloration mode in Unreal that allows us to visualize which LOD is active at any given moment. Here in the LOD map, we have our forklift, and if we go to that visualization for Mesh LOD coloration,"},{"start":"2:13","end":"2:48","startSec":133.0,"text":"we can see the color change as we zoom in and out, despite the fact that when we're in Lit Mode, you really can't tell when we're switching from one LOD to another. We can also see this visualized directly in the Static Mesh Editor window where we start with level 0, and we go very quickly to level 1, 2, 3 as the screen size changes. If we wanted to adjust any of this further, we could simply type in LOD, make this custom, use however many LODs we want, then we could even do something like uncheck Auto Compute LOD Distances,"},{"start":"2:48","end":"3:20","startSec":168.0,"text":"and then start to get very specific with the screen sizes that we swapped these two. As a quick example of another adjustment we could make, let's go down to LOD Settings and add in a fifth LOD, hit Apply Changes, and of course LOD 0 is 1, so we'll see a total of LOD 4, but we won't see it until we say what screen size we should switch to it on. So as we go .56, .42, maybe this one becomes .2."},{"start":"3:20","end":"3:50","startSec":200.0,"text":"And now 0, 1, 2, 3, 4, once we get to there as that screen size goes below 2. And at any one of those we can also decimate it further and say actually when we're at .2, I want to be at 20% triangles, and we could apply that. Confirm we don't see too big of a difference, and now we're all the way down at less than 2,000 triangles."},{"start":"3:50","end":"4:24","startSec":230.0,"text":"If the platform you're targeting supports it, Nanite can be an excellent way to handle millions and millions of polygons for your scene without hurting performance. The basic way Nanite works is it's identifying what is visible on a pixel per pixel level for your project and ensures not to draw more polygons than will actually be visible within that pixel. Thus we can have something that started as 5.8 triangles as seen in the STAT RHI window in the top, and then reduce that down to about 16,000 triangles just by enabling Nanite."},{"start":"4:24","end":"4:56","startSec":264.0,"text":"There's a number of different ways to enable Nanite. You can right-click on an object, go to the Nanite window and change it there. When we open up our static or skeletal mesh window, we can enable Nanite, and yes, skeletal meshes are supported by Nanite well, and yes, skeletal meshes are supported by Nanite as well, including trees and foliage now. And when we're importing through the FBX Import Options dialog, we also often have the option to generate a Nanite mesh at that time as well. Always be sure to hit Apply Changes when you're done."},{"start":"4:56","end":"5:28","startSec":296.0,"text":"Otherwise, you won't see the change. Let's go ahead and open up the Nanite map, and we'll see we have a piece of geometry here where if we type STAT RHI, it's 7 million, nearly 8 million triangles being drawn here with over 500 draw calls. Pretty expensive. Oh, and we have a few additional pieces of geometry as well. So what we could do is find where these live. Over here in Nanite, we have our different static meshes,"},{"start":"5:28","end":"6:06","startSec":328.0,"text":"and I could simply right-click on all of these, tell them all to enable Nanite. And then without changing anything about the complexity of the scene, we now see we're drawing 13,000 polygons, and we're down to about 200 draw calls, though that number is actually less because of all the other elements being drawn here in the editor. If we'd like to visualize Nanite directly, we can go to Nanite Visualization Triangles and see the sort of real-time, LOD pixel-level triangle adjustments happening"},{"start":"6:06","end":"6:39","startSec":366.0,"text":"as we get closer and farther away. No need to generate LODs. Now, of course, many platforms don't support Nanite, and Nanite can be a bit of a ram hog, and of course, you have to package all these assets at their full quality, so there's still a number of instances where a traditional LOD system might be best, but there is something very satisfying about being able to get very close to geometry and seeing as much detail as we can. Thanks, Nanite. In the next video, we'll look at the Unreal Engine modeling tools."}],"05_ModelingTools":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"In this video, we'll explore the Unreal Engine modeling tools. The Unreal Engine modeling tools are becoming a more and more robust one-stop shop to make a wide variety of changes to your model once it's already made its way into Unreal. You can repair mesh problems or even add new meshes entirely without going back to your DCC app. Some of the things you might adjust would be selecting triangles individually or by material or by element or by smoothing group, then changing the faces, the normals, changing your material elements so that different triangles are using different materials,"},{"start":"0:35","end":"1:13","startSec":35.0,"text":"and you might even change something like your pivot point. In order to use the modeling tools editor mode, you simply need to make sure that the checkbox is on in many of the templates it is on by now. And yes, you can see there's a number of editor modes, including a more robust static mesh editor modeling mode, hair modeling, and then of course we now have skeletal mesh editing as well. Oftentimes when importing our FBX data, we'll see that the pivot point is not where we want, and there's a very straightforward way to adjust exactly where the pivot point will go in a way that will affect all assets in the project using that particular model."},{"start":"1:13","end":"1:48","startSec":73.0,"text":"We have a wide range of different features available to us in the modeling mode, starting with how we select which triangles we would like to operate on. Just in the select tools, we can invert, grow, or shrink our selections, we can flip our normals, we can delete or separate triangles from the rest of the mesh, and then if we plan on going back to a group of triangles over and over again, we can create various polygroups. Once we have triangles or polygroups selected, you'll see a number of familiar tools available to you such as extrude, inset, cut faces, flip faces, and many more."},{"start":"1:48","end":"2:20","startSec":108.0,"text":"Another handy feature is the ability to select a set of triangles, add a new material index or element, and then assign that material to the triangles that you've selected as a new active material. To take a brief look at modeling mode, let's go into our content drawer, filter by static meshes, and let's type in forklift underscore LOD, and bring in a couple versions of this. We can also just hold down alt and copy them."},{"start":"2:20","end":"2:56","startSec":140.0,"text":"The reason I'm doing this is to demonstrate that in modeling mode, when we save an adjustment to a model, it's not just for that instance, it will be for all three of them. So let's say, for example, that we wanted to bevel this out a little bit and change the material. In fact, add an entirely new material. There's only four here right now. What we could do is go into modeling mode, which also has a shortcut of shift F5. And from there, we could start by going to select, try select, press down on our bracket to change the brush size."},{"start":"2:56","end":"3:28","startSec":176.0,"text":"I might need to change my camera speed a little bit here. And let's just grab that. From there, if we'd like, we could create a polygroup just to make it a little bit easier to select. And from there, we can go to polygroup edit, which then gives us a variety of different face editing tools. So we can select our polygroup. And in fact, we actually have bevel as one of the options for what we're going to do here. So once we click bevel, it immediately starts to create something that looks a little nicer than the hard edge that was there."},{"start":"3:28","end":"4:00","startSec":208.0,"text":"And if we want, we can kind of scrub up and down exactly what that bevel will look like. We can even add additional subdivisions and also decide just how round we want it to be. Try to zoom a little closer here without clipping to kind of see our options. So depending on how much you're fine tuning this, do this to a taste. And we're going to set this to material ID 5, which doesn't exist yet, which looks a little bit confusing, right? We're not going to see anything there yet. So I can go ahead and accept action."},{"start":"4:00","end":"4:34","startSec":240.0,"text":"And we know it's there, but it's invisible because it's using a material ID that doesn't exist. And we can say accept. And we see it's there, part of the geometry. And now we're going to go down to attributes, edit materials. We probably could have done this first, but that's okay. So we're going to add a new materials in this array of materials from there. Let's just type in the word red and find anything that might work for this particular use case."},{"start":"4:34","end":"5:06","startSec":274.0,"text":"M I metal red, sure. Great. And so we see that that's going to come up right away because we had already assigned our bevel there to material ID 5. Even though we haven't actually accepted it yet, it doesn't exist in our model yet, but it's here. And now all we need to do is select this here. Make sure that our active material is that new 5 M I metal red. And then down here, we're going to say assign active material."},{"start":"5:06","end":"5:36","startSec":306.0,"text":"There we are. Now we can hit accept. And we can get out of modeling mode and confirm that we applied this nice metallic bevel to our wheel there. And we can see we've got this nice bevel here. And we can see that this has in fact been added to our other objects. Very exciting. In the next video, we'll take a look at light maps and their UVs."}],"06_LightmapUVs":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"In this video, we'll take a look at Lightmaps and their UVs. If you don't plan on using Lumen in your project, then you'll probably still want to keep it optimized by baking your lighting. You can of course combine baked lighting with Lumen Reflections, but let's assume for a moment that we are working again for a platform that needs to be hyper-optimized, doesn't support Lumen or Nanite, again something like a mobile phone. Lightmaps are a very cheap way to store complex direct and indirect lighting information,"},{"start":"0:30","end":"1:05","startSec":30.8,"text":"and once lighting data has been baked, that light becomes basically free because nothing needs to be processed at runtime from it. Lightmap UVs are different from your texture UVs because a lightmap must have distinct, separate UVs for every surface of an object even if a texture were to repeat because shadows might come and hit an object from different angles even if the texture is the same at those different angles. You can generate UVs of an Unreal or set them up in your DCC tool. A Lightmap Index in Unreal Engine by default will be set to Index 0, but that can also"},{"start":"1:05","end":"1:36","startSec":65.3,"text":"be changed at a later time. All Lightmap UVs have to fit in the 0-1 UV space with no overlap, otherwise you'll get some very funky looking light baked data. Over in our Lightmaps map, we see we have shadows coming off of these two dumpsters. I'm also going to hold down L and bring in a simple light right here. We'll give it a color to help it stand out more. Why not? Hot pink. And if I go ahead and do a quick build of my scene, ignoring plenty of other things I"},{"start":"1:36","end":"2:07","startSec":96.7,"text":"should be doing like a Lightmass Importance Volume, etc., etc. We can see that Static Mesh Dump Lightmass No has a very high overlapping issue with its UVs, and this can of course cause problems where we can see on the left dumpster, which is Lightmass Yes, we have the pink light showing up correctly there, whereas on the Lightmass No one, things are a little bit broken and wonky. This should clearly be illuminated, but it's not."},{"start":"2:07","end":"2:37","startSec":127.3,"text":"If I jiggle my light here a little bit, you'll see it come back on, and that's from poorly constructed UVs. We can see issues over here as well. This one is fine, but let's go ahead and see if we can fix this one too. So we'll open up Lightmass No. We'll find in our details, Lightmap UVs. We can tell it to generate some Lightmap UVs, but before we do that, let's look at what we have here. So yes, this will cause some issues. We do generate Lightmap UVs and we hit Apply."},{"start":"2:37","end":"3:06","startSec":157.7,"text":"We'll now see we have UV Channel 0 and UV Channel 1. And now if we go ahead and rebuild our lighting, we'll see we actually still have some light."},{"start":"3:07","end":"3:37","startSec":187.7,"text":"We'll have the same problem, and that's because of where the Lightmap is currently set up. So I did say earlier that Lightmaps are typically going to be on Channel 0, but because we generated the Lightmaps after, it became Channel 1. Generally the Lightmap is going to be the one with more visible geometry because it's covering more surface area. So all we need to do is change our Lightmap Coordinate Index from the default of 0 over to 1. Now, it should work."},{"start":"3:37","end":"4:08","startSec":217.7,"text":"Let's give it a try. And there we are. Pink Light on both sides, as well as our little shadows on the ground. This is also baking lighting, and if we wanted this to be sharper, we could even change the Lightmap Resolution of the ground. Bring it up from 128 to 256 or even 512. Also note that in order to bake the lighting successfully here, I had to create a Post-Process Volume and Disable Lumen from Global Illumination."},{"start":"4:08","end":"4:15","startSec":248.4,"text":"Otherwise, Lumen will override everything in the scene. In the next video, we'll explore collisions."}],"07_Collisions":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"In this video, we'll look at collisions. Oftentimes, when we're importing into Unreal Engine, we'll have a checkbox available to us that asks if we would like to generate missing collisions. This will tell Unreal Engine that when we're walking around a scene, especially in, for example, a third-person character template, that we should bump into and not go through certain kinds of geometry. As we see in the bottom right, we can also have collisions set up manually, in this case, just affecting the columns,"},{"start":"0:30","end":"1:00","startSec":30.0,"text":"which is particularly useful if we have more complex geometry above the height that a character will be able to access, and there's no reason to have collision data there. To give your CPU a break, it's always ideal to keep your collisions as simple as possible, but if your platform can handle it, there are also very simple ways to make all the geometry just match the same collision data as the geometry itself. Here's an example of modeling a custom collision box over in a DCC tool. You can see that it's much simpler than the geometry inside of it,"},{"start":"1:00","end":"1:32","startSec":60.0,"text":"but will still allow more complex collisions than something like a simple box or sphere. These collision meshes can import into Unreal Engine automatically as long as they follow the naming convention of the prefix ucx underscore, full mesh name, underscore number. Let's take a look at the collisions map in Content Maps, where we'll see that we've got a simple wall with a hole cut through it, some various objects on the ground, and some columns."},{"start":"1:32","end":"2:04","startSec":92.0,"text":"So if we go ahead and start by looking at our Flayer collision, we can see that these are already set up in a pretty useful way that gives us a good sense of how collisions should work. So if we think our character is going to be able to hit the top of this wall, of course, we want this tab collision, whereas with the much taller columns, we probably don't need to go above the height that the player could jump or reach to, so this is perfectly fine. There's no need to get into the details of every nook and cranny of these columns."},{"start":"2:04","end":"2:34","startSec":124.0,"text":"Down here, we want these, of course, to be a little bit more convex. And so these are set up just enough to be able to block the player in a more robust way than a simple cube or sphere would be able to. Let's take a look at these a little bit closer. So if I open up Cart Damaged, and I view the collision here, we can see that this was set up as a convex element."},{"start":"2:34","end":"3:06","startSec":154.0,"text":"So if we wanted to try creating something like this ourselves, we could go and remove collision, and then try doing this with auto-convex collision. It'll ask us what we want the whole count and the max vertices to be. I can hit apply, and it will give us something actually a little bit more detailed than the one we just had. If we wanted to simplify it, we could say remove collision, make the whole count to max-hole vertices 8, hull precision 10,000, hit apply,"},{"start":"3:06","end":"3:38","startSec":186.0,"text":"and there we are with a simpler piece of collision geometry. This is different from the other cart over here, where the collision data was actually brought over from its origin, I believe in 3ds Max. And you can see the way this was modeled is quite different from how Unreal Engine would automatically process this kind of data. For our simple wall, we might want to see what the existing collision data is,"},{"start":"3:38","end":"4:10","startSec":218.0,"text":"but once we click here, we'll see remove collision is grayed out. That's because this does not actually have any collision data. We have no primitives, no convex elements. What's happening here is we have collision complexity set to use complex collision as simple, which means that it'll use the exact geometry here as collision data, which isn't too bad because there's only 44 triangles and 76 vertices in this entire object. It would be much more expensive if we did something like that with the colonnade here. So we went down to the same thing and said,"},{"start":"4:11","end":"4:42","startSec":251.0,"text":"collision complexity, use complex collision as simple and save that. We could test to see that it's working with player collision. And now we're putting a lot more load on the CPU, even though it's very unlikely if we've got a standard third-person game, for example. It's very unlikely a player would be encountering colliding with the cornice of the columns. So we could go back here, change this back to project default, and if we wanted to, we could view the current collision"},{"start":"4:43","end":"5:15","startSec":283.0,"text":"and try modeling this ourselves. So I could select each of these and delete them, or just to remove collision at the start of that. And now I could go ahead and add a box or, you know, let's say to make it a little different. Maybe I want to do a capsule because this is a little bit more rounded. So I could do a capsule and I'd scale that down using my traditional hotkeys of Q, W, E and R. Get this at a height. Turn off some of my snapping, maybe."},{"start":"5:21","end":"5:55","startSec":321.0,"text":"Get this at a height that I think is reasonable for my particular use case. Put it roughly there into the column. It's actually a pretty good fit. I could fine-tune this, of course, if I wanted to, by looking in some orthographic views, maybe in a wireframe mode, something like this. Yeah, that looks pretty good. I could make it a little bigger if I wanted to. But the other thing here is I can hold down Alt and drag this out to duplicate this"},{"start":"5:55","end":"6:13","startSec":355.0,"text":"and create another collider right there. So if I go ahead and save that now, we can now see that my new colliders, these capsules, are existing here in place of the cubes that were there before. In the next video, we'll look at a skeletal mesh import pipeline."}],"08_SkeletalMeshes":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"In this video, we'll explore a Skeletal Mesh import pipeline. Skeletal meshes are different from static meshes. Like a static mesh, there is a mesh object for the visuals, but it also has a hierarchical bone skeleton that can drive the animation of the vertices that make that mesh. The vertices are often weighted to different bones and different amounts, and skeletal meshes are usually used, but not always just for created animated characters and organic shapes. And again, everything from the skeleton to the textures to the animation data and the physics body data"},{"start":"0:35","end":"1:08","startSec":35.0,"text":"can be created over in your DCC tool of choice, but Unreal Engine can often generate this on the fly and even let you edit it using the Skeletal Mesh Editor tools. When we import a Skeletal Mesh into Unreal, if we leave the Skeleton field blank, it will use the Skeleton that comes with the FBX file or generate one, but we can also select an existing Skeleton if we would like to ensure that this Skeletal Mesh will conform to an existing Skeleton. Once we have a Skeletal Mesh in our project, we can begin to animate it, and I'll show you a few different ways of doing that now."},{"start":"1:08","end":"1:39","startSec":68.0,"text":"If we open up the map called Gaunt, we'll see a Skeletal Mesh Actor imported via FBX. We see it came with a physics asset, its skeleton, as well as textures and materials. The physics asset again gives us a sense of how it will collide with geometry, similar to the collisions we were looking at before, and like those collisions, this is simplified. If we take a look at its skeleton, we can see a fairly standard set of bones here."},{"start":"1:39","end":"2:13","startSec":99.0,"text":"If we'd like to, we could visualize all the bones and even start to adjust to see how they move and how adjusting one bone affects parents and children. However, if we want to see this with an animation right now, we'll find that if we choose Animation Asset, nothing is available because there are no animations set up for this particular Skeleton. Luckily, if you recall earlier, I did bring in this Zombie Animation Pack,"},{"start":"2:13","end":"2:44","startSec":133.0,"text":"and we should also have some animations from our third-person template down here, for example, Run Forward. So there's a very robust animation retargeting pipeline in Unreal Engine now, so allow me to demonstrate that for a moment. So I'll sort this by animation sequence, and I can just select any of these to begin, right-click, and yes, I could do Replace Skeleton, which could give me mixed results, but I'm going to go ahead and choose Retarget Animations."},{"start":"2:44","end":"3:16","startSec":164.0,"text":"And so right now, we can see the source Skeletal Mesh for these animations is actually the UE4 Manny. Let's stick with UE5 to keep things simple for now. I think we can see a UE5 Manny right there, so I'll go Retarget Animations, there he is, UE5 Manny, and the target Skeletal Mesh is going to be gone. So we see the two standing side by side, and yes, I could do all of these animations one by one, but to start, I'm going to export a retarget asset."},{"start":"3:16","end":"3:47","startSec":196.0,"text":"And this retarget asset, I'll put into my temp folder, and it will create this auto-generated retargeting system that will try to match Manny's movements to Gaunt. And if I wanted to test this briefly, I could open up any of these animations and see how the two of them respond together to the same animations,"},{"start":"3:47","end":"4:18","startSec":227.0,"text":"even though they actually have different skeletons, and we can see it's working pretty well. Let's also try one of the more standard ones, like a walking animation, although I guess that is a little bit zombie focused. Another idle animation, that's an idle animation, sure. And yes, from there, I could select any number of these animations. I'll just do the attack ones here, and I can do export selected animations, put them in my temp folder."},{"start":"4:18","end":"4:50","startSec":258.0,"text":"I have the option here to do some prefixes and suffixes, and just go ahead and leave it as is, and do export. Now I have these animations, as we can see by the thumbnails, targeted to our Gaunt character, and I can even test them here in the editor by selecting one of them and then going to update animation in editor. It's looking pretty good there."},{"start":"4:50","end":"5:01","startSec":290.0,"text":"In the next video, we'll look at some future considerations for our FBX workflow. Thank you for watching."}],"09_FutureConsiderations":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"In this final video, we'll review some future considerations for our FBX Data Ingestion Pipeline. Unreal Engine now has a series of plugins referred to as Interchange. What are these? Well, they're a new import and export framework, they're format-abnostic, they're asynchronous, customizable, they can work at runtime, and they like some formats better than others. For example, they work very well with GLTF and OBJ formats, as well as textures. They can be a little bit more finicky with FBX, but it's certainly worth playing with."},{"start":"0:33","end":"1:10","startSec":33.0,"text":"This seems to be the future of how Unreal Engine would like to process various data that doesn't go as well through the Datasmith Pipeline, so give this a try if you haven't already. To take a brief look at the interchange system, we can see a number of plugins available to us, including OpenUSD, and you'll see that if we navigate further up from our Uproject folder, we have an Assets folder with a number of different geometry types available to us. Gaunt is our skeletal mesh, we have some 3ds Max textures, and let's try importing a GLTF file."},{"start":"1:10","end":"1:41","startSec":70.0,"text":"So this will come in via that new interchange format with a number of different options, and this is how we see Unreal Engine beginning to coalesce how it imports different kinds of data. Data mesh is... Ah, and if I wanted that all to be one object, I could try that again."},{"start":"1:41","end":"2:19","startSec":101.0,"text":"I could find the checkbox for Combined, and then we can find the Combined one here, and that's an import using the new interchange system. Let's try the same thing with an FBX file,"},{"start":"2:19","end":"2:55","startSec":139.0,"text":"and we can see the same thing here, interchange generic Assets Pipeline. We also have some presets, Assets Materials Textures, but whether it's an FBX file, a GLTF, an OBJ, etc., this is what we're seeing the future of Unreal Engine imports look like when they're not Datasmith, a fairly unified list of options using this new interchange system. And we can see by default our lion here came in with Nanite enabled, perhaps at the wrong scale."},{"start":"2:55","end":"3:27","startSec":175.0,"text":"If we wanted to fix the units, we could go reimport mesh with Dialog, type Unit, and we can see it's in meters, so the offset uniform scale, if we want to go from meters to centimeters, can simply be 0.01. And just noting that if we have Nanite enabled but we're packaging to a platform that does not support Nanite, Nanite will actually automatically generate a fallback proxy mesh, and you should still have a working project,"},{"start":"3:27","end":"3:43","startSec":207.0,"text":"just with slightly less control over how it gets reduced. I hope you've enjoyed and found something useful about this course on Static Mesh Data Ingestion for FBX. My name is Alex Coulomb, and I wish you luck on your Unreal Engine journey. Bye for now."}]},"106.02":{"01_Intro":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Hello and welcome to this course on Datasmith ingestion for Unreal Engine version 5.6. My name is Alex Coulomb, I am an Unreal Engine authorized instructor, course author, and also I run the XR Creative Studio Agile Lens immersive design. In this course we're primarily going to be discussing Datasmith as it pertains to static mesh ingestion, and in this video we're going to go over the basic course outline and the agenda we have for this series."},{"start":"0:31","end":"1:02","startSec":31.1,"text":"First off we're going to discuss what Datasmith is, how to use it, typical workflows with DCC tools when you export and then import. We'll look at various options we have when tessellating CAD surfaces. When it comes to triangle count we'll discuss different implementations of levels of detail, nanite, and how to know which one to pick. In there we'll move on to looking at hierarchies and pivot points as they're set up in your DCC tool of choice and some considerations for how best to get it from there into Unreal"},{"start":"1:02","end":"1:32","startSec":62.7,"text":"Engine via Datasmith. Once your data is in Unreal Engine we'll look at the modeling tools and the static mesh editor in particular which will allow us to adjust certain things such as pivot points, UV mapping, etc. After that we'll look at collisions and how to make sure they're set up appropriately for our project, and then we'll begin to wrap up with combining objects and looking at optimization considering such factors as draw calls when to merge actors and use proxy"},{"start":"1:32","end":"1:52","startSec":93.0,"text":"LODs and other ways that we can start to optimize the project to improve framerate. Lastly, we'll wrap up with a few future considerations and ways to take this course content further such as a brief look at Datasmith runtime. In the next video we'll take a look at our overview of Datasmith."}],"02_Interoperability":[{"start":"0:00","end":"0:40","startSec":0.0,"text":"In this video, we'll start with our overview of Datasmith and explore how it often gets used. Datasmith is one of the ways that Unreal Engine can ingest a wide range of DCC, digital content creation, model data, for a wide variety of industries. Often, that data is not set up in its original tools for real-time rendering, and so it's important to set up a project as much as possible to ingest the Datasmith data in a useful way. When importing 3D data from DCCs, it used to be very common to use more standard file formats like FBX or OBJ,"},{"start":"0:40","end":"1:20","startSec":40.0,"text":"but that presented a number of issues with how different DCC applications would create those files. Datasmith was created as a sort of one-stop shop to unify the way that DCC applications export their data so that they can come into Unreal Engine in a consistent format. That being said, when data exists in other applications, especially for particular industries, the goal is not necessarily an optimized real-time scene, so while Datasmith can take care of some of this work in the conversion process, it is important to have these considerations in mind when prepping to export from your DCC application of choice."},{"start":"1:20","end":"1:53","startSec":80.0,"text":"We want to make sure we're able to bring in key properties from our DCC projects, such as geometries, material, lighting, and animation, but again, we need to ensure that they can be optimized and run well inside of Unreal Engine. It's important to consider the different purposes of why and how different data was created. For example, AEC data, such as in a program like Revit, is created for construction, and all of the detail of that might not be as relevant for a real-time environment that is intending to visualize that building."},{"start":"1:54","end":"2:35","startSec":114.0,"text":"One of the key components of Datasmith that we'll be discussing is the importance of being able to maintain consistent scene hierarchies and pivot point locations as we move from our DCC tool over into Unreal Engine. The Datasmith file type is .uDatasmith, this is regardless of which program it comes from. The Datasmith file extension is .uDatasmith, regardless of what DCC tool creates the file. It often requires its own special exporters, which can be installed the way most plugins for each DCC tool are, though many software applications are now starting to incorporate .uDatasmith as its own file type, such as Revit, without the need for a special plugin."},{"start":"2:35","end":"3:05","startSec":155.0,"text":"The hierarchy we'll see for Datasmith files include the .uDatasmith file, which primarily serves as an index, and then we'll have a folder, which includes .uDmesh files, as well as various textures, which are saved in their original format, such as JPEG or PNG. When we import these via Datasmith, they all get turned into .uAsset files, unless you're using something like Datasmith Runtime. When we import our Datasmith files into Unreal Engine, they become standard .uAsset files."},{"start":"3:05","end":"3:38","startSec":185.0,"text":"Note that most CAD applications do not require their own custom exporters, CAD files are natively read by the Datasmith importer, and all CAD services are converted into Polymeshs. Note that CAD applications do not require special exporters, CAD files are natively read by the Datasmith importer, CAD services are converted into Polymeshs. And once again, all that data is converted in Unreal Engine into .uAsset files. The Datasmith plugin exporters can be downloaded from the Unreal Engine site right here."},{"start":"3:38","end":"4:16","startSec":218.0,"text":"On the website, you'll see a brief description of what the Datasmith export plugins are for, and then a large list of the different DCC applications supported, as well as various versions available at the time. You'll also see links to archived versions if you need to go back into an earlier version of Unreal. You'll see Mac and Windows are often both included. And some plugins, such as Revit, stop at 2023, not because they're no longer supported, but because for Revit 2024 and newer, that functionality is included directly in the application."},{"start":"4:23","end":"4:55","startSec":263.0,"text":"Note that there are some plugins that require you to go to a third-party website. When we import Datasmith files into Unreal Engine, we go to the Add Content button, scroll down to Datasmith, and then you'll see we have the option for both File Import and Direct Link Import. Please note if you don't see this option that you'll have to enable Datasmith as a plugin. Note when importing DeltaGen FBX files via Datasmith's import system that Simplify Note hierarchy is on by default."},{"start":"4:55","end":"5:28","startSec":295.0,"text":"You might want to consider turning this off if you've properly set up your hierarchy and want to preserve it. A brief word about Datasmith Direct Link. Choosing this option allows you to create a direct link between your DCC application and Unreal Engine where changes that you make in your DCC application will be reflected in Unreal Engine in real time. We recommend disabling Use Less CPU when in background so that Unreal Engine continues to update its viewport even when it is not the window in focus."},{"start":"5:29","end":"6:04","startSec":329.0,"text":"Note in this ArchiCAD example, a car is created and a chair is moved, and then after pressing the refresh button in the Datasmith plugin, we see Unreal Engine update both of these changes. A standard Datasmith pipeline might include starting in a DCC tool such as 3ds Max, Sketchup, or Revit.max files with PNGs, JPEGs, etc. Then using the Datasmith feature or plugin to create a .udatasmith file which includes .udmesh files, JPEGs, PNGs, etc."},{"start":"6:04","end":"6:40","startSec":364.0,"text":"Or if you're in something like SolidWorks, Katia, Rhino where you have such file types as 3dm, .dwg, etc. You just save those as their native file types, and in both cases these come in via the Datasmith exporter. That Datasmith scene comes into Unreal Engine with several organized folders full of .usd files, the same as anything else in Unreal Engine. And then if you drag that Datasmith scene into your level, you'll now have a hierarchy of your parent actor, which is a Datasmith scene actor, along with the same hierarchy as your DCC tool."},{"start":"6:40","end":"7:13","startSec":400.0,"text":"Here is another diagram walking us through the Datasmith process. In this case we talk about importing, tessellating if necessary, confirming the hierarchy and hopefully matching it to our DCC tool, then using mesh tools such as Modeling Mode to adjust things as needed, provide further optimization to ensure a smooth frame rate, and finally a beauty pass where we might add additional high quality materials, lighting, etc. One note about materials, you'll find that if you go into the Datasmith content in the Plugins folder,"},{"start":"7:13","end":"7:40","startSec":433.0,"text":"you'll see that there are a number of master materials that are already set up as Datasmith files get ingested. You're also welcome to use these as master materials for your other Unreal Engine projects as well. Feel free to review the material graphs for these to see some best practices at work for master materials. In the next video, we'll take what we've learned to do a Datasmith import exercise bringing a Datasmith file into Unreal Engine together."}],"02_Interoperability_56":[{"start":"0:00","end":"0:40","startSec":0.0,"text":"In this video, we'll start with our overview of Datasmith and explore how it often gets used. Datasmith is one of the ways that Unreal Engine can ingest a wide range of DCC, digital content creation, model data, for a wide variety of industries. Often, that data is not set up in its original tools for real-time rendering, and so it's important to set up a project as much as possible to ingest the Datasmith data in a useful way. When importing 3D data from DCCs, it used to be very common to use more standard file formats like FBX or OBJ,"},{"start":"0:40","end":"1:20","startSec":40.0,"text":"but that presented a number of issues with how different DCC applications would create those files. Datasmith was created as a sort of one-stop shop to unify the way that DCC applications export their data so that they can come into Unreal Engine in a consistent format. That being said, when data exists in other applications, especially for particular industries, the goal is not necessarily an optimized real-time scene, so while Datasmith can take care of some of this work in the conversion process, it is important to have these considerations in mind when prepping to export from your DCC application of choice."},{"start":"1:20","end":"1:53","startSec":80.0,"text":"We want to make sure we're able to bring in key properties from our DCC projects, such as geometries, material, lighting, and animation, but again, we need to ensure that they can be optimized and run well inside of Unreal Engine. It's important to consider the different purposes of why and how different data was created. For example, AEC data, such as in a program like Revit, is created for construction, and all of the detail of that might not be as relevant for a real-time environment that is intending to visualize that building."},{"start":"1:54","end":"2:35","startSec":114.0,"text":"One of the key components of Datasmith that we'll be discussing is the importance of being able to maintain consistent scene hierarchies and pivot point locations as we move from our DCC tool over into Unreal Engine. The Datasmith file type is .uDatasmith, this is regardless of which program it comes from. The Datasmith file extension is .uDatasmith, regardless of what DCC tool creates the file. It often requires its own special exporters, which can be installed the way most plugins for each DCC tool are, though many software applications are now starting to incorporate .uDatasmith as its own file type, such as Revit, without the need for a special plugin."},{"start":"2:35","end":"3:05","startSec":155.0,"text":"The hierarchy we'll see for Datasmith files include the .uDatasmith file, which primarily serves as an index, and then we'll have a folder, which includes .uDmesh files, as well as various textures, which are saved in their original format, such as JPEG or PNG. When we import these via Datasmith, they all get turned into .uAsset files, unless you're using something like Datasmith Runtime. When we import our Datasmith files into Unreal Engine, they become standard .uAsset files."},{"start":"3:05","end":"3:41","startSec":185.0,"text":"Note that CAD applications do not require special exporters, CAD files are natively read by the Datasmith importer, CAD services are converted into Polymeshs, and once again, all that data is converted in Unreal Engine into .uAsset files. The Datasmith plugin exporters can be downloaded from the Unreal Engine site, right here. On the website, you'll see a brief description of what the Datasmith export plugins are for, and then a large list of the different DCC applications supported, as well as various versions available at the time."},{"start":"3:41","end":"4:13","startSec":221.0,"text":"You'll also see links to archived versions, if you need to go back into an earlier version of Unreal. You'll see Mac and Windows are often both included. And some plugins, such as Revit, stop at 2023, not because they're no longer supported, but because for Revit 2024 and newer, that functionality is included directly in the application."},{"start":"4:13","end":"4:45","startSec":253.0,"text":"Note that there are some plugins that require you to go to a third party website. When we import Datasmith files into Unreal Engine, we go to the Add Content button, scroll down to Datasmith, and then you'll see we have the option for both File Import and Direct Link Import. Please note if you don't see this option that you'll have to enable Datasmith as a plugin. Note when importing DeltaGen FBX files via Datasmith's import system, that Simplify Note hierarchy is on by default."},{"start":"4:45","end":"5:18","startSec":285.0,"text":"You might want to consider turning this off if you've properly set up your hierarchy and want to preserve it. A brief word about Datasmith Direct Link. Choosing this option allows you to create a direct link between your DCC application and Unreal Engine where changes that you make in your DCC application will be reflected in Unreal Engine in real time. We recommend disabling Use Less CPU when in background so that Unreal Engine continues to update its viewport even when it is not the window in focus."},{"start":"5:18","end":"5:53","startSec":318.0,"text":"Note in this ArchiCAD example, a car is created and a chair is moved, and then after pressing the refresh button in the Datasmith plugin, we see Unreal Engine update both of these changes. And so a standard Datasmith pipeline might include starting in a DCC tool such as 3ds Max, SketchUp, or Revit, .max files with PNGs, JPEGs, etc. Then using the Datasmith feature or plugin to create a .uDatasmith file, which includes .udmesh files, JPEGs, PNGs, etc."},{"start":"5:53","end":"6:29","startSec":353.0,"text":"Or if you're in something like SolidWorks, Katia, Rhino, where you have such file types as 3dm, .dwg, etc. You just save those as their native file types, and in both cases these come in via the Datasmith exporter. That Datasmith scene comes into Unreal Engine with several organized folders full of .uAsset files, the same as anything else in Unreal Engine. And then if you drag that Datasmith scene into your level, you'll now have a hierarchy of your parent actor, which is a Datasmith scene actor, along with the same hierarchy as your DCC tool."},{"start":"6:29","end":"7:08","startSec":389.0,"text":"Here is another diagram walking us through the Datasmith process. In this case, we talk about importing, tessellating if necessary, confirming the hierarchy and hopefully matching it to our DCC tool, then using mesh tools such as modeling mode to adjust things as needed, provide further optimization to ensure a smooth frame rate, and finally a beauty pass where we might add additional high quality materials, lighting, etc. One note about materials, you'll find that if you go into the Datasmith content in the plugins folder, you'll see that there are a number of master materials that are already set up as Datasmith files get ingested."},{"start":"7:08","end":"7:31","startSec":428.0,"text":"You're also welcome to use these as master materials for your other Unreal Engine projects as well. Feel free to review the material graphs for these to see some best practices at work for master materials. In the next video, we'll take what we've learned to do a Datasmith import exercise bringing a Datasmith file into Unreal Engine together."}],"03_Exercise":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"In this video, we'll import a Datasmith file into Unreal. Now let's perform a brief exercise where we import our own .uDatasmith file into Unreal Engine. If you open up today's project folder, you'll see two subfolders, one for the uProject file, which will give you access to the Unreal Engine project, and then the other one is an assets folder that gives you access to CAD files, Datasmith files, and DCC files. So we open up the Datasmith file folder, we'll see that we have two .uDatasmith files in here,"},{"start":"0:34","end":"1:07","startSec":34.0,"text":"as well as the assets that come with each of them. In there, we see our .uDS mesh files, our .uDatasmith file in something like Notepad. You'll see it's fairly readable, we see which program made this Datasmith file, right in a 3D in this case, what version of Unreal it was originally made in, 4.27, as well as the various assets, and then how they are going to be located in the scene, including additional data such as their light map values."},{"start":"1:07","end":"1:42","startSec":67.0,"text":"So now go ahead and back up into the uProject folder, and go ahead and open up today's project. From here, we can take what we've learned, and go ahead to here, Datasmith file import, and we can find assets, Datasmith files, and cumulusexp.uDatasmith. When we open that up, it'll ask us where we want to put it, I'll put it in this temp folder, and then it asks us what we want to bring in, geometry, materials, and textures, lights, cameras, animations, etc."},{"start":"1:42","end":"2:14","startSec":102.0,"text":"And then if we plan on baking lighting, we can have a min and max light map resolution. If I do not plan on baking lighting, and if I do not intend to bake lighting and use Lumen, I can uncheck generate light map UVs. From here, I can go ahead and click import, and we'll see that not only is a scene created here, but it is also automatically imported."},{"start":"2:14","end":"2:46","startSec":134.0,"text":"We can see also the hierarchy has been preserved from Rhino. And if I wanted to adjust the origin of the whole project, for example moving the 200 cm up, I could do that and everything follows along, and if I wanted to update the actors from the scene, if I re-imported the file, I could do that. Similarly, I could right click here and say re-import with new file, and go ahead and choose the cone option,"},{"start":"2:46","end":"3:21","startSec":166.0,"text":"and we'll see an option here as well for respawn deleted actors if I had already made some adjustments here. I'll leave everything as it is, press import, and we'll see the scene comes in, and it looks the same, except now we have this cone on top, which is the difference between the first file and the second file. If my original file had changed, I could just click re-import, and that would also update the scene as it was. Also note the example map under content maps, modern house, we can save our scene here,"},{"start":"3:21","end":"3:43","startSec":201.0,"text":"which is also an imported Datasmith scene file, as we can see right here. Find it in our browser if we like. However, because we no longer have the source of this file, we are unable to re-import it. In the next video, we'll explore tessellation options when importing CAD data."}],"03_Exercise_56":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"In this video, we'll import a Datasmith file into Unreal. Now let's perform a brief exercise where we import our own .uDatasmith file into Unreal Engine. If you open up today's project folder, you'll see two subfolders, one for the uProject file, which will give you access to the Unreal Engine project, and then the other one is an assets folder that gives you access to CAD files, Datasmith files, and DCC files. So we open up the Datasmith file folder, we'll see that we have two .uDatasmith files in here,"},{"start":"0:34","end":"1:07","startSec":34.0,"text":"as well as the assets that come with each of them. In there, we see our .uDS mesh files, our .uDatasmith file in something like Notepad. You'll see it's fairly readable, we see which program made this Datasmith file, right in a 3D in this case, what version of Unreal it was originally made in, 4.27, as well as the various assets, and then how they are going to be located in the scene, including additional data such as their light map values."},{"start":"1:07","end":"1:42","startSec":67.0,"text":"So now go ahead and back up into the uProject folder, and go ahead and open up today's project. From here, we can take what we've learned, and go ahead to here, Datasmith file import, and we can find assets, Datasmith files, and cumulusexp.uDatasmith. When we open that up, it'll ask us where we want to put it, I'll put it in this temp folder, and then it asks us what we want to bring in, geometry, materials, and textures, lights, cameras, animations, etc."},{"start":"1:42","end":"2:20","startSec":102.0,"text":"And then if we plan on baking lighting, we can have a min and max light map resolution. If I do not intend to bake lighting and use Lumen, I can uncheck generate light map UVs. From here, I can go ahead and click import, and we'll see that not only is a scene created here, but it is also automatically imported. We can see also the hierarchy has been preserved from Rhino."},{"start":"2:20","end":"2:54","startSec":140.0,"text":"And if I wanted to adjust the origin of the whole project, for example moving the 200 cm up, I could do that and everything follows along, and if I wanted to update the actors from the scene, if I re-imported the file, I could do that. Similarly, I could right click here and say re-import with new file, and go ahead and choose the cone option, and we'll see an option here as well for respawn deleted actors if I had already made some adjustments here. I'll leave everything as it is, press import, and we'll see the scene comes in, and it looks the same,"},{"start":"2:54","end":"3:26","startSec":174.0,"text":"except now we have this cone on top, which is the difference between the first file and the second file. If my original file had changed, I could just click re-import, and that would also update the scene as it was. Also note the example map under content maps, modern house, we can save our scene here, which is also an imported Datasmith scene file, as we can see right here. Find it in our browser if we like."},{"start":"3:26","end":"3:39","startSec":206.0,"text":"However, because we no longer have the source of this file, we are unable to re-import it. In the next video, we'll explore tessellation options when importing CAD data."}],"04_Tessellation":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"In this video, we'll go over some of the tessellation options available when importing CAD files into Unreal Engine. If you're working from CAD or computer-aided design programs, we should talk about the tessellation options available to you. These are for NURBS services only. NURBS of course stands for Non-Uniform Rational Beast Splines and are often extremely curvy geometry that is generated in a different way from traditional meshes with polygons and triangles. Because Unreal Engine does not support NURBS directly, we'll have to tessellate and triangulate"},{"start":"0:34","end":"1:06","startSec":34.2,"text":"NURBS as they come into Unreal Engine. Essentially, we'll need to determine how the bodies and the surfaces will be processed, and then we'll be creating a static mesh, which is Unreal Engine's file type used as a base for further processing. Here you'll want to ensure you have enough detail for your targeted applications, not so much that you end up overburdening your system in getting a frame rate loss, but also not so little that we're not seeing the appropriate level of geometry detail necessary. This will be dependent on the individual model elements."},{"start":"1:06","end":"1:38","startSec":67.0,"text":"Here in the Datasmith Import options, we have a few things we can change here. We can talk about the tolerance, the edge length. We'll discuss each of these in the following slides. So let's take a closer look at tessellation and how we process the converting of 3D precise surfaces defined by algorithms and vectors into meshes. The three primary settings we'll be investigating are Cord Tolerance, Max Edge Length, and Normal Tolerance. Cord Tolerance defines the distance between the reference cat surface and the resulting"},{"start":"1:38","end":"2:10","startSec":98.3,"text":"triangular surface in UE5. Meshes do not actually have curves in their geometry, everything has to get straightened out at some point, so this is one of the first instances where we decide where something becomes straight that otherwise should be curved. If we take a look at the seat, we have references of 0.1mm Cord Tolerance, 0.5mm Cord Tolerance, and 10mm Cord Tolerance, which as we can see creates progressively more triangles if we have a smaller Cord Tolerance. And we'll see this as a bit of a pattern."},{"start":"2:10","end":"2:43","startSec":130.0,"text":"The smaller we make these numbers for tolerance, the higher our triangle count will be. Now, are any of these correct? It depends entirely on your application and how important this particular seat is. If you are doing a driving simulator and it needs to run on a mobile phone and you're spending a lot of time close to the seat, you probably want the seat to be pretty high quality but you're going to be limited by the processing power of the phone. If you have a seat that is going to be far away and it's not an important part of your scene and you're on a very heavy PC, maybe in that case you might actually use an even"},{"start":"2:43","end":"3:14","startSec":163.7,"text":"smaller triangle count than what you'd be using on a phone, it all depends on the priority you want to give it and what kind of frames per second you're willing to sacrifice. This will also give us a sense of harder edges or softer edges. Maximum edge length defines the maximum length of any edge in the triangle. Looking at our seat example again, we can see that as the number is lower, 10mm versus 20 versus 40, the lower number has the highest number of triangles and we can see in the"},{"start":"3:14","end":"3:50","startSec":194.7,"text":"wire frame the density of that versus the higher tolerance of 40mm which only produces 21,000 triangles. Now we have a few different ways that we can get into fine tuning exactly how this is set up. We have various CVARS and I'll give you a few examples of them when we do the exercise but ds4datasmith.cadtranslator.disableCADCURNALTESCELATION0 is a way that we can actually start to affect this setting more directly. It's on by default and needs to be deactivated in order to use CADCURNALTESCELATION0."},{"start":"3:50","end":"4:24","startSec":230.5,"text":"And once more here with normal tolerance we see how this defines the maximum angle between adjacent triangles and using our seat example we can see 5 degrees versus 10 degrees versus 40 degrees with the larger tolerance resulting in fewer triangles and a smaller tolerance resulting in more triangles because it is trying to be more accurate with how the curvilinear surfaces get translated into meshes. Once again what makes the most sense for your project will be application specific."},{"start":"4:24","end":"4:57","startSec":264.0,"text":"And of course don't forget that you can also set up LODs or Nanite which we'll talk about later on which allow us to have various levels of detail when we're closer or farther away from the object. Now let's do a short exercise where we import a CAD file into Unreal Engine and retestulate the components to add additional detail. Over in Unreal Engine 5.6 I'm going to open my content drawer and in a folder I will import a CAD model in CAD files, CATIA, TurboCharger, Darshart, and Kibar."},{"start":"4:57","end":"5:29","startSec":297.0,"text":"We have one here called assembly matap.catproduct, catproduct file. And if we go ahead and open this up you'll see that we will not be presented with an import dialog box, it will import on its own and we have static meshes here as well as a simple white material. So we go ahead and open up hybrid body 1. We can hover over it for a moment and see some details of it. And we can see here that we've got 3,640 triangles and so our goal is to increase that. We can see a little bit of some hard edges here, right?"},{"start":"5:29","end":"6:01","startSec":329.8,"text":"So let's see if we can make those feel a little softer. This is a hero object that we're going to be inspecting very closely inside our Unreal Engine application. Now I do want to note that we have reimport mesh with dialog and this normally would be a great way to do what we want to do. It does not work in this case but fear not, we do have the ability to retesolate by right clicking on the object here and choosing retesolate. Now keeping an eye on this again, 3,640 we can start to bring these numbers down as we"},{"start":"6:01","end":"6:31","startSec":361.3,"text":"saw in our previous examples if we want to bring the triangle count up. So let's try .1 for chord tolerance and let's try making the normal tolerance 10 degrees instead of 20. We'll leave these options as they are, leave max edge length at zero and go ahead and hit tessellate. And there we go. We see it goes up to 11,446 and now these are much softer edges. We could continue to bring it up further if we wanted to and if we wanted to remove some"},{"start":"6:31","end":"7:05","startSec":391.9,"text":"of those dark shadows for Nanite we could either disable Nanite or go ahead and uncheck support ray tracing. Lastly just to give you a little preview of some of the Datasmith CAD translator C-Vars we have access to, there's quite a few of them and if you want to know about any of these in particular you can just click on them and then just add a question mark to the end and open that up in the output log, scroll down to the bottom here and we can see there it says disable to use the CAD import library tessellator."},{"start":"7:05","end":"7:14","startSec":425.6,"text":"The default is that it's enabled so once again we could add zero to disable it. In the next video we'll go even deeper into understanding triangle count."}],"05_TriangleCount":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"In this video, we'll dive deeper into Triangle Count. Looking more at Triangle Count, as we just saw, various DCC and CAD applications have their own ways of processing geometry, some of which allow more control over the density of your mesh, while others do not. You should always keep your Triangle Count in check, especially if you do not plan on using Nanite. LODs, or levels of detail, can be generated in your DCC tool or automatically by Unreal Engine simply by selecting an LOD group or by specifying a number of LODs."},{"start":"0:36","end":"1:09","startSec":36.9,"text":"The idea behind LODs is that you will see higher poly, more detailed versions of a model as you are closer to it and it takes up more screen space and a simpler, less triangle dense version of your model as you get farther away and its space on the screen becomes smaller. The more LODs you have, the heavier your geometry will be, especially in terms of its RAM usage, so take care with deciding how many that you actually need. Note that while you're testing in Unreal Engine, you can temporarily disable certain LODs or"},{"start":"1:09","end":"1:42","startSec":69.4,"text":"even set a minimum LOD to determine what's actually necessary for your scene. Here we can see in LOD settings the opportunity to set the number of LODs that we have, as well as the decimated percent of Triangles that we are going to see. So for example, if our mesh had 10,000 Triangles, then at this level we'd be seeing 8,500 Triangles. Don't forget to always apply your changes after you've adjusted. And note that we have a Mesh LOD coloration view mode that actually will show different"},{"start":"1:42","end":"2:14","startSec":102.8,"text":"LODs as different colors. When fine-tuning these parameters, consider the details that need to be viewed on distant objects and what is not as necessary. And also feel free to consider adjusting the advanced option of the screen size, which will affect when we make a switch from one LOD to another. If you are using a platform that can support it, Nanite is the newest Unreal Engine 5 technology able to handle millions of polygons without breaking a sweat."},{"start":"2:14","end":"2:49","startSec":134.3,"text":"It does this by determining what's actually visible at a per pixel level and never drawing more Triangles than what's actually needed. Here we can see a comparison of the same scene with and without Nanite. Without Nanite, Unreal Engine has to process 5.8 million Triangles, whereas with Nanite, that becomes reduced to just 16.7 thousand. As we've already seen, in Unreal Engine 5.6, most new geometry that gets imported has Nanite enabled by default. However, there are plenty of opportunities to toggle Nanite on and off."},{"start":"2:49","end":"3:20","startSec":169.1,"text":"You can do this sometimes in the import dialog or just by right clicking on an object and choosing Nanite enabled or disabled here, or when you're opening, for example, the static mesh window, you also have access to toggle Nanite on and off there. Once again, it will not apply until you apply your changes. Let's take a brief look at the Nanite scene in the project, which can be found under Maps and Nanite. Here we can see a building as well as a more natural rock formation."},{"start":"3:20","end":"3:51","startSec":200.7,"text":"And if we type in stat RHI, which can also be found up here under viewport stats RHI, we can see that we're currently drawing between 13 and 16 million triangles. Now let's try enabling Nanite. We'll do it one at a time. We can open up SM Cliffs by finding it in the browser here and just go to Nanite, hit the checkbox or hit enable."},{"start":"3:51","end":"4:25","startSec":231.2,"text":"And this will take a moment to process. And while the rock looks the same, we now see a drop in the total number of triangles. Let's try the same thing with the building, which can be tricky because as we can see here, this building is made up of lots of individual parts. So what we want to do is we want to find the top level of classic building, find it over here, and then that entire geometries folder is going to want to be set to be Nanite."},{"start":"4:25","end":"4:59","startSec":265.9,"text":"So we can control A to select all of them, choose Nanite, and say enable Nanite on all 44 meshes. We don't have to save it right away. We can test to see if it's doing what we expected to in our scene as all the geometry reloads. And we can see as this is happening, a significant reduction in our triangles drawn. We're now down to only 7,000. And yet, we can see all the detail is maintained."},{"start":"4:59","end":"5:29","startSec":299.3,"text":"We can see this in our viewport by going to Nanite visualization triangles. And we can see the way that these triangles change as we get closer and further away for a cleaner view, type stat RHI again to remove that window. And we can see the way that Nanite, automagically, handles real time LOD without needing to manually"},{"start":"5:29","end":"5:40","startSec":329.7,"text":"set anything else up. In the next video, we'll examine how various DCC tools handle scene hierarchies and how best to preserve them in Unreal Engine."}],"06_Hierarchies":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"In this video, we'll examine how various DCC applications handle scene hierarchies and how best to preserve them in Unreal Engine. As we've already seen, Datasmith creates a hierarchy of parent and child relationships in Unreal Engine to mirror a similar setup that started in the DCC tool. Whenever possible, consider adopting various naming conventions and using tools in your DCC application to automate hierarchies and keep things organized. Consider using layers, groups, blocks, adjusting your pivot points, or using dummy or null"},{"start":"0:35","end":"1:12","startSec":35.4,"text":"objects which are quite similar to empty actors in Unreal Engine. Let's start with 3ds Max. Consider using the layers tool which works exactly the same way in Unreal Engine as it does in 3ds Max. All objects in each layer will be preserved when it comes over into Unreal. If you'd like to preserve the parent-child-actor relationship in the Outliner, if you'd like to preserve a parent-child-actor relationship in the Unreal Engine Outliner, use the group tool in 3ds Max to provide an empty actor for the child meshes to be attached to."},{"start":"1:12","end":"1:44","startSec":72.1,"text":"Ensure the pivot points are in the correct place and liberally use the rename tool to ensure you know what each object is. Be careful exporting any objects in 3ds Max that have been scaled or mirrored. If you have, use the reset XForm tool in the Utilities menu prior to exporting. Also note instances are preserved from 3ds Max and will result in a single static mesh over in Unreal Engine 5. Here in Sketchup Pro, we can already see an example of when it can be important to rename"},{"start":"1:44","end":"2:15","startSec":104.5,"text":"your actors to ensure that you know what they are. If we didn't know what these are over in Sketchup, we're certainly not going to know what they are when they translate over to Unreal Engine. The way the hierarchies work is a group is used as a top parent under the Data Smith scene, then come the components, then come the various objects that are part of the component. If an object is separate and not part of a component or a group, it will lie directly under the Data Smith scene in the hierarchy. Be sure to name your objects, components, and groups according to a naming convention"},{"start":"2:15","end":"2:46","startSec":135.8,"text":"that works for you. Otherwise, as we can see, things get very messy very quickly. Like 3ds Max, components that have the same definition will become instanced in Unreal Engine 5 and only have a single static mesh definition per object. And again, like 3ds Max, layers will be preserved, which is primarily helpful for selecting groups of actors at once and toggling on and off different categories of objects. In Revit, the hierarchy works like this."},{"start":"2:46","end":"3:18","startSec":166.7,"text":"A level is used as a top parent under the Data Smith scene, then come the family types, then come the components inside of that family. The layer list that Unreal Engine will give you after a Revit file will be based on family types. Note that because of the nature of Revit, you'll be somewhat more limited in terms of how you can rename or rearrange different assets. Note that families also count as instance geometry and will create one mesh in Unreal Engine that gets used by all family objects in the scene."},{"start":"3:18","end":"3:48","startSec":198.5,"text":"Note that a family will create a single static mesh in Unreal Engine, which then becomes instanced throughout the scene, just like 3ds Max and SketchUp Pro. For Rhino, our layers become the top parent in UE5, then the defined blocks, then the various components of that block. Note that Rhino groups do not affect the hierarchy in UE5, unlike 3ds Max. In Rhino, we recommend using blocks as much as possible, as they'll also help with establishing"},{"start":"3:48","end":"4:19","startSec":228.6,"text":"pivot points. Otherwise, the pivot point of every object will be set to 000, resulting in objects that are very far away from their origin. Again, be sure to rename layers and individual objects in Rhino so when they come to Unreal Engine they still make sense. And note there's a robust scripting community for Rhino, and there are scripts out there that will rename objects based on layers, groups, or anything else you might like. Here are two Python scripts as examples."},{"start":"4:19","end":"4:38","startSec":259.3,"text":"Note that instanced blocks in Rhino result in a single static mesh definition for the components of that block, again carrying on this trend that one piece of geometry can then be instanced many times when it makes its way back over to Unreal. In the next video, we'll explore the modeling tools available to us in Unreal Engine."}],"07_ModelingTools":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"In this video, we'll explore the modeling tools available to us in Unreal Engine, which can help to adjust geometry that needs further changes after a Datasmith import. Sometimes, your scene may need to be readjusted in your DCC application, then re-imported into Unreal as a Datasmith file. Other times, you may find it makes more sense to make the adjustment directly in Unreal Engine. The Modeling Tools plugin is a good friend for this. It allows us to repair or adjust meshes without going back to our DCC application and do"},{"start":"0:33","end":"1:06","startSec":33.4,"text":"things such as selecting triangles individually, by material, by element, or by smoothing groups. We can change pivot point placement, we can delete or flip faces, we can adjust UVs, and we can even add material elements or sub-materials to any set of selected triangles. In order to use the Modeling Tools plugin, it simply has to be enabled as the Modeling Tools Editor mode. You'll also find other editor modes, such as for hair, static meshes, and even skeletal meshes, but they will not be covered in this course."},{"start":"1:06","end":"1:38","startSec":66.2,"text":"To enact minor mesh repairs, simply select and edit faces using the variety of face selection parameters available to you. From there, you'll see common model actions, such as extrude, inset, delete, and flip if you want to change the normals. If you plan on acting on the same groups of geometry several times, you can create polygroups for easier reselection. Also note the ability to easily relocate pivot points based on simple selections of the overall position relative to the mesh."},{"start":"1:38","end":"2:15","startSec":98.5,"text":"To briefly demonstrate modeling mode, let's go ahead and open up that Modern House Datasmith map, select any object you like, go to the drop-down here and select Modeling, which can also be found with Shift 5, and then we're presented with a cornucopia of different tools, creating fresh geometry. Briefly, let's go ahead and click Select and Try Select, just to see that we're able to grab services here. There's the ability to create a polygroup if we've got a selection we plan on reusing quite a bit, and if we go down to Deform, we can see a quick example of Offset."},{"start":"2:18","end":"2:52","startSec":138.1,"text":"In case we want an easy way to change that geometry, we have tools like Displace, which with a higher subdivision of triangles could start to add a lot more variation to the geometry here if we wanted to feel a little less orthographic. Finally, let's just take a look over in X-Form and Edit Pivot. We'll notice that in this scene, all of the objects came in with their pivot point over here, which is 0, 0, 0, in the original project the Datasmith file came from, but we might want to reuse some of this geometry or just have easier access to adjust it, and here"},{"start":"2:52","end":"3:25","startSec":172.8,"text":"we could click on something like Center to bring the pivot point here. If we wanted to stay on the ground, we could click Bottom, and if we don't like how far underground that is, we could go and start to adjust that manually. We could go and start to bring this up until this is at 0. As this transform is specific to the pivot point, once I press Accept, I now have a pivot"},{"start":"3:27","end":"3:45","startSec":207.5,"text":"point much more usable for this particular piece of geometry. In the next video, we'll look at collisions."}],"08_Collisions":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"In this video, we'll discuss collisions and how to set them up properly with Datasmith imports. When we first import geometry into Unreal, including with Datasmith, we are often presented with a checkbox that asks us if we would like to generate collisions. We also have the ability to add in custom collisions using simple primitives like boxes or spheres or capsules, as well as the ability to create auto-convex collisions. A complicated piece of geometry using its own geometry for collisions can get expensive,"},{"start":"0:33","end":"1:06","startSec":33.7,"text":"so when possible, try to keep collisions simple. And note, as seen in this example, that a single object can have multiple collisions, so I find it pretty useful to be able to use some combination of the simplified collision options here to create a custom set of different primitive shapes to conform to the collision shape that I need for a particular project. As a quick example, let's go back into our project and set up a couple collisions. If we want to see the collision already existing in our map, we can go to View Modes and click"},{"start":"1:06","end":"1:39","startSec":66.9,"text":"on Player Collision, not Visibility Collision, and if we see that it's black like this, we know no collision has been set up yet. So let's use the same piece of wall geometry we were already looking at, double click here, and we can see, if we click on Collision, that because we don't have an option for removing collision, we know that no collision is set up yet. This is a pretty simple box, so we could go ahead and do a box simplified collision, which will adapt and conform to the geometry in a nice clean, simple way."},{"start":"1:39","end":"2:12","startSec":99.7,"text":"Go ahead and save that. And now, if we go back to that View Mode, we'll see this one object shows up as a collider. Let's try doing a custom one for the ground. So instead of automatically setting it up, we can go into the static mesh here, and we could go ahead and add still a box, but we might start to adjust a few features of it,"},{"start":"2:12","end":"2:43","startSec":132.1,"text":"and we can move it up and down by grabbing it and changing it like this. We looked at a side view, something orthographic. And of course, if we wanted to build this up from a number of pieces, especially imagining if the terrain was higher, we might actually do this in a couple parts. So perhaps we might have one piece of geometry over here, and I could hold down Alt, just"},{"start":"2:43","end":"3:14","startSec":163.8,"text":"like in the regular editor, to duplicate another piece of geometry here. I could even rotate it if I needed to, and start to build this up from a number of different services, all depending on what level of precision you need. Perhaps you're going to have a basement level, and you need the collision to be clear, so you have easy access to the basement area without being blocked by that additional collision. Or maybe you just have floors that you want to set up in a particular way."},{"start":"3:14","end":"3:52","startSec":194.0,"text":"You might also get into the world of physical materials and creating friction in certain ways. There's a lot of ways this can become more advanced if you like, but I'll go ahead and save that. And then once again, just check on our player collision, and we can see everything showing up there in the shapes of the collision we've done. Now if we want to set this up in a bulk way for everything in our scene, we can go ahead and find the folder where this lives, mHouse, find it here, then we can go over into Geometries,"},{"start":"3:52","end":"4:30","startSec":232.7,"text":"and we can select All and right-click, and we'll go to Asset Actions and Edit Selection in Property Matrix. From here, we have all of these objects selected. We can do Control-A to confirm, and then for Collision, we can tell the collision complexity to use complex collision as simple. From there, if we save, we'll now find that if we go to our collision view, everything"},{"start":"4:30","end":"5:02","startSec":270.5,"text":"now has colliders. And then if we wanted to go and disable colliders in certain places like the door, we could just open up those particular pieces of Geometry and scroll down, and there's actually two choices here. We could change our collision preset to No Collision, or just simply change this back to Project Default. Save that, and then we can see we have a nice opening where we can move into the project,"},{"start":"5:02","end":"5:25","startSec":302.1,"text":"bump into furniture, and climb upstairs. And though noting that we are adding additional complexity, especially on the CPU, to have such complicated geometry here for collision when that might not be necessary, this could probably be done as a cube or a few cubes, all dependent on the needs of your project. In the next video, we'll look at how to optimize our project further."}],"09_Optimization":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"In this video, we'll explore various optimization techniques to ensure that our Datasmith project can run at an acceptable frame rate for our application. When considering the work that goes into achieving performance, we often have to consider how that balances against quality and features. It is often thought of as a triangle where you can sit somewhere within here, but you cannot achieve all three of these equally. With enough knowledge of engine optimization tools, you may find that you're able to buy"},{"start":"0:30","end":"1:02","startSec":30.2,"text":"back performance. Draw calls is one aspect of optimization that you'll hear often discussed. Draw calls represent a package of triangles sent to the GPU, and the GPU renders draw call by draw call, not triangle by triangle. Note that each mesh and material represents a different draw call, which means that if you have three objects, even if they have the same material, they will still represent three draw calls, and one object with two materials will represent two draw calls."},{"start":"1:02","end":"1:34","startSec":62.2,"text":"You can profile draw calls at any time using statRHI, this is the same command we used earlier when looking at Nanite and Triangles drawn, and that's a particularly useful statistics window to keep an eye on as you can see both triangle count and draw calls side by side. Once again, every project is different, but as a rule of thumb, desktop and console experiences often want between 2,000 and 4,000 draw calls as a maximum, virtual reality 800 to 1200, and mobile devices 200 to 400."},{"start":"1:34","end":"2:09","startSec":94.7,"text":"One of the ways Unreal Engine tries to auto-optimize the scene, and you can play to the strengths of this, is Unreal Engine will attempt to not render what it can't see in the scene, and this can mean both the camera frustrum, what the camera can actually see in the current screen space, as well as objects that are hidden by other objects. So in this case, we can't see the motorcycle behind the wall, so that could get cold, but then we also can't see the motorcycle behind the camera, and so that also gets cold. If you have very high triangle count objects, especially with a lot of draw calls, consider"},{"start":"2:09","end":"2:42","startSec":129.1,"text":"separating them from each other so they are rarely seen at the same time. Changing actors is a way to reduce draw calls. You can select a number of static meshes in your scene, and then generate a single static mesh from them. You can preserve the geometry, which would mean you have no reduction in triangle count, but if there are shared materials, that will reduce draw calls without changing anything else about the objects. Note this can be an issue for very large objects, we're looking at a corner of the object will still require rendering the entire thing, as those other previous elements which"},{"start":"2:42","end":"3:16","startSec":162.8,"text":"were separate are no longer called out, and it can be an issue for animated actors where you're dealing with skeletal meshes and bones and animation data. Another option you have when you're combining actors is to generate proxies. In this case, instead of the geometry being preserved, it's simplified and can result in a lower quality mesh based on parameters that you choose. As part of that, you can even combine the materials into one single texture and material family. One option you have during this process is to combine all the materials."},{"start":"3:16","end":"3:34","startSec":196.2,"text":"This is something worth playing with. There are many options when generating proxies, so be sure to experiment with them in order to ensure that you achieve the results that you're after. For our final exercise, we'll review a number of objects in a scene and figure out the best way to combine them. Thank you. Bye."}],"10_OptimizationExercise":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"For our final exercise, we'll look at a couple different sets of objects in our scene and discuss the best ways to combine them. Let's go ahead and open up the map called bulky stairs. Here we'll see another simple house, which of course is another Datasmith file, and we want to zoom in on the stairs in the back. Now we could profile this a little bit, look at statRHI, see that we've got about 400,000 triangles being drawn as well as about 1,400 draw calls,"},{"start":"0:35","end":"1:11","startSec":35.0,"text":"and we could start to try to figure out what's causing this. But of course, the name of the map gives us a little bit of a clue. Still, if we go over to our optimization view modes and look at shader complexity and quads, we can see some areas that are a little bit more upset. These red areas, it's because of the translucent glass, translucent materials are expensive. Over here, it's some combination of the high detail of the couch and possibly the materials as well. And then over here in the stairs, we see these relatively straight, simple lines seem to be very, very complex."},{"start":"1:11","end":"1:42","startSec":71.0,"text":"So, right now again, we're kind of keeping an eye on our triangles and draw primitives. And if we want to confirm that what's going on is what we think is going on, only go ahead and type stair. Or if things are named properly, we can actually just find there that selecting any of these objects will show us that the parent object is stair. And we can right click and we can do select immediate children, ctrl alt D. Now by default, this will just go one below, but if we do ctrl alt D several times,"},{"start":"1:42","end":"2:14","startSec":102.0,"text":"we'll eventually select everything connected to the stairs. And so again, keeping an eye on our triangles here, which we can already see are quite high, even though we're really just looking at the stairs, frustrum calling and whatnot still helping us out. If I were to right click in here and go to visibility and do show only selected, I'm still seeing 400,000 triangles, even more if I zoom out, nearly 700,000 triangles at times. And 6470 draw calls."},{"start":"2:14","end":"2:47","startSec":134.0,"text":"Now that is too much for these stairs, unless these stairs are the star of your project and you really don't want to deal with optimizing this in any capacity at all, which depending on your computer might be okay. But for the heck of it, let's try optimizing this a little bit. Now because this is the main thing we want to focus on, one of the first things I'll do is I'll go over to my levels tab here, which can also be found under window levels, and I'm actually going to add a new empty level."},{"start":"2:47","end":"3:22","startSec":167.0,"text":"What this will allow me to do, just stairs, is separate out the stairs from everything else in the project and make it very easy to select this. I could also do this by just creating a group. And then once again isolating when needed, but this will allow me to just focus on the stairs a little easier. So I can do move selected actors to level to bring all the stairs over here. Ah yes, and sometimes you'll see a message like this if you're dealing with a datasmith file, because of course we're breaking up the band, so to speak."},{"start":"3:22","end":"3:56","startSec":202.0,"text":"So if I go ahead and say yes, we are kind of keeping the stairs as its own separate object. But the benefit now is we go back to lit mode and unisolate everything, show all actors control H. We now have the ability to focus just on the stairs by toggling off the persistent level, noting that we'll probably want to be in an unlit view mode or maybe even a wireframe mode to examine this as we make changes. So as we can see, we have about 200,000 triangles."},{"start":"3:56","end":"4:41","startSec":236.0,"text":"We have a higher max, but I think that's from when we were seeing the rest of the scene, and then over 2400 draw calls. So that of course, if you think that sounds like too many, that is in fact too many. So the first simplest thing we can do is we can select all of this and because this is now in its own empty level, we can just do control A. And then we can go to actor, merge 2425 actors and just try hitting merge. And we'll go find a folder to put this in, stair merging, and we'll call this sm underscore stair simple underscore V1 sm for static mesh of course."},{"start":"4:41","end":"5:22","startSec":281.0,"text":"And that happened pretty quick. We can see in this folder that we have not created anything other than a new piece of geometry and the size is still rather large. So all that we've done really is combined everything into one object, but by just having this one new object in here, let's try dragging it into the scene. We'll find, if we can find it, yes, the pivot points a little bit of a strange place, that if we compare these two, the merged object and the original 2400, we'll have a significant difference in performance."},{"start":"5:22","end":"5:54","startSec":322.0,"text":"So let's turn off the parent actor there for stairs. And we'll see here, while our triangle count remains quite high, our draw call count has reduced significantly. Compare that to the stairs being on. Again, similar triangles, but a much higher draw call count. And do note that some of the draw calls here are actually due to the editor and the UI. There should really only be a few because of the two materials here, and this being one single static mesh component."},{"start":"5:54","end":"6:33","startSec":354.0,"text":"Now, if we were to take this a step further and enable Nanite, we would actually see a significant reduction in the triangles. Here, we're now down to about 6000. Draw calls stay similar, although it does look like there's been a reduction there as well. But this is the magic of Nanite. We retain all the detail assuming we're in a scenario where we need to see those nuts and bolts, but we're never drawing too many triangles at once."},{"start":"6:33","end":"7:08","startSec":393.0,"text":"We can take this further if we wanted to. If we decided that we did not want to have the full detail of this for any reason, we could go ahead and open up that mesh. And if we type in the word triangle, we have two similar options here. One is for when we're using a traditional LED workflow and one is for Nanite. They essentially do the same thing. We can basically say, don't have all 200,000 Nanite triangles. Let's have 20% of that."},{"start":"7:08","end":"7:40","startSec":428.0,"text":"And it won't activate until we hit apply. Let's keep an eye on some of the higher detail elements right here. We'll see if these still remain very curved or if they'll feel more faceted. So if I just scroll down here, we'll find where it says apply. There we are. Apply changes. And we'll see Nanite vertices and Nanite triangles reduce. And we can indeed see that this is faceted now."},{"start":"7:40","end":"8:12","startSec":460.0,"text":"Of course, it's fine from a certain distance away. It's just a question of whether or not you need to see that level of detail. Now we can also from here try the traditional LED workflow. We could disable Nanite, hit apply changes, and then we're back to the original triangles and vertices post merge. But again, we can go down to our reduction settings and we could once again go to something like 20 and apply changes."},{"start":"8:12","end":"8:50","startSec":492.0,"text":"And there we are once again seeing a slightly more faceted surface there, though it's worth noting the cylinders still feel very smooth. And if that's okay, we might treat this as an LOD zero, but then add a few more LODs, let's say four, and apply changes. And we'll be starting from that level of triangles and going down from there. And now we can see as we zoom out the automatic LOD changes, we could of course manually adjust the screen sizes that these appear at."},{"start":"8:50","end":"9:23","startSec":530.0,"text":"If we go ahead and uncheck auto compute LOD distances, then we can change the screen size at which each of these will appear. But now if for any reason we can't use Nanite, for example, if we're on a mobile platform, this becomes a very robust way to clean up how the stairs look. Now for only two materials, we're probably okay stopping there. But if we did want to reduce this to a single material, the next thing we would want to do is go over to actor, merge actors, and then we could just click on simplify."},{"start":"9:23","end":"9:55","startSec":563.0,"text":"But let's look at some of the settings at our disposal. Merge, simplify, batch and approximate. I'll go to simplify. And you'll see that we have the ability to basically decide how big from a screen size perspective this should exist, 1200 being the maximum. And then we can change some things like merge distance and most importantly, at least when I usually use this, the ability to have Nanite on and off and the material settings. So I like to increase this texture size from the default usually 1024 by 1024 to 4096 by 4096."},{"start":"9:55","end":"10:33","startSec":595.0,"text":"So when these get combined, we're going to see sharper relief of where everything goes. We can reduce that texture if we need to later, but that's where I'd like to start. I don't think for something as simple as this will need a normal map or a metallic map. These are very similar materials just using a different color. In fact, I think they share the same Sketchup reference master material, right with only the color being different. So this will be the highest quality that we can create or the most triangles, I guess you could say from this particular option with simplify because this is intended to be a proxy mesh."},{"start":"10:33","end":"11:05","startSec":633.0,"text":"Let's see what happens when I click merge actors, noting that we can also replace the actor we already have if we want to. But I'll just go here and say SM Stair. Stair symbol B2. And it now says creating mesh proxy, noting also that we are generating a collision for this with create collision on by default. And here we are. You'll notice right away a significant reduction in the triangle count."},{"start":"11:05","end":"11:40","startSec":665.0,"text":"But as I mentioned, this is about as high of a triangle count you can get using those particular merge settings using the maximum screen size of 1200 that it will create for. But it's also created this new material with a 4k texture that very deftly maps where all these different elements should be based on the UV mapping. And the two materials in the original. So this will be a very highly optimized object with a single material."},{"start":"11:40","end":"12:16","startSec":700.0,"text":"And great if you need to be working on a much older device such as I don't know a 2015 smartphone perhaps. So we'll put these two side by side. Actually, maybe we'll put all three side by side. And start to compare them. So we have these stairs over here. Lots of detail here, including these tiny, tiny elements. Oh, those are just sprites."},{"start":"12:16","end":"12:48","startSec":736.0,"text":"I'll go into game mode so we don't see the sprites. So lots of detail here. We'll also turn on a wireframe mode. Lots and lots of detail there. Much less detail here in the proxy mesh. And then back to more detail here. Worth noting in the proxy mesh that much of the geometry that is disappeared has now been replaced with the texture."},{"start":"12:48","end":"13:20","startSec":768.0,"text":"So we can actually see, despite there being no geometry here again just to see it in wireframe. It's actually projected. The absence of that geometry as texture settings when baking the material. So it might be helpful to see this in full lit mode with our main level turned back on. And just to compare these two side by side, you'll notice from a distance, they're actually fairly comparable."},{"start":"13:20","end":"13:53","startSec":800.0,"text":"But as we get closer to them, we start to notice more and more of the differences. But at a glance, you know, if you're running up these stairs, this might be enough and you don't need the full detail of the nuts and bolts here. And certainly, or probably not, the full full detail of everything in the original setup. Now let's find an example where combining materials and merging will make a lot more sense. We have another map in here called Sports Bike."},{"start":"13:53","end":"14:26","startSec":833.0,"text":"And if we frame in on what we've got here, we can see once again, we have a lot of triangles, a lot of detail, a lot of draw calls and more materials. So let's see what happens if we use the same settings we just used for our stairs, but for a smaller, more contained object with more materials. For this, I'll select Headset 2 and once again, Control-Alt-D several times until everything here is selected, 86 out of the 94 actors in the scene."},{"start":"14:26","end":"14:57","startSec":866.0,"text":"And I'll go to Actor, Merge Actors, Merge Actor Settings. And this time, I'll just replace Source Actors just so we can see what happens when we do that. Noting again, we've got a very high number of triangles, almost a thousand draw calls just from this one scene, although we've got other things happening in the background as well. I'll keep that screen size of 1200 and I will go ahead and make sure the Material Settings are once again at 4K by 4K. Let's go ahead and choose Merge Actors."},{"start":"14:57","end":"15:28","startSec":897.0,"text":"I'll put this over in my Temp folder. Call this one Sports Bike. Proxy is fine. I can call it Static Mesh if I want. And we should see the existing 84 objects swapped out with a single object now with far less than the million or so triangles and 800 plus draw calls."},{"start":"15:28","end":"16:05","startSec":928.0,"text":"And now here we are with a very colorful looking texture combining those various materials with the UV mapping. Again, I generally like to start at 4K and then just bring the resolution down if needed. MIPS, of course, can also help with that. And we can see there's already 13 MIPS applied to this as a power of two texture. So as we zoom out or just check in here, we're basically getting different LODs for the texture anyway. And we can see that the proxy we generated is actually more triangles than the stairs because it is in a more contained area and therefore can reach a higher triangle count."},{"start":"16:05","end":"16:38","startSec":965.0,"text":"And here we are with our simplified object with a single material and a decent level of detail, which may be acceptable for us, depending again on our application and how close we need to get to it. Note, of course, some of the inaccuracy with what we're seeing here with statRHI. Because if we open this up, we can see it is actually only 22,000 triangles."},{"start":"16:38","end":"17:08","startSec":998.0,"text":"And once again, if we wanted to, we could enable Nanite or set up a number of LODs to stream. From 22,000 max triangles to less than 3,000. I hope this has been a useful exercise. In our final video, we'll review future considerations for our Datasmith projects."}],"11_FutureConsiderations":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"In our final video, we'll wrap up the course and discuss future considerations. There are many ways to expand on the Datasmith capabilities we've already discussed, including a number of other options when importing Datasmith, using Data Prep recipes, including using templates like the Collab Viewer, which has architecture and automotive variations, and include robust Datasmith capabilities already. Some of what's coming up for Datasmith include more round-trip capabilities where we can"},{"start":"0:30","end":"1:03","startSec":30.3,"text":"actually bring our data from Unreal Engine back to our DCC tools, and more capabilities directly in Unreal Engine to reduce the need to go back to our DCC tools. One final feature I'll show you, to give you a taste of what other Datasmith features are in store, is Datasmith Runtime. As mentioned, this also exists in the Collab Viewer template, and it is a way to load Datasmith actors while in play mode, allowing for Datasmith files or GLTF files to be simply loaded into memory without having to store them in your project."},{"start":"1:03","end":"1:34","startSec":63.9,"text":"Here in our empty scene, ensure Datasmith Runtime is enabled, and then here, I'll simply create a Datasmith Runtime actor, which is actually referred to here as a Datasmith destination. I'll leave that in the middle of my scene, and then I'll open up the level blueprint, get a reference to our Datasmith Runtime actor, pull off of it, and go ahead and load file"},{"start":"1:34","end":"2:11","startSec":94.5,"text":"from explorer. Make sure we're coming off of begin play, and we could set a default path if we wanted it to find a particular path automatically, but I can just compile this as is. Go ahead and hit play. It'll prompt me to load a Datasmith file, and I can go ahead and grab my old file, cumulus exp with cone, and as our exposure gets set up, we can see we've got that Datasmith file loaded directly into our scene."},{"start":"2:11","end":"2:29","startSec":132.0,"text":"And when I press stop, I'll find that because it was just loaded into memory, it's not even here. Thank you so much for following along this course. My name again is Alex Coulomb, and I wish you well on your Unreal Engine journey. Take care."}]},"107.04":{"01_Overview":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Hello and welcome to today's Unreal Engine training. We're talking today about an introduction to animation in automotive using 5.0. So today we'll be covering the new 5.0 animation editors and features. We'll be talking about importing and exporting your animation assets. We'll go over the skeleton, mesh and animation sub editors and we'll also create a new animation asset inside the engine. And then we'll talk about the animation blueprints and talk about the sequencer animations as"},{"start":"0:33","end":"0:35","startSec":33.1,"text":"well. So let's get started."}],"02_New Animation Features- Unreal Engine 5.0":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"So, I'm starting with a look at the new animation features in Unreal Engine 5.0. We've got coverage on some of the animation node functions that are new to the editor and also we'll look at the folder structure being slightly different than how you may have seen it before. So animations are now stored in the sequences folder. So if you go to content, Manikin for example, if you are looking at the Manikin, the animations"},{"start":"0:30","end":"1:03","startSec":30.1,"text":"folder there, you've got the sequences inside of that folder. You can also edit in Sequencer with or without Control Rig and we'll talk about that later in the presentation. Some other new features mentionable. With 5.0 there have been many added improvements regarding animation. So some of these improvements include an IK retaggator and IK rig. So essentially what we're saying here is that retaggating animations from one skill set to another no longer uses the retaggating manager. So using these two new tools, a new workflow has been created there."}],"03_Animation Types- Ways tp approach Animation within UE":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"When we're looking at ways to approach animation in Unreal Engine, we've got a few different animation types to go over here. So when you're animating within Unreal, you've got the input animation, linear animation, and Live Link. And so I'll just discuss a little bit about what each of these are. So input animation is typically where the user wishes to control or play the scene. Any inputs that they're pressing on a wide range of input controllers, whether it's"},{"start":"0:32","end":"1:04","startSec":32.6,"text":"a touchscreen, iPad, gamepad controller, the animation system drives the animation through pushing a capsule that talks to that animation system. So then the output of that is typically a character, in our example a pawn, which can be a bipedal, quad, a vehicle, whatever kind of pawn you would like there. The controller possesses that pawn and runs it around in the world. So that's what we mean when we say input animation. Linear animation is bringing in animation files into Unreal coming from some kind of"},{"start":"1:04","end":"1:38","startSec":64.4,"text":"FBX exporter, which we'll talk about the FBX exporter in the next few slides. But linear animation will be something that's come from your DCC app maybe, or some kind of live mocap data. So you can also bring that in via Alembic, which is the raw data, frame by frame cache, and apply it to the sequencer using a control rig or even keyframed directly inside the sequencer. The last animation type will be Live Link, and this is a plugin that allows you to connect a mocap suit, you can connect it to Maya or maybe some other 3D application, and you can"},{"start":"1:38","end":"2:11","startSec":98.8,"text":"drive animations live inside of Unreal Engine. So by having one-to-one information from your, through your Live Link plugin, maybe it's using a mocap suit and you can see the performance happening live inside of Unreal Engine. You can then use a take recorder to record all this input and export it to its own animation, which you can then use in sequencer or you can play over the top layer in animation. You can do a whole bunch of things with this information once you've got it inside the"},{"start":"2:11","end":"2:41","startSec":131.2,"text":"engine. But the main tool being here that you can see one-to-one feedback from the input, whether it be a mocap suit or Maya or any kind of 3D application like this directly inside of Unreal Engine. So the type of animation sequences you can get, you can either have in-place or game-driven motion and these are great for the input animations that we were referring to before. These animations are in place, they're just on the spot animations, and then the animation"},{"start":"2:41","end":"3:14","startSec":161.3,"text":"blueprint will push them around with the capsule based on player input and that's all handled through code. So the root bone wouldn't move in this instance. If you want a more animation driven approach, it goes some place or root motion is what we refer to here, which is intended for a sequence to drive it. So we would maybe add keyframes in sequencer or do some other kind of action inside of sequencer to push the character around. If you enable root motion option, it will force the capsule to move according to the"},{"start":"3:14","end":"3:31","startSec":194.9,"text":"root motion of the animation and animations need to have root bones for that to work. So if you're using a Mixamo, AnimSkeleton or it's in the wrong place, you just need to make sure you have a root bone with that option for it to work with the enable root motion option."}],"04_Exporting and Importing- FBX Pipeline":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"So let's talk a little bit about how you go about exporting and importing your FBXs and the best pipelines to follow. So the main rules of the skeleton are essentially the same rules apply to any skeleton setup. You should have one root bone in your mesh or your skeleton, should we say, that connects to everything else. Root goes from zero zero to a central bone, e.g. a hip bone if you're using a humanoid"},{"start":"0:32","end":"1:04","startSec":32.4,"text":"skeleton and this helps with root motion, which we'll talk about a little bit about later. Your blending is based on a fully connected skeleton, so the hierarchy is key here and even if you're not making a humanoid character, even with a vehicle, just making sure you follow a good hierarchy is super important here. When we talk about floating bones in new skeletons, the best practice is when creating your skeletons not to use inline twist bones and instead you should parent the wrist bone to them and"},{"start":"1:04","end":"1:41","startSec":64.0,"text":"then creating a leaf bone. So typically this is used with organic skeletons, but it's useful to keep in mind there. And then also when talking about hierarchy, especially when we're talking about automotive, it is really, really important. So always start with that root bone, usually at the center of gravity, wherever that might be on the automotive vehicle, for example, even if your model's pivot was built around zero zero zero, you want to extend from the root outward. So super important to keep in mind when talking about hierarchies and bones."},{"start":"1:41","end":"2:15","startSec":101.4,"text":"When we look at a pre-made animation pipeline, you're looking at the model, the rig and the animations inside of your DCC app, and then you import your animations into UE5. So we may end up with the sequencer animation tracks. These are from baked animation assets. They're all blended, weighted, maybe additive animations. And then you can modify the animations either using the sub editor, which is our old method, or edit in sequence option, which you can edit with the FK control rig or baked to control rig."},{"start":"2:15","end":"2:47","startSec":135.9,"text":"That just gives you a little bit more freedom and flexibility over your approach there. The in-editor animation pipeline. So you model and weigh in your DCC app. So then whenever it comes to rigging and animating, you would actually use Unreal Engine 5 for this. So you can use a control rig and you can build out all your animation controls here. And it's turned on by default in Unreal Engine 5. So if you're using any of the early access versions, just make sure you're in enable control rig. But from this point onwards, it will be on by default now."},{"start":"2:47","end":"3:18","startSec":167.1,"text":"So you shouldn't need to do anything to get access to control rig. The sequence of key framing. Control rig is animated using the level sequence. And then you build an empty level as a work area or you can animate directly in the scene. So we'll talk about sequence in a little bit more detail in a few slides here to give you a better idea about what sequence there is. When it gets to the mayor export, we can select the items we want to export inside of mayor. So your mesh and your joint chain root. And we can export selected."},{"start":"3:18","end":"3:49","startSec":198.3,"text":"So just file export selected and select the FBX type. Set the file type, sorry, to FBX. And you want to make sure the animation checkbox is there. You want to include smooth and deforms. Do you want to bake the animation? So using Alembic to bake complex deformation, beyond blend shape and linear skinning. So just a quick note here that a smooth mesh should be disabled and the smoothing groups should be enabled. So there's an image there of the type of properties you want to be setting just to give you an idea."},{"start":"3:49","end":"4:19","startSec":229.2,"text":"When it comes to 3ds Max, it's pretty much the same. The Max and Mayor exporters have very few differences. So we've included an image anyway. But they're relatively on parity there. And then Blender, we send it to the UE plugin. So Epix created a plugin that allows you to export an FBX, which doesn't even include meshes, but you can also export your rigs there. And Epix playlist goes over installing and using the plugin, which will save you a lot of time in your setup."},{"start":"4:19","end":"4:53","startSec":259.7,"text":"So to export your FBXs in Blender, you want to go to export and then FBX. You want to make sure the fixed transform tickbox is applied there. And armature, you want to disable add leaf bones. The smoothing groups don't exist. So auto smooth and split, apply modifiers, and then just make sure you uncheck the baked animation. And so you should be OK to go on the Blender from there. So in Blender, forward is minus y. So in Unreal, forward is actually positive x."},{"start":"4:53","end":"5:23","startSec":293.2,"text":"So you just want to make sure that your exports are set up in the right orientation here. When you export the FBX, you want the default settings for the majority of this. But also Shade and Auto Smooth for smoothing groups is selected there. And you want to keep the scene model scale in mind. So Blender defaults to a one meter per unit scale, whereas UE5 is one centimeter per unit. So you just want to make sure. So you're not trying to do any override scaling inside of Unreal."},{"start":"5:23","end":"5:42","startSec":323.2,"text":"You just want to make sure the units are set up correctly inside of Blender. When we're exporting to Unreal, you need to provide the project's export settings only once. And it's not necessary to set the project again for subsequent export operations. So enjoy exporting all your FBX animations. And we'll move on to the next section."}],"05_Further uses of FBX":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"So we've spoken a little bit about getting the content into Unreal Engine, how about when we want to export from Unreal Engine. So we can still use the FBX version, we can keep or remove the mesh and the information that we're looking at here is vertex color, LODs, collision and animation mesh. So first time importing, you want to click the import inside the content browser, you"},{"start":"0:30","end":"1:02","startSec":30.1,"text":"can either do this through the content browser or you can go to file import and you want to select the FBX option. The first time you import a whole new character, you'll need to import the mesh and the skeleton together. So every subsequent import doesn't need the skeleton because Unreal will already have that information but just make sure you do those together on the first import and skeleton mesh needs to be checked and import mesh needs to be checked too. So there's an image there of what we mean but just make sure skeleton mesh and import"},{"start":"1:02","end":"1:37","startSec":63.0,"text":"mesh are both ticked on your import FBX options here. So when we're importing animations, you can set the animation length, so the exported time, do you want the whole thing, do you want the animated time or do you just want to leave the animated parts here. Are you setting your range so you can manually select the frames that you want to import here. You've got the sample rate and also import bone tracks. So you've got a lot of options at your disposal here. A helpful important note would be the transform so you can compensate for any incorrect rotations."},{"start":"1:37","end":"2:08","startSec":97.5,"text":"So again, like we said before, you really should be fixing this in your DCC app to make sure everything is one to one with Unreal Engine in your external package before you import. We can override transforms here for example but it'll just lead to headaches later on if you need to reimport anything and you forget that you've set certain issues and also just any scaling issues. Just make sure ideally importing at a uniform scale of one is just the best default here."},{"start":"2:08","end":"2:39","startSec":128.8,"text":"Some miscellaneous options to talk about here, you could force front X axis just to make sure that, say for example if you're using Blender and setting the X axis there, you could tick that and you can convert the scene unit as well. So when we're importing new animations for old skeletons, you would just go ahead and import like normal. You can select the skeleton you want and choose the animation length but just know if the"},{"start":"2:39","end":"3:12","startSec":159.1,"text":"skeleton is exactly the same then this should be a very straightforward process. If not, you may have to retarget it using the new retargeting tools which we briefly went over before. If you want to reimport an animation, you can just right click in the menu and reimport the editor for more options. So you'll see different dialog boxes here that you can use to reimport and you'll get your import settings and just reimport using these settings and that should allow you for"},{"start":"3:12","end":"3:42","startSec":192.2,"text":"some quick reimport from the base mesh there. So we've got the skeleton mesh editor on the left details panel. You can right click on the asset in the content browser and the skeleton mesh editor in the top menu there. If you are using animations from the library, so from the marketplace maybe, you can add these to the project directly. So you can just click add to project on any animation packs that you have or you can just"},{"start":"3:42","end":"4:14","startSec":222.5,"text":"migrate the specific animations. If you already had that project open and you want to bring them over to another project, sorry, you can right click on the content, you can go to asset actions and migrate and you can migrate these animations over to a different project and they'll bring the information with them or you can just add them fresh to a new project. So you're probably more likely than not to find yourself needing to be retargeting these animations and it likely comes with its own skeleton in that instance, but it is possible and very straightforward process to do."}],"06_Skeletal Mesh Editors- Skinned Animated Mesh Pipeline":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Next up, let's talk a little bit about the Skeletal Mesh Editor, and talking specifically about Skinned Animated Mesh Pipeline. So the editor overview, you'll see some new icons, especially if you're familiar with Unreal Engine 4 or previous versions. We got some new icons of how to toggle between each section here. And when we jump into a workshop demo in a second, you'll see each of these being used."},{"start":"0:31","end":"1:03","startSec":31.1,"text":"So the first one, we've got the Skeleton, then we've got the Mesh next to it. We've got Animations, Animation Blueprint, which we'll touch upon at the end, and then also the Physics. So it's very easy to cycle through each of the editor windows from directly inside the editor, which is a really nice feature of Unreal Engine 5. When we talk about the Skeletal Mesh Editor, all editors can be accessed with these editor windows. So in reference to the previous slide that we were just talking about, if you look at the top right-hand side of the screen here, you can see the Skeletal Mesh Editor and"},{"start":"1:03","end":"1:35","startSec":64.0,"text":"the Skeleton, and also the Blueprint and the Physics. So we can directly hop into each one of these editors from those icons on the top right there. So really, really nice. And the one that we're looking at right here is the Mesh Editor. So we have a lot of settings pertaining to the mesh. We got all the materials listed on the right-hand side, for example. You can set your LODs from here, Morph Targets, and it can all be accessed from this one central space. When we're talking about the Skeleton Editor, in this window, you can see that the actual"},{"start":"1:35","end":"2:05","startSec":95.3,"text":"Skeleton has all the bone names. So in the bottom left-hand side here, we've got the bone names starting from the root. You know, when we're talking about that hierarchy, before we see the hierarchy playing a part and showing where each of the bones are and what they're doing. So you can also add sockets, which we'll be doing in a second. You can add virtual bones, change the preview mesh. We can even preview animations in this window as well, which is a really nice feature. So you can create different asset types and also manage the animation notify."},{"start":"2:05","end":"2:37","startSec":125.9,"text":"So an animation notify might be a certain car tire sound when it hits a certain animation or something like this, and we can fire all the notifies and especially preview those animations directly from this window. So when creating a new asset, we have a few different options available to us. We can create an animation asset, a new pose. We can even record animations directly inside of Unreal, which is a really nice feature. So say you're driving this car around and it's a movable vehicle, you can actually"},{"start":"2:37","end":"3:03","startSec":157.5,"text":"record that session and have it as an animation, which is a really, really powerful feature. We can access our animation blueprint as mentioned before, and we can also do composite and montages as well as the blend spaces and aim offsets. So these are also available through the mesh editor, just as a quick note. But yeah, whole host of tools here that are useful to kind of directly dive into from this window."}],"07_Workshop- Create a Socket":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"So with all that in mind, let's jump into Unreal and start creating a socket in one of our skeletal meshes. So sockets is essentially just a point attached to a bone. And the great thing about sockets is they then move with that bone so you can attach different components maybe at runtime. You can add essentially any extra mesh to that bone and it has multiple purposes."},{"start":"0:30","end":"1:04","startSec":30.5,"text":"So if you think about this car example, it's great for designing an attached location such as a door handle or a mirror or something essentially that wasn't part of the rig that came into Unreal. So let's go ahead and create a new socket just to show you what that process would be like. So I've just got a car here and I'll hit CTRL and B in my content browser to find that skeletal mesh in the browser. So if I can open up the individual asset but just to show you going through the skeletal"},{"start":"1:04","end":"1:36","startSec":64.5,"text":"mesh window which we were speaking about in the PowerPoint, if I went over to the skeleton, I can see all of my bones here. So again, I could have gone if I just drag and drop these windows just so you can see my browser, I could have gone through the skeleton here. But if you're going through this skeletal mesh and you're not sure where the skeleton is located, that's how to get there. So I went through the mesh and then clicked on skeleton which opened this window."},{"start":"1:36","end":"2:09","startSec":96.6,"text":"So you can essentially add a socket anywhere. If you say, let's go for the hood maybe. So over on the hood, say for example, we were attaching a windscreen wiper. So this windscreen wiper isn't there by default. Maybe we want to attach a windscreen wiper to the hood. So we can just right click and add a socket. And then it creates a socket name based on the bone name. And so hood underscore body socket, that's a nice enough naming convention."},{"start":"2:09","end":"2:42","startSec":129.3,"text":"I'm happy with that. I don't need to rename it. Now with the socket, the good thing about the socket in Unreal is that if I press space bar and then space bar again, I'm just toggling through my widget here. I can actually move this into a different location than what the bone would be. So if I wanted this socket in a different location, for example, that's an easy way to do that. And so it's like offset from the bone which is here. And that will move. So say this bone was animated on the windscreen wiper, whatever the relative offset of this"},{"start":"2:42","end":"3:15","startSec":162.0,"text":"socket was, that would follow the bone's orientation as well. And just a little tip when you get into blueprints, if you are attaching a mesh to a socket or something like this, you'd need to get the socket name. So a lot of the time you could misspell the socket and the socket name needs to be specific inside a blueprint. So you can either hit F2 or you can right click and rename socket. And when that box opens, I just hit control C. And then when you're inside a blueprint,"},{"start":"3:15","end":"3:32","startSec":195.8,"text":"you can just hit control V. That's copy and paste on the keyboard. And that will essentially just paste in the socket name. I like to do that just to make sure I know that the naming convention is all correct and working. That's essentially how to add a socket to a skeleton in Unreal."}],"08_Sockets Explained":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"So, what do we just do in this workshop? Well, we create a new socket and we attached it to a bone and the great thing about that socket is that it will then move with the bone as we spoke about in the workshop there. We can attach extra meshes, so it has multiple other purposes rather than just what we used it for, but it's really good for designing an attached location for your items such as door handles or mirrors or anything you may want to attach to a certain bone either at"},{"start":"0:32","end":"0:35","startSec":32.5,"text":"run time or to preview a certain functionality."}],"09_Animation Editor":[{"start":"0:00","end":"0:37","startSec":0.0,"text":"Getting into a bit more detail now with the animation editor. So we have the overall user interface here with the animations. We're talking about key frames so you can add additive animations and also curves to this interface. So you see the list of animations on the bottom right hand side there of all the animations that you currently have. You can add notifications. So a classic example of this with animation notifies would be if you have a standard walk"},{"start":"0:37","end":"1:09","startSec":37.2,"text":"animation and every time the foot hits the ground you want to notify Unreal to maybe play a sound or something like this. So you could add a notify of every time the foot plants on the ground to then send a message into Unreal somewhere. You can also record animations in this editor window as well. So the animation editor with the asset browser. So on the bottom right hand side, you have all your assets. You can pop this out into its own window if you wanted to."},{"start":"1:09","end":"1:42","startSec":69.8,"text":"You can just drag and drop the windows however you want to layout the information. But you can browse all the animations that you currently want to use and preview them there inside the animation editor with the use of the asset browser. So useful to kind of preview your animations that you've got here. If you are editing the animation in Sequencer, you can edit with Control Rig here. So you just want to use that drop down option and use edit with FK Control Rig and then you'll get a baked to Control Rig pop up notification."},{"start":"1:42","end":"2:15","startSec":102.8,"text":"So you can edit your animations via the edit in Sequencer option in this instance. When we're talking about Sequencer, Sequencer is a really powerful cinematic tool that comes with Unreal Engine. So we can create videos and cinematics and we can essentially play at runtime if we want to maybe play it during a game cinematic sequence or something that's in engine that plays at real time or render them as a video file in multiple different formats if you want something"},{"start":"2:15","end":"2:48","startSec":135.7,"text":"pre-rendered. We can create gameplay animations so we can bake out animation using Sequencer using that take recorder that we were referencing before. So if you set up a series of animations and you maybe add a walk cycle to some kind of blend into a jump and then jog or something like this and they're all their individual animations, you can actually play that out and bake it into its own animation which is a really powerful tool. We can also trigger events directly from Sequencer. So if you want a certain event to trigger as the character gets to the middle of their"},{"start":"2:48","end":"3:17","startSec":168.5,"text":"walk cycle for example or something like this, it will send out an event into Blueprints and you'll be able to call different events directly from Sequencer. Sequencer also comes with its own curve editor. So if you want to refine any of the movement, any camera pans, anything like this, it comes with its own curve editor which you can see as the icon on that main nav bar right in the middle, the furthest icon on the right hand side but it's in the middle of that window. That's your curve editor."}],"10_Workshop- Adding Animations to Sequencer":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"The easiest way to explain how animations work inside a sequencer is we'll just add an animation track inside using the mannequin that we were referencing before. If you don't know where that is, you can follow this hierarchy down here. You can also filter out skeletal meshes. So if you click this button and click skeletal mesh, it'll give you all the skeletal meshes that are available inside the content folder, which are this series of skeletal meshes here."},{"start":"0:33","end":"1:06","startSec":33.6,"text":"So let's first of all create a level sequence. So you can do this a couple of different ways. In my content folder, I'm going to right click, New Folder, and just call this SEQ for Sequencer. I'm going to untick, make sure if you tick the skeletal mesh filter, make sure you untick that, otherwise you won't be able to see any sequencer files. I'm going to right click, Animation, and then go to Level Sequence. So right click in this grey box, Animation and Level Sequence."},{"start":"1:06","end":"1:38","startSec":66.2,"text":"I'm just going to call this SEQ underscore Manny Walk. Manny is the name of the skeletal mesh that we have. You can also create sequences through this button at the top for quick access. I just like to create them through the content browser so I know exactly where they're being saved and stored. And then I'm just going to double click the sequencer. So the first thing I'm going to do is I'm going to pin it to my tab up here. Don't worry if you don't have this Merge Axis window, I'm going to close that."},{"start":"1:38","end":"2:08","startSec":98.0,"text":"It's up to you what windows you have open and the kind of organisation of your workspace here. And so we've got a sequencer. We've not got any information in the sequencer. So the first thing I want to do now is back into my content browser. I want to make sure the content is selected, skeletal mesh and I will find my mannequin character. I will drag my mannequin into position here. I will use spacebar to toggle through the different widgets to manipulate the mannequin into place."},{"start":"2:08","end":"2:43","startSec":128.8,"text":"So just by tapping spacebar we go through location, rotation and scale. I've got the mannequin roughly into position here. I'll go back into my sequencer window and I will, with my mannequin selected, I will right click, Active to Sequence, Add SK Mannequin. So if I deselect mannequin, deselects the mannequin in the editor. If I select mannequin, it selects the mannequin in the editor. So we've got a one to one relationship with the mannequin. So just make sure you have that. If not, make sure you add that track again by selecting the mannequin, right click, Active"},{"start":"2:43","end":"3:14","startSec":163.2,"text":"to Sequence and add the mannequin there. So the first thing we'll do is we'll add a transform here. So we'll add a new key under the transform. So just select this little circle option here on 000. I'm going to drag along this dark bar along the top. I'm going to drag right to the end and I'll put my timeline around 148 units. I'll use my mouse to navigate the scene. So again, right mouse button pans around, left mouse button to back and forwards, both"},{"start":"3:14","end":"3:45","startSec":194.0,"text":"mouse buttons to move around. So somewhere around this end point, I'm going to move the mannequin into position. I'll drag them up here and I will add another key here. Now if I press this button to front here and I press play, the mannequin will move over the duration over that amount of units. So make sure that you don't need to delete this key but I'm just going to click the"},{"start":"3:45","end":"4:20","startSec":225.9,"text":"key and press delete on my keyboard. Make sure you don't have this first key selected, then move the mannequin and then try and set the key later down the timeline because the mannequin will snap back to the original position. So you need to make sure you go to the time that you want, move then the actor that you want to bind the key to and then add the key. And then if I press rewind here to front and then press play, we got that movement."},{"start":"4:20","end":"4:58","startSec":260.1,"text":"Now you can just add whatever kind of additional movement you want. Maybe I'm going to, around this point, I'm going to drag the mannequin up a little bit in a perfect, very precise manner. Not really. I will maybe go here, maybe at this key here. Oh classic example of me not moving the mannequin correctly. There we go, add key and then maybe, maybe I'll rotate this just to see that and there"},{"start":"4:58","end":"5:28","startSec":298.0,"text":"we go. A very imprecise, precise movement of mannequin going up the little ramp here. So we've got some basic movement but the mannequin's not got any animation. So let's go ahead and add some animation now. So I'm just going to, again, to front button here. I'm going to go to the animation tab and you might see a series of animations here, especially if you've got multiple animations for the mannequin. You might see walks and idols and different things like that."},{"start":"5:28","end":"6:01","startSec":328.1,"text":"I just have a jog available to me in this project. So I'm just going to select the jog animation and you'll see that first of all the mannequin has a little jog animation. So we'll do that and what I can also do is because it runs out of space around frame 60, I can actually just drag this animation along here and it will continue to loop straight through the duration of this. Now because the mannequin is running, it's feeling a bit slow so you may just want to"},{"start":"6:01","end":"6:33","startSec":361.5,"text":"end up bringing all these keys in anyway. You may just want to do something like this and this and this and this and you may just think that it looks way better like this just because it gives it more speed. But completely up to you how you do your animations. The other thing to note here is if you want to do a walk into an idol for example, I could add another animation here. So like on frame 60, I could go to animation and jog forward and I have these two jogs."},{"start":"6:33","end":"7:04","startSec":393.8,"text":"I can actually just drag and drop this forward run over the previous one and you'll see some blending behavior going on here. So especially if I had a walk animation into an idol animation, I could blend from the walk into the idol over a series of frames, you know, however long you want that duration, that crossfade to be and that would actually blend the animations quite nicely. So there's quite a lot of tools just for a few button presses inside a sequence that you can get access to."},{"start":"7:04","end":"7:37","startSec":424.6,"text":"We've just discussed the transform and animation track and just with those two alone, you can create some quite complex animation sequences and you can even then like we said, render them out to the take recorder if you so wished. So what did we cover there? So we added a track for a skeletal mesh. We added some keyframes in the timeline and we chose the time that we wanted to make these changes. And in this example here, we've got an idol into a walk and then back into an idol just with a few keyframes down. And so it's completely up to you then the approach that you take when creating these"},{"start":"7:37","end":"8:00","startSec":457.6,"text":"sequences. So when you finish with your sequence, you can create a linked animation sequence if you want. You can bake out the animation as we said before, you can just bake this to its own animation sequence now. You can export your animations in the FBX if you want to use those somewhere outside of Unreal. And you can also edit with the FK control rig just to get some more fine tuning going on if you wanted to."}],"11_Animation Blueprint Overview":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"As we start to wrap up this course, I wanted to give you an overview of the animation blueprint functionality and also a quick pro tip as well for anyone using vehicles inside of Unreal. So a really good pro tip is the rotation of tires, which we see requested quite a lot. So we're not going to dig into how to create this example, but I just wanted to provide an example tire rotation control rig setup because this will likely be very useful in"},{"start":"0:33","end":"1:04","startSec":33.0,"text":"your project. You can dig apart, pick apart the different nodes and kind of recreate this setup. But I just wanted to provide an example image in case that was useful to you. And then when we're talking about the animation blueprint overview, we essentially have the two different graphs. So we have the event graph for logic. The event graph will house a lot of the blueprint control and any kind of specific input content. And then also the animation graph will be for the control and the flow of information."},{"start":"1:04","end":"1:37","startSec":64.9,"text":"So you may end up with kind of state machine functionality for the flow of information there. When we talk about the event graph, it's essentially a very similar to a blueprint event graph. You have variables in here. So you may have the car movement speed variable, for example. So the event graph will control variables and logic. You know, if you're wanting to drive this vehicle around, you'd have a lot of the logic there in the event graph. So then we actually get this information and we send it through to the animation graph."},{"start":"1:37","end":"1:47","startSec":97.1,"text":"And so if you want any additional resources on the specific functionalities, it's definitely worth checking out the documentation page on that for some additional resources there."}],"12_Outro":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"So, I really hope this was a useful introduction to Unreal Engine animation states and controlling animation inside of Unreal Engine and just the different opportunities you have, whether you want to author animations outside of Unreal Engine and bring them in via the FBX importer. Do you want to do a lot of the animation driven sequences inside of Unreal and really get the most out of working in real time within your scenes and using the different tools"},{"start":"0:31","end":"0:56","startSec":31.6,"text":"such as Control Rig to then manipulate the content to create the best output. Or maybe you want a blend of the two and hopefully there's a lot of tools here for you to just play around with, especially loading up the sequences and the blueprints just to get a feel for how you interface the information and how the flow of information works. So, I hope you found this useful and thank you for watching."}]},"108.01":{"01_IntrotoControlRig":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Welcome to another Unreal Engine training course. Today we're going to be looking at an introduction to Control Rig. So we'll take a look at how rigging works in Unreal, and what the concept of a Control Rig is and so how they work. And then we'll create our own Control Rig, going over how to create controls and set their transforms, and then set up the logic to make them drive your skeleton with a simple FK setup, and then get a little more complex with a simple IK setup. And then we'll see how to set up an aim control."},{"start":"0:31","end":"1:04","startSec":31.0,"text":"So there are a lot of different benefits for this, which allow you to easily control what something is pointing at, like somebody's head or a turret of a gun, for example. And lastly, we'll take our Control Rig into Sequencer and see how you can animate with it directly in the engine. So let's start off with what Control Rig is and what it can do. So Control Rig is a sort of umbrella term for a suite of tools that you can use to rig and animate your characters in engine. There's a lot of familiar functionality with the way that Control Rigs are set up"},{"start":"1:04","end":"1:34","startSec":64.5,"text":"and how they function when you compare it to external rigging softwares. And it's super user-friendly with visual scripting, like you'd use in a traditional blueprint, with nodes and functions to easily connect your controls to your bones for animating. And it has some great functionality, like procedural rigging or modular rigging, where you can create controls and hierarchies automatically, based on various tags and metadata that you can set up, or even create template rigs that work across several different characters in your project."},{"start":"1:34","end":"2:05","startSec":94.5,"text":"And the best part is you don't need to know how to write any code to set up advanced rigs, but you can use the Python editor to write tools or code directly in the engine, and that'll help automate some of your workflow. Now, if we jump inside the engine here, this is the Control Rig Editor with an example of a Control Rig that's been created for our mannequin character. And to give you an overview of the editor here, in the center we have the Rig Graph, which is similar to all of Unreal Engine's editors,"},{"start":"2:05","end":"2:37","startSec":125.0,"text":"where you'd set up your visual scripting and all of your logic that would connect your controls and your bones together. On the right-hand side we have the Details panel, and this contains all of the information about the element that you currently have selected. So if I was to select a control from the viewport here, we can see what type of control it is, and some of the transform values on that control. Coming down to the bottom left-hand side, we have a few different Rig menus. So this first one is the Rig Hierarchy, and this shows us the hierarchy of our Rig that's been created,"},{"start":"2:37","end":"3:08","startSec":157.5,"text":"as well as the hierarchy of the skeleton that the Rig is connected to. The next is the Execution Stack, and this will give you a preview of the order of operation for the Control Rig logic. Now this can really help with debugging your logic and seeing the sequence of events that are triggering. And next we have the My Blueprint tab, and this is similar to the panel you'll find in a regular blueprint, where you can see your various functions and variables that you've created. Now the slight difference is that the variables in here are meant to be used within your Rig Graph"},{"start":"3:08","end":"3:39","startSec":188.0,"text":"as a way to drive logic, rather than being exposed when you have the asset in a level. And if I zoom out of the Rig Graph here, you can see that the logic is split up into a few different branches. And that's because there are a few different types of solve directions. So control rigs are evaluated in several ways called solve directions, and these allow you to split the logic into different streams or solvers, which enable workflows such as rig sharing or baking your animation from your bones to your controls,"},{"start":"3:39","end":"4:09","startSec":219.5,"text":"and even debugging the behavior inside your Rig logic. So there are three solve directions we can look at. Up the top here we have Forward Solve. Now this is the primary solve direction for the control rig, where you would set up the traditional rigging logic of having your controls drive your bones, and then allow you to key the controls and animate your characters. So next would be Backward Solve. Now this is the inverse of Forward Solve, where you would have the bones drive the controls,"},{"start":"4:09","end":"4:40","startSec":249.5,"text":"and this is intended to be used to bake skeletal animation back to the control rigging sequencer, so that you could then easily make edits to the animation if you wanted to. And the last we'll look at is Construction Event. Now the Construction Event executes at the top of the stack, and this is used to execute preparation logic, so you could use it to initialize data like variables or spawn controls and set their initial positions, so you can use those within the other two solve directions."},{"start":"4:40","end":"5:12","startSec":280.5,"text":"Now that we've gone over some of the basics of what control rig is, let's create our own. So we'll create a new control rig, and we'll learn a couple of different methods of how to create new controls, depending on the circumstances, and then set up the logic to connect those directly to the bones, giving us control over the character with a simple FK setup. So inside the engine here, what we're going to do is create a new control rig for our Quinn character. So to do that, we can do that one of two different ways."},{"start":"5:12","end":"5:46","startSec":312.0,"text":"We could right click, come up to Create, and choose Control Rig, and what this will do is give us a control rig that's paired to the Quinn character skeletal mesh. Now the second way that you could create a control rig is by right clicking in an empty space in the content browser, coming up to Animation, and then down to Control Rig, and you could create a new control rig here. This will give you another option, whether or not you want a standard control rig or a modular control rig, that you could reuse with different characters. But if we just choose Control Rig here to create a standard one, it will ask you to name it,"},{"start":"5:46","end":"6:17","startSec":346.5,"text":"so I'll just rename it CRDemo for now. Now the differences between these two is that our CRDemo control rig we just made isn't paired or connected to any other character, and what we'd have to do is come inside here, set our preview mesh, and import our hierarchy for that to be connected. Something that you might have noticed when we right clicked in the content browser and came down to the Control Rig options is the Control Shape Library."},{"start":"6:17","end":"6:48","startSec":377.5,"text":"Now this contains all of the Control Shape assets, where there are many different shapes available by default, but you could use this to import and build your own library of shapes if you need something more custom or visually different for your rig. We're going to look at two different methods we can use to create a new control. With this first method, we'll create a control that doesn't have a relationship to any bones in the skeleton, and then see how to reposition it and customize the look of it."},{"start":"6:48","end":"7:24","startSec":408.5,"text":"So if we come to our Rig hierarchy window here and scroll down to the bottom until we find an empty space, I'll right click, come up to New, and select New Control. Now what this will do is create a new control outside of the skeleton hierarchy, and it'll position it at World Zero. Now typically with new controls, especially with an FK setup, you want their initial position to be in the location of the bone that you're trying to control. So we could come into the window here, the Preview window, and reposition this up to the elbow, for example."},{"start":"7:24","end":"7:54","startSec":444.5,"text":"And we can actually get our control close to this bone and use a tool to snap it to its location. So if we come to Character and just show bones so we can see the elbow joint here, and we'll right click the control inside the Rig hierarchy window, we have an option to set offset transform from closest bone. And what this will do is snap its position and its orientation to the closest bone in the viewport."},{"start":"7:54","end":"8:27","startSec":474.5,"text":"And we can see that that's now positioned and oriented to the elbow joint. So when we set up the logic, we know that they both have the same initial start points. Now we can customize the look of these controls. So if you select the control in the viewport or in the Rig hierarchy and come to the Details panel here, under Shape we have Shape Properties. Now this might be closed by default, but if we just pop it open. And under the Shape dropdown, we have the default shape mesh here."},{"start":"8:27","end":"8:59","startSec":507.5,"text":"And so there are lots of different shapes here and you can just choose whatever's appropriate. Now if we go for something like a circle thick here, we can see that it's still slightly inside the mesh, so what we could do is reposition the rotation of the shape. And if we reposition it along a Y axis like this, I think that's going to give us a result that we want to encompass the elbow."},{"start":"9:00","end":"9:36","startSec":540.5,"text":"So I'll just put 90 degrees inside the shape transforms. And I'll actually scale it up just to make it a little bigger. And now this is much easier to select and it's not stuck inside our mesh. We can also change the color of the shape here. And as you can see as we scrub through the various colors, it updates live in the viewport, and you can also see the icon for the control down here changes color to match."},{"start":"9:36","end":"9:45","startSec":576.5,"text":"So I'm just going to make it green for now. And that's it, we've made our first control."}],"02_IntrotoControlRig":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Now, typically with FK setups, as I was saying, you want the control's initial start point to be in the same place as the bone that you're trying to control. So what we can do here is we could select the other elbow, for example. We can right-click that bone, come up to New, and create a new control in the same way that we did before, except this time, that will automatically position and orient the control to match that of the bone that you had selected."},{"start":"0:32","end":"1:03","startSec":32.7,"text":"Something that it also does is names the control the same as your bone and adds underscore CTRL at the end. And this is just a great way of keeping your controls and your bone names separate so that when you're using your rigging logic, things are a bit more straightforward. In previous versions of the engine, this control would have been created as a child of the bone that we had selected, and we'd recommend that you select the control and press Shift P to remove it from the hierarchy, because it's best practice for the rig controls to"},{"start":"1:03","end":"1:37","startSec":63.3,"text":"be in their own hierarchy rather than a skeleton's hierarchy. And we can do the same thing with this. We could change the shape, so we could go for another circle, and we could reposition the shapes transformed the same way again. So if we went 90 degrees on the Y axis, and increase the scale to 2, just so it's a little easier to select. So it's really as easy as that to start creating your controls. Now what we'll start to do is build the logic for our FK controls."},{"start":"1:37","end":"2:10","startSec":97.3,"text":"So we'll create a root control that will be at the head of the hierarchy, and then we'll create a control for the spine and set up a simple hierarchy for our rig. So if I delete these two controls here, what I'll do is come up to the top, select our root and our spine, and if I right click the two of these together, come up to New Control, what that will do is create the two controls for us and put them down out of the hierarchy down here. Now to child the spine underneath the root control so that when we move the root control,"},{"start":"2:10","end":"2:42","startSec":130.6,"text":"the spine comes with it, what we'll do is drag the spine control on top of the root control, and you can see this child's under the root control, and you can see that based on the small arrow that we have here, and the line connected to it. Now if we change the look of our controls like we did before, with the root control, we can create something like an octagon, and maybe it'll be yellow, and we'll scale it up to something like 10."},{"start":"2:42","end":"3:15","startSec":162.4,"text":"Oh, we didn't keep that, so let's try that again. There we go. And with our spine control, this is stuck inside of our mesh at the moment, so what I'm going to do first is just scale it up until we can see it a little better, something like 3.5, and then we'll change the shape again to be a circle, and we can see again that it's slightly misoriented for how we'd like to use it."},{"start":"3:15","end":"3:47","startSec":195.7,"text":"So using the shape transform, what I'm going to do is rotate 90 degrees on Y again, and I'll even scale it up a little more, maybe 4 will be better. So as you can see, we have our two controls here now, and as I move the root control around, our spine control follows. Now let's set up the logic to connect our controls and our bones together. So what we'll do first is we will grab our control here, click and hold and drag it into"},{"start":"3:47","end":"4:21","startSec":227.9,"text":"the rig graph, and we'll choose get control. So this is going to get the transforming information about this control, and because we want the root control to control our root bone, I'll also grab the root bone and drag that in, and I'll choose set root bone, because we want to use the transforms of the control to set the transforms of the bone. And to connect these two together, we grab the transform output pin and plug that into the value input pin of the set transform bone node, and then we just connect the logic up."},{"start":"4:21","end":"4:52","startSec":261.9,"text":"I compile that and select our control. What we'll see is our control is now controlling our skeleton. Now if we set the same thing up with the spine control, currently that's doing nothing, that's not affecting skeleton in any way, but if we drag that into the rig graph and choose get control, and then we drag in our spine 01 bone and choose set bone, connect the transform"},{"start":"4:52","end":"5:24","startSec":292.4,"text":"to the value pin, connect up the execute logic, and when we hit compile, we'll see that this control is now controlling our spine. It really is that straightforward to get your controls driving your bones and moving your character, and now you could do this for all of the bones on your character, and pretty quickly you'd have an FK rig that you could use to animate with. But what if you wanted to get a bit more complex? Now it's very common for characters with arms and feet to have an IK setup, which is a super"},{"start":"5:24","end":"5:56","startSec":324.9,"text":"useful way of having the hands and feet drive the movement of the arms and legs, or even pinning the hands and feet in place. So let's do that next. Let's create an IK setup for the arm. So for this simple IK setup, we're going to use the basic IK node, and for this to work, it needs a few different bits of information. So if I right click inside our rig graph here, and search for basic IK, I can spell it right, basic IK, this is the node that we're going to use."},{"start":"5:56","end":"6:28","startSec":356.9,"text":"Now we need to tell this which bones we want to affect, so we're going to set this up on one of the arms. We need to give it the effect information, which is essentially the wrist control or the hand control that we're going to use to control the entire IK system. And then we need to give it a pole vector, and this just allows us to control where the elbow is going to point. So first of all, let's create all the pieces that we're going to need to make this work. So let's create our wrist control or hand control first."},{"start":"6:28","end":"7:04","startSec":388.1,"text":"So inside the rig hierarchy here, I'm just going to search for hand, and we'll set it up on the right hand side. So with hand are selected, I'm going to right click and create new control like we did before. And I'm going to drag that inside our root control, so that wherever we move the root control, all of the rest of the controls for the body will follow. I'm also going to change the look of our wrist control or our hand control."},{"start":"7:04","end":"7:34","startSec":424.0,"text":"Let's come down here, make it a circle again. If I just press F to zoom in, we can see that we need to rotate along the Y axis again. And I'll do the same thing where I scale this up slightly. Let's go to 1.5 maybe. So compiling that, we now have our new control in the correct position where the hand is. Our next control we need to make is a pole vector."},{"start":"7:34","end":"8:05","startSec":455.0,"text":"Now we need to make this at the position of the elbow because the elbow is what we're going to be wanting to control. So for us, that's our lower arm. And make sure that we're choosing the right one here. If I press control N, that's the shortcut to create a new control. And then I'll do the same thing and bring that inside our root control. And we can see that we are aligned with the elbow."},{"start":"8:05","end":"8:40","startSec":485.5,"text":"But I want to bring this out a little bit. And I'm going to move this along the Y axis only because that's the axis of the bone that we want to point towards the pole vector control, meaning we're maintaining the plane that the bone is on. So if I just bring it out to here somewhere that's nice and accessible, I'll then right click and set our offset transform from current. If I wasn't to do that and I was to compile our control rig, you see it snaps back to where it originally spawned. So if I pull that out again, right click, set offset transform from current."},{"start":"8:40","end":"9:12","startSec":520.7,"text":"Now when I compile, you see that that's this control's new initial location. Now we have all the controls that we need. Let's start setting up the basic IK. So let's tell our basic IK node what bones we want to control. Now this is going to be our upper arm bone, our lower arm bone, and our hand bone. So in item A here, which will be the start of our chain, we want to put our upper arm bone. And we can just put that in by searching for the name of the bone."},{"start":"9:12","end":"9:46","startSec":552.8,"text":"Or what we could actually do is select the bone in the outliner here and the rikai raki and use this arrow to use the name of what we have selected. So if we choose our lower arm, if I search for it, lower arm R, I could just hit the arrow there and then our hand R is going to be our effector or the end of our chain. Now that we know what bones we're affecting, let's tell the system what controls we're"},{"start":"9:46","end":"10:17","startSec":586.8,"text":"using. So if I clear out our search there, come down to the bottom. We have our hand control and our lower arm control. I'm just going to right click and rename this to be our pole vector control. So I'll put PVR control. Now with both of these, I'll drag the two in and I'll choose get control so that we can get the transforms and the information of these two controls."},{"start":"10:17","end":"10:51","startSec":617.9,"text":"Now we can see the hand control that I have here. We're going to be using that as our effector control, which means it'll be directly driving the effector at the end of the IK chain or our hand bone. So if we connect the transforms directly up to the effector there, the last thing we need to connect up is the pole vector control. Now the pole vector is based on translation or position data only. So if we open the transform tab here, grab our translation information from the pole"},{"start":"10:51","end":"11:21","startSec":651.5,"text":"vector control and plug that into the pole vector pin here. That's all we need to connect up to get the IK working. So let's plug it into our execute chain here, connect the logic up. And we can see that something's definitely changed, but it does look a little bit broken. So it's sort of half working. We've got an IK chain where we can move the hand around and the upper arm and the lower"},{"start":"11:21","end":"11:57","startSec":681.5,"text":"arm respond to how that hand's moving. It just seems to be that perhaps the rotation of the elbow here isn't quite right in relation to the pole vector. Now that's for two potential reasons. It could be that our primary or secondary axis are slightly incorrect essentially. I'm going to just disconnect this to get us back to our default pose. And if I select our lower arm for our primary axis data, this is the axis that points along"},{"start":"11:57","end":"12:32","startSec":717.1,"text":"the bone. So if I zoom in here, you'll see that we have our local orientation axis that we can see here of each bone. Now if I just orient myself around here, you can see that this red line here indicates that the x-axis is pointing down the bone or in the direction of the bone. And it's actually the negative x-axis that is pointing down the direction of the bone from the elbow to the wrist. So under the primary axis here, although we are on the x-axis, we're currently set to"},{"start":"12:32","end":"13:03","startSec":752.1,"text":"positive. So I'm just going to flip that round to negative. And if I correct our logic up or connect our logic up, we can see that this looks different but we're still not quite correct. So under our secondary axis here, if I disconnect the logic again and select the upper arm again or the lower arm, sorry, we can see that this green line here indicates that the positive y-axis is pointing towards our pole vector control."},{"start":"13:03","end":"13:32","startSec":783.4,"text":"So if I was to flip that to the positive one instead of negative one and connect to our logic, we'll see that we now have a correctly working pole vector. So it's quite important to make sure you orient your joints in the correct way so that you know which axis is pointing down the bone and which axis will be your secondary axis pointing towards things like your pole vector."},{"start":"13:33","end":"13:59","startSec":813.5,"text":"But now if we see if I just hide the bones, come up to character, bones, and just choose selected only, which means any bone that we select would now be visible. And if I select the wrist control here, we can see that it's now controlling our whole arm and our pole vector control is controlling which direction the elbow is pointing."}],"03_IntrotoControlRig_55":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Once your rig becomes a bit more complex, you might find that you spend a bit of time customizing the look and the position of your controls, and you might want to consider how you can speed up some of that workflow so that you're not repeating the same steps every time you make a new control. Something that works really well here is initially setting up the controls for one-half of your body and then using the mirror function to copy and mirror all of the controls to the other side. Now, this will save you a lot of time when you're setting up your controls and it maintains how you've customized the look of the money copies them over."},{"start":"0:34","end":"1:07","startSec":34.0,"text":"So let's take a look at how to mirror some controls. We have a slightly more complex rig here where, as you can see, we've set up the controls on one-half of the body and for each of the controls, we have customized them in a different way. So they're a different color and they're a different shape. And we're going to mirror these over from the character's right-hand side to the left side. So to do that, if we select all of our controls by shift-selecting, right-click and then choose mirror. And this is going to ask you, what axis do you want to mirror the controls across?"},{"start":"1:07","end":"1:39","startSec":67.2,"text":"And if we look at our little gizmo down here, we want to mirror along the x-axis, so this is correct, and we want to flip along the z-axis, so we want to flip them 180 along that vertical axis. So the axis to flip is also correct. Now the search and replace options are to do with the naming of the controls. So currently, because this is the right side, within the control name, you can see we have underscore R underscore. I'm going to copy and replace with underscore L underscore."},{"start":"1:39","end":"2:11","startSec":99.1,"text":"So in search, we put underscore R underscore and replace underscore L underscore. When we hit OK, you can see that our controls are mirrored across from left to right. They look exactly the same, they're the same color and same shapes and any sort of positional updates we've made to the shapes transforms, you can see they've been updated as well. Now we need to make sure that our controls transforms are matching with their corresponding bones. And to test whether or not the controls are aligned with the bones transforms, there's"},{"start":"2:11","end":"2:43","startSec":131.5,"text":"a nice way to visualize this. So if I search for upper arm, for example, we know that this upper left-hand arm is the one that we've just created a new control for with the mirror function. And if we right-click and choose control bone transform, we can see with our manipulator handle here, our gizmo, that we've got the x-axis pointing down the bone, the y-forward and the z-sort of up to the right-hand side here."},{"start":"2:43","end":"3:16","startSec":163.1,"text":"Now if I select the control we just created, you can see that that's flipped slightly. So what you'll find is that the same thing has happened with each of these controls that we've created. So the position in space will be correct, but the orientation might be flipped. So we choose the lower arm, right-click, control bone transform, and then if I select the control, you'll see that this flips slightly. So what we need to do here is set out offset transforms from the closest bone, like we"},{"start":"3:16","end":"3:50","startSec":196.8,"text":"did with the controls in the other rig. But if we do that while all of the controls are in hierarchy, you'll find that things go a little bit wonky. So I'll just show you an example of this. If I select all of these controls here, I choose right-click and then set offset from closest bone, you'll see that the controls kind of jump around all over the place. And that's because the parent is having an effect on each of the children. So if I control Z to undo that, if I select each control and press Shift P, you could"},{"start":"3:50","end":"4:20","startSec":230.1,"text":"also select multiple controls together and press Shift P. That will bring them out of the hierarchy. We can then select all of our left side controls, if I zoom out a little bit here. Right-click, set offset transforms from closest bone, and you can see that the controls haven't moved their world position, but the orientations have updated to match the bones. So now if we just fix the hierarchy again, putting our arms and legs back together, if"},{"start":"4:20","end":"4:53","startSec":260.1,"text":"we were to select the upper arm, for example, right-click, control bone transform, we can see that it's still set up the same way that it was, so X pointing down the bone, Y forwards. And if we now select our upper arm, control, you'll see that set up exactly the same way, which means that when you set up your logic, everything should work correctly. Coming back to our basic IK setup here, what I've done is I've used the mirror function"},{"start":"4:53","end":"5:24","startSec":293.1,"text":"to duplicate and mirror our hand and our pole vector controls from the right-hand side to the left-hand side. Now I wanted to show you one more thing in relation to mirroring that's available on the basic IK node itself, and this might speed you up when you're setting up the rest of your rig logic. If we duplicate our node here, what you can do is right-click the node itself towards the top here and choose search and replace mirror. And this will give us the same sort of mirror options that we had when right-clicking in"},{"start":"5:24","end":"5:55","startSec":324.0,"text":"the rig hierarchy. So we want the same options again, we want to mirror along the X axis and then flip along the Z axis. This time we're searching and replacing the name of the bones that we have inside the node here. So we'll search for underscore R and we want to replace with underscore L. And when we hit OK, you'll see that these bone names update inside the node. And then we just need to create the same setup as we have with the other basic IK node."},{"start":"5:55","end":"6:31","startSec":355.2,"text":"So drag these two controls in and choose get control. Remember that our transform of our hand control is going to go into the effector pin and the translation of our pole vector node is going to plug into pole vector. And something we want to do as well because it's mirrored is change our primary axis from minus one to one and then also flip our secondary axis from one to minus one. And when we connect up the logic and hit compile, if I select our left hand control here, you'll"},{"start":"6:31","end":"7:02","startSec":391.7,"text":"see that we now have two IK hand controls working pretty quickly after just updating a few mirror search and replace options and copying over the right hand controls to the left hand side. The last thing we're going to look at is setting up some sort of aim control using the aim function. And this is a really handy tool if you want part of your skeletal mesh to always point towards something. So that could be creating a head look system for your character or maybe something like"},{"start":"7:02","end":"7:33","startSec":422.3,"text":"making the turret of a gun always point towards a target. So the aim function works a lot like the pole vector setup we had just a moment ago. Now we need to tell the function what bone we want to affect and give it a control as a target to aim at. And then make sure that we have our primary and secondary axes set up correctly. So if I come back to our rig graph here, right click and search for aim. This is the aim function that we're going to use."},{"start":"7:33","end":"8:06","startSec":453.9,"text":"Now we need to give our aim function something to target at. So I'm going to select our head bone, right click, new control. Put that inside the hierarchy of our root control. And the same as we did with the pole vector, I'm just going to drag this out along the y-axis. Right click and choose set offset transform from current."},{"start":"8:06","end":"8:37","startSec":486.5,"text":"So back to the aim node. The bone that we're trying to control is going to be the head. And our target, if I drag our head control in here, is going to be the position of our head control. So if we plug our translation pin in here to our target pin there, and then I'll connect up the logic. And you can see already we're aiming towards our control, but again we haven't quite got"},{"start":"8:37","end":"9:08","startSec":517.2,"text":"the primary and secondary axes correct. So if I select our head control, or our head bone should I say, and press F to zoom in on that. Just so we're not getting some misleading results here, I'm going to disconnect the logic to get it back to its default pose. And we can see that our y-axis is pointing in the positive direction. So that'll be our primary axis."},{"start":"9:08","end":"9:44","startSec":548.7,"text":"So underneath the axis tab here, we'll change x to zero and then y to one. And underneath the secondary axis tab here, we're currently set to Z. Now this is our up axis, or the axis that's pointing towards this bone's parent. So if we select the head here, and I just zoom in a bit, we can see that the pointing towards our parent is the negative x-axis. So if I put negative one inside here, and then zero in there, whoops not ten, zero."},{"start":"9:44","end":"10:18","startSec":585.0,"text":"And then reconnect up the logic. When we compile, you can see that the head is pointing in the right direction. And when we move the head control here, our head continues to point towards it. And this is super super useful for things like setting up a head control system like I mentioned earlier. Or even just animating your character's head to look left and right, and always aim towards something maybe as they're walking around. Now that we've seen how to create a simple FK setup and a simple IK setup, as well as"},{"start":"10:18","end":"10:49","startSec":618.2,"text":"using the aim function to give your character a target to always aim towards, let's go into sequencer and see how we can now animate with it. There are two ways we can get started with our animation. The first would be to grab our control rig here and drag it straight into the level. And what this will do is create a new level sequence for us, including our character and the rig that's connected to them. The second way we could do this is to add our character to a pre-existing sequence."},{"start":"10:49","end":"11:19","startSec":649.2,"text":"So if I come back to the content browser, we have a pre-existing sequence here called my level sequence. Double click that to open it. Come back to our content browser. I can grab our character mesh here and I can click and hold and drag it on top of the sequencer window here. That gives us a new character and also includes a control rig with the character. Now this isn't the control rig that we initially created."},{"start":"11:19","end":"11:50","startSec":679.7,"text":"So we'd have to delete that control rig by highlighting and press delete. We could hit the plus next to our character's name here. Come to control rig and go into untick filter asset by skeleton and search for the control rig that we just created, which is skm quen simple control rig. Now there's one big difference when you add assets to sequences in these two different ways."},{"start":"11:50","end":"12:21","startSec":710.3,"text":"If you drag them in from the content browser like we just did, that asset becomes what's known as spawnable and it only exists in the level when you have the sequence open. This is great for if you're working with some sort of shot based workflow. When you add an asset to the sequencer from the level instead, these assets are known as possessible, which means they are persistent within the level and you need to have the level open for the sequencer to reference that asset. This is useful if you have multiple level sequences that want to reference the same"},{"start":"12:21","end":"12:53","startSec":741.2,"text":"asset. An indication of a spawnable asset will be inside the sequence here where you see the lightning bolt icon. If we open our sequence that was created when we dragged the control rig into the level, you'll see that this character doesn't have that icon. So this character is possessible, meaning that the sequence is referencing this character saved in the level. So let's get started with our animation. I'm going to briefly go over some of the core components of a sequencer so we know how to"},{"start":"12:53","end":"13:27","startSec":773.2,"text":"select our controls and how to set a key on those controls and then how to bake our animation out and save that as its own animation sequence. So as you can see, we have our control rig track just inside the sequencer here. And if I pop that open, this shows us all the controls that are inside that control rig. Let's just zoom in on our character a little bit here. Now I could select the controls from inside the sequence here, which isn't too bad if you've only got a few controls, but this list can get quite long."},{"start":"13:27","end":"13:59","startSec":807.6,"text":"So you can also select them from the viewport or from the anim outliner here. Now to set a key on our controls, we could set a key on everything in the control rig by hitting this plus on the parent track. Or if you just want to add a key to individual controls, you would just use the plus on the individual control track. So let's set a key on everything with the plus here. And what we're going to do is just make a simple animation of our character waving."},{"start":"13:59","end":"14:33","startSec":839.3,"text":"Now something that's really useful to turn on here that we already have active currently is auto key. So whenever you make a change to a control, whether that's translating it or rotating it, what auto key is going to do is set a key when you make that change. So we've dragged our time slider across here. And what I'm going to do is grab our control here, bring it up in the viewport and just rotate it so it looks like the start of a wave."},{"start":"14:34","end":"15:09","startSec":874.3,"text":"Now something to make working with control rig a little easier in the viewport. Under the animation tab here, you can turn on select, which only selects the control rig controls. So if we activate that, now when I click on the mesh or the skydome, none of this gets selected, which is just super handy so that you can only select the controls and you don't accidentally select a mesh or something else in the viewport. But if I select our control again, come along a little further and we'll just make our wave"},{"start":"15:09","end":"15:44","startSec":909.0,"text":"animation. And I think what we might do here is if we grab the head control, we could have that look towards us on the camera over here. And then if we set a key again, we could bring that back to default just by resetting"},{"start":"15:44","end":"16:18","startSec":944.0,"text":"all the location values and the same with the hand here to finish off our animation. So if we play this animation back, we've got a quick wave and a head look over here that we can now save out as its own animation sequence and use elsewhere in the project. So if I press this little red button here, what that's going to do is bring the end of the playback range down to where my time slider is. And if we scroll up to select our character here, right click and choose bake animation"},{"start":"16:18","end":"16:49","startSec":978.5,"text":"sequence. This will then bake the animation down to its own animation sequence that we could use elsewhere in the project. So if I just use the content browser as the default location to save this and I just call this a underscore wave and hit OK, we get another option box comes up and depending whether or not any of these properties are relevant to your character like having morph targets or material curves or anything, you can tick these on and off."},{"start":"16:50","end":"17:23","startSec":1010.2,"text":"For now, I'll just leave them at default and choose export to animation sequence. Now if we go back to our content browser, inside the default content folder is our wave that we just created. And we can see our character waving to us, looking at us and then going back to the default pose. And that's it. So you can now access this animation as an animation sequence or bring it back into sequence and edit it further and then use elsewhere in your project."},{"start":"17:23","end":"17:45","startSec":1043.1,"text":"Hopefully you now have an understanding of how control rig works and how to set up a simple FK and IK rig as well as learning how to create a name target for your rig and then animate it in sequencer. We have more courses that cover rigging in much more depth as well as animating in sequencer. So if those are some skills that you want to develop, be sure to check those out. But for now, good luck with your rigging and animating."}]},"110.01":{"01_Introduction":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Greetings everybody, my name is Sam Dider and I'm a senior Unreal Engine instructor with Epic Games. In the following video tutorial, we're going to be taking an introductionary look at Niagara and how we can use Niagara to power all sorts of visual effects inside of Unreal. Now, we're first going to start off by exploring what Niagara is. Then we're going to take a look at the Niagara content examples as these provide a really great reference for all of your questions that you might have about Niagara when it comes to what it can do"},{"start":"0:32","end":"0:57","startSec":32.0,"text":"and even help give you ideas of things that you might not have considered before. Then we're going to take a look at the Niagara Editor overview and we're going to punish that up with creating our first Niagara effect. That's right, we're going to be actually getting hands on with this and creating a smoke using Niagara. So, let's go ahead and jump right in with what is Niagara."}],"02_WhatIsNiagara":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Now, for anybody that's not aware, what Niagara is, is, well, it's very simple. Niagara is a tool for creating visual effects inside of Unreal Engine 5. With Niagara, you can create anything from a simple smoke to an interactive crowd simulation. Niagara is also built for everyone in need of visual effects, whether you work in architectural visualization, you just need maybe a simple something for ambience, or you work in industrial design such as automotive designs, and you need to use some visual effects to heighten"},{"start":"0:33","end":"1:04","startSec":33.2,"text":"your user interface, or maybe possibly add some tire smoke, or maybe you work in virtual TV and film production, and you need some magical spells, or maybe in video games where there's all types of different effects. Unreal's Niagara system is going to be where you can create all of this different type of effects for whatever your needs happen to be. And here are some great examples of things that you can create with Niagara. Now, these are taken right from the content examples, which we'll cover here in the next"},{"start":"1:04","end":"1:35","startSec":64.7,"text":"slide, but what these are showing is just the absolute insanity that you can make with this tool. It is extremely powerful. And what we have here is we actually have particles that are spawning on the surface of a skeletal mesh. We have the beginning of a fluid simulation. We also have on the right hand side particles that react to the light. That's right. As that light shines across that face right there, those bugs are going to move around and scurry to get out of the way of the light."},{"start":"1:35","end":"1:49","startSec":95.6,"text":"And this is all done through Niagara. And you can see just from this images that this is a very powerful tool. So we'll show you some stuff you can do in the content examples. You're going to see why Niagara is such a great tool for you to learn how to use."}],"03_ContentExamples":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Now Niagara offers a number of content examples that shows you how to do pretty much anything you could ever want to do. And the reason I'm bringing them up is these can act as some really great learning content. And the examples that I'm talking about are Niagara particles, Niagara advanced and Niagara fluids. Now in Niagara particles, you're going to learn the very basics of Niagara. It's going to show you how to do simple sprite and static mesh emitters. There's GPU beams as well as emitters with multiple renderers."},{"start":"0:33","end":"1:05","startSec":33.7,"text":"And then showing you how to do things like simple collision or texture sampling, playing audio and alignment and a few other things. Niagara advanced, you're going to find a variety of ways that you can interact with Niagara. There are simulation stages, reading and writing to rendered targets or sampling from a skeletal mesh or a GPU buffer. There's also using attributes and distance field traversal. You can also see some examples on bird flocking, 3D grid support, as well as component rendering,"},{"start":"1:05","end":"1:38","startSec":65.4,"text":"exporting particles to blueprints and even sampling from dynamic distance fields. Now Niagara fluids, this is where you're going to find a variety of emitters that can be used to simulate smoke and liquids in real time. Examples here included are gas and liquid, quality versus performance, light interaction, particles infection, there's going to be camera facing smoke and fire, as well as 3D smoke and fire. So let's just pop over to the end of really quick and take a look at some of these. So first off, hit control space and we're going to go to our maps folder here and the"},{"start":"1:38","end":"2:12","startSec":98.2,"text":"content examples, NI and NIA and there is our Niagara particles. So let's just double click on this to open it up and have a look at it. So it's going to start over here and then as we go to the right, the particles are going to get more and more complex. So the examples again start off here, we're going to go with our sprite and then there is a mesh and then as we go on, we're doing GPU and sprite facing. So all of these really, really fantastic examples that you can see here that goes all the way down here to a mesh orientation versus rotational force."},{"start":"2:12","end":"2:49","startSec":132.8,"text":"Next we're going to have our advanced one. I'm not going to save that. And in our advanced, we start again over here at looking at our render targets and then going all the way over till we get to sampling from our dynamic sampling from our distance field right here. And there's tons of just different examples that we can use here for anything that we would really want. This is really cool. This is the start of a structural support. So some of this stuff as it starts to come undone, everything is going to start to fall"},{"start":"2:49","end":"3:21","startSec":169.0,"text":"down in different stages. So there's just really great examples that we can use here. Last but not least Niagara fluids. So open this one up and have a look at it. Now Niagara fluids is quite expensive. So if you're running with lots of programs open, you might need to close some to get this to run. But again, as we start here, we're going to go for something very simple like this is a 2D gas and liquid simulation. And then we have a 3D one right next to it."},{"start":"3:21","end":"3:52","startSec":201.4,"text":"You can see here there's quality versus performance. There's fire. Some of these do require that you come up here and press play. I just am recording. So I want to make sure that let's just try and simulate and see if that can help us. I might actually have to press play. And there we go. Get up close to some of this. I think some of this I have to get really close to it in order for it to work. There we go. So there's some fire rendering."},{"start":"3:52","end":"4:23","startSec":232.6,"text":"It's working with the lighting. There's a little bit of lighting offset there. You can see the particles are changing colors. A lot of really, really great and cool stuff here. So definitely worth checking out. Now one of the last things that I want to talk about before we go on is every part of the content examples also contains information about what is going on. So if I do go to one of these and I open it up, I'm going to see comments about what is going on and why this is set up in the way."},{"start":"4:23","end":"4:54","startSec":263.4,"text":"And again, this is why this works for such a good learning resource is I can not only have a look at stuff. You know, if I come in here, maybe look at something like maybe we grab this one. So let's hit control E and then I come in here and it looks like I grabbed a bad one for a let's go into our particles here because I know that these ones are. Let's look at that one right there."},{"start":"4:54","end":"5:19","startSec":295.0,"text":"Maybe hit a control E and there we go. So this one has a little bit more information inside of it as the fluids are documented on the website. Again, we can open up a lot of these and we're going to see inside of them a lot of information about how we can use these or shouldn't say how we can use it, but why these. Particles work in the way that they do and things that we need to be aware of when we are using them."}],"04_Overview":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Before we jump into using Niagara, we're going to take a quick look at Niagara as a whole and get more information about what we are using so we better understand how things are set up and they work. Now the first thing that we want to talk about with Niagara is inheritance. And that's because inheritance plays a massive role inside of Niagara. So each Niagara system that you create is actually going to be a collection of Niagara admitters."},{"start":"0:31","end":"1:02","startSec":31.0,"text":"Those admitters are actually a collection of dynamic input scripts, functions, and modules. And those are further made up of Niagara asset tags, data channels, effects types, parameter collections, parameter collection instances, definitions, simulation caches, and rules. So you can see here that all of the things that you might work on inside of Niagara are actually created of bits of smaller VFX."},{"start":"1:02","end":"1:37","startSec":62.0,"text":"So you can kind of think of Niagara as creating material instances but for VFX. Now because Niagara is such a complex editor, when you go to create a new admitter, you're going to be greeted with this wizard. The wizard allows you to select template to get started from and it's also a great resource when you're learning because it's going to show you a bunch of different examples of things that you can create."},{"start":"1:37","end":"2:12","startSec":97.0,"text":"Now the Niagara editor is going to look similar to many of the other editors you used with the file menu across the top. And then one, much like with Blueprints and with the material editor, we have our save and our browse to asset and our compile. The thumbnail controls our thumbnail or this is what it's going to look like when viewed inside of the content browser. Our bounds shows us the rendering bounds, debug will show us debug information, simulation is for playing the simulation."},{"start":"2:12","end":"2:44","startSec":132.0,"text":"Baker allows us to bake out this to a texture and scalability controls what is going to be turned on and turned off for our scalability. So again the menu bar here is very, very similar to what you've used in the past with other editors. Over here, two, this is going to be our preview window. This will show us the effect as we are building upon it. Now three over here, this is going to be our parameters, user parameters and local modules."},{"start":"2:44","end":"3:15","startSec":164.0,"text":"Now out of this one, the one that we're going to use the most here is going to be user parameters and we'll cover those in just a little bit. Over here four, this is going to be our timeline, curves, Niagara log and script stats. Now the timeline doesn't necessarily work in the way that you might be thinking. It doesn't actually control the parameters inside of here. Since this Niagara system can have multiple admitters in here, we can actually have different admitters and then control them through the timeline down here."},{"start":"3:15","end":"3:47","startSec":195.0,"text":"Curves allow us to control the curves that we are working with. So if we have something that's going maybe from like an alpha from zero to one back to zero, we can look at that curves in the Curve Editor with more detail. Niagara log is going to show us the Niagara logs and the script stats are going to show us the stats of the whole system. Five is going to be our details panel. Now like with many of the other details panel in the editor, this is context sensitive. So what we have selected is going to change that."},{"start":"3:47","end":"4:25","startSec":227.0,"text":"And then finally, six is our system overview and this is where we're going to be doing a majority of our work here. We can select each of these individual modules inside of this Niagara system right here. The details panels will populate with them and that is where we're going to do the work. So speaking of populating with it, the item that we're looking at here is called the stack. And the stack is basically where we interact with our particle. So you can see here we have an Admitter Summary, then we have our Admitter Spawn, our Admitter Update, and then our Particle Spawn, our Particle Update, and the Renderer."},{"start":"4:25","end":"4:58","startSec":265.0,"text":"So the Admitter Spawn and the Admitter Update can be thought of as the things that get started. So this is what is going to start to admit all of our particles. And then the Particle Spawn and the Particle Update can be thought of as well, this is what we're actually going to be seeing. And if you press, you can either collapse these by pressing this little triangle, or you can add different modules by pressing the plus sign next to each one of these stages. Once you do that, you're going to see this new module list come up and there are an awful lot of modules here."},{"start":"4:58","end":"5:28","startSec":298.0,"text":"So keep that in mind that if you're looking for something to do with these, it's probably going to be there. You're probably going to need to search for it. In addition, each of the inputs you have here have the ability to be set up to either a parameter, or we can further implement something like an expression, or we can multiply them by a little formula or something like that."},{"start":"5:28","end":"6:16","startSec":328.0,"text":"So we have a huge amount of control around our particles inside of Niagara. Now there is one other thing that I want to talk about that you might run into, and that is a lightweight admitter or a stateless admitter. You can have this type of admitter working with another Niagara admitter in the same Niagara. And what the difference between this one and a standard Niagara admitter is that a lightweight admitter reduces the concurrent cost per tick, and in essence what it is is a reduced version of a particle system that is just the bare basics that is needed for it to run."},{"start":"6:16","end":"6:43","startSec":376.0,"text":"So these are really good for things, maybe like a fire or an ambient smoke that doesn't need all of the various options that Niagara comes with. We just need something very simple. So we can add a lightweight admitter and then you'll see there'll be some parameters that we can add to it, but not as many as we normally would. So with that said, the next thing we're going to do is we are going to get into creating our first Niagara effect."}],"05_CreatingYourFirstEffect":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Now that we know a little bit more about what Niagara is and how we can use it to create effects, let's go ahead and take a look at creating our first effect. And what we're going to be doing is we're going to be creating this smoke right here. Now we're going to focus just on the Niagara aspect of that. And because of that, what we're going to be doing is we're going to actually be working with some content that exists inside of the starter content. So if you haven't done so or if you're not sure about this, what you can do is you come up here to add and go add feature or content pack."},{"start":"0:32","end":"1:02","startSec":32.2,"text":"And then from the wizard that comes up, go over here to content and then select starter content and press add to project. Once you've done that in your content browser, you will now have this collection of starter content and the piece of content that we're going to be focusing in on is this smoke material right here. Now, this is from the old Cascade example, which is the old way to do effects inside of Unreal Engine. There are two nodes that I want to call out because this material is actually really set"},{"start":"1:02","end":"1:33","startSec":62.7,"text":"up great to work with smoke, especially a lit smoke. The first thing is this particle color. Notice that it has the RGB multiplied by the texture sample that represents its base color and it also has the alpha done the same thing. The reason that this is important is if we want to work with this data inside of Niagara, we need to make sure that this particle color node is connected. The other thing, depth fade, this node makes it so that when this particle intersects geometry, there's a nice fade. This can be really expensive, especially if you have a lot of particles or your particles"},{"start":"1:33","end":"2:05","startSec":93.6,"text":"are very large, so just keep that in mind. Some of the other things to note about this material is its blend mode is set to translucent. This will allow us to get this smoke that looks kind of semi see-through and will also react with our level lighting by changing our lighting mode to volumetric directional. Last but not least, we increase the shadow density scale to 3.0. This is purely an artistic choice. Just to make things look a little bit cooler, please feel free to mess around with any of"},{"start":"2:05","end":"2:38","startSec":125.2,"text":"the numbers in there to see how they'll affect the smoke in different ways. To get started now, what we're going to do is we're going to create a new Niagara system. Then what we're going to do is from the wizard that comes up, we're going to select the lightweight fountain. Let's go ahead and do that now. Inside the editor here, I'm going to come up to my content folder, right-click, Niagara system, and then template, fountain, create. I'm going to call this smoke."},{"start":"2:38","end":"3:08","startSec":158.2,"text":"NS for Niagara system, smoke. Let's go ahead and double-click on it to open it up. Then what we're going to do is we're going to look for this m smoke sub-UV. This material right here is the material that we are going to place on our effects. To do that, what we're going to do is we're going to hit control space. Then I'm going to come down here for our starter content. If we go to particles and then materials, we can actually find it right there. Those are m smoke sub-UV. We can add this a number of ways. Easiest way is we can actually just drag and drop this."},{"start":"3:08","end":"3:39","startSec":188.9,"text":"I need to click on that first. We can drag and drop it now over here. It will line up. We can see it, if I was to pause here, we can see here it's not really lining up. That is because a sub-UV is actually playing a series of images to give the illusion of motion. By default, it thinks that we, one by one, it thinks there's a mapping of one image to one piece of geometry. That's just not the case."},{"start":"3:39","end":"4:12","startSec":219.6,"text":"This is actually a 64 by 64. That means that we have eight images in the x-axis and eight images in the y-axis. To fix our problem here, what we do is we come over in the details panel to sub-UV. We just change our sub-image size to 8 by 8. If you don't know where that is, you just need to click on the sprite renderer right down here and then our sub-UV size. We're going to go 8 by 8. It's going to give us these nice looking little clouds that we're going to now adjust"},{"start":"4:12","end":"4:43","startSec":252.0,"text":"to give us something that looks a little bit more like smoke. First off, we're going to adjust our spawn rate, our lifetime, and our size. These are all going to be found in the same spot. What we're going to do is we're going to come up here to our particle spawn. Our lifetime right now, it's between 1.4 and 1.75. I'm actually going to change this to direct set. We're going to give this a lifetime of 5."},{"start":"4:43","end":"5:15","startSec":283.1,"text":"Then what we're going to do here is we're going to go to our... Up one more, there's our spawn rate right there. We're going to change this to 20. Then what we're going to do is we're going to come down to our initialized particle one more time and we're going to go to our sprite attributes here. Instead of random uniform under sprite size mode, we're going to say uniform and change this to 64. This is going to give us a uniform sprite size instead of a random sprite size."},{"start":"5:15","end":"5:47","startSec":315.0,"text":"Again, we changed our spawn rate to 20. We set our lifetime here to 5 and our uniform sprite size to 64. What we're going to do next is we're going to change our velocity, adjust the size that the particles are spawned from, and then disable our gravity force because it's working against us right now. Let's go ahead and do that now. First off, let's go ahead and disable our gravity force because that's really going to work against us right now."},{"start":"5:47","end":"6:19","startSec":347.8,"text":"Then what we're going to do here is under our add velocity, we're not going to do that in a cone, we're just going to change that to linear. That's going to give us access to our x, y, and z axis right here. You can see here we've already got quite a difference there. Let's change this to maybe like 80 for right now. Give us a smoke that is kind of fast moving up. Then what we're going to do here is we're going to go to our shape location and we're going to increase this to say 20. You can see here that kind of spreads the smoke out a little bit."},{"start":"6:19","end":"6:52","startSec":379.0,"text":"It gives it kind of a wider surface area. It looks like it's spawning for something a little bit larger. Okay. Next, what we're going to do is we need to adjust our alpha channel because right now when the smoke comes in, it is full alpha and it actually is kind of jarring. Let's check this out. What we want to do here is it's got this nice fade out, but it doesn't have this really great fade in. Basically what we want is something like this. We want a fade with, we don't have any fade."},{"start":"6:52","end":"7:23","startSec":412.4,"text":"It's actually backwards, but we want a fade with a nice fade right here. We want to change this so that it fades in and fades out. To do that, what we're going to do is we are going to come to our scale color. We should have this scale alpha. If you don't, you can just come here and just look for a curve. If you don't have one, actually this one up here, sorry, a float from curve. That will add this little input right here."},{"start":"7:23","end":"7:53","startSec":443.0,"text":"What we're going to do is at 0.5, we're going to add this. We're going to actually set its value to 1. Then we're going to set the beginning values to 0 and 0. We have this curve that goes like this. That's going to give us something that fades in and then it fades out. The next thing that we want to do is we are going to add our controls to animate our sub-UV. Right now, if we look at our smoke, it's actually not really doing anything."},{"start":"7:53","end":"8:23","startSec":473.1,"text":"It's just kind of hanging out there. It looks really cool, but it's not actually animating. If we come down here to particle update and we look for something called sub-UV, we have this sub-UV animation. As soon as we click on that, what's going to happen is it's going to put it on there, but we get this error right here. Under our sprite renderer, we need to select sprite renderer. Once we do that, we are going to get, and it's very subtle, but you should see the smoke looking like it is actually playing some animation."},{"start":"8:23","end":"8:54","startSec":503.9,"text":"This just gives it a little bit more realism and a little bit more life. We might need to maybe come down here and come to our spawn rate and maybe change this to 15. We can see the smoke moving around and things like that. That's really cool. What we're going to do next is we are going to expose some parameters. This is a really great feature of Niagara because you can expose many different parameters to your user."},{"start":"8:54","end":"9:27","startSec":534.5,"text":"First off, let's go to our spawn rate here. Right next to our spawn rate, we're going to click on this. We're going to look for user. We have this read from new user parameter. I'm going to click on that. If I come over here to my user parameters, this might be set on parameters. Make sure you click on user parameters. You can see the spawn rate. If I'm just going to save this and I'm going to just pull this in the level, you don't have to do this part right now. What we're going to do is we're going to look for this, browse to this. If I drag this into the level, check this out. When I come down to the Niagara system user parameters here, I'm going to save this spawn"},{"start":"9:27","end":"10:00","startSec":568.0,"text":"rate so I can set this to something really crazy, 89. What we want to do now is let's spend some time exposing some various parameters and things like that, such as maybe like the sphere radius here. Right-click user parameter. We have our sphere radius. We want our add velocity, read from new user parameter, compile and save."},{"start":"10:00","end":"10:31","startSec":600.4,"text":"We have all of this cool stuff that we can now do inside of here. You know, we'll offset this. It's blowing backwards now. All types of really, really cool stuff that we could do. Well, that was a little bit too much. There we go. Now, spend a little bit of time doing that. When we come back, what we'll do is we will take a look at how we can adjust this for"},{"start":"10:31","end":"11:01","startSec":631.4,"text":"level lighting. All right. We're going to take a pause right here and then we're going to come back and we're going to set this up to work with level lighting. Now that you have added a couple of controls, let's put this in a level and show you how it can easily work with your level lighting. So, let's just pop back over here to Unreal. What I'm going to do for now is I'm actually going to close this and I'm going to do a file new level."},{"start":"11:01","end":"11:33","startSec":661.5,"text":"What I'm going to do is completely empty level and hit create and we're not going to save that. Then what I'm going to do is hit control space, grab my smoke and just bring it in. Then here in my transform, I'm just going to zero these values out and hit F to kind of focus in on this. It looks like it's lit now, but if I go into game mode, I'm not going to see anything. So, if I hold down L and click, I'm going to add a light and I'm just going to, again, zero it, it transforms and I'm going to change it to a red light. Then what I'm going to do is hold down alt and bring over another one."},{"start":"11:33","end":"12:08","startSec":693.6,"text":"I'm going to change this one to green and you can see here that as soon as I do that, I get this nice yellow and that is because it is actually mixing the two colors there. So you can see there's my green and it becomes more red. And that's because of our material setup being set to allow translucency and also our lighting being set up to work with volumetric non-directional. You can see how powerful some of those settings can be to give us something that looks like this. And let's see, maybe we need, I think we might need one more light back here."},{"start":"12:08","end":"12:26","startSec":728.9,"text":"I think we were just hitting like a weird light frustum thing there. So actually set this one to blue. So there we go, there's blue. And then we're getting white because that's the combination of everything. So that's really, really cool that it's kind of really true to mixing everything together."}],"06_Outro":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"So, that is it. That is going to wrap up this video tutorial. And in this tutorial, we covered what Niagara is. We talked about Niagara being Unreal's solution for any visual effects, no matter if you are a film person or an architect or a game developer, you can find some use for Niagara. We then looked over the various Niagara content examples and then took a look at the Niagara interface. And finally, we put all this information together and created our first Niagara effect, which"},{"start":"0:33","end":"0:45","startSec":33.5,"text":"was some lit smoke that used a sub-UV to help simulate the smoke actually moving even more. So I hope you learned something and I appreciate having you here and I will see you next time."}]},"111.00":{"01_Intro":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Greetings everybody, my name is Sam Dider and I'm a senior Unreal Engine instructor with EVE Games. In the following video tutorial, we're going to be taking a look at how we can quickly get started using Landscape in any of our Unreal Engine 5 projects. Topics include creating a new landscape, then how we can use the tools to sculpt that landscape, then look at how we can create a simple material to paint on our landscape giving it colors, and then finally we'll take a look at how we can use the foliage tool to apply various"},{"start":"0:30","end":"0:38","startSec":30.7,"text":"static meshes to our landscape to act as foliage. We've got a lot to get into, so let's go ahead and get started with creating a new landscape."}],"02_CreatingNewLandscape":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"So, first things first, we're going to be creating a new landscape. And to do that, what we're going to do first is we're going to create a new basic level. And then once we do that, we're going to go ahead and click over to our landscape tool to activate it. Then once our tool is activated, what we're going to do here is we're going to make sure that the location is set to 000, that our section size is set to something relatively small. Section sizes could control how many quads our landscape is, and making them bigger is going to result in a larger landscape, making that number smaller is going to result"},{"start":"0:32","end":"1:03","startSec":32.2,"text":"in a smaller landscape. And then we're going to hit create. So let's go ahead and pop over to the editor now and do this whole process. So again, file new level, select the basic right here, going to hit create. Then what I'm going to do is I'm going to select this static mesh here that represents our floor and hit delete. That's going to go ahead and delete that because we're making a landscape. We don't actually need that. Next we're going to come up here to our selection mode and come down to landscape. And once we do that, it's going to activate our landscape tool."},{"start":"1:03","end":"1:37","startSec":63.0,"text":"Now since we don't have a landscape in the view yet, this is what we're going to see. This green outline represents where our landscape is going to be. Make sure our location is in 000, that's good. We're going to leave the scale exactly as it is. And I'm going to take my section size, maybe down to 15 by 15, just to make my landscape a little bit smaller and a little easier to manage for this example. Once all of that has been done, I'm going to go ahead and hit the create button. And you're going to see here my landscape is ready to be painted on. So in the next section of this video, what we're going to be taking a look is at how"},{"start":"1:37","end":"1:42","startSec":97.0,"text":"to use the various sculpting tools to sculpt our landscape. So I'll see you in just a bit."}],"03_SculptingTheLandscape":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Now that we have our landscape created, we're going to take a look at how we can use a few of the tools Unreal Engine 5 provides to sculpt the landscape. Now the tools that we're going to be using are going to include the Sculpt, Erosion, Hydro, and Noise tool, but there are other tools that we can use which I encourage you to mess around with outside of this tutorial. Now to use the tools, you simply click on which tool you want and then the left mouse"},{"start":"0:31","end":"1:07","startSec":31.4,"text":"button will apply the brush and if you hold down shift while pressing the left mouse button, you will do the opposite. So for example, if I'm on Sculpt that I press the left mouse button, I will raise the terrain up. If I hold down shift and press the left mouse button, I will push that terrain back down or make it go negative. Each one of the tools, there's also going to have some tool settings, but there are some tool settings and brush settings that are common between any tool that you have selected that involves a brush. This is both the tool strength which controls the intensity that the applying brush has"},{"start":"1:07","end":"1:39","startSec":67.8,"text":"on the landscape. So the closer this number is set to one, the stronger, the more intense that effect will be. One pro tip with the tool strength is that less is often more with this, so using numbers like 0.1 or 0.2 are going to have a much better result and allow you to have more control. Brush size allows us to control the size of our brush and we can also use the shortcut key left bracket and right bracket to increase or decrease the brush size."},{"start":"1:39","end":"2:14","startSec":99.1,"text":"Brush falloff allows us to control the falloff or how dome like our brush is going to look as the falloff increases to 1, we're going to get a smoother looking brush and then as we decrease that number back to 0, we're going to get a much sharper brush especially at the sides. This last option we see here, use clay brush, we'll demonstrate this in just a little bit, but this is unique to the Sculpt tool and we'll turn the Sculpt tool into this additive brush which allows us to make some really interesting features that we can further refine later"},{"start":"2:14","end":"2:48","startSec":134.2,"text":"on. So let's go ahead and pop over to the editor and start using the noise tool to break up our landscape and our goal is to get something that looks kind of like this where we have some highs and some lows and let's go over to the editor now. So inside of the Unreal editor, we want to make sure that we are in landscape mode so if you're not, we come up to selection and go to landscape and then we're going to select here the noise tool. We're going to make sure our tool strength is set to 0.2, that our noise mode is set to both and I'm going to increase my brush size a little bit, probably something like"},{"start":"2:48","end":"3:21","startSec":168.3,"text":"that and what we're going to do now is I'm just going to start to paint here by holding again the left mouse button and you can see here what it's doing is it is increasing and decreasing the height of my landscape. So spent the next few minutes increasing and decreasing the size of your landscape to give you some nice areas to work with. You can also mess around with the various options inside of the tool to kind of really get a feel for how things are working and again we're trying to get something that looks like this. Now once you have gotten that, the next tool that we're going to look at is going to be"},{"start":"3:21","end":"3:55","startSec":201.7,"text":"the sculpt tool and specifically with the sculpt tool we're going to enable this use a clay brush option and what this is going to do is it's going to make it really easy for us to kind of make the beginning of mountains. So let's take a look at how we do that now. So in the editor I'm going to click over to sculpt and I'm going to make sure that my use clay brush is enabled which it is here and then I'm going to decrease my brush size and something like that and we can see here as I start to paint in one area I get these"},{"start":"3:55","end":"4:31","startSec":235.4,"text":"really nice looking kind of round mounts. Now if I was to disable the clay brush here you can see it's going to bring it up more brings up the slopes a little bit more and in some instances that's great but I'll oftentimes I find that when I'm trying to begin an area trying to make some mountains that look kind of cool or some plateaus or something like that that using the clay brush in this manner works really well. So now what I want everybody to do is spend a little time going through their area and figuring out how they're going to make various brushes work for their project."},{"start":"4:31","end":"5:05","startSec":271.3,"text":"Remember you can also use the bracket keys to bring the brush down in size so left bracket goes down and then right bracket goes up to give you some variation in your project. Then once that is complete we're going to use the smooth tool to smooth out areas of our landscape and you might often click on the tool over here and you might think that well let's just do something like this and just smooth everything at once and while that might give you results it is really going to destroy everything."},{"start":"5:05","end":"5:37","startSec":305.9,"text":"What you actually want to do here is we want to make sure that things like I'm going to also set this down to like 0.1 that things like this are you know not too crazy for us here because that's going to result in some weird rendering from the triangles but it's also just not going to work for when the player tries to run over it or view it it's going to look like an error. So again just kind of smoothing out kind of areas that we have so we get some good looking topology but we're also kind of keeping the highs and the lows."},{"start":"5:37","end":"6:15","startSec":337.8,"text":"Remember I set that tool strength down to 0.1 because I want to just barely get some of this stuff smoothed out so I still have some really cool looking terrain to work with when we go to our next step which is going to be applying erosion and stuff like that. So spend the next few minutes pause the video and go ahead and smooth things out so that you get a little bit of a smoother result here and when you come back we're going to take a look at using erosion. Now the erosion tools are used in a similar manner as the smooth tool."},{"start":"6:15","end":"6:46","startSec":375.1,"text":"We don't want to apply erosion to everything we want to start somewhere and apply erosion locally and what I mean by that again is we don't want to come in here with our erosion so I'll come here to this erosion and bring this you know we don't want to apply this this might work but it's not going to give us the best results. What we want to do here is start at the top of something and I make my brush really small and remember erosion starts at the top and brings stuff down so when we're doing erosion we always want to start at the top and bring things down that's going to give us the best"},{"start":"6:46","end":"7:18","startSec":406.7,"text":"looking results. So again what I want everybody to do now is using the various tools that we just talked about the sculpt the erosion the smooth and we can even use the hydro again with the hydro we want to do from the top down to the bottom so you can see it's going to give us a similar result to erosion but I want everybody to spend some time now really working on getting some great looking just terrain using these various tools and when you have something done like this go ahead and move on to the next part where we'll talk about creating"},{"start":"7:18","end":"7:25","startSec":438.3,"text":"material that we can use to help paint our landscape giving it the look of grass, rocks and dirt."}],"04_PaintingTheLandscape":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Now that we have our landscape sculpted, let's take a look at how we can paint the landscape. Now before we can start painting the landscape, what we're going to need to do first is create a material that uses a node called the Landscape Layer Blend. And the Landscape Layer Blend allows us to basically do that blend between these various layers. Now for this example, we're going to be creating it using just some colors. We're going to make a dirt, a rock, and a grass. So let's go ahead and pop over to the editor now."},{"start":"0:30","end":"1:01","startSec":30.0,"text":"Now if you are in the Landscape Tools, you should come out of them by coming up to the selection mode here and just going into selection to get out of the tools if you're in them. We're going to hit Control Space on the keyboard, come to our content, and then right click and make a material. We're going to call this new material M-A-T underscore Landscape. And then once we have created it, we're going to double click on it to open it up. Just bring this over here. Now what we're going to do first is we're going to look for our Landscape Layer Blend."},{"start":"1:01","end":"1:39","startSec":61.0,"text":"So to do that, we're going to right click in the graph of the material and look for our Landscape. And right there we have our Landscape Layer Blend. Now by default, there are actually no inputs for this node. So to add some, what we need to do is make sure we have the node selected. And then in the Details panel under Layers, we need to add three elements. You can see that as soon as I do that, I get a Layer None, Layer None, and Layer None. Now for this example, we are going to have a dirt, a rock, and a grass."},{"start":"1:39","end":"2:10","startSec":99.0,"text":"So each one of these indexes, layers, names is going to be named like this. And you can see here I have my layer dirt, my layer rock, and my layer grass. So next what we're going to do is we're going to right click and we're going to look for a vector. And we want a vector parameter. So just type in vector and then PA and there's a vector parameter. We're going to call this first one dirt. And I'm going to give it a default color of some kind of like a dirtish looking something."},{"start":"2:10","end":"2:40","startSec":130.0,"text":"So maybe something a little bit like that. Okay, we're going to plug this in to our dirt. And then what we're going to do is we're going to right click on this and duplicate it. And then we're going to call this New One Rock. And then we're going to give it a new color, kind of like a grayish color. We'll go a little bit of a darker gray, a little bit too dark. All right, and then we're going to plug this into our rock. And then we're going to right click and duplicate again. And we're going to call this one grass. I'm going to give this some type of darkish kind of grassy looking color. There we go."},{"start":"2:40","end":"3:11","startSec":160.0,"text":"And then we're going to plug this right here. Now, once that is completed, we need to take the output from our landscape layer blend and bring that right into this base color. And then let's just compile and save our material. Because the next thing that we're going to do here is once we've done this part, we're now going to do this part, which is going to add a normal to this. This is going to make it a little bit easier to see the differences between them. And it's just going to give a little bit more life to our material."},{"start":"3:11","end":"3:42","startSec":191.0,"text":"So let's go back over here to our material. And this is actually really cool. What we can do now is we can right click on this and duplicate it and bring it down here. And we're just going to plug this right into our normal. And then what we're going to do is don't mind that. That'll be taken care of in just a second. We're going to make some parameters to control the size of our textures. So we're going to left click and look for something called a landscape. And we're going to look for this landscape layer coordinates."},{"start":"3:42","end":"4:16","startSec":222.0,"text":"There we go. And then what we're going to do is we're going to look for a constant. And for this constant, we're going to give it a value of one. But we also want to make this adjustable inside of the material instance. So we're going to right click on it and convert it to a parameter. And then we're going to call this normal tile. Then what we need to do next is we need to multiply these two together. So we're going to drag off of this and look for a mole and under our math multiply."},{"start":"4:16","end":"4:48","startSec":256.0,"text":"We're going to add that. And then we're going to take the output of our normal tile and plug that right into our multiply there. Now with the tiling logic set up, the next thing that we need to do is create our normal map. So to do this, there's a couple of different ways. One of the ways that we can add a normal map is by just holding down the t key and clicking. And that's going to add a texture sample. So again, I just did that by holding down the t key on the keyboard and left clicked. Then we're going to right click on this and convert it to a parameter."},{"start":"4:48","end":"5:20","startSec":288.0,"text":"And we're going to call this n underscore dirt. And we're going to do a couple of things now. We are going to take the multiply and plug that into our UV. And then on the n underscore dirt, we're also going to need to give it a default texture. So we're going to look for something here. I'm just going to look for dirt. We'll just do an underscore n and then we will give it something like, I don't know, this rocky something looks pretty good."},{"start":"5:20","end":"5:52","startSec":320.0,"text":"Okay. So the next thing that we need to do is we need another one of these for our rock and our grass. So this is actually going to be really quick because we already have most of this set up. So all we need to do is right click, duplicate and then instead of calling this n dirt, we're going to call this n underscore rock. We're going to plug the multiply in to our UV right there. And then if we want, we can change this. We'll just do underscore in to look for again some normal maps and we'll do maybe some ground gravel."},{"start":"5:52","end":"6:24","startSec":352.0,"text":"There we go. And then right click, duplicate, pull this down. I'm going to call it n underscore graph. And then like we did before, we're going to bring the multiply down into the UVs and then we're going to look for something. We actually have a ground moss. There we go. That'll work for us for the time being. And then what we need to do is we need to plug these into the respective inputs on the landscape layer blend. All right, so let's just apply and save."},{"start":"6:24","end":"6:57","startSec":384.0,"text":"So we are done with that, but there's a couple of things that we need to do next. So what we're going to do is we need to select our landscape and apply this material, but we're not going to apply the material itself. What we're going to do is we're going to make an instance of that material and the instance is going to make it easier for us to adjust. So we're going to come back over here. I'm going to close. Oops, said back over here. We're going to close this down. I'm going to hit control space. On our material landscape, I'm going to right click and go create material instance. All right, so that's going to create our landscape material instance."},{"start":"6:57","end":"7:30","startSec":417.0,"text":"And then what we're going to do is we're going to select our landscape. Make sure our material instance is selected in the content browser here and over in the details panel, we're going to look for our material, which if we come down here, it's going to be under our landscape and then our landscape material. And we're going to say use selected asset from the content browser. And this is going to take just a second. There we go. And we're not seeing anything. And that's because we need to assign something called weight blended layers to each one of our layers for our landscape."},{"start":"7:30","end":"8:02","startSec":450.0,"text":"And what these are going to act as is a mask so that when we go to paint, we can expose the dirt or the rock or the grass. So let's take a look at how we do that right now. So we're going to come over here to our selection mode and go down to landscape. And then we're going to make sure we're on the paint tool. And you can see here there are no current layers assigned. So what we want to do so that we're on default, and then we're going to hit the create layers from assigned materials."},{"start":"8:02","end":"8:32","startSec":482.0,"text":"And that's going to create our different layers here. All right. And then what we need to do is we're going to come right here to the layer info and we're going to go where weight blended layer normal. It's going to ask us where we want to save this and we're going to save it to the untitled three, which is just going to take this math name and put it in the folder. So we're going to save there. There we go. And then we're going to do the same thing for our rock. We're going to do the same thing again. There we go. And then we're going to do the same thing for our grass."},{"start":"8:32","end":"9:03","startSec":512.0,"text":"Now there are a few options that we have that are kind of under the hood, so to speak. And if you right click on the layers, you're going to get the ability to export or import, but you also have this fill clear and rebuild material so that fill is going to fill any particular layer with like doing a fill in Photoshop. You'll fill it with your dirt or your rock or your grass. The clear layer is going to do the opposite. If you right click on this and clear it, it will get rid of the dirt, the rock or the grass and the rebuild materials is used."},{"start":"9:03","end":"9:41","startSec":543.0,"text":"And if you happen to change your material drastically and you want to rebuild the material is used behind the scenes, then you will use that to do that. Now, all that's left to do is to paint. Now there's actually two things that we can do. We can paint and we can smooth and basically paint will allow us to paint our various areas and then smooth will allow us to smooth the transition between those two. And by doing that, we can get something that looks like this. So again, let's pop over to the editor now and I'm going to come over here to my rock and let's say that, you know, I want to just come over here and start painting some rock."},{"start":"9:41","end":"10:13","startSec":581.0,"text":"So there we go. So the rock selected brush probably a little bit smaller than that. So there we go. There's that rock that I have added there. And then I can do the same thing with my grass. So there we go. And then if I want to, I can come here and I can smooth out kind of in between them. You can also use the bracket keys on your keyboard. Left bracket will make things smaller and the right bracket will make things, your brush bigger so that you can get a better smoothing and things like that."},{"start":"10:13","end":"10:43","startSec":613.0,"text":"I'm going to hit control space because I also want to come over here and mention one thing about the landscape material instance. So if I was to bring this out and do something like, you know, normal tile, maybe we set this like 0.1. You can see here, we're going to get a little bit of some better looking kind of tiling information on that. And then also we could do something like come here, maybe our grass is a little, little too green for my, my liking. So we're going to maybe not make it black, but bring it back over here. There we go. That's a little bit better. It's a little too bright."},{"start":"10:43","end":"11:16","startSec":643.0,"text":"There we go. That looks, that looks a way better for grass right there. So if I come here and go to paint, get some little bit better looking grass. So again, that's why we want to use this material instance because it makes it really easy for us to be able to adjust things as we are going on the fly. So what I want everybody to do now is take some time to paint their landscape and make adjustments. And when we come back, we will take a look at how we can apply mesh based foliage to our landscape to make the landscape look even more lush and full of life."},{"start":"11:16","end":"11:17","startSec":676.0,"text":"Thank you."}],"05_ApplyingFoliage":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"We're now going to take a look at how we can apply various static meshes as foliage. This is actually quite easy to do. The first thing we're going to need to do is open up the foliage tool. Then once we have that open, we can actually apply any static mesh we want. Let's take a look at how we do that now. We're going to come over here to the editor and I'm going to get out of the landscape tool and come down to the foliage tool. Before I can use it, I need to bring a mesh down. What I'm going to do is I'm going to hit control space. I'm going to go to my starter content."},{"start":"0:32","end":"1:02","startSec":32.2,"text":"We're going to look for our, I think it's under props. There we go. I'm just going to grab this bush and just drag that right there. Now, as soon as I have done that, I will be able to now paint this piece of foliage here. And there we go. Look at that. I can use a shift to erase. And I also have the ability to come in here and actually select the individual foliage pieces. Let me just make sure G is on so we can see that. And then I can do things like move this around. I can rotate them."},{"start":"1:02","end":"1:34","startSec":62.3,"text":"I can even scale them. And I can also delete them. So this is really cool because this allows me to have finite control over a piece of foliage and still use this tool to apply foliage to a massive area. If we look further down, there are also a bunch of different options inside of the tool that control things. At the top, the painting, this is going to control the density. And as well as the size of the various instances that we're painting. So if I was to set this to 1.5, we would get some between 1 and 1.5."},{"start":"1:34","end":"2:05","startSec":94.9,"text":"Let me set this to 0.5. Make it a little bit smaller. There we go. So we get a little bit of variety. We also control the density and the radius here. So the radius, if I was to set this to, say, like 200, what this will do is it will ensure that they don't actually intersect with one another. By providing a radius around it that it should spawn. Now a great way to find this number here is if we just double click on this mesh. Not that way. Let's just browse to this."},{"start":"2:05","end":"2:36","startSec":125.0,"text":"There we go. And if we look at the approximate size here in the Static Mesh Editor, it's 122. So 122. If we use that number here, that's going to be a great way to kind of use for our radius for this particular object. We can also add other objects by simply just dragging and dropping right there. And then now we have chairs and bushes. If we right click on the chair here, we can also remove it, or we can replace it with something else."},{"start":"2:36","end":"3:04","startSec":156.1,"text":"I'm just going to remove that. I'm going to say yes. There we go. So what I want everybody to do now is just spend some time applying foliage to your project. And this is what you can get. This is using some content from FAB. There's a few stones and things like that. We're just all randomly scattered throughout using the foliage tool. So I want everybody to take some time now to use the foliage tool and adjusted settings and paint some foliage on your landscape and see what you get."}],"06_Outro":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"And with that, that is going to wrap things up for this video tutorial. So we first started this video tutorial by creating a new landscape. We then took a look at some of the tools that we could use to sculpt our landscape. We then took a look at how we could create a material that allowed us to paint different landscape layers, giving the illusion that we had things like brass, rocks, and dirt. And then finally, we finished up with looking at how we can use the foliage tool to apply"},{"start":"0:31","end":"0:47","startSec":31.3,"text":"various bits of foliage to the landscape and paint and interact with those foliage actors so that we can adjust them or scale them or even delete them. With that said, I want to thank everybody for listening. It was my pleasure having you and I will see you next time."}]},"111.02":{"01_Introduction":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Greetings everybody, my name is Sam Dider and I'm a senior Unreal Engine instructor with Epic Games. In the following video tutorial series, we're going to be taking a quick look at how to use the water tools inside of Unreal Engine 5. This is first going to start with us enabling the water tools plugin and restarting the editor. We're then going to take a look at how a world needs to be set up so that the water tools can be utilized inside of that world. We'll then take a look at each of the tools by exploring the ocean, lake and river tools"},{"start":"0:33","end":"0:49","startSec":33.3,"text":"individually. We'll then take a look at how we can bind all of the tools together in one single map and then we'll finish up by talking about waves and buoyancy. We've got a lot to cover, so let's go ahead and get started with enabling the plugin."}],"02_EnablePlugin":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Before we can begin to use our water tools, we need to enable the plugin inside of our project and restart the editor. Now to do this, all you need to do is simply go up to the plugins menu, look for the water section and then enable water. You can enable buoyancy water actors and water advanced to see more examples of how to utilize different features of the water tools. Let's just pop over to the editor and look at this now. So from our editor, we'll come up to our edit plugins and then from our plugins menu,"},{"start":"0:32","end":"1:07","startSec":32.5,"text":"we will scroll all the way down here to the bottom and look for water. Once we've located the water, we simply enable the plugins that we want and we'll see a little restart editor pop up down here or in the lower right hand corner of the editor. Once we have restarted the editor, we can go up to the quickly add, type in water and we should see something like the following which is going to show us all of the water tools we have available. Let's go ahead and check that now in the editor. With the editor open, we go up to our quickly add, type in the word water and then we should see the water body ocean, lake river, shallow water and all of the other parts of the plugin"},{"start":"1:07","end":"1:21","startSec":67.8,"text":"that are available to us. Once we have established that all of this is enabled and working, we are ready to move on to the next part which will involve setting up our world so that we can use these tools in any way, shape or form we wish."}],"03_WorldSetup":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Now, before we can utilize the water tools in any of our levels, we need to create a level that has a landscape actor in it. So to do this, what we're going to do is we're first going to create a basic level by coming here to the editor, going to File, New Level, and then selecting the basic from the New Level dialog. Once we have done that, we're going to go ahead and delete this static mesh here. So I'm just clicking on the floor and pressing Delete. And the next thing that we need to do is we're going to go up to our landscape and we're"},{"start":"0:31","end":"1:05","startSec":31.1,"text":"going to add a new landscape. The one thing that we need to make sure that our landscape does have enabled is this Enable Edit Layers. The reason we need this is this is going to enable the option for our landscape to have multiple layers. And our water tools work on these layers as the water tools can directly affect the look and shape of our landscape. So let's go ahead and set that up now. So again, we're going to come up here to our selection mode and we're going to go to landscape we're going to make sure we're on Create New Landscape. We have Enable Edit Layers on by default and then we're just going to hit Create."},{"start":"1:05","end":"1:18","startSec":65.4,"text":"And once we've done that, you can see here we have our landscape ready to go. So we're going to get out of landscape mode and get ready to, in the next section, explore the different tools that make up the water tools."}],"04_OceanTools":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Now that we have everything set up so that we can use the ocean lake and river tools, let's take a look at each one of the tools individually starting with the ocean tool. Now to add the ocean tool to any of our projects, all we need to do is go up to the quickly add and type in the word ocean and then click or drag the water body ocean into the map. Once we do that, we're going to get something that looks similar to this. So let's go over here to the editor and do this now. Inside of the editor, we're going to come up here to our quickly add."},{"start":"0:31","end":"1:05","startSec":31.7,"text":"We're going to look for ocean and then we're going to do our water body ocean like so. This insert new landscape edit layer. This is telling us where do we want to put this layer in relation to our other landscape layers. For us, we just have the single water, so we're going to leave it as default and hit complete. And when we do that, there we go. We have got our landscape here with our water and site of it. Now, one of the things that we do need to do is move this over. We always want to make sure that the spline that you're seeing here that represents our landscape area"},{"start":"1:05","end":"1:37","startSec":65.7,"text":"is inside of the landscape actor itself. If it goes outside of the landscape actor, you're going to see that issue that we just had. One of the other things I like to do just to make sure that there are no issues is just zero out the X and the Y. Now, we can adjust the landscape's height. We can push it down and things like that. The other thing we can do is we can adjust these little spline points right here to adjust the look. And feel of the landscape. And now if we right click on one of them, we can add a spline point like so, so that we can actually kind of rough around the shape of our landscape here."},{"start":"1:38","end":"2:09","startSec":98.8,"text":"To look kind of similar to something that we are trying to achieve. Now, there are a couple of ways that we can adjust the way that the landscape and the water intersect with one another. Underneath the ocean itself, you're going to find a terrain and a water height map settings. Now, every single water actor that you are going to encounter are going to have these settings and they all work in a very, very similar manner. What we can do those for is first, let me just pop over here to the editor really quick."},{"start":"2:09","end":"2:41","startSec":129.6,"text":"What we can do is first we can come over here and if we go to our curve settings, the first one is adjusting how the landscape and the water intersect with one another. So if I take this channel depth here and I put this really shallow, what this is going to do is this is going to give us a very, very shallow entry into the water, much like you would find at a beach. If I take this number and I increase it really, really high, it's going to make that drop off really, really, really steep, much like you would find it."},{"start":"2:41","end":"3:16","startSec":161.0,"text":"Maybe the ocean and the cliff and notice the waves as well. The waves will actually react to the channel depth. So the sharper that drop off is, the steeper the waves are going to be, the shallower that drop off, the more shallow those waves are going to be. And you can see here, it actually does kind of have a shallow waves here towards the beach. And then as it gets deeper, the waves get more and more intense. The next area that we're going to adjust is going to be the terrain settings, which can help us give a more natural look to our our landscape just by editing a few parameters."},{"start":"3:16","end":"3:47","startSec":196.3,"text":"So this was actually achieved by just editing the curl noise and falloff settings. So if we come back over here to the editor, let me just zoom out so we can see stuff a little bit better. So the curve settings under here, under this part of the train are going to affect the water and the beach interaction. The height map settings that we have over here are going to affect this as a whole. And if we come over here to effects and we do something like a curl noise and we do something like a point one, two, five, maybe we do like a little bit more here. We can get some start to get some really cool effects."},{"start":"3:48","end":"4:31","startSec":228.2,"text":"But just be aware that the more intense the numbers that we put in here, you know, if we were to put in like something like 16, we're going to get some really, really, really crazy results. Just keep that in mind that lower numbers tend to work a little bit better here. Now, one of the other things that you might encounter is having the landscape water not intersecting or creating a little bit of a hole with your terrain. And the easiest thing to do that is to either grab your landscape spline points and move them in so that the water occupies that area or just add a few more spline points by simply right clicking on them and adding a point here and then finessing that point so that the water mesh will go up against the landscape."},{"start":"4:31","end":"5:01","startSec":271.2,"text":"And there won't be this missing piece of water. Now, again, this only happens when you start to really push the editing inside of the landscape in the water body ocean here and under the terrain settings, the water height map. If we start to push the effects like our curl noise very high, that's when we're going to start to see some of these artifacting. Now, there is one other thing that I want to talk about and that is the LOD. Now, by default, it is going to have the LOD on. Older versions of Unreal did have this defaulting to off."},{"start":"5:02","end":"5:37","startSec":302.1,"text":"And what this level of detail actually does is it makes sure that the most active or the highest concentration of the simulation for the water is happening at the shore and closest to the camera. And then after a certain point, it's going to go to a completely flat static mesh that is much cheaper to render. And in order to adjust that, if we click on our water zone down and rendering under our far distance, we're going to see this far distance mesh extent. And this is going to allow us to push that far distance mesh really far back into the distance or bring it up closer should we want to do that."},{"start":"5:37","end":"5:49","startSec":337.4,"text":"Now, again, by default, it's set to, I think, 400,000 here. So you're probably not going to need to adjust this, but it is something that is nice to know about in case you need to adjust it for a future project or something of that nature."}],"05_LakeTools":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Now that we have created our ocean tool, let's take a look at creating our lake tool. Now to add our lake, we do exactly what we did before. We go up to our quickly add, we search for lake, and then we click and drag and drop it, and we're going to get something that looks kind of like this. Not exactly, but let's pop over to the editor and have a look now. So again, quickly add, we're going to type in the word lake, and then we're going to add our water body lake, and there we go. We've got our water body lake added right to our particular map. Now same with the ocean, we can click on the individual points here and adjust them."},{"start":"0:33","end":"1:03","startSec":33.2,"text":"We can also right click and add spline points. If we come to our water body here and we go down to our curve settings here, we can adjust the channel depth. Remember this is going to act as the basically deepest point in our lake, and then we can adjust the curve ramp width here. This is going to affect the fall off. And then underneath our water height map settings, we can do affect our fall off settings here by affecting how the lake is going to go from the existing terrain down into the"},{"start":"1:03","end":"1:34","startSec":63.9,"text":"lake itself. We can also do all types of cool effects. We can blur. We can also add a little bit of curl noise. Maybe one was a little bit too much, but we could do something like that. There we go. Point five gives us some kind of cool results. So add just a little bit more in there. We got some interesting looking lake going on right there. But again, with the ocean and the lake tools, you're going to see that all of the settings do virtually identical stuff. So once we have kind of gone over the settings once, applying them and using different settings"},{"start":"1:34","end":"1:50","startSec":95.0,"text":"is of trivial importance because once you've learned how they work once applying them to other things is going to be very repetitive, but also super simple because you've done this once already and you kind of know what each one has done."}],"06_RiverTools":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"We're now going to take a look at adding rivers to our particular maps. Now to use the river tools, again like we did with all of the other ones, we simply search for water body river and then we click to add the river to our map. We're going to get something that looks like this. So let's go ahead and do that now. So we're going to come in here and we are going to go river and then we're just going to click this water body river and we have added the river to our particular map. Now with rivers, what we want to do is select our individual points here and just kind of"},{"start":"0:34","end":"1:06","startSec":34.7,"text":"drag them along to make the river longer. If we right click on them, let me just put the river all the way across the map like this, right click, add spline points. We can start to add various bends and shapes inside of the river that make it look a little bit more like a river and a little less made inside of a computer. If we come back to our water body river instance here, let me just pull this up so we can look, just make sure that we're on it. There we go. Underneath our terrain, you can see here we have our channel depth, which again is going"},{"start":"1:06","end":"1:36","startSec":66.3,"text":"to control the depth of the river right here. So if we want a shallow river, we can set this to something like, you know, four or seven. We'll get something that's very shallow. We can adjust the ramp width, which will make the river narrow or wider. However, there are a couple of other things that the river tool has the other tools do not. And that is if we click on the individual points and look for the water, we have our depth, river width, velocity and audio intensity."},{"start":"1:36","end":"2:10","startSec":96.9,"text":"So the depth and the river width are going to be some properties that you mess with a lot, as well as the velocity. Now velocity controls how fast the river moves in a given direction. So if we want the river to go one, one way, we make it positive. If we want the river to go another way, we make it negative. So let's just take a look at that right now. So I'm going to come in here and I'm just select this one right here. We're going to come all the way up to the top under our selected points and then water. So depth, I can make this like 64 to make the river really, really shallow."},{"start":"2:10","end":"2:42","startSec":130.2,"text":"And then maybe I do this like, we'll just do the times two to make it 4096. So I make the river very, very wide there. The other thing I can do is set this velocity. If I set this to zero, we're going to see there is no velocity there. If I set this to a negative 128, we're going to see it actually flows the other direction. One of the other cool things that you can do with rivers is that we could actually have a bunch of rivers all put together. So let's look at how we do that now. All we need to do is either duplicate this river by holding alt and not alt. I want the whole, whole river."},{"start":"2:42","end":"3:16","startSec":162.3,"text":"There we go. Holding alt and duplicating the entire river. And then what I can do is I can rotate this and they will actually intersect with the other river bodies. So you can see here, they're both intersecting. We got one flowing one way and one flowing the other way. We can take them apart. They can flow across a river and then, you know, do something like that. So we have actually two that are intersecting and then going, going across. So that's some really cool, interesting stuff that we can do here. And again, if we just, you know, right click, add a right click, add a spline point here,"},{"start":"3:16","end":"3:36","startSec":196.6,"text":"we can get some really interesting looking shapes. And then much like in this image here, we have a three different rivers that are all crossing each other and going in and flowing in all together. So really, really great stuff and interesting stuff that we can do with the river tools, especially considering we can add multiple rivers to them."}],"07_CombiningAllTools_56-":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Now that we have seen how all the tools work individually, let's take a look at using them all together. What we're going to try to do in this part of our tutorial is take the lake, river and ocean tools and set up something that looks like this, where we have a lake that leads into a river that leads into the ocean. So this is going to be pretty easy for us to set up. So let's go over to the editor now. So this is just a level that we have created before. Remember, it's got a landscape in it. And first thing we're going to want to add here is our ocean."},{"start":"0:33","end":"1:06","startSec":33.7,"text":"So we're going to put in our ocean. And then what I'm actually going to do is I'm going to come over here and zero out the x, y and z location of our ocean just so that we have something that looks like that. Alright, then what I'm going to do is I'm going to come in here, I'm going to look for our lake. I'm going to add our water body lake. And I'm going to position our lake so that it sits on top of the little bit of a surface that is created from our ocean. And then last but not least, I'm going to put in a river. And then we're going to need to take this river and actually drag it down"},{"start":"1:06","end":"1:40","startSec":66.6,"text":"and then move it over. There we go. We could move it this way. And the other thing we're going to need to move these splines over so that they kind of intersect with our river. Whoa, that was a little bit too far over. So let me hit Ctrl Z to undo that. We're going to do something like this. And one of the other things that you are going to want to make sure, notice that we don't get this really great transition between the river and the lake here because they're at different heights. So what we want to do is we want to make sure our water body lake here is at 280. And then we're"},{"start":"1:40","end":"2:11","startSec":100.4,"text":"going to grab our river here and we're going to say 280. And that way we have them both on the same the same level so that they are not giving us that really weird looking transitional piece. So here, don't forget our river is also flowing backwards. So we can change this just by going negative 128. And that is going to push this going the other direction. So here again, we can do negative 128. And then here right here, we can also do negative 128. And that's going to push our"},{"start":"2:11","end":"2:43","startSec":131.9,"text":"river down. So let's hold Alt and just kind of drag some of these down here. And we're going to have to kind of make start making stuff go down a little bit. So remember nice, even nice easy, I should say ways to get down and we'll eventually make it down to the water all the way down here. So we can fix some of this with some adjustments afterwards. So get the"},{"start":"2:44","end":"3:18","startSec":164.4,"text":"water coming down here. Now one of the interesting things that we would want to do here, if we grab our last point here, and we take this actually this is our last point here, we take this, we're going to set this to zero. And if we set this one to zero as well, we'll get a really nice transition between what is kind of coming down the hill and what is going into the water. So you know, this is just going to take a little bit of work here to kind of make things look more like a river, pulling things down, pushing things back up. Maybe we add some more spline points to"},{"start":"3:18","end":"3:49","startSec":198.2,"text":"give us a little bit more elevation to work with. And this is really how we're going to make our thing look like a river. Don't forget, we can also come in here and change this to say 1024, you know, make things a little bit more narrow and easier to work with. We can grab both of these ones and hit them to 1024 just to make things a little bit more narrow. And we'll select all of these just by holding down control and set them all to 1024. There we go. Look at that. That just"},{"start":"3:49","end":"4:28","startSec":229.8,"text":"gives us a lot easier, more narrow narrowly defined river to work with. So there we go. We got all that. So that is coming down into the ocean right there. So that's looking pretty good. Maybe add a little spline point there. Bring it down a little bit, bring this one down. You know, it's just a little bit of finessing. Look, we've got a little bit going outside over here. So we might just want to bring this over. Maybe we adjust the point like that and bring that over. Maybe we add a new spline here so we can do something like this. So and then we have the also remember that we have"},{"start":"4:28","end":"4:59","startSec":268.2,"text":"the ability to come here and do things like we add a little bit of maybe curl noise. There we go. Mess up the rivers of values a little bit. Do the same thing for our lake here. So we're going to go up and we're going to look for our our terrain here and water height map settings effects. And we're going to go to our curl noise. Do like a point two. There we go. We like a point one, two, five. We get some interesting results here. We might want to do this for our overall water itself."},{"start":"4:59","end":"5:33","startSec":299.4,"text":"So we're going to go to our water body ocean. Remember, we come down here to our point two. There we go. And point one, two, five. So we get some cool looking results. And that is basically using them all together. So what I want everybody to do is just take a little bit of time before moving on to the next portion in this tutorial and just mess around with the different settings here and kind of moving things around trying to get your landscape to match the river's surface. Don't be afraid to also come up here into your landscape and try and use some of the the landscape"},{"start":"5:33","end":"6:07","startSec":333.8,"text":"tools, maybe smooth things out. You know, we can also add another layer here. So we will just do edit layers and hit select. And then we can do all types of stuff we can sculpt up, or we can sculpt down. There's a lot of things that we can do here to try to finesse the landscape to make it so that it will fit this river a little bit better. So you know, just spend some time now trying to do that. We can you know, there's just all types of really cool stuff we can do. We can run some erosion on these hills and give them like a really cool looking weathered look. So again, a lot of stuff that we"},{"start":"6:07","end":"6:27","startSec":367.6,"text":"can do here to get us to have something that's similar to this. So again, spend the next five to 10 minutes just messing around with the various settings and seeing what you can create and seeing how simple it is to use these tools to make something that can fit whatever your needs are for rivers, lakes or oceans."}],"08_WavesBuoyancy":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Now that we're done with waves, let's move on to buoyancy. Now buoyancy allows objects to float on top of the surfaces, but not only just that, we can actually have buoyant objects that are say in a river, and they can actually use that river's velocity to drag them from the river down to the ocean. Now there's a couple of things that we need to do. First off, we're gonna need to make sure that we use the buoyancy component and set up something called pontoons, which allow us to see where things are floating,"},{"start":"0:32","end":"1:03","startSec":32.8,"text":"or not see where, but work as areas where things are gonna float from. So let's go ahead and set this up now. So what I'm gonna do is hit Control Space, we're gonna right click, Blueprint Class, base this off of actor, we'll just call this BP Floating Actor, and then double click on it to open it up. Bring this over here so that we can see it. So the first thing we're gonna add is a cube. So we're gonna add a cube right here like so. We do need to add a couple of other things."},{"start":"1:03","end":"1:34","startSec":63.2,"text":"So we're gonna make the cube the default scene root. This is important because this has to happen in order for buoyancy to work correctly. Also with the cube selected, we're gonna do a simulate physics, and we're gonna set our mass KG enabled. Then we're going to add a BU buoyancy component, and then next we need to add a box. You want this box collision, and the box collision, we're just going to pop it out once so that we can go,"},{"start":"1:34","end":"2:05","startSec":94.2,"text":"if we go out once like that, and then bring it back in one, we'll get a perfect box collision looking. So if we go to our wireframe, we'll see here it's exactly what we wanted. And then what we need to do is select our buoyancy here, and underneath the buoyancy, you're gonna see a bunch of things that we want to enable or adjust. So first things first, we're gonna go up to pontoons. We're gonna go one, two, three, and four, and we're gonna set this first one at 50 and 50, and we're gonna change its radius to 50 as well."},{"start":"2:05","end":"2:37","startSec":125.1,"text":"And then for the next pontoon, we're gonna go negative 50, negative 50, and we're gonna set its radius at 50 as well. So basically we're gonna be putting a pontoons on this, or areas where this can float in all four corners of our box. So to continue to this, we're gonna go 50, negative 50, and then we're gonna set this one to 50 as well. And then for this one, we're gonna go negative 50, 50, and then finally 50 here. So that is all we've done. We've just literally set all of these to 50."},{"start":"2:37","end":"3:07","startSec":157.0,"text":"Then once we have done all of that, we are gonna come here and we're gonna apply drag forces in water, and then we're gonna allow lateral push, allow current when moving fast upstream and apply downstream angular rotations that things will rotate, because we're gonna make one that kind of does all of our needs. So let's go ahead and compile and save. And once we run this, what we're gonna be looking for is something kind of similar to this, where we have all of these objects out off in the distance, and as we drop them in,"},{"start":"3:07","end":"3:38","startSec":187.4,"text":"they are gonna come from the distance into the actual beach, and the same thing with our river. So let's pop over here to our editor, and I'm gonna close this, and let's go up here and try this out right here. So we're gonna hit Control Space, we'll bring in our floating actor, we'll put it right above this, close that, and then we're just gonna hit Alt S to simulate, and let's see what happens. So there we go, it's coming through, it's bobbing up, all right, that's working. Now you can see it is moving, so it's starting to get some speed there."},{"start":"3:41","end":"4:12","startSec":221.4,"text":"And there we go, it's starting to take off, it'll go down, and that's pretty cool, right? It's being pushed along with that river, and we didn't have to do anything other than add our buoyancy component here. So let's go ahead and we'll hit Control Space again. This time though, I'm going to maybe increase this to a value of five, bring it up a little bit, let's just hit Alt S to see what will happen, and check this out. And yep, there we go, it's kind of bobbing along. Now there is one command that we can use here"},{"start":"4:12","end":"4:45","startSec":252.3,"text":"if we want to diagnose what's going on. If we enter the command r.water.boyancydebug set to one, this is going to show us the water debug. So those little red things that you're seeing here, those red spheres, those are our pontoons that we set up before, okay? So you can see them, they are covering the entire object there, and we can see them kind of over here as well. So this, and the green area is showing us how this is simulating with the surface."},{"start":"4:45","end":"5:16","startSec":285.2,"text":"So we're basically running a simulation underneath the surface that we are then mapping this buoyancy to, and that is how we can see these waves. So if I go ahead and hit stop here, and maybe I just make a couple more of these, whoa. You can see some really awesome results that we can do with this. So let's just hit Alt S, because the last little tip that I want to leave you with is this, if we, I'm just going to hit stop really quick, if we come to one of these and we hit control E to open it up, and we are simulating,"},{"start":"5:16","end":"5:47","startSec":316.6,"text":"we can actually grab our buoyancy here, and we can start to adjust some of these parameters, and we can see what the effect is going to be on the buoyancy kind of in real time. It gives us a better idea of what is going on so that we don't necessarily have to restart our simulation each time. We want to just kind of understand what these values are doing and how they affect our objects. Remember, if you do want to disable, oops, and I didn't want to do that, what I wanted to do is hit F and then hit the Alt S again."},{"start":"5:47","end":"6:01","startSec":347.6,"text":"If you want to get rid of this little debug here, that's, remember, we just need to come back to our console. I'm going to press up and then set that back to zero, and we will get rid of that debug information, and we'll have back to this view right here."}],"09_Outro":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"With buoyancy and waves now completed, that's going to bring us to the end of this video tutorial series. So we first started this video tutorial by showing you how to enable the water plugin. Remember, once you've enabled it, you do need to restart the editor. We then showed you how to set up a world. Remember the water tools, no matter which one you're using, does require a landscape in order to work. So make sure your worlds do contain that so that you can utilize those tools and your projects. We then took a look at the ocean, lake and river tools individually and how, although they do widely different things,"},{"start":"0:36","end":"1:06","startSec":36.0,"text":"their controls on them are actually very similar. We then took a look at how we combined the river, lakes and ocean tools together in a single map to give us a landscape that's got a lake with a river that goes into the ocean. And then we finished with covering waves and buoyancy. Remember waves can be stored to an asset to allow us to take this very complicated, but very powerful tool into an easy to use asset"},{"start":"1:06","end":"1:37","startSec":66.0,"text":"that we can share between our rivers, lakes and oceans. And then we also touched on buoyancy, which allows objects to float. Remember, we can have objects also be pushed by the streams so that they can go into the lakes and even into the oceans and in the oceans and lakes, they can bob up and down. So that is going to do it for us for this video tutorial about quickly starting with the water tools. My name is Sam Dider. I'm a senior Unreal Engine instructor with Epic Games. It was my pleasure having you and I'll see you next time."}]},"113.01":{"01_Introduction":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Hello and welcome to MetaHuman Introduction. My name is Gabriela Crisenio-Tacas and I will be your host for this course. In this course we will begin with an overview of the MetaHuman framework and MetaHuman sample projects. From there we will go over how to access the MetaHuman creator using the Quixel Bridge Unreal Engine 5 integration and go over some additional assets we can download with the Quixel Bridge standalone application."},{"start":"0:33","end":"1:05","startSec":33.0,"text":"Then we will dive into the MetaHuman creator and explore all of its tools. From there we will move into a hands-on session for creating a MetaHuman in Engine with the MetaHuman plugin using a RealityScanFaceScan asset. We will also go over how to bring a MetaHuman into Unreal Engine and go over some best practices when working with them in your project. We will wrap up this course with some final recommendations by going over how MetaHumans"},{"start":"1:05","end":"1:40","startSec":65.7,"text":"can be used for vertical specific applications and I will provide you with some tips and resources for continuing your work and training with MetaHumans. This course will be using the project MEH9130055 and the level map should load automatically. The map is located in the content browser under the courses folder labeled MEH11301"},{"start":"1:40","end":"2:13","startSec":100.3,"text":"in the course maps folder and it is named MEH11301MAP. This course will also use a RealityScanFaceScan asset with textures. The asset is located under the assets folder in the folder named scanMesh. Additionally the original OBJ file and textures have also been provided in the source files folder named 11301 RealityScan associated with this course."},{"start":"2:13","end":"2:46","startSec":133.7,"text":"If you need to reference the location of the course map that can be found at the beginning of the slide deck after the training outline. Now as we go through this course you will find that many slides in this presentation contain a lot of information and I will summarize all of that for you but if at any point you want to read what is on each of those slides feel free to pause and dive right in. Now let's move on to the first section of this course and begin by exploring the MetaHuman framework and some MetaHuman sample projects."}],"02_GettingStarted":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In this section of our course, we will get started by learning about the MetaHuman framework and MetaHuman sample projects. Let us begin with the question, what is a MetaHuman? MetaHuman is an Epic Games product that democratizes the creation of engine-ready, high-quality digital humans. MetaHuman Creator, released in 2021, is a cloud-based application, allowing users to create fully rigged, high-fidelity digital characters that can be brought to life in"},{"start":"0:32","end":"1:08","startSec":32.9,"text":"Unreal Engine easily. This brings us to the next question, which is, what is the MetaHuman framework? The MetaHuman framework is the culmination of decades worth of bleeding-edge research and collaborations with three-lateral and cubic motion, which are part of Epic Games. MetaHuman, based in Serbia, specializes in creating digital humans using cutting-edge scan technology and rigging. Cubic motion, based in the UK, and presently under the three-lateral banner, is focused"},{"start":"1:08","end":"1:44","startSec":68.2,"text":"on performance-driven, facial animation solutions. The MetaHuman Creator presets are derived from three-lateral's MetaHuman framework, using their database from having scanned people's appearances and geometry. The MetaHuman framework is made up of a variety of collaborating parts, and the assets include the body and head meshes, skeletons and control rigs, animation blueprints, materials and animated maps, clothing, grooms, MetaHuman DNA, and rig logic."},{"start":"1:44","end":"2:04","startSec":104.4,"text":"A more in-depth look at the assets that make up the MetaHuman framework are covered in the MetaHuman blueprints and animation course, and the MetaHuman DNA calibration courses. Now, that's it for this section. Next, we will take a look at a few MetaHuman sample projects worth exploring."}],"03_ SampleProjects":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Now, let's take a look at a few metahuman sample projects that are available for free on FAP. With the release of Metahumans in 2021, the Metahuman sample project was made available. This project includes a cinematic sequence with high quality body and facial animations. I have included one of the face and body animations from here, located in the course project assets folder inside the folder named Animations."},{"start":"0:33","end":"1:06","startSec":33.2,"text":"We also have the Metahumans lighting project released in 2022, and this includes lighting presets made with the help of cinematographer Greg Frazier and three created for the Matrix Awakens Unreal Engine 5 experience. I have included the maps from here in the course project assets folder inside the folder named MH Lighting. The game animation sample project released in 2024 showcases fully functional animation"},{"start":"1:06","end":"1:41","startSec":66.5,"text":"systems and includes hundreds of animations and retargetor setups for UEFN skeletons to Metahumans. We also have the UEFN Talisman demo, which allows users to explore the Olympic cloth simulation and optimization of Metahumans for UEFN. Two other projects worth mentioning are the City Sample Project from the Matrix Awakens Unreal Engine 5 experience released in 2022 and the ML Deformer sample project, which"},{"start":"1:41","end":"2:09","startSec":101.6,"text":"showcases Unreal Engine's machine learning technology to create deformations driven by muscle, flesh, and cloth simulation. Both of these projects use characters from the Metahuman framework, although they are somewhat different from the standard ones downloaded from Quixel Bridge. Now, let's move on to the next section of this course where we begin our journey in creating Metahumans using the Metahuman Creator."}],"04_MetaHumanCreator":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"In this section of our course, we will begin by learning how to access the MetaHuman creator using Quixel Bridge. And from there, we will dive into the MetaHuman creator and explore all of its tools. Let us begin our journey by first learning how to access the MetaHuman creator using the Unreal Engine 5 Quixel Bridge integration, and then look at some of the additional assets we can download with the Quixel Bridge standalone application."},{"start":"0:30","end":"1:01","startSec":30.1,"text":"So let's jump into Unreal Engine and go through the steps. To access MetaHumans directly in Unreal Engine, in the main viewport, go to the Get Content panel and select Quixel Bridge. With Quixel Bridge open, ensure you sign in using your Epic Games account. On the top right, go to Preferences and ensure you have a Megascans folder path assigned."},{"start":"1:01","end":"1:33","startSec":61.8,"text":"Now, select the MetaHuman's option in the Quixel Bridge menu. Then select a preset MetaHuman. And then on the right hand side, over here, select Start MetaHuman creator. The browser will open and prompt you to select the engine version you wish to work with. And from here, select Launch MetaHuman creator."},{"start":"1:33","end":"2:04","startSec":93.8,"text":"Now before we move on, let's do a quick review of the steps we just covered. To access MetaHumans directly in Unreal Engine, use the Get Content panel to access Quixel Bridge. Sign in using your Epic Games account and inside of Preferences ensure you have a Megascans folder assigned. From there, select the MetaHuman's option in the Quixel Bridge menu."},{"start":"2:04","end":"2:42","startSec":124.4,"text":"Select a preset and then select Start MetaHuman creator. Once the browser opens, select the engine version you are working in and then launch the MetaHuman creator. Now let's take a look at using the Quixel Bridge standalone application for use with MetaHumans. The Quixel Bridge standalone applications allows for Maya and Zebra scopes to be downloaded for DNA files to be accessed and for exporting MetaHumans to Unreal Engine 4.27."},{"start":"2:42","end":"3:15","startSec":163.0,"text":"Begin by going to the web browser link for Quixel Bridge and sign in with your Epic Games account. From there, download and install the application. The Quixel Bridge plugin will be located in the Epic Games launcher and should automatically install along with the latest versions of the engine. Now let's jump into the Quixel Bridge standalone application and take a look at some of our options."},{"start":"3:15","end":"3:47","startSec":195.8,"text":"Inside of the Quixel Bridge standalone application, navigate to the Quixel Bridge menu on the top left and select the MetaHuman's option. Then select MetaHuman presets for the engine version you are using, which in our case will be the MetaHuman presets for Unreal Engine 5. By selecting any MetaHuman preset, you can access the MetaHuman creator by selecting Start MetaHuman creator over here on the right."},{"start":"3:47","end":"4:24","startSec":227.8,"text":"You can download and export MetaHuman presets or ones you've created to Autodesk Maya. To do this with a MetaHuman selected, go to the bottom right and over here if you click here next to the resolution option, you can select the download or export settings. We are going to select the download settings first. In the download settings, go to models and make sure the download option for MetaHuman is set to source assets."},{"start":"4:24","end":"4:56","startSec":264.6,"text":"If you are using Unreal Engine 4.27, set it to UAsset and SourceAsset. Now let's go back and select export settings. In the export target tab, change the export target to Autodesk Maya and install the Maya plugin if it is not already installed. Upon opening up Autodesk Maya, the MS plugin pop-up will appear, which means the plugin has been successfully installed."},{"start":"4:56","end":"5:31","startSec":296.4,"text":"The next step is to download a MetaHuman by going to the bottom right corner and selecting download. A green check mark will appear indicating that the download process is complete. Now if you want to export this to Autodesk Maya, with the blank Maya scene open, you can select export. Another thing you can do is access the MetaHuman DNA and Maya Source Assets files by going to the vertical ellipsis right below the thumbnail and select go to files."},{"start":"5:31","end":"6:01","startSec":331.8,"text":"This will open up the location of the downloaded assets in your Megascans folder. Now let's do a quick review of everything we've just covered. We have just gone over how to select MetaHuman presets for Unreal Engine 5 inside of the Quixel Bridge standalone application. We've also covered that we need to change the download settings to SourceAssets and the export target to Autodesk Maya"},{"start":"6:01","end":"6:30","startSec":361.8,"text":"along with installing the Maya plugin. The MS plugin pop-up icon will appear in Maya ensuring the plugin is installed. We've also learned how we can locate and access our downloaded assets in our Megascans folder such as our MetaHuman DNA and Maya Source files. Now that we have covered this information, let's dive into the MetaHuman creator."}],"05_MHCSculptFaceControls":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In this section, we will explore the cloud-based MetaHuman Creator toolset. Once you select Start MetaHuman Creator, select the engine version you wish to work in, and then launch the MetaHuman Creator, it will take a few moments for the Creator to load. Once our browser is finished loading, we can now see that we can create a MetaHuman using one of the presets. If you have already created one, you will be able to find it in the My MetaHumans Gallery."},{"start":"0:32","end":"1:02","startSec":32.0,"text":"We will start by choosing a MetaHuman preset, and with this selected, on the bottom over here, we are going to click on Create Selected. Now, let's get acquainted with the MetaHuman Creator interface. Inside of this window, on the top left, we have our main menu with the name of our MetaHuman, which we can modify. Right below, we have the Environmental and Quality toolbar."},{"start":"1:02","end":"1:37","startSec":62.0,"text":"We can control settings such as the environment by choosing from a variety of backgrounds and lighting presets. Over here, we have the Camera View, where you can select six different camera presets, or use one to six on your keyboard to switch between them. The Render Quality allows you to select the quality of lighting, hair, global illumination, and ray trace reflections. Over here, you can view all of the available levels of detail for your MetaHuman."},{"start":"1:37","end":"2:11","startSec":97.0,"text":"The Toggle Clay Material replaces the skin texture with a clay-like material, making it easier to see the shape of certain facial features such as the eyes and lips. The Toggle Hair enables and disables hair rendering. And here, we have the hotkey reference on the right, and we can toggle this on and off if we wish. Then, over here on the left, we have the Sculpting toolbar. There is a Blend Mode, Sculpt Mode, and Move Mode."},{"start":"2:11","end":"2:42","startSec":131.0,"text":"The Attributes and Property selection allows you to select areas you want to customize. And finally, we have the Animation toolbar, which is where you can control face and body animations that play on your MetaHuman in the Viewport. Now that we are acquainted with the Viewport, let's explore some of the tools we have available to us starting with the Sculpting toolbar. The Blend tool allows you to blend between three to six MetaHuman presets."},{"start":"2:42","end":"3:16","startSec":162.0,"text":"You can use the control points to change the shape of your MetaHuman's facial features. Drag any MetaHuman preset to a slot on the Influence Circle. I'm going to add Ada here, and then add Amelia over here, and Bernice over here. The Blend Spaces allow you to blend per region. If I move the control point on the nose closer to Ada, Ada's nose will blend with the nose of our MetaHuman."},{"start":"3:16","end":"3:50","startSec":196.0,"text":"I can also blend it with Amelia's nose or Bernice's nose. Now, if you want to undo a change you have made, you can use this back arrow up here to revert back to the previous state. Now, let's take a look at the Sculpt tool. This allows direct manipulation with the finest level of control. Think of this as an IK face control with the control points as the end effectors manipulating the geometry endpoints."},{"start":"3:50","end":"4:22","startSec":230.0,"text":"When this is enabled, two additional options become available. Symmetry controls how to mirror edits from one side of the face to the other with the exception of the eyes. You can mirror edits from left to right, right to left, or leave it set to average. You can also turn symmetry off. I will leave this set on and set it to average. The Sculpting plane controls what view plane individual markers are moved in."},{"start":"4:22","end":"4:55","startSec":262.0,"text":"The Closest plane constrains the Sculpt markers to the front or side plane depending on which one of them is closest to the current camera angle. This is enabled by default. Take note of how the Sculpt marker moves when in this mode. Now, let's switch to Screen plane. This moves the Sculpt markers in a screen plane that is projected onto the 3D world from a particular camera angle. We can see this moves a bit smoother in different directions."},{"start":"4:55","end":"5:31","startSec":295.0,"text":"And this has a similar functionality to some modeling applications such as Maya. Now, let's take a look at the Move mode. This allows us to make adjustments to broad regions of the face. As I move this, we can see this allows us to move a group of markers at the same time. And we can see what this looks like by using it to adjust the nose area. Let's stop here for a moment and do a quick review of everything we've just covered before we move on."},{"start":"5:31","end":"6:02","startSec":331.0,"text":"We have become acquainted with the MetaHuman Creator interface and where all of our tools are located. We've also gone through the Sculpting toolbar options. Something to note about the Lend mode is that it overwrites any changes already made using the Sculpt or Move tool. Moving a preset to a different slot or removing the preset will remove the influence from that preset region."},{"start":"6:02","end":"6:39","startSec":362.0,"text":"Now, the underlying system that drives the Sculpt and Move tools tries to find the closest combination of facial features of the real humans that have been scanned into the database and it uses this to approximate what is being Sculpted. When either the Sculpt or Move tool is selected, the Enable Symmetry and the Sculpt plane options will become available. Now, let's move on by looking at the different attributes and properties we have available in the MetaHuman Creator."},{"start":"6:39","end":"7:14","startSec":399.0,"text":"The attributes and properties on the left over here are organized into three sections. The face controls, the hair controls, and the body controls. For the face controls, we have the skin, the eyes, the teeth, and makeup. If we look at the skin tab, here we can customize the skin color and texture. The skin color controls the skin tone and you can use the sliders at the bottom to control the picker position when choosing a shade."},{"start":"7:14","end":"7:46","startSec":434.0,"text":"The texture slider will allow you to control high frequency details in the textures. This will also affect geometry and dynamic maps which are activated during facial expressions. This is helpful if, for example, you wish to add details to the skin that indicate a character's age. Moving on to the Freckles tab. This has customization options that allow you to choose a freckle pattern."},{"start":"7:46","end":"8:18","startSec":466.0,"text":"You can also control the strength, density, saturation, and tone shift. And then we have the accents tab. This allows you to control the redness in specific areas of the face. And this can be used to simulate different skin characteristics such as blushing, suntan, or sunburn, or dark circles under the eyes. Now let's move on to the eyes where we have a lot of options."},{"start":"8:18","end":"8:55","startSec":498.0,"text":"By selecting a preset, this gives you a starting point for different eye colors and combinations. The iris tab over here allows you to customize the eye details even further. You can control the base and detail color of the eye and also truce from a blend method. You can control the way colors are balanced and blended and you can even adjust the iris size, the saturation, and the limbous darkness."},{"start":"8:55","end":"9:26","startSec":535.0,"text":"The Sclera tab over here controls the white part of the eyes. Here you can control things such as brightness, the vascularity, and even the veins rotation. Now let's move on and look at the teeth properties. I'm going to move our metahuman so we can get a closer look at the teeth."},{"start":"9:26","end":"10:00","startSec":566.0,"text":"Over here we have a visual representation of the teeth with nine adjustable controls. We can adjust the control points to customize the tooth length, the tooth spacing, the upper shift or lower shift. We can add an overbite or underbite and even modify the gums and the narrowness of the teeth. We can also go through different variations of teeth. Here we have the ability to change the tooth color."},{"start":"10:00","end":"10:35","startSec":600.0,"text":"We can change the gum color and even adjust the plaque color and plaque amount. We can also open the jaw to get a better view of how these changes affect the teeth. Finally we have the makeup properties. I will reposition the face again so that we can see some of these options better. Over here we have the option to choose from a few foundation presets."},{"start":"10:35","end":"11:10","startSec":635.0,"text":"Once we check this on we can adjust the concealer intensity under the eyes. We can also fine tune the intensity and roughness of the foundation. The eyes tab contains pre-made styles for combining eyeliner and eyeshadow. This has its own color options and you can control the roughness, the transparency and the metalness. The blush adds blush to the cheeks and you can select how blush is applied to the face."},{"start":"11:10","end":"11:47","startSec":670.0,"text":"You can create your own custom color or choose from a variety of presets. You can also control its intensity and roughness. For the lips you can apply pre-made lipstick styles and also control the color, the transparency and the roughness. Now before we move on to the hair controls let's do a review of everything we have covered. For the skin properties we can use the skin tab to access customizations such as the skin color and textures."},{"start":"11:47","end":"12:22","startSec":707.0,"text":"The texture option is a very powerful tool as it affects geometry and dynamic maps. The freckles tab gives you the ability to add more detail to the skin. You can select from a freckle pattern and customize things such as the strength and density of the freckles. The accents tab which controls redness in specific areas of the face can be used to simulate different skin characteristics such as blushing, sun tan, sunburn or dark circles under the eyes."},{"start":"12:22","end":"13:00","startSec":742.0,"text":"For the eye properties you can get a starting point with one of the presets. The iris tab gives you control over the color and iris details. And the sclera tab controls the white part of the eyes and you can adjust things such as the brightness and vascularity. You can also adjust the left and right eyes separately. For the makeup properties you can apply foundation and concealer. And you can choose from a variety of pre-made styles for eye makeup, blush and lipstick each with their own customizable properties."},{"start":"13:00","end":"13:30","startSec":780.0,"text":"If you are using a medicuman for fashion for instance, these makeup properties can save you a lot of time instead of having to add these types of details using other DCCs. The teeth properties come with 9 adjustable controls and we can even tailor the color of the teeth and skin tone of the gums. Now that's it for this section. Next we will continue exploring the medicuman creator by looking at the hair controls."}],"06_MHCHairBodyAnimCtrls":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"We just finished exploring the MetaHuman Creator face controls. Next, we continue our journey with the MetaHuman Creator by looking at the hair controls. So, let's jump back into the MetaHuman Creator. Now, let's take a look at the hair controls. If we select the head and go to Style, we can see a variety of hairstyles we can choose from."},{"start":"0:33","end":"1:08","startSec":33.0,"text":"For the hair color, you can choose from any of the presets, and you can also choose from neutral, deep, or vibrant colored presets. And you can create your own custom color. If you want to further customize the hair, you can go to the Details tab. You can adjust properties such as the roughness, salt and pepper, and salt and pepper lightness for the main color. Depending on the hairstyle you have selected, you will also have the option to enable ombre,"},{"start":"1:08","end":"1:40","startSec":68.0,"text":"which starts at the tip of the hair and spreads upward. This has its own customizable properties, such as color, shift, contrast, and intensity. You can enable the highlights, which controls the balance between dyed and natural hair strands. You can adjust the color, the color blending, the intensity, and variation. Just as we have hairstyles we can choose from for the head,"},{"start":"1:40","end":"2:14","startSec":100.0,"text":"we also have some options we can choose from for the eyebrows and eyelashes. For the eyebrows, we can select any style we want, and adjust the color and the details for these independently from the head. Depending on the brow style you choose, some may have in the Details panel the option for shading and microblading. Moving on to the eyelashes, having options for the eyelashes can be helpful,"},{"start":"2:14","end":"2:46","startSec":134.0,"text":"especially when working with more custom metahumans. For instance, your character may have a unique eye shape, and you might prefer the lash placement of one style over the other. The eyelash color can also be customized and has its own color details. I will go here to turn off the toggle clay material. For the mustache and beard options, these also have their own styles,"},{"start":"2:46","end":"3:17","startSec":166.0,"text":"and there are a variety of mustaches and beards you can choose from. Now depending on which style you select for either of these, some will also have the color options such as ombre and highlights. Before we move on to the body controls, let's do a quick review of the hair controls. For the hair controls, we have a variety of styles and colors we can choose from"},{"start":"3:17","end":"3:47","startSec":197.0,"text":"for the head, the eyebrows, the eyelashes, the mustache and the beard. When you select a color for the hairstyle, that color is applied to all the other grooms. You can change the color of the other grooms independently. Now depending on the style you have chosen, you will also have a few other options you can configure such as ombre and highlights. Depending on the eyebrow style you have selected, some may have the additional option"},{"start":"3:47","end":"4:19","startSec":227.0,"text":"to choose microblade and makeup shading. Now that we've looked at the hair controls, let's continue by exploring the body controls. Now let's take a look at the body controls that allow us to customize the proportions and add contemporary clothing such as tops, bottoms and shoes. Starting with the proportions, we have 18 unique body shapes we can choose from"},{"start":"4:19","end":"4:50","startSec":259.0,"text":"based on height and these are short, average and tall. Now we can choose whether we want to have a feminine or masculine body type and we can choose if we want our character to be underweight, overweight or normal. There is also a head scale slider over here if we wish to adjust the head size in relation to the body."},{"start":"4:51","end":"5:23","startSec":291.0,"text":"For the clothes, starting with the tops, these contemporary styles also come with a wide variety of patterns. These patterns can be applied and further customized. If we wish to remove the clothing, we can select this option over here. For the pants, we will also have a few contemporary styles. Some of these options will also allow you to select from a variety of patterns."},{"start":"5:23","end":"5:59","startSec":323.0,"text":"If we wish to remove the pants, we can select this option. Lastly, we have a few different styles of shoes. There are no patterns or additional detail options for the shoes other than the color options that are available here. Now before we move on to the animation toolbar, let's review the body controls one more time. For the body controls, we can choose the proportions based on height, feminine or masculine and body weight."},{"start":"5:59","end":"6:32","startSec":359.0,"text":"A quick note is that the female medium normal body weight metahuman will always be the metahuman based skeleton. For clothes, it is worth mentioning that they are contemporary. So if you are looking for something different, there are several options for metahuman custom clothing on Fab. Now let's move on and take a look at the animation toolbar. If you want to see what your character looks like with all of the customizations you have applied,"},{"start":"6:32","end":"7:08","startSec":392.0,"text":"you can use the animation toolbar to apply a variety of body and face animations. Starting with the face, if we click on the vertical ellipsis and select a facial pose over here, we can see what our character looks like when making certain expressions. We can also select the facial rom animation and see a variety of expressions on our metahuman. This is especially useful when testing out changes you have made to the face, such as wanting more prominent wrinkle maps."},{"start":"7:08","end":"7:46","startSec":428.0,"text":"This is also very helpful in spotting problematic areas while working with more customized metahumans, as you can identify those and make changes on the spot before bringing it into the engine. You can also choose from a variety of body poses or animations, and this is helpful if you want to see what the body proportion you have chosen looks like when your character is in a certain pose. The body rom is especially useful if we want to see what our character looks like in motion, perhaps with a specific clothing style."},{"start":"7:46","end":"8:25","startSec":466.0,"text":"The animation toolbar can help you make decisions on the spot based on how your character looks when the face and body come to life. We can also use this to see what our customizations look like with a variety of lighting scenarios and camera positions. Let's do a quick review of the animation toolbar before we move on to a few other things we can do with the metahuman creator. We have just looked at the animation toolbar, which includes a number of body and facial animations and poses that we can apply."},{"start":"8:25","end":"9:02","startSec":505.0,"text":"The face animations are particularly helpful as you can see with the wrinkle maps and adjustments to the face look like in the event you want to change something before bringing it into Unreal Engine. Some of the facial animation poses we can access inside of our Unreal Engine project in the metahumans folder located in the face pose library folder. The body animations can be helpful if you want to see what different proportions and clothing options might look like when your metahuman is in motion."},{"start":"9:02","end":"9:39","startSec":542.0,"text":"We have just seen what is possible inside of the metahuman creator by simply selecting a metahuman preset and using the various tools to further customize it. There may be times where you might want to share a metahuman you have created with another user. So let's jump back into the metahuman creator one more time to go over the process of how we can share metahumans with other users. Inside of the metahuman gallery, let's go over how we can share metahumans with others from here."},{"start":"9:39","end":"10:14","startSec":579.0,"text":"With the metahuman we wish to share with someone selected, we can go to the bottom left panel over here. In this panel, we will have the option to permanently delete a metahuman or create a duplicate. And over here we have an option to import an mhb file and export an mhb file. If you select export, a progress bar will appear and a copy of your metahuman will be downloaded as an mhb file."},{"start":"10:14","end":"10:48","startSec":614.0,"text":"If you want to import an mhb file someone has shared with you, you can click on the import option and choose the mhb file. And that metahuman will appear in your My Metahumans gallery. Alright, let's review everything we've just covered before we move on. We have just seen how we can export and import metahuman creator files in order to share our metahuman characters with other users."},{"start":"10:48","end":"11:21","startSec":648.0,"text":"It can be helpful to share and receive metahuman creator mhb files so that you can work with other users on the same character. If you wish to share a metahuman with someone, in the My Metahumans gallery, use the panel below to select export. The mhb file will be downloaded and you can share that file. If you want to import an mhb file someone has shared with you, you can select import then locate the mhb file."},{"start":"11:21","end":"11:54","startSec":681.0,"text":"A progress bar will appear and that metahuman will appear in your My Metahumans gallery. We have explored what we can achieve inside of the metahuman creator, but there may be cases where you want to push for more likeness with your character. So this brings us to the next section of this course where we go beyond the metahuman creator and use the metahuman plugin for Unreal Engine to create a character from an existing 3D mesh with the mesh to metahuman workflow."},{"start":"11:57","end":"12:02","startSec":717.0,"text":"Thank you for watching."}],"07_MHPluginRealityScan":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"In this section of our course, we will go over metahuman tools and workflows that can be used to achieve more likeness with our metahuman character. We will also go through a hands-on session for creating a metahuman in Engine using the metahuman plugin for Unreal Engine with a face scan asset created using the RealityScan mobile app. The metahuman plugin allows you to create a metahuman from a 3D character mesh and is available from Engine versions 5.0 or later."},{"start":"0:36","end":"1:08","startSec":36.0,"text":"You can also create a metahuman from facial footage with Engine versions 5.2 or later. To use the plugin, begin by installing the metahuman plugin to the appropriate Engine version from the fab marketplace. Once the plugin is installed, inside of your Unreal Engine project, open up the plugin's menu, enable the metahuman plugin, and then restart the Engine. This plugin is already installed and enabled in our course project."},{"start":"1:11","end":"1:45","startSec":71.0,"text":"For our hands-on exercise, we will be using a face scan that was captured using the RealityScan mobile app. RealityCapture is a company that is part of Epic Games, and you can use the standalone or mobile app version for free by signing in with your Epic Games account. If using the RealityScan mobile app, once you capture your scanned data, that data will be processed in the mobile app, and from there you can either export the 3D model or share it on Sketchfab."},{"start":"1:46","end":"2:02","startSec":106.0,"text":"Once you have the asset, inspect it, and then import it into Unreal Engine. Using the face scan data that has been captured with the RealityScan mobile app, let's dive into a hands-on exercise and create a metahuman in Unreal Engine."}],"08_M2MPart1":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In this section, we will primarily work in Unreal Engine to create a metahuman from a face scan. As we work through this exercise, you will note that this is broken down into a step-by-step process that is found in your slide deck. As we complete portions of the practical exercise, I will review the completed steps. So, let's jump into Unreal Engine and begin creating a metahuman. With Unreal Engine open, as mentioned at the beginning of the course,"},{"start":"0:32","end":"1:08","startSec":32.0,"text":"the RealityScanFaceScanAsset has already been imported and is located under the Assets folder in the folder named ScanMesh. If you wish to go through all of the steps I will show, you can locate the original OBJ file and textures that have been provided in the Source Files folder named 11301 RealityScanAsset. Now, I'm going to navigate to our Course Topics folder and in here, I'm going to create a new folder to work in by pressing Ctrl Shift N."},{"start":"1:08","end":"1:39","startSec":68.0,"text":"I will name this EX for example and then open this up. Inside of here, we will get started by importing the 3D mesh. Start by going to the import over here, then inside of the Source Files folder named 11301 RealityScanAsset, in the RealityScan folder, select the FaceScanMesh and the textures and then select Open."},{"start":"1:39","end":"2:09","startSec":99.0,"text":"The Import Content option will appear and if you are working with an asset that has separate meshes, for instance the eyes and the head are separate, go to Static Meshes and enable Combine Static Meshes. Then go here and select Import."},{"start":"2:09","end":"2:42","startSec":129.0,"text":"Once the asset and textures are imported, open up the FaceMesh to inspect it. Make sure it is facing the X-axis. If it is not, you can re-import it and make the appropriate adjustments to the offset rotation in the import options. The next step is to prepare the mesh. Now, let's create a new material in order to apply the textures to our 3D head mesh."},{"start":"2:42","end":"3:16","startSec":162.0,"text":"Right click in the Content Browser and select Material. I will name this M underscore RC for RealityCapture and then open this up. Going back to the main viewport, I will undock the material so that I can add the textures to the material graph. And from here, I will select the Albedo and Normal map and drag these into the material graph."},{"start":"3:16","end":"3:56","startSec":196.0,"text":"You don't necessarily need the Normal map but since we have it, let's use it. Inside of this material, I will connect the Albedo to the Base Color and then connect the Normal map to the Normal. You may find it helpful to adjust the specular in the event your material is a bit shiny. So I will press 1 to create a constant and set the value to something like 0.3 and then I will connect this to the specular."},{"start":"3:56","end":"4:28","startSec":236.0,"text":"I will save this and go back to our main viewport. With the new material selected, let's go to our Static Mesh window and apply this to our 3D head mesh by assigning it over here. Now, before we move on, let's review some of the steps we just completed."},{"start":"4:28","end":"5:06","startSec":268.0,"text":"For the Mesh to MetaHuman workflow, begin by importing the 3D head mesh and textures. If working with a 3D model that has separate meshes, in the Static Mesh section of the import options, check on Combine Meshes. Once imported, check to see that it is facing the X-axis, otherwise adjust the rotation offset in the import options and re-import it. One note is that the import options will look different from previous versions of Unreal Engine 5."},{"start":"5:06","end":"5:43","startSec":306.0,"text":"The next step is to prepare the mesh. Apply a material using an albedo texture. It is helpful to use an albedo map in order to separate the sclera from the skin tone. With the material results, the 3D face model should have the eyes open with a visible seam separation of the eyelid and eye to assist with the tracking marker placement. The mouth should be closed and the face should have a relaxed neutral pose. Something to note is that if the model does not have eyeballs, the empty sockets may generate artifacts in the mesh fitting."},{"start":"5:43","end":"6:16","startSec":343.0,"text":"Now, let's jump back into Unreal Engine and continue with the next steps. The next step of this workflow is to create a metahuman identity asset. There is an existing one you can inspect located in the course topics folder inside of the folder named Mesh to Metahuman Identity in the folder named Sample Metahuman ID. This is already gone through the process of being generated using the 3D headscan data."},{"start":"6:16","end":"6:47","startSec":376.0,"text":"Let's go back to the Mesh to Metahuman Identity folder and create a new folder to work in by pressing Ctrl Shift N and name this EX for example. Inside of here, right click in the content browser and select Metahuman Animator and then select Metahuman Identity."},{"start":"6:47","end":"7:26","startSec":407.0,"text":"The name you give this will be the name that will appear in the Metahuman Creator later on. I will name this RC underscore scan. Now, I will double click to open it. I'm going to dock it up here and once this window opens, you may be prompted with an Epic Games sign in. The next step is to populate the Metahuman Identity asset. Go to the main toolbar, go to create components and drop this down, select from Mesh"},{"start":"7:27","end":"7:57","startSec":447.0,"text":"and then search for the 3D mesh. I will type in RC underscore scan and then scroll down to locate it. Once it is selected, it may take a moment for it to load. Once loaded, navigate to the front of the face scan. In the top left panel, select the body component."},{"start":"7:57","end":"8:35","startSec":477.0,"text":"Right below, select the body type that you wish for this Metahuman to have. In my case, I want to select the female medium normal body weight. Now, before we move on, let's review the steps we just completed. After importing and preparing the face scan model, the next step is to create a Metahuman Identity asset. Right click in an empty space in the content browser, select Metahuman Animator and then Metahuman Identity."},{"start":"8:35","end":"9:05","startSec":515.0,"text":"The name you choose will be a placeholder for it in the Metahuman Creator. Once you open up the Metahuman Identity asset, you may be prompted to sign in with your Epic Games account. Inside of the Metahuman Identity asset window, the next step is to populate it with the 3D model and assign a body type. Go to the main toolbar, go to create components and drop it down."},{"start":"9:05","end":"9:30","startSec":545.0,"text":"Select from mesh and then search for it. It will take a moment to load in the viewport. Next, select the body component and then select the body type you want your Metahuman to have. Now, that's it for this section. In the next video, we continue our hands-on exercise with the next steps of the Mesh to Metahuman workflow."}],"09_M2MPart2":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"In this section we continue our hands-on exercise with the next steps of the Mesh to MetaHuman workflow. So let's dive back into Unreal Engine. Now the next step is to adjust the camera in lighting. Go here and click on the viewport camera. Change the field of view to 20 degrees or something less. And now position the camera so that the scan is facing forward and is completely visible."},{"start":"0:36","end":"1:07","startSec":36.0,"text":"Take your time when framing the face. Now with the camera positioned, the next step is to adjust the lighting. Go to the top left of the viewport toolbar and click on lit. Here you can choose from lit, unlit, or lighting only. For meshes with skins textured with the skins albedo, unlit works best."},{"start":"1:07","end":"1:39","startSec":67.0,"text":"For other meshes, you can rotate the light by holding down L until the entire face is evenly lit. It is worth mentioning that lighting and framing can influence the way in which the tracking markers track the facial features. With a full view of the face, the next step is to create a neutral pose frame. Select the neutral pose component."},{"start":"1:39","end":"2:10","startSec":99.0,"text":"In the main toolbar, select promote frame. A pop-up will appear saying that the current promoted frame will be set as the front view. If you wish to add additional frames, you can add them by clicking on this. Just ensure by going to the neutral pose detail panel under frame promotion that used to solve is enabled only for the neutral front facing frame."},{"start":"2:10","end":"2:44","startSec":130.0,"text":"Before we continue, let's review the steps we just completed. After creating a metahuman identity asset and populating it, the next step is to adjust the viewport lighting and camera positioning. As this step can influence the way the tracking markers land on the facial features. Adjust the lighting by going to the viewport toolbar and selecting lit. Then, choose between lit, unlit or lighting only."},{"start":"2:44","end":"3:23","startSec":164.0,"text":"As mentioned earlier, for meshes with skins textured using the Skinz Albedo, unlit works best. For the other two lighting options, rotate the light until the face is evenly lit. There will be variation in the way tracking markers are placed on the facial features with different lighting scenarios. And you may find one setting may give you better tracker positioning than others depending on your mesh. For framing in the viewport toolbar, use the viewport camera options to change the field of view to something around 20 degrees or less."},{"start":"3:23","end":"3:54","startSec":203.0,"text":"And then position the camera so that the eyes, mouth and nasolabial folds are visible. The next step is to promote a front-facing frame. Select the neutral pose component and then in the main toolbar select promote frame. Additional frames can be helpful for features such as the ears if you wish to track more details. When using multiple frames in the neutral pose details panel under the frame promotion settings,"},{"start":"3:54","end":"4:29","startSec":234.0,"text":"ensure that use to solve is enabled only for the front-facing frame. Now, let's continue with the next steps of this workflow. The next step is to track the neutral pose. With the neutral frame selected, go to the main toolbar and select track markers. Once we click this, we can see that the tracking markers have been placed on the facial features."},{"start":"4:29","end":"5:05","startSec":269.0,"text":"Something to note is that the albedo texture from the scan assists the tracking markers in locating and shaping facial features such as the eyebrows and nasolabial fold creases. If we were to track this without a texture, it is possible we may get different results as the tracking markers may have a harder time locating the shape of the eyebrows for instance. In the event that tracking markers may need to be adjusted, for instance, I may want to define the eyes a bit more."},{"start":"5:05","end":"5:38","startSec":305.0,"text":"You can select individual tracking markers and reposition them by clicking on them and moving them with your mouse. If you wish to move an entire tracking section, double-click on the tracking marker curve. This will select all of the tracking markers, allowing you to move these all together. You can also deselect tracking markers by holding down shift and then clicking on each one individually."},{"start":"5:38","end":"6:17","startSec":338.0,"text":"If you want to add more definition to certain features, you might want to add new tracking markers. Using the mouth area as an example, using the mouse wheel, I'm going to zoom in on the upper right lip. To add additional tracking markers, press control and then left mouse click on the tracking curve. I'm going to go and inspect the right eye and move some of these tracking markers to define the tear-duck region a bit more."},{"start":"6:17","end":"6:47","startSec":377.0,"text":"And now I'm going to move over to the left eye and do the same by moving some of these tracking markers in order to fine-tune their position over here. I'm going to zoom out using the mouse wheel and then with my mouse hovering over the mouth, I will zoom in. Here, I want to add a bit more definition to the top of the upper lip area."},{"start":"6:49","end":"7:18","startSec":409.0,"text":"Again, spend some time with this process as this type of solve depends on how these tracking markers are placed on a 2D image, as opposed to it being solved on the actual geometry. Once you are happy with the position of the tracking markers, the next step is to run the metahuman identity solve and view the results. Go to the toolbar and select metahuman identity solve."},{"start":"7:19","end":"7:49","startSec":439.0,"text":"Once the solve completes, you can toggle between the solved mesh and the template mesh in the viewport toolbar by clicking on the AMB tabs. We can view the results side by side or we can view this as an overlay. The overlay allows us to compare specific regions of the face close up and decide if we are happy with the way the facial features have been tracked."},{"start":"7:49","end":"8:26","startSec":469.0,"text":"If there are areas that may still need adjustments, you can continue the process of fine-tuning the positions of the tracking markers. If you ever get an error after running the identity solve, you may find it helpful to simply move a few tracking markers and then rerun the identity solve. Now before we continue, let's review the steps we just completed. Once you have adjusted the framing and lighting and promoted a front-facing frame, the next step is to track a neutral pose."},{"start":"8:26","end":"8:56","startSec":506.0,"text":"You can adjust the tracking markers if needed to fit around the facial features. Using your mouse, you can move individual markers or groups of markers by double-clicking on a track curve and then moving it. You can deselect tracking markers by holding down shift and then clicking on individual tracking markers. And you can add markers by pressing control and then left mouse click on a tracking curve."},{"start":"8:56","end":"9:34","startSec":536.0,"text":"Once finished repositioning the tracking markers, the next step is to run the metahuman identity solve. Inspect the results by using the AMB tabs in the viewport toolbar. You can view the results side by side between the solved mesh and the template mesh or by using the overlay option. Now let's continue with the next steps of this workflow. That's it for this section. In the next video, we continue our hands-on exercise with the final steps of the mesh-to-metahuman workflow."}],"10_M2MPart3":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Let's wrap up our hands-on exercise with the final steps of the Mesh to Metahuman workflow. So let's dive back into Unreal Engine. After running the Metahuman Identity Solve, if the tracking markers still need to be adjusted, or you wish to add additional markers to refine certain areas, such as the eyes and ears, you can now enable additional tracking markers."},{"start":"0:30","end":"1:05","startSec":30.4,"text":"In the top right over here, we can see additional tracking options that we can enable. Some tracking curves may already be set to visible, and others may be disabled. If you hover your mouse over the icon next to the tracker name, an image of what portion of the face that tracker is assigned to will appear, which can be helpful. If for example we want to add tracking markers to the left and right eye crease, we can go"},{"start":"1:05","end":"1:38","startSec":65.1,"text":"here to make the left eye crease visible, then select this to enable the curve to be used for the solve. Let's repeat these steps for the other eye crease. Now go to the tracking markers of the right eye to start adjusting the eye crease tracking marker positions. I'm going to select this tracking curve and move it over the eye crease, and then I will"},{"start":"1:38","end":"2:13","startSec":98.6,"text":"start to reposition each individual tracking marker. Moving over to the left eye, I'm going to move the tracking curve, but this time I will deselect each tracking marker one by one."},{"start":"2:13","end":"2:45","startSec":133.0,"text":"Now if you wish to track the ears, we can add another frame by going here and clicking on the plus sign. I'm going to rotate the camera so that we can see the left ear. And now I will go to the top right over here, and I'm going to select the first ear and drop this down. I will change the visibility for each tracking curve, and this will automatically set these"},{"start":"2:45","end":"3:20","startSec":165.5,"text":"tracking curves to active. Just make sure with this frame selected, go to the neutral pose details panel on the left over here, and in the frame promotion panel, uncheck used to solve for this additional frame. We do this so that only one frame is used for the identity solve. I'm going to delete this frame now. Once you are finished adding additional tracking curves and adjusting their positions, go back"},{"start":"3:20","end":"3:52","startSec":200.0,"text":"to the toolbar and run the metahuman identity solve again. You can keep running the metahuman identity solve and continue to adjust tracking marker positions or adding new tracking curves until you are happy with the results. Use the viewport toolbar to continue to inspect your mesh. I can see when using the overlay option that the eye creases have assisted in getting a"},{"start":"3:52","end":"4:26","startSec":232.4,"text":"better solve and I am happy with the results. Once you have a ballpark approximation of what you want to achieve, the final step here is to auto-rig the metahuman identity. Go to the main toolbar, then go to mesh to metahuman and drop this down. You can choose whether you want to auto-rig the skeletal mesh only, which will create an auto-rigged version with the embedded DNA added to the Unreal Engine project, or you"},{"start":"4:26","end":"5:00","startSec":266.2,"text":"can select skeletal mesh and full metahuman. Once selected, you may be prompted to sign in with your Epic Games account. This will generate a skeletal mesh with embedded DNA to the project and a full metahuman will appear in the metahuman creator for further editing. This process may take a few moments to complete. A pop-up will appear letting us know that a skeletal mesh with embedded DNA is now available"},{"start":"5:00","end":"5:33","startSec":300.6,"text":"in our content browser and a metahuman is also available in the metahuman creator. We can now leave this metahuman identity asset window and go back to our main viewport. I'm going to save everything and in the content browser, there will be the skeletal mesh of the metahuman identity. The final step of this workflow is to go to the metahuman creator and further customize"},{"start":"5:33","end":"6:09","startSec":333.9,"text":"our metahuman. In the main viewport, go to the get content panel and select Quixel Bridge. Go to the Quixel Bridge menu on the left and in the my metahumans option, you will be able to locate and select your newly created metahuman identity. With the metahuman identity selected, we can go here on the right to start the metahuman creator. Now, as we wait for the metahuman creator browser to load, let's review the steps we"},{"start":"6:09","end":"6:42","startSec":369.0,"text":"just completed. Once you have tracked a neutral pose and run the metahuman identity solve, additional markers can be added. In the top right window, you can see all of the tracking markers that are available. Some of them by default will be visible and used for the initial metahuman identity solve. If you hover over the icon located next to a curve, an image of what portion of the face that tracker is assigned to will appear."},{"start":"6:42","end":"7:13","startSec":402.3,"text":"You can change a tracking curve to visible and also change it to active so that it is used for the solve. Then you can continue rerunning the metahuman identity solve and adjusting or adding more tracking curves until you are happy with the results. The next step is to finalize your metahuman identity. In the main toolbar, go to the mesh to metahuman dropdown and select auto rig metahuman identity"},{"start":"7:13","end":"7:45","startSec":433.8,"text":"and full metahuman so that you can make further adjustments to it in the metahuman creator. When you run the auto rig and full metahuman option, a skeletal mesh and embedded DNA will be added to your project and a placeholder for your metahuman identity will become available in the metahuman creator. Now, let's wrap things up with the final steps of this workflow inside of the metahuman creator."},{"start":"7:45","end":"8:15","startSec":465.1,"text":"Now that the metahuman creator browser has loaded, we can see our metahuman in the My Metahumans gallery. With this already selected, I am going to go down here and select edit selected. I am going to stop the animation and I want to toggle off the hotkeys. In the properties and attributes, we can see the custom mesh panel has become available."},{"start":"8:15","end":"8:49","startSec":495.5,"text":"I want to change the camera view to focus on the face for this. Now this is unique to metahumans created with the mesh to metahuman workflow. This slider allows you to adjust the overall region influence which blends the delta in volume between your input and a template metahuman. I will bring the face a bit closer. Over here in this panel, you can select specific regions of the face and then move the slider"},{"start":"8:49","end":"9:22","startSec":529.8,"text":"to increase or decrease the region influence for this specific area. This is especially helpful if you find problematic areas. If I select the eyes for instance and start to move the slider, we can see how even though the change is minor, this can be useful if your custom character's eyeballs and eyelid might be intersecting. And you may find it helpful to use this on the mouth area to blend a bit of the template"},{"start":"9:22","end":"9:55","startSec":562.5,"text":"mesh in cases where perhaps the teeth and lips may be intersecting. In order to use the blend, sculpt and move tools, you can select enable editing. It might be helpful to select duplicate and unlock so that you always have a copy of the original in the event you want to revert back to it. Now before we start making any modifications, it may be helpful to view your character with skin textures applied by going to the skin control."},{"start":"9:55","end":"10:29","startSec":596.0,"text":"Select assign skin color to apply a skin texture. You will notice that the template mesh texture is assigned as the texture we used previously will not transfer over. Now you can see your newly created metahuman character come to life by using the animation toolbar and continue inspecting and refining your character. Now that we have gone over some of the options inside of the metahuman creator that are unique"},{"start":"10:29","end":"11:01","startSec":629.8,"text":"to the mesh to metahuman workflow, let's wrap up this section of our course by reviewing the steps we just completed. The last step of the mesh to metahuman workflow is to inspect the metahuman identity inside of the metahuman creator. An option that is unique to this workflow is the region influence which allows you to blend either the entire face of your input with the template metahuman or to adjust the"},{"start":"11:01","end":"11:33","startSec":661.8,"text":"region influence for specific areas of the face. This option is especially helpful if you have problematic areas such as the eyes and eyelids intersecting or to adjust certain areas of the mouth. You can use the blend sculpt and move tools by enabling editing. You will be prompted to duplicate and unlock the metahuman so that you have a backup of your original or to just use the original to make further adjustments."},{"start":"11:33","end":"12:05","startSec":693.1,"text":"The original albedo texture associated with your 3D model will be replaced by the template mesh texture so you can assign a skin texture in the skin tab. You can apply animations to your metahuman using the animation toolbar and again this will be helpful in spotting problematic areas or to be able to view any customizations you make as you continue to refine your character. And this brings us to the end of this section of our course."},{"start":"12:05","end":"12:17","startSec":725.9,"text":"In the next section we will take a look at how to bring a metahuman into Unreal Engine and also go over some best practices for working with it in your project."}],"11_MHinUEPart1":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In this section of our course, we will go over how to bring a metahuman into Unreal Engine and go over some best practices for working with them in your project. Let us begin by going over the download options and how to export a metahuman from Quixel Bridge in order to add it to our Unreal Engine project. In Unreal Engine with Quixel Bridge open, the first thing you will need to do is download your metahuman."},{"start":"0:32","end":"1:10","startSec":32.0,"text":"With the metahuman you wish to add to your project selected, select the quality you want to download. In earlier versions of Unreal Engine 5.4, the options that were available were based on texture resolution quality. We now have the option to select cinematic, which gives us full resolution textures with separate materials, LODs focused on quality over performance, the highest fidelity animation blending, along with body and neck correctives enabled."},{"start":"1:10","end":"1:43","startSec":70.0,"text":"This also gives us full strand based hair on LOD 0 and the average file size will range between 2-3 GB. For the high, medium and low optimized options, we will have compressed textures and optimized materials with less instructions and baked textures, the LODs have been adjusted to improve performance, and the settings that enable and disable correctives are based on LOD for more optimized animations."},{"start":"1:43","end":"2:16","startSec":103.0,"text":"We also have optimized hair grooms and the average file size is under 100 MB. Once you have selected the quality you wish to download, it will take some time to process before you can download and export them to Unreal Engine. If you wish to update a revised metahuman from the creator, Quixel Bridge will display an update button. By updating this asset in Quixel Bridge, this does not mean the asset in the Unreal Engine project is updated."},{"start":"2:16","end":"2:49","startSec":136.0,"text":"You will need to re-download and re-export the metahuman to Unreal Engine. Before you do so, as the asset will be overwritten, make sure to close all levels and sequences using the older version. Then add it back into the project, save and restart. Once the download of your metahuman has completed, on the bottom right of your selected metahuman in Quixel Bridge, you can now click Add to export the metahuman."},{"start":"2:49","end":"3:22","startSec":169.0,"text":"Inside of your project, you will see a metahuman's folder, and inside of that folder, navigate to the folder with the name of the metahuman that was added, and double click on the blueprint to open it up. Once you do so, pop-up prompts will appear for missing plugins and project settings in the lower right corner. It is required that these are enabled, so click on Enable Missing on each, and then restart the engine."},{"start":"3:22","end":"3:56","startSec":202.0,"text":"Once you restart the project, you can start working with your metahuman. Our course already has all of the required plugins and project settings enabled. Now, let's jump into Unreal Engine and start working with our metahuman. Inside of Unreal Engine, let's begin by going to the metahuman's folder. Inside of this folder is where you will find the metahuman you have exported from Bridge."},{"start":"3:56","end":"4:29","startSec":236.0,"text":"Let's open up the folder named Lena underscore CQ. I've added CQ to reference that this was downloaded with the cinematic quality settings. Over here, we can see Lena's blueprint. Let's double click on this to open it. Inside of the metahuman blueprint, you will see it has an event graph, a construction script, and a viewport. And this is where we can see our metahuman components brought together."},{"start":"4:29","end":"5:00","startSec":269.0,"text":"Let's bring this closer to view. On the left side, we can see all of the components that make up a metahuman. You will notice that when you select a component, in the Details panel on the right, the options that are unique to that asset will be displayed. We can modify each component's properties, and once finished making adjustments, you can go here to compile and save those changes."},{"start":"5:01","end":"5:34","startSec":301.0,"text":"Now, let's return to our main viewport. To add a metahuman to a level, simply drag and drop the metahuman blueprint in here. In the Details panel on the right, go to the Transform to zero out its position. I'm going to delete this because we already have a metahuman in the level. Now, if we select this metahuman in the Details panel on the right, all of the components will be visible."},{"start":"5:34","end":"6:08","startSec":334.0,"text":"You can select each component and have the option to adjust things such as what you want to set the LOD to in the level. For some assets such as the skeletal meshes, it may be best to adjust those inside of the blueprint. Now, before we move on, let's review what we've just covered. We have just taken a look inside of the metahuman blueprint. Metahumans are made up of several components, and when selecting a component,"},{"start":"6:08","end":"6:38","startSec":368.0,"text":"the options that are unique to that asset will appear in the Details panel. We can modify components and their properties, and once finished making adjustments, we can compile and save those changes. To add a metahuman to a level, drag the blueprint into the level. When you select a metahuman in a level, all of the components and their options will be accessible in the Details panel,"},{"start":"6:38","end":"7:08","startSec":398.0,"text":"and you can make adjustments to each component from there. Now, let's return to Unreal Engine and go over how we can apply animations. Metahumans come with built-in body and face control rigs, and we can use these to create animations. To do this, we will first create a level sequence. We can go up here and select Add Level Sequence."},{"start":"7:09","end":"7:39","startSec":429.0,"text":"I will save this in our Course Topics folder, and now you can add a metahuman to Sequencer, either by going to the Outliner, selecting it and dragging it in here, or we can go here on the left, select the Add button, and then go here to Actor to Sequence, and select it from here. By default, the body and face control rig will appear."},{"start":"7:39","end":"8:10","startSec":459.0,"text":"Let's go to Perspective and select Cam01Body in order to view it better. If we look at the body controls, we can move some of these controls by rotating each individual joint. I will change the gizmo to Rotate, and I have already disabled snapping. For controls that allow you to only rotate individual joints, this is called Forward Kinematics or FK."},{"start":"8:10","end":"8:48","startSec":490.0,"text":"I will change the gizmo to Translate, and I have already disabled snapping. If I select the foot control over here, I can move a hierarchy of joints, and this is called Inverse Kinematics or IK. By default, the arms are set to FK and the legs are set to IK. If we go into Sequencer and scroll up, and then go to the Global Control Track, here, this is where you can switch controls from FK and IK."},{"start":"8:48","end":"9:22","startSec":528.0,"text":"Now, let's take a look at the face control rig. I'm going to scroll up here and collapse the body control rig. Let's go to Perspective and select the camera labeled Cam02Face, which will make it easier to see all of the face controls. There are over 200 controls for the face. In order to move and adjust them, make sure the gizmo is set to Translate and it's set to Local Space, and also ensure that snapping is disabled."},{"start":"9:22","end":"10:01","startSec":562.0,"text":"Now, we can click on a control and use the slider to move it. If you want to select multiple controls at the same time, select the first control and then hold down Shift and select Additional Controls. To create a key, press the letter S, or you can create a key in the Animation Details panel over here on the right, or in Sequencer over here."},{"start":"10:01","end":"10:36","startSec":601.0,"text":"Let's move a few frames over and now move these controls and press the letter S to set a key. If I script through this, we can see we just created an animation. Now, let's see how to go about exporting this as an animation sequence. I'm going to scroll up to the top and collapse the face control rig board. I'm going to select the component for the face and right-click, and then select Bake to Animation Sequence."},{"start":"10:36","end":"11:08","startSec":636.0,"text":"You will be prompted to name your animation and direct it to a folder, and once you do so, it will export this as an animation sequence. Now, before we continue, let's do a quick review of the steps we just completed. To access the body and face control rig, add the metahuman to Sequencer, and by default, the body and face control rigs will appear. The body control rig uses both FK and IK for moving controls."},{"start":"11:08","end":"11:39","startSec":668.0,"text":"FK stands for Forward Kinematics, which allow you to rotate individual joints. IK stands for Inverse Kinematics, and allows you to move a hierarchy of joints. To use the face control rig, select controls with the gizmo set to Translate in local space. To create an animation with control rig, select the controls you wish to adjust and set keys for them by pressing the letter S,"},{"start":"11:39","end":"12:12","startSec":699.0,"text":"or set keys in the Animation Details panel or inside of Sequencer. To export an animation from Sequencer that has been created with control rig, right-click on the face or body component track in Sequencer, and select Bake to Animation Sequence. The control rigs are helpful in that they allow you to quickly pose and animate your metahuman. Now, let's jump back into Unreal Engine and take a look at how we can apply existing body and facial animations to a metahuman."},{"start":"12:12","end":"12:46","startSec":732.0,"text":"In order to apply existing animations to a metahuman in Sequencer, begin by selecting the face control rig and the body control rig, and then deleting them. For the animations that we will apply, I am going to go over here and change the track length of the sequence to 600 frames. I will use the N bracket down here to expand the sequence length and then go to the start of the sequence."},{"start":"12:46","end":"13:16","startSec":766.0,"text":"Let's apply an animation to the body first. On the body track, go to the plus sign, then go to Animation in order to add an animation track. Search for mh underscore sample body and select it. Now, this is a body animation from the Sample Metahumans project. We now have an animation applied to the body."},{"start":"13:16","end":"13:50","startSec":796.0,"text":"Let's repeat this for the face. Go to the plus sign, then to Animation and search for mh sample face and then select it. Let's go to Perspective and select cam3 face. If we play the sequence, we can now see our metahuman come to life. And this is how you apply existing animations to the metahuman face and body in Sequencer."},{"start":"13:50","end":"14:29","startSec":830.0,"text":"Now there may be instances where perhaps you want to adjust an existing animation. To do this, you can bake the animation to control rig. Select the body or face component whose animation you wish to adjust. Then right click on the component and then go here and select Bake to control rig. For the body, you would select metahuman control rig. Now before we move on, let's review the steps we just completed."},{"start":"14:29","end":"15:02","startSec":869.0,"text":"We have just looked at how we can apply an existing animation sequence to a metahuman in Sequencer. Begin by deleting the default control rig tracks, then use the plus sign on the body or face component to add an animation track. If you want to adjust an existing animation, you can bake that animation to the control rig by right clicking on the face or body component and selecting Bake to control rig."},{"start":"15:02","end":"15:34","startSec":902.0,"text":"All metahumans are performance capture ready using LiveLink, LiveLink face, metahuman animator and more. We've only scratched the surface with what is possible with metahumans. And we delve much deeper into the topics we have covered with the metahuman blueprints and animation course. Now let's wrap up this introductory course with some final recommendations. Thank you for watching."}],"12_FinalRecsTips":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"In this section, we will wrap up this course with a few final recommendations, providing some tips and resources for you to use as you continue your training with MetaHumans in Unreal Engine. MetaHumans provide a digital human pipeline that can fit into any workflow. Let's take a look at vertical specific applications they can easily be integrated into. In architectural visualization, MetaHumans can be used to add life to an environment"},{"start":"0:36","end":"1:12","startSec":36.5,"text":"and create a sense of scale. In automotive product design, they can add a human touch to a digital product and can even be used for digital car showroom presentations. In film and television, they can be used as digital doubles of real world actors performing in a digital world. They can also be used to pre-visualize performances with real-time animation workflows. For games, they can be used for high quality cinematics, playable characters, and easily"},{"start":"1:12","end":"1:25","startSec":72.6,"text":"be integrated into UEFN. That's it for this section. Next, we will go over some tips and resources that may be helpful when working with MetaHumans."}],"13_FinalRecsTips2":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"This brings us to the final section of our course. Let's wrap things up by going over a few tips and resources you may find helpful when working with metahumans in your project. We will jump back into Unreal Engine to go over some of these. One thing you may encounter when working with a metahuman in your scene is you may accidentally select one of the components instead of the actual blueprint."},{"start":"0:30","end":"1:00","startSec":30.0,"text":"One way to prevent this and to also move your metahuman around in your scene with ease is to use an actor. Go to the Get Content panel, then go to Basic and select Actor. In the Details panel, with the actor selected, reset the transform settings to zero for the actor, and ensure the position of the metahuman in the level has also been zeroed out."},{"start":"1:00","end":"1:31","startSec":60.0,"text":"Now, in the Outliner, drag the metahuman blueprint over the actor to make it a child of the actor. And now, you can use the actor to move the metahuman around in the scene. This will also prevent the metahuman from reverting back to its default pose and position when moving it around when it has an animation applied to it. Now, before we move on, let's review the steps we just completed."},{"start":"1:31","end":"2:02","startSec":91.0,"text":"We have looked at how we can use an actor to move our metahuman around in our level. To add an actor to the level, go to the Get Content panel, then go to Basic and select Actor. Zero out the position of both the actor and metahuman, and in the Outliner, drag the metahuman blueprint over the actor to make it a child of the actor. Now, let's continue by jumping back into Unreal Engine."},{"start":"2:02","end":"2:37","startSec":122.0,"text":"There may be cases where you have been using a metahuman as a placeholder to block out a scene and are now ready to bring in your final version, or you simply want to replace it with a different metahuman. A simple way to do this is to add the metahuman you wish to use in the level. Then, in the Outliner, select the metahuman you want to replace. Right-click on it and select Replace Actors With, and then select the metahuman blueprint you want in its place."},{"start":"2:37","end":"3:11","startSec":157.0,"text":"And now, we can delete this one and continue working. Let's review the steps we just completed. If you want to replace an existing metahuman in a scene with a new one, add the metahuman you want to replace the existing one with into the level. In the Outliner, select the metahuman you want to replace. Right-click on it, select Replace Actor With, and then select the metahuman you want to replace it with."},{"start":"3:12","end":"3:47","startSec":192.0,"text":"Now, let's go over a few other things worth mentioning when working with metahumans. When working with metahumans, at some point you may be considering changing engine versions. Determine which engine version you will be using as that will define available feature sets for your metahuman. If you decide to upgrade metahumans in a project, just note that there will be a series of steps you will need to go through to ensure you have successfully updated them."},{"start":"3:47","end":"4:26","startSec":227.0,"text":"Metahumans can only be upgraded as previous versions have several variations in skeletal joint systems or blueprint setups that prevent downgrading. We saw with our hands-on exercise how we can use the metahuman plugin and the mesh-to-metahuman workflow to generate a metahuman identity from a 3D model to achieve likeness with our character. You can also generate a metahuman identity from footage using depth footage from an iPhone or vertical stereo head-mounted camera."},{"start":"4:27","end":"5:01","startSec":267.0,"text":"The template mesh workflow, also referred to as conformed mesh, solves a metahuman identity using the mesh-to-metahuman workflow based on geometry. The only requirement is that the 3D mesh uses the same topology as a metahuman mesh. This workflow results in better fitting of geometry in joints. The DNA calibration tools allow you to go beyond the metahuman creator and the mesh-to-metahuman workflow in order to push likeness even further."},{"start":"5:01","end":"5:33","startSec":301.0,"text":"We delve into these workflows in greater detail in the metahuman DNA calibration courses. When integrating metahumans into your pipeline, keep in mind there will be a learning curve. As mentioned at the start of this course, the metahuman framework is made up of a variety of collaborating parts. Having an understanding of each of these assets and how they work together seamlessly is vital to the learning process."},{"start":"5:33","end":"6:11","startSec":333.0,"text":"This can help when making decisions on how to approach modifying the different assets, what and where to look if something is not working, and what changes have been made to feature sets as engine versions update. With each new release of metahumans and feature sets, the end user license agreement may be updated or amended to reflect changes to the legal document that explains a user's rights and obligations related to the use of metahuman technology."},{"start":"6:11","end":"6:46","startSec":371.0,"text":"This can include the metahuman creator, the metahuman plugin for Unreal Engine, metahuman animator, and any other related Epic Games assets and technologies. For Unreal Engine versions 5.5 and earlier, metahuman assets are licensed for use in Unreal Engine projects, meaning users must render metahumans with Unreal Engine. Be sure to read the full agreement carefully. You can locate your ULA history in your user account on the Unreal Engine website."},{"start":"6:49","end":"7:20","startSec":409.0,"text":"Finally, all of the online resources and links to some of the tools discussed today can be found by following the URLs on this slide. Feel free to pause here or take a screenshot for later reference. This brings us to the end of the metahuman introduction course. I want to thank you for spending your time with me, and I hope that these videos help you as you continue working with metahumans in Unreal Engine."}]},"124.05":{"01_Introduction":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Hello and welcome to this course, an introduction to smart objects. We will be teaching this course in engine version 5.6 and all the project files that come with it will be in this engine version. Most of this is relevant from 5.2 onwards. From this course we have a couple of outcomes that we would like to achieve. Firstly, we would like you to have a good understanding of what smart objects are and"},{"start":"0:33","end":"1:06","startSec":33.6,"text":"how they were, also that you can set them up and configure the smart objects for different situations and understand and know how to implement them alongside the gameplay behavior system and state trees. Finally, we would like you to have a good idea of where you can go in order to expand your knowledge and do some more advanced things with smart objects. In this video we are going to be going over a little bit of theory"},{"start":"1:06","end":"1:36","startSec":66.0,"text":"before we jump into the engine and start putting things together. First of all, what are smart objects? Well, smart objects are interactive objects you can place in a level that both AI agents and the player can use. They hold information that is needed for those interactions but not the actual execution logic. So in this project"},{"start":"1:36","end":"2:12","startSec":96.2,"text":"we are going to be doing a lot of sitting down. So a nice example of a smart object because we have to get the skeletal mesh to interact with the chair so that it looks natural. But smart objects don't need to just be chairs, no, but anyway they can be any number of things. At any point you would like your character, player or AI, to interact with the world in a kind of natural way. That's where smart objects can come in handy."},{"start":"2:13","end":"2:43","startSec":133.1,"text":"They work by using a reservation system. At any one point a specific slot for a smart object can either be free, claimed or occupied. So this will allow us to be able to select specific slots. So you can only, you might only want to be able to select a free one but you might want to be able select a free one but you might want to be able to override a claimed one for example."},{"start":"2:48","end":"3:21","startSec":168.6,"text":"At the core of the smart object system is the smart object subsystem. And this is what we would talk to at any point that will allow us to go in search and filter for our specific smart objects and be able to reserve them so that we can use them and release them and finished with them. The main class that we're going to be working with is the smart object factor component."},{"start":"3:22","end":"3:52","startSec":202.0,"text":"And this is what we are going to be adding to our numerous chairs but can work with any different smart object. The smart objects themselves do not contain any game pay logic. You'll see that this whole thing is quite modular and we'll talk about that a little bit but this allows us to reuse game pay logic in different places. So in this we would have a behavior"},{"start":"3:52","end":"4:22","startSec":232.1,"text":"definition which would tell the players what to do such as play and animation or trigger and the smart object subsystem has a lot of functionality that will allow us to filter and search the smart objects that are in the world is mainly done spatially. So we can find objects which are physically close to our agents but we also can use gameplay tags."},{"start":"4:23","end":"4:58","startSec":263.4,"text":"The full cycle works a little bit like this. The subsystem will search for a specific smart object, claim a slot then depending on how you have the behaviors set up and your state tree who would move to it, perform the behavior and then after the behavior is marked as done it would release the slot again. So this process makes interactions structured hand-reliable. Now there are three other classes that I would like to touch on before we get into the ended"},{"start":"4:59","end":"5:34","startSec":299.6,"text":"and these are the core classes that we will be manipulating to put together our scene. First one is definitions. This controls the slots, the entry points and the setup. Then we have the config. Now this is a data object that will provide different parameters for the behavior. We're going to use it to change the animation that's played. Finally there is the behavior itself and this is what holds the actual instructions for what the"},{"start":"5:34","end":"6:09","startSec":334.9,"text":"characters are going to do. As you can see in this illustration here, her behavior can be referenced by multiple configs and a config can be referenced by multiple definitions. It is worth saying a lot of the smart object functionality is exposed to blueprints. However C++ still has a lot more power over this system. So if you find yourself limited by what"},{"start":"6:09","end":"6:30","startSec":369.3,"text":"the smart object system does if you're working with blueprints, it might be worth jumping into the C++ in order to tailor the system to your specific needs. And that brings us to the end of our theory. Next up we will be jumping into the engine and start putting some smart objects together."}],"02_ProjectSetup_56-":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hello and welcome to this video where we will be jumping into the engine and starting off some of our exercises. Before we start there is a project file which comes with this course. I highly recommend that you download it. This course is designed to be a follow along and this really helps to make sure that you know how to set everything up and have some hands on experience working with it."},{"start":"0:30","end":"1:02","startSec":30.5,"text":"Now there are a few plugins that you might want to have turned on or who are actually required some of them if you want to use smart objects. In the project that we are downloading these plugins should already be turned on so you don't need to worry about setting them up and restarting them but I would like to go over them here. So to start off with we have the smart object plugin and this is what will allow us to set up and use the smart objects."},{"start":"1:02","end":"1:36","startSec":62.0,"text":"The second one is the AI behavior. Now the smart object system doesn't necessarily use the AI behavior system but it is recommended and this is the system that we are going to be using in all of our examples. It is a modular way of creating behaviors that can be plugged into things like state trees. And in order to get these running in combination with each other there is another plugin that we are likely to turn on and that's the gameplay behavior smart objects."},{"start":"1:36","end":"2:11","startSec":96.7,"text":"Now these two systems to talk to each other. Now we are going to use another plugin which again is not necessary but it does really help when you are trying to tie together animations with specific locations and measures. And that plugin is motion warping. What this is going to allow us to do is adjust animations dynamically so that we can have things like sitting, vaulting and interacting can line up correctly with the smart objects"},{"start":"2:11","end":"2:45","startSec":131.8,"text":"and the measures that are within the level. Now with that said let's jump into the project and we will start off by creating the classes that are going to be needed. Now when you've downloaded this project and opened it up you should hopefully get a screen that looks a little bit like this. Now we are using something that is called the trained and paid and what this is going to allow us to do is it's going to allow us to move between the different sections of"},{"start":"2:45","end":"3:21","startSec":165.6,"text":"the project as we are going through and it's going to highlight the assets that we are going to want to be used. So hopefully this fires up a new start up. If not under the links first kill this town under the link selection we have the training paid and that will bring this up. What I usually recommend is that you take it and you dock it in the top here and ideally place the heartline below it and if you bring it down so you can just see the top you can"},{"start":"3:21","end":"3:53","startSec":202.0,"text":"check that you are on the same slide as me and we are in the correct place to teach the class. If you don't have it don't worry too much the level itself isn't too hard to navigate. I am going to jump to the first slide here the example chairs. One thing you can see is this is brought on my content browser and we are going to be doing a lot of work in the content browser so I am going to hit the button dock in layout."},{"start":"3:53","end":"4:25","startSec":233.9,"text":"Now you can see that we have it down here. We are at the exercise one and we can see that we have our files that we are going to be looking at. Now at the moment we have one NPC who is in the level if you had a push play he would do nothing. Well this is because we have some problems in our state tree and if we have a look at our state tree chair and I was doing that up as you can see we have a relatively simple"},{"start":"4:25","end":"4:57","startSec":265.4,"text":"state tree and what it is going to do is we have a root and we have seen if we can find a smart object that is unclaimed and we use that smart object if we can find it. Now if we do not find the smart object we are going to come down to the part of combat here and wander about and go back to root and after we have come back to root we are going to check to see if we have a smart object again."},{"start":"4:57","end":"5:32","startSec":297.0,"text":"So it is a straight forward we have two settings we are wandering around with using a smart object. Now the reason why this is not working is because if we really jump into the tasks you would see that we are lacking a load of code and that is because we are going to add in this code as part of the exercise so that we can see how it is working. But before we do that we are going to need to create a few different classes."},{"start":"5:32","end":"6:02","startSec":332.5,"text":"So the first class that I would like you to make is gameplay behave. So this is what we are going to run when we actually go in and use the object. So I am going to come up in here I am going to search for blueprint class and I am going to search for gameplay behavior and you can see that we have gained by behavior here."},{"start":"6:02","end":"6:44","startSec":363.0,"text":"And I will select that and I am going to name this GB for gameplay behavior and sitting down. So we are going to be doing a lot of sitting down. Okay so that is my first class. Now the next class that I want is going to be the gameplay behavior config. If you right hand click again come up to the blueprint class and search for gameplay behavior"},{"start":"6:44","end":"7:17","startSec":404.6,"text":"config. See that we have that here and it is a behavior config and we will open that up. And it goes gameplay and I will rename this GBC under store for sitting down. So I have gained by behavior config. So again the gameplay behavior is the actual thing that we are going to do."},{"start":"7:17","end":"7:51","startSec":437.7,"text":"The config is the configuration where we can change some of the settings in the gameplay behavior. Now the next thing we are going to do is create a smart object definition. Now this is slightly different to how we have created the other ones because what we are actually going to do is right hand click and we are going to be looking into the miscellaneous side. And from this we are going to be selecting a data asset because this is what the definition"},{"start":"7:51","end":"8:25","startSec":471.5,"text":"is going to be part of. So if I search for smart you can see that we have an option for a smart object definition. I am going to select that and I am going to call this smart object definition so sod and this is going to be for a chair. I am just going to call that sod chair. Now we have all the files we need in the next video where we can start setting them up so"},{"start":"8:25","end":"8:27","startSec":505.4,"text":"that they work in conjunction with each other."}],"03_ChairActor":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Hello and welcome to this video, we're going to be carrying on the exercise here and all we're going to be doing is we are going to be creating the smart object actor itself and connecting everything up to it. So for this smart object itself, we can actually select any class which is below the actor, but for this we're just going to be working with an actor direct."},{"start":"0:31","end":"1:02","startSec":31.5,"text":"We're going to call this BP Chair. I double clicked and open this up. You'll see we have a standard actor here and we're going to need a couple of odds and salts in this. First thing that we're going to need is the static mesh itself. So if I come in here and I search for static mesh in the components, see we have a static"},{"start":"1:02","end":"1:33","startSec":62.9,"text":"mesh. Then I'm going to call this SM underscore chair. To call this static mesh, I'm going to search for the same one SM underscore chair, then you should see that we have this chair here. Okay, so we have our physical representation. Now I'm going to add in a couple more things. First thing I'm going to add in is a box collision."},{"start":"1:33","end":"2:08","startSec":93.5,"text":"And this isn't a necessity, but what you will find when you are working with smart objects is that we have a little bit of a challenge often with collisions in order to get the static mesh to sit cleanly onto a chair. At some point, some collision needs to be turned off. And in this case, we can turn off the collision on the chair itself. And I only had a collision find it, just so it's a very small collision."},{"start":"2:08","end":"2:42","startSec":128.9,"text":"I'm going to scale down here. I'm going to use this as a method of preventing other people from walking through the chair as it's going on. So if you can do that, that just means that we can turn off the collision on the chair and it will, and it, and our navigation is still, is going to be infected. Okay. So let us jump in for this collision."},{"start":"2:42","end":"3:14","startSec":162.2,"text":"We need to change the collision preset because these are set by default to overlap dynamic. And we want to put it down to block all. So that gives us our back collision. Go helping with that. Now what I'm going to add is our smart object component. You can see here, it is down here on the, as we're going through, smart object here."},{"start":"3:14","end":"3:47","startSec":194.6,"text":"So in our smart object, we need to provide it with a smart object definition. And you can see that we have our chair, smart object definition chair. So we're going to use that on that. Now I'd like to actually put this in place, but we have not fully set up our smart object definition. So I'm going to double click and open this up. So here we are in our smart object definition for chair."},{"start":"3:47","end":"4:22","startSec":228.0,"text":"And I know we can do a more advanced one in the second exercise. For this, I would just like you to add in the Sundiana slot. So you can see at the top here, we have had slot. And you can see that this is going to have none below it here. But what we want to do is we want to connect up the default behavior definition to the push pride and do a drop down. We go work with the gameplay behavior smart object definition and a third one down here."},{"start":"4:23","end":"4:54","startSec":263.2,"text":"We're going to do the drop down and we're going to go with the GBC sitting down. So that's everything there connected up. What we should see when we go back to our BP chair, so you can now see that we have our slot is visible. Now I'm going to move it a little bit further forward. But until we get the animation running, it's going to be a little bit hard for us to figure"},{"start":"4:54","end":"5:28","startSec":294.8,"text":"out where this slot needs to be. So I will leave that as it is all the time being. Now there's one more thing that's let's do with this chair. And that's to add a interface. So we've always point you should have used interfaces quite a lot. They define a method for us to communicate between actors without having to know necessarily what the actor is. Before this interface, I'm going to come to class settings and implement interfaces."},{"start":"5:28","end":"5:58","startSec":328.2,"text":"I'm going to search for BP smart object interfaces. And with that, we will be we will be given a couple of functions that we can override down here that we would do when we get to the coding side of this. With that, I will save and comply and I can drive each chair into the world. So we'll finish the video there."},{"start":"5:58","end":"6:01","startSec":358.4,"text":"In the next one, we're going to be doing some of the actual coding."}],"04_FindSmartObjects":[{"start":"0:00","end":"0:29","startSec":0.0,"text":"Hello and welcome to this next video. In this we're going to be doing some of the coding. We are going to be jumping into the Find Smart Object task and we're going to be accessing the Smart Object subsystem for the first time. Okay, so the first thing I would like you to do is to come down to the STT underscore Find Smart Object and double click to open it."},{"start":"0:30","end":"1:01","startSec":30.6,"text":"So here we have it here. As you look at this you can see that we already have the Interstate showing and that is if you were creating this from scratch you wouldn't have it. You'd have to get it from the overrides here in the drop down. But because we are trying to make this a bit silica we've already dragged it in and added it. We've also created a number of the variables. Bear in mind these variables are in the appropriate categories so we have context"},{"start":"1:01","end":"1:36","startSec":61.8,"text":"for the character and the AI controller and we have the claim handle and the slot handle for the output. These are so that they can be accessed through the state tree as part of the task and can be populated. So let's see what code we've already got. So if I scroll out and come over to the end here you can see that we have some code already here. We've got our finished task. And this is required for us to tell the state tree that we have succeeded in this task."},{"start":"1:37","end":"2:10","startSec":97.5,"text":"But before it we have a little bit of code that is going to allow us to grab the claim handle and the smart object subsystem and get the slots transform and save it to our AI. AI is the BP NPC chairfinder. Now this probably isn't the best modular way of doing this but we are going to need the transform. Probably using interface in other instances but I think"},{"start":"2:10","end":"2:41","startSec":130.5,"text":"this shows what's going on quite well. We're going to need the transform in order to hand it to the motion warping. So that is where we are going to move the mesh using root motion so that it can sit down and perfectly interact with the chair. So warping is going to allow us to move the skeletal mesh and make it so that when it sits down it actually sits down on the chair."},{"start":"2:42","end":"3:17","startSec":162.0,"text":"So all this is doing is if we get to this point we are grabbing the chairfinder and saving the transform of the mesh so that it knows where to sit. Okay I am going to jump to the beginning here and go through piece by piece. Now bear in mind there's always a finished version of the code in the finished version folder so if you do get stuck you can jump in and get it but I encourage you to copy alongs so that you understand what each of these nodes do. The first thing that we want"},{"start":"3:17","end":"3:55","startSec":198.0,"text":"to do is find the smart objects. Now I am going to right-hand click and we are not going to be able to find the smart object from here because it is a node which is part of the smart object subsystem. So I am going to type in smart object and sub and that will bring me a option to get the smart object subsystem. And once I have that I can drag off and I can search for find smart objects."},{"start":"3:55","end":"4:29","startSec":235.6,"text":"We are going to be finding multiple in this case and then selecting one random. So that's the code that I need. We will need to get the character to plug that into the use actor. This is the actor that is using it. And now the next thing we need to do is make a request. So I am going to drag off of the request pin and I am going to type make and you will see the only one that comes up is the make smart"},{"start":"4:29","end":"5:02","startSec":270.0,"text":"object request. I need to drag off this request pin. And as you can see as part of this make smart object request we have two inputs the query box and the filter. We will start with the query box. What the query box is going to be is the spatial so the locational size which we are going to search for a smart object. And if we look over this"},{"start":"5:02","end":"5:35","startSec":302.8,"text":"this is of a box structure. So we need to make a box. I am going to drag off from there. I am going to type in make and you will see at the bottom here we have make box. Now for this to be a box we just need to give it a minimum vector a maximum vector. However we need this to be relative to the AI. So this is in world space. I am going to grab my"},{"start":"5:35","end":"6:14","startSec":336.0,"text":"hacked again and I am going to get actor location. Drag that in and for the minimum I am going to do is I am going to minus. So I am going to subtract and on the subtraction I am going to right hand click on the second input pin and I am going to change that to a float double precision. I will plug that into the minimum."},{"start":"6:15","end":"6:46","startSec":375.6,"text":"Let's change it. I will do both of them first. I come up and I am going to do a plus and I am going to add that into a maximum. I am going to convert both of these to a float. And then I am going to type in literal low. We will plug this in to both of the boxes. We could make this variable."},{"start":"6:47","end":"7:17","startSec":407.4,"text":"Well what this is going to do is it is going to allow me to just type in the squeeze of the box. And for this I am going to go big. So I am going to put that in 20,000. So that we definitely find something. Now it is very reasonable for that to be a smaller amount and could make a variable included in the inputs so that we could change it at the point that we are searching. But this will do for us at the time being."},{"start":"7:18","end":"7:43","startSec":438.1,"text":"So that gives us our query box. Now next we have the filter. For this I am going to drive off and type make again and you see it has detected the pin that I have got and it is suggesting make smart object request filter."},{"start":"7:48","end":"8:19","startSec":468.5,"text":"Now with this you can see that we have two pins down the left hand side. A user tags and plane priority. I am actually not going to change either of these. But I do need to do some inputting. So I am going to do the drop down that we have here. And you can see that we have a number of different options. It includes elements such as should include claim spots and should include disabled spots."},{"start":"8:20","end":"8:53","startSec":500.4,"text":"But I am just going to leave it with should evaluate conditions. Now what we do need an input for which this is not going to function without is the behavior definition classes. So in order to do that I am going to drag off and do a make or a worry. And for the make or a I am just going to select the game play behavior smart object definition."},{"start":"8:57","end":"9:30","startSec":537.6,"text":"That is all we need for the smart object filter. However do bear in mind that if you did want to make something more advanced you could make a more complicated filter here in order to create something a bit more complicated. Grad wise we will up just a little bit with the smart object just for formatting. So I will drag that up a little bit more and try and get it all on screen so I can just leave it"},{"start":"9:30","end":"10:01","startSec":570.9,"text":"there for a second. So this is our first section to find smart objects in the local area. Right with that done let me jump on to the next section. Now what we need to do is figure out if we are not getting any smart"},{"start":"10:01","end":"10:29","startSec":601.5,"text":"objects because we want to return a failed condition if we don't have any smart objects. So this is relatively simple we've got a return pin here if I hold down B for plush I can connect that up and plug in the condition and if it is false we want to finish the task but we want to finish the task as a fail."},{"start":"10:31","end":"11:07","startSec":632.0,"text":"We are quite straightforward if we have no object returned to all then we fail to find our smart. Now next we want to mark slot as claimed and get main handle. So we have all results here. With this I am going to write off and I am going to type in random so we get a random array item. Now you can see from this we have a smart object request result structure."},{"start":"11:08","end":"11:45","startSec":668.2,"text":"I am going to right hand click and you can see we have an option to split the struct pin. I am going to do that because what we need is the slot handle. It is not the smart object handle but just the specific slot because we might have multiple slots on the actor and we want to work with that slot. So I am going to now draw right off of the slot handle and type in mark smart object as claimed. So we haven't returned any so we can now grab this and mark it as claimed."},{"start":"11:46","end":"12:27","startSec":706.4,"text":"Again we need a use actor so I will get my character, to round it over so you have a little green line there and that plugs in perfectly. Now the claim handle is actually part of our outputs. Now we have our claim handle. We might as well do the same thing on the other side. So I am going to drag the claim handle, place it over the output pin and it will automatically connect it up like this. So we now have grabbed a random one of the slots and we have slamed it and set that claim handle"},{"start":"12:27","end":"12:58","startSec":747.1,"text":"so that it can be as part of an output for this task. So we have our final piece of code and this brings us to our final piece of code. So all we need to do now is connect that up and that is our entire code done and dust it. Now we cannot test this until we have got the other codes and bits of running."},{"start":"12:59","end":"13:23","startSec":779.0,"text":"I would believe that all makes sense. You need to save and compile to check that there are no errors and I am going to go back to my lab. So thank you very much that brings us to the end of our first piece of coding. The next one we are going to finish off the task that actually runs the behavior."}],"05_UseSmartObject":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"Hello and welcome to this video. For this video, we are going to be doing the code for the use smart object task. So what I would like you to do is open up the STT underscore use smart object. And for this, like the previous task, we have the files it's up mostly already. We have automatically overridden the end state task here."},{"start":"0:36","end":"1:16","startSec":36.2,"text":"And we have two comment boxes so that I know what we're supposed to be putting in. And in the variables, we have the context so we can easily get hold of it and an input for the claim hand. Right. So the first thing we're going to want to do is check to see the claim handle is valid. I'm going to drag in the claim handle and get it. Then the drag off just type is valid."},{"start":"1:16","end":"1:52","startSec":76.5,"text":"Again this is giving us a is valid output Boolean pin. So I am going to hold down the letter B to create a branch and lug that in. If it's false, we want to finish the task but with a failure. And on true, we are going to move to that smart object and use it."},{"start":"1:52","end":"2:24","startSec":112.8,"text":"In order to move to it, the instruction we need to provide to the AI controller. So we have in our context here a reference to our AI controller. So I'm going to grab that. And then I'm going to show right off and search for move to and use. And you can see that's going to give us the option to move to and use the smart object with gameplay behavior."},{"start":"2:24","end":"2:54","startSec":144.6,"text":"And that's the one that we want. So I will now like this in. Now at this point, what this is going to do is going to tell the AI to walk to wherever the smart object is. And once it's got there, it is going to hand over control to the game. So this is where we fundamentally leave the state trip."},{"start":"2:54","end":"3:26","startSec":174.7,"text":"However, we still need a finished task. So I am going to drive off succeeded. And then I'm going to search for finished task. And I'm going to with it selected press control D to duplicate it. So I'm going to do a failed on both the on fail and the move to fail. So this is two tasks."},{"start":"3:26","end":"3:59","startSec":206.3,"text":"First, it's going to move and then it's going to play the gameplay by the on fail would be the failure of the game by the and the on move to fail would be that moved. And the final thing was to do here to make sure we have the input from the flame handle connected up to the move and control. So this is where it's going to find the gameplay behavior. And that is all we need to do."},{"start":"3:59","end":"4:15","startSec":239.4,"text":"All of the rest of the work will be done in the game behavior. And we'll do that in the next video. That brings us to the end of the quick video. Next up is going to be a bit of a long one because we are going to need to set up gameplay behavior."}],"06_GameplayBehaviour":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Hello and welcome to the next video in our exercise, in this we are going to be programming the gameplay behavior. So for this I would like you to open up GB underscore sitting now, this is our gameplay behavior. When you open it up you will get a screen just a little bit like this. Now this is a data-only blueprint at the moment."},{"start":"0:34","end":"1:04","startSec":34.3,"text":"What we are going to want to do is add code. So if you come up here you will see that there is an option to open the full blueprint editor. If you click on that you should get something that looks like what we are more used to working. What I would like to do is first come up to the functions that are overriding. And what we are looking for is the on-triggered character. There is a number of on-finished and there is a number of untriggered."},{"start":"1:05","end":"1:39","startSec":65.7,"text":"But different events are going to give us different pins that we are going to be able to access. And this isn't a task, it is part of the stature, so we are not using the variables and the context to get data in and out. So I am going to select on-triggered character. Now it is going to bring up this build. Now I am going to be referencing these values quite a few times. So to make it neater I am going to save out a couple of these two variables."},{"start":"1:40","end":"2:16","startSec":100.8,"text":"So the first one I want is the power timer. Right hand click and you can see we have an option to promote to variant. If that in it creates the variable and we are good to go. Now the second one is the smart object owner. So what I would like to do is right hand click and again promote that to a variable and plug that in after you have it. Now after I have done this the first thing I want to do is turn off the collisions on the share."},{"start":"2:17","end":"2:51","startSec":137.4,"text":"Now the collisions are going to be different smart objects. So I am not going to hard code it here. What I am going to do is drag off of the smart owner object and I am going to go turn off collisions. You can see our interface we have an option to turn off the collisions. So that is going to send an interface message to just turn off the collisions. It is a nice quick way and we will put the code on the smart object itself in a minute."},{"start":"2:55","end":"3:32","startSec":175.1,"text":"The next thing I would like to do is I want to make sure we have the look target set up correctly. And we saved that variable to the AI. So unfortunately we are going to need to do a cast at this point to make sure that we have it. So I am going to drag in the avatar and I am going to cast to BP underscore NPC share from the end. And once I have that I am going to get off of the pit."},{"start":"3:33","end":"4:06","startSec":213.1,"text":"And once I have that I am going to drag off and I am going to find the smart object transform. I am going to get the smart object transform swap. This is the variable that we made in that piece of pre-written code. And then I am going to get component by class. And the component that we are looking for in here is the motion warper."},{"start":"4:09","end":"4:38","startSec":249.4,"text":"Motion warping component. And I am going to add or update warp target transform. I am going to plug that in and I am going to connect that to the cast like this. Now there is one last thing we need to do and that is set the warp target name."},{"start":"4:39","end":"5:14","startSec":279.8,"text":"In this instance the name is share. So just set that to share. That is quite straightforward. Unfortunately this is the only non modular part at this point. But what we are doing is we are just updating the warp component so that we can see it play. Now we are all ready to play the montage. What I am going to do is I am going to again grab the avatar."},{"start":"5:17","end":"5:46","startSec":317.3,"text":"And I am going to go play amy montage. And we have the animation montage here. We are going to promote this to a variable. And in the defaults I am going to search for sitting down."},{"start":"5:48","end":"6:19","startSec":348.4,"text":"So that is our animation montage. This is the first time that we are playing animation montage. Now you may have noticed that we are using this animation montage node not the normal one which has the calculate pins for when it ends. That is because we are unable to use those kind of nodes within the gameplay behaviour. So we have to be a little bit cleverer in order to make this whole thing run correctly."},{"start":"6:20","end":"6:57","startSec":380.7,"text":"So the first thing I am going to do is you see this return value. This is going to return the length of the animation in seconds. I am going to promote this to a variable. I am going to name this animation black. And I am going to press slide. So we are just running the animation and record the map. Next up, I will have to wait until this animation has finished running."},{"start":"6:59","end":"7:35","startSec":419.7,"text":"And have a bit of idle time in the middle. So rather than having the outlet pin what I am going to do is drag off and go set timer by event. And we have an input for a tiny. So what I am going to do is grab my animation length and I am going to add to it. I am going to add three seconds and plug that output into the timer."},{"start":"7:36","end":"8:12","startSec":456.0,"text":"So applying the animation, wait for however long the animation is. Plus three seconds and then it is going to kick off our new event. So I am going to drag off here and go add custom event. I will name this custom event. Stand up. So for this custom event, I will do two things."},{"start":"8:12","end":"8:40","startSec":492.6,"text":"I am going to create a sequence. So I am going to do two things relatively immediately. Now the first thing I am going to do is I am going to bring in our avatar. And I am going to get the mesh. And from this I am going to play a montage."},{"start":"8:42","end":"9:16","startSec":522.8,"text":"So and I will switch. I am going to plug in the montage again here. Now I already know the type so I do not need to use the other one. So it does not really matter because I am not using the outlet pin. I am using the sequence here before. But what I would like to do, what I need is this starting position and this play route. So what I am going to do is I am going to get the animation length. And I am going to plug that into the starting position."},{"start":"9:17","end":"9:48","startSec":557.3,"text":"So that means we are going to start at the end. However, I do not want the play route the length to be one, I want it to be minus one. And that is so we are playing it backwards. So what this will go away and do is it will run the animation backwards, starting at the end. I am not worried about any of the other outlet pins I will miss."},{"start":"9:48","end":"10:18","startSec":588.2,"text":"That is all I am using this for. And once this animation has run, we are going to have to come out of this. So again, I am doing what I did before and that is set timer by event. And we know this is going to run for the same amount of time so I just need to plug in the animation length. Now I am going to drag off, add custom event."},{"start":"10:19","end":"10:48","startSec":619.1,"text":"And this event I am going to call stop, montage. Now there are a couple of ways that you can stop the montage, but our goal is to go back to the previous animation. Now one of the things we have not mentioned before barboring this up is if we were to go away and actually look at the montage itself, double click on the montage, and then we are going to go back to the animation. So we are going to go back to the animation. And the montage."},{"start":"10:54","end":"11:26","startSec":654.6,"text":"You can see that we have a couple of pods and sobs in here. First one is we have our motion warping section at the top here. So I just add in, add state motion warping. So that is required. How to get the motion warping to work on the animation itself. We need to make sure that we have root motion turned on. So let's have a quick look at that. So if I was to fire that up, this is the animation."},{"start":"11:26","end":"11:57","startSec":687.0,"text":"In the details, we need to make sure we have the enable root motion here. Fire that back to our montage. The other element that we need is we need to disable the enable auto blend out. And it's a very simple reason we're doing this. It's because when we play the animation, we're sitting down,"},{"start":"11:57","end":"12:25","startSec":717.4,"text":"we want the character to stay at the end of the animation. So we're turning off the enable auto blend out. However, this does also mean that we're going to have trouble coming out of the animation. Because without a blend, it's not going to seamlessly convert back to the animation blueprint. And that's why we're doing the little bit that we're doing next."},{"start":"12:27","end":"12:58","startSec":747.4,"text":"So we went back to the sitting down, we're stopping them on touch. Now there is a node that will allow us to just directly stop the montage. The problem with that is it can jump back to the animation blueprint and it will pop out because there's no blend. So what I'm going to do instead is I have created another animation. Just call transition. And it goes to select here."},{"start":"13:00","end":"13:32","startSec":780.3,"text":"There is very little to it. But what it is is it is the character in the idle mode, which means that we can now blend out this animation. I'm actually giving us a relatively perfect blend. So I've created this and all that it is is a very, very short section of the idle animation. We've the blend out automatic KNA. So that we don't have to have the plot at the end."},{"start":"13:34","end":"14:06","startSec":814.9,"text":"Okay, so how I'm going to do this is again, I'm going to drag our avatar. Then I'm going to drag off and get this color to mesh. Pick any of these to color down some of this way to do that. And I'm going to play in one. So I'm going to hem into the next element out and move it to theamosos Location Se understandable,"},{"start":"14:06","end":"14:39","startSec":846.5,"text":"because it has to see this entire section, but then I'm going to match all the appeared video pregunta with everything else that I made here. And what I'm doing now is a flow-ish exchange and control and see. And thanks for sticking with us with that one, then next up we're going to finish off"},{"start":"14:39","end":"14:41","startSec":879.5,"text":"some odds and sorts and get this up to Nuremberg."}],"07_TweakingAndTesting":[{"start":"0:00","end":"0:37","startSec":0.0,"text":"Hello and welcome to the final video in our series of exercise 1, in this we are going to be tidying up the end, we are going to be testing and getting the whole thing to work. To get back in the engine the first thing I would like you to do is to come into our config file, GBC sitting down, and we need to set our behaviour once, we are going to sell that to GBC sitting down, file and say. And the next thing I would like you to"},{"start":"0:37","end":"1:12","startSec":37.8,"text":"do is to come into the chair, and we are going to sort out this collision, so we already have the interface here, so I am going to implement these events and put the code, the first one is the turn off collision, implement and this is the straightforward, we are going to grab our chair mesh, drag out, and set collision enabled, log that in and we are ok with no"},{"start":"1:12","end":"1:45","startSec":73.0,"text":"collision, so we are just turning off the collision at this point, next up I want to do the turn on collision, and this is a little bit more complicated, because we don't want to turn the collision on immediately, because the actor will still be over it, it would push them away and it would look a bit unnatural, so what I am going to do is I am going to add in a check to see that the actor is far enough away before turning the collision back on again, so the first"},{"start":"1:45","end":"2:19","startSec":105.4,"text":"thing is this character, right hand click and promote to a variable, then I am going to drag off and I am going to do set timeout by event, and so this I am going to set to 0.5 and then I am going to make it loop, so this means any event which is attached to here, it is going to happen twice a second, whilst this timer is on,"},{"start":"2:21","end":"2:53","startSec":141.4,"text":"now I am going to want to turn off this timer, so I am going to save it to a variable and call it timeout, so I am going to drag off this event, go add custom event, and I am going to call this check distance, and from this I am going to drag in the actor, get to it, and I am going to get the actor location,"},{"start":"2:57","end":"3:32","startSec":177.8,"text":"and also select the actor location and go ctrl D in order to duplicate it, then I can drag off and get the distance in vector, so this is going to return me a float of the distance between the actor and the chair, now if this is greater than 120, then I want to turn the collision back on,"},{"start":"3:33","end":"4:10","startSec":213.1,"text":"so hold down B to bring up a branch, lock that up in and connect that up, then what I can do is I can get the chair and set collision enabled, if it is true, and I want to set this back to collision enabled, then finally I want to get the timer, and I will be applause this,"},{"start":"4:11","end":"4:46","startSec":251.8,"text":"applause timer by hand, so that should give us power code in order to turn it back on, just come away until the actor is far enough away and then switch the collision back on, now there's one more thing that I need to do and that's to call this, so I'm going to go back into gameplay behavior, and after the final play montage, I'm going to drag in the reference to the smart object,"},{"start":"4:47","end":"5:23","startSec":287.3,"text":"and I'm going to set, I'm going to turn, and then I'm going to set the collision on, now in order to get this to work, I also need to plug in the avatar to the actor here, so that gives it all of the information in needs, okay let's test this out, in fact in the world now I'm going to press simulate,"},{"start":"5:24","end":"5:56","startSec":324.8,"text":"and we seem to have a problem, our character is wondering about, but he is not noticing the chair, I know why this problem is, if I had push down p I can see the navigation, and the actor is only going to go and do the behavior, if it is able to reach the slot, but because of the way we have set up this, the navigation cannot find a route to get"},{"start":"5:56","end":"6:31","startSec":356.4,"text":"close enough to do the slot, but it's a relatively easy fix, just going to jump back into the chair, and in the viewport, and going to take the smart object, and move it forward, and that way it should be picked up, now this will affect how the animation is played, but because of the way the animation is set up it should still work, so now if I push play, you can see our character immediately walks over to the chair and sits down,"},{"start":"6:31","end":"7:04","startSec":391.9,"text":"waits three seconds, and stands the cover again, and nearly sits down again, so that looks like it's working, however what I would like to do is to make sure this is completely working, I'm going to bring up three chairs, and I'm dragging with alt button held down, and I'm going to bring up six ai, and then I'm going to press simulate,"},{"start":"7:08","end":"7:44","startSec":428.6,"text":"now this looks like it is working, probably three of them have the claim to spot at only one time, however they're having a bit of trouble because the other ai are getting in the way, so let's see if we can do something about that, the first thing that I'm going to do is I'm going to go into our npc chair finder, and on the movement component, I'm going to search for rvo, and turn on use rvo avoidance,"},{"start":"7:44","end":"8:17","startSec":464.8,"text":"and I'm going to go into the test, and see if there's still any problems, slightly better, what rvo avoidance does is it means that the characters will give a slight push away from each other, so it's harder for them to get stuck, now there's one more thing I'd like to do, and this needs to be done on the BP chair,"},{"start":"8:19","end":"8:53","startSec":499.2,"text":"and for that I'm going to add in a nav modifier, and in the nav modifier, I'm going to change the area class to a obstacle, and in order to get this to work, I'm going to add in a sphere collision, I'm going to expand it out to be about Haiti, I'm going to drag it out in front of the chair, maybe a little bigger,"},{"start":"8:54","end":"9:29","startSec":534.6,"text":"and if we have a look at the environment, you can now see we have a little costly area around the chairs, and if I was to run in this, you're going to see that they're not going to want to get close to the chairs anymore, unless they have to, so they will move away from the chairs, for doing anything, and they won't cross in front of it, they'll give it a bit of space,"},{"start":"9:31","end":"9:59","startSec":571.2,"text":"and this really does sort of meet and eat all lock, and allows the characters to have a more natural walking in, and with that we come to the end of exercise one, and we will be doing a couple of other little bits and bobs, but nothing is going to be as complicated as this, so thank you very much."}],"08_Exercise2":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Hello and welcome to this video on Exercise 2. And in this, we are going to be using a different animation so that we can make our smart objects a little bit more modular and a little bit more reusable. Now there is a reason why we have so many different classes when we're setting up a smart object. And that is so that this can be scalable and modular. So that we can write one piece of code such as the behavior."},{"start":"0:31","end":"1:01","startSec":31.0,"text":"Then we can set up different classes with different settings and we can reuse that without having to write a whole new piece of code. Now in this instance, we already have a chair actor, which has an animation attached to it. We are going to create a different definition and have this be controlled by our config. And we're going to play a different animation so it can function in a slightly different way."},{"start":"1:01","end":"1:32","startSec":61.0,"text":"So for example, at the moment we have a floor spot and we have a chair spot. And as you can see, our chair spot is working fine, but our floor spot has a completely inappropriate animation. So I am back in the engine now and I have gone to slide exercise 2, expose parameter. Now this should also bring me to the folder for exercise 2 with the different files that we need to edit."},{"start":"1:32","end":"2:05","startSec":92.0,"text":"So if we have a look at the files, they're very similar to the ones we had in the previous exercise, but at the point where we should have finished it. We have our chair, we have our AI, we have our game behavior sitting down, and we have our game behavior config sitting down. And we have two definition files, one for chair and one for floor. Now if I was to simulate, you'd see that both of our characters work."},{"start":"2:05","end":"2:35","startSec":125.0,"text":"They grab their appropriate spots, but our character on the left here is not sitting on the floor, he's sitting in thin air. So let's see how we might go about fixing that. The first thing that I'd like you to do is to open up our GBC sitting down EX2."},{"start":"2:36","end":"3:10","startSec":156.0,"text":"And if you come up with this as a data only, just click on the open, open the full blueprint, the blue button at the top. Now all we need to do in this is add a variable. So under variables, I'm going to hit plus, and I'm going to call this variable montage. And on the Boolean dropdown, I am going to look for Ami montage, and I am looking for a object reference."},{"start":"3:10","end":"3:45","startSec":190.0,"text":"Now if I hit compile, this will allow me to put a default value in. Now under the default value in, I'm looking for sitting down. Because that's our default sitting in a chair. And that is all I need to do in this, but I am going to close that down. And the next thing I'm going to do is I'm going to go into the gameplay behavior. So that is GB sitting down underscore EX2."},{"start":"3:45","end":"4:18","startSec":225.0,"text":"Now you should see at the beginning of this file, we have a caption at the beginning here, prompting us to put some code in. Now we want to get this value from the config file. So I'm going to pull that out and I'm going to type in cast to, and I am looking for GBC, the config, and we want exercise to. I'm going to plug that in here."},{"start":"4:18","end":"4:47","startSec":258.0,"text":"Now this will give us access to the config. And if I jump out of here, I can search for montage. So if I get the montage and we have a variable for the animation montage, which I'm going to plug in here, because this is the variable which is used throughout the system for updating it."},{"start":"4:48","end":"5:20","startSec":288.0,"text":"So all we're doing is going to the config and saving whatever is in the config to the variable here to be used in the gameplay behavior. Now I can save and compile, shut that down. We just have one thing left to do and that's if we open up the definition file for floor. So that is SOD underscore floor underscore EX2."},{"start":"5:20","end":"5:50","startSec":320.0,"text":"Now you will see in our gameplay definition, we have an option for sitting down. Now I can override this. You can see that we have a montage for sitting on the floor. And if I save that. Now if we look at the BP floor spot in the smart object, I have already selected that definition file."},{"start":"5:50","end":"6:20","startSec":350.0,"text":"So we don't actually need to do anything within the floor spot. And if I now push simulate, you'll find that the character selects the correct animation for the smart object that they are sitting in. And that brings us to the end of exercise two."},{"start":"6:20","end":"6:31","startSec":380.0,"text":"In the next one, we are going to be looking at using multiple spots to create something slightly more complicated."}],"09_Exercise3":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Hello and welcome to exercise three using multiple slots. So in this exercise, we are going to be creating a bit more complicated definition file so that we can imitate something that might be like a car or something like that. But where you want to have multiple slots and the different AI would do different things in different slots. Now to start with, I would like you to move to the third slide in the training eight."},{"start":"0:33","end":"1:18","startSec":33.0,"text":"That's exercise three multiple slots. And you should see that we have a set up that looks a little bit like this. Now if I was to simulate, we'd see that all the AI walk around and in the middle there is a bonfire with a guitar. So what I'm looking to do here is have the characters sit around the bonfire and one of them to play the guitar. Now if we look through what we have here, we have the BP bonfire itself that we're going to make into the smart object or character and the M underscore play guitar."},{"start":"1:19","end":"1:57","startSec":79.0,"text":"If we were to look at the montage for the play guitar. Now the interesting bit that we have about this is we are using a specific bone here called the interaction. And the way I'm going to animate that is I have put together this animation with the guitar on the interaction button. And that means when the character comes in and picks it up, it will use the the transform of the interaction boat in order to know the location for the boat."},{"start":"1:57","end":"2:33","startSec":117.0,"text":"And this means that we can just pick it up and put it down and it will sync with the animation. You'll also see that at the beginning here we have an a N toggle use object. And all this is is an animation notifier where I open that up. We do a couple of things here. We receive the notifier and I'm getting the owner of the notifier say finding the smart object."},{"start":"2:33","end":"3:04","startSec":153.0,"text":"And I'm saving a couple of variables on the smart object. A variable Boolean saying play guitar and a variable save of the skeleton mesh. That's all I need in order to get this up and running. It's relatively straightforward. You can go in and look at it. It's not the best example. But what I want to concentrate on in this example is putting together a more complicated definition."},{"start":"3:04","end":"3:38","startSec":184.0,"text":"So let's do that now. What I would like you to do is right hand click. And again, we're going to come up to miscellaneous and we are looking for data asset. Once we select data asset, I'm going to search for smart and you can see we have a smart object definition here. I will select that and I'm going to call this smart object definition underscore bonfire."},{"start":"3:38","end":"4:13","startSec":218.0,"text":"And then double click to open this up. Now to start off with we have no slots. So we're going to want to add some slots in, but it's a little hard to place the slots down when we don't know what the object looks like. Luckily, we have a preview settings up here. So I'm going to come up to the preview settings and under the object actor class, I am going to search for BP underscore bonfire."},{"start":"4:13","end":"4:43","startSec":253.0,"text":"I'm going to select the bonfire. And now we can see we have our guitar and our bonfire. And this will help us to add in the different sockets. Now the first socket I would like to add. I want this one to be the one where we have the guitar player in it. I'm going to drag this over to the right hand side."},{"start":"4:43","end":"5:13","startSec":283.0,"text":"And I already have played around with this and I reckon the offset needs to be about 190. And I also want to rotate it. 880 degrees. So it's facing back towards the center. Now that's good so far. Now next up. It doesn't matter so much where these slots are."},{"start":"5:13","end":"5:48","startSec":313.0,"text":"And that's because we we don't have to line it up as long as it's on the floor. It shouldn't make much difference. So what I'm going to do is I'm going to add in a few different slots. And see they always appear in the middle. I'm going to rotate them so that they face in. So I'm actually just going to put them all in place first."},{"start":"5:48","end":"6:18","startSec":348.0,"text":"I'm not going to make it too even. And I'm just going to grab all of these and rotate them so that they're facing the fire. OK, so that's given us six slots here for people to be gathered around the fire. Now they're all called none. I'm going to jump on the first one. I'm going to rename this to guitar. Because this is the only one that we're going to do something slightly different with."},{"start":"6:18","end":"6:49","startSec":378.0,"text":"Now we need to set up the behavior. So I'm going to come in here and I'm going to select the index. I'm going to come down to gameplay behavior smart object. And in the drop down, I'm just going to be looking for exercise three so that DBC underscore sitting down exercise three. Now drop down again."},{"start":"6:49","end":"7:19","startSec":409.0,"text":"We have a default of sitting on the floor. That's fine. So as long as those are up, that's for our default. So all of the slots are going to have that. But in the guitar one, we want to override that. So under the behavior definitions, I'm going to hit plus. And I'm going to select the game pay behavior smart object definition. Another drop down."},{"start":"7:19","end":"7:50","startSec":439.0,"text":"Again, I'm going to select game pay configuration sitting down. I want the option to play guitar. Okay, and with that done, we can now come in and open up our bonfire. We need to add in our smart object."},{"start":"7:50","end":"8:29","startSec":470.0,"text":"And we need to set that to bonfire. You look at the viewport. We can see now that the guitar one is pointing towards the guitar and everything looks okay. So if we come back into the level here, we select this. We can actually see the spots. And if I press simulate, you can now see that some of the characters sit around."},{"start":"8:29","end":"8:48","startSec":509.0,"text":"But the one that is in the slot with the guitar is going to start playing the guitar as soon as it's there. And that brings us to the end of our final exercise video. Hopefully you may get that all working. Thank you very much."}],"10_FutureLearning":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"Hello and welcome, this is the final video as part of our introduction to Smart Objects course and I just want to touch on a couple of odds and sorts of future learning that you might want to go into from here. Now we have looked at coding all of the game-paper-havia into a singular script. Now we don't have to do that, we can actually move over to a secondary state tree."},{"start":"0:36","end":"1:07","startSec":36.3,"text":"This we use quite a lot when it comes to Fortnite or Lego, but what this allows us to do is shift the functionality between different state trees dependent on the object. And finally a fantastic video, if you really want to get into this in more depth, is a talk that was given at Unreal Fest a few years back and that is exploring the new state trees for AI. That was for Unreal Fest 2024."},{"start":"1:07","end":"1:26","startSec":67.2,"text":"But you can follow this QR code, should take you directly to it. Well thank you for sticking with us through that quite long course. Again this is just an introduction, there is lots more that you can do with Smart Objects but hopefully this has given you something you can start out with. Thank you."}]},"201.04":{"01_Overview of Material Theory and Real-time PBR":[{"start":"0:00","end":"0:23","startSec":0.0,"text":"Hello and welcome to today's Unreal Engine training on materials and today we'll be talking about masking and material functions. So we'll give you an overview of some material theory and talk about real-time PBR which is physically based rendering and today the topics that we want to cover in this section are just what is real-time PBR and how you might use it along with some material concepts. So let's get stuck in."}],"02_What is Real-time PBR":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Let's start by talking about what is real-time PBR. So PBR is a unified light and shading system. It approximates light in real life behavior. So you can see these materials kind of reacting in the scene as you would expect that type of material. Maybe it either reflects a lot of light or absorbs light and doesn't have as much specularity. You can dial in these values based on the material, regardless of the type of texture that you're using."},{"start":"0:30","end":"1:02","startSec":30.8,"text":"So we try to create something that's more physically accurate. So it uses real physical measurements such as lumens and looks and inverse square law, energy conservation, etc. And it's just a little bit more intuitive and consistent to understand when you're creating your projects. It also produces just a more accurate and natural look, as you can see in these images here. When we talk about material concepts with PBR, we generally can divide the materials we build into metals and non-metals."},{"start":"1:02","end":"1:33","startSec":62.3,"text":"So non-metals and metals on the right hand side here, you can see that we can create the desired approach based on a type of material concept as seen in these images. So if we're thinking first about base color, which we call an albedo map. So non-metals, color info always have some kind of range. There's no pure whites or pure blacks in nature. So we want to keep in mind a roughness is a key in defining the look of a material"},{"start":"1:33","end":"2:05","startSec":93.4,"text":"as it's selling in the real world. So you can see the non-metals here, we have some RGB values and sRGB values, and we might be approaching if we want a non-metal concept, we might be approaching it more like this. Whereas a metal concept, again, we'll be using just different information to get our PBR material to react in a different way. We have levels of metallic that we can change based on zero to one. So it's a grayscale value ranging from zero to one."},{"start":"2:05","end":"2:39","startSec":125.9,"text":"And the most common usage is either one or zero. It is more binary in that respect. So when on, it results in 100% specular reflection, as you can see on the right hand side of the image here, zero would be on the left hand side, and you can see all the values in between. Again, it's most common to use either zero or one kind of binary approach. However, obviously, the results will depend on what effects you're actually going after. We also have roughness masks, which is again a grayscale value ranging between zero and"},{"start":"2:39","end":"3:11","startSec":159.3,"text":"one, but roughness materials will scatter the reflected light in more directions than a smooth material might. So if you want a more mirrored surface, that is on the zero end this time, a bit more reflective. And then a more matted surface is going to be the one value here. So again, you can dial it in from zero to one based on how rough you want that material to feel. And then we've got a few credits here. The room was created by Fabrice Bruehle and we've got some additional resources here on"},{"start":"3:11","end":"3:14","startSec":191.4,"text":"physically based index. If you want to dig into those."}],"03_Parent Materials and Instance Materials- Adding More Features":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Next, we'll talk about the difference between parent and instance materials and how to add a few more features to those functionalities as well. So we'll review parent materials and instance materials to begin with. We'll talk about creating some switch parameters for instance and so you can really dial in the result of what you want a specific instance to look like. And we'll talk about creating a master material, a UV control for instance So let's just review the parent materials and the instance in concept. So when to use it and what"},{"start":"0:33","end":"1:06","startSec":33.1,"text":"and why is it useful? So you'll see that we have parent material on the right hand side here. We've got color value. In this example, we've decided to create a metallic value and also a roughness value. And we've plugged those into the respective inputs. Now you'll see that these are all parameters. You'll see in the slight italicized text below, it says param, param, and param. And that essentially means it's a parameter that we can use to change the result outside of the parent"},{"start":"1:06","end":"1:36","startSec":66.3,"text":"material. So on the left hand side here, you'll see an instance version of this material. And on the top properties, you'll see that we've got the albedo ticks, we've got the normal ticks, and we've got the roughness ticks. And we can dial in these values based on the instanced version of that. So we've created one material here that has parameters that we can change. And on the instance, we can make subtle tweaks and shifts. Sometimes we want to make large shifts"},{"start":"1:36","end":"2:06","startSec":96.6,"text":"and tweaks. But essentially, you don't have to create a material from scratch. You can just change the values that you wanted to change based on the parameter of the master parent material. So we can think about adding a little bit more functionality to these materials. The previous example was a little bit more of a basic that you'd expect to see in any given Unreal project. Now let's think about how we might switch based on some of these parameters. So we can import a desired"},{"start":"2:06","end":"2:40","startSec":126.8,"text":"texture, whatever you'd like, and we'll prompt you at the end of this section to create your own. So if we just go through the notes to begin with, and then you can pause the video and try and recreate this yourself. So you import some kind of desired material, we'll right click and search for a switch parameter. So if you just right click in the material graph, type in switch parameter, you'll have a static switch parameter that will appear there. And then you just want to select that. And then we can create several constraints and plug them into the false node. So if you"},{"start":"2:40","end":"3:14","startSec":160.0,"text":"want to create a const, you can hold down one on your keyboard and left mouse click and that will create a const one. Alternatively, you can just find the constants in the right click menu. Scale parameters, in a similar way, scale parameters are constants nodes that have been converted to a parameter. So once we've created that const, so we maybe held down number one on our keyboard, we left clicked, you can actually right click on that new node that you created and convert it to a parameter. And therefore you'll then be able to give it a name. By default,"},{"start":"3:14","end":"3:49","startSec":194.3,"text":"it'll just be a numerical value. But if you want it to be a parameter, you can right click and convert that to a parameter. So we want to convert all the texture sample nodes to parameters, including any constants parameters, they will now become scalar parameters for you to assign names to that we'll be able to communicate with in an instance version of this material. If we want to think about creating a master material with UV control, let's maybe add a UV coordinate. So just right click UV coordinate. And this is a text coordinate in this example,"},{"start":"3:49","end":"4:24","startSec":229.2,"text":"we want to create two multiply expressions. So we've got one multiply here, one multiply there, you can actually hold down M for multiply on the keyboard. And to create a multiply there, we can create an append expression, we can create three scalar parameters, again, just holding down one on the keyboard for each one and convert them to a parameter, and then connect them to each texture UV desired. So just a note on this last section here, you'll see the comment box there as well. But the last multiply acts as a bridge and can be an ad instead. So if you'd like to"},{"start":"4:24","end":"4:58","startSec":264.0,"text":"create an ad instead of a multiply, you can do that. And it will simply shift the UVs whilst multiply shifts and increases the scale. So keep in mind and depends on the design effect of what you would like your material to look like. To create the instance version of the material, so we've got this new material in our content browser, you'll see it wherever you created it in the folder, you can actually right click on this master or parent material and create a material instance based on that parent material. When you do a new material will be created,"},{"start":"4:58","end":"5:34","startSec":298.8,"text":"but it'll be a material instance instead of an actual just master material. And we can load up this instance and you'll see some kind of box like this, it'll have different parameters based on what you had created in the previous example. But it'll allow you to tick certain parameters on and off of the properties that you want to edit based on the material that you're trying to create. So instances are used to prevent constant recompiling of shaders because we've got this parent or master material. That's what's doing all your shader compilation. It knows what to"},{"start":"5:34","end":"6:05","startSec":334.4,"text":"expect from the PBR system that you're trying to create. And therefore every instance is just based on that parent shader. So Unreal knows to calculate certain parameters and then it's just dialing in the specific result that you want. So we can make the instance from the master material, we can open the instance, click the nose to activate them, swap out any textures you would like and it gives you a lot more freedom and flexibility. And it's also just less performant, well it's more performant but less heavy on performance to take this approach. So maybe"},{"start":"6:06","end":"6:33","startSec":366.0,"text":"it's worth jumping in now into your editor. Maybe think about creating a new parent material with some switch parameters. You could create the UV parameter control as we just went over in the video. And maybe just test them out, test that workflow, see, get familiar with it. It's a concept that you'll use in all your Unreal projects. It's just a very streamlined way of working, it allows a lot of flexibility and it's just a useful pipeline to know and understand moving forward."}],"04_Creating Masked Materials with Nodes":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"So stepping up the complexity a tiny bit here, we'll talk about creating masked materials with some nodes. So we want to cover the process of how you might create a masked material. We'll talk about using minus nodes and clamps, and we'll also use the lerp node to linear interpolate between two different channels of the material that we want. We can talk about masking textures for materials using one texture, and we'll also talk about using the RBG RGB channels to almost get a more performant texture based on a specific channel"},{"start":"0:31","end":"1:04","startSec":31.9,"text":"rather than the overall texture. So let's jump into this. So we've got the process. There are two ways that can be achieved when we're talking about masked materials. So with an outside alpha embedded in a texture, or you can do it in a standalone texture that has an alpha data plugged into opacity. You can also do this through the color channels, which we were talking about with the RGB material setup. So when you create a texture sample, you'll have an alpha pin on the texture sample, which is the main output, and then"},{"start":"1:04","end":"1:39","startSec":64.3,"text":"it's the RGB, and then you've got an A. So anything imported with some kind of opacity, a 32 bit alpha channel, you can use that alpha to plug into one opacity of the material. You can even just pull in a specific channel, whether it's the green channel, the red channel, the blue channel, to have an alphaed material as well, depends on what you packed into that texture sheet to begin with. But suffice to say, there's a number of ways that we can achieve creating a masked material. And it's up to your kind of preference and also just workflow of how you're trying to pack textures together on the approach that you want. When"},{"start":"1:39","end":"2:10","startSec":99.3,"text":"we're looking at a material setup that we want for thinking about masked materials, we'll use the minus nodes and some clamps here as well. So we'll create or use a black and white texture, which we provided in the project, and you can create a texture sample. So a nice little shortcut here is if you do use the texture that was given in the project or anything that's already in your content browser, you can have that selected in your content browser. Don't double click it, you can just select it. You can come into the"},{"start":"2:10","end":"2:40","startSec":130.2,"text":"material and if you press T on your keyboard and left click, it will first of all create a texture sample, but it'll also automatically apply the texture that you had selected in your content browser. So it's just a nice quicker way of working. Again, you could always just press T or just right click, add a texture sample and then select the texture after the fact. It doesn't matter either way, but it's just a little bit more streamlined way of working. Next, we want to create a one minus if we need to flip the masking effect. So"},{"start":"2:40","end":"3:11","startSec":160.7,"text":"this is our one minus and it'll essentially just flip to the opposite. So if you've got Alfred on the outside and the solid colors on the inside, the one minus will then flip it to translucent outside and opaque on the inside. So it'll just basically flip the effect that you're going for, which you can see this one minus doing there. So instead of importing a brand new texture that does the same thing, but in the opposite way, we can actually just dial that in based on the material, which, you know, reduces the amount of texture samples"},{"start":"3:11","end":"3:42","startSec":191.4,"text":"you might need in your project, which is really useful for having that flexibility. So we've done this to make some kind of gold trim on the material. Next, we'll create a clamp to keep things in range if parameters are introduced for control. So if someone programs into your shader, they will see that they have a clamp to keep things in a nice certain range. So that's just more of a quality control type of clamp that we've put in there to make sure we're getting the desired effect. We can also use Lerp nodes, which is a linear interpolate."},{"start":"3:42","end":"4:14","startSec":222.9,"text":"So you can just right click, add Lerp. You'll likely see that it's called linear interpolate as well. And so we'll create a Lerp node and run the one minus into the alpha input of the Lerp. And then we want to duplicate that process for the material texture. So when we talk about duplicating the process, you can actually select these nodes, Ctrl C to copy, Ctrl V to paste, and just work a little bit more efficiently there. So you just want to notice that there's not a metal texture for the wood. So we can plug in a constant"},{"start":"4:14","end":"4:44","startSec":254.3,"text":"into the Lerp. So this is the setup that we're going for here. You can see that we've got that const going into the A, we've got the texture sample going into the B, and where the alpha is actually based on this texture sample here. And then when we talk about masking textures for materials using one texture, you can actually see that we've got, if you go into your texture and you click through the RGB channels, you'll see there's different information packed into the various channels. And we can actually just pull off, say the"},{"start":"4:44","end":"5:16","startSec":284.4,"text":"green pin or the red pin in this instance, to get specific information from that channel. So if in your external app, you've either painted or included some information onto a specific channel, instead of just using the main RGB channel, if you're layering stuff, for example, in Photoshop, you can just pull off that information in the RGB channel, or even the alpha channel, and use that. And so we call that texture packing. You can pack"},{"start":"5:16","end":"5:47","startSec":316.7,"text":"multiple textures into one texture when importing it into Unreal. And it's just a slightly more efficient way to work if you especially if you're trying to keep the texture sample instructions down to a minimum. So go ahead and follow through those steps, you can create a mass material, play around with the type of masking approach that you'd like. Again, we kind of noted two or three different ways that you could create a mass material based on the samples. And again, it's going to be project specific, depending on what you're trying"},{"start":"5:47","end":"6:05","startSec":347.6,"text":"to achieve. But hopefully that gives a good overview to the mass materials. And also just to add at the end of this that we want to credit to Frick for the scene shown in the RGB channel. And then we've also got a documentation on how to mask materials if you'd like to dig into that topic further."}],"05_Material Functions":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"And then lastly, we just wanted to touch upon some material functionality, slightly more complex again, but as you'll see, it's very straightforward if we're layering up these approaches and learning about each step as we go. So we'll cover what material functions are, we'll talk about using function inputs, we'll talk about building an animated material function, and then we'll also use that material function in some form of master material. So what is a material function? So material function allows you to embed materials within"},{"start":"0:32","end":"1:03","startSec":32.9,"text":"materials, avoiding unnecessary clutter. It also just allows for reuse in various other projects, packages, multiple materials. It's kind of reusing that functionality so you don't have to keep creating or coding the same thing over and over again. So if you get a really nice simple grass wind shader, for example, in this example, or you've created a really nice water shader that you really want to reuse throughout your projects. Material"},{"start":"1:03","end":"1:34","startSec":63.5,"text":"functions are a really nice clean way of saying, here's some complex piece of information. I mean, it can be lightweight, but generally it'd be something a bit more complex, where you've created this functionality and you can just use this as a function to plug into an existing material to get the desired results. So you don't have to keep reworking existing work. So we can use function inputs. So function inputs allow us to create some kind of customized data, and we can edit the sorting priority, which allows control on where the new node"},{"start":"1:34","end":"2:08","startSec":94.5,"text":"is and placed within the material function and the material destination. So how to create this is that we want to first create a material function. And you can just do this by right clicking in your content browser. Generally where you'd store other materials, maybe you'd create a material function folder specifically, so you know where all your material functions are. Again, it's just dependent on what your preferred workflow is. Essentially, you just want to right click and go to materials and textures and create the material function from there. Then you can open it up and create the system. So this is an in class exercise."},{"start":"2:08","end":"2:38","startSec":128.4,"text":"So we can go through this in the in class portion. However, even though there's a lot of nodes going on, it's definitely not as hard as it seems. We provided samples. And based on the previous example that we covered in the previous section, you can see that it's a lot of copy and paste that information. So we've set up one section, and then we just duplicated it and we're trying to dial in the desired results. So always just break down the material to its component parts, kind of work backwards. And you'll see that"},{"start":"2:39","end":"3:12","startSec":159.0,"text":"a lot of the information is then duplicated and replicated in different ways to achieve this result. And so once we've created that material function, we can actually just use that in a different master material now. So we can select the main material node and change the material domain to light function. So this is the main material node here. So we just want to click this pillar here of inputs. And you just want to on the on the left hand side here, you'll see that we've got a light function material set up here. And that just"},{"start":"3:12","end":"3:46","startSec":192.4,"text":"makes sure it cast shadows. You want to make sure that that's enabled. And then we can call up the material function in the graph. And we can technically just drag it in. So if you wanted to select it in your content browser and drag it in, or we want to specify that we want to assign this MF four way motion or two, if that's what you called it in your project. So by default, you'll just create a material function and then plug in the specific function that you want into that node. Or you can drag and drop it in. So you just want to"},{"start":"3:46","end":"4:20","startSec":226.6,"text":"for this example, you want to create a text quad and a scalar pram to multiply in the material function. We've used all those before. And then we want to connect the caustic softer texture to the texture node and then into the emissive. You'll see that we've only got the emissive channel available to us now, because we went into that light function material type. And so it just accepts emissive colors. So once we've done that, we can just connect our light under the light function in the editor. And that should be working as some"},{"start":"4:20","end":"4:53","startSec":260.1,"text":"kind of caustic style material in your editor. So just to cover that last section again, when you have a light in your scene, all lights, if they're some kind of dynamic light, will have a light function option. You can just plug this material into that light function in the details panel. And that would add a caustic effect to the specific light. So if you follow along in class and create this material function, master material that will give you a really nice introduction to mass materials, again, slightly more complex concept. It's just getting"},{"start":"4:53","end":"5:25","startSec":294.0,"text":"familiar with each module as you go. But you'll see that it's a lot of the replicated information. You just build on upon your knowledge base. Try not to let it feel too complex and just break it down to its component parts and just build from there. And then to close out here, we've just got a few additional resources if you want to read up on any documentation. So whether it's the introduction to materials, animating some UV coordinates, even just a high level introduction to materials and material nodes, all that documentation is available to you."}],"06_Thank You":[{"start":"0:00","end":"0:26","startSec":0.0,"text":"So thank you for your time today. Hopefully that was a really good introduction to creating materials and thinking about some of the more advanced properties of materials, whether we're talking about material functions or even just parameters and parent materials and how to just instance those materials to create not only a cleaner workflow, but also just something that's more performing for your projects. So thank you again for your time and we'll see you in the next course."}]},"202.03":{"02_Theory":[{"start":"0:00","end":"0:38","startSec":0.0,"text":"Hello and welcome to this video on tool theory, where we will be laying some groundwork on how to think about creating tools. When we talk about tools in Unreal Engine, we are standardly talking about tools that will be used either in the editor or as an extension to the editor, like something connecting to an external package or application like Blender or Maya. What we're not really talking about is tools that would be used at runtime, that would be part of the game themselves."},{"start":"0:38","end":"1:11","startSec":38.0,"text":"This means we're going to be looking at some functions and some parts of the engine which will just not be available at runtime. There are a number of reasons why we might make a tool, but they usually fall into one of these categories. The first one being to speed up your workflow. If we ever found that we were doing a manual task over and over again, and it was quite time consuming, this is a good example of something where a simple tool might save you a lot of time."},{"start":"1:11","end":"1:43","startSec":71.0,"text":"So tools are often used to speed up workflow and remove boring and repetitive tasks. The second reason why in games tools are often made is to enforce a specific pipeline. With large projects, it's very important that things like naming conventions and placement and creation of assets are done consistently in the same way. Tools are great for forcing this on people."},{"start":"1:43","end":"2:16","startSec":103.0,"text":"Creating your own custom importers that will check and reject anything that doesn't fit the specific needs is another great use for tools. Thirdly, you might use a tool to make sure the work is done more accurately. Sometimes a task will require placement of assets or configurations which are very difficult for a human to do manually, but a computer can do easily."},{"start":"2:16","end":"2:47","startSec":136.0,"text":"In this case, sometimes tools are used. Another thing that tools are good at are automatically monitoring things or identifying issues. It's very common to write a tool which might create a log or will look over a scene for problems or things that need to be corrected. Something that can be done very fast by a computer, but would be incredibly difficult for a human."},{"start":"2:47","end":"3:24","startSec":167.0,"text":"When designing a tool, there are two main things that you need to know. You want to know what would trigger this tool to be used and the function that it would carry out. Selecting an appropriate trigger is often obvious dependent on the function, but it's good to have them in a convenient and obvious place so that they can be easily found and used. Some examples of these are Construction script. Construction script will trigger at the point an actor is placed into the world or it is shifted around or forced to update."},{"start":"3:24","end":"4:01","startSec":204.0,"text":"This is great for randomization or where the actor would need to query the world in order to set itself up appropriately. Next one is exposed functions. This is where we take a function from inside a actor and mark it as exposed. Therefore, we would be able to trigger it using a button within the details panel. This is great if you have an optional event that you might want to trigger on actor."},{"start":"4:01","end":"4:31","startSec":241.0,"text":"Next we have custom menus and buttons. Here we are talking about editor utility widgets, where by using Unreal Engine's UMG interface, we could create our own menu systems for complicated tools, which can be docked into the editor. Tick. So tick is an event which usually runs on every frame of the of the game."},{"start":"4:31","end":"5:12","startSec":271.0,"text":"Now, now since we are not creating tools during gameplay, tick is a little bit different in this case. Now tick can be accessed via tools such as an editor utility widget. Tick is often considered quite dangerous because it runs on every frame of the game. If you put anything complicated, which would require quite a lot of computation, it could end up hanging the engine. And unlike in a game where you can just escape out the game and fix it, this would take over the entire editor and it can be very hard to to get back from."},{"start":"5:12","end":"5:44","startSec":312.0,"text":"This is best used for monitoring things and triggering other programs off the back of that. Custom buttons or menus added to the editor. There are numerous ways to add extra buttons or menus to the editor. You can either do this by using Python scripts or the editor utility actors and the editor utility assets will automatically create a menu entry."},{"start":"5:44","end":"6:15","startSec":344.0,"text":"The command line can also be used to trigger a tool. These tools can either be in the form of C vowels or triggering a Python script to run. And finally, it's also possible to trigger a tool on the startup of the engine. So in this course, we are going to be looking at a number of different trigger points to give you an idea of how different tools can be created."},{"start":"6:15","end":"6:46","startSec":375.0,"text":"The most common assets used for making tools are the actors itself, where we can just place or create functionality within them in order to fulfill some function. Editor utility widgets. These are tailor made interfaces that operate within the editor will allow us to make our own menu systems. Actor action utilities. These are functions that will be activated by right clicking on an actor in the level."},{"start":"6:46","end":"7:12","startSec":406.0,"text":"And asset action utilities. These are functions activated by right clicking on the assets in the content browser. In these exercises, we will use actors, editor utility widgets and an asset action utility. So that covers all the theory we really need to go over at this point. In the next video, we're going to be starting on our first exercise."},{"start":"7:25","end":"7:28","startSec":445.0,"text":"You."}],"03_ConstructionScript":[{"start":"0:00","end":"0:37","startSec":0.0,"text":"Hello and welcome to this video on the scatter tool exercise, where we will be using the construction script. Now there is no project which comes with this course. What I will be using is the third person template from the games category. I'm going to make sure that I have the starter content ticked on, because we're going to be using some of the meshes which come with this. I'll just push create. And once that's loaded up, you should get a project which looks something like this."},{"start":"0:37","end":"1:13","startSec":37.1,"text":"The only thing that I'm going to do slightly differently, so I'm going to come down, I'm going to select the content drawer, and I will dock that in the viewport. We're going to be working with assets quite a lot, so I'd like them to be visible. For this first scattering tool, what we will do is we'll develop a tool that enables a random scattering of meshes throughout the scene. This tool will provide options for adjusting the scatter distance and selecting the meshes that we want to use, also determining the number of meshes that you want it to generate."},{"start":"1:13","end":"1:52","startSec":73.4,"text":"And all of this we're going to do on construction script. So to start with, I'm going to right-hand click and I'm going to select a blueprint class. For this, I am going to select the actor class. I'm going to call this BP underscore scatter tool. I'm going to double click to open this up."},{"start":"1:52","end":"2:25","startSec":112.6,"text":"Now the first thing that I'm going to want to do is select the tab for construction script up here in the center. Now it's going to bring us to this page where we just have one purple node popping out here. And to start with, I'm going to drag off and search for print string. Then just compile and save. This is just so that we can see when the construction script fires."},{"start":"2:25","end":"2:57","startSec":145.0,"text":"I'm going to jump back into the map and I'll drag this into the level. And straight away you can see that we have a massive great big list of hello down the left-hand side here. So that's just to demonstrate when it triggers. The construction script will trigger whenever the actor is placed in the level or whenever anything is updated, such as his transform here as I drag it around. Okay, we can jump back into the tool."},{"start":"2:57","end":"3:30","startSec":177.1,"text":"I'm going to delete this print string. We don't need that anymore. And I'm going to generate some variables, because how we're going to control what the script does is by exposing some variables. So the first one we want, if we push plus here, first one is going to be spawnable meshes."},{"start":"3:30","end":"4:03","startSec":210.0,"text":"And this is going to be of the type static mesh. Just search for static. And you'll see we here we have an option for static mesh. I'm just going to select the object reference. You see it turns blue because this is a reference. Now there's a couple more things I need to do with this. So the first thing is, we're going to want to allow numerous static meshes to be added"},{"start":"4:03","end":"4:34","startSec":243.8,"text":"to this tool. So rather than it being just a single static mesh that's referenced, in the drop down, I'm going to select an array. This will allow us to add multiple meshes. And the last thing I'm going to do is you can see that we have an option here for instance editable. Now if I tick this to be true, you'll see down in the bottom left hand side here that an eye is exposed."},{"start":"4:34","end":"5:07","startSec":274.2,"text":"This is just a quick indication so that we can see which of the variables are made instance editable. We can also see if I hit compile and jump back into the level in the details panel, we can now see that we have the spawnable meshes as a array that we can add elements into on within the actors details. So I could come in here and I'm going to add in the bush."},{"start":"5:07","end":"5:39","startSec":307.6,"text":"So the SM underscore bush. So we already have one asset up ready. Now we're going to need a couple more. Next up, if I'm going to add an extra variable, and this is going to be the radius. This is the radius in which the meshes will be scattered. So in a drop down here, I'm going to select a float."},{"start":"5:39","end":"6:10","startSec":339.9,"text":"Now allow us to enter a value for how large the ray scatter radius will be. Now this we don't want to be an array. So I'm going to convert that back to a single and I'm going to click on the eye this time. So that's going to make this instance editable as well. Now we need another variable. And this is going to be the spawn amount. This is how many meshes will be spawned."},{"start":"6:10","end":"6:42","startSec":370.8,"text":"Now this is not going to need a decimal point. So I'm just going to do a drop down and I'm going to change this into an integer. And again, I'm going to click on the eye to make that instance editable. If I hit compile and jump back into the level, you can now see that all of these variables are now accessible within the menu. If I wanted to set a default amount, if I can jump into radius, you can see here we have a default value in the details panel."},{"start":"6:42","end":"7:13","startSec":402.2,"text":"I could start off by making that 300. And if you have the spawn amount, I'm going to start off by making that five. Compile. And you'll now see that the values are updated within the details panel. However, they can be overwritten. At any point, I could update it to 10 or increase the radius. So this is how we're going to control how the tool spawns the meshes."},{"start":"7:13","end":"7:50","startSec":433.1,"text":"Let's jump back into the tool here. And we're going to do the work on the construction script. So I'm going to grab the spawn amount to start with. I'm going to drop that down and select get. I'm going to drag off the construction script and look for a for loop. See the bottom here, we have a for loop. Now I'm going to connect the spawn amount into the last index and the first index I'm going to change to one."},{"start":"7:50","end":"8:23","startSec":470.7,"text":"This function will repeat dependent on the value of the spawn amount. If this would be set to zero, it wouldn't repeat at all. Let's say this would be set to five. It's going to go around five times. The reason we've changed the index to one is because a for loop standardly starts at zero, meaning that if we set the amount to five, we would get six out. It's just to reduce it down by one."},{"start":"8:23","end":"8:59","startSec":503.5,"text":"Next up, we are going to add a static mesh component. So this is just going to create a static mesh component as part of this actor. And we want to do this for each iteration here. So we've connected it to the loop body. Now I want to set the transform. I'm going to need to do some calculations on this. So the first thing I'm going to do is come up to this orange pin, which is a transform."},{"start":"8:59","end":"9:33","startSec":539.2,"text":"It's a struct of location, rotation and scale. I'm going to right hand click and hit the split struct pin. And that's going to give me the individual pin for both the location, rotation and scale. I'm going to split this down even further. What I'm going to do is I'm going to right hand click on the location and split the struct pin again, giving me an individual pin for each X, Y and Z."},{"start":"9:33","end":"10:06","startSec":573.2,"text":"And we want to randomly place these. To do this, we're going to use the random unit vector. And what this will do is it will generate me a random vector between minus one and one on each X, Y and Z. So it's going to be a very small vector. And afterwards, what I'm going to do is I'm just going to multiply this."},{"start":"10:06","end":"10:38","startSec":606.0,"text":"I type in star, grab multiply. I'm going to change this to a float. So I right hand click and select float single precision. I can drag in our radius and plug that in. So what that's done is that has generated a random vector and then it's multiplied it by the radius so that we've made it bigger. However, at the moment, this is going to generate it in any direction."},{"start":"10:38","end":"11:10","startSec":638.2,"text":"So I'm going to split the output here. So I come in again and go split struct pin. I'm going to plug the X and the Y in, but I'm going to ignore the Z so that we know that this is going to be on a flat plane. The final thing I'd like to do is I would like to randomize the rotation a bit, but not on all of the axes. So what I'm going to do is I'm going to right hand click on our rotation and split this pin."},{"start":"11:10","end":"11:52","startSec":670.4,"text":"So we have another three floats. And I am going to search for the function random. Rotator. I'm going to split this struct pin here. I'm just going to grab the Z and add that in. So you can see what this is doing is it's going in and it's giving us a random location only on the X and Y, and it's also randomizing the Z rotation."},{"start":"11:52","end":"12:28","startSec":712.4,"text":"Finally, we've added a static mesh component. However, we haven't actually set the mesh. So let's do that now. So if we drag off and we type in set static mesh, it's important that you drag off of the blue pin to get this. Come up here. Now, if we drag in the spawnable meshes and get the spawnable meshes."},{"start":"12:28","end":"12:59","startSec":749.0,"text":"Now, since this is an array, we may have multiple entries in this spawnable meshes. So therefore, we want to randomize the one that we get. So I'm going to drag off and I'm going to type get a copy. I'm going to plug that in. What this is allowing us to do is to use an index, a number of the array to get one of the copies of the meshes from this spawnable mesh."},{"start":"12:59","end":"13:33","startSec":779.0,"text":"Now, we want to randomize this value, but in order to randomize this value, we first need to get the length of this array. So I'm going to drag off and type in length. Now, I can grab a random integer value in range. Now, we want to."},{"start":"13:33","end":"14:03","startSec":813.2,"text":"Now, we want to actually use this length as the max. So I'm going to hold down the control key and drag that so it plugs into them. And I am going to make minimum one. In order to get this to match up with the array, I am going to need to subtract one."},{"start":"14:03","end":"14:39","startSec":843.9,"text":"After I've done this, I'll drag that in and press compile. So if we look at what we've done here, first thing is, is we are going to loop around for the amount dependent on the spawn amount variable. And then once we've done that, we're going to add a static mesh component and we're randomizing the location within the radius. And we are going to randomize the rotator so that it looks a little bit more natural."},{"start":"14:39","end":"15:10","startSec":879.2,"text":"Finally, we are setting the static mesh by grabbing the array and we're getting a value of the array of a random value based on how long the array is. And we're going to set that mesh. Let compile and save and jump back in. We can already see that this is working. So we have because we only have one mesh and see that we have only bushes that are being created in here."},{"start":"15:10","end":"15:51","startSec":910.7,"text":"However, if I was to hold down alt and drag off a second version and add something extra to the spawnable meshes, in this case, I'm going to select the chair. We got the SM underscore chair. And all that for the time being, we can now see that this is randomizing the chairs as well. And there are a number of other settings, like we could increase the spawn amount to considerably larger and we could reduce the radius to compress it down."},{"start":"15:51","end":"16:23","startSec":951.6,"text":"So you can see here, this is straight away on construction script. We're just randomizing out these meshes. So that is our first tool. Hopefully, you've managed to follow along and create that. In the next video, we're going to be advancing the tool a little bit more so that it queries the environment, allowing us to stick the objects that we're scattering to the ground."},{"start":"16:23","end":"16:35","startSec":983.8,"text":"As you can see here, if I drag this over, it's not paying any attention to where the ground is at all. OK, so thanks for sticking with us. I'll see you in the next video."}],"04_Linetrace":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Hello and welcome to the second video on Construction Script. In this video we'll be looking at building on the scattered tool we've already made in order to use a line trace so that we can query the environment and we can then add the static mesh component in line with the ground. So here I am back in the engine. I'm going to open up my scattered tool again."},{"start":"0:31","end":"1:04","startSec":31.0,"text":"I'm back here on the Construction Script because we're still working on the Construction Script at this point. Now I'm going to want to keep the for loop. That is absolutely fine so I will move that over to the left hand side. However, before I add the static mesh component, I'm going to want to do something called a line trace. So I'm going to drag out and I'm going to search for line trace."},{"start":"1:04","end":"1:35","startSec":64.0,"text":"And you can see here we have line trace by channel. So I'll just add this in between the two sections. And what a line trace is going to do is it's going to draw a line between the start vector and the end vector down here. And then it's going to return any data on any collisions that it hits on the visibility channel."},{"start":"1:35","end":"2:15","startSec":95.0,"text":"And we can get the data out of this out hit here. Now all we're going to need to do is calculate the start and the end location. I'm going to do that by coming over here and grabbing my random unit vector multiplied by radius. And I'm going to press Ctrl and X to cut that out. And then I'll come back over this side and press Ctrl and V."},{"start":"2:15","end":"2:45","startSec":135.0,"text":"Now this is great for giving us the X and the Y, but I'm going to manually want to make the Z. So I'm going to do that by dragging off the X and I'm going to type make vector. So that's going to do the opposite of splitting a vector. It's going to put together a vector. This time I can just leave the Z out."},{"start":"2:45","end":"3:16","startSec":165.0,"text":"So we're forcing Z to be zero. So up to this point we've been working in relative space. So that means we've only had to calculate the transform from the root of our actor. However, when we do a line trace, this will be done in world space. So I'm going to need to calculate the world locations where we start from and where we end at."},{"start":"3:16","end":"3:48","startSec":196.0,"text":"In order to calculate the world transform from the relative transform, all I need to do is take the relative and then add on the actor's location to that. So I'm going to get the actor location. I'll type in actor location and here's get actor location. And then I'm going to add these two together, drag off, push add. And connect them up."},{"start":"3:48","end":"4:22","startSec":228.0,"text":"So this is now going to give me the world location of this. Now, because I'm drawing a line, we're going to want to have a start and end position of this. However, I'm starting with a singular vector. So the start position, I would ideally like to be above the actor that we're working on. And the end position, I would like to be below. So when you place the actor, it's going to look above it and draw a line directly down below the ground."},{"start":"4:22","end":"4:56","startSec":262.0,"text":"So I'm going to do that by dragging off this and pushing plus and selecting add. And then I'm going to add 400 on the Z axis. And that will give me my start location. Now I'm going to do the opposite here. I'm going to subtract. So I'm going to subtract 400 on the Z axis. And that will give us our end."},{"start":"4:56","end":"5:33","startSec":296.0,"text":"Now I'm going to disconnect by holding down alt and left clicking everything after this line trace. And for the draw debug, I'm going to select for duration. This is just so I can demonstrate how it will work in the engine. So if I hit compile and then jump back into the engine, you can now see we just have a lot of red lines. So if I was to grab this cube, move it here and then move our actor."},{"start":"5:33","end":"6:03","startSec":333.0,"text":"We can see a lot of red lines except for under the cube where it's green. So if I would shift this, every one of the line traces, you're going from 400 above and it's attempting to go 400 below. If I'd shift the camera, you can see it here. So for every line, it is going to return us the data of where the red squares are here. And that's great."},{"start":"6:03","end":"6:36","startSec":363.0,"text":"So if I was to go back to my scatter tool, I'm going to turn off the draw debug so that none. And I'm going to come over to our add static mesh component. Now I am only going to want to add a static mesh component if the line traces actually hit something. So the way I'm going to do that is I'm going to hold down the B key and left click."},{"start":"6:36","end":"7:09","startSec":396.0,"text":"That's going to create me a branch. And I'm going to connect the return value to the condition. So that means this code will only continue down the true path if we've actually hit something. OK, so now we have to add in the static mesh location. To do that, I'm going to right click on the transform and select recombined struct pins."},{"start":"7:09","end":"7:43","startSec":429.0,"text":"And that's going to give me a yellow input. And now if you look at the line trace by channel, you can see that we have one blue out hit pin. Now this is a struct. So if I right click on that and select split struct pin, we're going to see that we get a lot more options. The one that we want in this instance is the out hit location."},{"start":"7:43","end":"8:15","startSec":463.0,"text":"Now I can't connect that directly in. That's because, as we mentioned before, line trace is in world space and the static mesh component is going to be relative to the root of the actor. So in order to fix this, what I'm going to have to do is drag off the out hit location. And then I'm going to search for subtract. And plug that into the relative transform location."},{"start":"8:15","end":"8:50","startSec":495.0,"text":"And then I'm going to get the actor location. So what I'm effectively doing is minusing the actor's location from the out hit location to give us the relative transform. And now if we jump back into the world, you can see that this is all conforming to the ground below it. So if I increase the radius to about 600 and the spawn amount, let's say 400."},{"start":"8:50","end":"9:27","startSec":530.0,"text":"Now you can see how that has just distributed and placed meshes on the ground around it. OK, so thank you for watching. In the next video, we're going to add some more functionality to the scatter tool. We're going to make it so that with a button push, we can bake out all of these static mesh components to actors in their own rights."}],"05_Bakeout":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Hello, in this video we are going to be finishing off the scatter tool. And to do this we're going to demonstrate exposing a function. This function is going to allow us to click a button and it will bake out any of the meshes that we have to exist as separate actors within the world. So again we're back here to the scatter tool. And for this function I'm actually going to be jumping into the event graph."},{"start":"0:32","end":"1:06","startSec":32.0,"text":"So as we go here you can see the event graph. We standardly have the events that were triggered during gameplay. However I am going to create an extra event here. Right-hand click and search for custom. And you can see here we have the option for add custom event. I'm going to select that. And I'm going to name this event Bake Out Meshes."},{"start":"1:06","end":"1:36","startSec":66.0,"text":"With the event selected I am going to come up to its details and I'm going to tick the box for call in editor. And now I'm going to come in and I'm going to add a print string that just says hello. Compile and save and jump back to the world. Now if I select my actor you can see here down in the details panel I have a option to bake our meshes."},{"start":"1:36","end":"2:15","startSec":96.0,"text":"When I push that button you can see the hello appear in the top left hand corner. So we know that that's working. So this is what we're referring to when we expose an event or function. So call in editor. Okay so let's delete that. Now we're going to need to do a couple of things here. So I'm going to jump back to the construction script. I'm going to need a list of the meshes that we have created so that we can quickly go through them in order to save them out."},{"start":"2:15","end":"2:49","startSec":135.0,"text":"I'm going to do that by adding a new variable. And that variable I'm going to call MeshesToBake. And this is going to be of a static mesh component."},{"start":"2:49","end":"3:19","startSec":169.0,"text":"It's going to be an object reference. So I search there for static mesh component. I'm selecting an object reference. Now because we're going to have multiple of these I'm going to need to change it to an array. So up here, drop down, and we're not going to need this to be instance editable because it's a working variable. We're not going to set it at any point manually."},{"start":"3:19","end":"3:52","startSec":199.0,"text":"Now if I drag in the meshes to bake and get, drag off and type in add. That's going to allow me to add to this array. And what I want to add is the static mesh component. So I'll drag off the back of the static mesh component and connect that up. So you can see what we're doing here. We're just saving this static mesh component to the meshes to bake."},{"start":"3:52","end":"4:23","startSec":232.0,"text":"So we'll have a reference list. I'm going to compile and go back to the event graph. I'm going to grab our meshes to bake and get another reference. I'm going to do a for each. This is going to allow me access to a for each loop. And I'm going to connect that up to the event."},{"start":"4:23","end":"5:04","startSec":263.0,"text":"So what that's going to do is for every entry into the meshes to bake array. It will loop, it will action whatever is connected to this execution pin on the loop body. And this is going to be a reference to the specific mesh. Next, what I'm going to want to do is drag off and I want to spawn Pacta from class."},{"start":"5:04","end":"5:36","startSec":304.0,"text":"It's going to allow us to spawn an actor, drop down search for static mesh, starting mesh actor. And so this is just going to create a static mesh actor in the world. And we've got a couple of options here, but the main one we care about is the transform. Because we want this, when we bake this out, we want this to appear in the place where the mesh was generated."},{"start":"5:36","end":"6:06","startSec":336.0,"text":"So in order to do that, I'm going to drag off of the array. I'm going to type in get world transform. And so this is going to find the transform of where the component is in the world. So it's not, we're not going to get the relative transform, we're going to get the world transform. And we'll plug that directly in."},{"start":"6:06","end":"6:42","startSec":366.0,"text":"Now there's only one last thing we need to do. As with any static mesh actor, we need to set the mesh. So I'm going to drag off and type set static mesh. It will automatically detect the static mesh component. And I can connect that up. And the mesh that we're looking for is here. So if I drag off of the element again, go get static mesh, you can see it here at the bottom."},{"start":"6:42","end":"7:15","startSec":402.0,"text":"Allow me to get the static mesh. And I can plug that in. So again, what we've done here is we started off with a for each loop for each of the meshes to bake. We've then spawned the actor and we spawned it by class because you can't, the title can be misleading here. When you first grab it is going to be spawned by class. Then we've got the world transform, plugged it into the world transform."},{"start":"7:15","end":"7:51","startSec":435.0,"text":"And after that, we have set the static mesh. If I hit compile and save. I jump back into the world. We can now see, I'm going to reduce the numbers down. I'll use this small one for the time being. If I grab this, if I push the bake our meshes button. Then we can see that we have singular actors for each of the meshes."},{"start":"7:51","end":"8:26","startSec":471.0,"text":"That would allow us to use this as a bit of a stamp rather than having it so that it automatically updates every time that it's moved. You can just get something that you like. And then after you've set it up, you can just bake it out. Great. So that brings us to the end of the scattering tool. We have it all up and running. Hopefully you've been able to follow that. OK. In the next video, we're going to be looking at the editor utility widgets."}],"06_Widgets":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Hello and welcome to this video on Editor Utility Widgets. For this exercise we'll be making a tool that will quickly spawn actors into the world. For this tool I'm going to create a new asset. So if I right-hand click and I come up to Editor Utilities you'll see that there is an option for an Editor Utility Widget. I will select this and it's going to ask us to pick our root widget for the new Editor Utility Widget."},{"start":"0:34","end":"1:07","startSec":34.0,"text":"We have a choice of a stack box or a grid panel straight away. But I'd actually like to use a canvas panel. So I'm going to come down to All Classes and you'll see here we have a canvas panel a little way down. So we're going to select the canvas panel and push select. Now that we've created it I'm going to rename this E-U-W for Editor Utility Widget underscore quick spawn."},{"start":"1:11","end":"1:43","startSec":71.0,"text":"Now if I double click on this to open it up we'll get a window that looks like this. Now if you have used the UNG which is Unreal Motion Graphics then this will look pretty familiar to you at this point. What we have in the left-hand corner here which we have a library and a palette kind of do the same things. They just give you access to any of the components that you can add."},{"start":"1:44","end":"2:15","startSec":104.0,"text":"Down here we will have the hierarchy. We're not going to do anything particularly complicated in this case. We're just going to be adding buttons to the canvas panel. Not going to have to go into too much detail here. And in the center we have the viewport which will show what our menu system is going to ultimately look like. Now on the right-hand side we have the details panel like usual. This is contextual depending on what you have selected."},{"start":"2:15","end":"2:50","startSec":135.0,"text":"Like in the rest of Unreal Engine. The animations panel at the bottom we are not going to use. I'll just get rid of that for the time being. One of the things you'll notice is in the top right-hand corner we have a blue designer selected. These are actually tabs. Next to this there is a graph option. If we go into graph this is going to look more like the blueprinting graphs that we've had before. So this is the logic and the designer is what our widget is going to look like."},{"start":"2:52","end":"3:23","startSec":172.0,"text":"So as mentioned I am going to add a button in. So if you look down here at the top here we have an option for an editor utility button. I'm just going to drag that in to our canvas panel. Drop it down. You now see that we've got this in our top right-hand corner. I'm quite happy with this being anchored to the top right-hand corner. This isn't a class on the UMG so we're not really going to go over how to make this look pretty at this point."},{"start":"3:23","end":"3:53","startSec":203.0,"text":"So what I'm going to do is I'm also going to grab the text here and I'm going to place that on top of my button. I'm going to, and I want to change some of the details. So the text here I'm going to change that to have the words Spawn Bush. And I'm also going to reduce down the size of the font to 12."},{"start":"3:53","end":"4:24","startSec":233.0,"text":"You can see I need to do a drop down of the font to get that down. Then what I'm going to do is I'm going to expand out the box a little bit. So we now have a button which says Spawn Bush. Now we want something to happen when we push this button. So in order to do that I need to select the button. If I come to the details panel and go all the way to the bottom,"},{"start":"4:24","end":"4:56","startSec":264.0,"text":"you can see here we have a number of events. So we can connect logic to any of these events we have on our canvas. On clicked, on pressed, on released, on hovered, on unhovered. We're just going to keep this simple and use on clicked. So if you push the plus button, you're going to see we get an event which is tied to that button click. Now let's drag off of this and type print string."},{"start":"4:56","end":"5:31","startSec":296.0,"text":"Again we have our hello. I'm going to compile and save and jump back to here. Now to show an editor utility widget, what I'll need to do is right-hand click and you can see there is an option here for run editor utility widget. And as soon as I do, a new menu will appear with the Spawn Bush button. If I push this, you can see that we get the hello coming up in the top left-hand corner. I'm going to drag this and I'm going to dock it up here."},{"start":"5:33","end":"6:05","startSec":333.0,"text":"So that I can see this button when I'm working on it. Right, so let's add some more code to this. Delete the print string. So the goal of this tool is to quickly spawn a bush in front of the camera. Now we're going to use a line trace to do that. The first thing we're going to need to do is get access to the camera."},{"start":"6:05","end":"6:38","startSec":365.0,"text":"And that's not necessarily easy. If you right-hand click and you type in Unreal, that will give you access to the get Unreal editor subsystem. And this is a very useful subsystem. Primarily because you can do two things with it. You can either get the level viewport camera info or you can set the level viewport camera."},{"start":"6:38","end":"7:08","startSec":398.0,"text":"So this is going to allow you control over the viewport camera. So, for example, if I was to connect the set up to this button. And whenever I push the spawn bush, it's going to move the camera to zero zero zero. So that's what would happen if we had set the camera. We're not actually going to set the camera. I'm going to delete that."},{"start":"7:08","end":"7:39","startSec":428.0,"text":"We need to get its location. The reason we want its location is because we're going to do a line trace again out the front of the camera. So I want to get level viewport information. And let's add our line tracing again. So line trace by channel."},{"start":"7:39","end":"8:10","startSec":459.0,"text":"The camera is going to be the start location for this line trace. Now, in order to get the end point, what we're going to need to do is we're going to have to add a thousand or however long we want to be able to trace to the vector location. But in order to do that, we're going to need the direction that the camera is pointing it. We don't really want it as a rotator."},{"start":"8:10","end":"8:47","startSec":490.0,"text":"We want it as a vector so that we can easily work with it. And we can do that by dragging off of the camera rotation and type in get forward vector. And so this is going to give us a one centimeter vector in the direction forward of the camera. Now what we can do is we can multiply this, converting this to a float."},{"start":"8:47","end":"9:19","startSec":527.0,"text":"And I am going to multiply that by 1000. And then I have to add that to the original camera location. That gives us our line trace. I can check this is working by drawing the debug. I'm going to make it forward duration. I'm going to increase draw time five should be fine."},{"start":"9:19","end":"9:50","startSec":559.0,"text":"And hit compile, save. And now if I push spawn bush, I move, you can see the line trace. Spawn bush is the line trace there coming out of the camera. So the reason we're doing that is so that we can figure out the location that we want to place this spawned bush. So I'm going to chop back in."},{"start":"9:50","end":"10:30","startSec":590.0,"text":"So the next thing that I'm going to want to do is spawn actor from class. This class is going to be a static mesh actor. And the spawn location is going to be a bit more difficult in this case. So I have right clicked on the spawn location and I have split the pins because I'm just going to work with the location at this point."},{"start":"10:30","end":"11:03","startSec":630.0,"text":"There are two conditions in this instance. If the line trace does hit something, we will want to spawn the actor in the location that it hit. If it hasn't hit anything, we would want to spawn the actor in front of the camera. So in order to do that, rather than writing a branch dependent on the return value, I'm going to do this all in the input to the location."},{"start":"11:03","end":"11:35","startSec":663.0,"text":"So if I drag off, I can type select vector. Now with the select vector, the return value, I can plug in to the pick A. So now if we hit something, it is going to place the bush in the first location. If we don't hit something, it will place it in the second location."},{"start":"11:35","end":"12:06","startSec":695.0,"text":"So I am going to split the struct pin again. I'm going to find the out hit location. And that's A. So if the hit was successful, it would create it at A. If it was unsuccessful, I'm going to do that. I'm going to take the end of the line here. So that would be a thousand centimeters in front of the camera."},{"start":"12:06","end":"12:40","startSec":726.0,"text":"Again, we won't be able to see anything unless we set the static mesh. I'm going to type set static mesh. That gives us our static mesh component. And the mesh itself, I'm going to drop down, I'm going to search for bush."},{"start":"12:40","end":"13:10","startSec":760.0,"text":"And save and compile. Now let's test this out. So now if I'm down low and I push spawn bush, it will create the bush in front of me. If I look into the sky and push spawn bush, it's going to create the bush thousand centimeters in front of me. So you can see how this is quite a simple tool where you can query the environment and quickly create a bush in front of you."},{"start":"13:10","end":"13:42","startSec":790.0,"text":"Now that's good. That's just one button. What I would like to do is convert this into a function so that we can create multiple buttons all that spawn different things. The way I'm going to do that is I'm going to zoom out a little bit here using the mouse wheel. I'm then going to left click and draw a line around the whole section. Then I will right click and select collapse to function."},{"start":"13:42","end":"14:12","startSec":822.0,"text":"And that's going to create a new function here. And I am going to call this spawn static mesh. There's one more thing I'd like to do. Let's jump into this. And we have hard coded the SM underscore bush."},{"start":"14:12","end":"14:46","startSec":852.0,"text":"I'd like to choose this every time we run the function. So I am going to make this easier to see. What I'm going to do is I'm going to drag the new mesh and I'm going to drag it onto the input purple node here. And you can now see that is set as an input. If I compile, jump back to the event graph here, I can select bush."},{"start":"14:46","end":"15:18","startSec":886.0,"text":"And we have the spawn static mesh here. Now, if I was to jump back to the designer. So I duplicated this button. I duplicate this button, move it over here, change the text. So it says spawn chair. And I come down to the bottom. Oh, no, with the button selected, I come down to the bottom."},{"start":"15:18","end":"15:50","startSec":918.0,"text":"Add another event on clicked. Then I can grab this function. Press control and D for duplicate. Connect it up. Now change that to share. And hey, Presto, we have SM underscore chair. And you can now see we have a new button up in the top here that says spawn chair."},{"start":"15:50","end":"16:21","startSec":950.0,"text":"And now with one button, I will spawn a chair and with the other button, I will spawn a bush. Now, it's a very straightforward example here, but you can see how something like this could be built out. And this is often used in conjunction with more complicated assets, which have different settings required. So excellent. That is our second tool completely created, the quick spawn."},{"start":"16:21","end":"16:53","startSec":981.0,"text":"Now, again, what I'm illustrating here is the trigger points. There's a big focus on the trigger points because there's lots of different functions, lots of different things that you can do with tools. But what's useful to understand is what kind of tool you create so that you know how to trigger it, where the best option is for triggering it. Thank you very much. In the next video, we will be looking at working with assets in the browser."},{"start":"16:53","end":"16:57","startSec":1013.0,"text":"We will be creating an editor asset utility."}],"07_MassRenamingTool":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Hello and welcome to this video on Editor Asset Utilities. In this we will be doing an exercise where we will be making a mass asset renaming tool. Ok, let's jump into the editor and we're going to create a new asset. So if you right-hand click, if we come up to Editor Utilities, this time let's select the Editor Utility Blueprint."},{"start":"0:34","end":"1:08","startSec":34.2,"text":"This is going to give us a number of different choices. We are going to select an Asset Action Utility. And I'm going to call this S-A-A-U underscore rename. And I'm going to double click to open this up. Again this will look a little bit like the blueprints we've previously been working with."},{"start":"1:08","end":"1:48","startSec":68.4,"text":"But one of the things you might notice is we have no viewport in this situation. We do not need them. Now an Asset Action Utility works a little bit like a code library. So we could write a number of different functions and these would be available anywhere in the content browser by right clicking on the appropriate assets. The first thing we're going to want to do is create a new function. And I'm going to call this Rename."},{"start":"1:48","end":"2:24","startSec":108.9,"text":"So what I'll do is I will select the purple node. And you can see over on the right hand side we have options for input. I'm going to hit once and I'm going to call this the Free Fix. And this is going to be of the type String. And I'm going to add another one. And this is going to be the Post Fix."},{"start":"2:24","end":"2:57","startSec":144.8,"text":"So this function is going to take in two variables, Prefix and Postfix. And we're going to just put the prefix before the name of any of the assets we're going to change and the Postfix we're going to put after it. So let's write some code. So the first thing that we're going to do is drag off and we're going to want to get selected assets."},{"start":"2:57","end":"3:35","startSec":177.0,"text":"What this is going to do is it will return an array of any of the assets which you have selected within the content browser. So say I came up into here. I'm going to reduce this just down to materials. If I selected these four materials, it would return an array with these four materials. And I come in here and I will do a for each loop."},{"start":"3:35","end":"4:07","startSec":215.8,"text":"Now all I want to do is rename the asset that we have here. If I type in rename asset. So whatever I would input here is going to be the new name of the asset. We want this to be a string concatenation of our inputs and the actual name. So I'll drag off of this and I'm going to type in append."},{"start":"4:07","end":"4:39","startSec":247.8,"text":"And I'm going to add an extra pin by clicking on the add pin here. Now I'm going to get the object name. I'm going to connect that up to the B pin. And I'm going to grab the prefix and put it in the first pin and the post fix and put it in the C pin."},{"start":"4:39","end":"5:14","startSec":279.5,"text":"Now this is our entire code at this point. So all we're doing is getting the selected assets that we have. And for each of them, we're going to rename them, putting the prefix at the beginning and the post fix at the end. And if I now hit compile and save, and then if I jump back to our asset browser, let's do this with one to start with. So we've got our basic floor. If I right-hand click on this, you can see that we now have an option for scripted asset"},{"start":"5:14","end":"5:47","startSec":314.9,"text":"actions. And next to them, they've got the option for rename. If I click on this rename, I'm going to get a pop-up box. It's going to ask me for a prefix and it's going to ask me for a post fix. And so I'm going to call, I'm going to say this is pre underscore and I will do underscore post on the other side and click OK. Now because this is in alphabetical order, we've now lost it."},{"start":"5:47","end":"6:14","startSec":347.7,"text":"If I was to search for pre, you can see we have pre, m, basic floor and post. So that's working. Now the other nice thing about this is we could come in and we could select, let's select all of these assets. We could select as many assets as you wanted. Right-hand click and under asset scripted actions, rename. And I'm going to call this."},{"start":"6:17","end":"6:48","startSec":377.8,"text":"A underscore and at the end, I'm going to do the underscore and hit OK. You can see now all of these assets have been updated in one quick go. The main reason why these asset action utilities are really useful is because they'll automatically appear when you right-hand click and select the assets in the browser."},{"start":"6:49","end":"7:21","startSec":409.7,"text":"And I could create numerous ones. So if I just added another one, for example, and I change this to be hello. And I print string hello and compile, save, jump back in. Right-hand click, you see under scripted actions, we now got hello as well. Hello appears in the top left hand corner. So the trigger, and that's the main thing, the trigger for this is going to be on the"},{"start":"7:21","end":"7:47","startSec":441.4,"text":"scripted asset actions. Now what you might find is that you actually want these options to only appear for a specific class and you can do that. So if I was to come up here and I was to select class defaults, we have a list here of supported classes. If I was to push plus, I could select to only show this on materials."},{"start":"7:55","end":"8:26","startSec":475.5,"text":"And now these options would only appear for materials or classes that are children of materials. So, for example, if I was to grab this, just control P, right-hand click, the scripted asset options would not appear here. However, if I was to jump to the material, right-hand click, you'd see that we do have the scripted asset actions here. So you can see how that's a really useful tool to just very quickly create tools that can run against a lot of different things."},{"start":"8:26","end":"8:56","startSec":506.4,"text":"Now, say you wanted to do the same thing and add a menu option in, but this time for a actor rather than an asset. Let's just demonstrate that quickly. So if I come into here again, I come to editor utilities and I select an editor utility blueprint. Now it's not any of these. What I actually need to search for is if I search for utility, you can see that we have actor action utility here."},{"start":"8:57","end":"9:28","startSec":537.5,"text":"I'm going to select that and I'm going to call this act action utility example. If I double click on this again, if I just create another function and I'm going to call this hello and I'll drag off here, search for a print string. Hello. Compile save."},{"start":"9:28","end":"9:58","startSec":568.8,"text":"Now, if I select our chair, right-hand click, you will see here at the bottom, we have scripted actor actions. I can just select that as hello. Now, say we wanted to get hold of the selected actors. So if I delete this, grab one of these and I go get selection, get selection set. That is going to return us all the selected actors."},{"start":"10:00","end":"10:31","startSec":600.3,"text":"So I could do a for each loop. Like that. And all I'm going to do is I'm going to destroy these actors. So this is a quick way to go and destroy everything that you've selected. Of course, you could just press delete, but this is a good example of how you can implement something on an entire selection set. So I'm going to go ahead and delete this. I'm going to go ahead and delete this. So this is a good example of how you can implement something on an entire selection set."},{"start":"10:33","end":"11:05","startSec":633.2,"text":"So if I grabbed a couple of these. Right-hand click, come down to scripted actions, do hello, and everything's gone. So again, it's just an example of how you could create an action and you can do anything from the trigger. What's more important is where the trigger is. So you'll know that if you want to trigger something on a specific asset, then you could do it using an actor action utility."},{"start":"11:09","end":"11:20","startSec":669.5,"text":"Okay. So that is the last of our examples. Thank you very much for sticking with us."}],"08_Outro":[{"start":"0:00","end":"0:39","startSec":0.0,"text":"So that brings us to the end of the tool creation class. Thank you for sticking with us. Let's just do a quick recap of what we've covered. So we talked about the theory of tool making, where a lot of it's about considering what you want this tool to do and where you would like this or how you would like this to be triggered. We've then gone through four exercises and made a few different tools. First, we started looking at construction script where we use that for a mesh scattering and we improved that so that it used the line trace to connect to the floor."},{"start":"0:39","end":"1:14","startSec":39.0,"text":"We then made an exposed function that allowed us to bake out the meshes that we had scattered. Next up, we created an editor utility widget and we just used that in order to do another line trace in front of the camera and spawn meshes accordingly. We created a function in this instance so that the same code could be reused over and over again. Finally, we made a mass rename using an editor asset utility."},{"start":"1:14","end":"1:38","startSec":74.0,"text":"And as a final byproduct, we had a quick look at an actor action utility which demonstrated where we would be able to place a trigger connected to the right-hand click menu of an actor within the level. I hope you got some value out of that and thanks a lot for following them. Goodbye."},{"start":"1:44","end":"1:46","startSec":104.0,"text":"."}],"1_Intro":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Hello, my name's Edward Bennett and I'm an instructor here at Epic Games. I'd like to welcome you to Tool Creation for version 5.1. This course was originally written in Unreal Engine 5.1, but the tools are common across all of five. So you should be fine working in any version of five. In this course, we're going to start off by going over some toolmaking theory in the engine."},{"start":"0:31","end":"1:02","startSec":31.0,"text":"It shouldn't take much more than 10 minutes. And then the rest of the course is going to be pretty much hands on exercises. Each of these exercises, there's an expectation that will take around half an hour. So the first exercise we'll be doing will be on the using the construction script where we will be scattering meshes. Second exercise, we will be baking out those meshes using the exposed function commands."},{"start":"1:02","end":"1:25","startSec":62.0,"text":"Third exercise, we'll be building an editor utility widget to quickly spawn meshes. And finally, we will be creating a editor asset utility to do some renaming. So that's it for the introduction. Let's jump into a bit of theory in the next video."}]},"203.02":{"01_Intro":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Hi everyone, my name is Sean Spitzer, Senior Instructor for Epic Games. In this set of lessons, we're going to be talking about lighting in Cinematic Fundamentals. We'll be covering how to control Lumen and the appropriate settings to get you in the right direction, as well as controlling exposure, looking at baked lighting, looking at light mass and light maps, as well as GPU light mass and reflections, and eventually we'll look at lighting a character. So we'll go over the outline for that class in the next video, as well as look at exposure."},{"start":"0:33","end":"0:34","startSec":33.4,"text":"So let's get started."}],"02_RealisticLighting_Lumen":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hi everyone. In this lesson, we're going to take a look at the outline for Lightning Cinematic Fundamentals. From there, we're going to go ahead and jump into Unreal and look a bit at the slides when it comes to setting up a Lumen scene and controlling your exposure. So let's get started. So first up, we're going to take a look at Exposure Control and Tools. From there, we'll look at setting up a simple scene in Lumen. We'll look at engine scalability, Lumen material limitations, and Lumen CVars."},{"start":"0:30","end":"1:04","startSec":30.0,"text":"Next, we'll look at environment light baked lighting, which is our first way to work with lighting, which we first established before Lumen. We'll look at the initial setup as an option, working with lights in detail and adding AO baking. Next, we'll look at light maps and light mass under that same topic of baked lighting. We'll look at the best settings for light mass and light mass importance volume, light map UVs, and solver quality. Next, we'll look at reflections underneath baking also, and when to use them, reflection types, scenarios, building quality, and tips."},{"start":"1:04","end":"1:36","startSec":64.0,"text":"Reflections can also be used for ray tracing, so this can actually help a bit. View modes and visualizers. We'll next look at looking at volumetric light maps, light mass tips, screen space, global illumination, using it, and some of its limitations. We'll next look at GPU light mass, the overview, what it is, and setting it up. And finally, we'll look at an exercise where we will be lighting a character. So let's go ahead and get started."},{"start":"1:36","end":"2:09","startSec":96.0,"text":"So let's go ahead and take a look at realistic lighting and exposure control and tools. So what we'll do first is I'll walk you through a Lumen focus on setting things up just as a reminder of some of the things we covered in our first class. So here are some of the steps listed in my lecture, some of the things you can consider putting on, and it's very important to make sure that these are on when working with Unreal. I'm specifically going to talk about looking at your Lumen details for lighting mode and software ray tracing mode, which we'll point out in just a second."},{"start":"2:09","end":"2:41","startSec":129.0,"text":"Let's go and jump into Unreal and I'll point some of these details out so you can keep them in mind. Here I have a cafe scene, and if you want to open it up, it is actually found underneath if we go to our Lumen folder here for the class, which is labeled for our class here. From here, you'll see that I have a Lumen indoor sample scene, and that's pretty much what we have here. So in my scene, one of the things you want to keep in mind is how we're going to set this up initially, which we'll do in just a second."},{"start":"2:41","end":"3:12","startSec":161.0,"text":"But I want to point out some things first up that you need to do when working with Lumen. So say we're getting ready to look at a Lumen scene. Let's go to our project settings here and pull these across here. Sorry, it was a bit off screen. We're going to go underneath rendering. In rendering, we want to make sure that we're working with Lumen. We also want to make sure that we are using hardware ray tracing when available. And once you have that set in, you also want to make sure you're supporting hardware ray tracing."},{"start":"3:12","end":"3:44","startSec":192.0,"text":"You'll see one on first, and then the other will be available. With that, you also, if you're grabbing stuff from the marketplace, make sure you have virtual shadow maps on, as well as mesh distance fields. Now, these things won't be on by default if you're grabbing stuff from the marketplace, but it's very important to consider these things. And you can look at mesh distance field by simply typing in mesh distance field, and you'll see generate mesh distance field. And you want to have that with Unreal."},{"start":"3:44","end":"4:14","startSec":224.0,"text":"So again, some of these things will be on by default, but it's actually also good to check to make sure if you grab something from the marketplace that some of these things aren't turned off and maybe catering to the old baking method. We have ray tracing lit mode. You'll see it says surface catch, but you can also set this to a higher set by default and hit lighting for reflections. This can also be set in the post process volume. You'll also see under safe software ray tracing mode, it says detailed tracing or global tracing."},{"start":"4:14","end":"4:47","startSec":254.0,"text":"Of course, one is more expensive, such as detailed tracing versus global tracing. This just depends on your system and whether you can handle that. So keep things in mind and be very deterministic. One of the things or at least the two things you do need to also consider on my list is shader model six. Shader model six should be on when working with Unreal. I like to turn both of these on. I may not need this Vulkan one, but just in case I bring in a shader that may need that support, I make sure that I put these in here."},{"start":"4:47","end":"5:19","startSec":287.0,"text":"Also, you want to make sure that virtual text screen is on. This will help with some of the visualizers. So in this case, we don't really need it because we're not going to get into the visualizers that we covered in the first class. But you do want to be able to turn that on when you can. I already have my on, so we're in luck there. But if you don't have it on, do turn it on. If you want to check Lumen, you want to check your your your shadow maps. I shouldn't say shadow maps, your virtual shadow maps, and you want to make sure that those are in the right direction."},{"start":"5:19","end":"5:56","startSec":319.0,"text":"We already covered some of that in the first class. But in here, you can also double check just in case, again, if you're pulling things in from a marketplace or you're inheriting a scene that you think may not have that on. But those are actually good support for your visualizers. Let me close this for a second and let's go ahead and go to a scene that is a starting point for us. So there's our Lumen indoor start. Let's go and click on that. So this one just has a few things in here, maybe a few lights. Let's go and get some of the things in this scene and make sure we're really bare bones."},{"start":"5:56","end":"6:26","startSec":356.0,"text":"So let's go ahead and take a look at our lights and we're going to turn off our sky atmosphere. Get rid of that volume, which a cloud gone. Good. Let's see if there's any other lights that we need. There are some glowing items in our scene and there's also a post process volume. Let's get rid of that post process volume for a moment. And then we can track down if there's any other lights in here. And we should be good to go."},{"start":"6:26","end":"7:03","startSec":386.0,"text":"Double check the assets and we should be OK. Now, the only lights we're getting is from Lumen because these items here, each one has a glowing material. Our first class talked about this, how you can actually set up a glowing material in your scene. So that is actually giving us some light. Now, the problems you can run into if this item or object that's glowing is very small, you can get a lot more noise and there might be some issues. For now, we can leave this as is and let's actually open up our environment light mixer."},{"start":"7:04","end":"7:34","startSec":424.0,"text":"There it is off screen. I was just double checking to make sure it's open. It looks like it already was. We want to first create our sky light. Then we want to create our atmospheric light. Again, you're going to get this error because some of these lights do have dependencies to be able to get some of these to work together with it, to give that believability that you need. And that's why that first one comes up. It needs at least the sky atmosphere to be working correctly. We're going to create an atmospheric light. I'm going to create a sky atmosphere and then I'm going to create a volume at your cloud."},{"start":"7:34","end":"8:10","startSec":454.0,"text":"And eventually we'll do a height fog. Now we have these all set up in place. Now you'll notice our cafe doesn't seem to have anything to write home about. It's kind of standard stuff. And there's an HDR backdrop out here. And you can use HDR backdrops. It's up to you. There's no requirement for your scene. It's really how you need it for what you're doing because we're inside a cafe so we can maybe give a little suspension of disbelief. But just be aware that if you go outside or you're going to be looking at these and you do want to sell the idea and this pretty much looks this is pretty generic."},{"start":"8:10","end":"8:42","startSec":490.0,"text":"So just keep that in mind. Let's go and grab our directional light. With our directional light now, let's go and move this over. I'm going to move it where you can see where it's pointing. We can see it's in the opposite direction of our cafe. So let's rotate that so it's shining in our environment. We can bump that out if we bump that up if we want to. Let's check our skylight and always especially if you're grabbing stuff from the marketplace, make sure that real time capture is on."},{"start":"8:42","end":"9:17","startSec":522.0,"text":"If you turn that off, you're not going to get the quality that you need when it comes to your environment. Specifically when you're in a little bit different scenario here, such as maybe you have low light and it's coming in into your environment, that gives you some extra bouncing going on. We do want to make sure that your lights are movable. Very important to do so. Because that movable, you'll see a skylight directional, both movable, are going to work with lumen. So these are all just some reminders when it comes to working with lumen."},{"start":"9:17","end":"9:47","startSec":557.0,"text":"Next, we want to go in here and let's increase our light just a bit. We'll make this probably about a 20. Like it's kind of a foggy day. Now our fog is going to influence this a bit too. So if your fog is a lot more in your scene and magnified, we get into this in atmospheric lighting, but that can also influence how things are going to be viewed. Because like in the real world, that light's going to bounce around those water particles."},{"start":"9:47","end":"10:19","startSec":587.0,"text":"We can also soften our shadows if we're getting some very edgy areas here, such as right over here on the desk. And if we move away, you'll see that get a little bit more edgier here. In our first class, we talked about using CVars to maybe control some of that shadow quality. But what we can do with this directional light selected, we can go to the source angle and maybe increase that just a little bit there to soften that up if we get any hard edges. And oh, that looks much better."},{"start":"10:19","end":"10:51","startSec":619.0,"text":"So that's helpful for our scene. You may at time get some noise. Now there are some CVars to solve this, but like we talked about in the first class, you can also visit the material. And when you visit the material, you can control just how strong some of the roughness will be. And when you lower roughness and get things a little more shiny, you can see some of the noise dissipate. Now this is a something you have to dial down or dial up or revisit the texture to be able to get that going. But this is all up to you how this works."},{"start":"10:51","end":"11:21","startSec":651.0,"text":"Now there will be always a little bit of noise with Lumen because it is evolving. So just keep those things in mind. Control your roughness and how things are working and you can be the master of your own environment. Now we want to bring in a post process volume. This is really important because it's our quality control. So let's go ahead and do that. Now there's a couple of ways to do that. You can type in volumes here. You can look for them or you can just simply go in here under volumes. And find it."},{"start":"11:21","end":"11:52","startSec":681.0,"text":"You can also search at the top of this by just typing in volumes. And we'll do post process. I should do be more specific in your search. Grab that post process volume is now in our scene. And if you're wondering what just happened, I accidentally hit space bar, which shows you like everything. That's the hot key for the place actors. Learn something new every day, even on accident. So I'm going to go and move this over here."},{"start":"11:52","end":"12:29","startSec":712.0,"text":"My post process volume needs to be set to infinite extend unbound. So let's go and do that. So when you do set this, scroll a little too far, you can have it so it will control everything. You can also build a box around an area if you needed. But Lumen is pretty efficient. It doesn't necessarily have to be locked down like when you're working with ray tracing. Ray tracing, you really do want a specific area because it's a bit more expensive. We're just borrowing some of that technology from ray tracing and getting some of those light information bouncing around those photons back to the camera."},{"start":"12:29","end":"13:02","startSec":749.0,"text":"So but it is work. It works a lot smoother and a lot more trimmer than when you if you would work with ray tracing. So we want to make sure that Lumen is on. Now we do have it in the project defaults. But again, you want to turn it on under your global illumination and you want to turn it on under your reflections. Let's turn these on for now or revisit some of these quality control settings later. Just as a quick review. We also want to go to global illumination Lumen here for lighting quality, scene detail."},{"start":"13:02","end":"13:32","startSec":782.0,"text":"All these things can be bumped up to help a few things going in the right direction. And I'll give you some CVARS to help with a little bit with cleanup and show you the console tool that we have, which is pretty great. All right. So that's it with this video. What we're going to do now is take another look at the next video at the post process volume here. We're going to edit exposure as well as we're going to look at a few Lumen settings that we can do to get things in the right direction."},{"start":"13:32","end":"13:38","startSec":812.0,"text":"Thanks again. Thanks for watching."}],"03_ExposureControl":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"In this lesson, we're going to take a look at a few more things with Lumen, and then we're going to go and jump in and look at exposure control when it comes to setting up your scene. So let's get started. So we built our scene out and we brought in a post-process volume controlling some of the quality in here as we need. Now again, a review of some of that, we can actually, if your scene supports it, and remember some of these are GPU expensive and if you increase them, you need to keep in mind what"},{"start":"0:33","end":"1:03","startSec":33.6,"text":"your GPU can handle. So I can increase my lighting quality as well as my scene detail if I wish. Now my system is a bit stronger than some others and I can go in here and even increase my final gather if I need to. Now as we do this, you can remove some of the noise, but you have to keep in mind some of your materials, which was mentioned in other classes before, where you can actually adjust the material roughness. And when you adjust the material roughness, you're able to remove some of the noise."},{"start":"1:03","end":"1:34","startSec":63.8,"text":"Now some of the noise may still persist so that you can still use some C-Vars to clean that up. But keep in mind that Lumen is still evolving as it grows and gets stronger, faster and better. You will need to be very deterministic about your shots, your materials and your angles. And you'll notice here in this particular shot, there's a little bit, just a little bit of noise over here on these rough areas compared to over here where it's a little bit higher, where there's a lot more bouncing and refracted areas."},{"start":"1:34","end":"2:06","startSec":94.0,"text":"We also want to go in here and go to our project settings. In my project settings, I want to go in here and look at my static light. The reason why I want to do this and make sure that static light options are off is I want to make sure that they're not pulling anything unnecessary in my scene. So I'm going to turn off my allow static lighting. I'm also going to make sure that I turn off my ambient occlusion static fraction. And you'll see mine's already off."},{"start":"2:06","end":"2:41","startSec":126.1,"text":"Now this will require a restart. So let me go ahead and restart this and we'll go back into our scene. Now you'll notice if we float over that tick box that we turned off, Unreal will give you a breakdown saying you should really turn this off. That way it allows the bent normals and the luminal global illumination to actually calculate those correctly. And it really just is not needed. And you're saving some overhead there. So you want to make sure you turn that off. Now that was covered in the first class, but I just wanted to remind everyone about that."},{"start":"2:42","end":"3:18","startSec":162.8,"text":"So let me go ahead and close these two windows. So we have our scene in here and we're looking pretty good, but we want to maybe try to get it so that our exposure is really at a level that makes sense. So from ground up, you can say, let me close this window too. Don't need it at this time. So what we want to do is go into our content drawer. I'm going to click on engine and I'm going to type in calibrator. I'm going to pull in my SM color calibrator."},{"start":"3:18","end":"3:49","startSec":199.0,"text":"I'll pull this into my scene and I'll drag this one outside for a moment. This is going to give us the best possible results for our exposure and allow us to be able to pull in what we need. Now, before we do that, I do want to mention scalability. This is very important when working with Unreal to determine what your computer can handle. Now in older settings, it was found up at the top and older versions of Unreal, but"},{"start":"3:49","end":"4:21","startSec":229.8,"text":"you can now find underneath your settings here, scalability, engine settings. Everything I have is set to epic, but if I wanted to, I can also set things to cinematic. My computer can handle that. But you can also have auto here. Now when you set auto, Unreal will determine based on your computer, the best settings that are needed and can accommodate what you have under the hood."},{"start":"4:21","end":"4:53","startSec":261.4,"text":"Now let's go back to the slides. I'm going to take a look at a few points I want to make clear and some things you have to adjust before we go forward. So in our project settings, there's a few things we need to make sure that we turn off. One of them is bloom. We want to make sure that bloom is turned off. And AO. Now you can turn them on. I usually turn them on to turn them off or make them zero. And that way, if I need to go back to them and turn them back on, I can easily do so. Also turn off auto exposure that's in the project settings."},{"start":"4:53","end":"5:24","startSec":294.0,"text":"Any vignetting that you have in your post-process volume. And turn off your extended default luminance range. That will require a restart. So just keep that in mind. Some people may want to keep this on so that you still have a little bit of a auto calculation for your distance and your luminance. I prefer to actually turn that off. But it's really up to you as you decide to dive into these deeper. Let's go ahead and take a look at some of these things in Unreal and mess with these settings."},{"start":"5:25","end":"5:58","startSec":325.9,"text":"Okay, so let's go ahead and go into the project settings and change some of those things. One, let's go and type in bloom. So you can see I have bloom turned off. And you want to have this one turned off initially. Next we want to go in here and type in AO. So we want to make sure that our, or you can just type in ambient inclusion. Maybe a little bit easier so you don't get a thousand things. Turn off your default ambient occlusion as well as the baked one."},{"start":"5:58","end":"6:28","startSec":358.2,"text":"You don't need that. And you want to keep things pretty pure, especially if you are baking. You want to make it so you're starting off from scratch. You can go in here and change a few things later on as you go. Next we want to also go in here and change our extended. Make sure we spell that correctly. We need default luminance range in the auto exposure settings. We want to make sure you turn that off."},{"start":"6:28","end":"7:01","startSec":388.5,"text":"We also want to make sure auto exposure isn't on. I almost forgot about that one. So auto exposure, you want to turn that off so you're in control. And I'll show you how you can actually reactivate that. But within the post process volume, which is actually pretty nice. Also, if you did inherit something from the marketplace, you want to go into your post process volume. And in here, you want to go in here and you want to look for vignetting because someone"},{"start":"7:01","end":"7:35","startSec":421.6,"text":"may have turned it on and you may not even know. And you can see in this case, we have it on. We can turn that off. We don't want to have that on. That makes it so you have a pure scene. You know exactly what it is you're getting exposure wise. And it's pretty beneficial. So now we want to go ahead and take a look at our exposure and see the amount and judge exactly what we have with those settings, everything else in place."},{"start":"7:35","end":"8:08","startSec":455.2,"text":"Now that we're in unreal, I'm going to go and move over to the outside where our calibrator is at where we left it. And I'm going to look at the third gray square from the right side here. And we're going to use a thing called a pixel inspector. This pixel inspector will allow us to go in here and to be able to judge exactly what it is on our color exposure. Pretty much looking at our exposure, I should say, and looking at the color in that pixel,"},{"start":"8:08","end":"8:38","startSec":488.0,"text":"the luminance of it, I should say. And it's going to tell us exactly where we stand with things. Now you'll see it here right where it says debug. You'll go down to pixel inspector. Want to click on pixel inspector. Let me drag it over. We're going to turn on the start pixel inspector and we see there is a luminance here that we want to focus on. And it says luminance before tone map."},{"start":"8:39","end":"9:10","startSec":519.6,"text":"I'm going to float over and it's going to give me what that is for that particular pixel. And we can see that it's 7.5. But that's not exactly what we need. If we go back to the notes here, you'll see that we're looking for a 0.18 or 18% gray. This is going to be coming back as a 50% in our gray sRGB. This really does depend on the scene, but we can actually adjust things and correct"},{"start":"9:10","end":"9:42","startSec":550.6,"text":"things to what we need. Let's go back into Unreal and do that. With the pixel inspector active, we can now use it so that we can analyze that scene again. So let's go and do that. Go to debug again. I'm going to go to our pixel inspector. And again, you click on the magnifying glass. We can now inspect where our luminance is at. Now we can see that our luminance is pretty high. So to be able to fix that, we're going to go in here and adjust our strength of our light. And we're going to lower this to like a 4.5."},{"start":"9:42","end":"10:11","startSec":582.6,"text":"You can even keep it at 5 if you want to. But we can now check with the pixel inspector. And we're pretty close with our luminance before tone map. So we can actually get this just to 4 and see what we get. And then do that again. Pretty close, but not quite there. And we'll get that intensity adjusted. So we'll do a 3.5."},{"start":"10:13","end":"10:44","startSec":613.6,"text":"There we go. 3.5 it is. Now with that set up, I can now go in here and control my exposure. So I've adjusted the light here and I can go in here and now in my scene, go to my post process volume and turn on a few things. Now if we look at exposure up close, you'll notice we do have a default bloom intensity and threshold. So I can turn these off if I want to. It's up to you how you do this."},{"start":"10:44","end":"11:15","startSec":644.6,"text":"Realize when you do turn on bloom and crank that up, it could actually make things a bit blown out. We'll close mobile because we're not in mobile. We'll close bloom for now. And we're going to mainly focus here. Now there's several different ways that you can choose your exposure. There's an auto exposure, which I prefer, because then I can lock it down within a range. Let me show you what I'm talking about, particularly the minimum brightness and maximum brightness. So if I do adjust that and turn on auto exposure, I can keep my minimum and my maximum within"},{"start":"11:15","end":"11:47","startSec":675.6,"text":"a particular range and it will help adjust according to my settings and what I have in place. Now, I, a lot of the times, will set this simply to one because then everything works as a simple EV slider and I can choose whether I want it dark or I want it bright right there within my scene. And I'm in full control of everything and I know exactly where my exposure lies and how I've set it. You can also choose to do auto exposure basic and a few things will be grayed out as you"},{"start":"11:47","end":"12:18","startSec":707.6,"text":"go and change between these, as well as you can also do manual, which is pretty straightforward. We're just mainly messing with this again, like an EV breakdown, but you'll notice some of these are grayed out and no longer such as the minimum brightness and maximum brightness are no longer adjustable when you're in manual. But again, I like auto exposure. Call me an old school game head for me. That helps me be able to adjust this. And if I did want to create a minimum and maximum to get that auto to be able to control"},{"start":"12:18","end":"12:52","startSec":738.6,"text":"within a range, I have that choice. It's really up to you how you want to do it. And we can set these to default and you can see the auto exposure kind of adjusting itself as I go from one room to the next. I look in different areas. You will notice too, off to the right here, we have a thing called a exposure compensation curve. You can load these and build the curves yourself. There are some default ones that come in here. If I double click on this, this curve now is able to be adjusted and will affect my scene."},{"start":"12:54","end":"13:25","startSec":774.6,"text":"Now, some of it might be very minimal when you move these around, but it's up to you how you adjust it and how you move things and how you edit things accordingly. If I grab the whole line here and move it up and down. You'll see things slightly change. You got a little brighter and I'll move this down. You'll see it get darker. So it does have an influence. It just may seem a little bit weak in here. It's up to you how you adjust that curve. I'm going to turn the curve off. We don't need it. And they can definitely see the dramatic change."},{"start":"13:25","end":"13:55","startSec":805.6,"text":"There is a exposure meter mask. You could also load if you wanted to. But all these things are at your fingertips to be able to control your exposure. There are a few materials to keep in mind when working with Unreal 2. So this particular one has a very distinct material in here for our glass. There's a frosted glass effect in here. You will see the noise because lumen and some materials may not play necessarily nicely. It may give you a bit higher noise. So keep that in mind."},{"start":"13:55","end":"14:30","startSec":835.6,"text":"And this particular material, if you slide over, is a spiral blur texture, scene texture. So you can experiment with some of these materials. Some of them I'm not really sure some that will work and not work. You have to. It's always a case by case. And also lumen is constantly evolving, getting better and stronger. But you can definitely see the noise coming through on this blurred effect. In this particular case, you may want to just use an alpha mask that is a bit more 50 50 gray. And per using it within the material, because we definitely are getting a bit of noise there."},{"start":"14:32","end":"15:01","startSec":872.6,"text":"Here is a list of CVARS that you can use to be able to run and experiment with your scene. And they are available to you. But let me show you some quick tips and tricks when working with these CVARS in Unreal. A lot of people aren't aware in Unreal you have the ability to actually call upon the CVARS at any time, because they do disappear if you just work in your output log down below. But you can use a tool that we have set up for you that allows us to be able to go in here."},{"start":"15:02","end":"15:37","startSec":902.6,"text":"And let me go ahead and find this guy. This is just an added added bonus that I'm adding to this course. We got to turn him on. So if I go to plugins here. We turn on console. You'll see there's a thing called a console variable editor. Let me turn mine on and give it a restart. And you can actually see kind of how cool it is. Now that I've restarted, I'm going to go in here under windows and pull up a thing called console variables."},{"start":"15:37","end":"16:09","startSec":937.6,"text":"This console variables allows me to add any console variable that I have in my commands. Say I've worked on a few and I've added a few. I can place them in the console variables. Worked on a few and I've added a few. I can place them here and I can even save those presets that I already have in place and call upon them whenever I need them. It's really nice. So you don't have to worry about punching stuff into the command line here and seeing it disappear or no longer working as an on when you close in real. You can actually load it through your console variables."},{"start":"16:09","end":"16:42","startSec":969.6,"text":"Very handy. And also if you get stuck and you're like, I'm not sure which Lumen ones I have. I have maybe I don't have Sean's a magical PDF. You can go into your console variable search table here that is built under help here. If you go down just about four lines here, you'll see console variables. Click on that and you're going to get quickly navigated to an area where you can look up that console variable that you need. Pretty nice. And I can simply just type in Lumen. So everything that has to do with Lumen is now going to come up into my search."},{"start":"16:44","end":"17:10","startSec":1004.6,"text":"And it gives you a description for each item to which is really helpful. Well, that's it for this class. Here's some more information that you can click on to be able to actually dive a bit more into auto exposure and other exposure properties when working with unreal. In the next section, we're going to take a look at the old school way to bake your lights in using the bake lighting system in unreal."},{"start":"17:14","end":"17:16","startSec":1034.6,"text":"You."}],"04_Environment Lighting-Baking Lighting":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this lesson, we're going to focus on environment lighting when it comes to baked lighting. There will be a few tips and tricks when it comes to using your lights and they can still be associated with Lumen. So feel free to stick along for the ride and check out what we're talking about. So let's get started. So the initial setup, again, you always want to make sure you take into account your scalability for your scene, whether you're going to use epic or cinematic in your settings. You also want to make sure, again, high precision normals are"},{"start":"0:31","end":"1:02","startSec":31.0,"text":"on. And some of these settings are already on when it comes to Lumen. But when it comes to a bake scenario, you do need to double check and make sure that things are set accordingly. You also want to make sure your reflection captures are high enough to give you the best, highest visual fidelity. If you're using ray tracing, this also benefits ray tracing. So in the initial setup, you always also want to look at your lighting quality. When you start baking, are you doing production? Are you doing high, medium or preview? Let me show you where those are found."},{"start":"1:03","end":"1:36","startSec":63.6,"text":"You can find that setting under build here and we'll see a lighting quality. Right now, currently I'm in preview. But if I really want to get the highest reflection quality and bounces, I want to make sure I'm production. So I'm going to set that to production and I'm going to go ahead and run the build together. Now we're getting exactly what we need and want out of our bake here at the highest quality. It's really important for such things as a light mass portal that you want to be able to be on production. Otherwise, you won't get exactly what you want. Now, if you're unfamiliar with light mass portals, they"},{"start":"1:36","end":"2:08","startSec":96.1,"text":"can be placed in a room right where the window or the opening of a door area is located. So you can see that there's a lot of light mass portals. So there's a bit more believability between the dark regions and the light regions. It's kind of like a priority area to make sure that your GI is working correctly for those two changes. You also want to make sure you always have a light mass importance volume in your scene. This is really critical when it comes to light mass global illumination when it comes to using GI bakes,"},{"start":"2:09","end":"2:40","startSec":129.1,"text":"I should say. So now GPU bakes, GPU bakes are really important to consider putting this in there. And the reason why is becomes a priority area for how things are going to be baked and working with your moving characters. Now, when it comes to regular light mass importance volume in a CPU bake scenario, you still want it in there because you don't want to bake necessarily on everything. You want to make sure that you're not going to bake necessarily on everything. You want a priority area that's honoring your"},{"start":"2:40","end":"3:13","startSec":160.6,"text":"light mass settings. Really important to consider this, especially if you're working with terrain. That way Unreal is not working harder than it needs to. Let's go back to the slides. Under each light that is set to stationary, you want to make sure you set things to use area shadows for stationary light. This is really important. Let's talk briefly about the mobility and then go back to the slides again. Now again, this is specifically for baked lighting"},{"start":"3:13","end":"3:45","startSec":193.2,"text":"scenarios, but I just want to point this out just in case it wasn't clear in past classes. I'm going to click on my light source here. If we scroll up just a little bit details, we'll see that there's static mobility, stationary, and movable. Unreal gives you a nice brief breakdown when you float over it. Static is the cheapest and this is again for baked lighting, for objects that do not move. You can have as many as your computer can support. We also have stationary. Now stationary can change color and"},{"start":"3:45","end":"4:17","startSec":225.2,"text":"intensity, but then only be for overlapping at a time because you're calculating a bounce within a bounce. You're having these lights interact with each other and you're getting like double bounces if they overlap. So only four can be supported at a time. We'll talk about this later on. So just keep that in mind. This is not supported with Lumen, nor is static. Lumen supports movable and with movable, the Lumen settings as well as the mesh distance field set in our project settings and our virtual"},{"start":"4:17","end":"4:49","startSec":257.2,"text":"shadow maps are all supported using this particular light type. But baking is going to be shadow maps. And as you can see in our project settings, and we go to rendering, we'll scroll down just a bit and you'll see shadow maps is supported. Also in this case, screen space is supported for our dynamic global illumination, which helps support any bakes that we create. You can also set none and set it later within your post-process"},{"start":"4:49","end":"5:20","startSec":289.2,"text":"volume. Let's go back to the slides. So when baking your shadows, you're going to be creating a thing called a shadow or light map. That light map is baked within the objects, especially if they're static onto the existing geometry around them. It will create a self shadowing type of cover of shadow. You can think of it as almost an ambient occlusion in your texture on an object, but it's baked directly into a thing called"},{"start":"5:20","end":"5:51","startSec":320.3,"text":"that shadow map. Now, if you need to increase that resolution, it's best to go into the geometry of that object and use a thing called override light map resolution. That's going to be the most helpful, especially for your hero objects. And you want to set it to the appropriate resolution. Now, if that object is intersecting with other objects, you need to consider what that resolution is going to be. We dive in that a little bit later, but what I mean by that is the resolutions need to be somewhat in the same ballpark, or you run the"},{"start":"5:51","end":"6:21","startSec":351.3,"text":"risk of getting some blobby shadows. So working with lights in detail, the reason why you want to turn on that area shadow map setting, which was mentioned before, that area light shadow gives you a nice, believable, more of a blurred shadow in your environment and can soften things out. So it's a little bit more mirroring what happens in the real world. If you don't, you may get some edgy shadows. It may not quite be what you want, but you can push this even"},{"start":"6:21","end":"6:51","startSec":381.3,"text":"further within the light. In the light, you can create a thing called a source angle under light mass settings. This can be very helpful to keep things soft. You can also mess with your light source angle in general. And let me show you where those are at. Now, some of these topics were covered in other classes and will still hold true. And what I mean by that is the source angle when you're working with lumen will soften your shadows just great. But if we're in a"},{"start":"6:51","end":"7:21","startSec":411.3,"text":"baking scenario and you're not getting the softness that you're looking for so much with source angle, you can actually go down. And this is what I meant. You can actually go down underneath your light source angle and you can soften it up here to get even a better or a softer edge for your shadows. And again, this is for a baking scenario. When you create a directional light, you can also tell it to affect your atmosphere or not. That's really up to you how you want that to be"},{"start":"7:21","end":"7:53","startSec":441.3,"text":"included. Now, when real, if you have more than one directional light specifically when it comes to lumen, it will actually ask you for forward shading priority, basically which light you want to influence the atmosphere or the other. And it will give you a prompt for that. So just look out for that. If you're using lumen and you bring in two directional lights. So working with lighting in detail, you can see here that with that ability to be able to tell it to affect your atmosphere, you can control a"},{"start":"7:53","end":"8:24","startSec":473.4,"text":"few things such as cast shadows on clouds, whether it's going to be atmospheric sunlight enabled. You can control the atmosphere sunlight index, the cast shadows on the atmosphere, the cast cloud shadows and cloud scattering luminance scale. All these things are really helpful if you need to edit things after the fact, after you bring things in. So lights also have the ability for you to isolate them for influence via"},{"start":"8:24","end":"8:55","startSec":504.4,"text":"channels. Let me demonstrate that briefly and then we'll get back to the slides again. See with this particular light, we want to control exactly his influence on the environment. So to be able to do that again, like I said, you can use the thing called channels. So I can type in and look for channels or you can search in under advanced and you can find the channels for this object. You can see it here or for this light. And the same thing there. The objects also have channels too. So if I typed in channels here, you'll see that there"},{"start":"8:55","end":"9:31","startSec":535.4,"text":"is make sure you get the right piece of geometry. There we go. We'll just pick up this guy because he's bigger. This one's a clump and combination of objects. So you can see here we have channels also active. So let's go to that spotlight for a moment and we're going to tell it to not affect the world, but to affect maybe channel one. And then I can go to the object next to it and I can say he's not affected by the world, but also channel one. So when I move him near the other light or the spotlight, we are now getting them"},{"start":"9:31","end":"10:04","startSec":571.4,"text":"both to interact with each other. And you can see that they're not affected by the lights around that around him, but he is affected by this one because they're both on the same channel. So that actually works with limit two as well as baking. So working with lights in detail, we demonstrated this in some of the other classes where we can actually are in our first class. We can actually change the shape of this light and you can do that several different ways. So each light has the ability to be able to change the same the shape as"},{"start":"10:04","end":"10:34","startSec":604.5,"text":"well as the influence on reflective surfaces. You'll see a thing called soft source radius. So the soft source radius allows you to blur out any shapes that may come in, particularly with this point light. So we'll talk about this in just a second, just a quick review because we did talk about this already and a quick review when it comes to rec lights, because rec lights are pretty handy with that. So in our scene, if I bring in just a simple point light in here, we have"},{"start":"10:34","end":"11:06","startSec":634.5,"text":"several different things that we can choose from. And when it comes to this, we can actually control our source radius. This can soften a bit of our shadows. Now you got to be careful when it comes to baking. This can actually get pixelated in your environment and it can a little bit too with lumen, but mostly here when it comes to baking. So just keep that in mind. If you change those things, we also have source soft source radius, which I just mentioned earlier, which will make it so that any reflectivity in the shape, say there's a"},{"start":"11:06","end":"11:37","startSec":666.5,"text":"circular hot spot that's showing up somewhere. I don't really have shiny objects here that we actually can soften that up. And we probably can see it if we bring it over here to this space probe. Let's see if it's going to show up here. He's not too reflective, but he is a little bit. So that soft source radius, we can, you can see it shift a little bit. If you look, the highlights become less sharp. The lower it's sharper, the higher it's softer. So you can actually"},{"start":"11:37","end":"12:11","startSec":697.5,"text":"mask or hide that hot spot coming in the reflectivity. And then we also have source length. And we talked about this before in another class. You can make some tube lighting. You'll notice if we brought in a spotlight into our scene, the spotlight will give us the ability to be able to go in here and work like a typical spotlight. We can control your cone angle, outer cone angle, your inner cone angle. So you get kind of the typical stuff to be able to mess with. Now your source radius again, you can soften up your shadows as you mess with"},{"start":"12:11","end":"12:44","startSec":731.6,"text":"this, but be careful not to push things too far. Rec light again is one of my favorite ones to work with because he has full control when it comes to working with the, the source width and the source heights and the barn door angle. Now be careful with this too, because he is the most expensive, but he is fantastic for fill light information that you're bringing into your scene. It's really great to work with. You can also bring in a source texture if you need to, but we currently don't have it where you can hide that shape. So hopefully later on"},{"start":"12:44","end":"13:14","startSec":764.6,"text":"we'll be able to evolve in that area. There is a thing called sun in sky. So I'm going to briefly demonstrate this for a second. I'm going to do a new level for a second here and we'll just do empty level. Now I'm not going to go through all the steps with this, but I want to show you what this can do. Your sun in sky, when you bring it in, it gives you immediately a quick lit area, but with the ability to have a compass in this compass, you can control longitude, latitude,"},{"start":"13:14","end":"13:47","startSec":794.6,"text":"longitude in time zone, which is really nice if you need that really quickly. You still want to add a few more things like you could easily just go in here and say, Hey, I'm going to go to my environment light mixer. I want to add volume at your cloud and hide fog. So you can add a couple more things if you need to. Oh, that's really blown out, right? So definitely we can adjust the settings here, but I wanted to show you that you can pair this up with the other tools you have for your environment. But this compass is fantastic to be able to work with because that compass allows us to go in here and he got a little blown out. We"},{"start":"13:47","end":"14:21","startSec":827.6,"text":"couldn't see him anymore. This allows us to go in here and to control some of these things such as time of day, the year, and et cetera. Pretty cool. I do want to mention also with the spotlight, let's pull that spotlight in for a second. I'm going to pull this up. This spotlight also can connect and you'll notice is if you scroll down, if you're curious enough, you may have spotted this. There is an IES profile you can put in here for light profiles. You can put in an IES texture I should say. And in here we can choose what kind of IES"},{"start":"14:21","end":"14:51","startSec":861.6,"text":"texture we want. And this actually is used quite a bit for architectural purposes. But let me boost up the light here so you can see there's a lot of light in here. So it's kind of blowing things out. But you can see the different types of shapes you can get out of this, which is pretty cool. So we can do like 90 degrees. We can do it. You can attach this in a game scenario. You can make this go to like a flashlight or spotlight. Maybe you're looking for someone and you can really see it here with this particular one. You kind of that"},{"start":"14:51","end":"15:23","startSec":891.7,"text":"spotlight flashlight kind of look how the lights passing through the glass of that particular light set up here. And it's pretty cool. So you can add those which can be pretty helpful. And you can use this also with Lumen too, as well as in a bake scenario. Now when you're using baking, you do want to make sure that you're using an ambient occlusion set up here. And this allows you to be able to add it in your project. So you can actually have it in there. And it's kind of our almost like a screen space ambient occlusion in our scene and makes things"},{"start":"15:23","end":"15:54","startSec":923.7,"text":"a little bit easier for you to work with. Now you don't want to turn that you don't want to have that on for your static lighting, especially when it comes to Lumen. But in a baking scenario, it's a good idea to play with that, tweak it and put it on. And you can also have it within your post process volume as a little help for pushing your visuals. Well, that's it for this one. And the next one In the next class, we're going to talk about light mass and light maps and a bit more detail. We did cover it a little bit here, but we're going to get a little bit"},{"start":"15:54","end":"15:58","startSec":954.7,"text":"more detailed. And then we're going to move on to some other really cool topics."}],"05_Lightmaps and Lightmap UVs":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"In this lesson, we're going to talk about light mass and light maps. So let's get started. So again, we're in the baking scenario here if you were to use it. Now again, sometimes you may use it, sometimes you may not, but mostly Lumen does a really good job. But say you didn't want some of the noise that came with Lumen, you can definitely take this approach for certain shots or for a particular game if you wanted to. It's still fully supported. Now how it works is, and I notice I have here it says kicking it old school, is kind of"},{"start":"0:33","end":"1:04","startSec":33.2,"text":"our offline GI renderer. Its performance cost is virtually zero at runtime. The building process gets longer as your scene becomes more complex. So you have to keep that in mind. And also that your shadows won't be as realistic as they would using virtual shadow maps. Because as we talked about in the first class, your shadows, the visual fidelity of those shadows are determining on how close distance you are to that object and puts it in a cache and it will call upon it when needed."},{"start":"1:04","end":"1:36","startSec":64.6,"text":"Unfortunately, when it comes to light mass, when it builds your shadows, it's going to be kind of an all or nothing scenario where it's going to bake it and they're all going to share space on a particular type of texture map that's actually put into our scene and almost like a blanket specifically for static objects. So you can adjust light mass settings at the actor level or more globally in the world settings panel. And we're going to talk about this in just a second. And again, you can see the options here where it says shadow maps and virtual shadow maps."},{"start":"1:36","end":"2:06","startSec":96.1,"text":"Again, virtual shadow maps for Lumen, shadow maps for baked lighting. I do want to make a note here on the bottom here. It says Nanite is made for Lumen and not really for Unreal light mass baking. You can use it, but you could slow things down if your geometry is really complicated. So make sure you turn Nanite off when baking and that you are using shadow maps for baking or you will crash or take forever to bake non-Nanite. Just keep that in mind."},{"start":"2:06","end":"2:36","startSec":126.3,"text":"GPU light baking can be used if Nanite is needed. Now also want to make the statement here. If you have non-Nanite objects and they're in your scene, you're using Lumen, it's better to try to keep that within Lumen. Keep it Nanite if you can. And using virtual shadow maps. It's like the three Musketeers, which I kind of mentioned in the first class. Lumen, Nanite and virtual shadow maps all play nice together and it's best to work in those"},{"start":"2:36","end":"3:10","startSec":156.5,"text":"scenarios. So let's look at some settings in light mass that can get you started in the right direction. Now this is found under the world settings. Let me point you in the right direction. Then we're going to go back to the slide. So in Unreal you go to your world settings and again you'll see where we have our light mass settings here. And there are several different things and several approaches you can take. But in the beginning I have to really emphasize start low and then go high."},{"start":"3:10","end":"3:40","startSec":190.2,"text":"Some people when they are working with baking will crank all these up really high at first and throw everything at it. But Unreal you want to be very deterministic because you're working in a real time setting. The same goes with Lumen. So always start low then go high and test your settings, your computer, what it can handle as you go and also in relation to your scene. Let's go back to the slides and look at some of these settings that I have pointed out for you. So you'll see initially we have static lighting level scale set to one."},{"start":"3:40","end":"4:13","startSec":220.5,"text":"This is your light mass detail. We also have number of indirect sky bounces, three to ten, and it actually helps handle scene brightness. We have indirect lighting quality, one to four. This increases your final gather rate count and reduces artifacts that may occur. You also have indirect lighting smoothness. You have a one to a 1.3. This blurs indirect lighting results, reducing noise. So that can be very helpful. We also have compressed light maps. You want to disable this if you want a bit more realism in your scene."},{"start":"4:13","end":"4:47","startSec":253.8,"text":"You'll see in my example here that it has it checked on. But try to turn that off if you're going to be using a baking scenario to get a bit better with your shadows so that they don't look, I guess the best way to put it is they look very edgy. They look very almost like a video, an old Atari video game. So you start to get like those blocky edges. We don't want that. We want a smooth transition into our shadows if we're using baking. So you also want to have, which I mentioned earlier, is a light mass importance volume."},{"start":"4:47","end":"5:18","startSec":287.2,"text":"This is very important to put into your scene, particularly if you're going to have a terrain. This allows Unreal to know what your priority area is and what you're focusing on when you decide to do rendering. So the volume that focuses the detail in direct lighting, photons coming from the light mass. Use it to determine the area of gameplay or area of importance. This is very important for your visuals. It is a detailed GI. It restricts that area."},{"start":"5:18","end":"5:53","startSec":318.2,"text":"So it's honoring your settings and the area outside of the importance volume will only get the low quality GI once bounce. So you're making it so that it's honoring what you've put in and you're telling Unreal, Hey, prioritize this and use my settings that I have in place. So light map UVs, why are they important? So when it comes to baking, these UVs allow Unreal to place self shadowing on this object and also shadow relationships to other objects in the scene, particularly if they are static."},{"start":"5:54","end":"6:28","startSec":354.7,"text":"Now, self shadowing still does occur for objects that are being lit, say they're moving. Things are being lit by stationary light because a stationary light is made to be able to handle moving objects, but there's only four overlapping at a time, which I mentioned earlier. So to create believable self shadowing is why they're in place and object casted shadows. It can be important so you can make your own UV light maps. You can make a secondary copy your UVs in a your DCC and you can make one with proper"},{"start":"6:29","end":"7:00","startSec":389.3,"text":"padding and put it in there as a secondary UV channel and Unreal will recognize that. And you can also tell Unreal to look at that if there's a problem with that. You want to make sure if you do do that, there's no overlapping, there's adequate padding, and you also hide those seams. It also can be auto-generated by Unreal, and I've never really had a problem with it auto-generated. It does a really good job, but there may be times where you specifically, if you are using baking, you want to make your own UVs because you want the shadows to look really good on this"},{"start":"7:00","end":"7:30","startSec":420.8,"text":"hero object and you want to make sure that it's you're in full control. But again, we have a solution for this. This is a heavy workflow. You can use lumen. The only thing with lumen is you need to watch out for the noise that may occur. So light map UVs made with two light sources. You can see some samples here. Light is baked to a light map texture and you'll see it bakes it in almost like I said before, like an AO occlusion is self shadowing. It's baked right into the texture."},{"start":"7:31","end":"8:05","startSec":451.4,"text":"The base color texture here, light map is multiplied on top of that base texture. So you can kind of see the logic and the process of what Unreal does. The end result relies entirely on a texture for displaying lighting. So again, we talked about solver quality. So don't forget about this. When you're working initially in your scene, you may want preview and you might want to try medium or high, but production is going to give you the best results of the bounces that you need and want. Here's a link for more additional resources on light mass and global illumination."},{"start":"8:06","end":"8:25","startSec":487.0,"text":"That's it with this one. In the next video, we're going to talk about reflection baking, how to work with these reflection probes and assets that we have in Unreal to be able to get things in the right direction. Thanks again. ."}],"06_ReflectionsBaking":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"In this lesson, we're going to take a look at reflections when it comes to baking. So let's get started. So first, we want to talk about when to use them. So reflections are to be used with primary reflective surfaces, giving them the illusion of believable reflective materials and substances. If they aren't used, Unreal will use screen space reflection as a default. And that's not always the best way to represent your visuals, especially when you're baking. So using the reflection capture elements creates a more detailed, believable reflection."},{"start":"0:30","end":"1:02","startSec":30.2,"text":"And you can find them under Modes, Visual Effects. The types that can be used are as follows. We have screen space by default, spherical reflections, box reflections, and planar reflections. I'll walk you through some of these and I'll bring one into Unreal briefly and we'll get back to the slides so you can see how they work. So to be able to call them up, we can simply type in here under Place Actors, the reflection"},{"start":"1:02","end":"1:34","startSec":62.4,"text":"here, and you'll see we have box reflection, planar reflection, and sphere reflection capture. Now sphere for things that are a bit more rounded or more organic, box for obviously things a little bit more box in size and shape, and then, or I should say, this is planar, box on the top for the size and shape, planar for things if you like have your body of water or things that you really need the reflection to be realistic."},{"start":"1:34","end":"2:06","startSec":94.3,"text":"And again, this is a baking scenario and is not needed with Lumen. Lumen has its own reflectivity properties. It borrows from ray tracing, but in it, it also has a boost where it's actually using global illumination in its reflectivity. So it's actually pretty great to be able to see that. Now in here, you can also type in here under Get Content. You can type reflection, and you'll see those same ones come in. You can see here I have a sphere here, reflection capture."},{"start":"2:06","end":"2:34","startSec":126.8,"text":"Now this one, I can control its influence radius. So if I need to make it bigger or smaller, it actually can help. And you'll see those highlights show up on that rock at the distance, and it shift on the sphere itself. So this is really up to you how you place it. And as you place it, Unreal will try to update initially. And as it does, then you want to make sure that you're running another reflection capture build right here."},{"start":"2:38","end":"3:09","startSec":158.1,"text":"So let's go back to the slides. So note again, reflection captures are used for baking and are not necessary for ray tracing, but I do highly recommend them because they can help. So if you do use ray tracing, which we'll go over in another class, ray tracing has real-time reflections with no rebaking needed, but a hybrid of both can be used to help performance. And visuals, I should add. So when you use a reflection capture, you can actually tell ray tracing to lean on them,"},{"start":"3:09","end":"3:41","startSec":189.3,"text":"like be able to borrow some of that. Now again, we go into that CVAR in detail and that breakdown in another course talking about ray tracing, but I just wanted to point that out. So screen space reflections can also be controlled in the post-process volume. There you can control the intensity, the quality, and the roughness. But keep in mind, it's based on the positioning of your camera. So if I move my camera around, that screen space could warp and distort. And obviously, it's not going to give me fully accurate"},{"start":"3:41","end":"4:12","startSec":221.8,"text":"reflections. So the sphere reflection and box reflections, again, we can control the radius of that. But you can also load a cube map if you need to by changing the reflection source type. This is really up to you. You can also control brightness as well as the angle. So this depends if you're loading a source in there. So you can't load your own if you have a cube map that you want to load and you want that reflection to represent that. So another way to be able to adjust your reflections"},{"start":"4:12","end":"4:43","startSec":252.9,"text":"is if you use in the baking method, Unreal 4 as well as Unreal 5 supports the planar reflections. So planar reflections are expensive, keep in mind. And some of your effects may not show up in it. So if you're using older Cascade or Niagara, they may not show up in the reflection. But it does give you accurate reflections. It's just kind of a good way to do it. So if you're using a real-time camera, it's just kind of expensive. Again, when you can to try to use Lumen. And this is a fallback if you needed"},{"start":"4:43","end":"5:13","startSec":283.5,"text":"to use it for a particular shot or necessary part of a lower end game and you're noticing that the Lumen isn't quite what you're looking for. So these are just informative areas that you can think of that you can add to your scene if you had to use baking. So just keep these things in mind. Be very deterministic and don't rule out Lumen. But this is also, I want to put this in your screen. So if you're using a camera, you can use the Lumen as a secondary to be able to have an option"},{"start":"5:13","end":"5:43","startSec":313.9,"text":"if you need to. So again, we have scenarios for it. Using the sphere for more spherical or rounded surfaces. You can get away with using it for hard flat surfaces that are more box-shaped. But you have to make sure that the spherical reflection is pretty close to the point of interest. So if you're using a camera, you can use the Lumen as a secondary to have an option to have a more spherical reflection. And start to break down to become a spherical type"},{"start":"5:43","end":"6:15","startSec":343.9,"text":"of reflection or warping. And we want to avoid that. You do have building quality, which we mentioned in the earlier part of the course, where you can control reflection capture resolution. So if you're going to use them, try to keep them relatively high if you can. We lower those a bit. But 2048 and 1024 is good for more PC games, centric, or maybe even final pixel. But definitely can support ray tracing better to have a higher quality."},{"start":"6:15","end":"6:42","startSec":375.4,"text":"Tips and tricks here. Reflections are used for light baking. Again, not calculated in a ray-traced scenario because you don't have to rebuild them. But it can add some detail and give a little optical illusion to it. It actually is a fallback. You can think of it that way for ray tracing. Uses that data that that spherical reflection capture comes into play and allows you to get a better quality and bounce in your reflectivity."},{"start":"6:45","end":"7:06","startSec":406.0,"text":"You'll see here a few more tips. And again, keep your resolution high, especially if you're making your own. Here's another link that gives you a little bit more in depth than that if you dive into it. And that's about it with this course. In the next course, we'll look at view modes and visualizers when it comes to Unreal and analyzing your scene."}],"07_ViewModesandVisualizers":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"In this lesson, we're going to take a look at view modes and visualizers. So let's get started. One of them you can look at underneath optimization view modes. You'll find that underneath our show. And in there you'll see light complexity. Light complexity will let us know if our lights are movable, stationary, or static and cover them associated to their complexity. Overlapping movable lights are the most expensive to work with. You can resize the radius will help when it comes to stationary lights and them overlapping"},{"start":"0:34","end":"1:07","startSec":34.8,"text":"each other because you can only do four overlapping at a time when it comes to baking. Static lights are basically free. They're really cheap to work with. And so you can put as many as necessary. But also keep in mind your geometry and how long things are going to take to bake. Let's go and take a look at that up close and unreal. And I'll bring up a few points that are also known in lumen. So in our scene here, we can quickly check here what it looks like for a light complexity."},{"start":"1:07","end":"1:41","startSec":67.9,"text":"So I'm going to go under lit here. And we're going to go down, not show. If I said show, please excuse me. We want to do lit. So under lit, we want to go in here and we want to take a look at our optimization view modes. And there you'll see light complexity. This shows us where the complexity of our light is at. And we see one light here, which is stationary, has quite a few areas here that it's taken into account that are kind of expensive. Now some of the geometry is coming in black because it's using a level instance to be"},{"start":"1:41","end":"2:14","startSec":101.2,"text":"able to build it. But you can see these lights. Here's another one here, also stationary, how they affect each other as I move them around. These stationaries show me where the overlap is happening with another stationary light, case in point, this rec light. So if I have more than four overlapping, and I'll demonstrate over here in this green area. If I go to say my point light, I'm pulling one and I'll pull in two and I pull in three. And then if I pull in a fourth one, you'll see that one of them has an X going on."},{"start":"2:15","end":"2:50","startSec":136.0,"text":"not really doing and pulling the weight like he's supposed to. He's not quite working like he should as a stationary light. He's more moved into movable just for this to be more manageable because these four overlapping plus we have a directional light in place. So we've kind of hit our limit. So these three are being counted plus our directional light. So what we can do to remedy that is one, if again, this is a baking scenario, I can lower the the attenuation or I can move it out of an area of influence."},{"start":"2:50","end":"3:22","startSec":170.8,"text":"And when you do, you'll actually see the X go away. This guy's going to stick around for a bit because we have quite a bit of lights in here, two directional lights, several wrecks, as well as as well as a few others in here. So that's something to consider. But this will tell you the complexity of it all. Another mode we have is called light map density. Let's take a look at that up close and some things to keep in mind when working with this."},{"start":"3:22","end":"3:55","startSec":202.5,"text":"So let me go ahead and remove these lights that we just created. Don't need them. And you'll see the colors change as I get rid of them. Red is very high. White is really high. And green, as you can tell, is pretty light on the importance or complexity scale. So let's go from optimization view modes here. And we're going to go to our light map density. Now the light map density shows me how my settings are set for each one of these pieces"},{"start":"3:55","end":"4:28","startSec":235.3,"text":"of geometry. So let's pick something that's not merged or in a level instance, something that's a little more singular. So I'm going to grab this here and I'm going to scroll to the area where it shows us where a light map information is at. Now for some reason you can't find it. You'll find it right underneath the lighting and you can also do a search for light map and you'll see the resolution set here. You can see this is pretty low. And I'm fortunate enough that I'm not getting any blobby shadows. But if I was, I might want to increase this to be the same light map resolution as the"},{"start":"4:28","end":"4:59","startSec":268.3,"text":"ground. We're fortunate enough because both of these, even though this is a smaller item, have the same light map resolution. So we're doing okay. But if for some reason this is really high resolution. Let's say the arch is set to like, I don't know, we have like, I shouldn't say really high, but you know, you don't want to go too high with these. You want to keep it reasonable. So say this is like a one, a 512. It's a real little, little over the top. It could be one, one, 28. Okay. But it's a five, so it's really getting close on click really good."},{"start":"4:59","end":"5:31","startSec":299.2,"text":"But then down on the ground, it's only, it's left at 64. As soon as this object hits this area and they connect with each other, I could get a blobby shadow just because it, Unreal's trying to bake that light map on there. And it is trying to evaluate the difference between these two resolutions for that light map. So just keep those things in mind if you are baking that those might be an issue. In this previous scene, let's take a brief look again at some of the visualizers like"},{"start":"5:31","end":"6:02","startSec":331.5,"text":"we talked about in the first class when it comes to Lumen. So we have lit here and over here we have Nanite visualization. So if I do an overview, I've now converted, I right clicked in the content browser and I converted all of these chairs into a Nanite object. So you can view that ahead of time if you want to. So we can say, hey, let's look at our Nanite visualization. Now you can look at mass, the triangles, how they're clustered together, what's going on"},{"start":"6:02","end":"6:34","startSec":362.2,"text":"with the primitives, how the calculations working, instances of those objects, the overdraw that might occur if it's really high detail, material ID that's involved, UV, light map, UV going on, so if you are using that, and evaluate world position offset. So all these things can be listed within the overview. So if I click on overview, you'll see that each one of these are in each different category. This is the nice thing about overview, you can just pick and look at what you need. In this case, we'll focus on the triangles."},{"start":"6:34","end":"7:04","startSec":394.4,"text":"So if I move around, you'll notice in some instances, and in this case, the chair is really simple, but if let's go and switch the triangles here, you will see those triangles flip and recalculate based on distance of the camera from the object. So I'll go to triangles here for the whole thing. And in this case, since these chairs are super simple, you're not going to see it as much, but you would see it on high resolutions, scanned rock objects, you'll see those triangles shift according to the distance we are to the object."},{"start":"7:04","end":"7:36","startSec":424.4,"text":"And you may see a little bit of it. You see the top of the chairs kind of shift a little bit. That is unreal trying to give us the best possible geometry based on distance using Nanite, and Nanite is a lot more efficient because it gives you a higher resolution at lower cost when it comes to your geometry. So it's pretty cool to be able to see that ahead of time. We also talked about in the first class, the lumen overview, which shows our geometry normals, our reflection view with our hardware ray tracing involved here, lumen pink missing"},{"start":"7:36","end":"8:07","startSec":456.1,"text":"surface catch coverage. So it tells you where the errors or situations you might have or issues you may have in your scene. So it's actually pretty cool to be able to take a look at that really quick. We also have our virtual shadow maps. So in here we can look at the shadow mask. It shows you how things are being amassed into our scene, almost as if you're seeing a real time update bake. But in this case, when it comes to virtual shadow maps, they are updating on the fly and they're actually not picked at all."},{"start":"8:07","end":"8:37","startSec":487.5,"text":"We have a clip map level. You could see it sorting and popping in as we go through here and you can see that it's working and doing and digesting things based on location. Next we have virtual page. Again, this works kind of like we saw with the Nanite. So you can see it bring in what we need based on our positioning and it's trying to sort through the data and the objects in the scene and where our light is positioned."},{"start":"8:37","end":"9:11","startSec":517.6,"text":"We also have the catch page, which simply is showing us how things are being catched and called upon. Going back to the topic of light mass and volumetric light maps. Light maps, light mass in this case, creates a volumetric area in which objects can be calculated. Again, this is a baking scenario. These volumetric light maps allow objects to be calculated in the shadows to update"},{"start":"9:11","end":"9:47","startSec":551.4,"text":"for stationary lights. You can actually see this ahead of time in a baking scenario. Let me show you what I mean. So in Unreal, I can go in here and I can show, take a look at these components here. Now at any time you can choose, I'll just briefly talk about this. You can see Lumen and Nanite have some extra areas to be able to visualize things. You'll see an overall visualizer. We can add some more advanced stuff. So don't get confused. It's easy to get lost with this, but we're going to focus mainly on showing where that"},{"start":"9:47","end":"10:20","startSec":587.5,"text":"light mass mapping is happening. So let's go back over there. We're going to visualize. I'm going to go to that light map area. Volumetric light map right there. And it shows you the calculations. It shows you all of this. These spheres are points of calculation in here in our world so that our shadows can"},{"start":"10:20","end":"10:53","startSec":620.2,"text":"correctly update and work according to our geometry and our objects in our scene. Pretty cool. Now you can increase that resolution if you want to. I like to use it. I think at default it works pretty darn well, but you'll see down here, there's a detailed cell size. As you increase that, you can increase some of the quality. But it also is going to require a bit more brick memory. You can also increase that if needed. You can smooth things out if you need to. Again, this is the volumetric light map."},{"start":"10:53","end":"11:25","startSec":653.2,"text":"This again helps with our characters and how they're working in our world and how those shadows are being established. Let's look at some tips and tricks real quick here for light mass. So indirect quality lighting doesn't work on preview quality presets. You want to make sure that if you want to get exactly what you planned and you want to get the highest resolution for your bake, and you want to make sure you have a good representation of what you've chosen, you really do want to make sure you have it on"},{"start":"11:25","end":"11:56","startSec":685.2,"text":"production. But you can start off low and do preview and medium and high, but eventually find yourself at production if you're noticing you're missing some of the details that you know you put in there, such as increasing your indirect lighting quality and so forth. So ways to improve and optimize light baking, better UVs for light maps, override light map resolution per object. So your hero objects will have a higher resolution. Optimization view modes, check things with that, show light components, and compressed"},{"start":"11:56","end":"12:30","startSec":716.9,"text":"light maps are set to off. Now briefly, I want to go back to view modes for a second because I want to point out one more thing. So in Unreal, underneath our optimization view modes, you'll notice there's also the overlap which we talked about, but there's also shader complexity, as well as shader complexity, quads and quad overdraw. Quad overdraw will show us exactly where our density is at in our scene and where things"},{"start":"12:30","end":"13:04","startSec":750.2,"text":"might be getting pulled a bit stronger with our memory. In this case, this isn't too bad because we still have our spheres, which are a little bit dense. And back here, we could definitely merge these. We go over that in our optimization course. But you'll notice we're doing pretty well. As soon as we introduce trees or other items, we definitely want to look at maybe switching to lumen and then also switching those larger, higher poly objects to nanite. Here I have a screen showing some ways in which you can better get better results using"},{"start":"13:04","end":"13:35","startSec":784.9,"text":"light baking, such as number of indirect lighting bounces. You'll see there's five here and we'll also see the indirect lighting quality set to 20 and indirect lighting. So this is point zero point five. And you get some really nice stuff going on here. Now, the more you increase your bounces, keep in mind, you may not see a difference if you go past like 10 because the eye is not going to pick up those bounce upon another bounce upon another bounce. So it'll be very minute changes."},{"start":"13:37","end":"14:10","startSec":817.5,"text":"You can also make a static object glow. So if you have like some simple lights in a city scene, you can actually bake that in there. If you wanted to, you could even do that for on the real cheap, bake it ahead of time and still use lumen if you are afraid of noise and the objects, you know, are static, such as maybe a car and a neon light that would actually work pretty well. But just keep in mind, if your characters walk in front of that bake, they're not going to get that light. So just be aware of it."},{"start":"14:11","end":"14:19","startSec":851.5,"text":"Here's a link here diving deeper into those topics that we talked about in the next lesson. We're going to take a look at screen space GI. Thanks again."}],"08_Screen Space GI":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this lesson, we're going to take a look at screen space global illumination and how that works. So let's get started. So using screen space global illumination, keep in mind that it is beta. It's been there for a bit. It allows us to have a really quick on screen global illumination solution. Now if you are using it with baked lighting, because you can use it outside of baked lighting, and we go into that in other classes, but in this particular case, we'll talk a little bit more focused on the baked lighting side."},{"start":"0:31","end":"1:02","startSec":31.0,"text":"You want to make sure when you are using it with baked lighting that you have your baked lighting already set in because it is complementary. It doesn't replace it, but it is complementary in that particular scenario. It can also be turned on in your post process volume, which I'll show you in just a second. In your indirect lighting, strength can also be controlled too. So let me show you what I mean. So in Unreal, we already have things pre-baked out here, and we're using screen space global illumination."},{"start":"1:02","end":"1:34","startSec":62.5,"text":"And again, what I mean by you being able to turn this on in two different places, if we go to our edit project settings and we go back under rendering, when I showed you previously to edit things for baking or for lumen. Let's go there. We went too far. Let's go back up. So we go down here. You can see we're in screen space global illumination under dynamic global illumination method. And we're using shadow maps because this is more of the baked scenario."},{"start":"1:34","end":"2:04","startSec":94.6,"text":"And again, this is the old school way to do things with Unreal. And you can use screen space global illumination when it comes to lumen. You can mix things up. Let's actually talk about that post process ability to mix things up here. So I'm going to go and type in post process volume. Let's go and call that up. And we can scroll down and see what our global illumination method is. Now in our project settings, we know they're already set, but we can override things here. So I can set this to screen space global illumination."},{"start":"2:04","end":"2:35","startSec":124.6,"text":"You saw a momentary error there because Unreal's all, there's no way you can do this for you because we don't have the settings for lumen. But now we're in screen space here. In screen space, we can actually control how things or the strength of things are when it comes to global illumination. And what I mean by that is we can actually adjust that indirect lighting. Let me show you how that works. You'll see under advanced, we can click on this and we can control indirect lighting"},{"start":"2:35","end":"3:07","startSec":155.9,"text":"intensity. See that? So we're actually controlling how that light is being bounced around and the strength of it in our environment. We can also adjust a color if we need a particular color. This is really great to be able to have this option in here. Now this is in a baked scenario. You can also use this in lumen as well as with ray tracing. But when you do that, you have to make sure you know exactly where your settings are at. So case in point, if I'm using screen space global illumination in my GI, am I using it"},{"start":"3:07","end":"3:38","startSec":187.8,"text":"in my reflections? Well, if we had it to ray trace, we could use ray trace reflections and still use screen space global illumination. We could use lumen global illumination, and I'm not sure why you would, but you could use screen space reflections. All these things are adaptable, but you have to remember where things are at. So I like to keep things either lumen or not lumen. But if I'm in ray tracing, maybe something might be expensive, I can easily switch my global illumination instead of ray tracing GI, go to screen space."},{"start":"3:38","end":"4:13","startSec":218.4,"text":"You can see ray tracing GI down below. And it does say deprecated, but don't let that fool you. In our next class, we talk about ray tracing. In our next advanced classes, I should say, we talk about it. We talk about the ins and outs of this. Now this is going to be around for a bit, but some of these things are actually already incorporated with lumen, hence the name deprecated. So it's still going to be around, so don't think that it's going to disappear just yet. So the nice thing about using this is you can actually see these items glowing on screen."},{"start":"4:13","end":"4:45","startSec":253.8,"text":"Now the disadvantage you run into is when using screen space, as you turn your camera, you can lose some of the stuff that it may be affected. Now I'm fooling the eye here. I'm actually using a rec light to make it look like there's a little bit more glowing going on, but that anything like a glowing material, such as this little green area, there can be some clipping occurring. Today, Unreal's working like a champ and no clippings happening, but if I turned my camera past a certain point, I would actually get some clipping and that would disappear."},{"start":"4:45","end":"5:18","startSec":285.3,"text":"So just be aware of that if you have glowing objects and you want them to, say, relate to other objects, and we can cheat a little bit here. And I'll get a simple piece of geometry in here. Pull it up to that green area. Maybe we can see that effect. We'll get really close to see if that green light. There may be too many lights in here for this to actually give off any reasonable reaction. You would see things clipping go away as I turn my camera here."},{"start":"5:18","end":"5:55","startSec":318.6,"text":"You can see a little bit of that there. See that geometry that has bounced light disappear here off the orb right around this part on the very rim of the geometry. You'll actually see that disappear. And that's what I mean. Some of those, as you turn your camera, will go away. You would have to use over scan if you're using ICV effects. If you were to use this effect, you would have to do it within your NDC properties, your camera properties, to be able to compensate for that. So just keep those things in mind. Note, the effect can also be used for interiors and interiors and the objects can be animated,"},{"start":"5:55","end":"6:27","startSec":355.3,"text":"but do be careful of how that clipping happens. So just be aware of it. It can be tricky. You'll also see we have reflection capture resolution. We also have reflection screen space. You can actually use also screen space for your reflections, but it's not as accurate. So you may want to mix and match if you can. Just be aware of that. There can be some banding going on, obscure type of looks and feels for things."},{"start":"6:27","end":"7:00","startSec":387.6,"text":"So again, limitations. Screen space is based on your camera and 3D space, like we mentioned. You'll notice clipping, which I demonstrated. Also when you're using it, you need to have some sort of baked data in place if you're using it with baked data. It was created to complement baking in place and not replace it. You can use it with ray tracing if you wish, and you can use it. And again, I wouldn't really recommend it, but you could if you wanted to, saying Lumen is giving you too much noise. You can turn off Lumen GI and switch the screen space with some Lumen reflectivity in some"},{"start":"7:00","end":"7:32","startSec":420.6,"text":"areas. You can do that. Just be aware of how things are placed in the scene, because the more you stack things up, the more you mix and match. There could be other conditions and situations happening with your material, with your lighting, with your reflectivity. Just make sure you're managing how things go and understanding the limitations for all of these. That's about it with this course. Here's a link to get you deeper into the subject and understand the material better. In the next course, we're going to take a look at GPU lightmass and we'll do a quick"},{"start":"7:32","end":"7:35","startSec":452.7,"text":"overview on how that works. Thanks again."}],"09_GPU_LightMass":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this lesson, we're going to take a look at GPU lightmass and take an overview on how it works. So let's get started. So the first thing we're going to ask, you're probably going to ask is what exactly is this? Well this is using a light baking system, but we're going to be leaning on our GPU to be able to build. We're not going to be using the CPU based lightmass system, so it improves upon that. It leverages DirectX 12 DXR ray tracing capabilities to speed things up. It significantly reduces the time it takes to build a complex scene."},{"start":"0:31","end":"1:05","startSec":31.6,"text":"It achieves speeds on a single host comparable to distributed swarm render, which we saw that earlier where you can actually use a swarm agent. It makes it so that we're leaning on the GPU versus the CPU to be able to do so. So it's using a progressive lightmapper with optional real-time preview in the viewport. So you can actually see it going on. You want to make sure your virtual texturing is on if you want to be able to see this display correctly. Offering multiple modes for building lighting, full bake and bake what you see, significantly"},{"start":"1:05","end":"1:35","startSec":65.0,"text":"increases the speed of lightbakes for complex scenes, producing a more physically accurate result than CPU based lightmass. Let's go ahead and take a look at this up close and we're going to convert a lumen scene into a GPU lightmass bake scene and I'll show you some of the ins and outs and things you have to look out for. So let's go and jump into Unreal. In my Unreal scene, I'm going to go ahead and open up my project settings. In here, we want to make sure we turn on allow static lighting."},{"start":"1:35","end":"2:09","startSec":95.3,"text":"We turned that off before, but we're going to turn that on now. We want to go into rendering and then convert everything to a non-lumen scenario. What does that mean? Well, I'm changing my dynamic global illumination method to screen space. That way when we bake, we might, we should be able to actually get some, a little bit of glow for those lamps in our scene and kind of capture some of that lumen realism. Still going to be at a disadvantage as you can already see the preview shadows here are kind of blobby, but once we do a bake on full production, we'll get pretty close, although"},{"start":"2:09","end":"2:41","startSec":129.2,"text":"we will not get the real time update we would get with lumen as we move the light around because our light has changed mobility too. It needs to be changed to stationary versus movable. So once we set all this reflection method to screen space, as well as our shadow method to shadow maps, we also want to make sure in our post-process volume, once we've got all this down, and again, you want to be under rendering, changing it from lumen to a screen"},{"start":"2:41","end":"3:12","startSec":161.9,"text":"space, you want to go to our post-process volume and do the same. Change the global illumination method to screen space and change the reflection method to screen space. We're going to go ahead and restart. So once you've rebooted and you've also turned on allow static lighting and you also have ray tracing active, again, I do recommend, and I'm going to emphasize this, is you turn on virtual texturing for some support for your view port modes."},{"start":"3:12","end":"3:47","startSec":192.6,"text":"Now it may not be as dependent as it used to be to be able to have that on, but you will see some progress bars hopefully showing up in your scene to be able to see things as they go. Now it's really not necessary. It's just a fancy thing to be there, but you can also turn those off if you don't want those at any time. You can turn them off if you don't need them. I don't really care if they're on because I get the percentages at the bottom. It tells me how it's going and there's our build lighting. So let me walk you through some of these settings. Now you'll notice immediately there's quite a difference between this and Lumen."},{"start":"3:47","end":"4:21","startSec":227.8,"text":"We'll also notice though that the materials are handled a bit better though with baking, but we are getting that banding from screen space reflections. So there is a difference between a give or take between both of these. You also notice that there are some little bit of light leaking going on. So we have to again make sure that our lightmap resolution is to the level that we want for each item and also make sure that the floor is not paper thin. Now if it's paper thin and not thick, you can see it is paper thin."},{"start":"4:21","end":"4:52","startSec":261.7,"text":"That can be an issue sometimes where you will get some bleeding of shadows and light. So we would probably have to go back and rebuild this floor and make it thick like it actually is in the real world. These are things a lot of people don't consider when working and baking items. And it's also a good idea to have thick and actual geometry you can punch into when it comes to Lumen too. So overall it's just a very good practice to have. You'll see in the mode here we have a full bake or bake what you see."},{"start":"4:52","end":"5:23","startSec":292.0,"text":"This is beneficial. If you don't want to go through the whole system there, you can actually do partial. You can press your lightmap so we can actually turn this off and run this again. Right now that's one of the reasons we are getting a little bit of a blobby shadow or not as accurate as we had for Lumen. You can also have denoise on completion and you can turn that on or off if you want to. And the denoise are overall. There's a global illumination samples and says 512."},{"start":"5:23","end":"5:54","startSec":323.7,"text":"I always start at the default and then as I need I can increase things and you'll see there's a stationary shadow samples here, light shadow samples and you can increase that. Which is usually pretty decent, but again on a more macro level you can actually go to each one of these pieces of geometry and increase those light maps as you need them. So those keep those things in mind. And there's also use iridescent here. Make sure I say it correctly."},{"start":"5:54","end":"6:29","startSec":355.0,"text":"This is catching should be enabled with interior scenes to achieve more physically accurate GI intensities. So just keep those in mind. Now we're using screen space, but we all still getting a glowing material and that's a nice thing about working with screen space. You can give off a little bit of light. You'll see a little bit here, but you also see a change when I move my camera. So again, another reminder about the limitations with screen space. OK, so let's look at a few more things here. You'll see a quality multiplier so we can increase that if we need to for volumetric"},{"start":"6:29","end":"7:06","startSec":389.2,"text":"light map that helps with our moving characters with our volumetric environment detail cell size we can. So it's basically kind of a dumbed down. Think of it as a dumbed down version of our regular CPU light mass in our world settings. This is a kind of a dumbed down, easier to get to type of interface kind of gives you the meat of your control versus all the little ins and outs you actually can go straight to and then it'll favor the GPU. Now, GPU does not support certain things such as a light mass portal."},{"start":"7:06","end":"7:40","startSec":426.2,"text":"So if we created a light mass portal and put it here in front of the window so we have a difference between the light area of the outside and the darker area in the interior, it will not support that. So CPU light baking supports that more than this does. OK, so there's just a few more items here you can mess with. You can do aggressive leak prevention. We could turn that on to prevent any leaking going on. Now remember your light maps and the thickness of geometry. Those can also play a factor for some issues that may occur."},{"start":"7:40","end":"8:14","startSec":460.2,"text":"So there's also you'll notice a first bounce ray guiding all these things as we turn them on and we adjust them and say hey I want to be able to play with these settings. You'll notice this particular one is grayed out. So I wouldn't worry about this one too much but it does do the number of samples used for first bounce ray guiding which are thrown away before sample lighting. I don't normally mess with this one. So I think you're OK keeping that gray. You don't necessarily have to turn that or activate that one on. You'll see there's a real time workload factor. Again this tries to help with your workload for your heavy scenes."},{"start":"8:14","end":"8:45","startSec":494.1,"text":"There's a non real time workload factor. This is baking speed multiplied with real time. When real time is disabled in the viewer. So if you turn that off in your viewer you actually can have that. So it's kind of speeds things up a little bit. And then you also have your light map tile pool size. The default should work fine but feel free to bump that up. And again this gives you GPU light mass manages your pool size for calculations and invisible tiles. So it really tries to help you with that."},{"start":"8:45","end":"9:15","startSec":525.6,"text":"Now my first pick is aluminum. That's my first pick. But I wanted to walk you through these because there will be scenarios where you may have to do this particularly with virtual production particularly like say you're working in ICV effects and just your machines just don't like lumen or your materials very particular and lumen gives you too much noise. You could go this route but be very deterministic. Test it out ahead of time. See what you're going to get ahead of time. If you don't you won't know. So you don't want to be stuck on stage."},{"start":"9:15","end":"9:47","startSec":555.8,"text":"You don't be stuck in front of your art director and you don't know your options. So this again this class is really mainly to help you with that and decide what you need based on what you have. I do want to mention a cute a couple more points that you have here underneath lighting. You'll notice you can also use error coloring. This will color areas which are you're getting like some errors in your computation. It'll color those areas for you so you can find it in your light map."},{"start":"9:47","end":"10:18","startSec":587.6,"text":"Also there's show lighting stats. You can actually get that in here and this will tell you what's going on. It'll tell you your metrics and stuff and tell you how your performance is doing. All right awesome sauce. So again let's reiterate some of the things that you cannot do. So lightmass portals are not supported. Pixel depth offset is not supported. Lighting channels are not supported. So keep that in mind. Use lightmass importance volumes to help with volumetric light maps which you heard me talk"},{"start":"10:18","end":"10:50","startSec":618.6,"text":"about before. It uses as a focal area for your moving items. It's very crucial in this case with GPU lightmass. Also you will logically need that for your terrain if you have terrain. Texture encoding and denoising a run on the CPU and are not affected by the multi GPU. But you did see some of those options for it because they're still talking to each other but mainly you're leaning on your GPU for speed. We have stationary skylight currently not supported but on the roadmap."},{"start":"10:50","end":"11:24","startSec":650.2,"text":"And then we have custom settings and properties of lights. So what that means is when you have maybe you've injected a custom light in there and maybe you're even editing some of those deep dive test it out first I recommend. So like if I'm working with direct lighting let me show you real quick here. You'll notice in Unreal we do have a section. Oh I zoomed down my camera next and I meant to wheel scroll over here. You'll notice lightmass this is no longer."},{"start":"11:24","end":"11:56","startSec":684.4,"text":"Now this is CPU based mostly but you can help out with a few things. So your light source will still work light source angle your indirect lighting saturation test that out to make sure it's giving you what you want. Shadow exponent. These were originally created with CPU light baking in mind. But you always for good measure you always want to make sure that your stationary light that your excuse me your area shadows for stationary light that is on that's going to"},{"start":"11:56","end":"12:35","startSec":716.6,"text":"give you a better shadow quality. And when you do this you'll have to do a remake. You can also do such things as light shafts. But again test things out as you go because there are some of these customizations which may not work a one to one to what you have with the CPU bake. And there's lots of customization in CPU versus GPU. So if you are very specific on a particular look and feel and a tool test it out first and do a comparable because such things as like we said the light mass that we saw here."},{"start":"12:35","end":"13:10","startSec":755.2,"text":"That's actually we can get this out of the way. We saw that the light mass portals. These little guys aren't supported. So there are a few things that are very particular for CPU baking and also pixel depth offset is not supported. So just keep those things in mind. Here's a link for additional information on these topics. Feel free to dive in and take a look. In the next video we're going to do an interactive session here where I will be lighting a character."},{"start":"13:10","end":"13:19","startSec":790.9,"text":"He's a bit more stylized not really a metahuman but we're going to have some fun with him and you feel free to follow along as I go through that workflow. That's it."}],"10_CharacterDynamic Lighting":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"In this lesson, we're going to explore character dynamic lighting with Unreal. So let's get started. So setting it up. When lighting characters try to use colors in the background that complement the character's tone. With a character having a tan skin tone, peach, blue can complement them when placed behind them. Now you'll see this in Love, Death and Robots, the Entombed project I worked with, Sony Imageworks and Unreal. You'll see that there's a blue color back behind the characters, pretty consistent through most of the film."},{"start":"0:34","end":"1:09","startSec":34.0,"text":"But it works really well with these tan skin colors of most of the characters in the episode. Now you'll notice I have some rim lighting in here too, which works really well. And this overall and several of the shots that I worked on like this worked really well like that. But you'll also notice there is a bit more shadow on one side of the face versus another. So also for dynamic lighting, try to keep that line to one side of the face. Now, again, you'll see it again on this image down below with a metahuman of myself."},{"start":"1:09","end":"1:44","startSec":69.0,"text":"This is available if you want to light this particular character in the baked project that I give you. So you're more than welcome to. We're going to mainly focus on Lumen when we light our character. And we'll take a look at how you can do it and use some of the tools to get some of that really dramatic feel. Now, again, it's always good to try to explore those areas with lighting on your character where you want one side a little bit darker than the other. You will see in some shows like, you know, like, I don't know, soap operas and dramas where everything's kind of evenly lit."},{"start":"1:44","end":"2:18","startSec":104.0,"text":"I never really like that. It's always better to get a little bit some sort of drama, even in those particular environments, some sort of dramatic feel for the light and for the camera. Just to tell a good story and keep things interesting. That's the artist side of me. But again, it's all depending with your tools, with your shot. Always explore and be creative and using your tools in a real can never be easier. And again, you can see for each one of three of these shots, and this is the one called the Crimson Claw scene that will be lighting."},{"start":"2:18","end":"2:51","startSec":138.0,"text":"You'll notice there is a rim lighting here. There's rim lighting here and there's rim lighting here. All three that I've established and built. Now, again, you can have some fun with this and explore it any way you want. You don't necessarily have to light exactly like me. But let's actually take a look at those tools in just a bit. So one of the lights I'm going to point out that I use quite often is the rec light. It is fantastic. And you can't hear me speak enough about it. It is the more expensive light. So keep that in mind when you're either baking lights and we have character examples for baking."},{"start":"2:51","end":"3:24","startSec":171.0,"text":"And this one is included or whether you're using lumen. Now, lumen is really efficient. It can work really well. But be aware of some of the noise that may occur due to your your shadows and the unreal trying to digest and calculate the GI on the camera. So just be very deterministic and be careful and just be aware of them and move things around accordingly. Now, again, lumen is evolving. It's going to get better, faster, stronger or the noise can and will be eventually completely removed."},{"start":"3:24","end":"3:56","startSec":204.0,"text":"But for now, there's always going to be a little bit. So be very strategic with your shots and how you place things in the world. Let's go ahead and take a look at this in Unreal and you can go ahead and follow along and build things with me. So in Unreal, we have our hero, the light. In Unreal, we have our hero, the crimson claw. You have to say it every time you say his name. I'm going to say that deep. You can see him fighting back the evil manys here, the mannequins or the man. We say we call him Manny, the male's Manny and the female's Quinn."},{"start":"3:56","end":"4:27","startSec":236.0,"text":"So you can see him fighting them back, trying to get to him. And you'll notice again, I have rim lighting. I have some nice universal lighting in here. You can even add more fill lights in here, but this is shows you a nice little base to be able to play with and to work with. So let's actually light our own. And I'm going to get you going in the right direction here. So to do that, let's go to our content browser here and we're going to go ahead and open up our scene."},{"start":"4:27","end":"5:02","startSec":267.0,"text":"And we'll go to character lighting. This is where you can grab this underneath the class name. And then you'll see character lighting. And I'm going to go ahead and grab on the start. Let's go and click the start. We really just have nothing but glowing objects in here. And Lumen is working in that direction. Now we can actually get them to be a lot more stronger in our influence for here. But we got to add a few things such as Lumen GI and so forth. So since we're using Lumen, we can go to our project settings and double check and make sure everything's on."},{"start":"5:02","end":"5:32","startSec":302.0,"text":"One, let's make sure our shader model six is active. We can see it is active here, which is our primary. And I also like to turn on the target shader formats here for Vulkan. That actually helps, especially if you're bringing such things in. Let's go to rendering. Under rendering, let's double check. We have Lumen. We have Lumen reflections in here. Surface catch, detailed ray tracing. We can change these to to be more hit lighting for reflections."},{"start":"5:32","end":"6:02","startSec":332.0,"text":"You can actually change it in the post-process volume. Virtual shadow maps supporting for ray tracing. All these hit the checkboxes. And we, again, mesh distance field is already active in here. So if you want to look it up, you can. You can say, hey, man, is my mesh distance field in here ready to go? You really shouldn't have to. And you'll see here, allow. This is a little bit different. We can see generate mesh distance field."},{"start":"6:02","end":"6:34","startSec":362.0,"text":"This is the one that you want in here. Also, we should be good to go. Everything should be rocking. So let's go and get started with that. Now, the glows in here are given off light. You'll see that a little bit here on the head here. The glow here is not too strong on the shield, but it's definitely something I could explore more if I wanted to. Everything is grouped on him. So you would have to ungroup him to change some of those items. It just made it easier for me to place him in the world. Let's go ahead and go to our tools here."},{"start":"6:34","end":"7:04","startSec":394.0,"text":"Actually, I should say Windows environment light mixer. Let's go and create a skylight. You'll get an error at first, but we've talked about this in previous classes. We're going to create a volumetric to clear some of that out. Create an atmospheric light. Create a sky atmosphere. You'll see that disappear. Create a volumetric cloud and create a height fog. There we go. So let's go and rotate that light in the direction that we need. So let's grab that directional light. Let's move it into our scene a bit here. It's pretty close by. There he is."},{"start":"7:04","end":"7:38","startSec":424.0,"text":"Let's pull this up. Now, if you want to, you can rotate this any way that you want. We can make it look like it's a moonlit night and have a light kind of bleed across the hero's face. And if we want to, we can lower this to like a five or two. We can give it a bluish color like Hollywood does that. Moonlight's always blue, right? Not real light. We can do that if you want to. A little dramatic. And we can go in here and soften things up a little bit with the source angle."},{"start":"7:38","end":"8:09","startSec":458.0,"text":"If the shadows aren't as blurry as we want. But actually, these look pretty good. They're pretty good. So we can always revisit that if you want to. We want to have a post-process volume. Now, I have one already in here. But again, put this in here as you need. We can set this to lumen. Set the method to lumen. Also, we want hit reflection in here. And we want to go in here and underneath lumen, low illumination, turn all these on as well as the advanced. Now, start low and then go high."},{"start":"8:09","end":"8:40","startSec":489.0,"text":"Always remember that. So I'm going to bump up the lumen scene quality and the lumen scene detail. Now, again, these are expensive GPUs. So if your computer is a little bit questionable, be careful with it. Final Gather is going to help get rid of some of the noise that may occur. You can see that there. Unreal's even telling you that. And I think we're in a good spot to be able to keep rolling and light things. Now, we've covered some of that in other classes. So explore as you need. I don't want us to get too caught up with the details. Because we do need to place lights in here. So I'm going to pull in a rec light initially."},{"start":"8:40","end":"9:10","startSec":520.0,"text":"I'm going to rotate him and make sure he's not intersecting with geometry. So there can be some noise that occurs. That happens quite often with ray tracing because Unreal doesn't know where the photons begin and end. I'm going to place this up into the scene. I'm going to set this at a really low amount. So we'll set this to like maybe a two. And we can stretch this out. And we can go ahead and set this to like a three. Make sure you do it in the details and not anywhere else. You can you can feel free to actually go in here and play with this a bit more with Alex. Kind of cool. Nice little highlights off his suit."},{"start":"9:10","end":"9:45","startSec":550.0,"text":"And you can determine whether you want shadows to come off this. It's up to you. So I'm going to do that a little bit dramatic. I do want a little bit of that redness coming off his shield. So I'm going to pull in and make sure that he's not intersecting with geometry. And I'm going to go ahead and set this to like maybe a two. And we can stretch this out. Make sure you do it in the details and not anywhere else. So I'm going to do that a little bit dramatic. I do want a little bit of that redness coming off his shield. So I'm going to pull in and make again, make sure your lights are movable so that the GI updates appropriately. And I'm going to go and pull in a point light. You may not think, oh, well, my my stationery is working."},{"start":"9:45","end":"10:19","startSec":585.0,"text":"No, you still want to do movable because anything you change in your post-process volume is going to make sense to Unreal. If it's stationary, it will not make sense. It will be very weird and Unreal will not obey and do what you want. Your intentions will not be clear because you're not connecting a dynamic light with a dynamic GI setup. You see, has a little EEC line going on for our hero. Let's set this to like a two and make this red."},{"start":"10:19","end":"10:49","startSec":619.0,"text":"And actually, we can even make it lighter. Seems like a little strong so we can make that maybe a point five. There we go. Pretty cool. A little different than what we had before. I like this highlight better than my original. It's pretty cool. I got a little fog material on here. Unreal did a nice little transition when I brought in the material from Maya. It created a new to control that material made like a fog material. There are a few limitations with that, but it's like a."},{"start":"10:49","end":"11:21","startSec":649.0,"text":"If we look at it. Well, I won't bother looking at it, but if you did crack this up and you will see a material function buried in there, it's OK. I like it for this particular case. I think it looks fantastic. But if you need to make some more details, you may want to swap that out and just adjust it and remove that material function and just use Unreal's materials from there using roughness and a few other things. Quick material note. Now let's go ahead and bump up a few things such as some dramatic lighting."},{"start":"11:21","end":"11:53","startSec":681.0,"text":"So I'm going to pull in some rec light, a rec light in here. This rec light will rotate this. Do a 90 degree rotate. Move this back just a bit. Get some cool rim lighting. Move it up a little bit, stretch it out so it covers a little bit more. Oh, that's nice. And then we can lean that in just a tad."},{"start":"11:53","end":"12:24","startSec":713.0,"text":"We don't want it too strong, so we're going to set this to like maybe a three. We could even do a four half the amount. Tell it not to cast shadows. And we can also tell this point light not to cast shadows either. And again, make sure your lights are movable when you select them. We're going to say don't cast shadows. This also needs to be movable. Set that to movable. There we go. So far, so great. Do we want this to cast shadows? Yeah, it's kind of cool."},{"start":"12:24","end":"12:55","startSec":744.0,"text":"It actually works pretty well, so we can leave that. We're going to need a few more rec lights in here and I'm going to need maybe one more here to get a dramatic shadow in the face. So let's pull on another rec light. Again, they are expensive, so keep those things in mind. Move this over. Move this up. Change the source width. Notice it changes the energy. Change the source height."},{"start":"12:55","end":"13:26","startSec":775.0,"text":"Set this to like a two. And maybe even lower. Let's do a .5. And if we want, we can fake this like moonlight. What? Make it slightly blue. Even more blue if you want. It's up to you. And even take this to a one if you want at that point. Or a two. Or a three. It's up to you."},{"start":"13:26","end":"13:56","startSec":806.0,"text":"Pretty cool. Pretty cool. A little blue casting behind him, which will work great with the skin. Oh my. I don't want every light in here to cast shadow, so we definitely can turn that one off too. So now we got our villains we want to handle. And we can probably lower the highlight of the suit to a one. There you go. Or maybe even a two. Let me see. 1.5. I think will work. 1.5."},{"start":"13:56","end":"14:29","startSec":836.0,"text":"There we go. All happy medium. We're going to do one more fill light for the whole scene. So let's do some rim lights. I'll keep it pretty brief because we don't want this to be too long of a lecture. I'm going to go ahead and pull on a rec light. And we'll do a source width. Do a bit of a source height. A little more of a width because we can get this more of a narrow highlight. Ooh, that's kind of cool. Almost like a Jack Kirby highlight. I know I'm such a comic nerd."},{"start":"14:29","end":"14:59","startSec":869.0,"text":"Oh, let me do controls here for a second. Turn it this way. Change the width a little bit. Lower it. Set it to now object rotation versus world. Don't cast shadows. Lower that strength and like one could even do a little bit stronger. I'll leave that for now."},{"start":"14:59","end":"15:29","startSec":899.0,"text":"Because we'll do another fill light here over here. Just a little one. Now, if you brought in, say, a point light, you're like, oh, I need to fill this a little bit. You got to be careful. Hot spots have a shiny object here. So you can use it. And again, remember, we talked about this. You can lower the spec so the shape doesn't show up or you can go in here and control the source soft source radius. So we can bump that up a little bit so it doesn't quite affect things too much because we want it to fill not necessarily take up space. And we can set this to one."},{"start":"15:29","end":"16:02","startSec":929.0,"text":"And move it up a little bit. And it can be a nice little fill light there. You can determine where you want to put it. What a highlight a little bit more. Rec lights are always a little bit better for this, but I just thought I'd put a point line in just to show you a bunch of tools to play with. All right. So we want to do a little rim lighting for him and a little fill lights for him. So let's go pull out another rec light. We can change that color whatever we want for this particular character."},{"start":"16:02","end":"16:33","startSec":962.0,"text":"There we'll have it facing him. Change the width. Change the strength. Rotate it. Oh, that's nice. We got like a nice little rim lighting off this character here. Turn off the shadows. No casting the shadows for that. And in this particular one where we have the rec light here we can even move this in a little closer. And if we do, we can get maybe a little more highlights on that limb that he has his limbs fading back there."},{"start":"16:33","end":"17:04","startSec":993.0,"text":"So I could do something like this. Like this, just by positioning things. There we go. Now we're getting quite as dramatic as are my example here. So what we can do if we wanted to is bump this up a little bit more. Kind of do like it a little bit stronger. That's up to you. Makes the robots seem like they've taken over a little mood lighting in here. Or we can even lower that down to maybe a one if you wanted to."},{"start":"17:04","end":"17:36","startSec":1024.0,"text":"And our directional light, if that's an issue, lower it some more. Put it to one here. So our primary lights are environment. And then we can take some of these and dumb them down even more. Point five here. And we can make this one too. It's up to you. And then now we can crank this one up maybe a little bit more. And again, you can change the mood of all your colors if you want."},{"start":"17:36","end":"18:08","startSec":1056.0,"text":"Whatever you want to do. And you can see dramatically this really has a good vibe. So you can play with these any way you want. I think a bluish gray works pretty well. Even more extreme blue too. Pushing blue a little bit farther. Now if we change this to more of a white, you'll see it changes the complete feel for this scene."},{"start":"18:08","end":"18:39","startSec":1088.0,"text":"Dramatic, not so dramatic. You can see that. Now if we want shadows on these at any time, you can add them. So we can say I want to cast a shadow here. That actually helps the TVs. A more believable feel to them. And again, when you bring in these lights, switch it to movable. Notice they're coming in stationary. Directional by default will become movable, but the others will not."},{"start":"18:39","end":"19:09","startSec":1119.0,"text":"Make sure you click on that. So finally in here, I think we're at a good spot. If we wanted to, we could even make it a bit darker. Just by changing these values, you'll notice changing these just a little bit can help with the look and feel that you need. Again, all of these are relating to the world. So if at any time you want to bring in the shadows, you can. They may help or may not. Office lighting obviously will give you more shadows as you play with these."},{"start":"19:09","end":"19:43","startSec":1149.0,"text":"As you pull them in, you'll see them come in here, make things a little more grounded and believable. They will remove highlights too, so be careful with that. And finally, if we wanted to, we can actually put in one more very low rec light right beside his head. Rotate this. Move it up for more dramatic feel. Change that width."},{"start":"19:43","end":"20:13","startSec":1183.0,"text":"And change that strength. We'll do that. We'll do something like a one to test it out. It kind of looks like an animated series there. We can move it closer to his face. And this particular rec light here, we can lower this one so it doesn't has less of an influence over there. Now, this is really up to you how you want to do this."},{"start":"20:13","end":"20:49","startSec":1213.0,"text":"And you can also change the dramatic positioning. Of our light here. And then we can lower some of the other ones in here as a whole. And move things around as you need. That way your characters don't get lost. And we can also probably add one more rim lighting here for the robot."},{"start":"20:49","end":"21:22","startSec":1249.0,"text":"Move that in. Move it across. And let's switch that to object. So it's a little easier to move around. And we could change that to like a pink color. Look like he got shot with electric pink death. I'm pretty sure that's the name of his weapon. It could be. We just open this up. Set this to a two. There you go. And then again, we can mess with our barn door angle."},{"start":"21:22","end":"21:53","startSec":1282.0,"text":"So we can make that a little more focused. Or opened up. Move it down. And even rotate this towards them. So they both look like they got shot. Cool. So I hope this helped you guys out on different approaches you can do. Again, make sure it's movable. And you can play with your lights. You can make any scene that you want as dramatic as you want. Just have some fun with it."},{"start":"21:53","end":"22:26","startSec":1313.0,"text":"And if I hit the G key, you can see everything within its intended look and feel. And we did this all in real time. We aren't getting much noise, which is fantastic. We also could play with some of the reflectivity here. You'll notice in the post process volume. If you go back to the post process one, just type it in. You want to make sure that you are using your reflectivity with lumen. But also in your project settings, we can go in here under rendering."},{"start":"22:26","end":"22:57","startSec":1346.0,"text":"And I'll make it so you can see this a bit better. We can go in here and say, move down here underneath reflections. We're using. Go down here. Where do you want to go here? We can change like hit reflections and then we have detailed. Tracing again, you can do that within your post process volume too,"},{"start":"22:57","end":"23:29","startSec":1377.0,"text":"so you can get things in the right direction. So this is going to give us like the best possible detail for our reflections. And again, keeping things lumen is going to be super, super, super helpful. And with ray tracing active and so forth. All right, so that's about it with this one. And again, if you have any questions at the end of our courses, and let's actually turn high transition reflections here and turn that one on. You'll see a little bit of shift. If you have any other questions on these, let us know."},{"start":"23:29","end":"24:00","startSec":1409.0,"text":"And we'll be there to help you and get you going in the right direction when it comes to Unreal. For further exploration with Unreal, you can actually look at our characters that are nested inside the bake lighting folder and the big lighting scene. And you can play with some of the things there. Keep in mind, they are more focused on baking. So feel free to convert the whole thing into lumen and play with them a bit farther and see what kind of results you get. Here's some credits again for all those that have worked on this project."},{"start":"24:00","end":"24:27","startSec":1440.0,"text":"And here's some of the things that we've done. So that's all we have for now. We hope you enjoyed this video. If you did, please like, share, and subscribe. And if you haven't already, you can click on this project. And here are some additional resources link, a link here that you guys can click on and jump into these topics a lot more deeper. Thanks again for being part of the class. In the next video, we'll just recap everything we've learned. And that's it."}],"11_Outro":[{"start":"0:00","end":"0:29","startSec":0.0,"text":"Let's go ahead and recap what we talked about. So for the class, we went over exposure control and tools. In that we talked about a lumen focus. We looked at engine scalability and a few things with materials and CVars. Next we look at environment light baking. We looked at initial setup in which we can get things rolling. We worked working with lights and detail and also adding some baking. Thanks again for being part of the class. And that's it."}]},"203.04":{"01_Intro":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Welcome to the Path Tracer class for Unreal Engine 5.6. In this class, we'll explore how to set up and use Path Tracer, adjust key CVars to improve visual fidelity, and author or adapt materials for high-quality offline rendering. We'll also cover how to leverage post-processed material buffers for fine-tuning results and enhancing realism. From there, we'll look at proven techniques to reduce visual artifacts along with the best practices for tweaking rendering and lighting settings to achieve true cinematic"},{"start":"0:32","end":"0:44","startSec":32.4,"text":"quality. And to wrap things up, we'll share a few pro tips and advanced considerations for maintaining optimal performance and control when working with Unreal's Path Tracing system. Let's get started."}],"02_WhatIsPathTracer":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Path Tracer is a progressive hardware accelerated rendering mode that mitigates the disadvantages of real-time features with physically correct and compromise-free global illumination, reflection, and refraction of materials and more. Path Tracer uses the same ray tracing architecture as other ray tracing features in Unreal Engine, such as real-time ray tracing and GPU lightmass, making it ideal for use in pipelines where ultra-realistic visuals are desired."},{"start":"0:30","end":"1:02","startSec":30.0,"text":"Path Tracer is not intended for real-time applications, but rather for achieving ultra-high fidelity and realistic visual output. Path Tracer provides the following benefits when compared to other rendering modes. The ability to generate high-quality photorealistic renders with physically accurate results. Minimal or no additional setup required to achieve comparable results to other offline renderers. It reduces the feature gap of comparable real-time features. For example, materials seen in reflections and refractions are rendered without limitations,"},{"start":"1:02","end":"1:34","startSec":62.0,"text":"such as having global illumination or path trace shadows present. It has full integration with Sequencer and Movie Render Queue to support film and TV quality render outputs, and it has full effect support with heterogeneous volumes. To enable Path Tracer on your project, navigate to the Project Settings and under Rendering, select Hardware Ray Tracing and ensure that the Support Hardware Ray Tracing and Path Tracing are enabled. After the Project Settings are configured, you can activate Path Tracer by selecting Path Tracing"},{"start":"1:34","end":"1:40","startSec":94.0,"text":"from the Viewport View Mode drop-down menu. Path Tracer will immediately begin calculating the scene."}],"03_ConfiguringPathTracer":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"To change path tracer settings, we have a couple of options. We can adjust the parameters through a post-processing volume, as well as through CVars. To start, we're going to drop a post-processing volume in our scene and break down the common parameters you'll likely change for your project. So inside the project, I have duplicated our level, and I've simply just disabled path tracer, and I've disabled the post-processing volume. So before we turn on path tracer, let's go ahead and go over to our Place Actors tab and search for a post-processing volume."},{"start":"0:35","end":"1:06","startSec":35.6,"text":"I'll drag that into our scene, and I'm gonna make a couple quick changes so we can see the effect of the post-processing volume. So in the Details panel, I'm gonna scroll down, and I'm going to look for infinite extent unbound. Simply check that, and then we're gonna go back to the top, and I'm going to look for our exposure and check my Exposure Compensation and my Min and Max EV. Now in this case, I just want to clamp it, although the default results are probably fine."},{"start":"1:06","end":"1:38","startSec":66.7,"text":"If you find that the exposure is ramping up and down too much, we can set our Min and Max EV to something like zero, and then adjust our Exposure Compensation. And I'm gonna go ahead and just do that now. So set these to zero, and then our Exposure Compensation, we can drag it down to something that works. I will go negative six. All right, and then to activate our path tracing, we're gonna go up to our Lit and simply hit Path Tracing. And you'll see that these samples will start calculating, and"},{"start":"1:38","end":"2:11","startSec":98.8,"text":"we will see our reflections and refractions and shadows update as soon as the calculations are done. So we'll let this run, I'll time lapse this real fast, and then we'll come back. Perfect, now Path Tracer has calculated the scene from the camera perspective. Of course, if we move our camera, it is going to recalculate the scene for us. Let's jump over to our post-processing volume that we just added, and I'm going to scroll down within the post-processing actor. Now there are several things that I encourage you to play with."},{"start":"2:11","end":"2:41","startSec":131.0,"text":"So for example, bloom, some of like traumatic aberration, lens exposure. You can even color correct your scene, your shadows, your midtones, your highlights, whatever you decide. However, for this particular section, what I wanna cover are some of the features of path tracing that we can control directly through our post-processing volume. So towards the bottom here, we have a path tracing section, and you'll see that there are several different parameters that we can adjust."},{"start":"2:41","end":"3:14","startSec":161.8,"text":"Now to adjust these and override the defaults, simply check the box and change the values within your little scrubber here. Of course, you can click and type in whatever you would like, and these settings will take effect. Now I wanna take just a quick side step and talk about balancing our editor performance and our final visual output. So if we take a look at our scene, we have our post-processing volume that's included in the startup map. And you'll notice that under the path tracing settings, we have various different properties that are checked and"},{"start":"3:14","end":"3:47","startSec":194.0,"text":"those values are either changed or just set at the default. The key thing here being that within our editor, we can have our post-processing volume. We can set these parameters to something that's lower and more performant. So our scene updates faster and we're spending less iteration cycles waiting for the engine to update. Of course, this is great for real-time performance, but it's not ideal for our final output, right? We wanna bump up our settings to 11 and get the very best visuals that we can."},{"start":"3:47","end":"4:21","startSec":228.0,"text":"So I'm gonna show you real quick. So if we go up to Window, Cinematics, Movie Render Queue, I've just simply loaded a sequence that's included in the project into this. And then under Settings, I've made a few changes, and that's what I wanna highlight right now. So if I just click the Settings here, the key parts that we're going to hit are the anti-aliasing and console variables. Obviously, we'll have path tracing enabled because that's what we're working with. Underneath anti-aliasing, I would highly recommend for spatial and"},{"start":"4:21","end":"4:51","startSec":261.6,"text":"temporal sample counts, setting those both to 10. Now, obviously, this is a deeper topic and subject than we're gonna cover in this one. But by setting both your spatial and temporal sample counts to 10, you should get a very good output, but also not take forever to render the scene. And then finally, you'll get a warning if you don't check Override Anti-Aliasing, because we are now specifying different properties, different parameters than the defaults. So we have to check Override Anti-Aliasing."},{"start":"4:52","end":"5:23","startSec":292.9,"text":"All right, now on to console variables. Now, this is a great setting that you can add just by clicking the setting, and it would be up here in the top section where we say console variables, but because we've added it, it doesn't show in this list. And what we have the ability to do in Movie Render Queue is by specifying some of these console variables, we can overwrite whatever is in our engine during the export process from Movie Render Queue. So for example, max bounces or max samples per pixel,"},{"start":"5:23","end":"5:56","startSec":323.9,"text":"if we really crank those up pretty high, it's gonna take a long time for our scene to render. So in Movie Render Queue, I can specify those console variables, which you can see here, r.pathTracing.samplesPerPixel, I've set it to 2048. Now I can do the same thing with our max bounces, right? So r.pathTracing.maxBounces, and bump it up to 64. I'll show you real quick just how you add a console variable. So by default, this is rolled up. We click a little plus, and you'll see that it adds another line."},{"start":"5:56","end":"6:26","startSec":356.4,"text":"And I could do something like r.pathTracing, and let's just say that I want to enable denoiser, and that should be .denoiser. And if you're unsure what the value is, you can highlight over the actual console variable, and it should give you a contextual pop-up. So in this case, 0 is disabled, 1 is enabled. So for example, if in my post-processing volume, the denoiser was deactivated, I can simply set this to 1."},{"start":"6:26","end":"6:59","startSec":386.9,"text":"And then now, when I render my movie render queue, it's going to override those properties of our post-processing volume. So this is a great way to be able to balance your performance, which will be your post-processing volume. So to balance the performance of your editor with bumping up your high visual qualities without having to go and manually set these each and every time. So once this is done, you can actually click this little drop down, save as a preset, accept. So now, when you load up your sequences for movie render queue,"},{"start":"6:59","end":"7:34","startSec":419.8,"text":"you can simply select your preset, and you're good to go. Now one other quick note is the reference atmosphere parameter within the path tracing rollup within our post-processing volume. When this property is checked and enabled, it will allow path tracing within the atmosphere, instead of baking the sky atmosphere contributions from the skylight. So any skylight in your scene when this property is checked will be ignored. Now something to take note of here is that we have available to us"},{"start":"7:34","end":"8:03","startSec":454.0,"text":"these lighting components. Now checking the box will allow or disable the pass when calculated by path tracer. So for example, if we disabled the indirect specular, you'll notice now in our scene that all of the indirect specular contributions are no longer being processed by path tracer. Of course, if we want to re-enable it, we can check this box or simply uncheck, and now those indirect specular calculations will be processed."},{"start":"8:06","end":"8:39","startSec":486.0,"text":"Now something else to take note of here is while we have these components or these settings that we can change within our post-processing volume, there are some advantages to using CVARS. Some of those primary advantages lie in the ability to isolate and output the results of each of our paths within Movie Render Queue. So just keep that in mind. All right, now something else to keep as a pro tip is when you're using emissive materials in your scene, it may be necessary to disable this"},{"start":"8:39","end":"9:13","startSec":519.5,"text":"emissive pass to prevent double lighting calculations. So again, that's gonna be in our post-processing volume under our path tracing. Simply check emissive and then uncheck if you are experiencing some of those double lighting calculations. Now in previous versions of Unreal Engine, path tracer did have some issues with translucency and depth of field. In 5.6, we remedied most of these problems by enabling the reference depth of field property within the path tracing settings of our post-processing volumes."},{"start":"9:13","end":"9:18","startSec":553.5,"text":"In the next section, we're gonna jump into modifying some of our material features to work with path tracer."}],"04_ModifiedMaterialFeatures":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Unreal Engine fully supports eye and hair shaders with Path Tracer. Additionally, we can use material parameters to selectively control glass absorption. All of these will be automatically calculated based on the shading model of the material, which can be modified in the parent material under Material, Shading Model. Unreal Engine also has the ability to leverage energy conservation on materials. You can enable this setting in the Project Settings under Engine, Rendering, Material section,"},{"start":"0:34","end":"1:04","startSec":34.0,"text":"and ensure that the Enable Energy Conservation on Material parameter is checked. Now, depending on the nature of your project or your intended target hardware, you may opt to create fallbacks for non-path tracing configurations within your materials. You can create a simplified material for ray tracing by using the Path Tracing Quality Switch Replace node This can improve performance while still allowing the engine to use a more complex material on non-ray traced viewports or hardware."}],"05_MaterialSetup":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Authoring materials for Path Tracer involves similar fundamental processes used to create any other Unreal Engine material. However, it's crucial to be aware of a few specific parameters. Your shading model, blending mode, and lighting modes of your material all affect the final results of your scene, especially when used with Path Tracer. When using Path Tracer, be aware that it considers the size and thickness of your meshes. Therefore, consider the geometry's thickness when modeling in your DCC application."},{"start":"0:33","end":"1:08","startSec":33.0,"text":"Included in the project files are three different glass materials. To open the material, you can simply click the object in your viewport, and from the details panel, navigate to and double-click on the material icon to open the material. From there, you can see how the material was constructed and better understand how path tracing is using these certain parameters of the material to produce the results in our viewport. In this next section, we're going to walk through a hands-on demonstration of creating a material from scratch."}],"06_MaterialCreationP1":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"The first material we're going to create is a simple thin glass material. I'm gonna navigate to my content drawer and in the lighting 203 for our T folder, I'm just gonna create a new folder and just call it examples. We'll double click and open that folder and I'm going to right click and create a new material. And we'll just name this M underscore thin glass. Go ahead and double click it and it will open our material editor."},{"start":"0:34","end":"1:05","startSec":34.1,"text":"Now from here, I want to adjust a few base settings of the material to allow it to work properly with path tracer. So the first thing I'm gonna do is change my blend mode to translucent and change my shading model from default lit to thin translucent. Now we will see a couple warnings and this indicates the third step we need to do, which is change our lighting mode to surface forward shading. So we can scroll down to our lighting mode and"},{"start":"1:05","end":"1:35","startSec":65.8,"text":"we're gonna change this to surface forward shading. Go ahead and hit save. Now we'll still get a warning here that says the thin translucent materials requires the use of a thin translucent material output node. All right, so let's go ahead and add that. So I'm just going to right click somewhere on the grid itself and just type in thin and we want a thin translucent material output. There we go, perfect. We should see the two settings, hit save."},{"start":"1:36","end":"2:08","startSec":96.5,"text":"All of our warnings should disappear right now. And now what I'm going to do is actually just apply the material to our example sphere here. So I'll just open the content drawer and I can simply just drag and drop it onto our object. Now we shouldn't see really any changes right now and we're gonna adjust that by adding some parameters to our material. So I'm gonna just move this off to the side so we can see and expand by material window out."},{"start":"2:08","end":"2:40","startSec":128.0,"text":"All right, now from here I'm just going to add a few properties. So the first one that I wanna do for my base color is just hold down the number three and left click which will get me a three scalars or R, G and B. I'm just gonna plug this into our base color, black is fine. And then I'm gonna hold down the number one and click, which should give me a single scalar. And I'm just gonna do that a few more times. We'll get ourselves four properties here. Go ahead and plug into our metallic and we'll set this at zero and"},{"start":"2:40","end":"3:12","startSec":160.4,"text":"plug the next one into our roughness. Now in this case, I'm going to have a very slight roughness. So we're gonna do 0.02 and we'll plug in our third property to our specular. So actually let's go into our opacity. We can leave specular as the default of 0.5. So in our opacity, we'll leave this at zero. And then finally, we're going to plug into our refraction. Now if you notice that it's disabled, we can enable that if we go back to our"},{"start":"3:12","end":"3:44","startSec":192.3,"text":"material so we can select the material or click anywhere in the grid. And what we're going to look for is our refraction mode. I'm gonna go ahead and just type in refract and right here we have refract refraction method and on this one we can change it to index of refraction. And you'll notice now that that property becomes available. So this is purely optional if you want to use it, you absolutely can. So in this case, you can set something to we'll do like 1.5."},{"start":"3:45","end":"4:18","startSec":225.5,"text":"You'll see that it gives us a slight bit of refraction, which is perfect. And then finally, the last thing that we wanna do is give our material a little bit of color. So I'm just gonna hold down the number three to bring up our three vector. And you can just double click this, which will open the color picker. And we'll just give it something like a hot pink, it's totally fine. And we'll plug this into our transmittance color. We should see now that this should update. And because this is a material and not a material instance,"},{"start":"4:18","end":"4:48","startSec":258.1,"text":"you'll notice a viewport doesn't update until we either hit apply or save. So I'll go ahead and just hit save and then we should see our example sphere update with the material. And if we move it out of the way, you see now we're getting our reflections, our refractions as we would expect with path tracer. So this concludes us making the thin glass material. In the next section, we're gonna go a little bit step further and create another material with a little bit more complexity."}],"07_MaterialCreationP2":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"In this section, we're going to create a simple light absorption material. Now within the material, we can control the color of transmission through the glass, also known as Beer's Law, by using the absorption medium output node. We can also add a few additional nodes to our absorption medium to control the normalized distance for color. Now if you recall from the previous section, we used this example sphere to apply our material to to see the results. All I've done is simply gone into the object itself and just reset our element zero,"},{"start":"0:34","end":"1:05","startSec":34.0,"text":"which is that primary material so we can see what we're building in this section. I'm going to go down to my content drawer and in that same examples folder, I'm going to right click and create a new material and we'll call this one M underscore PT absorption. It enter and we'll double click and open up this material. Bring over our window and very much like the last section,"},{"start":"1:05","end":"1:38","startSec":65.0,"text":"there's a couple basic things we need to establish on the material itself before we start adding all of our nodes. So by either clicking the material itself or in the empty space of our material graph, we need to change a few of the material properties. So the first one on our blend mode, we're going to change this to translucent. We do want to ensure that two sided is checked. Now pro tip, you can override this on your material instances, but in this case we want to have it enabled for the main material under our lighting mode."},{"start":"1:38","end":"2:12","startSec":98.0,"text":"We want to make sure that we have surface or shading enabled. And finally, we want to change two more properties here. So if we go to search and just type in refraction, change our refraction method to index of refraction, which again will enable this property on the material itself. And we are going to search for pixel and we are looking for pixel depth offset mode, which pro tip if you're not sure what the property is, simply highlight over the words and it should pop up a little contextual helper."},{"start":"2:12","end":"2:43","startSec":132.0,"text":"Explain a little bit about what that property is. So on this one, we're going to change it from a long camera vector to legacy. Now we can clear our search should give us back our material and we can hit save. Now, if you want to, we can go ahead and go back to our content drawer and simply drag and drop this onto our material so we can kind of see the results as we build it. Perfect. All right. So on the main material itself, we're going to go ahead and add a few properties to this."},{"start":"2:43","end":"3:16","startSec":163.0,"text":"Now you can, like we did in the previous video, hold down the numbers one, two or three to respectively create a single scalar to scalar or three scalar. Or you can just simply click in the property here and it will accept it. It's totally up to you. All right. So what I'm going to do is just go ahead and create a single scalar here for my roughness. Plug this into roughness and we'll keep it as something like zero in my opacity. So I'll do the same thing. Hold down the number one and left click and an opacity."},{"start":"3:16","end":"3:52","startSec":196.0,"text":"I'm going to plug this in and do something like point five. For my index of refraction, I will use one point five. We'll plug this in. And optionally, if we do want to convert this to a material instance so we can adjust those properties on the fly, you can pro tip select all of your properties, right click and convert to a parameter. And then we can start naming those. So I'll just do that real quick and just name them respectively so we can do roughness like this and we'll do opacity."},{"start":"3:52","end":"4:25","startSec":232.0,"text":"And finally, we can do. I or perfect. There we go. So now we can see it still accepted the values we created initially, but converted these two parameters. Go ahead and hit save. And it should update our material. Perfect. Now, in this next section, we are going to create the additional output node, which is the absorption medium. So I'm going to right click and in here I'm going to type in absorb and we're looking for absorption medium material output."},{"start":"4:25","end":"5:02","startSec":265.0,"text":"And you notice it is path tracer only. Now, from here, I'm actually just going to drag back and we're going to do a power node. So just type in power. And from our base, I'm going to drag off of this and we can do something like constant and we're looking for a constant three vector. And for this one in particular, I'm just going to give you the values of the example material, but feel free to kind of play around with this. So for our X, which will be just our red, we're going to do point one point two one six for our green will be one."},{"start":"5:02","end":"5:34","startSec":302.0,"text":"And for our blue B point four one five, we'll do something like that. Perfect. And then from our exponent, we're going to drag back onto here. We're going to do a divide. And then in our a, we drag back here and I can just type in scalar and get me a one scalar parameter. And you notice that if we use scalar parameter as opposed to just a single vector, you'll notice it creates the single scalar and converts it automatically to a parameter. Just a handy little shortcut."},{"start":"5:34","end":"6:04","startSec":334.0,"text":"We can still do the same thing by holding down the number one and then right clicking convert to parameter, which will just save us some time. All right. So our first parameter, I'm going to call this normalization. And then we could do something like after a hundred just as a little bit of context as to what's happening. And we'll set the default value to a hundred. And then for our second parameter, we are going to create absorb shin. Distance."},{"start":"6:06","end":"6:38","startSec":366.0,"text":"And then for this one, it will be a value of five. Perfect. And we'll do this. And that should be our absorption medium, which again, this is these two particular parameters we can control individually, which is just controlling the path tracing calculations on the glass through the absorption based on a distance that we're setting with that property. Hopefully that makes sense. All right. So we'll go ahead and hit save. And then we should see the material update in our viewport."},{"start":"6:38","end":"7:08","startSec":398.0,"text":"Perfect. And now you can start to see some of that coloration that's happening with the absorption and we can move our path tracer around and just kind of view the material a little bit more. Now, to help with the effect, I'm just going to take our capacity down to something like point one, it save and we'll see it update just to highlight a little bit more about the material. So you can see it on the video. But again, feel free to play with all of the parameters and just experiment with what they do and see the results inside of your viewport."},{"start":"7:08","end":"7:23","startSec":428.0,"text":"Now, in this next section, we're going to dive a little bit deeper into our materials, in particular, being able to control some of the different passes through the material itself for some really fine tune power level control. So we'll jump into the next video."}],"08_MaterialCreationP3":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"The Path Tracing Ray Type switch node can be used to replace material information for shadows, indirect specular, volume, and diffuse rays. The Path Tracing Ray Type switch node lets you feed different material inputs depending on the ray type being traced. We have camera, shadow, indirect diffuse, indirect specular, and volumetric. It's a path tracing only node that we can add to our material that's used to fine tune how material behaves under different ray evaluations."},{"start":"0:35","end":"1:07","startSec":35.0,"text":"So in short, the node gives you a per ray type material control, allowing artists and TDs to reduce noise, improve render performance, or fine tune artistic or physically based behavior when using Unreal Engine's Path Tracer. Now, if we jump over to the project, you'll see that I have applied here a quick debug material that I've created. Now, before I show the material, one quick change you may have noticed is that the viewport is a little bit darker than normal."},{"start":"1:07","end":"1:41","startSec":67.0,"text":"And all I've done is simply gone to my perspective and under game settings, I've just unchecked it and adjusted my EV. So if I turn this on, these are the settings that the scene will use. So if the level has a post processing volume, it will use those post processing volume settings. Or by simply unchecking it, I can manually override it. So that's the only difference here. And that's just to help better visualize and see this material. Now, if I bring the material over, I'll leave this up on screen so you can see it's a very basic material."},{"start":"1:41","end":"2:11","startSec":101.0,"text":"And if I click the material or the empty graph, I'm going to go over to my details panel and click the little settings cog and do show only modified properties. And this will show you the properties that I have changed outside of just the basic material. So from the previous sections, you should be comfortable creating a basic material, going into these properties and changing them. And then, of course, adding properties like our single scalars or our three scalars."},{"start":"2:11","end":"2:40","startSec":131.0,"text":"And if you notice here is our path tracing ray type switching node that we have been discussing. So from here, I've just simply plugged in various colors and then applied it to our debug sphere. And then I can start to visualize how the engine is processing all of those different passes. All right. In the next section, we're going to cover some of the post processing material buffers and how we can modify those to our liking."}],"09_PostProcessMaterialBuffers":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"When using Path Tracer, post-processed material buffers exist to let artists and TDs access and manipulate the raw render data generated by Path Tracer after it's computed lighting, shading, and ray interactions, but before tone mapping and final composition. Selecting from the Path Tracing Buffer Texture node's dropdown settings, we have a few options for changing the buffer texture. This displays the full Path Trace lighting results, including all light interactions."},{"start":"0:32","end":"0:57","startSec":32.5,"text":"Denoise Radiance shows the lighting results after the denoise smooths out noise. Albedo displays the pure material color, independent of light or shadow. Normal shows the surface direction information that affects shading and denoising. And finally, Variance highlights where the Path Tracer's noise or sampling instability is at its highest. In the next section, we're going to talk about reducing artifacts."}],"10_ReducingArtifacts":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Path tracing produces physically accurate lighting but can suffer from sampling noise and convergence artifacts, especially with limited samples or complex materials. Reducing these artifacts improves image quality, stability, and realism without necessarily increasing render times dramatically. Our two primary means of reducing noise and increasing visual output is through sample count and denoising. Fireflies are isolated, overly bright pixels that appear as tiny white or colored specks"},{"start":"0:34","end":"1:08","startSec":35.0,"text":"in a path tracing image. They usually show up in reflections, refractions, or glossy surfaces, and flicker or sparkle between frames. You can think of them as render noise spikes caused by a rare but extremely high energy light sample. While path tracing attempts to minimize the most common sources of these effects, they can still occur in some scenarios. One of the most common methods for controlling the quality of path tracing is through a post-processing volume. Under the path tracing rollup, there are various parameters we can adjust to control the balance"},{"start":"1:08","end":"1:41","startSec":68.7,"text":"between performance and visual quality. Note, the parameters in our post-processing volume, as well as several others, can still be controlled through CVARs. This is a great way for us to lower the quality of path tracing for real-time editor performance but still increase the visual quality using those CVAR parameter overrides when using Movie Render Queue. Speaking of Movie Render Queue, even with high sample counts, Path Tracer will always have a bit of residual noise in the rendered frame."},{"start":"1:41","end":"2:11","startSec":101.1,"text":"By using the denoiser option in the post-processing volume, Unreal will utilize Intel's Open Image Denoise library to remove the noise from the last sample. The denoise option is near the bottom of the path tracing rollup within the post-processing volume. To enable it, simply check both boxes and it should be on. Finally, on-screen are the current denoising algorithms implemented by Path Tracer through"},{"start":"2:11","end":"2:25","startSec":131.3,"text":"various plugins within Unreal Engine. Included in the slides are links to the various support docs that go deeper into using these denoisers. In the next section, we're going to cover editing some of our settings for Path Tracer."}],"11_EditingSettings":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Path Tracer and Unreal Engine uses an approximation for caustic lighting. The complex light patterns created when light reflects or refracts off of shiny or transparent surfaces like glass or metal. True caustics are physically accurate, but very noisy and slow to converge, especially on materials with low roughness, that have like smooth or mirror-like surfaces. They can take an impractical number of samples to render correctly. To keep images smooth and reduce noise, Unreal's Path Tracer automatically"},{"start":"0:33","end":"1:04","startSec":33.0,"text":"enables an approximation that simplifies the caustic calculations instead of fully simulating them. This is controlled by the console command r.pathtracing.approximateCaustics and setting the value, the default being 1, and it's on by default. When working with caustics in Path Tracer, it's important to know the difference between refractive and approximate caustics. Using the denoiser lets you preview what true refractive caustics would look like if the renderer had enough time to fully converge,"},{"start":"1:04","end":"1:34","startSec":64.0,"text":"showing you the physically accurate results. In contrast, approximate caustics generate a production-ready image much faster, using a simplified model that greatly reduces noise. You can toggle this feature on with the console command r.pathtracing.approximateCaustics and using 1 or 0 to enable or disable respectively. Finally, here are some CVars commonly used to modify path tracing"},{"start":"1:34","end":"1:43","startSec":94.0,"text":"and path tracing results within Unreal Engine. In the next section, we're going to cover using skylights, particularly with Path Tracer."}],"12_SkyLight":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"When using Path Tracer, keep a few things in mind about using skylights. First, the skylight capture is only visible when real-time capture is enabled. For higher quality renders, increase the skylight capture resolution beyond what is typically used for real-time playback. Setting the resolution to 2048 or 4096 should be a good starting point. If you're not using real-time capture, make sure your skybox or skysphere provides the sky's proper visual representation."},{"start":"0:32","end":"1:06","startSec":32.3,"text":"Also, the skybox or sphere should have the material's Is Sky flag enabled in the material settings, otherwise the lighting will be double counted, which introduces extra noise. Finally, your sky geometry, the sphere or the box, should not cast shadows, or it can block light contributions from both the skylight and the directional light. You can disable shadows on the geometry by unchecking the Cache Shadow in the Assets Detail panel. The skylight can also capture lighting contributions from the sky atmosphere and volumetric cloud"},{"start":"1:06","end":"1:40","startSec":66.8,"text":"systems. To do this, simply enable Real-time Capture on the skylight. Because these features rely on the skylight's Cubemap capture, their visual quality depends directly on the skylight cubemap resolution. Higher resolutions mean cleaner, more accurate skylighting. Note, when Reference Atmosphere is enabled in the post-processing volume, the sky atmosphere lighting is calculated volumetrically, providing far more realistic results. In this mode, any skylight in the scene is ignored since the atmosphere itself handles"},{"start":"1:40","end":"2:03","startSec":101.0,"text":"all sky illumination through directional lights and local light sources. Finally, Path Tracer represents the planet as a large sphere, ensuring accurate ground reflection and realistic shadowing in bounce light across the sky. In this next section, we're going to cover a few pro tips to keep in mind when using Path Tracer."}],"13_ProTips":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"When multiple denoises are available in your project, Unreal uses console variables to decide which one path tracer relies on. You can use r.pathTracing.spatialDenoiser.type and toggle between spatial, zero, and temporal, one denoising. You can use r.pathTracing.denoiser.name to pick the spatial denoiser you prefer. So for example, NNE denoiser, the default, or OIDN."},{"start":"0:33","end":"1:05","startSec":33.8,"text":"For temporal denoising, use r.pathTracing.temporaldenoiser.name to choose between the options like NFOR, which is the default, NNE denoiser, or OptiX. These tips simply give you finer control over which denoising method is applied, helping you balance speed, stability, and image quality. Here are some additional CVars for targeting your final image quality. Note, if you ever change a CVar's value and are unsure of the original default,"},{"start":"1:05","end":"1:37","startSec":65.0,"text":"you can type the CVar into Unreal's command line and hover over the text to see a tooltip which should also show the original default value for that particular CVar. Path Tracer now includes initial support for rendering heterogeneous volumes, things like smoke, fire, and clouds. You can create these volumes using the Niagara Fluids plugin or by adding a heterogeneous volume actor directly in your scene. These actors use sparse volume textures, for example, VDB files,"},{"start":"1:37","end":"2:07","startSec":97.3,"text":"which can be imported and rendered natively in Path Tracer. This means complex volumetric effects like simulated smoke plumes, rolling clouds, can now be rendered with full path trace lighting and shadows. As of the latest update, Path Tracer supports both static and moving heterogeneous volumes, giving artists far more greater flexibility for cinematic and visual effect work. Now, before you dive too deep into path tracing, keep in mind a few limitations."},{"start":"2:07","end":"2:37","startSec":127.5,"text":"First, heterogeneous volumes are only partially supported. This includes effects like smoke and fire. The sky atmosphere system isn't yet fully compatible with this feature, so the results may vary depending on your scene setup. Next, with Motion Blur, for the most accurate Motion Blur, use the Movie Render Queue and enable Reference Motion Blur in the Path Tracing module. This will give you a smoother, more physically accurate result, though at a higher performance cost per frame."},{"start":"2:37","end":"3:06","startSec":157.6,"text":"In this mode, no post-processing vector blur is used. Denoising happens after all spatial and temporal samples are accumulated. So, for the best result, apply a higher temporal samples and be mindful of the tick rate limitations when working with Sequencer. And lastly, volumetric clouds are also only partially supported. They can be captured through the skylight or represented natively when referencing atmosphere mode is enabled in the post-processing settings."}],"14_CourseRecap":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In this course, we explored how to use the Path Tracer in Unreal Engine 5.6 to achieve high fidelity cinematic quality visuals. We began with an introduction to Path Tracer, what it is, why it matters, and how it delivers physically accurate lighting and reflections with minimal setup. We also covered how it integrates seamlessly with Sequencer and Movie Render Queue, and how to enable it in both project settings and your viewport. Next, we walked through Path Tracer's configuration, adjusting parameters through post-processing volumes and console variables,"},{"start":"0:32","end":"1:02","startSec":32.0,"text":"tuning lighting components, and resolving translucency and depth of field issues using Reference Depth of Field. We explored modified material features including support for eye and hair shaders, controlling glass absorption, leveraging energy conservation, and using the Path Tracing Quality Switch Replace node to define fallback materials for non-path traced scenes. Then we broke down material setup and creation, showing how to build realistic materials like thin glass using thin translucent shading,"},{"start":"1:02","end":"1:32","startSec":62.0,"text":"or light absorption materials using the Absorption Medium Output node. We also demonstrated how to create a debug material with the Path Tracing Ray Type Switch node to visualize per-ray type behavior for camera, shadow, indirect view, specular, and volumetric. You learned how to work with post-processing material buffers to access raw path traced data, including radiance, denoise radiance, albedo, normal, and variance, which is useful for composing, grading, and debugging."},{"start":"1:32","end":"2:06","startSec":92.0,"text":"We reviewed methods to reduce artifacts such as noise and fireflies using sample control, denoising tools like Intel's Open Image Denoiser, and other quality-focused CVAR adjustments. We also examined caustic lighting, comparing refractive and approximate caustics, and how to find two results using r.pathtracing.approximate caustics, and related console commands. And finally, we discussed Skylight best practices, enabling real-time capture, increasing capture resolution, and setting Is Sky Flag on sky geometry,"},{"start":"2:06","end":"2:28","startSec":126.0,"text":"and disabling shadow casting to prevent over-occlusion. We wrapped up with pro tips for controlling denoisers, working with heterogeneous volumes, and optimizing performance while maintaining photo accuracy. By now you should have all the tools and understanding to push your path tracer renders further, delivering physically accurate production-ready visuals inside Unreal Engine 5.6."}]},"204.04":{"01_Overview":[{"start":"0:00","end":"0:23","startSec":0.0,"text":"Hello, and welcome to today's Unreal Engine training on the introduction to HMI optimization. So today we'll be talking about how to set your projects up. We'll go through mesh and texture optimizations, and then go into material optimizations. We'll talk about the optimization view modes, and then we'll talk about optimization tools. So lots of great content to optimize your projects. So let's get stuck in."}],"02_ProjectSetup":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Let's first jump into how to set our projects up. So the main feature we want to talk about here is the mobile HDR. Mobile HDR has a huge impact on your project's performance. So as you see on the left hand image here, with it turned off, your project will still run fast, but you won't have the additional render features. Whereas on the right hand side here, you can see it enabled. And although the project may run a little bit more slower, you'll still have lots of the rendering features enabled. So to keep the details from the HDR lighting, the mobile HDR rendering pipeline will draw"},{"start":"0:34","end":"1:08","startSec":34.5,"text":"the HDR scene color buffer first. It then converts it to the LDR post-process pass and sends it to the back buffer. So these render target operations cost different performances based on the different hardwares, but from a visual perspective, the LDR rendering pipeline dims and flats the highlight in the scene. So you need to tweak and hack your lighting settings and then the cube map also to compensate for the final visual result. Meanwhile, you may lose some of the post-process effects such as bloom and rendering effects"},{"start":"1:08","end":"1:24","startSec":68.7,"text":"like that. So it's good to keep in mind how you want to approach HDR on mobile. Of course, there's always a payoff between performance, but if you're looking for the extra rendering features, it's worth highlighting this and turning it on in your project settings."}],"03_TextureOptimizations":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Next, let's talk about how to optimize your textures. So here we'll talk about a few settings that you can use for when you import textures into Unreal Engine. And so the first thing being that in HMI, you should use a max texture size of 2048, but 1024 is better. So you can see that we've got a few different settings on our texture images here, but max texture, especially on mobile, should really be 2048. 1024 is more ideal."},{"start":"0:32","end":"1:06","startSec":32.0,"text":"Again, it depends on your project and what you really want to emphasize in your project settings. So having your textures in a power of two means that they can pack into memory more efficiently. So Unreal Engine will always want you to import textures. You can see the series of numbers here in some form of power of two. The textures don't have to be square, but they do need to maintain this kind of ratio. So you can import non power of two textures, but you will lose all the performance benefits and optimization."},{"start":"1:06","end":"1:36","startSec":66.0,"text":"So if you don't import power of two textures, you won't get any texture streaming. You won't get any MIP mapping. And then any non power of two textures will also be full resolution at all times. So there's no performance gain if you don't import the power of two. So non power of two textures will perform poorly on mobile devices and it will pack into memory less efficiently. So just keeping these things in mind when you're creating your textures."},{"start":"1:36","end":"2:13","startSec":96.0,"text":"Next, we'll talk about texture compression settings. So in HMI, you should use a variety of different texture compression settings dependent on the texture that you're trying to import. So every texture that you import will be compressed in some way unless you tell Unreal Engine not to compress it in a certain way. So we apply texture compression to textures to lessen the memory footprint of the project across a variety of platforms. So most textures are going to be either DXT1, which is the default by Unreal Engine."},{"start":"2:13","end":"2:43","startSec":133.0,"text":"As you can see at the top there, the default DXT1 essentially just means it's not got an alpha. If it comes in at DXT5, it means it's got an alpha channel assigned to it. So changing the compression settings will also change other settings for the texture. So sRGB will be disabled or remain enabled depending on how you've compressed that texture. So taking an example on the normal map settings, we will, if we set a normal map compression,"},{"start":"2:43","end":"3:18","startSec":163.0,"text":"it will disable the sRGB as gamma correction. It's just not needed for normal maps. So for HMI, the following texture compression methods should be used. So we've got our normal maps. We've got a cube map, IBL or HDR. We've got the EXR that will need to have their MIP maps manually set to off. So if you are doing EXR, just make sure you turn those MIP maps off. We've got grayscale on the right hand side here to help with banding, but make sure you use this sparingly."},{"start":"3:18","end":"3:49","startSec":198.0,"text":"And then we've also got UI texture compression setting. It's more important to make sure that the UI texture size can be divided by four with no remainder. If not, images will just not be compressed. So for example, 96 by 88 image would be OK as both 96 and 88, sorry, have no remainders when divided by four. However, if it was 97 by 89 image, it would not be OK as both 97 and 89 have remainders when divided by four."},{"start":"3:49","end":"4:19","startSec":229.0,"text":"So again, it's just keeping these texture compression settings in mind as we move through the projects. But hopefully that gives you a good overview of the texture compression. And so let's move into texture groups now. So texture groups will help determine what MIP or LOD resolution will be shown, what type of filter should be applied when the texture is magnified or minified by the GPU,"},{"start":"4:19","end":"4:49","startSec":259.0,"text":"and how the GPU should also blend between two MIP levels when viewing a grazing angle. So every texture in your project should be placed in one of the texture groups. So the existing groups are named in relation to what the textures that they control are. And then the so for example, an naming group would be normal maps for objects placed in the world should be set to the world normal group."},{"start":"4:49","end":"5:24","startSec":289.0,"text":"A normal map for characters, for example, should be set to a character normal map group. So you can change these in the default engine I&I. So you could also change main engine properties. But if you go to where your project is on the desktop files, you'll find in the config folder, you'll find an any called default engine. So you can mod some of these directly from there. And so they should be under the same settings. Just make sure that each texture is in a texture group."},{"start":"5:24","end":"6:02","startSec":324.0,"text":"So it's useful to do this from when your project starts, especially if you're thinking about memory and performance, we should always be at the start of our projects anyway. And so you can a few things to keep in mind on that specific point is that you can knock back the LOD bias down to one. Now that you're once they are assigned to groups, so that they'll be automatically set to the next smaller MIP. So this can, for example, take a 4K texture down to a 2K texture without even needing to reimport it or change in any of the source artwork,"},{"start":"6:02","end":"6:35","startSec":362.0,"text":"which is super useful when working directly in the project. So just make sure that each texture is put in a group and you can save many hours of work and rework even to help the performance and memory at these specific points. When we're talking about further optimizations and the RGB mass packing, RGB mass packing is just a way to cut down on the amount of textures and memory use. So it works by essentially just storing different textures in the RGB channel."},{"start":"6:35","end":"7:11","startSec":395.0,"text":"And sometimes you can add them to the alpha channel as well as a texture. So with HMI, you should not use the alpha as it increases the memory and it's not really worth the extra channel. So if you are wanting to pack your textures in the material settings, you can then when you have a texture sample node, for example, you can just pull off the ARPIN and only get what's on the red channel. Similarly with green and then blue, as you can see, these are all packed into the same texture. So instead of importing three different textures here, we import one texture, which has an RGB channel."},{"start":"7:11","end":"7:44","startSec":431.0,"text":"And you can pull off the required information based on the different channels there. So really nice way to optimize a project if you're not doing that already. And then when we talk about RGB mass packing, so inside the material, we then have the RGB pack texture in the material graph. And then we can just pull off the different pins, as I just said a minute ago. So you will only get black and white information from each of the channel. So storing colored data isn't possible."},{"start":"7:44","end":"8:16","startSec":464.0,"text":"The workflow is best when you don't really need anything that's super high fidelity, but you're OK with just this information that you can see on the right hand channel here. So a few settings to keep in mind, you want to disable sRGB on your RGB pack texture so they are not gamma corrected. And then make sure that your texture sampler is set, the type is set to masks. Next up, we have MIP mapping. And essentially you can think of MIP mapping as level of detail for your texture."},{"start":"8:16","end":"8:47","startSec":496.0,"text":"So MIP maps generation happens during when you import the texture into Unreal Engine, and it just creates a MIP map chain for that texture. So the MIP map chain consists of multiple levels of the same image. Each image is then half the resolution of the level before, as you can see in the image. So essentially as a texture gets further and further away, it will use a smaller MIP map. So if you are very close up to a certain texture, say we're working with 4K textures,"},{"start":"8:47","end":"9:19","startSec":527.0,"text":"which we wouldn't be in this instance, but to just give you the wide range of scale. So there'd be no reason to display a 4K texture when that object is taking up, you know, maybe a hundred pixels on the screen in the background. So most of the time you're seeing the second or third MIP. So the first MIP is only really ever shown when the camera is extremely close to the texture, and then it stacks back from there as you pull the camera further back. So there's nothing you need to do to set this up. Unreal handles all of this behind the scenes for you."},{"start":"9:19","end":"9:54","startSec":559.0,"text":"And if you do have any MIPs that you see that are shimmering, you can adjust the way the MIPs are generated in the MIP Gen settings. So when we talk about the settings, there's three that you want to keep in mind here. Simple average, which uses a two by two kernel size. You've got sharpen, which uses an eight by eight kernel and some negative weights to sharpen in addition to a four by four Gaussian kernel. And then sharpen zero is not sharpening, but it still uses the quality down sampling filter."},{"start":"9:54","end":"10:26","startSec":594.0,"text":"So using sharpen values four or five is a good place to start testing and check your MIP issues based on that. And then here you can see a visualization. It's an example of how MIP mapping looks like in action. So you notice that the highest MIP is not used everywhere. And keep that in mind, especially when you start a brazing textures into, you know, 8K and beyond. Just making sure that the real estate that's on the screen,"},{"start":"10:26","end":"10:34","startSec":626.0,"text":"the objects that you're wanting to look at, have the relevant MIPs assigned to it just to get that the most performance out of your scene there."}],"04_MaterialOptimizations":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Next, let's take a look at a few material optimizations. So let's look at parent materials first of all, and this is a really nice high level way to just optimize any kind of material what they have in your project. So it'll really help your whole team work faster and also allow you to make sweeping changes just by editing one material instead of a series of materials. So a material instance works with a parent-child relationship. So the material instance gets all the properties from the material they are linked to, and"},{"start":"0:34","end":"1:09","startSec":34.4,"text":"it's the exact same workflow that many other systems use. So you select items from the parent, pass down into the child, and then the child can decide what we want to use. And you can even use material instances as the start of the chain if you should want. I never use this as it can become confusing, but it's possible to potentially not cause any issues. You have parent materials at the top here, and you have the building parent and the glass parent. So as you can see, you don't really want, you want a different master material based"},{"start":"1:09","end":"1:40","startSec":69.3,"text":"on the properties that you are wanting the child to inherit. So we wouldn't have a master material that could account for a glass type opacity as well as a solid. So we'd make two different parent materials here, and then when you make your parent material, you can right click on this material. And one of the top options on the right click should be create material instance. And then you can create various instances based on that, that parent material. And then you can go in and change maybe just the texture that's been used on a parameter"},{"start":"1:40","end":"2:13","startSec":100.4,"text":"so that you can assign a variety of different textures, which all have similar properties. So that's a really good way to start optimizing your project when thinking about materials. Next we have quality expression nodes. So we can use the available switch nodes to control the functionality and quality of our material. So we've got a series of different switch nodes, and we'll just go through a few of them here. So we've got a shading path switch, which is useful for specifying what part of your material logic should be used for the render path."},{"start":"2:13","end":"2:43","startSec":133.6,"text":"You have a quality switch, which is used when the engine's quality levels are controlling material logic. We have a feature level switch, which is useful when setting up material for the use on the different devices. And then we also have a static switch or a static switch parameter, which is used to exclude the entire branches of your material in a base material or potentially control through a material instance. We also have a vertex interpolator."},{"start":"2:43","end":"3:18","startSec":163.8,"text":"So a vertex interpolator node allows for better control of the value interpolation between the vertex and the pixel work. So offloading the work from the pixel shader to the vertex shader is a performance win in some cases. So in this example, we want to title the texture in the material instance and notice the 96 instruction count, which really helps with optimizing in this instance. And then another example, it's the same material, but with the UV tile moved to the vertex"},{"start":"3:18","end":"3:48","startSec":198.6,"text":"shader from the pixel shader. So if you check out the instruction count, it's down to 95 now. So while it's not a huge saving, this spreads out across your projects. If you have many, many materials in your project, those extra instruction counts can all mount up to a huge saving. So sometimes it's about these smaller wins that we can get when applied across a larger project, especially if you're making a parent material into a material instances, these"},{"start":"3:48","end":"4:22","startSec":228.6,"text":"will all add up into your project. And then we'll see an example of the default versus interpolated. So here we see the material applied to that static mesh. And you can't really tell the difference between either one of these material types. So it not only works with items that have their calculations done in the vertex shader, you can try using this to offload UV tiling calculations or anything along those lines. And you might get a lot of mileage using this approach when working with certain materials in your projects."},{"start":"4:22","end":"4:56","startSec":262.4,"text":"We've also got texture area masking. So there are a number of different ways you can do masking. You can either do texture masking or vertex masking. Texture masking is using a texture to define the area that should be masked. Whereas vertex masking uses the object's vertices to define the areas that should be masked. So vertex masking gives a few different advantages on mobile over texture masking. So vertex masking, there are no bound by resolution or texture maps for masks."},{"start":"4:56","end":"5:27","startSec":296.6,"text":"It also reduces instruction count by not needing to sample additional material. And it also reduces the number of used textures, which is a massive win, especially on mobile. So if we look at the vertex area masking, there are a number of different ways you can do the approaches. So you can see that the instruction count between vertex area masking and your texture masking, that you'll get different results."},{"start":"5:27","end":"5:57","startSec":327.1,"text":"And it depends what you're looking for in your projects here. And then moving on to area masking, we have a few tips. So when importing a mesh with vertex color, make sure to set the vertex color import option to replace. It defaults to ignore. So you want to make sure the vertex color will not show up there. And then you can mix and match vertex colors and texture mask data just to make sure it keeps things consistent. And then also talking about quality improvements."},{"start":"5:57","end":"6:28","startSec":357.7,"text":"Just lastly, on the material side, by default, materials for mobile rendering will be set up to be as cheap to render as possible, especially if you set your project settings to mobile when opening the project to begin with. Because of this, materials that use cubemaps might not look as good as they could. So to fix this, you can enable a couple of different flags here. There's actually three different flags. So you want to use full precision, which makes the material use the highest precision level on the device."},{"start":"6:28","end":"7:05","startSec":388.0,"text":"And it offers instead of medium. And then you've got this pre-integrated GF for simple IBL, which uses GF Lite lookup. And then you also got the high quality reflections, which provides parallax correction on reflections and also removes the two reflection pro blending limit. So this will make your material a little bit more expensive to render. So don't only use it if this is maybe the key thing in your scene or that you really want to get these extra details into your project."},{"start":"7:05","end":"7:12","startSec":425.2,"text":"So on the above image here, the reflection is on the door, as we can see it turning on and off."}],"05_MeshOptimizations":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Next, let's dig into some mesh optimizations. So the first thing we want to talk about is some system units. So no matter what DCC you use, you just need to make sure your system units are set up before creating items. We mostly use 3ds Max for this example, but it applies to whatever DCC you're using. In Unreal, we use centimeters for its default unit of measurement. So having the right scale is a good user experience. The wrong side or mismatched scales"},{"start":"0:32","end":"1:02","startSec":32.3,"text":"can break any immersion you have built, especially in VR. So making sure you keep system units in mind is a good way to start. And then we're looking at draw calls. So Unreal Engine's mobile renderers are efficient at rendering large numbers of vertices. So draw calls are what you need to optimize if you've got a lot of rendered meshes in your scene. So the image here shows how having a different material"},{"start":"1:02","end":"1:36","startSec":62.4,"text":"assigned to different sets of triangles will give an additional draw call. So the more materials you have in your scene, the more draw calls you'll have. So your aim is to have no more than 120 draw calls on high and 50 on low. It's a rough approximate, but obviously your mileage may vary there. And when we're looking at normal mapping of meshes, on the lower end hardware, normal maps can be used to greatly enhance the quality of reflections"},{"start":"1:36","end":"2:08","startSec":96.2,"text":"and lighting on the surface of the material. However, subtle shapes like body panels on a car can exceed the 8-bit deltas normally used for these maps, which results in visible banding on the final render. So you can use 16-bit normal maps to compensate for this, but the pixel costs for the 16-bit normals then extends the vertex cost of a higher density mesh. So 16-bit normals are uncompressed in the engine, which means they are also eight times the size of a regular normal map there."},{"start":"2:08","end":"2:42","startSec":128.6,"text":"So it's a little bit hard to see the effect that this has on reflection, but if we move into the next slide here, you can see how jagged the reflection is when it's on versus being off. So it's useful to keep these settings in mind in your projects. And then we'll also lastly just talk about limiting overdraw in our projects. So overdraw is something that comes up when dealing with transparency or opacity, and it refers to your GP having to draw a mesh,"},{"start":"2:42","end":"3:13","startSec":162.4,"text":"draw a bunch of transparent see-through areas, sorry, that do not display on the texture information. So you tend to find this a lot on foliage, which you can see here, and it has the leaves map to the different planes. All pixels must be evaluated, even the ones that show nothing. So this will cause the GPU to do a lot of extra work that it just has to disregard. It doesn't actually result in anything. So we want to limit by doing some of the following steps."},{"start":"3:13","end":"3:45","startSec":193.8,"text":"So you want to see that you can limit the amount of transparent objects that overlap. So by optimizing your mesh like this, you can imagine if there was many different cards of foliage all on top of each other, and you had a card here, well, it wouldn't be trying to render through something. Whereas on the left-hand side, you may have something on the bottom right-hand side there, and it might be trying to render the first pass and then render the pixels behind that. So you want to limit the amount of transparent objects that overlap. And then you can see that you can get away with using geo here"},{"start":"3:45","end":"4:16","startSec":226.0,"text":"instead of having the transparency. So add the extra vertices to the meshes so that they fit the transparency information better. That'll be the best approach moving forward with foliage. So you can use the shader complexity view modes, which I'll touch upon in a second, and you can see how bad overdraw may be. But no matter how hard you try, you'll not completely eliminate overdraw. So don't waste too much time trying, but it's just good to keep these mesh practices in mind when you're first creating your assets."},{"start":"4:16","end":"4:24","startSec":256.4,"text":"So just try and limit as much as possible and just follow these steps as you go through the mesh creation process."}],"06_OptimizationViewModes":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"As promised, let's touch upon a few optimization view modes that we can look at here. So our first one is going to be lighting complexity. And what is lighting complexity and how do we use it? So we can actually get to the view modes as well I should say, by from the editor, you can go to show on the top of the editor window, and you'll be able to see these different view modes. So one of the properties will be optimization view modes. And then you can go and find lighting complexity. Now in more recent versions of Unreal Engine, so I think"},{"start":"0:33","end":"1:06","startSec":33.1,"text":"it's Unreal Engine 5.1 onwards, you can actually just click show and you can actually type in the box. If you typed in lighting complexity, it would find the lighting complexity option. So that's useful to keep in mind. But lighting complexity shows how many non static lights are affecting your geometry. So the more non static lights you have affecting a surface, the more expensive it'll be. So red means the area will have performance issues when it's run, so you can see it gets a little bit expensive on the right hand side here. And ideally,"},{"start":"1:06","end":"1:43","startSec":66.5,"text":"on this left hand side, you want these darker blues to brighter greens for the lighting complexity. As you move lights around increase or decrease the radius, you can see the cost that the lights have and that will change the complexity. So on the shading complexity, if lighting complexity showed how many non static lights are affecting the geometry, the more this on the shader complexity side, the shader complexity is showing how many shader instructions it has to run to render each pixel. So green means that it only took a few,"},{"start":"1:43","end":"2:13","startSec":103.3,"text":"whilst white can mean 1000 plus render passes. So ideally, you want to see all of this green information, green or dark green is more ideal. And you can see that when we're looking at transparency, whether it be on the headlights or the car windshield, it'll get worse, the more translucent objects we have to look at. So we want to reduce the material complexity and make sure we're not wasting too much transparent space. And we can also take on practices that we learned in"},{"start":"2:13","end":"2:46","startSec":133.5,"text":"the previous mesh optimization series that can reduce some transparency as well. Lastly, we'll talk about quad overdraw. And quad overdraw, if we think about GPUs work on a two by two quad granularity, which means thin and small triangles, small and two by two, these can result in lots more work to calculate than bigger pixels on the screen or bigger triangles on the screen. So you can lessen the impact on this by making use of LRDs that get rid of smaller triangles that can't"},{"start":"2:46","end":"3:07","startSec":166.6,"text":"be seen from a distance. But also we want to make sure we have as much blue sharp as possible. So the more green into the pinks and purples, it gets super expensive. So this is a relatively okay image. But if you could pull your camera back from this car, you'd want to make sure you had LRDs in place to reduce some of the complexity of this mesh here."}],"07_OptimizationTools":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In our final chapter here, let's look at some optimization tools. So first we'll talk about some UMG. This command will make it so that UMG widgets are only redrawn if and when they are changed or updated. So the command is enabled by doing the following and number one is enabled. So this slight enable global validation, invalidation. If you have space number one, it will enable it and zero will disable. So you can see the result of this when you have to do the following."},{"start":"0:32","end":"1:03","startSec":32.3,"text":"So if we run the game in a new editor window, which is very important, don't just play in play in editor as part of the viewport there because you'll be rendering the editor as well as your project. So run the game in a new editor window, super important. Enable the stat slate. So open your console by pressing the tilde key and type stat slate and then input the command and watch the numbers. So this is a good one for UMG."},{"start":"1:03","end":"1:38","startSec":63.7,"text":"We also want to check it on the device. So PC is great for emulation, but you'll always want to check on your target device. So the PC will give you a rough estimation of what's going on, but it's not going to be true for your project on that specific platform. So especially in HMI, check early and check often. We also have a tool called size map, which you can right click and find in this property here. Size map, you can also see the console shortcut alt shift and M and the size map will show"},{"start":"1:38","end":"2:10","startSec":98.8,"text":"you the size of the selected asset, including anything that it's linked to. So it's a visual representation and it really helps narrow down really large assets. So the tool will tell you both the size on disk and then also the memory and asset or groups will take up. So that's really useful when trying to optimize the package content there. Next we have statistics. So in our level editor window, we can also see statistics there and this window will break down the number of assets in our level files."},{"start":"2:10","end":"2:45","startSec":130.7,"text":"So we can display that either on all levels or only specific levels. And the primitive stats information on the list here is about the number of triangles and memory consumption and count. So other data that's displayed on this list include things like texture usage and static mesh lighting information. But this window can quickly illustrate which assets are consuming the most memory. So it's definitely worth looking at this when looking to optimize your projects."},{"start":"2:45","end":"3:18","startSec":165.4,"text":"There's also a merge actor tool inside of Unreal Engine. So when we're looking at the merge actor tool, it's just a way to combine multiple meshes into one static mesh and one material. So the tool will take all of the selected meshes and materials and merge them into a mesh and into one material. So you used to have to do this inside your DCC, but you don't need to do that anymore. You can do it inside of Unreal Engine, which makes it way less time consuming and doing it will reduce the amount of draw calls, as we were speaking about before in reference"},{"start":"3:18","end":"3:52","startSec":198.6,"text":"to draw calls. It just makes things cheaper to render, which is especially important for especially things like VR and mobile applications. So each material is an object, which means that it has to be rendered each time. And so an object with three materials will be rendered a minimum of three times, which is why you want to reduce as many draw calls as you can. So this tool will take all your selected static meshes and materials. It'll create an atlas out of them, reducing it down into one mesh with one material."},{"start":"3:52","end":"4:24","startSec":232.8,"text":"So how this tool works depends on your content setup. So content, you know, as long as it's all set up in the zero to one UV space, that will help it work better. Assets that use world position offset or world based texturing will not bake down correctly. And then also, if you don't like the results, try using something like a substance pater to combine the meshes. So an external DCC you might have better mileage with as well. So let's look at some of the settings of the Merge Actor tool."},{"start":"4:24","end":"4:57","startSec":264.8,"text":"So it's found by going to Window, Developer Tools, Merge Actor. And again, if you just click Window and type in what you're looking for, it'll automatically select the pane as well that you're wanting to open. So you'll need to do a few things here. We want to make sure the Merge Actor tool is open. Then select all the items we want to merge into one static mesh. Make sure that the following options are checked. So we've got on the bottom here, we've got pivot point at zero."},{"start":"4:57","end":"5:29","startSec":297.9,"text":"We've got Merge Physics Data and also Generate Lightmap UV. We also want to set the LOD selection type to use a specific LOD level. And then in the materials, we want to set the texture size to 2048 by 2048. We want to size the type to use bias based on the texture size. And then also enable all the maps we have. So check replace source actors and then press the Merge Actors button."},{"start":"5:29","end":"6:04","startSec":329.9,"text":"And then tool can take anywhere between a few seconds to a few minutes, depending on what you're trying to merge. And it depends what you had selected. And you should do this at the end of your project right after you've completed all the content and you're happy with the layout because if you need to redo it, that can be the most time consuming to redo. And another tool we can make use of is the Memory Parting Tool. So this is another console command. So you use a tilde key in your project editor and then you can type memory part dash full."},{"start":"6:04","end":"6:37","startSec":364.3,"text":"And it provides a closer look at the memory usage on devices. So once the app is built in the development configuration and is loaded to the device that you can use the console command on, if you're using an Android device, it's four finger press on the Android to open the console. And then you can just enter this console command and it's essentially a memory snapshot, which is saved into the projects directory on the device. So usually it'll be something like, you know, UE5 game dash your app dash your app dash"},{"start":"6:37","end":"7:10","startSec":397.2,"text":"saved dash profile in dash memory ports. You'll likely find it somewhere in that directory. So again, it's in your app, saved, profiling, memory ports. So if you search the term listing all textures, you will find a list of each and every texture used along with detailed information about the texture type, the group size and the memory footprint and the larger textures are represented first, which is quite handy there. So it's a quick and easy way to spot the textures that are costing the most amount of memory"},{"start":"7:10","end":"7:44","startSec":430.9,"text":"and definitely useful to run on the target platform that you're looking for. We have a few other stack commands as well, which provide pretty detailed information on our project. So there are many more than what's listed here. A good target of draw calls, for example, in an optimized scene is below a hundred on something like a Galaxy Tab S6, 50 or less on lower end hardware. But again, hardware quickly becomes outdated. So it's best to check what your target for the optimization is and process the scene"},{"start":"7:44","end":"8:17","startSec":464.9,"text":"based on that. We've got the StatGPU, StatUnit, StatUnitGraph, StatTextureGroup and StatRHI. And they're all useful commands to get you going on your journey of optimization. Looking at PSO caching as well. So PSO caching is a way to speed up the rendering of your package projects when deployed to device. So PSO caching works by first creating a list of all the needed shaders that are required by the materials that are used in our Unreal project."},{"start":"8:17","end":"8:47","startSec":497.4,"text":"And that list is then used to help speed up the compiling process of the shaders when they are first encountered by our Unreal project. So in terms help essentially reduce any of the hitches of the project might encounter when a material requires a new shader to be compiled. So PSO caching doesn't require our artwork to be set or created in a specific way. It's just something that is enabled at build time. And so because of this, setting up PSO caching can be a complex process that is generally"},{"start":"8:47","end":"9:16","startSec":527.5,"text":"best handled by a programmer or an advanced technical artist. It's important to know about these as it greatly helps load times and reduces hitches. But if you want to know more about PSO caching, there's some great documentation. So if you just type in on Google Unreal Engine docs and then type in PSO caching, you'll find the correct documentation page on exactly the step by step process of how to set that up for your scenes."}],"08_ThankYou":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"So thank you for watching today's course. Hopefully you got a lot of mileage out of the different tips and tricks that we have presented today. There's a lot of additional resources that you can dig into, whether it be in the slate architecture, the invalidation boxes, anything to do with UMG designer. There's a few good additional resources to dig into there if you'd like to follow those links. And then we've talked about optimizations based on textures, meshes, materials. We talked about the different view modes that are available in Unreal Engine, and also a"},{"start":"0:33","end":"0:48","startSec":33.5,"text":"few different tools you can use to get you started on your journey. So thank you very much for watching today. Hopefully it was a lot of in-depth knowledge to at least point you in the right direction of how to start optimizing your scenes. So thank you for watching and we'll see you on the next course."}]},"204.05":{"01_Intro":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Hi everyone, my name is Sean Spitzer, Senior Instructor for Epic Games. Today we're going to be talking about optimization for linear content and profiling in geometry. Some of the things we'll be talking about is profiling concepts in which we'll look at different tools that we have to analyze our scene, as well as optimization visualizers, Nanite and virtual shadows, as well as we're going to have a review of understanding LODs and how they work in your scene outside of Nanite and then we're going to review texture material optimization. In the next video, we're going to be taking a look at those profiling"},{"start":"0:34","end":"0:39","startSec":34.6,"text":"concepts up close, as well as the outline for the course. So let's get started."}],"02_DrawCallsGPUProfiling":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Hi everyone. In this lesson, we're going to go and take a look at the outline for this series of courses. And then we're also going to take a look at profiling. So let's get started. So first up, we'll talk about profiling concepts. From there, we'll look at types of rendering. We'll also look at concepts of thread profiling, how that works, calling concepts, calling methods, GPU visualizer, GPU draw thread, the CPU draw thread and how that plays, as well as the analyzing of draw calls in general, and looking at Unreal Insights. We'll then take a look"},{"start":"0:34","end":"1:06","startSec":34.0,"text":"at optimization visualizers. We'll look at using visualizers, some quick notes on those, and also a review of Lumen, Nanite and Virtual Shadow map visualizers, which we've covered in other classes. And then we'll also look at a few pro tips and some secret little visualizers that you can use to help with your workflow. Next we'll look at Nanite and Virtual Shadows. Why use Nanite? Using it and Virtual Shadow maps overview. We'll also look at a review of understanding LODs. Now again, I say review because some of these are covered in your other classes. We'll look at editing and using"},{"start":"1:06","end":"1:36","startSec":66.3,"text":"LODs, LOD colorization, using poly edit tools, swapping geo, merging geo and HLOTs and how that works. And finally we'll end with review of texture material optimization, texture optimization and material optimization when it comes to working with Unreal. Alright, let's go and get started. Optimization for linear content, profiling geometry, we're going to take a look now at profiling concepts. So some of the things you want to look at"},{"start":"1:36","end":"2:13","startSec":96.8,"text":"is a pros and cons when it comes to the types of rendering. There's forward rendering and that is your typical use or at least in the past that is used to create a VR scenario because it was a little bit lighter, but unfortunately you would have some limitations on the type of light that you would use, which would make things a little bit trickier. The overhead or the idea behind it was that things could be a little bit lighter so you weren't using the full capacity of all the things in the engine, but you're using just enough to be able to create a nice, efficient VR scenario. There's also deferred rendering. So deferred"},{"start":"2:13","end":"2:45","startSec":133.0,"text":"rendering is the old school way in which Unreal would bake your lighting. You would be fast, is especially in small, medium scenes, and had lower realism compared to ray tracing in Lumen. And it's largely a 2D operation. Calculates lighting with approximations is complex to use. Now you'll notice in the first one forward, it says a number of features are not yet supported, but you don't have to worry about that so much now. You can actually use VR or build things in VR using Lumen. Lumen now supports VR, so you don't have to"},{"start":"2:45","end":"3:20","startSec":165.0,"text":"actually set things in your project settings for forward rendering, which is kind of convenient. So looking at ray tracing in Lumen, this is suited for complex effects, GI reflection, refraction, and soft shadows. Now refraction is limited. You won't get the same as you would with ray tracing. You'll have to fake some of it, but there will be some ability that you have in here to simulate some of those options. But again, full caustics and refraction, you're going to get from Path Tracer. It's easy to implement when it comes to ray tracing in Lumen. It's more intuitive, reliable, realistic, and mimics light's behavior."},{"start":"3:20","end":"3:54","startSec":200.9,"text":"Only Lumen is optimized though, keep in mind to be able to be used with ICV effects. Ray tracing leans more towards final pixel. That's because it takes a pretty big hit on your GPU. Now Path Tracing is not suited for real time. It is not real time, or at least the idea of real time was not in mind when it was created. It's for rendering final pixel projects. Displays a more accurate light refraction and caustic effect, takes longer to render than ray tracing in Lumen due to sample settings used for better quality, and renders each frame"},{"start":"3:54","end":"4:25","startSec":234.7,"text":"independently. It isn't like previous renders, such as ray tracing in Lumen, where if you rendered it in the movie render queue, it typically will reference the previous frame to be able to make the new one. Path Tracer is a bit different, so you have to keep those things in mind and test things out as you go. Now again, that's for another class when we talk about path tracing, and we get into that in our ray tracing and path tracing courses. So when to use them? Again, as I said before, rasterization forward is mainly used for AR"},{"start":"4:25","end":"4:57","startSec":265.3,"text":"and VR, because it's dumbed down to be able to make things work a little bit more efficiently. Rasterization or deferred baking lights, this one can be used in your typical game scenario if you need, and can be used for virtual production if needed. Ray tracing also can be used for virtual production, but it's mainly its focus is on final pixel, such as with movies and so forth. Now we do have some of our ray tracing clients, such as automotive and architecture that will use ray tracing quite often. But again, a lot of the times it's not necessarily"},{"start":"4:57","end":"5:32","startSec":297.1,"text":"for interaction, although it can be used for interaction, you just have to optimize your materials and your items in your scene accordingly, so you get the best frame rate that you possibly can. Lumen is one of the more efficient ways to be able to work, and is now unreal out of the box. As soon as you fire up unreal, you'll see that Lumen is working, and you'll go in there and be able to check off some of the things to make it work appropriately. We go into that into another class, when we talk about lighting optimization. But for the most part, it is ready for ICVFX, and also games, as well as final pixel. Path tracing,"},{"start":"5:32","end":"6:02","startSec":332.6,"text":"like we said before, is mainly for final pixel made for film and TV. And you can keep that focus using it, because it really does give you some high realistic refractions and cost basics, and it's really great to use. So let's go and take a look here at draw calls for a moment. So draw calls here are very important to consider. A package of triangles, and what it is, is a package of triangles being sent to the GPU. The GPU renders draw"},{"start":"6:02","end":"6:34","startSec":363.0,"text":"calls by draw call, not triangle by triangle. So in other words, each mesh material is a different draw call. So as you see here down below on this example, you'll see that this skydome is a draw call. This piece of geo here is a draw call, the floor is a draw call, this other piece of geo number four is a draw call number five. But as soon as you introduce a new material, that becomes a new draw call. So the materials and the geometry are to be considered. And each one, if you have too many or not optimized, you're not been using material"},{"start":"6:34","end":"7:11","startSec":394.9,"text":"instances or merging when you can, you can end up having a really huge scene, which has a lot of draw calls, and that's going to hit your frames. So think of it this way, if you don't do that, if you don't merge geometry, if you don't optimize what materials you're using, if you don't do those things, you can imagine it such as a single image copying a single one gig file versus copying one million KB files. It's going to eat up time. It's going to processing. You want to be able to work"},{"start":"7:11","end":"7:44","startSec":431.1,"text":"efficiently. And again, consider your materials, dumb down your textures as things in the distance, merge geometry, which is, which you can find is okay to do so. It's not maybe something that doesn't animate. It's not interactive. You don't have to interact with. So you have to think deterministically. And that's with games as well as film. So let's take a look at what's being processed here. And we're going to be using a console command called stat unit. Stat unit works really well. This allows us to see our frame, a total time to finish each frame, our game information,"},{"start":"7:44","end":"8:16","startSec":464.9,"text":"C++ and blueprint game play operations, our draw CPU render time and GPU render time. Now we've added a few since this particular graphic, this gives you an overhead of some of the main things you'll be looking at, for the most part. But there are some others, as you can see off to the right, because this once you run this console command, it will show up to your right towards the top. And you'll see a few others in here, such as our dinariz draws, prims, as well as a newer one called"},{"start":"8:16","end":"8:52","startSec":496.3,"text":"our HIT. So let's actually break these down our hit. So frame number shows you the total time your hardware took to render that particular frame. Game thread, this is a C++ as mentioned earlier, blueprint physics and etc. Draw thread CPU render time GPU render time for GPU, R hit R, you can just think of it R is easiest for me. Typically it's RHI thread time is synced to the frame, and it will likely be similar to the frame time. And then RHI stands for render hardware"},{"start":"8:52","end":"9:27","startSec":532.1,"text":"interface, if you're wondering. Next, we have the dinariz. It's not supported unless turned on. This helps to optimize things, especially if testing packaging out. So you can actually turn it on if you need to, and if you need to cater a particular export that you need to send things to and say, hey, I want to see what things look like on Windows and on a Android pad or whatever, I figure with their interfaces for Android. They have their own interface, which is Android. My bad. So sad that I said that. Such a PC guy and a Mac dude. So we have a prims here, the current amount of triangles"},{"start":"9:27","end":"10:02","startSec":567.8,"text":"being drawn. So all these things are set into place to be able to help you look at your calculations. So to better understand how that works, I have a graphic here that shows you the CPU game, game context. And then next we have the CPU mostly draw what to render. And finally the GPU brings all these two guys together and gives you our final pixel. So you can kind of think of it that way. And have another graphic up here, which kind of breaks that down just the same to make it a little bit easier to understand. So in other words, the game threat computes the data in the world"},{"start":"10:02","end":"10:35","startSec":602.5,"text":"to know where everything is. The draw thread calculates what is on screen and then what can be called. And the GPU thread is set to draw calls for any meshes that were not called by the draw threat. So the bottleneck you can hit long thread times can create bottlenecks and reduce frame rates. So if you have stuff that's unnecessary, that you were bogged down, you're saying this is the thing you have to think about if you're coming from a movie background where you're throwing everything at Maya, unreal, you have to be deterministic. You can't throw this chicken"},{"start":"10:35","end":"11:08","startSec":635.5,"text":"and the chicken, the kitchen sink at it, because you want to be able to think what is it that you need? What are the hero objects? What is the primary focus? And you have to come in with a game plan and focus on making the higher resolution, the higher poly for those items and things in the background can take a hit in the texture department. You can merge when you need to, nobody's interacting with it. And this also goes for games. You just got to think deterministically how you're going to approach things. So you can think of the calling this way. You can see here that it's only"},{"start":"11:08","end":"11:42","startSec":668.7,"text":"unreal, only draws what's in front of it as where that camera is moving. It's not going to, it doesn't draw everything at the same time. It's just an efficient way for Unreal to work. Now there are different calling methods and you can turn these in and you can use a calling distance volume if you want to. And we're going to go briefly over that, not too much in the film department. You don't use it as much and Unreal works pretty well without necessarily needing it, but there will be times where you might need it on a more game centric workflow. We see here we have the view frustrum"},{"start":"11:42","end":"12:16","startSec":702.5,"text":"calling uses the visible screen area of the camera field of view FOV to call objects not within this space. Professtrum is a Pyramedal, I got to get that word right, Pyramedal shape that includes endear and far clipping plane, which defines the closest and farthest of any object should be visible within this space. All not to be, all not in view removed. So it's basically kind of, let me go back to the last slide we talked about. It's again only going to draw what's in front of that camera or"},{"start":"12:16","end":"12:50","startSec":736.4,"text":"that view. Even as you are working in the editor, if you're just using a perspective camera, it's going to do the same thing, which is super convenient to work with. All right, so there's precomputed visibility. Now all these things you can actually adjust in your settings if you need to, and that can be helpful in the cases of lower level hardware. So let's go on to the next one here. There's dynamic occlusion, dynamic occlusion system is what Unreal is primary working with right now in Unreal 4 and 5 and comes with several calling methods to choose from. So again, you can query"},{"start":"12:50","end":"13:25","startSec":770.2,"text":"these, you can change these. I prefer using the defaults. I really will rarely ever have to mess with these because Unreal just does a really good job and really relies on you to be efficient with the way that you are making and creating and crafting your scene. So just think efficiency, just think hero objects are the ones that get the most texture, they get the most polycount, they get the most love in your scene and everything from there can degrade and be lesser. Now we all know that directors, we all know that game heads will actually want those things to"},{"start":"13:25","end":"13:57","startSec":805.7,"text":"change on the fly, just be prepared to swap them out if needed to prevent bloat. But for the most part, if there's a game plan, a game level design, if there's a game plan for the film, knowing what the objectives are, you're going to be working pretty nicely with the system in place. You can see here kind of how it works and how the camera frustrum is shown here and you can actually see it. Now this in previous versions of Unreal doesn't always show up to the party. So if you find in 5.3 doesn't quite show up, don't worry about it. It's just a demonstration of what that view is"},{"start":"13:57","end":"14:27","startSec":837.3,"text":"as it increases. I found in earlier versions of Unreal this wouldn't always show up and wouldn't always update as you changed that frustrum. So we're going to go and take a look at some profiling, some quick tools to be able to profile and see what's going on in your scene. This includes the profile GPU. Let's go to Unreal to see that up close and I'll point out a few things. So in Unreal, we're going to go and activate profile GPU. I'm going to hit enter."},{"start":"14:27","end":"15:01","startSec":867.9,"text":"You'll see it pop up. Mine kind of went off screen. Let me pull it over for you so you guys can take a look. So what is happening here is Unreal's taking a snapshot just for a brief moment of my scene and where I'm at. I do recommend if you are going to use this tool to make sure that you create a bookmark of the areas that you want to analyze for that brief moment. This snapshot here you can save if you need to and it will allow you to go in here and you can analyze each one of your frames and see what might be giving you some trouble. The yellow areas are going to be where the"},{"start":"15:02","end":"15:37","startSec":902.6,"text":"most trouble we're going to have. Now we don't have a lot of fog in here but if we had fog, looks like I moved some things. If we had fog, it would be a bit or at least had it heavier. That would be the bigger draw call or issue we may run into and I can do a quick search if I wanted to in my scene for exponential height fog and I can see for that brief second what my millisecond were giving me overall. You'll see that it took a snapshot here just a couple seconds here and you can again how the bar works is it takes those scene elements and it gives you a computed"},{"start":"15:37","end":"16:07","startSec":937.4,"text":"breakdown color coding where your trouble may be. So let's actually go and look at this a bit closer in our slides and we're going to go and look at a few other ways to do profiling. Now again you don't have to use this method. This is just one of many because it tells you right here in our track here what duration, what milliseconds took up the most time to calculate and then you can find out oh I can see where my issues may have occurred and in this case it's the"},{"start":"16:07","end":"16:38","startSec":967.7,"text":"ray tracing dynamic update. We can open that up further and we can see where those issues may have occurred. Now you can a clap scenes at any time but you'll notice then the build here is a ray tracing dynamic geometry update here and this took up the most time. Basically we have a lot of geo in here so if we needed to we could do a bit more merging if we needed and even use some cards for some of our land items they don't have to be full on nanite geometry. All right let's go back"},{"start":"16:38","end":"17:11","startSec":998.5,"text":"into the slides. So again the profile GPU command allows you to quickly identify the GPU cost of the various passes sometimes down to the draw calls. The data is based on GPU time stamps and is usually quite accurate. Certain optimizations can make the numbers less reliable and it is good to be critical about any number. So in other words I wouldn't just use it by itself it's great for a quick look where the trouble's at but you definitely want to look at such things as insights and a"},{"start":"17:11","end":"17:50","startSec":1031.7,"text":"few other things I'm going to show you to analyze things overall. Drivers tend to optimize shader cost a few seconds after using the shader. This can be noticeable and it might be useful to wait a bit or measure another time to get more confidence. So again the snapshot is a disadvantage here because you might want to compare a couple of snapshots together to see what you're getting and this is why I emphasize maybe using other ones on top of this because it's good for a quick look but necessarily not necessarily for a deep dive on what's going on. So overall how to use it"},{"start":"17:50","end":"18:19","startSec":1070.1,"text":"we again we placed the camera we made sure that we bookmarked it we ran GPU a profile GPU we typed that in the command line and it gives us a snapshot of what's going on and again good to bookmark like I mentioned before. Floating your cursor over the largest of the recorded bars shows you what is taking up the most hits again this larger bar here and it looks like it's going to be our fog. I did say the color before it's mainly the larger bar versus the color"},{"start":"18:20","end":"18:58","startSec":1100.9,"text":"and in this case it's the volume metrics so in this case it definitely is hitting a bit more. As you can see you can do a comparable as I move around you can see our our sections are seconds here milliseconds and you'll see that 1.15 in this particular case is eating up the most time. And again clicking on it gives you the duration time to the process listed below. So let's go ahead and take a look at another one called stat GPU. This is going to give us a nice overview gives us like an overlay and milliseconds showing us what's eating up most of our GPU processing"},{"start":"18:58","end":"19:34","startSec":1138.9,"text":"time and calculation and it will give us the minutes the min the max and the overall average and then you can actually get a quick real-time response and see what is going on. Now you can run the stat stat space GPU or you can simply go to stats advanced and you'll go all the way down to GPU here on the bottom. Let's go and take a look at it in Unreal. So I'm going to go to my Alpalog. I'm going to type in stat space GPU. Sometimes it might take a"},{"start":"19:34","end":"20:11","startSec":1174.5,"text":"little bit of time to come up. You can now see here it is calculating for us letting us know what's eating up the most of our time. We have our space probes there just sitting there waiting for our information. As we move around you can test and see what those calculations are. Pretty nice to be able to have that. You can say oh you know what I am noticing that things are a little bit heavier here when it comes to our Lumen scene probe gathering. I think a little bit heavier here"},{"start":"20:11","end":"20:44","startSec":1211.4,"text":"when it comes to our volumetric clouds maybe a bit. So that gives you a quick rundown of things. So I go to my output log here. I'm going to hit my up arrow and we're going to turn that sucker off and it's simply just inputting that one more time and I'll just then enter. There we go. That's it with this one. In the next video we're going to take a look at CPU draw threads and we're going to look at Unreal Insights. Thanks again."}],"03_CPUDrawCalls_UnrealInsights":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In this lesson, we'll take a look at viewing CPU draw threads as well as looking at Unreal Insights. So let's get started. So the CPU draw threads, what goes on here when you actually run this display, it handles most of the occlusion processes. It decides what is visible or not. And it'll do this in real time as you move your camera around. It happens per object, not per triangle. You'll look at your distance calling. There's a frustrum calling as well as your occlusion calling being looked at."},{"start":"0:32","end":"1:04","startSec":32.3,"text":"The console for that is stat init views here. And you'll see also in stat menu pull down, you can also access it if you don't want to use the console command. So you can also grab it there. So if we go into the next slide here, you'll see it is broken down into two different sections. The first one being the cycle counters. Here you'll see the view visibility. That's the amount of the frame time spent to process actor visibility queries. Occlusion call, the amount of frame time spent to query the scene for the actors within the"},{"start":"1:04","end":"1:34","startSec":64.2,"text":"view frustrum that were occluded by other actors. We have the frustrum call. And we also have decompress occlusion. Now there's a few more that we've added as you go through here and you can actually see what's going on looking at your milliseconds, what may be causing a slowdown in your system. That's really why you want to look at this. You're seeing what the CPU is doing to calculate things. It's almost like you're going in between the calculations between the CPU and the GPU final output."},{"start":"1:34","end":"2:07","startSec":94.8,"text":"So you can actually see where there may be a hold down in the system. The second section looks at the counters here and we have the process, primitives and frustrum call primitives, occluded primitives, occluded queries, visible dynamic primitives and visible static mesh primitives. Now if we go to the last one here, which is our cycle counters, you'll see I just gave you a few here. There's quite a bit in here so I didn't break them all down. But I gave you some of the key ones to look at for the most part. And you can go in here and see how things are being digested overall."},{"start":"2:07","end":"2:38","startSec":127.3,"text":"But these are some of the key factor ones if your milliseconds you're noticing that things are taking a bit longer. Now this will take an account anything with your CPU that's mainly being digested and running into some problems. And this will also account if your blueprints are running into here, some issues or your C++ maybe you made a particular plug-in that's working in your system. You can actually see if those queries are also messing with the other things that it's calling upon. It's basically looking at the middle of the chain and trying to see where those holdups"},{"start":"2:38","end":"3:10","startSec":158.6,"text":"might be. So the next one we're going to take a look at here is also you can look at your draw calls here using a stat RHI. These can also be punched in the console command and it will pull it up. And again it will be like an overlay in your system and as you move your camera around it will tell you exactly give you an update of what's going on with your minimum and maximum pull on your system here like milliseconds wise what is actually causing things to go"},{"start":"3:10","end":"3:42","startSec":190.6,"text":"to a crawl. Currently Unreal has a dynamic instance scene system making it easier to have more items in the scene. If the actor shares the same geo and material and this is why we talked about this in the beginning it gets drawn as one draw call. To see how it works you can use the command mesh draw command dynamic instancing 0 for off and 1 for on. So this is all up to you how you want to process that. Now if we go briefly into Unreal you'll see that we're actually running at a pretty high frame rate. In the beginning I think just things were calling and things were getting into in the"},{"start":"3:42","end":"4:16","startSec":222.8,"text":"system. It was a little bit slow but we're actually at a pretty good frame rate right now. So in our scene if I go up here and I click on here you'll see show frames per second. We're running at 7670 frames per second. If you do get this landscape error because this is a bit of a bug currently what you can do is actually hit play. All that play for a second. I don't even have to necessarily run around and then hit escape to get out of there. And typically this should go away but it looks like it doesn't want to go away."},{"start":"4:16","end":"4:47","startSec":256.8,"text":"But that's usually how you would get rid of that. So you'll see we're going at a really good frame rate here. Let's actually run those stats here. So let me get rid of that trace stop for a second. We'll reference that just a bit. We're going to go to a stat and it views. There we go. Now we're looking at our CPU draw thread here. And again you can move into your scene and take a look at where things may be a little"},{"start":"4:47","end":"5:21","startSec":287.6,"text":"bit odd in the hold up here. Now again these are just multiple tools we give you at Epic Games to be able to work with these things. You don't have to necessarily use them but we want to give you options in here. Let me hit enter to get rid of that one. And let's go and run that other one. Let's do that stat. RHI. And again you'll see this one here. Take a look again at our GPU memory pool."},{"start":"5:21","end":"5:54","startSec":321.2,"text":"And it's giving us an average letting us know how things are being drawn. Triangle, triangular wise. Looking at the triangles. I can't talk. But you'll actually be able to get a good analysis of what's going on and millisecond wise where your hold ups might be. Now let's take a look at another way to analyze your scene using Unreal Insights. This is using the trace system. Let's talk a bit about that and how that works. And how using the Unreal Insights is actually pretty efficient overall."},{"start":"5:54","end":"6:26","startSec":354.3,"text":"There used to be other systems such as session front end but now it's a little bit fractured and there's some aspects of it that are deprecated so it doesn't quite work the same as it used to. Now you can't analyze things and check for bugs kind of but you won't be able to analyze them on the same type of level that you get here with Unreal Insights as you used to. So data here is collected from a runtime using the trace system that we've developed. That Unreal Insights will look at the trace server and look at the application and look"},{"start":"6:26","end":"6:58","startSec":386.2,"text":"at the game. So the structured event logging, it's high performance, low overhead. And what it means by low overhead, you actually have this works in within a reel. It actually works as an EXE standalone type of function inside of Unreal. So you don't have to worry about having the editor in the background and giving you kind of bad data because things are being digested as you're in the editor at the same time as trying to check for any kind of problems going on in your scene slowdowns."},{"start":"6:58","end":"7:30","startSec":418.4,"text":"So it acts as a standalone and works actually pretty efficiently. It can be activated again as you see from the bottom menu there and I'll run you through that in just a bit and I'll talk a little bit about the menu in Unreal as well as look at some of the points of the menu that I have in our slides. So again, how the system works. We have the game editor, we have a trace API. This is going to be looking at whatever host directory you can choose. It's up to you. I'll point those things out to you. You can run a trace file if you want to via console command."},{"start":"7:30","end":"8:02","startSec":450.8,"text":"Heck, you can even run a trace file in your Windows console if you want to. It's up to you. But for the most part, you can run it via Unreal and it'll act as an individual EXE if you wish. So you have several options here. So Insights works just like an EXE and you'll see there's a session browser UI here. That's again acting like an EXE. It's almost like a one to one. We have a trace server. You can run the trace unrealtraceserver.exe or Trace Store here, which is the equivalent"},{"start":"8:02","end":"8:33","startSec":482.9,"text":"inside of the interface. And it will use a UTrace file that it's going to read and write to. And eventually when you launch, Unreal Insights is going to analyze things and your Insights viewer, Unreal Insights EXE is going to trace and analyze things overall. And all these things are kind of built into the UI now, which is actually kind of nice. Before you would run the EXE, it would run the UI by itself, but now we have it built into the editor. So it acts like an EXE."},{"start":"8:33","end":"9:07","startSec":513.7,"text":"So it actually is pretty efficient. So here are some things to consider. So Unreal 5 Trace Center for Enabled Channels is catched and the Always On buffers. So we have trail tracing plus import events. So it's really going to be there for you to actually look at where your milliseconds are being hit. What is bogging down your game? Also slash, say you're sending things to the wall via ICVFX, you're like, man, I don't understand what's going on. You can actually trace that, but not only can you trace that, you can actually, on one"},{"start":"9:07","end":"9:38","startSec":547.9,"text":"level GPU, you can also do CPU. So you can do both at the same time. So you'll see command line arguments here that you can choose once, you can choose where to put it, and you can choose where that file is going to go to, per se. And it will be sent to a trace server or to a file. And again, this is up to you how you choose that within your pipeline, working with your IT team. Do you have a server or are you all analyzing a particular scene that everybody can access? It's up to you."},{"start":"9:38","end":"10:08","startSec":578.3,"text":"Are you a small indie house or it may not be as big to grab it, but you can actually still place it in a certain area. And then you can also use that data. You can grab that scene to analyze it from your desk if you needed to. So Trace is a structured login framework for tracing instrumentation events from a running process. The Unreal Trace server is run in the background as a single server instance and can be shared between multiple projects or branches. And this is what I mean by that."},{"start":"10:08","end":"10:42","startSec":608.7,"text":"So it is a lightweight program that has minimal impact on performance and does not include, a user interface. So that can also be run here. You can do and you'll see it's launched by separate server process executable. Unreal Trace server.exe located in the engine binaries, Win64 directory folder. So running this trace system, we can run it through Unreal Insights, but also if you needed to, you can run things individually if you even want it cleaner. But overall, we have it pretty set pretty nicely using Unreal Insights to be able to"},{"start":"10:42","end":"11:13","startSec":642.3,"text":"actually work really well. But again, the Unreal Trace server can be placed and even isolating things a bit more to be able to analyze your overall scene. So the Trace system. The Trace server has two functionalities. The Trace recorder listens on port 1981 for incoming trace in connections and records the live trace stream. Number two, the second point here, the Trace stores the recorded traces as a file to a path like users."},{"start":"11:13","end":"11:47","startSec":673.3,"text":"Users API data, local engine, common Unreal Trace store. It watches this folder for changes and exposes a list of available traces to Unreal Insights. So this trace is being accessed through Unreal Insights. Unreal Insights uses this Trace system. But again, like I said on the previous slide, you can run the Trace system by itself. I don't really know in what cases you might do that. That's really up to you. You may just want to isolate things a bit more if you want to. But I liked being able to use the Unreal Insights and accessing that information because then"},{"start":"11:47","end":"12:19","startSec":708.0,"text":"you have the full interface to be able to filter out what the data that you need and what you need to look at. So just keep those things in mind. All right, let's talk a little bit about the interface here. And then we're also going to go back and forth between Unreal. I'm going to pop into Unreal and then we'll go back and reference these slides. So ignore my error here on the top here. This is a bit of a bug. Usually you hit play, like I mentioned earlier, and you run around and hit escape. It usually goes away. So in this case, it doesn't want to and that's fine."},{"start":"12:19","end":"12:52","startSec":739.8,"text":"So we find our trace here information. We can even start a trace individually without pulling up Unreal Insights to make sure everything's in order. We could just quickly run a trace if you want to. Again, you can still look at it through Unreal Insights, which is nice. It's basically just jumping the gun and not doing it through the interface. You go straight to the button that does the trace. Now you can set into a file if you needed to or trace store, which is the directory that you choose. So in here, I'm going to choose my Unreal Insights."},{"start":"12:52","end":"13:24","startSec":772.4,"text":"So I can show you a little bit of what I'm talking about. So in here, we have a series of traces that we already ran. Now you're probably wondering, why are some of these pink? Well, that's because earlier versions of Unreal, this wouldn't always stop like what you wanted it to. You would do a trace stop or in this case, if I go to the output log at the up arrow, you'll see a trace stop. It used to be used to be able to do stop trace and trace stop. And there would be a little bit of a delay. But in 5.3, we've kind of weeded some of that out."},{"start":"13:24","end":"13:55","startSec":804.2,"text":"So that's less of an issue. So let's go and pull this up again. So again, it's going to give you a full log directory of all the traces that you've run. Now you can choose platforms if you need to. There's an app name here, config. There's some very minimal type of viewing filtering you could do and versions of Unreal. So all that is available there too. So what I can do here is also I want to make sure first up I want to check my connection. Am I going to a server? What is that IP address?"},{"start":"13:55","end":"14:28","startSec":835.1,"text":"What is the initial channels? And you want to check if you can connect. So you see we are successfully connecting, which is great. And that allows us to do a trace. Now once you've created a trace again, you can open a trace. This is doing a live trace currently. If I double click on it, it's going to show me the process as it is running. And let me open this up a little bit so you can see what's going on. So now it's running a trace. I do advise moving around your scene if you can. And that way you can see if the player or your camera in ICVFX is giving you a bit of a slowdown."},{"start":"14:28","end":"15:01","startSec":868.3,"text":"Let's go back to Unreal Insights here. We can see that's running. Let's go and stop that trace. So I'm going to go to my output log. I'm going to go ahead and delete this and hit the up arrow. And we're going to go to stop or trace dot stop. And I'm going to hit enter. Now I'll go back to Unreal Insights. It should have stopped. Yay, it did. And that's good. We can now zoom in on any areas of data that we need to. And you can highlight and see, hey, you know, what is the issues that are occurring with my scene?"},{"start":"15:01","end":"15:32","startSec":901.9,"text":"You also have down below here, we have a log. Now you can filter all of these if you just want to keep it a little bit cleaner. Like say, I don't want to look at my frames. I don't want to look at my timing. I can turn that off. I don't want to look at my timers. I can turn that off. I can look at my callers. Say I don't want to see all those in here per count. If I wanted to, instant count, number of selected items in here, you can double click these at any time within your listing here. Let's go to GPU specifically. Turn off CPU."},{"start":"15:32","end":"16:05","startSec":932.4,"text":"And I'll say I'll look at my lights. I'll double click on my lights. It'll give you a color code of what it is in the scene. You'll see there's an info here as I slide over. Tells me the ID for the lights, the GPU, and it gives you a mini rundown of what's going on here. Now I can go in here and isolate data if I want to. I can zoom in on a particular area of data and I can double click on that area. So let's look at a spiking area. This is a little spiky here. So let's go on. What's the issue here? So I'm going to click on this game frame here and see what it is."},{"start":"16:05","end":"16:36","startSec":965.1,"text":"And I can zoom in on it if I want to and analyze what's going on. And Unreal's giving me a section of data that's being processed for that particular region here. It's actually kind of nice. So this is really great to be able to get a handle on this. And then you'll see the callers come up here. Now they are populating. So again, we have the log two. This will tell me and give me a little bit more data of what's going on. It tells me what my console commands are, where my errors might be occurring. In here, I typed in a trace stop versus a stop trace."},{"start":"16:36","end":"17:10","startSec":996.9,"text":"I think that's always re-invert those. I did a stop trace versus a trace stop. So, but my log is letting me know that that was put in incorrectly and letting me know any errors that may be occurring. So again, you have the session information here tells you where things are, how things are being handled. And then we also have the timing insights here. So all of this can be analyzed and I can move these around if I need to. And I can highlight regions and you'll see this come up and give me my caller information."},{"start":"17:10","end":"17:40","startSec":1030.6,"text":"I'll look at my direct rendering there, my shadows in here if I need to. And this is based on my highlights. So I'm going to click on this, the bypass here, and it's going to pull up the callers again. Show me what's going on with it milliseconds where I'm being hit and say, hey, lumen reflections. Is that giving me trouble? I can see that it's actually not too bad and gives you a full analysis of things. And again, you can choose CPU and GPU if you need to and you can walk through that."},{"start":"17:40","end":"18:14","startSec":1060.9,"text":"So let's talk a little bit more about the interface here in the slides. And I'll give you a quick walkthrough here of how you can analyze things and get up and running a bit faster. You can see here again, it says where, who and what are you analyzing? If we go here, you can run Unreal Insights via the Unreal EXE. We talked about that. If you choose to, it's up to you. You can do it through Windows console commands if you need. Both are very valid and Unreal has it nice and cleanly in the menu, which works like an EXE if you need it to work."},{"start":"18:14","end":"18:45","startSec":1095.0,"text":"So you'll see the interface here a little bit more broken down for you. Talking about how to use this again, there's a trace store and there's a connection. And also what and where we talked about that. So I broke this down for you in the slides so you can actually get a little more acquainted with it. Note for games, you can run Insights and keep it open while running your game for a performance trace. When doing so, you can run Insights via EXE or via a command prompt. So you can do that through the Windows command prompt. So emphasize on that again."},{"start":"18:45","end":"19:16","startSec":1125.3,"text":"If you wanted to analyze that in an actual build. So again, the interface breaking it down here, again, we saw the log. We saw how you can look at the data up close. We see that you can look at the timing panel overall. All these things can be filtered the way that you need. And again, you can look at GPU, CPU, and then look at the callers based on what you have selected. So here are some of the commands to work with this. We have trace enable, trace disable, trace pause, and trace resume."},{"start":"19:16","end":"19:47","startSec":1156.2,"text":"You have trace send, you have trace file, and you also have trace stop. And then we also can look at your trace status, where things are at. And it'll give you a quick brief breakdown there of how things are. So how to read it, groups. You can also group and isolate data. They may be at times a refresh issue requiring you to close in real and unreal listeners temporarily. This is particularly for ICB effects or switch for it to get insights to reopen and sometimes populate data."},{"start":"19:47","end":"20:18","startSec":1187.8,"text":"Now this is less of a problem with 5.3, but it was a problem with earlier versions of Unreal where sometimes things would get a little bit delayed. It also may fail to execute inside of the editor and the EXE will need to be used if you ever run into that. But it should not be a problem at this time with 5.3. But be aware if that occurs, that's a solution for it. Unreal Insights in Unreal now works like an EXE, like I said before. So again, it actually is nice and clean and has a nice little standalone"},{"start":"20:18","end":"20:46","startSec":1218.3,"text":"workflow specifically for ICB effects that works great. But again, you can run it as an EXE or Windows console if you want to run it while you're playing your packaged game. Here's a few more links here to help you get on that vein of thought here, working with Unreal Insights. And a little YouTube video we had a while back about testing and optimizing your content. Thanks again with this one. In the next video, we're going to look at optimization visualizers when it comes to analyzing your scene."}],"04_Visualizers":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this lesson, we're going to take a look at optimization visualizers. So let's get started. So using the visualizers can help you analyze your scene and kind of see what's going on under the hood. Now the optimization view modes you'll see here as the pull down here under lit, and you'll see optimization view modes. There's a lot of these that have to reference not all of it, but some of it has to reference when it comes to old school baking. And that in particular is such things as stationary light overlap."},{"start":"0:31","end":"1:04","startSec":31.4,"text":"When it comes to aluminum, you don't really have to worry about that. And light map density is a bit more on the baking side also. But you do want to look at your light complexity. You do want to look at your shader complexity and quads too. Because that's very important to see how dense your geometry is and how complex your shaders are, which may be giving you a bit of a slow down when it comes to your scene. Now I'll walk you through a little bit of these. This is a bit of review if you've taken the lighting courses. But I'm definitely going to point out some things you do need to consider. So you'll see that there's light complexity for debugging dynamic light overlap."},{"start":"1:04","end":"1:36","startSec":64.5,"text":"There is light map density, which we'll talk briefly about that if you are using the baking route. I do recommend you try to find your home or try to find your workflows a little bit more towards aluminum. The baking is great, but there are some limitations for realism. But on the flip side on aluminum, there are moments where noise is still persistent. And it is evolving and getting better, stronger, faster. So let's go ahead and jump into Unreal. And again, you'll have stationary overlap, shader complexity and shader complexity quads and quad overdraw."},{"start":"1:36","end":"2:07","startSec":96.1,"text":"I'm going to look at these with you and point out things to be considered when it comes to baking versus just using Lumen. So let's go and do that. So in our scene here, we have lit and then we have our optimization view modes. We can look first up at our light complexity. Now again, this leans a little bit more towards baking because pretty much when you're in Lumen, all your lights are movable. If I click on this light here, I want to make sure that it is movable in my scene. This will allow me in my scene to be able to actually adjust my lighting on the fly."},{"start":"2:07","end":"2:41","startSec":127.8,"text":"And things will react wonderfully. This is great for ICV effects and visual effects when it comes to virtual production. Because you can actually get some updates on the fly and show it to your directors and so forth. And also pretty handy when it comes to games because then you don't have to worry about baking out everything. So just keep that in mind. So that one's kind of a little bit more, you know your lights are complex because you know they're all movable, which is the highest one to work with. And the mesh distance field is on, so it's going to be a bit high already. And again, light map density also has to do with baking."},{"start":"2:41","end":"3:14","startSec":161.4,"text":"So we still have kept it in there because we still have studios that choose to use that for the case that maybe they have a lot of complicated materials. And there seems to be a lot of noise coming through. They actually want to be able to bake still because Lumen still has a little bit of issue with that because when it comes to your, when it comes to like things with high rough and so forth, it's borrowing some of the technology from ray tracing, but there will be areas, maybe some shadow areas that maybe get a little bit of noise and you can adjust those. And we talk a bit about that in our foundation intro to lighting class."},{"start":"3:14","end":"3:46","startSec":194.4,"text":"We talk about Lumen. So this is the light map density. Now note itself, you'll notice it will pop up here. You'll notice that there's a higher resolution on the ground versus the wall. Now, if you were to use baking, I'm going to let you know you need to make sure that both of these are close in ballpark when it comes to your resolution. Now these are pretty different when it comes to Lumen and that's okay because we're not baking. We're using Lumen on the fly. It's giving us our updated shadows and using virtual shadow maps versus light"},{"start":"3:46","end":"4:18","startSec":226.2,"text":"making information. But if we were baking, we would want this to maybe be a little bit higher or the ground to be a little bit lesser. And that what that prevents is you may get some blobby shadows if you don't. So in our case, we're doing just fine because we're using Lumen, but just note to self if you were to use baking, that may be an issue. So just be careful of that. Also, we have stationary light overlap here. This will tell you if any stationary lights are near, we have none because everything's movable, so it doesn't apply to us."},{"start":"4:18","end":"4:49","startSec":258.2,"text":"In our particular case, there's shader complexity. Now this one's always important to analyze because we can see that our land is very complex. Is it in the danger zone? It's kind of in the medium, just something to keep in mind that that is complex. So, but you'll see the terrain and the plant and even our alien probe here. All these are at a relatively decent usability. They're not going to burden us too much."},{"start":"4:49","end":"5:21","startSec":289.6,"text":"So we have shader complexity in quads. This will tell you what your shader complexity is plus if there's high levels of geometry. We'll see that these orbs are pretty dense. So the ones in the back room can be less. Some of the looks one right here, he looks pretty, pretty thick. So we definitely can optimize that. So this scene is available for you to play with as we talk about some of these tools. And we'll talk about geometry when it comes to merging and how you can actually make these a bit lighter and make it so that they still sell and fool the audience."},{"start":"5:21","end":"5:54","startSec":322.0,"text":"And that's kind of what's important. You want to smoke and mirrors people even in games and film. You want people to believe that your scene is doing what it's intended and none is the wiser that you're actually fooling the audience. So we'll talk about that later. We have quad overdraw overall tells you where the dense meshes are at in here. And there's a good amount on these orbs, but you'll notice the ones up above are a lot cleaner. These I merged and made a lower levels of detail. Now see it's a proxy and that actually is better."},{"start":"5:54","end":"6:25","startSec":354.5,"text":"And no one new knows that until I pointed out. Cool. All right. So there's a few other things here you see texture streaming accuracy. You can check for these primitive distance mesh UV density, material, texture scales. You can actually use these tools also to check for your even also your virtual texture pending MIPS. We don't go over to this too much in this particular class, but these are also things you can use for streaming accuracy. We will talk about getting virtual textures up and running here in just a bit."},{"start":"6:25","end":"6:58","startSec":385.2,"text":"But again, these can also be used to check a few things. But for the most part, I'm going to show you that workflow working with virtual texturing and things to look out for them. So I'm going to go to lit mode here. Cool. So let's go ahead and get back to the slides. So quad overdraw best practices. Use the quad overdraw viewport mode to profile the scene. Any green or worse should be avoided to keep costs low. So blue is ideal. So if you get like this really dense green, that's not so great or is this solid?"},{"start":"6:58","end":"7:29","startSec":418.4,"text":"That's what made my worse. You know that it's a really dense geometry and you probably could lower it. Now, again, this depends on the output. Where are you going? Are you working in games or you're working in film? If you're working in film and it's just virtual production, you want some final pixel work done, you may not have to worry about that. But if you're going to the LED volume wall, you want to go ahead and think about how you're going to maintain that because you want to make sure that you don't have too heavy of geometry as your cameras moving around because you have to take"},{"start":"7:29","end":"8:00","startSec":449.1,"text":"an account to draw calls not only on the geometry, but also on your material. If a mount only fills 100 PX by 100 PX on an LED wall, then that mountain doesn't need to consist of 2 million triangles. You can even have a facade. You can have it so that's on a card if you needed to. The same optimization practices apply for textures. The GPU might not load an 8K texture until it's in the camera's direct view. So you have to determine where that direct view is."},{"start":"8:00","end":"8:34","startSec":480.8,"text":"And if you do need a full piece of geometry, you may even have hollowed out geometry, a card which is bent, but there's an alpha on top of it. We used to use that trick all the time for plants. Just bend that card, have some vertices and edges to be able to manipulate it. So now the plant looks like it's more robust than it actually is. It's just bending a card and adding more systems to it or more divisions to it. Best practices avoid too much translucency, especially large translucent areas and overlapping translucency."},{"start":"8:34","end":"9:03","startSec":514.6,"text":"So just be careful with that. Use masked materials instead of translucent when possible due to the lower performance cost and avoid dense meshes built for your screen size. So again, like I said before, build to your shot. So quick notes. Buffer overview can give you a quick visual rundown of the different G buffers being rendered. Let's go and take a look at that really quick in Unreal."},{"start":"9:05","end":"9:40","startSec":545.6,"text":"All right, so if we go to lit again and I go into here and look at buffer visualization, you can look at the overview. And this kind of gives us an overall view of our scene showing our subsurface colors, specular base, world normal, separate translucency, RGB, what does our opacity look like? What does our shading model looks like? Metallic. And it's really nice to get a quick rundown of everything in your scene. Since we're in Lumen, let's take a brief look at Lumen visualizers, nanite and virtual shadow maps."},{"start":"9:40","end":"10:10","startSec":580.6,"text":"Now we've did this for some of our foundational classes. When it comes to lighting, introduction to lighting, and we jump into that in some of our other lighting classes going forward. But I'm going to walk you through a little bit of this so you can understand how this actually works. So in our scene, let's go back to Unreal. We're going to go ahead and go to lit and we're going to go to nanite visualization. Now if I do an overview, you'll notice we don't have anything to look at. But let's go and turn that off for a second."},{"start":"10:10","end":"10:40","startSec":610.6,"text":"And let's actually convert some of these to nanite because nanite works really well when it comes to using Lumen and virtual shadow maps. So making things nanite is not a bad idea. We have a piece of geometry up front here. Let's actually find where he's at. And let's actually right click on this particular piece of geometry and go to nanite and turn that on. So when we turn that on, we can also pick on this guy, find where he's at. I think it's pretty much the same one. Yep, it is."},{"start":"10:40","end":"11:13","startSec":640.6,"text":"So let's go and grab this piece of geometry here and convert that to a nanite object. Right click. And it's really that easy to turn on nanite. Now there's a few hoops and other versions of Unreal, but in this particular version of Unreal, it's pretty straightforward. Now for some reason you're not sure it's nanite. You can go back and check it. It didn't populate the tick box when I clicked on it, but it actually was on. So we see that that's on. So now when we go to our viewer here, we go to lit and we go down to nanite visualize."},{"start":"11:13","end":"11:48","startSec":673.6,"text":"We go to overview. It's going to show us the calculations for these as I move around in 3D space. It's going to show my triangles being calculated and you'll see them flip and flick as I get closer and farther away to them, which is actually Unreal sort of it and only pulling up the best possible visual fidelity images on that object based on my positioning in 3D space. So being able to view these ahead of time is really great. So the overview you can use or you can choose to go in here and say, hey, I want to look at these individually."},{"start":"11:48","end":"12:21","startSec":708.6,"text":"You can something I want to emphasize though, when you're working with a scene such as this, you do want to work with nanite and you do want to work with virtual shadow maps and you do want to work with Lumen. They're the three musketeers. We made them so they work really nice together and they're efficient. So keep those things in mind. Working with them are really great. If you don't do that and choose to use LODs with your virtual shadow maps and with your Lumen,"},{"start":"12:21","end":"12:55","startSec":741.6,"text":"you could get a hit a bit on your performance. And again, the reason why is Lumen and virtual shadow maps and nanite all work together efficiently to only bring to the camera what the highest visual fidelity based on the position of you in the 3D world. And it is one of the most efficient ways to tackle things. Now I want to point something out really quick here. This is more of a migrate issue. It's a little bit segue, just a tad and then we'll get back into the view modes for like Lumen and so forth."},{"start":"12:55","end":"13:25","startSec":775.6,"text":"Now you may have noticed in the earlier shots, like some of my rocks looking a little bit dull and not quite having the texture information. That's really just a transitioning between 5.2 and 5.3 because those had worked before. They had made a blended material for me to use. Unfortunately, sometimes when you update in migrate, a object which is merged, you do want to do that. You do want to double check that because it may not work anymore. And in that case, you could repull your geometry in and reemerge them."},{"start":"13:25","end":"13:55","startSec":805.6,"text":"In this particular case, the blend material doesn't quite work with this particular piece of geometry. So if we find this piece of geometry, we find them here. This is the merged piece of rock. It's several different things together. At this point, I can just remove it and just replace it. So just be aware that that may occur sometimes. That's a little bit of the texture optimization stuff, but I'll emphasize, reemphasize those things with Ron as I talked to you about them. Because it's something to consider where things can go a little bit south as you go to a new version."},{"start":"13:55","end":"14:26","startSec":835.6,"text":"And there's a there's a merged material that may be a little bit more complicated. That becomes a problem when it comes to migrating sometimes. You want to keep those materials pretty simple. And also when you're updating your files, take a look at those and see those things in there. So let's analyze this real quick here again, using some of those viewers. The next one we have here is Lumen. So we can do an overview of Lumen too. This is going to show us a few things that will show our geometry normals and those things are being processed by Lumen."},{"start":"14:26","end":"14:58","startSec":866.6,"text":"We have reflection and view hardware ray tracing. And then we have Lumen seen pink missing surface catch coverage, yellow, cold surface catch. So you'll see any issues that may be occurring. So even though those are being marked and tagged here, we're actually not really having any major problems with them. But again, Lumen tries to bring those things to your attention. And let me explain what that means. So areas that don't have surface catch coverage are colored pink in the surface catch view mode."},{"start":"14:58","end":"15:28","startSec":898.6,"text":"Now these areas will not bounce light and will appear black in reflections. Issues like this can be fixed by increasing the number of cards used with Max Lumen mesh cards. But not always. So if you do run into more problems with them, it's best to maybe break them down into smaller pieces. Just be aware of that. Now again, that's a bit more on the lighting optimization, which we'll get into another class. But I wanted to point out what that meant."},{"start":"15:28","end":"16:01","startSec":928.6,"text":"And finally we have here, we can go ahead and look at our virtual shadow maps. I'll look at our shadow masks in here. We can actually take a look at how things are being digested in our scene. If we're going to have any issues. Overall, what you're looking for is just a visual representation for areas that you see that are not doing their job. You'll notice everything is actually working the way that we want. You'll see the colorization happening as we move around. That is unreal, making sure that it gives us the best possible shadow quality the closer we get into our scene."},{"start":"16:01","end":"16:37","startSec":961.6,"text":"Things in the distance, you'll see they're a bit lighter and we don't have to worry about them as much. But for the most part, it's really just making sure and it's not giving you clear data. It's just giving you a visual representation. And you have to look at all these kind of with a grain of salt. You can look at them. They'll give you a visual representation. The Lumen one is a bit more easy to read and understand versus some of maybe when it comes to our virtual shadow maps. It's a little more, it's doing the same thing and the fact that it's showing how it's digesting as we're moving around our scene."},{"start":"16:37","end":"17:09","startSec":997.6,"text":"You'll see the color process. It's basically showing you how it's handling these cards. We're way out past the water at this point. But it's only drawing what is needed. The white stuff is like the most minimalist and you'll see the blue it's calculating almost on an LED type of level. We do get into this in more in our lighting class, but I just wanted to point out what's going on when you look at this visualizer. And again, we will actually review some of this in that optimization workflow. Again, we'll go back into virtual shadow maps here. We'll look at our virtual page here."},{"start":"17:09","end":"17:40","startSec":1029.6,"text":"And this again shows you as it's calling upon them as needed. You can think of this as almost like a nanite type of workflow where it's only pulling up and sorting these on a page by page almost like card information on how it's sorting and doing the data for the shadows. It just shows you in real time how it's shuffling through things. And then finally we have catch page here and it's kind of again the same type of idea. All right."},{"start":"17:40","end":"18:10","startSec":1060.6,"text":"Another pro tip you can see here is you can actually use a tool called show advanced mesh edges. This will actually show or put an overlay of a wire mesh over all of your geometry. It's actually pretty convenient, pretty nice. Let me show you how to get there in Unreal and how to use it. So you want to click on under show, go to advanced and you'll see mesh edges right here. That's actually pretty cool and puts it on these objects, but you'll notice it's not putting on the nanite objects."},{"start":"18:10","end":"18:43","startSec":1090.6,"text":"I just wanted to make that point. The non-nanite objects, we don't have it set right now to recognize them. Nanite objects we don't have it set to recognize them, but the non-nanite is actually putting the mesh over that. So just letting you know it's actually kind of nice as you're in the middle of building. But as soon as you convert things to nanite, it's going to not show up to the party, but it is kind of a cool tool. So I just want to show you that real quick. So overall, let's go back to same...let's turn that off real quick."},{"start":"18:43","end":"19:13","startSec":1123.6,"text":"Let's go back to our show. We'll go to our advanced and then turn off that mesh edges. So again, things to consider when working with your visualizers and overall your scenes. Again, like I said, and I say this over and over again, and I will say this continually, because we've had clients run into problems where they're using LODs, they're using Lumen, and they're using virtual shadow maps. And that becomes a very big performance hit specifically with games as well as virtual production, depending on the scale of your scene."},{"start":"19:13","end":"19:46","startSec":1153.6,"text":"So try to keep things kind of in the three musketeers vein where you're working with Lumen. You're working with virtual shadow maps and you're working with nanite. That is the best approach for that. So again, I want to emphasize that as you're working. Now we'll talk about in the next few videos, we'll talk about how to merge geometry, manage that, and I'll show you how you can actually merge even nanite and make things a bit more acceptable and smoother when you're working. Right now we're working at a really nice cool 69 frames per second, so we're doing pretty great."},{"start":"19:46","end":"20:15","startSec":1186.6,"text":"But again, as things start to increase in a popular scene, you have to consider those things. That's it with this one. Here's a link giving you some more a deeper dive into what we talked about. In the next video, we're going to take a look at nanite up close and we're going to look at virtual shadow maps and managing those overall. Thank you."}],"05_Nanite_VirtualShadowmaps":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this lesson, we're going to take a look at Nanite and virtual shadowmaps. So let's get started. So many people ask, like, why Nanite? Why use it? Well, it's Unreal 5's virtualized geometry system. Basically, it's a lot more complex than our regular LODs because we get a higher visual fidelity because it's stored as a hierarchical system of smaller parts using triangles and adds geometric complexity with less issues."},{"start":"0:31","end":"1:04","startSec":32.0,"text":"So it sorts it quite well, and it keeps that silhouette and the higher poly look and feel for that object on a more consistent, believable basis. So Nanite allows for higher visual fidelity and works well with Lumen. So when you're using Nanite, try to use it with Lumen as much as possible. It doesn't mean you can't use it with a regular baked system. It just takes a lot of time, and you may be limited, especially if you need several different higher poly objects. You want to lean towards Lumen and virtual shadowmaps when using Nanite."},{"start":"1:04","end":"1:39","startSec":64.5,"text":"Outside of Lumen, again, like I said before, it can't take a while to bake those shadows. Virtual shadowmaps are used for more high fidelity shadows versus baking shadows. When you bake, you're sharing that information. You're putting it into a texture. It's baking it on the environment, especially for static objects and your static lighting. It's not quite as visually unique and in the fact that it actually brings in more realism. So the suspension of disbelief is better with Lumen, with Nanite, and with virtual shadowmaps."},{"start":"1:39","end":"2:13","startSec":99.4,"text":"So instant object count and draw calls are less of a limitation now, and instances are in the millions versus what we had before. So again, that beats LODs again. So it's more visually accurate than displacement and has a less shadow artifacts. But that doesn't mean you can't use displacement. You can still add it to your object, which we'll talk about in just a second. So the issues that come up with displacement is it's inaccurate because you're actually pushing the object's visual look beyond the original bounds of the object."},{"start":"2:13","end":"2:47","startSec":133.7,"text":"Now if you do run into any kind of flickering or weird drawing issues happening, you can actually go into the object itself and increase the bounds just a tad, just a little bit, that's all it needs. And you can maybe edit some of those. But for the most part, Nanite makes it so that you don't necessarily have to lean so hard on displacement. So Nanite is great for a high resolution model and shadows keeping accuracy and working with virtual shadowmaps. So again, no, Nanite can be used for ICB effects, but baking takes a good amount of time outside"},{"start":"2:47","end":"3:20","startSec":167.8,"text":"of virtual shadowmaps. Lumen, Nanite, virtual shadowmaps are ideal for ICB effects, but also can be used for games, but both you need to be very deterministic as you work with them. So let's go and take a look in Unreal. And I'm going to point out some of the features that we have in here to be able to edit some of your Nanite qualities. Now I'm not going to get too much into buttonology, but I will walk you through the overall synopsis of what they are. And I do have them listed in my notes too, so never fear if you think you will forget."},{"start":"3:20","end":"3:51","startSec":200.3,"text":"So let's go ahead and take a look in Unreal and we're going to take a look at Nanite overall. I'm going to go and click on this particular rock. Let's go and click on our magnifying glass. Find that rock and we're going to actually mess with this copy here. We have a copy in here. I'm going to right click this particular one and we can see that we can easily and instantly turn this into a Nanite object. You can also disable it if you want to. So this Nanite object, we can now double click on it. Let's go full screen and we're in our scene and you'll see that we have some Nanite settings."},{"start":"3:51","end":"4:21","startSec":231.1,"text":"Let's isolate these a little bit better so we can actually talk about them. So I'm just going to type in Nanite in general. There you go. Got to be able to type and you'll see all of our settings in place. Now these allow you for a little bit more micro managing where you can actually edit things according to the needs of that object. You'll see obviously number one, we have enable Nanite support. This is actually super important and will now automatically tick on before you had to"},{"start":"4:21","end":"4:55","startSec":261.9,"text":"go in here and turn that on. This makes it so that Nanite is going to be drawn correctly. So Unreal automatically knows this is a Nanite object and it's ready to be drawn. We have a preserved area one in here now and this one can help with foliage, especially if you have like minute details that aren't rendering the way that you like. You actually can turn that on to maybe help things out. There's also explicit tangents. Now this is used to help store model tangents per asset versus runtime. So if you needed to for optimization purposes, you have that option."},{"start":"4:55","end":"5:26","startSec":295.4,"text":"There's also position precision here. Can't say that correctly. It's used to help calculate, generate the vertex positions of a Nanite mesh and can be adjusted for optimization. So if you need to, you can. And then we also have normal precision and this is for optimizing the disc footprint and enables choosing the precision mesh that should be used when generating vertex normal. So you actually have that here to be able to choose."},{"start":"5:26","end":"5:57","startSec":326.8,"text":"So there's a few more here and we've actually expanded these and we try to make these better and better with each build. That hasn't changed a whole heck of a lot, but we have made it so that just to make your life easier because if you have a huge world you're building or you're in this case optimizing things for ICV effects, you can actually manage things, especially if things get a little bit big. So we have a minimum residency here, root geometry."},{"start":"5:57","end":"6:32","startSec":357.7,"text":"This sets the memory bite size and streams rest for optimization. So you have that option there. There's keep triangle percent. This again used for to optimize the triangle usage. And we also have trim relative error here. This sets a maximum relative error amounts. You can do so if you need to fall back target. We talked a little bit about this in previous classes. It's used to help generating the appropriate fallback mesh. It determines which targeting system used when generating a fallback mesh overall."},{"start":"6:32","end":"7:03","startSec":392.6,"text":"Auto works pretty well. You can automatically create a fallback mesh based on project settings. The fallback triangle percent sets the percentage of triangles that remain when you're reducing the source mesh for Nanite. And then you also have a fallback relative error reduces until the specified error is reached relative to the mesh size. So you can actually again adjust these according to what you need. So we have source import file name. You'll see that one here."},{"start":"7:03","end":"7:34","startSec":423.5,"text":"So this one here is a source mesh used as a higher res LOD type loadout. So you can actually find that if you need to. There's a displacement. What you get displacement options. Yes, you do. So you can you can say hey I want this for to be my UV channel for this displacement. And then also a new feature where we have a displacement map. So notice we are adding little bits here and there. But just keep your eyes on that as it evolves. But this is where it stands at this time."},{"start":"7:34","end":"8:05","startSec":454.1,"text":"You may not need any of these. I haven't really found the need working in ICB effects and virtual production as well as Final Pixel and games working with game clients. This isn't always necessarily needed. But you never know when somebody comes up with a new game idea that may break the bank. So just keep those things in mind. Again these are all within the slides for you to take a look at broken down. So you can actually see each one of these and what they do so you can just keep them in your memory. So let's actually talk about a little bit about efficiency."},{"start":"8:05","end":"8:37","startSec":485.9,"text":"Now this has changed between 5.0. I think this went away in 5.1 maybe 5.2. So we used to have a Nanite debugger. We don't have that anymore. We have a thing called a Nanite Enable False. This basically works just like the debugger. It's basically just punching this into your search and you can instantly find out what is Nanite and what is it. Let me demonstrate. So in Unreal with my content drawer open here, I can go in here and type in, I'm just going to cheat and put paste."},{"start":"8:37","end":"9:08","startSec":517.6,"text":"Type in Nanite Enable 2 equal signs and false and it will show me everything that is not necessarily Nanite. You can see it's showing me all the things that I have not converted to a Nanite object. We're missing some of the cliffs, actually most of the cliffs, and some of the other pieces are missing such as simple pieces of geometry and shows everything within my project that doesn't have it. So if I convert just one thing, it will now disappear off the list."},{"start":"9:08","end":"9:41","startSec":548.3,"text":"So some of the updates, if you are in older versions of Unreal, not aware, we can actually turn our terrain now into a Nanite object as well as we can do also with the trees and your foliage, which is super helpful. You simply can find that foliage where it lives and then now you have the option to convert it to a Nanite object, which is actually pretty great. In the terrain itself, I can click on the terrain and simply type in Nanite and you'll see that we can enable Nanite in here and you'll see that there is a bit of micromanaging"},{"start":"9:41","end":"10:15","startSec":581.9,"text":"in here such as Nanite LED index, Nanite skirt enabled as well as Nanite skirt depth. So it's basically allowing you to control the draw method and you'll see here it says LED level of the landscape when generating the Nanite mesh mostly there for debug reasons. So most of these are mainly just to be able to check things out if you run into some performance hits. Now let's talk a little bit about virtual shadow maps. We do get into them pretty deep in the other classes here. So we're going to talk a bit about how they work overall and then how you can actually"},{"start":"10:15","end":"10:48","startSec":615.9,"text":"maybe edit things a bit here. So it significantly increases shadow resolution to match highly detailed Nanite geometry, unlike shadow maps which are like a texture projection. So we're not doing that in this particular case and you can see why they are the three musketeers Nanite virtual shadow maps and Lumen they all work together. Now what what what strength it brings to the table is a plausible soft shadows. It gives you with reasonable controllable performance costs. It provides a simple solution that works by default with limited amounts of adjustment"},{"start":"10:48","end":"11:18","startSec":648.3,"text":"needed and replace the many stationary lights that we normally have in a regular baking scenario techniques with a single unified path. So anytime you're actually building your lights and a couple things I want to point out when now we do get into light optimization here. So I don't want to dive too deep into this but I do want to point out a few things. You do want to make sure all your static lighting is off in your project settings. And again you do want to use a virtual shadow maps but you got to remember I keep saying"},{"start":"11:18","end":"11:48","startSec":678.4,"text":"this but it's made for Lumen not intended for unreal standard baking. Unreal will let you know too if you have some things off that on that don't need to be. If you want to switch to baking you must change your shadow settings in the project settings and make sure that Lumen is completely off everywhere but you also need to make sure your lights are no longer movable and the fact that if you want to be able to get your light to be able to generate some GI with that baking type of method. Now in our intro to lighting classes and other classes we talk about how you can use some"},{"start":"11:48","end":"12:20","startSec":709.0,"text":"CVARS to adjust your shadows but you also can do so in the soft source options in some of your lights. Now again we get into that a bit more in our other classes for lighting so keep those things in mind and you'll see here a soft angle source angle I should say I said soft source angle but it's mainly this guy. So this source angle allows us to go in here and soften that shadow and again we get into this and our hardening."},{"start":"12:20","end":"12:45","startSec":740.5,"text":"We get into this a bit more in our optimizing for lighting class which is our next class but I just wanted to point out how realistic and how nice these come out. It's really great to get this on the fly and again all your lights need to be set movable with that. Here's your few links with some more resources talking about these particular topics. That's it with this one and in the next video we're going to take a look at understanding LODs."}],"06_ReviewLOD_53":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"In this video, we're going to be talking about a review for understanding LEDs and how they work. Now, let there be a note here that working with LEDs, you primarily want to work with them when it comes to baking. You can use them with lumen, but you do run the risk, especially if you're mixing it with Nettite, of hitting some performance costs. And you kind of want to avoid that. Let's go ahead and take a look a little bit at understanding how they work. And I will be bringing in some caveats here to remind you that, well, as cool as LEDs"},{"start":"0:33","end":"1:07","startSec":33.6,"text":"are, they are primarily being used and should be used when it comes to baking scenarios. So the workflow with it, you always want to choose your LEDs wisely. If I was baking, say GPU baking, and my ICVFX environment required it, and maybe my game workflow that my, maybe we're porting stuff off out to the iPad or the phone, and we chose not to use lumen, just be able to control things a little bit better."},{"start":"1:07","end":"1:40","startSec":67.2,"text":"I can choose whether I want low quality in Quixel, high quality, and if I was in lumen to use Nettite. So all these things need to be determined exactly what you need ahead of time. It's a bit different when it comes to ICVFX. You have to actually determine in your stage, what is the priority areas or the hero object areas and how high those resolutions are going to be based on distance from the camera. Now I know that changes from week to week and from shot to shot working with the director."},{"start":"1:40","end":"2:10","startSec":100.4,"text":"So just keep those things in mind. You may want to grab a good amount of nanites if you needed based on your decisions, but not too much. You don't want to bloat your scene. You don't want to bring things to a crawl, but you'll at least have the option to import them if you needed to bring them into your scene. So just keep in mind, you need to be very deterministic. And I would recommend on being very strategic on where you place things and try to determine ahead of time what the goals are and visually what you want to go for."},{"start":"2:10","end":"2:42","startSec":130.7,"text":"And again, this does change and you can import these later on too. Now if you're using LODs, you can actually generate your LODs after the fact. And that's actually pretty helpful. So if you bring it in and you determine that you need a few more to represent objects in the distance, you can totally do that in a baking scenario. All right, let's go to the next slide. And in here, let's go and talk about a bit of controlling your LODs. Now again, this is a bit of a review from some of the other classes, which talk about"},{"start":"2:42","end":"3:15","startSec":162.2,"text":"working with LODs. But I'm going to dive a little slightly deeper in the fact that I'm going to point out some things that you can do and you can control for your environment. So let's go and hop into Unreal and take a look at a few things. So here in Unreal, I'm kind of breaking the norm here. I have several different versions of types of geometry here. I have one that is LOD, another one is Nenite. Again, that's not typical and you do need to be prepared and watch out for any performance hits. But I'm basically for lecture purposes, I have two different kinds."},{"start":"3:15","end":"3:51","startSec":195.5,"text":"So this one out here in the distance, let's actually look at the magnifying glass here with a folder. And we'll see that we have one that is Nenite. That's this particular one. And one that is not. And automatically, you'll know exactly which one is which, simply by clicking and seeing which one is active. So this one's using LODs. Let's double click on this one and take a closer look. Now again, when working with LODs, you want to work with it primarily with a baking scenario because it educators to it and you have less of a problem when it comes to generating your"},{"start":"3:51","end":"4:22","startSec":231.3,"text":"virtual shadow maps and Lumen. And overall, the performance is been made in such a way so that Lumen, virtual shadow maps and Nenite all work together smoothly. So if you do a mixed bag, you could run into some problems. Just remember that. So say we're in a GPU baking scenario here. So working with this, I have things set to an LOD auto. Now in here, we have one, two, three, four, five. We can determine these and choose these in our settings. So you can see that they're all in here."},{"start":"4:22","end":"4:53","startSec":262.7,"text":"And at any time, if I wanted to, I can custom these and isolate the ones that I don't want. And Unruh will shuffle accordingly to my needs. So working in here as we scroll down, let's actually close some of the material options here. So I can see that we have the LODs we can choose from and edit as we clicked on that custom. Allow me to switch materials if I need to, control my triangles. And because we have auto, custom compute distances, I now have, I can control exactly"},{"start":"4:53","end":"5:26","startSec":293.5,"text":"what the distance is on things going to be drawn. And that's actually kind of nice to be able to have that. You'll see we have triangle control, percentage triangles, max triangle count for each set of LOD that I have in place. The only problem or the thing you should look out for in this particular case when working with it, and this is mainly for reduction, you need to determine exactly what it is your LODs are sitting at. And you'll see here the percentage per triangle is set up nicely by default. If you change these, you need to remember what these numbers are."},{"start":"5:26","end":"6:00","startSec":326.9,"text":"So keep those things in mind if you decide to change those as we go. As I move my camera out and in, you'll see the LOD zero to LOD one, to LOD two, to LOD three, all set up pretty nicely. And Unreal does a really good job of setting this up in defaults to be able to actually control what's happening. Now, again, you can customize this if you want to or not. As you notice, I close it, all those other options go away. So you can control the max. You'll notice you can also control it on the lumen front, you can control the max lumen"},{"start":"6:00","end":"6:35","startSec":360.1,"text":"cards for that object. And that actually can be pretty helpful. That's a quick note. That's something I'll bring up later on when we get into lumen and lighting optimization. So you can also control the group. What this is, it allows Unreal to get a head start. And what your intentions are, is this a foliage object? Is it high detail? Is it a large prop? And Unreal will actually try to adjust things according to that object in 3D space. So it kind of just gives you a quick heads up. Now it isn't like a all sweeping, amazing. It'll get you a great large head start, but it actually helps Unreal calculate and know"},{"start":"6:35","end":"7:06","startSec":395.9,"text":"exactly what your intentions are for that object. Now you can choose the number of LEDs ahead of time too. We have five. Once you increase this number, you want to apply your changes and it will be set in there. All these things can be done as well as you loading your own LEDs for import. So if you need to actually swap them out, you can re-import a new version that you have. It'll actually re-import existing, but you can also choose which ones that you need and want."},{"start":"7:06","end":"7:37","startSec":426.1,"text":"So it's nice to be able to do this at any time and even build out your system. So if I go back to custom here, you'll notice as I bring in custom, we actually have some of our scenes such as screen size ready to go. Now you'll notice the screen size is grayed out. So this is necessary to be turned on. To do so, you actually have to turn off your auto compute. So you'll see auto compute down below. If I turn this off, you'll notice now that the production or I should say screen size"},{"start":"7:37","end":"8:08","startSec":457.1,"text":"control is now available. So I can choose how much percentage on that screen size I'm going to do with these properties. It's basically an override to say, hey, I want this to show up at a particular time kind of. You can think of it that way. So this is all controllable within here. We also have the ability to colorize and look at how things are being sorted. It's probably best that we do this in Unreal outside of the mesh editor. So let's go ahead and turn that on."},{"start":"8:08","end":"8:38","startSec":488.6,"text":"So I'm going to go to my view modes here. And we're going to go down to our level of detail colorization. And we're going to go to mesh LED colorization. You'll again see some that are grayed out because they're already in Nenite. But for the most part, you'll see it pop in and out through the different color levels of detail. It's actually pretty cool, but it shows you then that it's working and sorting according to what you need. I just can't drive right now. So if we go forward, you'll actually see it pop in and out and it's sorting through the"},{"start":"8:38","end":"8:56","startSec":518.8,"text":"levels of detail. Again, if you missed where I clicked on it, it's under lit. And then we have level of detail colorization and you can put that on. That's it with this one. In the next video, we're going to be talking about merging geometry and looking at that up close. Thanks again."}],"07_ModelingTools":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In this lesson, we're going to take a look at some of the modeling tools that allow us to edit our LODs. So let's get started. So the tool we're going to be looking at is the modeling tool editor that is found within the plugins. And once you turn it on, Unreal will ask you to reboot. And we're not going to go through all the aspects of the tool, but we're going to primarily look at being able to simplify a model as well as being able to change its pivot so that you can actually get things in position and get the look that you need."},{"start":"0:32","end":"1:02","startSec":32.7,"text":"Once you have it active, you can actually go to it through the pull down menu and select modeling. You can also access it with shift five. That'll get you where you need to go. So let's go ahead and take a look at these two sections here when it comes to simplifying and looking at the mesh. So in Unreal here, we can go ahead and switch to our modeling. And in here, you'll see that we have several different topics that we can choose from with our subcategories in here in there."},{"start":"1:02","end":"1:37","startSec":62.9,"text":"What we're going to mainly focus on is to the transform one and the mesh one. The transform one's pretty simple. I can select any model in my scene. Let me hit the F key and say this model doesn't quite have the pivot I want because I built it wrong or one of my contractors did. It ended up being bigger than we needed and we ended up scaling it in an engine. You can actually change this here with the edit pivot tool. This allows me to be able to move it in any area that I need, which is pretty convenient."},{"start":"1:37","end":"2:09","startSec":97.6,"text":"Once we move it into the position that we want and we can choose bottom, top, right, back, you simply hit accept. I'm going to hit cancel for that. You kind of get it. It is way better than the older way that we do things, which was the cumbersome pivot tool here. This doesn't quite work as well, but this tool is miles ahead. Let's go ahead and look at the mesh tool and what it can do. So before we get too far ahead, we want to make sure that we check and turn on a few"},{"start":"2:09","end":"2:41","startSec":129.3,"text":"things in our settings. Let me go to my project settings and show you what I mean. In my project settings, if you're going to be editing the models, you want to make sure that you turn these on, specifically if you're working with ray tracing. But I like to turn them on anyway if I'm in Lumen because some of the technology for ray tracing, mainly to speed things up and leaning on the hardware ray tracing aspect, is there in place and I just want to make sure there's no hiccups. So what I'll do is I'll put modeling in here and I'll make sure that I'll turn on enable"},{"start":"2:41","end":"3:12","startSec":161.7,"text":"ray tracing for a new mesh object as well as enable ray tracing while editing. This is great to actually turn on as a precautionary measure, especially if you're going from Lumen back to ray tracing, etc. And it just covers your bases there just so that things are updating accordingly in our environment. All right, so let's go and take a look at our tools here for the mesh. I'm going to turn this on here and let's go ahead and take a look at this polygon"},{"start":"3:12","end":"3:45","startSec":192.1,"text":"object and see what it looks like. I'm going to click on the magnifying glass with a folder. Now first thing you want to do is determine whether this thing is Nanite or not. The tools will still work if they're not Nanite, but I just wanted to show you say you brought in a model and you decided it doesn't need to be as high as it's marked. Maybe you want to just downgrade it a little bit because it's way in the background. There's no need to use it. Nanite's pretty clean, so you don't necessarily have to worry about that. But you may want to say there's a really high level of detail scan and you're noticing,"},{"start":"3:45","end":"4:19","startSec":225.3,"text":"man, I don't really need it to be that detailed. I just need to sell a web. You can actually go in here and simplify that mesh. You can also float over each model and get an idea what the polygons look like. This will also tell you whether it's Nanite enabled. You can see here on this particular one, we have Nanite off. On this particular one, Nanite is on. As you float over, it will tell you that Nanite is true. It says enabled there. It will even give you a Nanite vertices and triangles."},{"start":"4:19","end":"4:49","startSec":259.1,"text":"Let's pick on this particular one. This one is not Nanite enabled, as we can see. Let's activate that tool. I'm going to click away and we're going to go in here, select this tool. We're going to go to simplify. Now there's multiple choices that you can choose from here in simplification. I'm not going to go through too much buttonology. I do have this laid out in our lecture notes. Two of them, which work pretty well, is the normal aware, which allows you and allows"},{"start":"4:49","end":"5:20","startSec":289.8,"text":"Unreal to honor your normals, take them into account. UE standard, this is the one I typically choose. This one actually works really, really well. We can work through triangle percentage here. Again, it ballparks it. If you were to choose, say, you want to do exactly triangle count, it's going to also estimate it here, just like it would with Maya, Houdini, or 3ds Studio Max. It's going to give an approximation. I'll keep it percentage for now. I think that works pretty well."},{"start":"5:20","end":"5:50","startSec":320.4,"text":"Do we want to drop it 50%? Why not? We'll go ahead and do that. Let's go ahead and drop that. One thing I want to point out, though, before I get into this, is you want to make sure you have a copy of your geo in the scene, because if, say, you like the original and you want to dumb it down to see what it looks like, keep in mind it's going to dumb down the polygons on all the instances in your environment, which is not exactly ideal."},{"start":"5:50","end":"6:22","startSec":350.5,"text":"You might want to duplicate it in the content browser. Let me hit cancel for a second. Just find that piece of geometry, and you can see I have several duplicates here. Duplicate them, drag them in the scene, and then run a procedural, I should say, a simplification on it, and then kind of see how it looks and what you want. Instead of doing it on one, which may be in several different areas, it may not fit the bill. All right. So let's click on simplification, keep it at percentages, keep it at unreal standard,"},{"start":"6:22","end":"6:54","startSec":383.0,"text":"and we'll do 50%, and let's go ahead and hit accept. We'll let it run there. It's going to be running for us. There it goes, pretty fast. Now you can find that piece of geometry, and we can now see that it's been dropped. It was 47, I think 47, almost 53,000 triangles. Now it's 23, and it actually looks pretty good still. Now again, keep in mind it still has the high resolution texture."},{"start":"6:54","end":"7:25","startSec":414.0,"text":"You can also dump that down using virtual textures, which we'll talk briefly about later. But for the most part, we're actually in here, and it worked really, really well. All right. So say you have it in your scene, though, and you kind of want to replace maybe another one in your scene. But you're like, you know what? I have this guy, and there's several of them I want to replace. I'm going to hit shift E, and let's see if there's any duplicates."},{"start":"7:25","end":"8:00","startSec":445.8,"text":"No, there's not. We'll just pretend there's is. So let's go and make some duplicates really quick. So I go to Alt, there's another one, rotate it just a little bit. So this is like too generic. Move that back, not too far back, and then we do Alt and move. So if I have multiples in the scene, I can hit shift E, and it will select them. With them selected, I can right click, and I can replace that actor with the one that"},{"start":"8:00","end":"8:35","startSec":480.6,"text":"I've just dumped down, which actually works pretty well. Now if you're not sure, you can go in here and just float over this guy. You'll see he is variant three. You'll see that the one that we dumped down, he is variant one. So if I click on this, shift E, now right click, replace actors with variant one. There you go. Not too bad. And now we have replaced that existing one, which was higher poly, to a lower poly model."},{"start":"8:35","end":"9:06","startSec":515.3,"text":"And this can come in pretty handy, especially if you really just want simplification in your scene. Nanite works great, Lumen works great, virtual shadow maps work great, but if you throw the kitchen sink at it, you can bring anything to a crawl. So optimizing things where you need them, you can actually lower polygons, keep it in the background if you need it, and it works really great. So just another option if you need to edit things in here, you don't necessarily have to go back to your DCC."},{"start":"9:06","end":"9:43","startSec":546.3,"text":"So looking at the settings again. We have a simplifier type here, all the different ones, QEM, normal aware and UE5 standard. This is the one I typically use, edge claps, and minimal polygon group, preserving your polygon groups there. And then we also have target mode, which just controls your percentage of decimation. And do you want to try goals like I mentioned, polygons or disease and et cetera. That's really up to you. Once done, it updates the triangle count in the content folder. Similar to many DCCs, the changes approximated like I mentioned before, so keep that in mind."},{"start":"9:43","end":"10:16","startSec":583.3,"text":"So we talked about replacing it, hitting shift E, and then also just right clicking and getting that quick change in your scene. So I don't want to point this out at the bottom here. No, with modeling tools, modeling tools, you can increase polygons if the LOD that came in is too low res. So you can remesh it. Now you can also do that for an object that's come in as an ad-ite, and you want it to be maybe a little bit heavier. Now now that it's pretty great in the fact that it honors what you got from Megascans"},{"start":"10:16","end":"10:50","startSec":616.5,"text":"or maybe something that you scanned on your own, you can bring that in as an ad-ite mesh and it will get it at its highest level of detail. So you may or may not have to remesh. So this is really up to you and it's a case by case. This is a bit talking a little bit more towards LOD work and pretty much Nanite is its own type of LOD on a triangle basis versus on geometry swapping out the pieces. So in the next video, we're going to start talking about merging geo and how that works."},{"start":"10:50","end":"10:51","startSec":650.9,"text":"Thanks again."}],"08_Mergetools":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In this lesson, we're going to take a look at the tools for merging geometry in Unreal. So let's get started. You'll see here there are several options to choose from. Now, I'll go through in Unreal and show you how to work with this, etc. It's pretty straightforward, but I'm first going to walk you through some of the different options you have. Now, they have an option for merge. This merges and simplifies a mesh. It merges materials and it banks details into normal map and each proxy LOD is one draw"},{"start":"0:32","end":"1:02","startSec":32.1,"text":"call. So what it does, it allows you to have not multiple draw calls on multiple pieces, but makes one draw call as it combines the mesh into one piece, which is actually pretty convenient. You'll notice here though in the menu settings that material is grayed out. This actually makes a hybrid material, especially if you have two different materials already existing and you combine those objects. Now be careful when doing that if you decide to use this merge option, because if you have"},{"start":"1:02","end":"1:33","startSec":62.3,"text":"multiple pieces with multiple different materials, it can be a little rough. And when you decide to migrate this particular object, the material may not come along for the ride and may require to be reconnected and rebuilt. So that's a disadvantage with this. So when you do use the merge tool, make sure it's just a couple of different materials and not five or 10 different ones, because that's where things can get a little bit rough. The next option we have is simplify."},{"start":"1:33","end":"2:03","startSec":93.0,"text":"This merges and simplifies the mesh also. It merges materials, but you can control resolution. So it tries to give you a nice resolution control so you can dumb it down as you need. And it bakes details into the normal map and each proxy LOD is one draw call. So that one's pretty beneficial. There's also the old school batch method. Now this one isn't used as much. It tries to create like a nice instance reference for the combined object, which really isn't"},{"start":"2:03","end":"2:33","startSec":123.2,"text":"needed. This one I don't use so much. It is a older reference tool, but we do have today a new way to be able to merge such complicated meshes as a nanite and that's using approximate. Proximate works really well. It allows you to grab these higher visual fidelity, higher poly counted objects and merge them with a little bit of better ease. And you'll see there's several different options to choose from. And we'll talk about these."},{"start":"2:33","end":"3:07","startSec":153.5,"text":"So we're going to get ready to jump into Unreal and take a closer look. But before we do, I want to point out exactly how beneficial these tools are. You'll see that these objects are merged. The cliff. You'll see like there's a pillar. There's an archway. That is one draw call because we merge them. These over here that aren't merged with all the little details is 70 plus draw calls. That again is a disadvantage. So we're optimizing when we do this and making it lighter for the scene overall."},{"start":"3:07","end":"3:40","startSec":187.9,"text":"Now let's go ahead and jump into Unreal. We can see in the case of this probe that there's a lot of detail and a lot of individual parts in here. Each one of these are a draw call, which could be to our disadvantage, especially if you want to put a lot in the scene. We see up here we have one that has already been merged. And let me hit the F key. You can actually see a downgrade of the resolution and the geometry silhouette in here. But it's so far away from the camera, no one is really going to notice."},{"start":"3:40","end":"4:12","startSec":220.0,"text":"And that's to our advantage. And you'll see that there's a hybrid material if you double click on it, which is a combination of the normal maps and the texture all into one. So Unreal tries to do that work for you. So you don't have to worry about that as much. But you'll notice again, this is for an object in the distance. You'll see that the silhouette may break down a bit compared to our original down below, which has a lot more visual fidelity to it and texture resolution."},{"start":"4:12","end":"4:44","startSec":252.5,"text":"But that's just one way to merge. Let's look at them up close. So go to our tools here, and we're going to go to merge actors. I'm going to pull that up. I'm going to pull this over to the side. Now this is the basic merge. Here's the settings. You'll notice again, we don't have any material options. So we can't control our overall resolution. You'll see there's a thing called a gutter in Texels to add to each sub chart for our baked out material for the top of MIP level."},{"start":"4:44","end":"5:14","startSec":284.0,"text":"So you can actually choose that. The default relatively works great. There's also baked vertex data to the mesh. So if you did paint some vertices, some vertex information in there, you can actually bake it to it. And we also have Nanite settings if you were to work with Nanite on this particular object. Now this guy hasn't been converted, and we do have that option. But for really heavier pieces of geometry, I recommend you use approximate. We'll look at that in just a second. All right."},{"start":"5:14","end":"5:49","startSec":314.9,"text":"So let's go ahead and grab this piece of geometry. And we're going to pick on this particular one, because I think he's pretty close to the original. And we're going to go ahead and find all the pieces to him. Let's go and do that. I'm going to Alt Control here, select him, make sure I don't have anything selected in the background on accident."},{"start":"5:49","end":"6:20","startSec":349.0,"text":"There we go. And we're going to go ahead and run a merge. Now you can replace the actor if you want to, or pull the actor in. This is really up to you. But keep in mind, if you replace it, and it isn't what you want, you may not like that one very well. If you decide to pull it in, the pivot may be off, and you'll have to adjust it using again some of the modeling tools that I showed you, which can be pretty helpful. In this case, we're going to replace the actor, and we're going to merge actors."},{"start":"6:20","end":"6:56","startSec":380.1,"text":"It's going to ask you where to put it. So just pick a nice little place to put it. In our case, we can just simply load them into maybe a new folder here that we can just call class. And let's make one in class merge. And open it up and save it there. Now it's going to run and compress and make a new system honoring, you'll see two different"},{"start":"6:56","end":"7:27","startSec":416.1,"text":"materials. Now we didn't have any choice in resolution, but it went and combined, or I shouldn't say combined. My bad. It went, it goes and honors the materials, and it makes two different sets in here for us to look at. Now that's actually pretty nice because there's less of a chance maybe of getting some deprecation going on. But we now have one particular, we have one object with one single draw call, which is to our advantage."},{"start":"7:27","end":"7:58","startSec":447.2,"text":"But if we were going to go over here and say we wanted to make it so it isn't two materials because each one of these are draw calls, we can actually do the next one, which was the one we ran here with the F key. And let's open up those emerge tools again. And we had run simplify. Now simplify again, we'll take that material, simplify the material as well as combine the geometry, making one draw call."},{"start":"7:58","end":"8:28","startSec":478.2,"text":"Unfortunately, you will get hit on some of your silhouette items here. There is a light map resolution if you were to use baking so you can actually get that set up ahead of time. We're not using that in this particular case. You will also see a nanite section here. You'll notice it's not enabled. So we're okay in that front. But if I was to have it enabled, I would want to make sure that I control such things as positioning and normal precision. You have some of the same nanite control that you have before."},{"start":"8:28","end":"9:01","startSec":508.2,"text":"Typically the defaults should be just fine. It should be okay. And it will look at that object as is. But again, for heavier surfaces, if you're going to merge them, I recommend using approximate. Again, we'll get to that one in just a second. So in this one, we also have material settings. Since it's making a hybrid, you might want to control the resolution a little bit. So you don't run to any problems visually. So that's important to consider. So simplify, simplifies your texture with resolution options."},{"start":"9:01","end":"9:35","startSec":541.4,"text":"Merge makes a two sets of new materials with no material options. So tries to honor the original. But you'll end up getting two draw calls with it or multiple, depending on how many materials you have. It tries to honor each one. So again, like I said before, be careful not to have several different objects with several different materials, because that complexity can make it a little rough if you decide to migrate them outside of your scene. You may even convert your scene from a say 5.3 to 5.4."},{"start":"9:35","end":"10:08","startSec":575.1,"text":"And you may notice that your blend material no longer exists. And that will require another for you to run the merge tools again. And then we have batch. Now batch is kind of old school. It's a tries to create an instance for your object. This one I do not use much. It doesn't really, I don't find it necessary. But we do have approximate, which is the new kid on the block. Now approximate, again, is made for a higher visual fidelity objects. You'll notice there is no nanite necessarily."},{"start":"10:08","end":"10:38","startSec":608.1,"text":"There's a generate a nanite enabled mesh where to generate it. But you'll notice the settings are a bit different. They don't have that whole setup. We had a long and nanite breakdown of things. There is a material set up here. So you can set your material capture resolution. And there's ours a bit debugging if you run into or you suspect you're going to run into some issues. But overall, this is pretty straightforward."},{"start":"10:38","end":"10:51","startSec":638.7,"text":"And this allows you again to have higher poly objects and merge them to become one draw call. That's it with this section. In the next section, we're going to take a look at HLODs. Thanks again."}],"09_HLODS":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"In this lesson, we're going to take a look at HLODs and how they work with your levels of detail. So, let's get started. So, HLODs, you may ask, what exactly are they? Well, they're a hierarchical level of detail. It's a way to combine pre-existing SeticMesh actors into a single HLOD proxy mesh and material with at-list textures. So, using HLOD may lead to increased performances as they reduce draw calls down to one call"},{"start":"0:30","end":"1:03","startSec":30.4,"text":"per proxy mesh, which is pretty convenient. When generating HLOD proxy meshes, there are several parameters you can adjust which help define how static mesh actors are grouped together as clusters that will ultimately be built into proxy meshes. Now, you don't have to use this tool, but it is available. It's a little bit more on the old-school side, and you may find that Nenite fits the bill just fine. But to be able to create it, you do want to start out by going into your proxy meshes."},{"start":"1:03","end":"1:34","startSec":63.2,"text":"You can find them under your world settings. So these proxy meshes are created from clusters of static meshes, like we mentioned. Each cluster is going to be one draw call. That's the benefit you get from this. Clusters can't be merged into bigger clusters at a greater distance. So use them for wide shots or open worlds. No, HLOD layers can now be used to house Geo also with World Partition. So you can use them with World Partition also."},{"start":"1:34","end":"2:06","startSec":94.0,"text":"But I want to put a note here for World Partition. If you decide to use it with your team, keep in mind there are still some things evolving with it, such as linking your World Partition updates with Perforce. There can be some workarounds that you may have to tackle in that. And we're not going to cover that here, but I want you to be aware of it. So creating it, we're going to go to our world settings and load Hiercal LOD setup. We're going to generate a single cluster if needed."},{"start":"2:06","end":"2:38","startSec":126.7,"text":"And this can be set to HLOD in the HLOD Outletter also, which we'll take a look at in just a bit. So let's hop into Unreal and take a quick look too. From there, you want to open your Hiercal LOD Outletter and select the HLOD setup asset. And that can be default. So you don't necessarily have to do any heavy lifting on this particular case. We did have an older version if you were used to it, where HLOD would list a lot more options"},{"start":"2:38","end":"3:11","startSec":158.9,"text":"than it does now. It's been pared down quite a bit. But you want to generate your clusters. And when you generate your clusters, you're going to be able to get the items that you need. Now if the actor's changing anyway, it's going to prompt you. It'll tell you, hey, man, you need to generate those proxy meshes again. Because that's kind of important. Things have changed to update the HLOD cluster. Only use build all if you have to. As it can dirty your scene, and Unreal will let you know."},{"start":"3:11","end":"3:41","startSec":191.1,"text":"I'll say, hey, buddy, are you sure about this? This may not be the right choice for you. We're going to actually look at an HLOD volume also in place with an HLOD in my scene that I've given to you. Let's go ahead and jump into Unreal and look at the setup I have, as well as look at the HLOD Outliner breakdown that shows some of the things that have been generated and some overall sweeping control that you've gotten in your scene. In Unreal, I'm going to go to my beach HLOD sample."},{"start":"3:41","end":"4:16","startSec":221.7,"text":"Let's go and click on that. I'm going to say, don't save what we were doing. Get that to come up. We'll see it generate, get in there. Now, let's go and take a look at things overall. Let's open up our HLOD Outliner. Let me pull it over. You see that I have generated some HLOD objects in here. We have a LOD actor here that has all the parts for that particular probe."},{"start":"4:16","end":"4:49","startSec":256.2,"text":"We have another one in here. Unreal's clustering these, so let me know what has become an HLOD object. Anytime you don't want these in here, you can delete that cluster. You're like, hey, I don't really need this one. This one's fine. Nanite's handling it just fine. I can go ahead and delete that. You can also, as we go and open these up, look at these on an individual level. You'll see there's advanced settings here, and it just shows you the transform options. It isn't as robust as it used to be, or we used to have a bit more, or you have a little"},{"start":"4:49","end":"5:19","startSec":289.2,"text":"bit more material control and a few other things. Those don't quite pop up like they used to. Things have been pretty pared down here. You'll notice at the bottom here, we have a yellow message here. These actors represented in the HLOD have changed, generate proxy meshes to update. Since I've tweaked with this file a bit, I would have to just generate another proxy meshes here for any updates or changes that I've made. Keep that in mind. Again, build all. You kind of want to avoid if you don't really have to do it."},{"start":"5:19","end":"5:52","startSec":319.7,"text":"There's also regenerates your clusters, but no proxy meshes for meshes in the level. This is your initial button that you would click, and then from there, any changes you can do for your generated proxy meshes are found here. Now, another thing I want to point out, there's a thing called an HLOD volume. Type in volume here. There's a lot here. You'll see that I've drug in an HLOD proxy volume."},{"start":"5:52","end":"6:22","startSec":352.1,"text":"This actually acts as a container to hold a cluster of HLODs that we have built in. I can actually use this as a priority area until Unreal to read a group of pieces of geometry as one draw call. You'll see this HLOD volume here. This actually works pretty well. This HLOD volume, you'll see, also has a few more options. It tells you to include overlapping actors."},{"start":"6:22","end":"6:54","startSec":382.5,"text":"I can definitely tick that box on. There are a few that are overlapping a bit in my scene. We have a few generic brush settings in here, but we also have include actor in HLOD. It's going to, you want to make sure that's turned on. There's some advance with the brush settings, but it's nothing to write home about. But overall, you can see how things work. Now, down below, you will see a level instancing. We're not doing that in this particular case. Level instancing allows you to grab maybe a group of rocks, these particular ones."},{"start":"6:54","end":"7:25","startSec":414.8,"text":"If I wanted to, I can turn them into a level instance actor. In this case, we're not covering that in this particular class. It's a little bit more building of your game world. From here, we're mainly going to be focusing on our HLODs. I just wanted to point that out if you're wondering what that does. This basically allows you to have instanced pieces of large. You have a huge open world area and there's some rock formations and large landscapes and"},{"start":"7:25","end":"8:01","startSec":445.1,"text":"just things that you've kind of mushed together. And you have all these pieces of geometry to manage them. You can actually create a level instance to make things a little bit lighter and unreal will instance those pieces of geometry as an instance part of your level and make things, it makes things a little bit more organized and categorized and reading the geometry smoother so that your big world that you've created doesn't become too much of a bog in your scene. So here, again, we have an HLOD volume and again, it is calculating everything in my scene the way that I want."},{"start":"8:04","end":"8:36","startSec":484.9,"text":"And if we did a comparable like we just talked about, I could grab this pieces of geometry here, right click and you'll see level and I can create an instance level if I wanted to. And in there, I can have living an HLOD if I wanted. And then it would simply be able to be loaded in here. Now there's a difference when you're working with those. We're working in our levels here. If I was working in a world partition, I would not be working in levels. So there's a give and take situation there."},{"start":"8:36","end":"9:09","startSec":516.1,"text":"And we do have a class talking about that in which one of my colleagues really breaks that down a bit easier for you. But I just wanted to explain if there's any confusion about how that system works. So to break it down even further, they are used by the hierarchical level of detail HLOD system to group actors into a single HLOD cluster. So again, like I said before, it puts them in a cluster. When generating clusters, the Unreal Engine will override its normal generation process in difference to manually placed volume."},{"start":"9:09","end":"9:25","startSec":549.6,"text":"So basically going to look at them as a priority area, like I mentioned before. That's it with this lesson. Here's a few links here that allow you to dive in a bit deeper on these topics. In the next section, we're going to take a look at texture and material optimization."}],"10_MaterialTextureOptimizations":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"In this lesson, we're going to take a look at texture and material optimizations. So let's get started. So textures should be treated based on priority and the shot. And that really goes for pretty much everything you put into Unreal. You have to think of it as a real-time tool and not an offline renderer tool for those that are working in film. So your final pixel highest resolution textures should be used on Hero Objects. This is the same rule that we have with games."},{"start":"0:30","end":"1:04","startSec":30.6,"text":"So for ICVFX, less is more. For resolution to gain performance, and the highest is not always needed based on focus. Basically, your actor is the focus and everything behind that actor, if it's directly behind them, needs to have a higher resolution. But if it's farther back, you can lower the resolution. I'll give you an example. If I had a mountain range and my texture for it was 8K, and it's in the way in the distance, I don't need 8K. I can lower that to an easy 4K or even 2K if I'm using fog to hide some of the missing"},{"start":"1:04","end":"1:34","startSec":64.5,"text":"details. So that's actually really helpful to consider and think of things on that level. For large scenes that have lots of high resolution textures, say you have a terrain, and maybe you're using virtual production, less of ICVFX, but more of a kind of maybe even a final pixel scenario, you can use virtual texturing so that only the highest resolution of the texture is loaded per where the camera and the focus series are at. In Unreal, we also have mitmap control."},{"start":"1:34","end":"2:07","startSec":94.6,"text":"So if you run into problems with blurring or repeating patterns such as more, you can actually adjust that. Let me go ahead and take a look at that in Unreal. It's a bit of a review, but hopefully it'll let you know or remind you where things are located. So let's go ahead and double click on this particular texture. In this texture, let's go and zoom out a bit. You'll see in the details for it that we have a mitgen settings. This is where we can do some corrective work. If we're noticing there's some blurring or a moray pattern happening."},{"start":"2:07","end":"2:38","startSec":127.1,"text":"We can also tell what texture group we want this object to be in. This helps with a bit of compiling and maybe a little bit more centric for games for the final packaging. But for the most part, you can actually have Unreal kind of skip a step of picking through your compiling of your object and knowing your intentions. And if anything is dependent upon that can be a bit helpful. So those are some things to consider. Let's go back to the slides and look at a few more things. Another tool that we have at our fingertips is a thing called edit via property matrix."},{"start":"2:38","end":"3:09","startSec":158.4,"text":"Now this property matrix makes it so that we can lock down resolution to a particular type or I should say number. If you're noticing that things are getting a little bit heavy into your scene, let's jump into Unreal and I'll point out where those things are at. So several of these textures will say are maybe a little bit too high. I can go and select them. We'll do shift and click here. I'm going to right click in here and go to my asset actions. And then I'm going to go to my edit selection in property matrix."},{"start":"3:09","end":"3:41","startSec":189.9,"text":"Once you open up the property matrix, you have access to many things. One of them you can look at the texture overall and you can see, hey, you know, I want to change the tiling method, kind of a little bit of a sweeping control there. We even have importing settings here and we have adjustments. You'll see there's a simple layout. This is basically an expansion of the details that you get in the texture we were just in. We also have compression here that we can control as well as LOD level of detail."},{"start":"3:41","end":"4:15","startSec":221.1,"text":"So if we open this up just a little bit more, you can see all these details. You'll see right here a maximum texture size. So we can lock that down and we can do it for as many as we need or have selected. So that's actually pretty helpful for a bit of optimization. So here are some notes for a bit more linear content leaning towards ICVFX. If you're not using decals, make sure that you disable them in your project settings"},{"start":"4:15","end":"4:47","startSec":255.9,"text":"because they do use a little bit of memory. And don't use video elements as they cost. Use flip books instead, animated through a material parameter or EXR. So we have a fairly new system which has been updated for EXR where you can actually use high resolution EXR images and put them on a plate, which is actually pretty great. Both are good methods to have synchronized animated sequences. So I recommend that if at all possible, especially if you're working with ICVFX because the video,"},{"start":"4:47","end":"5:18","startSec":287.1,"text":"the latter is a bit more cumbersome to actually get going in that particular scenario. For elements in the background, you can bake textures also, but check with production leads to see if changes may be needed later. It's not always used, but that's basically due to the on fly edits you get when you're on stage. Since going backwards is tricky, so make sure that you maybe keep the original copy with you. So this is up to you and best to make a copy of all items whenever possible."},{"start":"5:18","end":"5:52","startSec":318.2,"text":"And you'll see a bake within the material itself. You can actually bake them automatically, those textures. You can also use virtual texturing for large scenes for overhead. Let me show you a little bit of that in just a second. But also you can also pack RGB into UV channels. We go over this in some of our foundational material classes, but that's pretty simple. You actually will be making the texture have different channels and in it you can have roughness, you can have an alpha. The only problem with that is you have to think ahead of time of what you want."},{"start":"5:52","end":"6:24","startSec":352.4,"text":"So let's go and pop into Unreal real quick and I'll show you the virtual texturing a bit of what you can do. So let's go ahead and pick on this particular texture. I'm going to go and get my magnifying glass here and say these three textures, I need to make them be a bit more virtual texture friendly. Now before you do that though, you don't want to make sure in your project settings that you actually have it on. I have it on, so I'm kind of cheating. So let's go to a virtual texturing and you'll see that I have enabled my virtual texturing"},{"start":"6:24","end":"6:55","startSec":384.4,"text":"support. Really handy. Now it's good to turn these on too, especially if you're having problems with your viewers and they're not coming up. They can support you a bit. So virtual texturing is active and I'm going to go in here and now with these three selected I can right click and I can convert these to virtual textures. Now when you do, it's going to ask you what resolution you want and it's going to give you a whole list. This gets pretty tricky. So you have to figure out what is the texture that you need and want and you need to find"},{"start":"6:55","end":"7:26","startSec":415.4,"text":"it and that way if you don't want to do all of them, you have the option and you can choose what that texture size threshold is going to be. It's actually pretty handy to do this, especially for large worlds that you're dealing with. And again, how virtual texturing works is it only renders what is needed and the highest fidelity images based on the positioning of your camera. So it's like virtual shadow maps, virtual texturing and even Nanite works like that, but on a triangle basis."},{"start":"7:26","end":"7:59","startSec":446.4,"text":"Now we won't dive too much into this part, but I want to remind everyone about these nodes, especially if you're working with ray tracing and it also works with path tracer, where you can actually use a ray trace quality switch replace. You can either do that or you can make a parameter, a switch parameter. Now that switch parameter allows you to switch between a texture or a simple number that you're using, but the quality switch replace when it comes to ray tracing does this for you automatically based on where you're at in the scene."},{"start":"7:59","end":"8:30","startSec":479.6,"text":"And it just gives you that nice automatic switch between a high quality and a low quality based on where you are at with your camera and your position in the world. So again, here's the static switch parameter option. And this basically is active. Once you create an instance material, you'll be able to see this and you can turn it on or off being able to have another scalar parameter in there to be able to control"},{"start":"8:30","end":"9:02","startSec":510.4,"text":"things, the values of each one that is up to you. This is covered in other classes, but I did want to put a reminder in here because this is important to consider, especially if you feel that your texture resolution isn't always needed in a particular area, such as rough or simple metallic, you can actually switch those. So things to consider and really think about when you're being deterministic for your shots, specifically for IC VFX."},{"start":"9:02","end":"9:36","startSec":542.2,"text":"So your parent materials need to be used with instances. This is really important because then you're actually not recompiling that material over and over again, and you can make an instant change with that instance material. Kind of a lot of instances in that almost got a tongue twister there. So we have also you want to make sure you use material functions as much as possible. So these will make it so you don't have a noodle fest, make things cleaner and allow you to get where you need to go. And you can connect your instances to these and so forth and just make things a lot easier"},{"start":"9:36","end":"10:06","startSec":576.6,"text":"overall. You also can use material layers. It's up to you. I don't recommend using substrate at this time. We do put a warning on that because it is still in beta. It's not ready for prime time. Also, when you go to substrate, you can't go back to regular materials. So it's kind of an all or nothing. But you can use your material layers in this particular case with Unreal default. And I didn't want to make that mention though for substrate because substrate gives you some"},{"start":"10:06","end":"10:37","startSec":606.8,"text":"options in there for that to keep things a little bit cleaner when it comes to layers. And I didn't want you to get too excited looking at material layers. Try to stay within old school at this time with 5.3 and a couple of versions coming up. But substrates almost there. Not quite there yet. The goal is for better real time performance. You have to think of it this way. What is the best performance you can get for that camera for ICVFX and your hero objects are the priority. You can bake textures if you want, but keep in mind, you can't actually make those changes"},{"start":"10:37","end":"11:08","startSec":638.0,"text":"once you've baked. So you might want to make sure if you are going to bake that you at least have the originals nearby so that if the director does change his mind, you can quickly switch them out. Keep higher textures and material complexity limited to hero objects like we mentioned before and use material parameter collections to help simplify material control, which we cover in some of our material classes. Final pixel parent materials need to be used with instances. Very important. Less worry with frame rate on less editing."},{"start":"11:08","end":"11:38","startSec":668.2,"text":"So you're not worried about frame rate so much. You're looking for the final results. But again, looking for better final results requires that you also do keep in mind the concept of hero objects. Again higher textures for hero objects as we said before, use material functions to group common features together and can use material layers. Again, this is a new system and you can use it when necessary. Use material parameter collections to help simplify material control."},{"start":"11:38","end":"12:06","startSec":698.6,"text":"Here's a few links that will help you get in the right direction. And if you want to dive in deeper, here's a few more additional resources and a link for game optimization. If you want to dive in there, some more resources here for optimization and some credits here of some of the people that I've worked with to pull this all together. That's it with this one. I hope you enjoyed this series of courses. In the next video, we're going to do a recap of everything we've talked about. Thanks again."}],"11_Outro":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Let's go ahead and recap some of the things that we talked about. One, we talked about profiling concepts, types of rendering, concepts and thread profiling. We looked at calling concepts, calling methods, GPU visualizer, GPU draw thread, CPU draw thread, analyzing those draw calls and looking at Unreal Insights. From there we looked at optimization visualizers, using those visualizers, quicknotes, lumen, nanite, and even some pro tips with those. We also looked at nanite and virtual shadow maps, why to use them in an overview of what they do."},{"start":"0:32","end":"1:01","startSec":32.0,"text":"We then looked at reviewing understanding LODs. And in that we looked at how to edit your polygons using the poly editing tools, swapping out geo, merging, and even HLODs. And from there we finally looked at texture and material optimization, looking at how to optimize your textures, the tools we have, as well as materials. Overall, I hope you've enjoyed this course and found it very interesting and helpful. And let us know if you have any questions. Thanks again."}]},"204.06":{"01_Intro":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Hi everyone, my name is Sean Spitzer, Senior Instructor for Epic Games. Today we're going to be talking about optimization for linear content, lighting and effects. Some of the topics we'll be covering is lighting, optimization, analyzing scene and priority areas, baking versus dynamic and overview. We'll also take a look at Lumen and how to handle the key workflows, limitations, quality control and optimizing and editing. After then, we'll take a look at Lightmass Baking, CPU and GPU as a review as a whole"},{"start":"0:34","end":"1:06","startSec":34.0,"text":"and we'll look at Lightmass Baking CPU as well as looking at setting up pre-computed lighting scenarios and GPU Lightmass review. Then we'll look at using Screen Space Global Lumenation, using some of the final pixel workflows for that as well as ICVFX. We'll look at ray tracing, optimizing for final pixel and ICVFX workflows and finally we'll look at optimizing fog effects, what to look for and how to tackle those scenarios. That's it for this one. Hopefully you'll enjoy this course and have a great time."}],"02_OutlineLightingOptimization":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Hi everyone, in this lesson we're going to go over the outline for this series of videos as well as look at some optimization lighting concepts. So let's get started. So the outline for the scores, first up we'll be looking at lighting optimization. We'll be analyzing scenes and priority areas as that's very important when it comes to lighting. We'll look at baking versus dynamic as a quick overview and then we're going to jump right in. So in Lumen we'll look at the Lumen equation overall as in key workflows, limitations,"},{"start":"0:34","end":"1:05","startSec":34.2,"text":"quality control, optimizing and editing. Next we'll look at a review of light mass baking. This includes CPU and GPU workflows. We'll look at light mass baking CPU review. We'll set up how to set up a pre-computed lighting scenario review and GPU light mass review. Next we'll look at screen space global illumination. How to use it, when to use it and how to add some things. Then we'll look at ray tracing as an overall review which will include optimizing for final"},{"start":"1:05","end":"1:39","startSec":65.8,"text":"pixel review and optimizing for ICV effects to workflows. And finally last but not least we'll look at optimizing for fog effects. We get that request a lot. What to look for and optimizing settings. With that in mind let's go ahead and get started. So review, lighting optimization. Now this is covered in some of the foundational lighting courses but we will be pointing out a few things specifically for ICV effects and linear workflows. With some mentions to games because there are some very fundamental principles for both"},{"start":"1:39","end":"2:13","startSec":99.4,"text":"of these that need to be considered when working with lighting. So let's go ahead and get started. So analyzing scenes and priority areas. The approach. You need to determine up front if you're using lumen versus ray tracing versus baked lighting. This is really important because with each type of lighting comes some things you need to consider. This can be determined if final pixel is your goal or ICV effects. Even games also depend on the strength of the machine's running. And you also need to consider where you're sending your information to."},{"start":"2:13","end":"2:44","startSec":133.2,"text":"So are you going to be in the case of games are you packaging it out for mobile or for iPads. Are you in the case of ICV effects on a large wall with high performance machines that you're sending to the via switchboard or are you working with a lower end scene or output and final pixel. What kind of GPO are you running when you decide to do and work with your machines. What is the best approach with those restrictions in mind."},{"start":"2:44","end":"3:19","startSec":164.6,"text":"So no lumen is currently available for ICV effects but takes some material and noise overhead. So you need to consider those things. Ray tracing is not effective for ICV effects. But for virtual production you can use it or in the case of final pixel. If used in games materials are a big part of the performance when it comes to ray tracing as well as small numerous geo and enclosed areas. So analyzing the scenes and priority areas. So your priorities are really important when it comes to ICV effects and virtual production."},{"start":"3:19","end":"3:50","startSec":199.0,"text":"You need to make sure that what's important what's up front needs to have the best visual fidelity and have the highest polys. So that's kind of the same principle when it comes to games. So if you're not worried when it comes to final pixel if you're not worried about frame rate typically. So ray tracing path tracer or lumen can be used or even a bake method with a combination of ray tracing at the same time if you wish. Out of the box unreal legacy baking does a great job."},{"start":"3:50","end":"4:22","startSec":230.7,"text":"So ray tracing or lumen may not always be needed. So just just depends what your visual and you need or want. The reason why I say that is because each one has a caveat. If we went to baking our reflections aren't going to be accurate. If we go to lumen we may find some noise that is persistent a little bit tricky to deal with. I say the effects lumen in this case is the best approach for instant results and output when it comes to putting stuff to your wall. But again you need to consider your materials and you need to consider what you can do to"},{"start":"4:22","end":"4:52","startSec":262.1,"text":"maybe hide some of that noise that is occurring. Others will pre bake or use GPU light mass and that also is an option for ICV effects. GPU baking makes things be a little bit faster if you have to update things on the fly on set versus CPU baking. Now we'll talk about the difference between those and it's a bit of review if you've taken some of the lighting classes but we're definitely going to look at some of those caveats. So keep those things in mind when you are tackling your scenes."},{"start":"4:52","end":"5:24","startSec":292.6,"text":"ICV effects approach having a good idea of the visual concepts ahead of time is key. A lot of people I find out working with clients and helping people out working in this workflow trying to get ICV effects or understand the concept of it in the context of Unreal. A lot of people will still think of Reels like an offline render and throw everything at it including the kitchen sink. But it doesn't work like that. You have to actually work within a real time within real time restrictions."},{"start":"5:24","end":"5:56","startSec":324.3,"text":"So again priority areas are key. Everything in the background can even be put on cards. So you can make an alpha that's clean and believable maybe even hide some of its impurities with fog cards or actual fog and you can actually come up with a really nice scene but you got to be very strategic when you do so. One thing people need to consider if they are looking at ray tracing it is not path tracing. In a real time scenario ray tracing is expensive. Lumion is the best approach for your LED volumes."},{"start":"5:56","end":"6:27","startSec":356.9,"text":"So keep those things in mind. So here's a couple comparisons here of how things are a bit more streamlined and work better when it comes to lumen versus baking. For ICV effects the dynamic lighting because all your lights are removable with lumen is ideal and optimized in 5.3 using level snapshots. We'll talk a little bit about level snapshots. We do have classes for that so we're not going to get too deep into it. They can be used for baking scenarios but they were primarily focused on or can update"},{"start":"6:27","end":"7:00","startSec":387.9,"text":"correctly better with stationary lights. Now when you introduce static lighting and you're trying to use level snapshots that's a little trickier because that bake information doesn't always slide across between each level snapshot that you made smoothly so it's better to use lumen if you can. For baking using a blueprint level streaming is an option which we'll briefly talk about for pre-computed lighting scenarios. Baked. That is better to be considered because Unreal can easily snap between them but there is"},{"start":"7:00","end":"7:34","startSec":420.7,"text":"a limitation where you only get about 3 otherwise you'll hit a GPU cap. So final pixel approach. Baking or ray tracing as well as lumen can be used depending on the need. Ray tracing many times will be used due to the fact that frame rate performance is not a concern when it comes to final pixel. So keep that in mind so if you just need a good final product you can turn down by using it in scaling turn down a bunch of effects and looks and feel and get the raw data you"},{"start":"7:34","end":"8:06","startSec":454.1,"text":"need then turn it on before you go to your final render and that can actually work pretty well. You'll see down below there's a lot of great things you can produce using baked lighting. All three of these are all baked lighting. This is the Australian outback sample that we had a while back. This is the rebirth demo that was done by Quixel before we acquired them and all of them are all baking. No ray tracing is involved. No lumen is involved for it hasn't come around yet and it's straight up baking."},{"start":"8:06","end":"8:21","startSec":486.6,"text":"Here's a link if you want to dive in more into these topics and get a better idea about optimizing. In the next section we're going to take a look at the lumen equation and have a deep dive into how to optimize and use lumen to the best of its ability. Thanks again."}],"03_Key WorkflowsLumenQualityControl":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Hi everyone, in this lesson we're going to take a look at the Lumen equation. We'll look at key workflows, limitations, and quality control. So let's get started. So Lumen fully supports ICVFX currently. There can be some noise that occurs, so just be aware of it in your materials. You can do some adjusting as well as controlling some of the quality there, but the noise may still persist in particular areas. So just keep in mind that Lumen is getting better and stronger with each new version."},{"start":"0:33","end":"1:07","startSec":34.0,"text":"It's good for Final Pixel and ICVFX, so feel free to play with those and experiment with them. It is quick and easy to use and updates on the fly. It does not currently support caustics, that is what Path Tracer is for. So make sure if you do need it, you can fake a few things with decals, which we've talked about in previous material classes, but for the most part, if you want that actual mathematical accuracy, you'll have to go into Path Tracer to do so. Again, like I said, it updates on the fly and Lumen is evolving."},{"start":"1:07","end":"1:38","startSec":67.6,"text":"It's getting better, faster, stronger with each new version. Now Lumen uses software ray tracing. So some limitations can come with this, so keep this in mind. So software ray tracing requires that levels be composed of modular geometry. So you need to make things pretty much like Legos. You need to build a wall, you need to build floors, and you need to make sure that they have some sort of thickness to them. If they don't have any thickness to them, you can run into problems."},{"start":"1:38","end":"2:09","startSec":98.0,"text":"The distance fields cannot represent extremely thin features or one-sided meshes seen from behind. So you make sure that you strategically position your meshes accordingly when that occurs. So keep that in mind because you can hit some light leaking if you're not careful. So something to keep in mind there when working with Lumen. So you can extrude them ahead of time in a DCC, then bring them in, or you can do them"},{"start":"2:09","end":"2:42","startSec":129.2,"text":"also in Unreal where you extrude them using the modeling tools. Just be aware that some UV navigation and editing will be needed at that point. So this has improved avoiding the light leaking in Unreal 5.3, and it's getting better stronger faster. But sometimes you just can't avoid the open geometry, such as scans, large mega scans, scanning that has been done, something that you and your company have scanned. There may be some open-ended areas, but try to seal this up if you can."},{"start":"2:42","end":"3:14","startSec":162.3,"text":"And it just makes things a little bit easier for the mesh distance fields and Lumen to be calculated correctly so we can prevent some of that light leaking that may be happening. So mesh distance field resolution is assigned based on the imported scale of the static mesh. This is something you have to be careful with. And I've been guilty of this when I first was introduced to Lumen, where you bring in a small item and you're like, hmm, I need that thing to be twice, three times, four times bigger than its actual size. And it mainly happens when you have a dramatic, like two times and maybe not so much, but"},{"start":"3:14","end":"3:45","startSec":194.7,"text":"something that you need to, that's really small and you make it a lot bigger. Once you've already imported into the scene, you can run into some weird build errors with your mesh distance field. So just keep that in mind. The resolution on that's going to be a little bit odd. So you make sure you do those ahead of time before you bring them in and decide to change their original size that came in. So Lumen provides two methods of ray tracing in the scene, software ray tracing and hardware ray tracing."},{"start":"3:45","end":"4:17","startSec":225.4,"text":"So this can be a little bit confusing for the people. So what's happening here is that ray tracing is helping elite, particularly with the software ray tracing. It uses mesh distance fields to operate on the widest range of the hardware and performs and platforms, but is limited to the types of geometry materials workflows it can effectively use. So there are some limitations there and that's where the hardware ray tracing leaning on that is going to be very supportive. It supports a larger range of geometry types for higher quality by tracing against the"},{"start":"4:17","end":"4:53","startSec":257.9,"text":"triangles and to evaluate lighting. This is where you can see the Nanite feature comes into play and helps greatly with this process. So we got virtual shadow maps and Nanite and Lumen. I call them the three musketeers and they all help you to have a nice and beautiful scene with the highest visual fidelity possible with the best performance. So to evaluate the lighting, this is actually pretty helpful in here where ray tracing is concerned and allows you to actually get some really great stuff instead of a lower quality."},{"start":"4:53","end":"5:27","startSec":293.6,"text":"Now the surface catch is an option where you can do a higher type of catch on your output for your objects. We'll talk about that in the quality control settings here. It requires supported video cards and systems to operate those. You got to make sure you have a good system under the hood that allows you to have some really great GPU processes to be able to lean on when you're using Lumen. So again, software ray tracing is the only performant option in scenes with many overlapping"},{"start":"5:27","end":"6:03","startSec":327.2,"text":"instances. It does help while hardware ray tracing is the only way to achieve high quality mirror reflections on a surface. So both give you a bit of the best of the world in Lumen and allow you to have some good performance going on and quality visuals. But remember, there may be some noise that still persists and you'll have to do some editing in there if that occurs. So Lumen is not compatible with forward shading, but why would you even try this?"},{"start":"6:03","end":"6:34","startSec":363.0,"text":"Because it does work great out of the box. You can also use forward shading on that topic. Was used quite often for VR, but now you can use Lumen for VR, which is pretty fantastic. So transparent materials aren't ignored by distance fields and mass materials are treated as opaque. So just be aware of that. There's a cafe scene that I show in one of my cinematic lighting courses and you can definitely see that effect where there's a blurred shader, spiral blurred shader in a node in the material."},{"start":"6:34","end":"7:05","startSec":394.2,"text":"And you can see that there's a bit of noise coming in and it doesn't quite know how to handle that because it's only on part of the material here and addressed and used on a particular area of the object, like a texture, like a mask. So it's mass materials can cause significant overshadowing on foliage too. So be aware of that too, where large areas of leaves are masked out. So just be aware and test it out visually. If you're getting noise, if it doesn't quite look quite right, go in there and do some editing after the fact."},{"start":"7:05","end":"7:37","startSec":425.3,"text":"Distance fields are built off of the properties of the material assigned to the static mass asset rather than the override component. So just be aware of this, overriding with a material that has a different blend mode or that has two-sided property enabled will cause a mismatch between the triangle representation and the mesh's distance field representation. So just be aware of this. That blend mode and two-sided might give you a little bit of issue. I haven't come across a lot of problems with the two-sided mode being on, on an object."},{"start":"7:37","end":"8:07","startSec":457.4,"text":"But then again, you always have to be very deterministic when looking at your foliage in small areas. Where there can be an issue though is where you have a bright cloud and you have a foliage object in front of it and that cloud is giving off a little bit of say, emissive and it has glowing properties. What happens is that's when you're going to see this two-sided foliage blended mode and masked issues occur, there may be some flickering with that foliage that's in front of that particular object."},{"start":"8:07","end":"8:39","startSec":487.9,"text":"So what do you have to do at that point is be very strategic moving things around. We go over that in world building for virtual production, but I wanted to make mention of that. So keep that in mind. So let's go and take a look at some of the quality settings in here in Unreal. Again, as you increase these numbers, your GPU, it can be expensive for your GPU. So you try to start low and then go high. Now they can, we do go over this in our foundational lighting courses, but I want to walk you through this before we get on to the next topic."},{"start":"8:39","end":"9:09","startSec":519.1,"text":"So let's go and jump into Unreal for a bit. So in Unreal, in our scene, let's go ahead and get our post-process volume. In my post-process volume here, I'm going to scroll down a bit here, close a few things we don't need open. We'll see that we're in Lumen and we have Lumen global illumination. We do want to make sure a few things are turned off, which we'll talk about later, to make sure that we have the best possible performance here. Now if I increase my light, you'll notice there isn't a whole lot of light bouncing around in this area here, but if I increase my light, you will see actually your GI get a little"},{"start":"9:09","end":"9:42","startSec":549.9,"text":"bit stronger, but you have to take an account how bright you want your scene to be. Now that's when you would bring in something such as a simple light such as a rec light, so you want to maybe fake some bouncing going on. So I can simply just bring this in here, move it up out of the way, increase its size a bit if I wanted to. So with its size increased, I can now fake that bouncing that is going on by increasing also the amount of light I have and maybe even change it to be a little more yellow."},{"start":"9:42","end":"10:12","startSec":582.3,"text":"So we're faking that sand, giving me some feedback. So that's one way you can cheat if you need to, if you don't want to increase your overall lighting, just a quick pro tip there and no one is the wiser. So let's go ahead and delete that for a second here. And let's go ahead and take a look at that post process volume. So in this post process volume, you'll see that our global illumination is Lumen. So we have our scene Lumen scene lighting quality set up to two."},{"start":"10:12","end":"10:43","startSec":612.8,"text":"Now if you want to, you can say, hey man, I'm going to go maybe three, you can do that. Two works pretty well, but you can go a bit higher. This overall quality here, you'll see scales Lumen scenes quality, but larger scales cause Lumen scene to be calculated with a higher fidelity, which can be a visible in reflections but increased if you cost. So you're going to see some better reflections as you increase this number, but it's going to cost your GPU. Now we definitely want to increase our Lumen scene detail. So let's go and increase that here."},{"start":"10:43","end":"11:14","startSec":643.1,"text":"We're going to keep that at four. And again, this one sure smaller objects are represented, so, but again, it does cost some GPU memory. We have Lumen scene view distance so we can increase the influence of our Lumen accuracy in our whole environment between that out. We definitely want to increase our final gather quality. This is going to remove some noise that's in our scene. And we also have max trace distance. Again, I leave that at default, but you can go ahead and it will increase the area that you're tracing against for your scene."},{"start":"11:14","end":"11:49","startSec":674.2,"text":"The values too small will cause lighting to leak into large caves. So yeah, we got a cave here and we don't want that. So we want to keep this at the default and we can go maybe a little bit higher if we needed. So and we also have seen catcher catch our resolution scale here. So again, this is helps with our overall look and feel smaller values save GPU memory at a cost and quality. So this is going to give us our Lumen surface resolution control here."},{"start":"11:49","end":"12:20","startSec":709.8,"text":"Down below we have the advanced settings we can open up here. Now this is going to give us a refresh that we need speedily and we want to increase this if we can. Now this all depends on your GPU. There's a cheap type of you know, you can think of it as a saturation boost here, diffuse boost here if you wanted to, you can increase that if you wanted to in your scene. Now we don't really need to do that, but we can say I want to do five, you'll see you get a little brighter. But this can actually maybe help in some areas when you want to get a little bit more of a bounce."},{"start":"12:20","end":"12:53","startSec":740.8,"text":"Watch the sand here as they go increase decrease that number. So it's at four right now, but I can go and switch that back to one. You'll see that get darker. I could even go as high as 10 if I wanted to. But again, that just gives you kind of a fake type of setting there and you'll see it if you're not careful. It can pulse a little bit. So just keep that in mind. I like to keep that just as a default one and that works just fine. You can even keep that at a zero if you wanted to. They have no reaction whatsoever. Well, I forget that zero doesn't really take it does take a one."},{"start":"12:53","end":"13:26","startSec":773.3,"text":"My bad for that. And it will not go. It refuse. It resists. It will not go any lower. Makes sense. This tells you that it's always active and available and then you can change it from there. So we have skylight leaking here. Now in ray tracing before used to have to evaluate your skylight and so forth and make sure that it's working because you would get dark areas. This allows you to control that type of feature here. So we have skylight leaking and you'll see Unreal helps you out here. This allows for your interiors, your indoors not to go fully black and allows you to control"},{"start":"13:26","end":"13:57","startSec":807.0,"text":"that if you need to. Mine's a little bit dark. So if I wanted to, I could increase this like maybe two, but you'll notice it brightens my sand a little too much. It doesn't quite give me the bounce. It's really dark over here on this particular object. So what I can do is just let's move that back down to its default zero and I can put that light in there. That's one reason I brought that up in the beginning and just bounce it in here artificially. Now also you want to make sure that you're using nanite."},{"start":"13:57","end":"14:27","startSec":837.2,"text":"So if I'm not using nanite, I want to find that piece of geometry right click in here and make sure that nanite is active. This is going to work a bit better in using our virtual shadow maps. Again does get a little bit dark in some areas, but you'll notice as I move my light around, everything's being calculated accurately. It's just that my light isn't very bright and it isn't very high in the sky. So if I wanted to, I can increase my light even more and you'll actually see the light bounce in areas that you want."},{"start":"14:27","end":"14:59","startSec":867.2,"text":"This is really up to you as you're working through this, but I'm always using fill lights as much as possible. And again, that's why I mentioned that earlier. We can use a fill light to get our light to bounce around like we need and those darker areas won't be so persistent. So if we go back to our post-process volume here, let's go back down. You'll notice we also have the full light leaking distance. You can actually control that too distance wise if you need. So just basically how much of that is going to be influencing our Lumen environment."},{"start":"14:59","end":"15:31","startSec":899.7,"text":"Down below we have our Lumen Reflections Quality Control Ray Lighting mode. Notice mine's set to hit. We have some water we want to have nicely represented. So you want to make sure that that set had a good amount. So let me actually move my light back down again. So we're not having completely blown out scene. And if I want to, I can just lower my lighting just a little bit there, move it around and maybe move it higher into the sky here. We get like an overcast today in the Caribbean."},{"start":"15:31","end":"16:01","startSec":931.4,"text":"So you can actually get some really cool effects here. Cool. All right. So back to my post-process volume again. It's going down a little bit. You'll see again we have high quality translucency reflections here, which we need for our water. Can't talk today. For sure. And then we have max reflection bounces. We have set these to three. We're kind of far away from the water and we're getting probably a little bit of noise there. So I'm not too worried about that so much."},{"start":"16:01","end":"16:33","startSec":961.5,"text":"What we can do is just edit that material if we needed to a little bit more and get things into a better position here. Now again, noise will persist a little bit in some areas. And notice we have a glowing environment here for our fog. And in that we have some thin areas, which are getting a little bit of noise. So again, if you want to, you can actually reposition or make your clouds a little bit lighter if you needed to and even dumb down your fog. Now in this particular case, our fogs, exponential height fog, if we scroll up, let's go back"},{"start":"16:33","end":"17:04","startSec":993.6,"text":"up here for a second. Notice we're not using volumetric. So if I turn on volumetrics and I decided to maybe just tone them down a little bit, you can get maybe slightly less amounts of that going on. But you'll notice it does flicker a little bit with the trees and these thin areas. What I would want to do is go and maybe make my clouds a little bit less persistent with their positioning and move things around. And you can do that choosing whatever cloud system that you want to use. Now you'll see a volumetric cloud."},{"start":"17:04","end":"17:20","startSec":1024.1,"text":"Notice our material and then we can just go into the material and maybe just play with some of the parameters in here. That's it with this one. In the next video, we're going to take a look at some key points in Lumen and some other details to get the best inner editing when it comes to using it. Thanks again."}],"04_LumenKeyPointsOptimizeEditing_53":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"In this lesson, let's go and take a look at some key points when it comes to Lumen, as well as some optimizing and editing that we can do. So let's get started. One of the things you want to make sure you do when working with Lumen is you want to make sure that you're turning off any static lighting that may be on by default. So we have allow static lighting, and we also have ambient occlusion static fraction bake lighting. We want to turn these off because we're not using baking. This is for better AO built into Lumen, and we're not leaning on any other kind of defaults"},{"start":"0:35","end":"1:05","startSec":35.4,"text":"in here for lighting. And to make sure you're not using the old default. So again, turning those off, and you'll find these in your project settings, you want to turn off your ambient occlusion static fraction, and you want to turn off your allow static lighting. Turn those off. So the bottom graphic here is what you want to shoot for. You also can adjust and fix any mesh distance field issues that you may be coming into where it doesn't quite look as clean as you want."},{"start":"1:05","end":"1:40","startSec":65.7,"text":"So in under rendering in our project settings, we can go to our distance field voxel density and increase that as we need to. But keep in mind as you increase that, it does get a bit expensive GPU wise. So just note to self, also in each individual object, you can actually go into the distance field resolution scale and increase it if you feel that that shadow needs better representation. Typically out of the box, it does a really good job, but we haven't implemented these in here so that if you need to adjust them, you can and you can go to these two areas."},{"start":"1:40","end":"2:11","startSec":100.0,"text":"One, the project settings into inside of the object itself. So again, like I say all the time, it's good to practice to pair Lumen with that night for a high visual fidelity, as well as virtual shadow maps. So you want to make sure you're working with all of these and you're going to get a bit more realistic of a scene and be able to put more into the scene as you build it out. So hardware ray tracing. So it supports a larger range of geometry like we mentioned before, more types than"},{"start":"2:11","end":"2:42","startSec":131.6,"text":"software ray tracing. In particular, it supports tracing against skin dimensions, which is really important. Software ray tracing also scales up better to higher qualities and it intersects against the actual triangles and has the option to evaluate lighting at the ray hit instead of the lower quality surface catch. And this is something that we mentioned before. So make sure you keep that in mind. This is really important because you can actually get a better quality overall visual representation"},{"start":"2:42","end":"3:17","startSec":162.4,"text":"for your scene and you'll see software ray tracing mode here. There's a detail tracing and there's a hit lighting reflection. So you can actually bump these up to get better visuals overall. And again, you can find this under engine rendering, which we talked about in the beginning of the course. So optimizing and editing in Unreal. So what happens when it comes to Lumen is a Lumen captures the material properties for each mesh from multiple angles. It's called cards and it digest this information so that it lets Lumen know exactly how that"},{"start":"3:17","end":"3:49","startSec":197.3,"text":"geometry is built and how to get it at the best possible representation in your real time 3D scenario. Now you can increase these cards or I should say you should be able to not only increase the cards, but you can actually see them. So this first output log, I should say CVAR in here, they can put into your output log or your console variables. You can actually see the cards in place. And let me show you what I mean. Let's go ahead and go to Unreal and implement this."},{"start":"3:49","end":"4:20","startSec":229.0,"text":"So I'm going to go ahead and just go simply to the output log. I'm going to go and place this in here and hit enter. And we can now see the cards here that are being digested. And it's actually calculating and using these little volumetric boxes here to give us the needed visuals in our scene. It's actually taking that information from each piece of geometry. And you can see it in here masked out and captured within each cube that these cards"},{"start":"4:20","end":"4:56","startSec":260.5,"text":"are evaluating and looking at our overall scene. Now if you ever forget what these do and you're like card placement, show me where the cards are to help Lumen do its work, you can also put a question mark and then Unreal will give you a brief breakdown of what it does. Now in this particular case it has failed. It doesn't do it all the time. But this allows you to actually see, you can put a question mark around most of all the CVARs and it'll tell you what it does. So the surface cache here can be used to see areas that don't have surface cache on coverage."},{"start":"4:56","end":"5:29","startSec":296.0,"text":"They are colored pink in the surface cache and view mode of the level editor. And you can see this if we switch to that in Unreal, you can see some of this going on with the cliffs. Now one thing I want to point out here, there's a lot of errors on this particular piece of geometry. And the reason why is because this piece of geometry is not built in a modular fashion, which it should be. So when you build things for Lumen, you want to make sure that you're building an actual wall, a wall in pieces, the floor, the ceiling, and you want to build it logically like something's"},{"start":"5:29","end":"5:59","startSec":329.0,"text":"actually built, like LEGO. You can think of it that way. And that gives you the best possible calculation with less light leaking or any obscure shadow areas going on. So that's how you want to approach that. And that's why you're seeing a lot of errors on this particular piece of geometry. Let's go to Unreal and turn this on briefly and you can see what I'm talking about. So in here, we'll go to our lit mode and we're going to go to Lumen and you can see surface cache."},{"start":"5:59","end":"6:30","startSec":360.0,"text":"So again, it tells you visualizes Lumen surface cache and pink is missing surface cache coverage yellow called meshes. So if we click on this, you'll see there are a few areas where we're getting some errors, but they're not major. We don't have to worry about them too much. There's just some areas where it's not quite getting as digested and being processed exactly the way that we want."},{"start":"6:30","end":"7:03","startSec":390.3,"text":"But overall, it's not too bad. And we can go ahead and turn that off. The reason why this is doing a bit better, obviously, dramatically better compared to that room that I showed you example of is because we've built this in separate pieces. But there are thin pieces of geometry in here due to the fact that these are been have been scanned, the nature of scanning, these guys are hollow. If I really needed to, I could take them into a DCC, thicken them out and do a little UV and then I could do the same thing even in Unreal using the modeling tools because you'll"},{"start":"7:03","end":"7:36","startSec":423.6,"text":"see that they are quite thin. And you can see in the backside a lot of light leaking that is occurring because they are thin having solid geometry is always the best if you possibly can get that implemented. So this occurs a lot of the times when you have a complicated piece of geometry and you can actually help yourself out if you break those pieces up a bit and again, build it like Legos. But you can also increase the Lumen card in here. You can make it so you have more cards per task in here."},{"start":"7:36","end":"8:09","startSec":456.6,"text":"So you can see max Lumen mesh cards. We can increase that max Lumen mesh cards to a higher number of value. Now, again, this is up to you and how you edit your piece of geometry and how it was built, how it was scanned. There's multiple factors in here to be able to get your scene to look a bit better if for some reason you're noticing that things aren't quite looking as cleanly as you'd want them to because these areas will not bounce light and will appear black in your"},{"start":"8:09","end":"8:39","startSec":489.8,"text":"reflections and you kind of want to avoid that. Now, again, I repeat this quite often. Use Nenite as much as possible with Lumen for best results. If you decide to mix it up and use Nenites and you're using LUDs, you can get a performance effect because they're not really made for that. I mean, you can use Nenite for a regular baking scenario, but if you do on the flip side, use LUD and Nenite, you've got to be careful with that. We've had some gaming clients run into issues with that, especially for larger environments."},{"start":"8:39","end":"9:13","startSec":520.0,"text":"So for the best performance, again, Lumen, virtual shadow maps and Nenite are going to be your best approach. So in other words, Nenite accelerates the mesh captures used to keep the surface catch in sync with the triangle scene. So after the surface catch is populated with material properties, Lumen calculates direct and indirect lighting for these surface positions. So you can see how they really like each other. So projects with extreme overlapping instances can control the method Lumen uses with the"},{"start":"9:13","end":"9:46","startSec":554.0,"text":"project settings, software ray tracing mode. And Lumen provides two options to choose from. So we have detailed tracing and we have global tracing. So one is detailed tracing gives you higher visual fidelity. And then the global tracing is a bit more dumbed down and gives you some faster traces in here. It's the for the fastest traces you can possibly get with your global distance field. So you can think of it as performance versus your visuals. You again, this is a case by case, whatever you might need."},{"start":"9:46","end":"10:17","startSec":586.4,"text":"So that things look the best in the scenario that you've built. If you're noticing in your shadows as you're moving around in your environment, maybe from a larger distance and maybe more geared towards virtual production, less maybe advice to be effects, it just depends on where your camera is at. But if you're noticing your shadows seem to disappear, fade in and out, what you can do in each light, you can disable your ray tracing cast shadows. So let me show you where that's at in your light."},{"start":"10:17","end":"10:50","startSec":617.2,"text":"If you forgot. So in Unreal, if I click on my directional light, I can actually go down here to my advanced area here. And you'll see that we have a few things in the ray tracing department that has been set up. It's down here. I'm clicking the wrong area. So you'll see my cast ray traced shadows is disabled. So you can turn that off. If you're, if it seems like you're getting a shadow conflict where your shadows are popping in and out based on your camera coming closer or farther away from an object. So that's something you can do if you do run into that issue."},{"start":"10:53","end":"11:25","startSec":653.0,"text":"Now we also go over this particular tool on another class. If you needed to, you can also use a level snapshot so you can update what your visuals are in your scene on the fly. And the director and your production team is going to love it because then you can, you don't have to commit. You can actually change it. And I have a few of those in my scene and let me show you real quick briefly. Again, we do have a class that talks about this in detail, but I'm just going to show you kind of how cool it is. So I'm going to go in here and open up my level snapshot."},{"start":"11:25","end":"11:56","startSec":685.4,"text":"Now opening up my level snapshot, it shows me some really older ones we have here. I'm not going to worry about them right now. So what I'm going to do is go ahead and make a new one. So we're going to go and take a level snapshot of what we have. We'll give it a description. I'll just call this awesome. Just awesome. Nothing else. And we'll hit create. Now I'm not going to get into all the details for the interface. And then what we can do is make another one just simply by moving our camera around or"},{"start":"11:56","end":"12:28","startSec":716.4,"text":"I should say light. Excuse me. I say camera. I did. I did say camera. Make that a bit brighter. And we'll take a snapshot of that, maybe even changing it so it's a little more dramatic. Barely peeking the light in the side snapshot. Another awesome. And we'll say create level snapshot."},{"start":"12:28","end":"13:00","startSec":748.4,"text":"So you can flip through these once you've made them and you can actually play with them a bit and do whatever you want, which is actually kind of cool. So I can say, hey, I want to show off what this one looks like. You can double click on it. Restore level snapshot. It will show me. And then you can always go back to the one that you had before. Double click on it. Restore level snapshot. And it'll restore it. It'll actually shuffle even the geometry if you change your geometry. Now you'll notice my geometry degraded here because I had changed a few things."},{"start":"13:00","end":"13:25","startSec":781.0,"text":"So it went back to where that texture material was before. So it tries to keep all that stuff in memory. That's it with this lesson. Here's a few links that will help you get you in the right direction talking about those details in Lumen. And the next lesson, we're going to take a look at light mass and baking the old school way in Unreal using CPU and GPU light mass. Thanks again."}],"05_CPU Lightmass":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this lesson, we're going to go ahead and take a look at Lightmass, baking, CPU and GPU. So let's get started. So CPU, Lightmass and GPU can be used for baking. We're going to mainly focus here up front on CPU baking. And both of those are kind of the old school way to be able to bake out your lighting in a scene. Now, Lumen will update on the fly because the lights are dynamic and Lumen is dynamic and updates in real time."},{"start":"0:31","end":"1:05","startSec":31.6,"text":"But when it comes to CPU baking, particularly we and GPU, you have to actually go in here and set up your lights accordingly, bake out your lights, and then you'll get the desired look and feel for your scene. Now it's very important. There's several ways that are several things you need to keep in mind when working with this. And I will point these out. You want to anticipate your needs for sure when it comes to working with your scene ahead of time because baking will take some time, especially if your scene is large. Now GPU baking, GPU Lightmass baking does beat up the process."},{"start":"1:05","end":"1:38","startSec":65.2,"text":"But again, you have to come in with a strategy and a game plan to be able to actually work a little bit more efficient. And say you have to bake on set, immediately you want to make sure that you know exactly what you need and want, especially if changes are coming in pretty hot and heavy. Now Lumen is a more ideal approach. But again, I want to cover this because there may be some times when you're like, Lumen's doing great, but we just can't seem to get rid of noise in this particular area. And that's when you can lean upon your CPU and GPU baking."},{"start":"1:38","end":"2:11","startSec":98.3,"text":"So you always want to start low and then go high. And you want to keep things at a medium level when it comes to static lighting level scale. This details gives you details of your Lightmass. Remember of indirect, your indirect lighting bounces, keep that low. That's a brightness of your scene overall, basically your GI, kind of how that indirect lighting is bouncing around. Indirect lighting quality, try to keep that high if you can. This decreases artifact noise and indirect lighting smoothness, keep this low."},{"start":"2:11","end":"2:45","startSec":131.0,"text":"This blurs indirect lighting component in your light map. So again, keeping these things in mind as you work through your process. Now if you're unfamiliar with the baking process, maybe you're new to Unreal and you're more on the Lumen phase, let me point out where these things can be found. So in my world settings, you'll see that we have a Lightmass settings area. You'll see Lightmass as the topic. And from there, we would open this up. We see our static lighting level scale. Our scene's pretty small, so we don't have to adjust this too much. There are some darker shadow areas in here that we can clean it with some lights moving"},{"start":"2:45","end":"3:15","startSec":165.1,"text":"nearby. But some of this is caused because of the thickness that is not included in some of these rocks. And that can be a little bit tricky. So the same rule that we came across when it came to Lumen, it's kind of the same process here. We want to make sure we have thick pieces of geo. And you'll notice that I've extruded them in Unreal using the modeling tool. There's a bit of banding. And I'm not worried about the EVs on the other side. It's this side where I'm more concerned. Now if you don't do that, you can get these dark areas."},{"start":"3:15","end":"3:45","startSec":195.6,"text":"And let me show you a little bit up close. So if I go in here and bring in a rec light, anytime you bring in a new light, Unreal's going to give you a warning and say, buddy, you really do need to rebuild your lighting. And the two modes for your lights you're going to be in a constant, going to be in a constant positioning for is you want to make sure that you set things to either static, and that's for objects that don't move, and stationary. And that can be for objects that do move in your scene. But again, both lights do not move."},{"start":"3:45","end":"4:17","startSec":225.8,"text":"The stationary one is a bit more complicated than the static. The static is the cheapest. Stationary is the second to that. And movable is the most expensive since it's dynamic. Stationary allows you to change the intensity of the light and the color and your characters and moving objects to be affected by that light with the shadows updating. So in this light here, we can bring this into our scene. And then we would have to go in here and make it so this light is bouncing around in our environment. And you can see we can remove some of those dark areas simply by moving things around."},{"start":"4:17","end":"4:47","startSec":257.1,"text":"Now again, you can increase the strength of this light, and you can remove some of that. And you can also control your width and height when it comes to your scene in here. And as you do, the energy will kind of be removed from the object as you increase the size, because it is again, like a series of point lights inside of a rectangle or square, depending on what shape you choose. And it is the most expensive light, but you'll see we're removing some of those dark areas. Some of them may still persist in some regions, but that's a quick way to be able to get that"},{"start":"4:47","end":"5:18","startSec":287.8,"text":"up and running. But again, you want to keep things low when you're working in your scene. So that's one way you can fix it. And you can even bump up the saturation in some areas if it's persistent to maybe cheat some of that or even correct your texturing. But overall, your light map density needs to be of the same level. Well, what does that mean? So if we go to lit here and we go to optimization view modes, we want to go to our light map density here. And you can see it in here showing us different resolution types."},{"start":"5:18","end":"5:51","startSec":318.6,"text":"And you'll notice for teaching purposes, I've actually kept this one a bit high. This could be definitely a lot higher. I should say a bit low. This could definitely be a lot higher so that they have the same resolution between the rocks. So if I went in here, I would want to change this override and make it from a 62 or excuse me, a 62, a 64 and make that a bit higher. You'll see the other one here. He's a 128. So we kind of probably want a 128 here too. And the reason why we do that is it can prevent some of those dark regions that could occur"},{"start":"5:51","end":"6:22","startSec":351.9,"text":"and blobby areas working with your again, your world settings for your light mass. So let's go back into the light mass here. And I just want to give you some quick tips there for those dark regions that may occur. Now again, indirect lighting quality, we have control here, keep these numbers low initially. You can also control your overall color for your environment. Now all of these changes that I've just made, including if I chose to maybe change the color of everything, it's going to affect my final bake."},{"start":"6:22","end":"6:56","startSec":382.8,"text":"When you are baking, make sure that you set your builds to, if we go here to production. Now we're in preview. That means the build is going to be pretty quickly. But if you want to see that actual bounce, we want to set that to production. Let's go ahead and go back to the slides. So you also want to take into account what kind of light you're using, like we mentioned before, static versus stationary. Now if you decide that you need a movable light is a move in your scene, you need to make sure that mesh distance fields are active within your project settings."},{"start":"6:56","end":"7:28","startSec":416.2,"text":"Now again, you can use CPU light mass for final pixel, as well as ICVFX. And you can also use GPU light mass if you need it. So keep in mind that Lumen will probably be your best bet, especially if you want updates on the fly. So keep those things in mind when you're working with Unreal. Now your volumetric clouds are expensive and will need adjustment for CPU baking for believability. So they will not render accurately at this time with ray tracing."},{"start":"7:28","end":"8:02","startSec":448.9,"text":"So if you choose that, that is still on the roadmap. So keep that in mind. So never forget the power of the rec light. That's one reason I showed it to you. It can fill those areas that you need. And that even goes for Lumen, as you saw me do earlier, that will fill that space and give and fake some of the bounce light that we may or may not be getting immediately. So again, you can control on the point lights your source length and your source radius, as well as your overall view and feel and shape for that with those properties."},{"start":"8:02","end":"8:33","startSec":482.4,"text":"So let me actually jump into Unreal real quick. So if you do get a hot spot or say this, this is not highly reflective, but if it was, I could go in here and soften that up using my soft source radius. And unfortunately, it can pixelate your shadow. So just be aware of that. I just want to mention that too. Remember also too, when it comes to light mass, make sure you use area shadows for stationary light. So if this is a stationary light and I keep it like this, say I want to use it to maybe"},{"start":"8:33","end":"9:04","startSec":513.4,"text":"fill out some bounce light in here, I would again turn that on and then I would make a fresh build bake in this environment. So here are some pro tips when it comes to using CPU baking. Try to make sure your geo is solid. Now this is a golden rule working with Unreal as well as Lumen. Having hollowed out pieces of geometry can be tricky. So when intersected, it makes sense to Unreal. Now you will see some times where you might see that rule broken."},{"start":"9:04","end":"9:38","startSec":544.9,"text":"There's like a cafe that I use every once in a while. There's a thin floor. There's thin walls. It's really made for baking. And it works okay. It's not too bad. And there really isn't much light leaking. But as soon as I switch to Lumen, that's where things might be a little weird in some areas and some corners of it because the mesh distance field isn't quite calculated incorrectly, especially if I step out of that area or I rotate in such a way that those little thin areas are revealed in some way, the mesh distance field gets a bit confused."},{"start":"9:38","end":"10:12","startSec":578.5,"text":"You want to keep your light map resolution for intersecting geo, which I mentioned before, the same or at least in the same ballpark. This will prevent any blobby shadows on the seams, any weird light leaking that might be happening. Can't seem to say leaking before the leaking, leaking. I don't know what's happening. Or in tears, you can use light mass portals, but can be expensive. So use them deterministically. Now, light mass portals that you heard me mention earlier and other classes, light mass portals do not work with GPU light mass."},{"start":"10:12","end":"10:42","startSec":612.3,"text":"They only work with CPU. For some reason, do not calculate correctly. And they're basically put in front of opening of a cave or a window versus interior and an exterior. You're right for that cusp in that area where the values change, and that's what you would use it for. Rec lights were great for interiors as fill lights, but can be expensive. And again, they are point lights over that surface, like a series of point lights. So indirect lighting quality can be increased, but can be expensive with build times. Keep that in mind."},{"start":"10:42","end":"11:17","startSec":642.4,"text":"Default maybe fine and turn off compressed light maps. So you can do that again, inside of your world settings for light mass, and you can turn that compress off right there. Make sure the stationary lights are set to use area shadows, like I mentioned before also. So don't forget that. Outside of ICV effects, though, you can show to your director different lighting scenarios. Now you can use that level snapshot, but if you have a lot of static lights, it doesn't"},{"start":"11:17","end":"11:47","startSec":677.4,"text":"really work really cleanly. You can cheat a little bit and use a thing called a streaming level node. And we can use a level blueprint, but you can only show off three at a time. So that's a bit of the limitation. So this is again, why lumens a little bit better. Let me show you a little bit of how that works in engine. And you can get an idea of what I'm talking about. So in Unreal, I'm going to go to our class folder. I'm going to go to maps. And I'm going to go into here and click on base. Now it's going to ask you to save."},{"start":"11:47","end":"12:23","startSec":707.9,"text":"I'm really not saving anything. I'm going to click on base here. I'm going to say, don't save. Now when I open up this base file, you're going to notice that there's really not much to write home about. It's pretty much just a dark environment. So what I did, let me click on my drawer and click here, what I did was I created a level blueprint in here. So let's go and open this up. Let's open up our level blueprint. And in this level blueprint, I loaded other scenes that I already baked out the lights."},{"start":"12:23","end":"12:53","startSec":743.2,"text":"I created a thing called a multigate. You can also use a sequence if you wanted to. That one works just fine. So that's up to you. If you want to use that, you can see sequence here. Kind of works about the same way. I just basically use the multigate, which is used for weapon swapping. So I built this guy in here. I had a hotkey to start it out, created a level switch here, Boolean, put it into the loop, and I used a current level here, which is an integer."},{"start":"12:53","end":"13:23","startSec":773.5,"text":"And I put it into the start index so it actually knows my intentions. From there, I created a unload stream level and a load stream level. I started out with one of my choice, which is like the day one that I baked out daylighting. And I cycled it through. There's a night one. You load it. You unload it. You unload it. It's really that easy. Load it, unload it. And then make sure that you compile once you get everything in there that you need. I do want to point out, though, as you click on this, you want to make sure you have make"},{"start":"13:23","end":"13:54","startSec":803.9,"text":"visible after load, make visible after load, and make visible after load for all of the load streaming little nodes that we have here, little sets that we have. So in my multigate, you notice it's pretty simple. Level switch here. You make sure you turn on level switch. Click on that little node there. And we have current level. You'll notice that's just set by default, but we are using an integer setting that to that. And then now you got to make sure you get the names right."},{"start":"13:54","end":"14:26","startSec":834.7,"text":"That's really super important. So once you get the names right, we can now go in here in our scene. And if I hit play, now, again, this is why it's not really used for ICVFX because you can't do this with a switchboard setup and so forth. But if you're doing virtual production, this actually works pretty well. I can hit play and click in the environment and hit X. And I can load, hey, there's my kind of nighttime area. Here's my super blue, not sure just the super blue day planet of blueness. And then we have our daytime in here."},{"start":"14:26","end":"14:59","startSec":866.5,"text":"And I'm just cycling through and we can fly through the environment too. And we can see a comparable of these different environment lighting scenarios. So you only get three. Now, I have a really powerful computer. It's an A6000 threadripper. And I am at my max limit GPU-wise, so I can't do a fourth. So just keep that in mind. Let's go back to the slides. So if you're interested, I'll walk you through each one of these. Again, I do recommend level snapshot using Lumen, but this is another one that you can"},{"start":"14:59","end":"15:28","startSec":899.1,"text":"use. If you were to use level snapshot, make sure that you have primarily stationary lights in your environment. Lighting between bakes can be a little bit clunky for static lighting, but stationary light seems to work OK with level snapshot. But mostly you want to use that for Lumen. And again, each step is walking you through how these work. That's it for this video. In the next video, we're going to take a look at GPU light mass in detail and how that works. Thanks again."},{"start":"15:35","end":"15:37","startSec":936.0,"text":"Thank you."}],"06_GPU Lightmass":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In this lesson, we're going to go and take a look at GPU light mass in detail for optimization. And it's going to be a bit of a review. So let's go ahead and tackle that. So GPU light mass, it basically improves on the current light baking system, or I should say the older light baking system. It uses a progressive light mapper with optional real time preview in the viewport. So offering multiple modes for building lighting. You can do a full bake, or you can bake what you see, which will help speed things up."},{"start":"0:32","end":"1:04","startSec":32.9,"text":"It significantly increases the speed of light bakes for complex scenes, producing a more physically accurate result than CPU based light mass, but it has more limitations. There's a few things we'll talk about on the back end of this on what those limitations might be. So in review, again, we were reviewing this, the other foundational courses talk about this. First up, you do need to turn it on to your plugins. But from there, you also want to make sure your DirectX 12 should be on by default. But you do need to enable ray tracing."},{"start":"1:04","end":"1:35","startSec":64.4,"text":"That needs to be on. Virtual texturing and virtual texture light maps can show you your interactive preview as you're working. If you're working in ICVFX, you don't necessarily need these unless virtual texturing you're using them. But for the most part, that update, as you see the bar build things is not really necessary. The GPU light mask window is now after you do all this accessible to be able to look at your stuff and to do a quality control pass. So some of the settings here we're going to briefly talk about."},{"start":"1:35","end":"2:06","startSec":95.8,"text":"We're not going to get too much into buttonology. This is a review, but I'm going to start talking about some of the key features and things to look out for. One, again, you have the option to full bake or partially bake. Make sure you turn off your compressed light maps in your scene. Here you GI samples and stationary light shadow samples. You can control that as a sweeping control. I like to do those on individual level because it's a case by case. Volumetric light map, a simplified option version of the CPU volumetric light map control."},{"start":"2:06","end":"2:36","startSec":126.0,"text":"So you have a little bit of quality control there and iridescence cashing here. So helps with interior scenes may not be needed to be adjusted. The default works pretty well. So workflows here, you have a denoiser here. No denoising is applied to the lighting render. And this can be useful for to determine a number of GI samples. So it's up to you how you edit those. We can look at the settings in just a bit here."},{"start":"2:36","end":"3:08","startSec":156.4,"text":"On completion denoises the results of the light build. So it makes it a bit cleaner for you. During the interactive preview, you can also have this here. It will denoise it on the fly. You have those options, either none on completion or interactively. And you can see it do its job. Now let's go back into Unreal and we'll get back to this slide. And we're going to take a look at those settings up close. So in my scene here, you'll see that my build is active and ready to go. There's a viewport real time is on."},{"start":"3:08","end":"3:38","startSec":188.4,"text":"If I wanted to, I could turn that off. I'm just leaving mine on for now. There's a full bake or you can just bake what you see. Again, that option is available for you. And the denoiser, I have mine the default set on completion. And again, you can say no or you can have it during the interactive. So you really do want to try to use that denoiser if you can. You'll see it says Intel open image denoiser, which works really well. We have GI samples. Most of these default work pretty great and it is pretty darn fast and compared to the CPU build."},{"start":"3:38","end":"4:09","startSec":218.8,"text":"So all of these are at your fingertips. Now let's talk about a few things when it comes to some pro tips and some optimizing. So final pixel, it's helpful to speed up things and get them ready to go if you need it. But again, I would lean more towards the lumen or even a path tracer if you're going for a better visual overall control because there are limitations with reflections and reflective properties. They just won't quite look right, especially if they're clear and you can see characters walking past them."},{"start":"4:09","end":"4:43","startSec":249.7,"text":"It's a little bit of a stretch and you'll have to do some tweaking to try to get it. And there's still high levels of limitations there. And the fact that the reflections won't look realistic, they'll be screen spaced. So you might want to switch to path tracer or even ray tracing or lumen in that case to be able to get the better visuals in that area. ICVFX, it can be perfect for making quick lighting changes and can be combined with ray tracing, but you'll have to play with that workflow a bit. I'll mention it. But again, I do want to encourage everyone to try to lean towards lumen if you can because"},{"start":"4:43","end":"5:15","startSec":283.5,"text":"lumen is going to give you the best results, but there may be a shot where you have lots of noise and you can't get past it. Then you can actually maybe use this light mass GPU on that case and be able to tweak things accordingly. After you do a build, you want to make sure that you go to ray tracing and you turn off all those effects. Let's actually look at a build that I just made and run this CVAR and you can see what I'm talking about. So once I have this build set up and you see that we've built this, ignore this up here, it's a little bit of an error."},{"start":"5:15","end":"5:48","startSec":315.3,"text":"It's an older conversion from an older version of Unreal, which will continually tell me it needs to be rebuilt, but it's already done. So I'm going to go to my output here and I'm going to do control V. And I'm going to go ahead and get rid of all my ray tracing effects. And this is going to give me the true bake because remember, GPU light masses using some of that ray tracing to be able to speed up our process. Unfortunately, some of that can still be into here and will give us kind of false results. So I'm going to hit enter. And when you do that, you now actually make it so that the ray tracing is gone. Now I may have already run this command in the past and that's fine."},{"start":"5:48","end":"6:21","startSec":348.8,"text":"But for the most part, that removes any errors that may be occurring in here and no ray tracing is going to be set in. So again, you want to run that CVAR when you can. Again, that makes it so that that is we're not using any kind of ray tracing. We're turning it off so that it doesn't interfere with our final results with our scene. Now again, you can turn them on if you need to, and you can turn them off if you need to. You'll see it's turned them on and I will turn it off again just so that you know we are"},{"start":"6:21","end":"6:52","startSec":381.6,"text":"in the mode we need to. You can see the shift there. So that's probably just because I ran that console out in the past. Cool. Awesome. So when running GPU light mass, you may run into a TDR delay situation happening. If you do, make sure you go into your windows and you want to go to your local machine here and then you want to set your TDR delay. You want to modify that and set it to like 60 if you need to. You can even go a bit higher if you need to. Never mind here where it says an old reference link."},{"start":"6:52","end":"7:27","startSec":412.1,"text":"This is still valid and it's basically just the TDR information that we're using. And yep. Here's some limitations and things you need to consider. So light mass portals are not supported. We talked about that before. Real depth offset is still not supported yet. Lighting channels not supported. Use light mass importance volumes to help with volumetric light maps. This is really important to consider because using a light mass importance volume is used in a regular CPU baking environment and you can find that under volumes but you really"},{"start":"7:27","end":"8:00","startSec":447.7,"text":"do need it for GPU light mass especially for characters moving around because it actually helps unreal digest that information for characters moving around for updated shadows. Now typically in CPU you want to use that because you have priority areas especially for a larger scene or maybe you're working with terrain but it's really key when it comes to the GPU light mass. World position offset is not supported. Texture encoding and denoising are run on CPU and are not affected by multi GPUs. You can consider that if you are using the system."},{"start":"8:00","end":"8:31","startSec":480.2,"text":"Very skylight currently not supported but on the roadmap and custom settings and properties of the lights some things such as indirect lighting intensity source texture and a few other things are not fully supported and quite there yet. You see a list of limitations found here which can also help you in the direction for 5.3. Also light channels are not supported so make note of that also. That's it with this section. In the next section we're going to go ahead and take a look at screen space global illumination."},{"start":"8:31","end":"8:32","startSec":511.7,"text":"Thanks again."}],"07_SSGI":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"In this lesson, we're going to go and take a look at screen space and global illumination. So let's get started. So screen space global illumination can be activated within our project settings and also within the Puzz process volume. Let me point out where those are at and then we're going to look at a few things we can do to actually do a little quality control and things to look out for, especially if you're using it for ICVFX. So in my scene here, what I want to do is first go into my project settings. Again, you can activate this after the fact if you want to, but in your project settings,"},{"start":"0:35","end":"1:07","startSec":35.0,"text":"if your intentions are to use it, it's good to actually have it on anyway. So we would go underneath and take a look at our settings here. You'll see under reflection method, we have screen space global illumination active. We have overall we have ray tracing in here. And that's because if we want to use GPU, if we want to use GPU light mask, we actually want to turn this on and make sure that it is on. If you don't have this on, it won't work. So it's using ray tracing in this particular case, but we can also use screen space."},{"start":"1:07","end":"1:39","startSec":67.0,"text":"If we wanted to for our GI, you just have to be careful if you decide to do that, even in your overrides, you have to keep those things in mind. Screen space will give you a bit of a clipping that could occur if you're using it for ICVFX. So you've got to be aware of that because when you move your camera, you can see glowing objects and certain materials start to clip away and you'll have to do a bit of an over scan. Let's talk about that. So it's not necessarily the norm to use this type of effect."},{"start":"1:39","end":"2:12","startSec":99.7,"text":"And again, you can see the two areas where we can turn it on. If you decide to use it in your scene and maybe you're not using GPU light mask and you're using regular CPU bake, you again want to change that in your global illumination settings. And they can also be done in your post process volume. But just keep in mind, if your scene isn't very big, that might be okay. But if it's a large scene, it takes a while to bake for updates needed by the director. That might be a little bit of a problem. So if you do decide to use it though, in that context, you want to go into your, your NDC"},{"start":"2:12","end":"2:43","startSec":132.2,"text":"in your NDC, you want to go to your viewport over scan. And in here, you want to make sure that you're making it just a little bit bigger than your area of interest. And this is going to be very important because as you move your camera around, like I said before, your, if you don't do this, you can actually get clipping on the edges of your camera. So you want to make sure you over scan that just a bit so that that clipping does not occur at the edge of your camera. If we go to Unreal, we can see here a viewport over scan option here."},{"start":"2:43","end":"3:18","startSec":163.3,"text":"And we also have viewport screen percentages. So we can actually change these as we need. There's the main wall. So we can enable this if we need to over scan and choose how much we want to shift things. Same thing with the sidewall and same thing with the wild wall. This is up to you how you do so. Just keep this in mind that it is a good idea to over scan if you are going to use this method. Rating space also has several quality settings that you can enable using the following commands. In using your console variable, you can use r.ssgi for quality and using number between"},{"start":"3:18","end":"3:52","startSec":198.2,"text":"one and four to control that quality. You'll see the number chart that I placed in the lecture here. It says one is ray steps eight, ray count four, two, ray steps eight, ray count eight, three, ray steps eight, ray count 16, and four here, ray steps 12, and ray count 32. So the resolution command to render at half resolution is dart.ssgi for half res. To use previous frames seeing color to achieve better quality results, you can use r.ssgi"},{"start":"3:52","end":"4:28","startSec":233.0,"text":"for minimum illuminance. So these are things that you can use. Remember these number counts between one and four for quality control here is at the top, but these ray counts you do need to keep in mind exactly what it is you're going for, what your visuals are going to be, and if you're going to over scan overall. Now again, using screens, physical illumination isn't the typical norm. Typically you would use Lumen and just adjust your materials and build your scene accordingly. This is an option for possibly maybe lower end machines or you're maybe running to situations"},{"start":"4:28","end":"5:04","startSec":268.4,"text":"where the noise is a bit too much. You may then want to switch to this and it's actually a pretty cheap way to use things. And let me show you a few things to keep in mind if you decide to use it. So in this case, we'll just pretend ours is on. Right now we're currently using ray tracing for our GI and I'm in the secondary post process volume reference. If you are looking this and downloading this for the class, I'm just using this particular lot one that's already been loaded. So in here, you'll see that we can actually go to our advanced settings and when we have it on."},{"start":"5:04","end":"5:35","startSec":304.3,"text":"And let's see if we can just go ahead and pop this on real quick. We want to Lumen, we're going to do a screen space in this case. Let's see things shift a little bit. You can correct your indirect lighting color and your indirect lighting intensity. So these things can be controlled. You see a little bit of a popping going on here. And you also see a little bit of a color shift if I choose to. Now this is contained within our post process volume, but this is up to you and it may conflict a bit with our light. But you have that option to be able to control this on a very low level."},{"start":"5:35","end":"6:06","startSec":335.5,"text":"And you'll see a little bit of brightness going on if you were to use it. And these overrides work pretty well. I'm going to set that to none. I'm going to put that as method, turn that off in general and turn these off too. But the advanced area is where you're going to get the ability to be able to control the brightness of that if you decided to go in this direction. Typically when you use SSGI, you want to make sure that you're using it in such a way so that it's complimentary to previously baked items that you have in your scene. That's typically what it's used with. Does that mean you can't use it with ray tracing?"},{"start":"6:06","end":"6:38","startSec":367.0,"text":"Well, you actually can. And for some reason you're using ray tracing and you're noticing it's very slowing. It's slowing down greatly. Your brute force seems to be bringing things to a crawl. Maybe you're not on stage. Maybe it's just simply for virtual production or final pixel. You can switch into your global illumination to be screen space in general. And that would actually make things go a little bit smoother. Just keep in mind the difference between those because you can keep ray trace reflections on and use screen space in that particular scenario. Again, you want to be able to block this out."},{"start":"6:38","end":"7:01","startSec":398.4,"text":"You want to make sure things are exactly the way that you want ahead of time. So just be very deterministic, but typically it's used as a complementary tool for your baking scenarios. That's it with this lecture. Here's a link here for you to dive in deeper on these particular topics. Thanks again. And in the next video, we're going to go and take a look at ICVFX when it comes to ray tracing as a bit of a review."}],"08_RayTracingReview":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this lesson, we're going to go ahead and take a look at Final Pixel and ICBFX workflows when it comes to ray tracing. This is a bit of a review from previous classes, but let's go ahead and get started. So here are a few things to keep in mind when working with ray tracing. One, you want to keep the ray tracing environment small. So you only use ray tracing in a small region for performance costs. And the reason why you do that is mainly because of the photon bounces that go around, they can get costly if your scene is quite huge."},{"start":"0:31","end":"1:01","startSec":31.7,"text":"And you will see your frame rates drop. It can be mixed with baking as needed so you could bake in the background and then do ray tracing in a small contained area in your post-process volume. With ray tracing, keeping in mind your polycount is very key. You want to make sure you avoid having really tiny details like if you have a lot of foliage and a lot of plants, it doesn't mean you can't do it. It's just the photons bouncing back from those cards going back to the camera can get expensive"},{"start":"1:01","end":"1:32","startSec":62.0,"text":"as things get heavier. So you might want to put some maybe some alpha cards in the background to maybe fake some of those trees in the distance and so forth. Keep textures simple and roughness wise because that also can bring things to a crawl because then you're getting the photons trying to determine the material ID and material information on those objects. The higher the rough, the more complicated that's going to be for ray tracing to calculate"},{"start":"1:32","end":"2:03","startSec":92.6,"text":"that and get it back to the camera so that it has a fair representation of that object. So also you want to keep your, when you do use your textures, you can use virtual texturing. Your texture overhead, just make sure the priority areas are their main concern or the main thing so that your textures aren't really high everywhere. Material nodes, you can use a switch replacing or manual based kind of like a static switch parameter."},{"start":"2:03","end":"2:33","startSec":123.4,"text":"This is in previous classes I talked about how can you use either or when it comes to ray tracing. This is more per shot. This is one that manages things as you're working in your workflow. Overall, as your camera moves around in your environment, avoid physical lights intersecting into geo. That's really important because as you do that noise can be persistent. Say I got a simple light in my scene, it's a rec light and I'm pushing it through a wall, accidentally maybe it's clipping, you're going to see some noise show up on those materials"},{"start":"2:33","end":"3:06","startSec":153.7,"text":"if you're not careful. Use reflection probes and CVARS to manage hybrid output for best performances. So you can run that and make it so that Unreal is going to lean on those for your shinier objects and reflective transparent surfaces. Use CVARS for better performance overall, also in your movie RenderCube. So we go over that in our rendering classes, but these are things to keep in mind when working with ray tracing because ray tracing overall can be expensive. Let's go and take a peek a little bit in Unreal and you can kind of see what I'm talking about."},{"start":"3:06","end":"3:37","startSec":186.3,"text":"So in my scene here, this does have ray tracing on, but I'm using two different post process volumes to demonstrate some blood information from a previous class. We're going to pull in a new post process volume and we're going to contain it within the area of our metal objects here. So pull this guy in into my scene, let me go and increase his size a bit. So again, you want to handle the ray tracing for that particular region in a very dialed down and controlled set."},{"start":"3:37","end":"4:07","startSec":217.2,"text":"Now also photons bouncing around in an interior can get a bit more expensive. Ray tracing in an interior can be a bit more expensive versus outdoors. Outdoors things are a lot easier to calculate, but when you have multiple things in an enclosed area, you're getting some photons bouncing back faster back to the camera and you do need to manage things accordingly. So just be careful how many items you have in there and your material complexity if you choose to go that route."},{"start":"4:07","end":"4:43","startSec":247.2,"text":"So in here, I'm going to activate ray tracing in my post process volume in my GI settings here. Let me close a few things we don't need. So let's go to global illumination. Let's set this to ray tracing. You can see that it's active there. In my ray tracing, I'm going to set this to, you can even mix these if you want to do, that's Lumen right there for reflections. We're going to set that to ray tracing in this particular case. And I'm going to show you what I mean. So we can run this CVAR right here called ray tracing dot reflection, reflection captures."},{"start":"4:43","end":"5:13","startSec":283.2,"text":"Right now it says zero, but if you want to lean on things and do more of a hybrid set, I can put a one in here and enter. And it's going to allow me to have a bit of a fallback. You will see a bunch of noise in here. You see that. And we can actually adjust the roughness in here and it being ray tracing. We're going to probably need to. We can also set in hybrid in here in our scene. And you'll see reflection ray tracing hybrid. And we can also set that to one. I'll hit one here and hit enter."},{"start":"5:13","end":"5:46","startSec":313.7,"text":"And you're going to see an active, there you go. You see a quick changer. So that hybrid is also referencing what we put in before, which was a reflection captures. So I put my reflection capture here. We can set that to zero. What that does is sets a fallback for some of our reflectivity in our materials here. And it allows you to get a better result. Now it works a bit better when it comes to translucency. I'm really just using it in my metal aspects here. But again, I'm using it in a contained area and that hybrid is using some of those reflection"},{"start":"5:46","end":"6:18","startSec":346.6,"text":"captures as a reference, as you saw that shift as I brought it into my scene. So let's turn a few other things on to actually see some better results. So on ray tracing, I'm going to turn on my max bounces. And I'm going to set this to simple final gather. You'll see that shift there for a second here. Final gather can bring a bit of noise. So we may even want to switch this to brute force. This will give us better results and we can set these numbers a bit higher. Making this eight and if your computer supports it, samples for pixel can be 16 also."},{"start":"6:18","end":"6:49","startSec":378.1,"text":"This could also be four in our case. And then we can set this to six to eight as a starter point. Then underneath our reflectivity here, we have ray tracing. So we can actually manage our ray tracing here. Things have slowed down a little bit here because we do have a lot of reflective surfaces. I'll even notice my particles are slowing down just a bit there. I can control my max roughness if I wanted to samples for pixel shadows. We have hard shadows. I can set those to area shadows to be a bit better."},{"start":"6:49","end":"7:20","startSec":409.4,"text":"And then I can lower my roughness if I wanted to. You can see you can get rid of some of the noise that may be occurring or you can increase it back to where it was. And you will see the noise persist if you are not careful. So let's set that back to default for a second there. And again, as we move in our scene, we can see some of the results of our work. So again, using brute force is ideal in your post process volume. And you can start low and then go high if you need to."},{"start":"7:20","end":"7:52","startSec":440.2,"text":"brute force and final gather. Again, there's always going to be a bit of a noise and either one, but brute force is going to give you less. You can also use stat D3D12RAT and GPU stats to track performance for ray tracing global illumination to work with a skylight enabled. The experimental console variable ray tracing global illumination evaluate sky can be turned on. This actually works pretty well most of the time to make sure that the sky is being evaluated"},{"start":"7:52","end":"8:25","startSec":472.9,"text":"accordingly. So again, using that reflection captures hybrid CVAR and sorting materials, which can increase things performance wise. So you can use all three of these to actually help out. Now here's some ideal CVARs for final renders to be placed in the render queue. So these definitely can help out. Now, do you need all these not necessarily all at one time experiment with them first? Don't plug all these in in your movie render queue before you know whether you really do"},{"start":"8:25","end":"8:56","startSec":505.6,"text":"need them. So just be very deterministic. It's like, you know, you can say, Hey, this is my depth of field quality. Not that good. Then I'll use this ice cream percentage. I need to increase that so make things look a little better. Motion blur quality, but all that looks, it needs, it looks great the way it is. I don't need to change it. So you have to be very deterministic through here. You can also change your speaking of shadow quality on this one. You can also change your ray tracing shadow quality within the light itself. But a lot of times you don't necessarily need that or the eyes not even going to pick it"},{"start":"8:56","end":"9:27","startSec":536.3,"text":"up. It does change it ever so slightly the quality wise of your shadow. But for the most part, most of those shadows should work just fine in the default setting. They do cost GPU wise if you were to mess with those. Now just for shocking purposes, I kept in this part of the lecture, what's talks about if you wanted to use ray tracing and to turn it on and off as you're using GPU light mass. And that's fine. You just got to make sure you run that CVAR."},{"start":"9:27","end":"9:57","startSec":567.0,"text":"I gave you earlier, what turns off all ray tracing effects in your scene. Once you've, once you've rendered things in GPU light mass, now you can turn ray tracing on and off if you need to. And you'll have to dump some of your baked information back and forth. It's a little bit of a hassle. And this is why Lumen's a little bit better. But these workflows are there if for some reason you need to use them. That's it with this lecture. Here's a link here where you can dive in a bit deeper on these subjects."},{"start":"9:57","end":"10:01","startSec":597.6,"text":"Thanks again. And in the next lecture, we're going to go and take a look at optimizing fog effects."}],"09_Fog Optimization":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"In this lesson, we're going to talk about optimizing fog effects in Unreal and how that works. So let's get started. So fog effects are one of the most expensive effects that you can use in Unreal, and especially if you're using volumetric fog. Now, volumetric fog, as you turn that on in Unreal, it allows you to be able to actually isolate the fogs in such a way so it doesn't invade your interiors nor areas where they're shaped."},{"start":"0:30","end":"1:05","startSec":30.5,"text":"Now, this is very minimal shade, but if you're inside of a room or et cetera, or just even a simple overhang of trees, the fog will not invade those areas. So checking that performance and making sure the most optimal settings is what we're going to be talking about here. Number one, we can look at profile GPU to inspect what's going on with our fog. You can also, if you want to, choose to cast volumetric shadows in your scene, but keep in mind this can actually increase things almost by three times the amount of heaviness"},{"start":"1:05","end":"1:36","startSec":65.4,"text":"going on in your fog. So just keep that in mind because you're actually trying to make it so that that fog is believable, but all of that needs to be calculated in your environment. Let's go and play with a little bit of the fog, and I'll walk you through some of the tips and tricks and things you need to look out for, and we'll also go back to the slides. So here we are in Unreal, and I'm going to go ahead and make sure my exponential height fog is set correctly. So we're going to make sure our volumetrics are on, and again, you can increase this or"},{"start":"1:36","end":"2:07","startSec":96.1,"text":"decrease this, and you'll notice the scatter, and I'm talking about the scatter distribution, also affects the light and the amount of fog coming through. We can actually see it here also in our environment, how that is affecting and even making it so that the lights are glowing more with the fog, such as our sunlight, but you'll notice that or I should say this particular rec light we're looking directly at, but such things as our spotlight over here have kind of lost some of that bloom and that cone and influence"},{"start":"2:07","end":"2:37","startSec":127.1,"text":"there just by us editing the scatter distribution. So you can keep that at 0.2 for objects you need to see more in a side angle, and you'll see a little bit with the lights, but not as much as if we adjusted that number like we just did. Now the fog overall amount, we can increase, and that will also increase the effect of our lights on those fogs, particularly one that is positioned in such a way such as this spotlight. Now if we want to actually edit that on a more micro level, we can go into that particular"},{"start":"2:37","end":"3:11","startSec":157.8,"text":"spotlight in our scene and edit that in such a way to make sure that it also gives off more fog influence, and that's using our volumetric scatter intensity. That's basically the influence of the fog and the light together. So I can increase that if I need to. Now working with these properties, again, as you increase this influence, things can get a little bit more expensive. We're in a baking scenario, but some of those rules still apply when it comes to lumen. If I go in here back to my fog properties that we have, to an exponential head fog,"},{"start":"3:11","end":"3:42","startSec":191.8,"text":"then let's actually just type in it, make it easier. There we go. Get that exponential head fog in here. You'll notice we also have a secondary area of data in which we can increase fog amount overall, but also make it so that it's on a lower level. Now we don't have any lower level geometry in this particular scene. We do go over this in atmospheric lighting, but that also can be added into our environment. But keep in mind, as you bring more fog into play, things can get expensive. So make a note to itself."},{"start":"3:42","end":"4:12","startSec":222.5,"text":"Now you'll notice also in a fog environment here, we have a static underneath our volumetrics. You'll notice we have a static lighting scattering intensity. We have static lighting in here, a few things, not a lot, and it would increase a little bit here such as our ground fog overall. And you'll see that we just kind of multiplied it in that environment there. And it's actually relating to our lights, the ones that are static. Now if you're not working with static lighting, because Lumion does not support it, that's really not going to help you much."},{"start":"4:12","end":"4:43","startSec":252.9,"text":"So just keep that in mind. But that is available if you wanted to use it. Notice we have our constant frame rate here. On here is actually pretty nice overall. And even though we may increase or decrease our fog, we will gain a few frames. And as you add other elements with that fog, and especially if you add these lights that use these scattering intensity, things can get a little bit heavy, especially if your ICV affects and you're on stage. And what I mean by that is your fog, plus all these elements that you have in play,"},{"start":"4:43","end":"5:19","startSec":283.0,"text":"need to actually all be calculated. And your each of your objects and materials will be counted as draw calls, as we've talked about in other classes. So keep those things in mind because fog is just going to add another layer of complexity. When you can, you do want to try to use fog cards. They have shader complexity, but they're still a little bit less in their view and how they are seen. And I'll bring up a scene real quick here so you can kind of see what you can do to fake some of those effects. This particular scene we use and show off in our atmospheric lighting course, but I wanted"},{"start":"5:19","end":"5:50","startSec":319.6,"text":"to use it just for a brief moment so you can actually see how the fog cards and even volumetric materials on simple pieces of geometry actually really kind of sell this environment. You can see the fog cards in here slowly just moving off to the left here and using also a fog blueprint. And here's our volumetric fog, which is connected to a piece of geometry for a cheap ground fog. It's pretty great. So whenever you can, you want to try to use fog cards and maybe even use this volumetric"},{"start":"5:50","end":"6:23","startSec":350.6,"text":"material and it can be a bit cheaper. And you can even sell the idea of fog on even a lower ground playing, such as down below here where you can actually see different layers of fog floating around simply by putting some fog cards in place. So just note to yourself there just exactly how cool and how great you can actually make some really cool scenes using a little bit of your fog or a lot. But these fog cards can add that little icing on the cake."},{"start":"6:23","end":"6:55","startSec":383.4,"text":"And sometimes that's all you need is in fog cards just so that things in the background, you'll get the idea of a visual representation that you're going for and they don't necessarily have to have all the bells and whistles. So again, three of the main players that you'll be using when it comes to your fog is one is going to be the intensity in your light. So it's going to relate to it just like it would in a regular world scenario where if your light is increased in a foggy area, that light's going to bounce around on the water particles and then they will affect the scene."},{"start":"6:55","end":"7:29","startSec":415.5,"text":"It works exactly the same way. So if you choose to, like I said earlier, you can cast volumetric shadows if you want more realism, but that is very expensive. So keep that in mind. And also the volumetric scatter intensity on each light can be adjusted for that implementing the strength of that influence of the fog and the light relationship. So here is some CVARs that you can use for final pixel fog optimization. And this is the one that we use for our cinematics for Fortnite. So this allow you to have the best possible resolution for your fog as you output them"},{"start":"7:29","end":"8:00","startSec":449.8,"text":"in your render queue, in your movie render queue. And you'll see we have volumetric fog grid size 256, r.volumetric fog.gridsize2, and r.volumetric fog.temporal reprojection 1. And these actually work really well. For ICV effects, you do need to be careful of noise that may occur on your scene. So again, whenever you can, try to use them fog cards. They're simplistic in nature, and they definitely can be used to your advantage."},{"start":"8:00","end":"8:32","startSec":480.6,"text":"So some of the CVARs that you can use to maybe dumb down things so they're not too strong and yet not too poorly represented is your r.volumetric fog grid size here. It defaults at 8, but can't be lower to 6. Anything higher than 8 can increase performance, but at the cost of pixelation. So just keep that in mind, performance versus visuals, and also r.volumetric fog grid size Z. This defaults at 128, lower values increase performance, and may cause pixelation like"},{"start":"8:32","end":"9:03","startSec":512.5,"text":"we talked about before. So keep that in mind. It's a trade off visuals versus performance. And at the bottom here, you'll see you can also turn it off to see what your fog effects are doing to impact your performance overall. And again, you have a few others here here, six 96 and then zero as a reminder overall as testing points to be able to mess with things a bit. Here's a link here for if you want to dive in a bit deeper looking at exponential height fog."},{"start":"9:03","end":"9:15","startSec":543.6,"text":"That's it with this course. We hope you've enjoyed what we've talked about. In the next video, we're going to recap a bit of what we talked about. And we're going to wrap things up and we hope you've enjoyed things."}],"10_Outro":[{"start":"0:00","end":"0:37","startSec":0.0,"text":"Hi everyone, so let's go ahead and recap some of the things that we talked about in this course. We talked about lighting optimization, analyzing scenes and priority areas, baking versus dynamic overview. We also looked at Lumen overall, the equation of what to tackle and how to get things done using key workflows, limitations, quality control, optimizing and editing. We also did a review of Lightmass Baking, CPU and GPU, looking at Lightmass Baking CPU review, overall setting up pre-computed lighting scenarios review, as well as GPU"},{"start":"0:37","end":"1:09","startSec":37.3,"text":"Lightmass review. We also took a look at Screen Space Global Illumination, using Screen Space for Final Pixel, and using Screen Space Global Illumination for ICBFX. We looked at some helpful CVARS in that direction also. We also took a look at Ray Tracing Review, we looked at optimizing for Final Pixel review, and optimizing for ICBFX dual workflows. And then finally we looked at optimizing Fog Effects, what to look for, and optimizing settings to get you in the right direction. Well, I hope you've enjoyed this series of videos and lessons,"},{"start":"1:09","end":"1:14","startSec":69.4,"text":"and they will add to your project and you'll make great stuff. Thanks again and have a great day."}]},"204.07":{"01_Intro":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Hi everyone, my name is Sean Spitzer, Senior Instructor for Epic Games. Today we're going to be talking about Optimization for Linear Content, Diagram and Foliage. Some of the topics we're going to be talking about in this series is Foliage Optimization overall when it comes to analyzing your scenes and priority areas, Optimization based on shots, Lumen updates with Foliage and we're going to look at a little bit of how that relates to the world partition."},{"start":"0:31","end":"0:51","startSec":31.3,"text":"Later on we'll look at Niagara Optimization, some checklists and debugging, additional steps, FX and baking effects overall and some of the options you have there. So let's go ahead and get started. In the next video we'll talk about the outline and we'll start looking at analyzing your scenes when it comes to Foliage. Thanks again."}],"02_ClassOutline_PriorityAreas_Optimization_53.mp4":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this lesson, we're going to go and take a look at the outline for this course overall, and then we're going to go ahead and take a look at the concept of priority areas when working with foliage as well as a bit of optimization. So let's get started. So one of the first things we'll talk about is foliage optimization, and what that includes is analyzing scenes and priority areas, one of the most important things that you need to bring to light, when it comes to your shots, your scene, or interactivity. One will look at optimization based on shots, lumen updates with foliage, and foliage and"},{"start":"0:31","end":"1:03","startSec":31.4,"text":"world partition. Finally, we'll take a look at Niagara optimizations. From there, we'll look at the checklist for performance, debugging, additional steps, console commands, FX Outliner, and bacon effects via a foot book as an option. So let's go and dive right in. So one of the first things we'll talk about here is foliage optimization. Rating your scenes and priority areas, I cannot emphasize enough, is very important. But one of the first things you do need to determine is exactly what your rendering type"},{"start":"1:03","end":"1:33","startSec":63.4,"text":"is going to be, what you're going to be using for your interactivity, whether you're going to be using ICVFX or film or interactivity for a game. This is really up to you, but you need to choose between ray tracing, big lighting, or lumen. Now when it comes to ray tracing, you're going to have to handle your frames carefully because well, the higher you go, using such things as brute force, things are going to slow down a bit, which we've talked about in previous classes."},{"start":"1:33","end":"2:04","startSec":93.5,"text":"When it comes to bake lighting, you need to understand that your reflectivity will not be accurate unless you're using certain particular tools, maybe even some plugins that are not inherently on by default. But they still may not capture the realism that you need and want, and it doesn't update on the fly. Lumen allows you to have realistic reflectivity, and it allows you to have updates on the fly, but at the same time, there is a bit of noise because lumen is still evolving. So you have to decide your look based on your needs."},{"start":"2:04","end":"2:35","startSec":124.4,"text":"So overall, the games workflow is similar to the film workflow, but is a bit more determinant on whether or where you are in the world, where you're positioned. So you have to figure that out, and you have to decide where your player is going to go. In the case of ICVFX, we need to decide where a camera is going to be showing or pointing at, and how much movement is in that camera. Is this a still shot? Do we need the camera to switch to a different angle in the middle of the actors on stage?"},{"start":"2:35","end":"3:05","startSec":155.6,"text":"This is really things you need to consider. For foliage, determine how much and where the plant will go. Note, foliage has a limit as you populate a scene. So everything has a cap, believe it or not, is cool and as neat as Unreal is. You can throw the kitchen sink at it, and you can still slow it down if you're not careful. With too much foliage, you can bring your machine to a crawl, as you see here. So you can get away with even putting cards in the distance, which have those alphas on"},{"start":"3:06","end":"3:37","startSec":186.0,"text":"there, such as you can do like a large mountain, could be set on an alpha. You can actually put a series of baked assets, foliage that is moving in the wind, on an alpha in a flip book. And you just have to determine how long that's on screen and where that cutoff point where the loop is going to be. Now when it comes to foliage for ICVFX, final pixel priority areas, it's very important to consider some of these assets and how you want to handle them inside of the settings themselves. So we're going to actually take a look at that real quick."},{"start":"3:37","end":"4:08","startSec":217.3,"text":"One of the things you do want to turn on is evaluate world position offset. You also want to make sure that your foliage is movable. This prevents any super sampling that we have to cause any blurring. And in the older versions of Lumen, this was a bigger problem. If you didn't put it on movable, you would have definite blurring happening. But right now, just for a precautionary measure, I like to turn it on and I think everyone should because also you get the option if you want to eventually make it dynamic and"},{"start":"4:08","end":"4:42","startSec":248.4,"text":"even control it in such a way so that there's wind and movement. So it doesn't just look like a fake prop. So in Unreal, let's go and jump in and we're going to go back to some of these settings. We'll take a look at screen percentages as well as anti-aliasing, as well as that last screen here where I show you how to address and to tweak and control some of the movability as well as casting shadows. Let's go and jump into Unreal and take a peek. So in our scene here, let's go and switch to foliage. So I'm going to go ahead and turn on foliage for a bit."},{"start":"4:42","end":"5:12","startSec":282.6,"text":"There we go. In foliage, you'll see that we have a few settings that we can control. Now we can make it so that we can paint on landscape, static meshes, or even a BSP. If you're not familiar with BSP, it's kind of our old school low level, think of it as an object. You can actually turn a cube into a BSP if you needed, but there are also active BSPs that you can use. So you can actually paint on those too if you want. You can even paint on other foliage if you want to and anything that's translucent."},{"start":"5:12","end":"5:48","startSec":312.6,"text":"So that option is there too. So I'm going to go ahead and select this and shift select all my foliage for a moment. And I'm going to turn them on. This allows me now to paint wherever and whatever I want to based on that tick box in there. Any of the settings that you create in each one of your foliage is, foliage is, if that is such a word, you can actually go in here and save those if you change them. Now let's go and just pick on one of these for now. We'll just pick on this guy here. So in here, we can choose our density, how much density we want to have, say 300 or so."},{"start":"5:48","end":"6:21","startSec":348.9,"text":"Then it shows that we can save it. And I'll go and get rid of this guy here or put it back to default. We can choose the radius. We can choose the unit if we want it uniform or if we want to make them a little bit more free as well as be able to lock down or change those values when it comes to the scale and size. At any time you can actually hit the marquee boxes here to be able to increase this is similar to what you can do in Photoshop and ZBrush. So you can actually go in here and close those down."},{"start":"6:21","end":"6:53","startSec":381.7,"text":"So you'll go down here, you'll see an alignment angle as well as a random yaw. But this is where we want to turn on our moveable. You want to turn that on. In there we can choose casting shadows, effects dynamic. You want to actually turn that on too, indirect lighting, effects a distance field lighting. So when you turn this on, you do got to keep in mind when it comes to lighting in general, you can turn this on and that's fine."},{"start":"6:53","end":"7:24","startSec":413.0,"text":"The only thing is in your lights themselves, you need to make sure your directional light, especially if you're grabbing something from the marketplace has has your mesh distance fields on your other lights don't necessarily have to do that. If you did do that with your other lights and turn on mesh distance field, you could get some banding. So just be careful of that. So we can actually turn this off. We should still be okay. This is mainly a little bit leaning more towards our old baking method. Why this is off, but you can actually turn that on if you're seeing something's not"},{"start":"7:24","end":"7:57","startSec":444.9,"text":"quite rendering correctly. Ours is doing pretty well right now, so we're okay. So for the most part here, again, also if you're doing baking, and again, remember, I'll be putting some baking nuggets into here into this, each one of these lectures, just to remind you, so we're going to mainly focus on lumen, but we're also going to be talking a bit about some baking. So you can control your resolution for this particular resource if you wanted to, you can do that here, or you can do that within the object itself. Now you'll notice we have all these different aspects, there's even an advanced area where"},{"start":"7:57","end":"8:27","startSec":477.7,"text":"we can cast shadows on two sided, you can control all of this and actually can be pretty helpful. Does it bloat the scene? Not so much. It's mainly the asset itself. We're mainly controlling a bit of its look visually in our scene. As you can see, there's even some light map control here, if you were to do some baking, and casting shadows on two sides, that does make it a little bit more beefy when it comes to that object. But for the most part, Unreal's working pretty slim and lean and mean right now, which is actually pretty cool."},{"start":"8:27","end":"8:58","startSec":507.8,"text":"Now again, you can bring things to a crawl. I said that with a grain of salt, because if I went in here and started painting my foliage everywhere, I can make things go really, really slow. So in the case of ICVFX, what you want to do is you can actually go in here and just literally find that asset. And if you need to, let's go ahead and just find the folder for it. Grab this mesh, open this up a little bit. It's really cramped. I wouldn't grab the component class."},{"start":"8:58","end":"9:30","startSec":538.9,"text":"We want to go to the actual asset. And you can actually literally just drag it into your scene if you need to. And there's no fear in doing that. You can totally do that. So you can do a combination of painting foliage, maybe in the background. When things are up close, you can actually bring them closer to the scene and then you can adjust them accordingly, maybe even make a duplicate. So if you need to make it a little bit higher, the one thing I do want to emphasize too, you also want to make things nanite as much as possible. Let's go and minimize this for a second here. And we'll go back to that asset itself."},{"start":"9:30","end":"10:02","startSec":570.9,"text":"So you'll notice also you can control placement. Now in that placement, it really just depends how you want it to be in the world, where you want it to set. The default should work just fine. But again, we give you the option to be able to control as much as you need in your scene. You can say whether it has collision or not. You can even control heck, even the channels in here for the lighting. I like to do this in the asset itself, but you do have the option to do this here inside of our foliage as we generate and paint them in the scene. Now you'll see there's also virtual texturing."},{"start":"10:02","end":"10:34","startSec":602.1,"text":"So if you need to draw on that, you can. That is covered a bit in our other classes, but I definitely want to point that out so that you can know that you can be drunk with power and build this any way that you want. You can also remove noise if it does persist, particularly when it comes to your final pixel. So you can increase the screen percentage. There's persistent flickering. But keep in mind, this is more from Final Pixel, like I said. And if you're going to LED wall, this may cause a hit performance, make things a bit"},{"start":"10:34","end":"11:05","startSec":634.4,"text":"harder to work with. So when rendering, punch in the console variable in our movie render queue, you'll see right here. You want to punch in r.screenPercentage200 to remove noise when rendering 4K output. Now, warning, like I said earlier, it's the same thing if you're just going to wall versus Final Pixel. All of this can be VRAM intensive if you're not careful. So increasing that rendering and tweaking these out can cause things to get a little"},{"start":"11:06","end":"11:38","startSec":666.7,"text":"bit chunky if you're not careful. To also remove noise, you can override anti-aliasing and set the spatial sample to 2 and temporal sample count to 16. So that's also an option in your movie render queue. So if you're using LODs, you can also increase your frames per second. We can decrease our polys on screen if you want to when you're using your LODs. So just be careful with that. Again, test it out before you commit. So to unlock screen size, control turn off your auto compute LOD distance, which we talked"},{"start":"11:38","end":"12:08","startSec":698.4,"text":"about in the previous class set. And in the LOD settings, you can set foliage to a small prop to gain frames per second. So that's also an option if you needed to. Now remember, converting your foliage to nanite ahead of time, like I said, when using Lumen is the best workflow for optimization. Again, nanite works on a triangular basis versus your regular LODs. And LODs will actually swap out geometry more on that asset itself."},{"start":"12:08","end":"12:29","startSec":728.4,"text":"What we're going to be doing when we're using nanite, it actually uses that triangle information so we get more finite detail and it pulls up what is needed on that object in a more finite control, which is pretty great. So don't rule out nanites. That's it with this video. In the next video, we're going to talk a bit more about optimization. Thanks again."}],"03_Optimization_Materials_WorldPartition_53.mp4":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Hi everyone. In this lesson, we're going to take a look at foliage optimization when it comes to some material control, as well as foliage optimization when it comes to using world partition. So let's get started. So you can edit the material as well as looking at the end call distance in the parameter for the foliage. And you can combine these in such a way we can actually control how they show up in your scene. Now this is catering a bit more towards interactive experiences and final pixel because you're controlling"},{"start":"0:34","end":"1:07","startSec":34.4,"text":"what the material does as well as that call distance. So when you do this, this can be reduced by adding a start call distance parameter inside that material and then setting up the material appropriately for it. To be able to do this, we would actually create a per instance fade amount note. So when connecting that to an opacity or masking value, you can use it to fade instances over a distance before they reach the call distance end and"},{"start":"1:07","end":"1:42","startSec":67.1,"text":"are removed from rendering. Now again, you have to be careful with this because you may get a little bit of noise when you use it. So just use it wisely if you were to try it out. I'm going to demonstrate a little bit how it's set up in the material in just a second. But we also want to look at here that you can control this setting overall. And it is a bit more game centric. And there's a couple ways. So if we look at the previous slide, you'll see here we have a texture sample. This is in kind of its more simplest form. A per instance fade amount controlled here, a multiply and then a general constant that"},{"start":"1:42","end":"2:14","startSec":102.3,"text":"you can actually adjust the numbers. You'll see it eventually goes into another multiply, which has the information for that object. And then it goes into the opacity mask. If we go to the next slide, you'll see here that there's a there's a switch parameter in place. And in that switch parameter, you can control the inputs. And from there, you can actually have it. So every aspect of this material is being pulled through with that opacity mask to be able to pop in the material when needed. You'll see the per distance fade amount, a"},{"start":"2:14","end":"2:48","startSec":134.3,"text":"dither temporal a a and then a multiply. Let's go and take a peek at it in an unreal. So as we see in unreal, I have a material called m a read this particular material is using all of the reads in our scene. So if you do want to check and you are doing this just a quick pro tip, we can go in here and click on finding where that materials at, you can right click. And then you can go in here under asset actions, go in here and say select actor using this asset. So we can see like, all of our let's get out of foliage mode for that"},{"start":"2:48","end":"3:24","startSec":168.1,"text":"to work correctly. We can see that all of our assets are being used by it. So if I click on that magnifying glass, right click on it, and then go to asset actions, select actors using this asset, you'll see that all of them are being selected. So we know that's we're in the right spot. So in here, what I have here is the per instance fade amount. I'm using this input data to be able to actually control here our alpha threshold results here for our dither temporal AA. Now you can make it random coming from our scene here where"},{"start":"3:24","end":"3:55","startSec":204.3,"text":"we have two different material attributes. And in here we have the different types of setup. There's somewhat similar, but a little bit different in the fact that one on the top is a bit more complex. And the one on the bottom has also its own dependencies. So they are a little bit different. And this is just the way the nature of how this was made. So taking into account the normal is the roughness of specular. And you'll also see this normal rough specular opacity mask. These dependencies are in here. And what we're"},{"start":"3:55","end":"4:31","startSec":236.0,"text":"doing is we're doing a true and false here switch parameter. So if we ever wanted to turn these on or off, we can in an instance material. So what we're doing here then is we're grabbing the multiply and we're bringing it right into that opacity mask. Now you can choose to turn this on and off to see what visual results you get using an instance material. And this particular case, I'm just going to show you what we have. And I'm going to go ahead and hit apply. And I'm going to show you how you can adjust some of the properties and how the coal within the foliage tool can help and work with this particular offset."},{"start":"4:31","end":"5:06","startSec":271.4,"text":"So now let's go ahead and I'm going to move this off to the side. And we're going to go back into the foliage tool with the foliage tool active, I'm going to make sure that all the ones that are using that particular shader are all on with them all on. And I'm just going to select them all, we're going to go ahead and be able to control the coal all at one time. So we're going to scroll down to our coal volume and our coal volume in the first slot, whatever number you punch in here will go automatically to the max. But what we can do is type in like maybe 500 or 200 in the max here and then over here"},{"start":"5:06","end":"5:41","startSec":306.3,"text":"in the minimum, we can go ahead and put like 100. Now as I move around, you'll see it smoothly pop in and out in our scene specifically the outdoor indoor. And actually let's hit apply for our material to make sure it is applied. There you go. So it's good. And you'll notice if you look really good, ignore my circular, circular painting little icon here, but you'll see the foliage start to come in and out of scene. There you go. You can see it kind of go away. And it's actually not too bad. Get it kind of nicely fades in. And the shader is helping a"},{"start":"5:41","end":"6:16","startSec":341.8,"text":"little bit here. But is the shader an end all beyond? Is it actually something you initially have to use? No, but it is another option, especially for virtual production, and maybe even final pixel, but it's really geared more towards games. But this allows you to control the fade distance within this object. Depending on your dependencies that you want to punch in, you can either make it have it random like we talked about, or you can make it so that you control it yourself by pulling in a scalar parameter, if you will. We can also use a thing called a coal"},{"start":"6:16","end":"6:49","startSec":376.3,"text":"volume. Now, I don't typically use these because they are pretty old school and they work okay. There is a tendency if you're not careful with your numbers, you will get some popping going on. It might be better to use that material option that I told you about and use the coal distance based inside of the tool itself of painting foliage. But you do have the ability to actually create one and put them in place. Let me point you where they're at. But I'll let you play with it and decide if you feel this may fit your needs. Now, again, this is catering more towards"},{"start":"6:49","end":"7:23","startSec":409.6,"text":"interactivity as well as final pixel, but not so much ICV effects. I would probably stay away from it because it can turn out looking pretty fake if you're not careful, especially if your camera is aggressive or moves a little bit faster than needed. But that's mostly on a more linear direction going forward and going backward, which rarely does happen in ICV effects. A lot of times your camera is going to move mainly side to side to give the illusion and not give up the reality that you are on a volume. To simply get to it and put it in place, let's go and close"},{"start":"7:23","end":"7:58","startSec":443.8,"text":"the Foldage tool for a moment. I'm going to go in here and go to selection here for a second. In my selection mode, I'm going to go in here and simply I can just type in volume if I want to or just type in call. Or you can do the same thing here on the top down here by just clicking in the space, get content and start typing. So there's my cold distance volume. I can pull him into space and then now that he is in place, let's go and grab him because he went took off into another land. That cold distance volume, we're going to actually make it so that we can space out exactly what"},{"start":"7:58","end":"8:27","startSec":478.6,"text":"areas we want him to be in. I'm going to hit the F key to find out where he's at. There he goes, just off camera. So I'm going to pull him down a little bit, pull him into here. And again, these values are up to you. You can make them extreme. If for some reason you have a lot of stuff and you don't need to get to those areas just yet, that may be a case where you may be using it with ICB effects, or there may be a case where you're interactively, you want to be able to control how much is on your screen at one particular time. So we'll push this into the ground"},{"start":"8:28","end":"9:00","startSec":508.8,"text":"and simply control its environment here and what you want it to do. Now, again, each one of these is based on your needs. So there's never a one size fits all. And you want to make it encased as far as you want that reaction to happen. So it's basically like you wouldn't use any volume, except for post process where you can actually make an infinite extent of bound. In this particular case, you kind of want to control exactly when things come in. You'll see that we have it enabled"},{"start":"9:00","end":"9:36","startSec":540.6,"text":"right now. And you'll see there's some advanced settings, which allow you to align a brush vertices if you want to do a little bit of editing on a brush level. But up above here, we can see that we have cold distance control, we have an index, we can choose that size if we want to, and we can add different volumes if we want to, or I should say distance control. So each one's going to be a bit different. It's up to you. Now you would change that size. And then you would change the cold distance based on your needs. Now you want to do it in descending order if you can, making it so that"},{"start":"9:36","end":"10:06","startSec":576.2,"text":"it is drawn appropriately based on where your camera's at versus where you're positioning this particular call and when you want things to show up into the party. All right, cool. Let's go back into our slides. And you see some suggested numbers I give you here that you can experiment with. You'll see the size 10, 200. And again, we're increasing our distance here. And you can choose how you want things to go. We have a 50 and a 500, besides 200, we could easily set this a"},{"start":"10:06","end":"10:37","startSec":606.5,"text":"little bit higher to like 1000. And you can experiment with it by sending some of these two lower numbers to see how it changes in transitions. And you'll notice there may be a little bit of popping when working with it. You now can also control the density of the foliage being rendered during runtime with the command foliage density scale. Below you can see the density of the foliage change as a foliage density density scale setting is set to 0.1 and 1.0. So let's take a look at some"},{"start":"10:37","end":"11:11","startSec":638.0,"text":"material limitations that can occur. So distance fields for mass materials are generated for the visible part of the material. So mass materials create significant overdraw. So you got to keep that in mind, especially when we're working with lumen. So for foliage, an example, an instance painted using the foliage mode, like you're dragging it in per se, to affect lumen, it must be nanite. So go into that object. If you're going to paint it, you need to actually go into that physical"},{"start":"11:11","end":"11:42","startSec":671.5,"text":"object and make sure one that it's nanite. And we also need to make sure the distance field lights and visible ray tracing are enabled. So let's go ahead and do that. And you want to do that in that asset itself. So I just drug the asset in here so I can go in here and go distance field effects, this and field lighting bingo ray tracing. So you want to make sure it's visible and ray"},{"start":"11:42","end":"12:15","startSec":702.5,"text":"tracing. So these are really important, especially if you're grabbing stuff from the marketplace, you want to double check these. Some of these may be already on, but you do want to triple check whenever, especially if you did not originally make this asset. So also we need to make sure it's nanite. So let me click this out for a second, find where this guy is at, and then right click and double check just as easy as we talked about the other classes, turn on nanite. This is going to be your best steps to be able to make sure this is drawn efficiently and that we can paint on this"},{"start":"12:15","end":"12:50","startSec":735.9,"text":"object and bring it into our foliage tool and work with it there. So let's take a brief look at world partition. So in world partition in your map, the default grid size for foliage instances is 256, 256 meters. This is separate from the world partition grid size. So to change the default size of the instance foliage grid for the new maps, you want to go into your project settings to simply type in foliage, and then you can set the grid size, which you need, so that things are"},{"start":"12:50","end":"13:23","startSec":770.4,"text":"being filled out accordingly. Now you want to open those project settings by opening the edit menu and select project settings in the search box. Like I said, you want to do foliage, then you want to change that instance foliage grid size value to your desired value in centimeters. And this is really depends on the size of your world, and it's a bit more on the virtual production and final pixel side. But you would change that. You'll see an example, we have 25,600 centimeters is equal"},{"start":"13:23","end":"13:55","startSec":803.6,"text":"to 256 meters. So you kind of have to do the math there and be able to figure out where and how you want that foliage equally represented in your scene. Now again, the default grid size can be changed for existing maps using the world partition builder command let. Now keep in mind, in the case of ICVFX, you probably won't be using world partition, because it's a little bit more of open world, a little bit more gamey, a little bit more final pixel and virtual production. But to be able"},{"start":"13:55","end":"14:29","startSec":835.9,"text":"to actually expand on some of these, you'll see, I'm giving you some information here. So in Windows, we can open a command prompt window at the prompt begin by navigating to the location of the Unreal editor dot exe executable file. And in the above example, you'll see, or I should say off to the right, your builds home on real five engine engine binaries when 64. Next, you want to begin the command with the name of the exe file that will run the command let unreal editor dot"},{"start":"14:29","end":"15:00","startSec":869.9,"text":"exe. And you're going to add the name of the project. That's where you're going to put it and add the name of the target map where you're going to your focus area. Now finish the command with the name of the command let and the following arguments. So again, we have run world partition builder command let is the name of the command. Builder equals world partition foliage builder is the name of the builder within the command let. And then we have grid size is the new value of"},{"start":"15:00","end":"15:31","startSec":900.3,"text":"the instance foliage grid size and centimeters. An example again, the value is five, five thousand one or 51,000, I should say 200 is equal to 512 meters. This is why you do art. I don't do math. That's it with this lecture. Feel free to click on the link that I've provided to dive deeper into some of the things when it comes to foliage. In the next video, we're going to take a look at Niagara optimization as a whole. Thanks again."}],"04_PerformanceChecklist":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Hi everyone, in this lesson we're going to take a look at Niagara Optimization. We're going to first look at our performance checklist that we can hit when it comes to developing and creating our effects for our scene. So let's get started. One of the things you can use and create when it comes to Niagara is create a Niagara effect type. Now that Niagara effect type can be found under effects and then you'll find Niagara effect type. This Niagara effect type will then be loaded into our scene in Niagara underneath our system"},{"start":"0:32","end":"1:04","startSec":32.3,"text":"effect type in our overview node. So this overview node is the blue node here that has a lot of our heavy lifting settings in here that we can control and we're going to go to system and then we're going to load our Niagara effect type here. Let's go and take a look at this in Unreal and I'll show you how to set this up. So to create a Niagara effect type we're going to right click here and we're going to go to our effects and we're going to go to advanced and you'll see a Niagara effect"},{"start":"1:04","end":"1:34","startSec":64.2,"text":"type. I'm going to click on this and we'll just call this demo so Niagara effect type and then we'll do demo and I'm just going to enter double click on it and you can see that we have several properties to choose from. Some of the key properties and workflows which we'll also point out in the slides is being able to control our system scalability in which we can hit plus here, open this up and we can choose how we want to degrade or I should say dumb down the effect in our scene."},{"start":"1:34","end":"2:08","startSec":94.4,"text":"There's also visibility calling that we can control and there's also budget scaling that we can also edit. You'll see there's a emitter scalability settings also. We can hit a plus here, open this up and also choose low, medium, high for our needs. We're going to take a look at one that I've already built and exactly where to put things. You'll notice there's also validation as well as performance. This performance allows us to be able to control a thing called Niagara baseline control basic which we can load in performance and if we load this in here we can now open this up"},{"start":"2:08","end":"2:41","startSec":128.1,"text":"and we'll be able to look at a baseline control that is in here to be able to control number of instances, test duration as well as the overall system. If you were to load a system in here that we need to be able to reference. Let's go ahead and take a look at this at our effect in general in our scene. In my scene here I have an effect placed in here. I'm going to double click on this effect and we're going to go to our overall overview here of our effect here. You'll notice things slowed down just a little bit there. What do you can actually help in and I do recommend this when you are working with your"},{"start":"2:41","end":"3:14","startSec":161.5,"text":"effect is to just pause or even stop that playback. That's going to make things run a bit easier. This is our Niagara overview node and in here we're going to load it underneath our effect type and you also want to make sure you turn on your fixed bounds when you're assembling everything. This is where you're going to load it and that reference that effect type that we had created and the settings we put in there. Now our effect is going to reference that in outputting what we need."},{"start":"3:14","end":"3:47","startSec":194.1,"text":"So again this allows us to control when it spawns, its scalability and its overall performance. Again, like I said, you want to make sure you turn on fixed bounds. Most systems should use it. It's cheaper and required for GPU emitters and make sure the bounds are not bigger than they need to be. Let me tell you what I'm talking about here because when you mess with your bounds you can mess with your overall look and feel and performance of your object. We're also going to talk a little bit about resolution too."},{"start":"3:47","end":"4:21","startSec":227.1,"text":"So again fixed bounds can be found right here underneath our effect type and then you can control how that fixed bounds is played out. What I do want to mention, what you heard me just say about resolution and you'll hear me mention this several times because it's very important to consider, you need to consider the size of your overall effect versus, and we can pick on this particular one here, your overall effect versus your resolution. Now you can control the overall size of your object and how it actually relates to your"},{"start":"4:21","end":"4:55","startSec":261.2,"text":"scene. Now that size directly correlates with your resolution max axes. So notice mine is at 192. So if I increase the size of my world space size and I don't necessarily increase my resolution, I'm going to get hit with some pixels and you'll see the kind of the voxel or pixelation happening with our effect and you want to be careful with that. So you need to fine tune and balance between the size of your object and world space versus"},{"start":"4:55","end":"5:29","startSec":295.2,"text":"your resolution max axis. So it's really important to not forget that. Now because my computer is pretty strong graphically, I could probably bump this up to 200, maybe get close to 300 and be okay, but this is where we want to control it. Now you can control that resolution inside of the effect itself, but I don't recommend it. This is kind of where you want to be able to dial things down. And again, your world space, if you make it too big, you're spreading that effect a little bit too thin and you could get major pixelation if you're not careful, but it also depends"},{"start":"5:29","end":"6:02","startSec":329.6,"text":"on the effect itself. Also make sure the warmup in the system properties, warmup time, warmup tick count is set to zero. Warmup is extremely expensive and it causes hitches and only works on CPU emitters. So keep that in mind. Check each emitter scalability setting and make sure that they are on the right platform, turn off what is not needed. So if you don't need it, turn that off for sure. Again, if you're using the component renderer experimental in scalability, leave cinematic"},{"start":"6:02","end":"6:31","startSec":362.8,"text":"and epic on. Check system scalability overrides and edit them as needed, not needed in all effects, overrides used to, they are used to adjust plane and effect timing. Note more for interactive and final pixel. So in a case of ICV effects, you may not necessarily have to touch these. That's it with this video. In the next video, we're going to take a look at debugging your Niagara effect. Thanks again."}],"05_Performance_DebugTools_53":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hi everyone, in this lesson we're going to go ahead and take a look at some of the debugging tools for Niagara as well as some things to consider. So let's get started. One of the tools that we have at our disposal is you'll see at the top if you double click your effect, a button called performance. Performance will give us a readout in milliseconds on how each one of the modules that we've created is performing. This can be pretty handy to be able to track where you might have some stalls if you've"},{"start":"0:30","end":"1:01","startSec":30.1,"text":"made a lot of like really complicated things and they're all starting to pile up or several different type of effects embedded in your overall effect. Things could cost if you start to put too much at one particular effect. So this helps you track that and see how things are performing and how their playback is doing. Let's go and jump into Unreal and take a peek. So here in Unreal we'll see that we have a performance button. I'm going to go ahead and click on that."},{"start":"1:01","end":"1:33","startSec":61.2,"text":"Now this performance button and you'll see the numbers. If you can't see them a little pro tip here, I can hit control and do the wheel mouse. You can actually see these in percentage wise how much they're taking up in our scene. You'll see an average millisecond calculation on the top there and you'll be able to actually see what they're doing. And again, you'll see it here. It says this shows the module runtime cost in percent. So your overall percentages in here you can track and you can see, well, man, this effect is really heavy in this area."},{"start":"1:33","end":"2:03","startSec":93.1,"text":"This effect is overall I could probably do to the milliseconds that we have going on. Maybe slow some things down. Maybe have too much in here. Have a fluid within a fluid. One thing I do want to point out though, when you are using fluids, they are pretty heavy because they are in a GPU effect and you'll see GPU is on here and I'll be referencing GPU back and forth. Now we do have Niagara classes. This isn't a Niagara class, but this talks about how to control your environment and"},{"start":"2:03","end":"2:34","startSec":123.7,"text":"optimize things accordingly. So if you want to dive more into Niagara, feel free to do so. But keep in mind, fluids are expensive by nature and sometimes they may not refresh like you want. You can simply just hit pause in the playback and run it again or you could select it and sometimes it pops back into view. Certain gas fluids may have a little bit of a refresh issue, but overall, especially if you're pairing them with other effects like maybe there's a gas nested within another effect."},{"start":"2:34","end":"3:06","startSec":154.2,"text":"So these are just things to consider when working with your effects overall. You'll see the three dot button here right next to the performance button. You'll be able to pull down and see the GPU profiling, display average, display maximum if we turn that on, and you'll also see display relative values as well as display absolute values. So you have a bit of options here. Another tool we have for debugging is the literal debug tool. Now we'll break down a few other aspects of it too."},{"start":"3:06","end":"3:38","startSec":186.0,"text":"It is evolving, getting better, stronger, faster, but we're going to be looking at some of the primary tools that we can use for optimization. To be able to activate it, you can go to three different areas. One, you can go into the details of that effect if you're selecting that in your editor. Two, you can go to the tools pull down menu and go to debug and go to Niagara debugger. And three, if you go into your effect itself and double click it, you'll be able to see debug right next to that performance button nearby."},{"start":"3:38","end":"4:10","startSec":218.9,"text":"Let's go ahead and jump into Unreal and take a look at a few things. So if I want to, I can run the performance in here showing my overall what's going on with our effect and those percentages. And I can also run the debug at the same time if I wish. But I'm going to save a little bit of overhead and I'm going to turn that performance off. Now that performance is not dependent upon whether we're playing in the viewer here. We can actually hit pause and you'll see your percentages still running. So I'm going to go and click on performance and turn that off."},{"start":"4:10","end":"4:42","startSec":250.8,"text":"I'm going to go and click on that debug here and you'll see it says debug hut. You also have the option to look at the FX outliner, which we'll look at later. And there's also an attribute spreadsheet. Let's go ahead and take a look at the debug hut. Now when we open up this debug hug, like I said before, you can get to it two different ways, three different ways. So we have tools, debug, now agro debugger, or selecting the effect in your environment. You can simply just click on debug."},{"start":"4:42","end":"5:13","startSec":283.0,"text":"You can also capture some data, which is kind of connected, which you can also do with the FX outliner. Let's go and take a look at this debugger. Now in the debugger, we want to be able to turn on our debug, HUD enabled. There should be on by default. You also want to turn on your debug, HUD rendering enabled. This will give you some text, but also it will show you your overall little outline here that we have for a scene. We want to be able to actually see our little bounce."},{"start":"5:13","end":"5:46","startSec":313.1,"text":"This is important and isn't always on by default, but you can actually help that by clicking this on. You'll see it'll actually turn on for us. So we also want to have a validate system simulation data buffers. You can turn that on. But these are optional. You don't necessarily have to have all these on, such as validate particle data buffers, validate particle system simulation data buffers, as well as validate log errors. This is just a little secondary checkbox that allows you to double check your work and see"},{"start":"5:46","end":"6:17","startSec":346.9,"text":"if things are doing what their intentions are. So I'm going to go and turn these off for now. We should be okay without them, but the options are there. At any time you're unsure what something does, simply float over that effect and Unreal will give you some pro tips. These are very helpful. These do have impact on performance. I do want to mention that. So note to self. We have a debug overview enabled. Turn that on. And this will give us an overlay of what's going on in milliseconds for that particular effect."},{"start":"6:17","end":"6:49","startSec":377.9,"text":"You'll also see include cascade. So if you're grabbing something from the marketplace, that's a bit older and includes cascade. You can do so. But there's a Python script you can use to be able to convert those cascades into Niagara. You have to just turn it on into your plugins. But keep in mind when you do that, there's some editing that may be involved. So let's go ahead and take a look at the debug overview mode. You'll see we have GPU compute performance in here. But by default, we can have the overview here."},{"start":"6:49","end":"7:26","startSec":409.1,"text":"And it shows us our total particles that were pushing. Now it also shows us our memory. And it also shows us our total emitters here. I'll pulse my cursor so you can actually see where I'm at. We can go over here too and choose scalability. This will give us another overview, looking at all the content that we have going on. Next we can do performance. And again, this will show us the data that we need. It'll show us what's going on on an average RT and also our general playback here in milliseconds"},{"start":"7:26","end":"7:59","startSec":446.4,"text":"and also what we're pushing. Again, you'll see the game thread, max on this particular one, and game thread average here. And we've talked about game thread in previous classes. Next we can go in here and choose performance graph. Now this performance graph is going to give us a readout and show us where things are spiking in here. And these tools are really helpful, especially if you have a lot of effects in the scene. So you've got to keep that in mind. Also note to self, if you have fluids, fluids are a bit more expensive."},{"start":"7:59","end":"8:30","startSec":479.5,"text":"For again, they are GPU, they're running some GPU processes here. And the higher or the more advanced they are and lots of different effects nested inside of them, you've got to keep in mind that what they're going to cost, especially with several. We can then choose also GPU compute performance again. Go back to where we were. And it gives us a big overlay. Let me move this down so you can see it here and shows our average instances, average use"},{"start":"8:30","end":"9:03","startSec":510.3,"text":"here or US, I should say, and max US. Now you'll look at this in context. You can see them all categorized here. So we have compute curl, scattered particles, pre-sim velocity, sourcing. So it's kind of peeling back the onion of all the effects that were working and some of the modules that we have active within our effect. As you look in the menu, as we scroll down, you have several options for viewing as well as you'll be able to change some of the positioning and the font."},{"start":"9:03","end":"9:34","startSec":543.3,"text":"You'll see there's a font control here. And if we scroll down even more, we can actually see there's a debug filter. You can actually choose what system you're looking at. Simply what I like to do is just deselect it, select it and then run the debug again. Otherwise, if you load that filter, make sure you're not confused on what you have in place. And that can happen, especially if you're working late at night. But I like to simply just click and re-click again. And it's pretty easy to do so. You'll see there's a debug system here where you actually can look at verbose and just"},{"start":"9:34","end":"10:08","startSec":574.6,"text":"gives you a little bit more information. You'll see I got verbose here on. We'll just do basic on this one if you want to basic. And it's just looking at the system overall. So you have a little bit of quality control in here too. So if I went in here, you'll see there's system attributes. If I hit a plus here, I'll be able to select what I want here. Do I want to, let's go and open this up here, go and add an array for this system attribute. And let me show you what I mean. If I typed in system, it's basically like a tag area."},{"start":"10:08","end":"10:41","startSec":608.6,"text":"This would actually match all system processes to that particular region. So it's almost like adding another slot in here and you'll see it real give you a quick rundown for that. So there's some advanced stuff and stuff you may not even touch. I rarely will touch this one because I know that I don't really need it. Everything that I try to build, I try to build clean in the system itself. You'll also see that you have a font control, like we said before, but even here you can move it and shift it if you needed to. You'll notice there's debug particles here where actually we have a few more things we"},{"start":"10:41","end":"11:12","startSec":641.3,"text":"can do such as there's tech more text options. You can actually show your particle index if you need to. There's quite a bit that we can play with. It's really up to you. And again, it's like a case by case. I don't want to get too much into buttonology, but I want to talk mainly on the stuff that I would be playing with and working with. You'll see there's a perf overview here. We can actually can control our preferences here for reporting your frames and you're also samples mode, your frame total if you want to take a look at that."},{"start":"11:12","end":"11:44","startSec":672.3,"text":"And we also, if we scroll down just a little bit more, you can control the color of the overall kind of testing of your look and feel for your object here. And also, let me see here. You'll also see there's a show global budget info right here. And you'll see that pop up towards the bottom. And let's go and turn this off for now. So if we scroll up a little bit, you'll notice we also have an area called particle attributes. This is under the debug particles."},{"start":"11:44","end":"12:19","startSec":704.2,"text":"Now I can add systems in here if I wanted to, but this is not typical for me personally. I like to do it where I can track it a little bit better within the effect itself. Again, let's go ahead and look at a quick review here at the interface. We have Niagara debugger panel. We have the playback options. And we have the debugger tabs. Each one of these are set up so that you can control the speed if you wanted to. And take a look what you need to. Now, when I say take a look, we want to focus mainly on the debug HUD and the FX Outliner."},{"start":"12:19","end":"12:52","startSec":739.2,"text":"Performance session browser and debug spawn are all experimental and they may not perform exactly like you want. So the main ones you want to focus on are these two, the debug HUD and the FX Outliner. They're a bit more stable right now in their current version. So just keep that in mind. Again, key points I want to iterate here is again, we have the debug HUD enabled and also the debug overview enabled. This will give us what we need to be able to bring things onto the screen."},{"start":"12:52","end":"13:24","startSec":772.4,"text":"And again, under debug overview, you can analyze visually the output such as the GPU compute performance and the overall performance. Let's go and take a look at some things we can do on screen, such as look at our particle perf. This is basically looking at what's going on under the hood and how the frames per second and the averages are working in our scene. So what we'll do here is close the debugger. With that on or with that off, I should say, you'll see that stuff that we had on screen"},{"start":"13:24","end":"13:56","startSec":804.3,"text":"go away. Let's go to our stats and in our stats, we'll look at engine and we'll look at the particle preferences here. Again, this is going to give us an overlay on our screen. Now for running some problems, you can squeeze in your menus a bit. You can actually see those full run of those numbers and see how things are performing with our frames in our scene. Another one we can run under stat Niagara, we can turn on Niagara baselines."},{"start":"13:56","end":"14:27","startSec":836.1,"text":"Let's do that. So let's do that same thing. We'll go under stat Niagara and Niagara baselines. Now if it doesn't turn on automatically, just move your camera a little bit and it should show up. It sometimes is a little bit refreshed. There it goes. It's popped in and it's now decided to give us our information. Now that particular system is used if you're going in here and it's a class for baseline controllers and these can be or are responsible for spawning and manipulating the effect needed"},{"start":"14:27","end":"14:58","startSec":867.9,"text":"for the baseline perf tests. Now if you're a little bit more into programming to effects, you would understand where that might be needed. Now we're not going to jump into that. I'm not going to run you through Python, Gambit here or a bit of C++ but overall you can use these as a comparable if you turn them on on your screen. And you'll notice we don't have anything right now to compare things to. Another way to optimize your scene is to go in here and if your effect doesn't need to"},{"start":"14:58","end":"15:31","startSec":898.3,"text":"move around, you can turn off require current frame data. So this can save a little bit of overhead. But again, if your effect doesn't need to move, you can turn this off. This can help a little bit of the overall, especially if you have several that are kind of complicated, but they're not really going to move. There's no that extra calculation isn't really needed. Now Unreal in aggregate slimmer, faster, stronger. So and your machines may be really spot on. You may not need to do this, but in other cases, it might help a little bit."},{"start":"15:31","end":"16:02","startSec":931.6,"text":"All of the stuff that we talked about so far in looking at the debug hub or HUD, I should say, heads up display, you can actually run them via a console command. And here are all the console commands that have listed in the lecture if you want to reference them. Obviously, you don't want to load them all. You actually can do all of these through the menu, but these are options in here. Here's a few more that can help you with playback if you wanted to control some of that. So the first one here will play all simulations."},{"start":"16:02","end":"16:32","startSec":962.5,"text":"You'll see FX Niagara dot debug playback mode one will pause the simulation and FX Niagara dot debug dot playback mode two will step single frames and then pause all simulations. Now you can also do that within the Delta tick inside of the effect itself, but you can also do it here through their playback mode. FX dot Niagara dot debug playback rate. You can also control that as well as FX dot Niagara debug playback rate 0.1. If you want to run all simulations at half the speed."},{"start":"16:33","end":"16:52","startSec":993.5,"text":"So I'm not going to go through all of these, but these are all available to be able to see and be able to tweak and edit things if you needed to. If you wanted to check your speed, check your thread count and et cetera, as well as your budget. That's it with this lecture. In the next lecture, we're going to take a look at FX Outliner breakdown."}],"06_FX_Outliner":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hi everyone, in this lesson we're going to go and take a look at the FX Outliner in regards to Niagara optimization. So let's get started. Now the FX Outliner is in that debug tool section and is one of the tools that we can use to maybe take a look at our scene and kind of see how performance is going. Now do you have to use it? No, you can probably get away with not necessarily using it in your scene. There are some refresh issues that may occur, especially if you want to catch information"},{"start":"0:30","end":"1:06","startSec":30.6,"text":"and look at the simulation and see how it's going. You also will see there's a capture button, but you can also hit that capture button in the details of the effect itself to instantly capture some of that data. Now it just does a snippet and kind of gives you an overall estimate of what's going on. You will see that you can also control the lane of the view, of the playback if you wanted to. You can see the light of it in your view mode. You can have it descending and us sending order if you need to as well as look at your units in milliseconds and seconds if you wanted to or seconds."},{"start":"1:06","end":"1:38","startSec":66.5,"text":"It's up to you. And then from there you can go into each one of your effects and it grabs all of them all at one time and you can kind of analyze and see what's going on under the hood. Let's go ahead and jump into Unreal and we'll take a peek at this. Let's go ahead and click on capture. That's the tool you will use to capture that session and what's going on. You see it kind of cleared out what we had before. And if you do run into any refresh issues, feel free to close the debugger, reopen it and then run that catch information again or capture, I should say, and then you'll get"},{"start":"1:38","end":"2:10","startSec":98.8,"text":"the information you need. Again we can control delay. You'll see here we have a view mode where we want to see the state performance or debug overall. And again we also have filters where we can go in here and look at our system execution state and our emitter execution state. So if you needed to deactivate these if you wanted to or see what's inactive you can and compute them. Now again, this is just a quick analyzing tool. It isn't necessarily perfect. You'll see there's a playback, a pause, a loop and a step back and speed and refresh."},{"start":"2:10","end":"2:41","startSec":130.9,"text":"So if we open this up, we'll actually see our effect in here and we'll show our different effects for this class. You'll see that there's a capture as well as an opening of what is active and what isn't active. Now we have this here in our scene and we can choose, you know what, I'm going to go ahead and take a look at my scene overall. I can run a capture here. Now I may pause the video here because this does a little bit of a hog when it comes to your simulation."},{"start":"2:41","end":"3:13","startSec":161.1,"text":"And just keep that in mind if you are going to capture this information. It may be a little bit slow and it may need a little bit of a refresh. So I made sure all my arrows are open here so you can see what's going on. So let's go ahead and run a capture and we'll run a sim. There we go. Now it may take a while for the interface to pop up, but the interface is going to bring in another layer of information. Basically going to break things down for us. We'll run a capture again. We'll do the sim here."},{"start":"3:13","end":"3:49","startSec":193.8,"text":"And let's see what we get. Now if it doesn't come up the first time, just hit that sim button one more time and you should get this here, a pop up, which allows us to be able to actually look at another win menu, be able to look at all the information for the effect and all the different aspects of that effect that we have in here. And we'll let me know what's going on. So it just gives you kind of a detailed list of where our effect is, where it's landing, where you can scroll down and find different modules in here like, oh, hey, we got a control"},{"start":"3:49","end":"4:24","startSec":229.3,"text":"here for a red, green, and blue. Do we do anything with this? This effect, the milliseconds, how much particles are being pushed through this? Is there any extra erroneous stuff I don't need? So it really just gives you an overall analyzing of your effect and your scene and those sim and the catch just gets that information and kind of breaks it down for you. If for some reason you need to look at that a bit deeper and you can see here all the information that we have in here, letting us know what's going on. Again, these tick boxes are going to give you those categories for each thing that you"},{"start":"4:24","end":"4:56","startSec":264.1,"text":"want to analyze. And Unreal is pretty great at being able to categorize things for you. And again, it'll tell you if you just float over, if you got what tick box you turned on, it'll tell you what in context, what this is on the part of that particle. That is being looked at. But be aware, when you hit that capture button, things will come to kind of a crawl. So be careful. Just be patient. And then again, just give you a snapshot of what's going on in your scene."},{"start":"4:56","end":"5:30","startSec":296.2,"text":"And when you run these captures and the Sims, they're really just giving you a spreadsheet. So again, nothing necessarily to write home about, but can give you the information you need. And then notice as I click on each one of these effects, I can actually see what's going on and what I have in place for my settings, what I have active and also what category is this particular effect. You can also see is it GPU or is it CPU will also show up. And then you also like I pointed out before can choose milliseconds, seconds in here if"},{"start":"5:30","end":"6:03","startSec":330.3,"text":"you need to. Now, again, the other ones, which I mentioned earlier also performance, session, browser, and debug are all kind of in development still. So they may not give you exactly what you're looking for. Those are evolving, getting faster, stronger. The most the time when I'm working with this, I'm going to be working with the FX Outliner. If that, I will definitely be working with the debug hut. Now, the debug mode can easily be switched if I need to. And I can go from debug mode to state mode."},{"start":"6:03","end":"6:33","startSec":363.2,"text":"If I want to, as well as I can go to performance mode and performance gives me a bit of a breakdown here. Let's go and look at the slides at exactly what we're looking at information wise and how this can possibly help us. So you can see here we have number one, which is the average total frame time for all effects. We have number two here, it shows the maximum total frame time for all effects. We can also go down or I should say off to the left, go to number three and we'll see"},{"start":"6:33","end":"7:04","startSec":393.7,"text":"the average per instant cost for this system. We go to four, you'll see the maximum per instance cost for the system. We'll see five here, which is the average total cost for all instances of the system. And we go to six where it says maximum total cost of all instances for the system. We'll go to seven here and you'll see the average cost for this instance. And then again, we'll see here at eight. Finally, that is the maximum cost for this instance."},{"start":"7:04","end":"7:37","startSec":424.4,"text":"Now I know that's a lot. This is why I put it in the slide for you because even I can forget this. There's a lot of numbers here, but you can now see and see the breakdown of how this is read and how this can benefit you. You can kind of see how this is overall going to affect your performance. You can adjust things, look at things in milliseconds. I need to tone this down. This is too much. So this mainly has to do with a lot of effects. A lot of times the case in point when to use this is if you have a lot of effects in your"},{"start":"7:37","end":"8:11","startSec":457.8,"text":"scene and you really need to micromanage them and you really need to somehow get them to play a lot better with each other in the scene with all the other assets you have in play. Now remember, there are ways around this and we'll talk about this in the next lecture. You can also bake things to, we have a baking method where you can bake it like to a simple piece of geometry. The only problem you can run into there is the quality can degrade. So VDBs are also an option, which I do have a class coming up on that which shows you"},{"start":"8:11","end":"8:44","startSec":491.6,"text":"how to use VDBs and also get them in sequencer. Those are effects, if you're unfamiliar with that, those are effects coming from Houdini or Maya or Embergen. You can bring them into Unreal and use them also. And they are a bit lighter. It just kind of depends how many you have in your scene, everything within context. You can break anything if you put too much on it. But for the most part, they can actually help out if you needed the effect to look pretty realistic, but not necessarily have a high playback cost."},{"start":"8:44","end":"9:18","startSec":524.6,"text":"But again, anything you can put too much on anything and you can bring things to a crawl. So everything has to be optimized in such a way where your hero objects and effects are up front and the things that are not that important can be put in the background. Now, we also have the option where if you baked things out into, say, you had Houdini and you baked it out into an EXR, you can actually import those in. And I give you a link at the end of this class. You can put those on a car geometry and you determine whether or how that alpha is going"},{"start":"9:18","end":"9:37","startSec":558.2,"text":"to be read, but you can actually put that in the background if you need to. And that actually is another option to keep things down. And those can be options definitely explored when it comes to ICV effects or virtual production. That's it with this video. In the next video, we'll talk about that very same thing about baking your effects and using the tool in Unreal. Thanks again."}],"07_BakingInterface":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Hi everyone. In this lesson, we're going to go and take a look at the baking tool inside of Niagara. So let's get started. In Unreal, we have the ability to use tools to bake our effects. So they're great, especially for items from a distance. So keep that in mind because it does keep things lighter, but there is a breakdown resolution-wise. So you kind of want to keep these in the distance, so they can't be helpful. The only thing you can really run into here that you also have to be careful with is how your loop is run."},{"start":"0:31","end":"1:04","startSec":31.8,"text":"Now for obvious reasons, a liquid effect, a fog effect, a particle effect is not going to loop exactly. So you want to make sure when you set it, how long your duration speed, or I should say duration seconds, are going to be. Now this baker, let's go and look at it in Unreal, is again, it's pretty new and it can be kind of experimental, but you can also run the option of exporting your images, which I mentioned from the last lecture, high resolution EXR and put them on a plate"},{"start":"1:04","end":"1:35","startSec":64.8,"text":"and make it so that there's an alpha involved. But you can also use this one, which again, can be used, but for things in the distance, and you want to make sure you know exactly how long that shot's going to be. If you're using ICB effects, in case and point, if you know how long that shot's going to be, you can match up your effect to know when it's actually going to come to an end. Otherwise, a loop is going to run into some trouble. So let's go ahead and jump into Unreal and take a look at that. So here in Unreal, I have the effect up front."},{"start":"1:35","end":"2:07","startSec":95.3,"text":"This is grabbing, and I just positioned my camera a certain way in the baker, which I'll show you. But you can see this is actually a pretty decent effect, but it is very short, and it being very short, you have to determine what you want from this effect and how long your seconds are going to be. You also need to keep in mind how things are getting cut off. How big in your original effect is your bounding box, your scale. And you'll notice here on this fire effect kind of comes to a ceiling."},{"start":"2:07","end":"2:37","startSec":127.3,"text":"So if I wanted to, I could open this up a little bit. But again, like I mentioned before, you need to consider your resolution because as you make the scale bigger for that effect, your resolution could take a hit and you could get some pixelation. But in the case of baking and it's in the distance, you may not have to worry about that as much because you really are just trying to give the illusion of something. And this actually, this one came out pretty good. But again, it is very short. So let's go ahead and take a look at this effect up close."},{"start":"2:38","end":"3:08","startSec":158.1,"text":"What we can do is do the same effect when it comes to the fire. So let's go and double click on this guy. And we'll go to the baker here. So let's open up the baker. So the baker is going to show me kind of a low level version of what I have. And it's actually not too bad in this particular case. But you will see in here that you do need to make sure you take an account how you position your camera. That's very important."},{"start":"3:09","end":"3:40","startSec":189.4,"text":"So you want to make sure that it's centered. If it isn't centered, you could run into the problem of things not being able to be looking like you want. You'll get some bad clipping. So what I mean by that, if we left click, we can move our camera around this 3D space. And this will drag left click and drag allow us to be able to position things like we want. Another one you can do is middle click and drag to pan. So if I middle mouse click, I can pan back and forth to get the right positioning."},{"start":"3:40","end":"4:15","startSec":220.5,"text":"And then we also can right click and drag to zoom. So if I right click, I can zoom in and out on this effect. And may get a pretty decent look visually for my output. Now, again, you also need to keep in mind the size that you're outputting when you decide to use this baker. Also click F to center the frame. So if I click in here and keep my finger on the F key, I can center on the effect. Now we're a little bit too close. So we're going to have to move back a little bit there. So let's go in wheel mouse there and a little back and try actually right mouse there."},{"start":"4:16","end":"4:49","startSec":256.7,"text":"And middle mouse to get that positioning. So you have to keep those things in mind when you're actually baking these that things are not getting cut off because they will easily get cut off if you're not careful. And again, you can see the top of my bounding box being hit by the smoke. So you also need to take an account your size, which I mentioned or scale, which I mentioned earlier. So in the settings, which we'll talk about in Unreal and go back and forth with the slides, we have to make sure we take an account our perspective or"},{"start":"4:49","end":"5:24","startSec":289.8,"text":"or throw front positioning or throw back. So you can literally punch these numbers in, but you can also control your texture size too. You do need to take an account what this spreadsheet is going to be. Because in this case, you want to make sure that your dimensions are of the equal size to what you want this to be. Because honestly, it's going to make a little spreadsheet for you and you have to do that math. So for ideal behavior, you want to set your textures size to a power of two and the frames per dimension to be a number that divides evenly into that texture"},{"start":"5:24","end":"5:57","startSec":324.5,"text":"size. Let me show you what I mean. In this one that I've already created, you can actually see a just a quick glimpse of this particular effect. I did it from a side view, which I thought worked pretty nice. But you want to make sure that in your Atlas texture size, and again, here we have the, the live sim and the big sim. You can do a comparable. We want to make sure that we increase the resolution to our needs. Now, if it's way in the distance, you could probably get away with doing 128."},{"start":"5:57","end":"6:29","startSec":357.6,"text":"But in our case, we might want it a little bit higher so we could do a 512. Now the problem with the 512 is you're going to bump up your resolution dramatically. Notice we went to 496. We also can turn off our playback here in the regular mode and just make it so that's just running through our Baker sim. And you can see it playback here down below compared to over here, which is going to eat up a bit of memory. Now that's pretty high. We probably don't need 4096."},{"start":"6:29","end":"7:02","startSec":389.2,"text":"So we could probably do 256. Nicely, it does a bit of the math for us, but you want to keep this again in a power of two, like mentioned before. Let's switch back to our gas fire here and let's actually make a bake for this particular asset. Now, again, we're going to follow the same rules here and we're going to change your resolution to 256. Now, when I set this to 256 by 256, again, the resolution increases, but you also want to make sure that the, there is a wrap in here. This is what I find to be the best options to choose from."},{"start":"7:03","end":"7:34","startSec":423.2,"text":"You can go in here and change these to clamp or mirror the effect if you want to, but we're going to keep that as a wrap. So you'll see there's also the out, the Atlas asset path format. Let's actually pause this playback here for a second. The Atlas asset path format here. So we've chosen this particular area where it's going to output. Now you'll notice if you scroll down just a little bit, there's a frame asset path format we could use too, as well as a frame export path format."},{"start":"7:34","end":"8:05","startSec":454.6,"text":"So these also can be assets that you want to send out the door and reference them as you need them. And you'll be able to have those assets for you as a backup. One thing I do want to point out too is your frames per dimension. If you don't have these high enough, things can get choppy and won't look as smooth, but if you have them too high based on your resolution, things also can get pixelated. So there's kind of a give and take with that. So let's go and run this bake simulation."},{"start":"8:05","end":"8:36","startSec":485.1,"text":"Now it's going to make a baker folder for you when you do it. You'll notice there's warnings here. It says a midder gas control is not set to deterministic results. We'll vary each bake. So what this means when you're working with your asset is that we need to go into the emitter itself and go to determinism here. And this is going to make sure we get the same results with the same effect here. And that should get rid of that issue. Now you may run into some with new versions of the effect."},{"start":"8:36","end":"9:10","startSec":516.9,"text":"If you import it, if you've got new version of Unreal and you get bringing it to your scene, you may run into some of these issues where you'll get like, hey, this is different now. This may give you weird results to keep that in mind. So I turned on the determinism. It should actually make that error go away. So let me go ahead and fix this particular issue where it says GPU is incorrectly running particle update script on the particle spawn. Now we had a couple of these. This is the first one that I fixed. I'm going to the second one. And this is due to the previous GPU code gen."},{"start":"9:10","end":"9:37","startSec":550.2,"text":"So be careful though. When you turn these on, you could actually make your effect not work anymore. And that just means something has been disconnected. This doesn't mean it's completely a wash that you can't use it. It just means you may have to go in there and fix a couple of these issues that may be persisting because of it. But again, I turned on the determinism here and that should fix some of the issues. And I simply looked it up into my effect. And we go ahead and fix this issue here."},{"start":"9:40","end":"10:09","startSec":580.6,"text":"There we go. Fire is coming back. Now, for some reason, you do fix an issue and it's still giving you issue, still giving you a problem. You can hit control Z and try to live with it and see if you can manage it. Just be careful with that because if you have a lot of dependencies, that could become an issue. Now, you'll notice that error has gone away, which is fantastic. Let's actually check the other one too, because he was kind of the problem in the baker. Let's go to his baker. I may have closed it."},{"start":"10:11","end":"10:43","startSec":611.2,"text":"Let me see here. Go to the baker tab. There it is. Yep. It went away. Fantastic. It's gone. So you can see that can actually clear that up pretty easily. So we have this here. Let's go and run this bake at 256. Now, again, you can go higher like you saw me do. We can go to 4k even. Let's turn off that playback again, because that is eating a bit of memory. And let's go ahead and make this up. You have to give it a little bit of time. It'll pixelate it first and then it will kick in."},{"start":"10:43","end":"11:15","startSec":643.1,"text":"I paused it just in case things I had too many processes going in the background. But it's actually not too bad. That's pretty good. Let's go and take a look at this material and how this works on the other side of things. So I went to my content folder here and just typed in baker. Probably should have been a little more specific where to put it, but you can actually see that it's made individual files too. If I needed it. So that's actually pretty handy. So that's secondary control. If we go to it really quick in Unreal, looking at our window, you'll actually"},{"start":"11:15","end":"11:46","startSec":675.5,"text":"see here again, you can do individual assets if you need to. Plus you can also do it for the Atlas if you need to. So that's pretty handy if you wanted to edit them and tweak them after the fact. You have that option. You can add more to it if you needed to, or take it into an editing software like Photoshop. You can actually do a little bit of adjusting. So back in my content folder here. We'll take a look here. Again, you can see the individual assets, but let's look at the Atlas here. And this actually came out pretty nice."},{"start":"11:46","end":"12:20","startSec":706.6,"text":"Pretty decent resolution. Again, you do see the top where it hits. So you've got to be aware of that when you're building these effects. Again, where your box begins and ends on your object. Now connecting this to the materials, what we need to do next and to be able to place it where we need to place it. Before we fully jump into that, I want to make sure I point out a few things. You'll notice that there was a source binding at the top. Make sure that's set to none. And again, you can choose your scene color HDR values if you want to when generating your texture, and you can determine where that texture is going to"},{"start":"12:21","end":"12:54","startSec":741.2,"text":"be plus the size, which we talked about the size control. You can also show where that's going to end up. It will see a texture graphic in our slides, but in this case, you can actually just simply click on the magnifying glass and you'll see where Atlas is loaded. Pretty nice and pretty convenient. And again, the frames paths can also be adjusted and where you want those to lie. Now, just remember, if you generate a new one, it's going to be replaced unless you designate where that new one is going to be at. If you don't, it will simply just right right over it."},{"start":"12:54","end":"13:03","startSec":774.6,"text":"That's it with this one. In the next video, we're going to go ahead and set up the material and the particle and connect those all together to get the flipbook to work. Thanks again."}],"08_BakingSpriteSheetNiagara":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hi everyone, in this lesson we're going to go ahead and grab that sprite sheet, create a material for it, and then create a Niagara system and load that material in that system. So let's get started. So in here we're going to go ahead and bring in our texture sprite sheet. Now you can simply just hit the T key and if it's selected you'll notice it will automatically populate. But for some reason you don't have it in place, you can simply go in here in our content"},{"start":"0:30","end":"1:03","startSec":30.1,"text":"drawer, have the sprite sheet selected, grab it, and you should be familiar with this, but if you're not simply click on the arrow and load it this way. So what we want to do now is build out this material. So to build out this material we're going to hit the D key and left click to create the divide node. I'm going to pull that RGB string and pull it into the A slot here, and I'm going to grab the A for the alpha here and pull it into the B slot here. And then what I can do from here is pull that right into the base color. Now you'll notice we're actually not quite doing exactly what we want, right?"},{"start":"1:03","end":"1:36","startSec":63.6,"text":"So to help things out, and there's no alpha information being read, we can simply click on our original node that we have here, the home base where everything gets plugged in, and we can go in here underneath our blend mode and set that to translucent. Now we're not done yet because we now need to grab that alpha and pull it into the opacity. And you'll see we're going to kind of get a one to one to our original effect. That's actually pretty cool. But say you want to have a little bit of glow. You'll notice in my original sample it has connected right from our divide into the emissive"},{"start":"1:36","end":"2:16","startSec":96.8,"text":"for a little bit of glow, but it does make things a bit lighter. So if we look into our scene itself, you'll actually see the effect here brighter than the one in the distance. So to be able to control some of that, what you can simply do is go in here and I can hit the M key and the M key will give us our multiplying. And then if I want to hit my finger on the S key left click, and we'll have our scalar and we'll call this emiss one M emissive amounts and plug that into the B channel."},{"start":"2:16","end":"2:47","startSec":136.6,"text":"Plug this guy, the divide into the A channel and then grab that and put it into the emissive. So now if I wanted to increase this, I can create an instance of this material and have this exposed so that I can control it. Pretty awesome. But remember, you have to keep in mind what your sprite sheets number of rows are. And you'll see we have one, two, three, four, five, six, seven, eight. And we have an eight by eight square. That's going to be 64."},{"start":"2:47","end":"3:20","startSec":167.4,"text":"And that number is going to be key as we build out our emitter. Let's go ahead and do that real quick here. So again, we want to make sure when we build our emitter initially, let's go back to the FX folder, a little bit less busy. You can see in the in class effects one, because I didn't change the folder, I kept it here, all of the individual sprites are rendered out as well as a sprite sheet. So that can be convenient if you need to take these into Photoshop and edit them later for whatever reason or make a brand new sprite sheet using a software to be able to do so."},{"start":"3:20","end":"3:50","startSec":200.4,"text":"But we have an already made, so we're okay there. So I want to go ahead and right click in here and I go to effects. And again, I go to Niagara system in this Niagara system, I can hit next, and I can simply go to an empty slot. So you can do emitter or system, but just whatever you choose, make sure it's an empty one, and you just hit a plus and then you hit finish and you're in. Now we have one here that's already set up here, but let me show you again pointing out what we have in place."},{"start":"3:50","end":"4:25","startSec":230.8,"text":"I made sure that underneath my emitter state, I hit plus and added or I should say update, I hit plus and I added my spawn burst instantaneous. And I kept this spawn count to one and the spawn time to zero. I left those default and that worked just great. From there, I also want to underneath my particle update, click down the plus arrow, and I added a sub UV animation. Click on this one. And we want to make sure that we're using our start frame of zero like I mentioned before, and end frame is 63 because we want one just behind the next frame."},{"start":"4:25","end":"4:59","startSec":265.1,"text":"Very important to consider. And then from there, we go to sprite render and under sprite render underneath sub image size, we change that to eight by eight, like we talked about before. And finally underneath our initial particle, we want to make sure that our underneath our sprite attributes, we set the sprite size mode to uniform and then the uniform sprite size to 500. This is key so that we actually have the accurate size that we need and it almost does like a one to one. Now again, you can change the size to whatever you need for your sprite."},{"start":"4:59","end":"5:33","startSec":299.2,"text":"So once you're done, you want to go ahead and hit save and then you simply just drag it into your scene. This particular one is going straight from the opacity and the emissive. The opacity is working great, but the emissive is a little bit bright. So if we decided to revisit this effect, we can go in here and go to its material. And if we want to hit save, let's see if we'll update this guy is the one that we kind of were tweaking with. And then now we can see that it is a bit darker and a little bit closer to what our original"},{"start":"5:33","end":"6:04","startSec":333.1,"text":"is. Now again, keep in mind you're looping. So if you do want to use this and this isn't too bad, the resolution isn't too shabby, especially if it's far away. You want to go ahead and edit things accordingly. So you can also go in here and edit the glow and Photoshop if you want to. And there's multiple ways to get this where you want, but this gives you a lower level effect that you can put in the background. Again, you do need to consider how many frames you want, how long it's going to play and how long the camera is going to be looking at it."},{"start":"6:04","end":"6:34","startSec":364.5,"text":"Now in another way, which I mentioned earlier, and I'll give you a link at the end of this course, you can also create a plate that you render out to using Houdini or Emberjan or Maya and it can be an EXR HDR output and UNRUL will accept that in your scene. Now this isn't part of this course, that course, but I do offer that link to you if you decide to go that route and you need something even higher resolution wise. But this gives you a quick, simple solution versus that EXR one, which gives you even"},{"start":"6:34","end":"7:07","startSec":394.5,"text":"a higher resolution. So you have the best of both worlds to play with things. Again, all of these steps are laid out for you, such as building the material, making sure that it's translucent, and then making sure you're loading the right texture in your texture sample node, and then connecting a divide to your opacity emissive. And also you can connect it to your base color. But keep in mind, if you connected to your emissive, there could be some brightness there and kind of just use it the way that I created. We had a scalar and a multiply and we can downplay that if we need to or increase it"},{"start":"7:07","end":"7:37","startSec":427.8,"text":"as needed. And then also in the effect itself, some quick review here again, start frame needs to be set to zero and end frame in the sub UV animation node that you need to make. Make sure you also create a spawn burst instantaneous, keep things at default, and then a sprite renderer you want to make sure the sub UV size is eight and eight underneath your sub UV category. And then finally in that Niagara emitter, or I should say system, you should go in here"},{"start":"7:37","end":"8:09","startSec":457.8,"text":"underneath your sprite attributes. And in here you want to control and make sure your uniform sprite size is 500. By default, the life cycle mode should be system on both scalability and life cycle. But you can triple check this, especially if you're inheriting an effect that someone else has created, make sure that the life cycle mode for this particular node is set to system and it sets a system for both of them. That's it with this lecture. Here's some links to help you along your journey to give you more information about what we"},{"start":"8:09","end":"8:15","startSec":489.3,"text":"talked about. Thanks again. And in the next video, we'll do a quick recap about everything that we've learned."}],"09_Outro":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"So, let's go ahead and recap some of the stuff we talked about. We talked about foliage optimization, analyzing the scenes and priority areas. We looked at optimization based on shots. We looked at Lumen, updates with foliage, and foliage and world partition. Then we took a look at Niagara optimization overall, looking at the checklist for performance, debugging, additional steps, console commands, FX Outliner, and baking the effects to a flip book."},{"start":"0:30","end":"0:37","startSec":30.4,"text":"Well, I hope you enjoyed this course. And thanks again, and let us know if you have any questions."}]},"205.01":{"01_Intro":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Hello, and welcome to the Unreal Training Sequencer Animation Production Workflows. My name is Kevin Miller, and I'm an instructor for Epic Games. This course is one of the follow-up courses to the Sequencer Introduction Course and begins the Sequencer Animation Track of courses. We'll begin this course with a look at virtual production, pipelines, and workflows. Then review some of the core concepts from the introduction courses, such as importing animations and sequencer fundamentals."},{"start":"0:31","end":"1:04","startSec":31.3,"text":"After that, we will look at the sequencer features and tools related to animating with Unreal Engine, such as the workflow features and tools that you can use while animating in-engine before we dive into some hands-on animation practice where I will briefly cover animation assembly and then walk through a step-by-step exercise on using the inverse solve to modify animations. Finally, we will wrap up this course with some final recommendations discussing organization, workspace layouts, and I'll provide you with some tips and resources for continuing your"},{"start":"1:04","end":"1:40","startSec":64.7,"text":"animation training with Sequencer. Additionally, this course will also use the project SEQ9050153 from the previous courses, and the level map should load automatically. But if the map does not load at the launch of the project, it can be found in the Content browser under the courses, course maps, and it is the level map titled SEQ90501 map. Course materials for this course are located in the courses folder under the 20501 course"},{"start":"1:40","end":"1:58","startSec":100.9,"text":"topics. Once again, if you ever need to reference the location of the course map, that can be found at the beginning of the slide deck after the training outline. Now let's move on to our first section and begin with a discussion of virtual production pipelines and workflows."}],"02_Workflow":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"As we begin to explore using Unreal Engine for animation, we need to first look at virtual production pipelines and workflows to better understand where Unreal Engine best fits into a project. First, let's look at a very simplified overall workflow for a production that begins like all productions, with an idea. Once that idea is presented, it moves its way through development and pre-production, and then into production. For now, Unreal Engine can be implemented in these two production stages."},{"start":"0:33","end":"1:07","startSec":33.1,"text":"But new tools will allow Unreal Engine to push its way into areas of the post-production stage, allow a production to extend the range where Unreal Engine can be implemented into the production pipeline. Now, if we look at this simplified overview of the typical animation studio pipeline, the current workflow usually begins with story development. That's where the story department and storyboards start charting the course of the project, with the main beats of the story. This lays down the track for the production train to follow, but in this way, you really"},{"start":"1:07","end":"1:41","startSec":67.3,"text":"can't move ahead in production without these core elements being nailed down for the other departments to follow. Once the story department lays the track, then production design and asset construction can move full steam ahead. This is where all the modeling, rigging, surfacing, or texturing happens, along with figuring out all the technical requirements involved in creating the scene assemblies. From there, production goes into creating rough layouts, and generally chugs along to compose all the scenes for the project before animation and layout send shots back and forth"},{"start":"1:41","end":"2:12","startSec":101.9,"text":"until the final layout is completed. After that, everything is transferred over to the shot enhancement track, and you might start doing more shot-specific work for things like lighting, character or camera effects, crowds, simulation, and creating mats for composite. Finally, when all that's finished, you're ready to start image output. Of course, the lighting and editorial teams have probably been working through comps during the entire process, but now all the elements should start to come together and get that"},{"start":"2:12","end":"2:44","startSec":132.9,"text":"final edit completed. So as we just saw through the pipeline example, there are some practical differences that manifest as strengths and weaknesses to this approach. These become pretty apparent in the traditional CG animation pipeline, as it is a very front-loaded story process that almost requires the project teams to figure out all the main story beats before anyone can do anything else. This creates those very silo-centric publishing requirements, and that in turn forces the"},{"start":"2:44","end":"3:17","startSec":164.2,"text":"editorial and layout departments to step in and serve as the main production hub, leaving principal creatives to be governed by the results of pre-production once all the elements are in place. This makes that the only way to know where everything else is going. This means there is potentially less interactivity between departments, and that can result in a rather labor-intensive revision process. And sure, you can still do things like dailies. That doesn't really change. But in the traditional pipeline, it's less tactile, and once a shot is near completion"},{"start":"3:17","end":"3:52","startSec":197.9,"text":"and the layered renders are getting composited for final output, it's not that easy to see the finished result and then suddenly have to make changes. At that point, the artist would have to go back, make edits, and then re-export the shot through the entire pipeline. And on top of that, limited cross-departmental or even cross-studio compatibility if you have partners or more locations can create an even slower iteration process than what you might get when working in real time. Here, we start to see some of the advantages when using real-time game engines in your"},{"start":"3:52","end":"4:26","startSec":232.3,"text":"production. The story development process is better integrated into production, and as a result, shot construction can feel more like a live-action production, where the director can be involved in the entire shot creation process thanks to Sequencer acting as the production hub. Since Unreal Engine's editorial tool, Sequencer, now serves as the production hub, the revision process, led by the director, becomes much more interactive. The finished or near final results from Unreal Engine can be exported or rendered at final"},{"start":"4:26","end":"4:57","startSec":266.3,"text":"pixel levels, and overall, the entire pipeline becomes unified and more collaborative thanks to real-time integration. The idea here being that you can either build a new pipeline from the ground up with Unreal Engine at the core of your workflows or have Unreal Engine take over the areas that benefit your pipeline for enhanced efficiencies. So what does that pipeline look like? Well, in the real-time animation studio pipeline you see here, there are two colors."},{"start":"4:57","end":"5:32","startSec":297.3,"text":"Everything in purple is a part of the production that can be done in Unreal Engine. Everything in teal still requires the use of a DCC application, but anything that shares both colors can be done using whatever tool the production decides to implement. That means the first thing that can change is the way story development works. Instead of being cut off from production, the story can be blocked out in Unreal Engine by using the free Storyboard plugins Epos and Iliad from the Praxinos Co-op group. This can be used to generate storyboards and create a real-time story reel or animatic."},{"start":"5:32","end":"6:02","startSec":332.2,"text":"This first change can drive faster scene assembly, concurrent modeling, rigging, and surfacing, and lead production through a more collaborative and dynamic production process. Everything works together to create the sequence assemblies. Ideas can be tried out, iterated, and either kept or discarded depending on what best serves the narrative direction. Performances can be captured in the engine, adjusted, and polished by animators. Cinematographers working together with the director in real-time don't even need to"},{"start":"6:02","end":"6:37","startSec":362.6,"text":"be in the same room as the project can be accessed remotely by staff. Performances don't necessarily need to be finished before some of the shot enhancements are implemented as the departments can pass shots around or work in parallel to achieve near final renders or a complete and more simplified final edit that doesn't have to wait for everything to be perfect and now allows for a faster revision process. Now I just mentioned how animation can be done in the engine and really that's what"},{"start":"6:37","end":"7:10","startSec":397.6,"text":"I want to focus on today. We're going to take a deeper look at this area in the real-time animation studio pipeline. Once character asset construction is nearing completion or totally complete if you aren't the Unreal Engine toolset for creation, then your teams can start creating performances that can be captured, imported, and edited using Sequencer and Control Rig. The current workflow for polishing the performance capture animation is one that lends itself to nearly infinite revisions and noodling."},{"start":"7:10","end":"7:41","startSec":430.4,"text":"Once the performances are trimmed down, you can use the bone matching and blend tracks to create your assembly. Then just choose one of two paths for polish. Either go directly to using the inverse solve and baking the performance onto a Control Rig character or add in some transform track keys and then bake down the animation to the Control Rig. From there, just create the Control Rig's additive transform layers and start animating. As you work through the animation, you can always bake down a new animation sequence"},{"start":"7:41","end":"8:07","startSec":461.9,"text":"and then apply that new animation track to see how it's going. This workflow is one that is non-destructive and allows you to go back to any previously saved point along the process. So that finishes up our look at the pipeline and workflows for virtual production. But before we try the animation workflow out on our own, we will do a few quick review sections of some core concepts starting with importing animations."}],"03_Importing":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Okay, in this section, let's review some core concepts. And we'll begin with importing animations. When importing animations, there are a few things that are important for you to know. First is that we're going to be using the FBX file format to import. And we're going to do that directly from the Content Browser inside Unreal Engine. Things to note here is that when you import an FBX file, Unreal Engine will triangulate the mesh associated with the rig that you are trying to bring in for that animation."},{"start":"0:32","end":"1:03","startSec":32.6,"text":"If it's the first time you're importing, click Import on the Content Browser. Select the FBX that you want to bring in. And the first time you import a whole new character, you'll need to make sure that the mesh itself and skeleton are imported together. The skeletal mesh needs to be checked on in the FBX import options, as does the import mesh option. When importing animations, you have a few options to choose from when it comes to bringing in your animation. Starting with your animation length."},{"start":"1:03","end":"1:35","startSec":63.6,"text":"The options to choose from are the exported time, which is pretty much the whole animation, the animated time, which is just the animated parts. So if you start on frame 12 and give yourself a few frames to warm up without any actual animation or keyframes, those warm up frames will be cut off. Next is the set range, which allows you to manually select the frames that you want to import. The only problem with the set range is that you cannot do more than one set range import at a time. If you have multiple animations on a single timeline, you will need to manually select"},{"start":"1:35","end":"2:07","startSec":95.0,"text":"the frames for each section that you want to import. Next, you have the option to choose the sample rate, and you must make sure that you check on import bone tracks. Some helpful importing tips for you is that the transform option will fix incorrect rotations from 1 DCC into Unreal Engine. It will also give you the option to fix any scaling issues that you might have. You also have the option of importing a uniform scale, which should correct any scaling issues you might find when bringing in your asset."},{"start":"2:07","end":"2:38","startSec":127.2,"text":"Under the miscellaneous section, you might want to check on force front X axis to correct the position so that you use Unreal Engine's Z up axis. To use Unreal Engine's preferred unit of measurement, which is centimeters, you want to convert scene Now, if you're bringing in animations for old skeletons, you just import that like normal. Select the skeleton you want, choose the animation length, and if the skeleton is exactly the same, then it should be pretty straightforward."},{"start":"2:38","end":"3:15","startSec":159.0,"text":"If not, you may have to retarget it with the new Retargeting toolset. When adding purchased animations to the Library tab, just add the project directly or add your animations to a different project and migrate just the specific animations that you are interested in using in your project. Now, your animation will probably need to be retargeted, and that's because it likely comes with its own skeleton that doesn't match exactly what you're going to find in the SKMany or SKQuin character rigs, or the metahumans that you might be building and bringing into the engine."},{"start":"3:16","end":"3:26","startSec":196.8,"text":"OK, that's it for this review section of Core Concepts, Importing Animations. In the next section, let's review a few Sequencer Fundamentals."}],"04_Fundamentals":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this section, let's continue our review of core concepts with a quick look at Sequencer fundamentals. First, just a reminder that the Unreal Engine Non-Linear Editor and Assembly tool is known as Sequencer, a tool that is used for ground-up shot creation, pre-visualization, full film creation, game cinematic creation, and more. Actors from the Outliner or assets from your Content Browser are added into Sequencer to create level sequence assemblies."},{"start":"0:31","end":"1:02","startSec":31.1,"text":"Sequencer's user interface is shown here and broken into four distinct sections, and the first section is right at the top. That's the toolbar. The toolbar area is where you will find several options like adding cine camera actors to your level sequence using the camera icon. The slate icon is used to open the movie scene capture or movie render queue for rendering. You can also adjust your frame rate, toggle on or off the automatic keyframe option, save your level sequence, or activate the curves editor, or more."},{"start":"1:02","end":"1:34","startSec":62.4,"text":"On the far right of the toolbar, you will find the breadcrumbs, which is a navigation tool that lets you dive into any nested level sequence shot, make changes, and then navigate back up to the original level sequence container. Next, section number two, which is the Outliner. This is where you can add or filter tracks in your level sequence. It also acts as the event manager, allowing you to trigger events keyframed in the timeline, which is section number three. Located at the top of the timeline is the little red arrow known as the playhead."},{"start":"1:34","end":"2:07","startSec":94.2,"text":"Below the playhead is our tracks area, where every character, skeletal mesh actor, or static mesh actor that needs to be animated, every audio track, shot track or camera attached to the camera cuts track, or event trigger are all able to be keyframed. Under that, at the bottom is section number four, the playback controls. These can be used to play, pause, advance frames, loop playback, or even record a performance with the built-in take recorder. This is also where your time range slider exists, so you can adjust the view and playback"},{"start":"2:07","end":"2:38","startSec":127.8,"text":"ranges. So, now that you've been reacquainted with the Sequencer user interface, let's jump into Unreal Engine and prepare for the animation in-engine exercises. First up, let's move into the Content Browser, and located in the Courses folder, you will find and select the SEQ20501 folder. Inside that folder, you will find a Course Topics folder. Inside the Course Topics folder, you will find a Hands-On folder."},{"start":"2:38","end":"3:09","startSec":158.3,"text":"And in that folder, there are two Topics folders, one for Anim Assembly and the other for Inverse Solve. Begin your preparations by opening the Anim Assembly folder and double-clicking on the Anim Assembly Level Sequence. This will open up the example for creating our first animation assembly. This contains an SK mannequin and a few animation clips. If you want to choose from any of the other animation clips to create your own track,"},{"start":"3:09","end":"3:28","startSec":189.4,"text":"they are located in the Anim Clips folder. Feel free to play around with your assembly. Alright, that's it for this review section of Core Concepts, Sequencer Fundamentals, and in the next section, let's review a few more Sequencer features and tools before we dive into our Hands-On exercises."}],"05_Features":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Now, before we get into the hands-on sections of the Animation Production Workflows course, let's talk about the Sequencer features and tools for animation. Beginning with the workflow features. So one of the features that users will run into when working with Sequencer is the Allow Edits options. There are three options found in the Allow Edits pulldown menu, and the first is to Allow All Edits, which allows you to make all edits to any asset in a level sequence, level, or"},{"start":"0:33","end":"1:08","startSec":33.5,"text":"sublevel. The second option is to Allow Sequencer Edits Only. This option prevents any edits you make to the assets in the persistent or sublevels by only allowing changes to the active level sequence assets that are contained inside the Sequencer Event Manager. The last option works in much the same way as the second. The Allow Level Edits Only option limits users to making changes only to the assets that belong to the active level or sublevel but are not necessarily part of the level sequence."},{"start":"1:08","end":"1:39","startSec":68.6,"text":"Another feature you will find in Sequencer is the Motion Blending option, which is essentially bone matching. And that allows users to match a specific rig bone from one animation track to a previous or following animation track by right-clicking on the animation track and choosing which clip and bone to match with. The next Sequencer feature is Animation Track Blending, and this works in conjunction with Motion Blending. Animation Track Blending includes several preset easing options, much like the easing"},{"start":"1:39","end":"2:11","startSec":99.1,"text":"options that are available when blending camera cuts tracks, and as we build out the animation assembly in the hands-on section, we will combine Animation Track Blending with Motion Blending to create a complete animated sequence. Now, working with Sequencer, users will encounter two types of Transform Tracks. The first type is the Standard Transform Track that functions on any static mesh actor added to Sequencer. Standard Transform Tracks have four options available to the user."},{"start":"2:11","end":"2:42","startSec":131.8,"text":"Absolute, Additive, Relative, and Additive from Base. Absolute overrides and ignores any existing keyframe animation and zeros everything out at the origin or initial state. This allows an animator to create new animations that replace any existing animations. Additive is the next and most common Transform option that layers new or corrective animations on top of the existing animations applied to an actor."},{"start":"2:42","end":"3:14","startSec":162.9,"text":"After that is the Relative option, which serves as a blend between Absolute and Additive options. As the name suggests, this option creates animations that are relative to the position, origin, and existing animations. Personally, I don't use this option all that much, but it does have its purposes. And lastly, the Additive from Base works just like the Additive, but uses the Base animation as its origin point. The next type of Transform Tracks are Control Rig Transforms."},{"start":"3:14","end":"3:49","startSec":194.8,"text":"With Control Rig, there are only two Transform options, Absolute and Additive. These function the exact same way as the Standard Transform Tracks. Absolute overrides and ignores the existing keyframes, creating a new track for every control on the Control Rig. While Additive is the second option, and just like the Standard Transform, Additive is also the most commonly used Transform as it allows for the modification, layering, and correction of any existing animations on every control in the Control Rig."},{"start":"3:51","end":"4:23","startSec":231.2,"text":"OK, so I want to take a moment and remind you of Sequencer's function as an Event Manager. And as we work through building our animation assembly and applying the inverse solve for Control Rig animation, the Event Manager is where all of your tracks and controls will be located. As you animate with Control Rig or add Transform Tracks and keyframes to your animation, you will also be working with Sequencer's Curves Editor, activated from the Sequencer menu. Additionally, I also want to note that the Curves Editor and Event Manager are not limited"},{"start":"4:23","end":"4:44","startSec":263.1,"text":"to just Control Rig animations, but both work with Take Recorder, Cinematic Event Triggers for Assets, Blueprints, Niagara, Composure, and Material Parameter Collections. Alright, that's it for the workflow features of this section. In our next Sequencer Features and Tools section, we will discuss working with the Animation Mode Tool Set."}],"06_Animation_Mode":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Now, in this section of Sequencer's Features and Tools, we're going to explore the Animation Mode toolset that is available when animating with Control Rig in Unreal Engine. The first thing you will encounter when working in Animation Mode is the addition of two animation-specific tabs, the Anim Outliner and the Anim Details panel. And just like the name suggests, these are animation-specific versions of the already familiar Outliner and Details panels. The Anim Outliner is designed to show the controls as organized by hierarchy in your"},{"start":"0:31","end":"1:01","startSec":31.0,"text":"active Control Rig. Here, you can show or hide the Control Rig controls or quickly select a specific control from the Outliner to make it an active selection in Sequencer. The other tab is the Anim Details panel, which provides animators an isolated view of the Euler Transform channels for the selected Control Rig control that they are manipulating. The next set of Animation Mode tools are a series of animation buttons found in the Animation tab when Animation Mode is active."},{"start":"1:01","end":"1:32","startSec":61.7,"text":"The first of those buttons is the Select button, and in general, I would just keep this button enabled while animating a Control Rig. When active, the Select button only allows users to select the Control Rig controls preventing any accidental selections of things like the Scale Mesh, Actor, Geometry, random Static Mesh props or set pieces, particle systems, lights, or cameras. The next tool is the Poses button, which activates the Control Rig Pose window. The Control Rig Pose window allows users to create and then share pose libraries for commonly"},{"start":"1:32","end":"2:05","startSec":93.0,"text":"used character poses. So for example, any kind of character-specific poses that must be frequently replicated across multiple sequences, scenes, or shots can be created and stored in a shareable library. Poses that add specific personality or quirks to a character's body mechanics can also be shared and then applied to something like performance capture data to alter or exaggerate that performance to fit the character's personality, allowing other members of the animation team to take on some of the work, reducing the burden on the character animation leads."},{"start":"2:05","end":"2:38","startSec":125.0,"text":"The next set of tools we will talk about is the Snapper and Pivot buttons. The Snapper button is used to define a parent and child relationship between a Control Rig and an Influence Actor for creating keyframe animations on the Control Rig controls through a temporary control attachment. This can be very useful when implemented in specific scenarios where you want to have an animated asset influence the position of the controls to generate synchronized keyframe animations on the temporarily attached Control Rig control. Just like the example shown here, where the parent, which is the bouncing static mesh"},{"start":"2:38","end":"3:09","startSec":158.3,"text":"ball, is used to create keyframes on the child Control Rig IK Hand control. Of course, additional polish animation will be needed to make this animation look better, but it does provide animators a solid synchronized starting point, saving some animation time. The next button in our toolset is the Pivot button, and just like the name suggests here, the Pivot button does exactly what it says it will do, allowing an animator to adjust the pivot point, creating an offset for the Control Rig controls."},{"start":"3:09","end":"3:42","startSec":189.3,"text":"Finally, there are just two remaining animation tools that need to be discussed, the Trails button and the Tweens button. The Trails button serves two functions. The first is going to help you with visualization of the animation path in the viewport. Motion trails can be visualized and information related to that path can be added or subtracted depending on the user needs. The second function is direct manipulation of the motion trail inside the viewport. Motion trails can be moved or modified, allowing an animator to perfect those arcs and look"},{"start":"3:42","end":"4:14","startSec":222.3,"text":"for any bumps or unnatural motions that might not be obvious. One thing to note, the Trails button can make curve manipulation easy, but they are very processor intensive, so be careful. Users will need something pretty powerful hardware wise to make the curve manipulation run smoothly. Lastly, we have the Tweens button, which is used to adjust the interpolation between keyframes using three preset tween modes. The tween modes are the BN mode, which blends keys to the nearest neighbor."},{"start":"4:14","end":"4:33","startSec":254.0,"text":"The PP mode, which push and pulls curves between the selected keyframes. And the TW mode, which tweens the selected keyframes. Alright, that's it for Sequencers features and tools. In our next section, we will jump right into some hands-on animating and engine, beginning with laying the groundwork by building our first animation assembly."}],"07_Assembly":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In this section, we're going to do some hands-on animating in Engine, and we'll start out by diving right into Unreal Engine and walking through the creation of a simple animation assembly in Sequencer using a few performance capture animation clips. As we work through the animation assembly exercise, you can choose to follow along or skip ahead to when you see the video jump back to the slides and review the steps used for creating the animation assembly in Sequencer. When starting out without a provided library of animation, you will need to import your"},{"start":"0:32","end":"1:05","startSec":32.3,"text":"performance capture animations and then duplicate the original captured data. Review the performances and duplicate the performances again for each clip you want to create for your assembly. Then edit and trim down the clips so that they are ready to use in your animation assembly. So let's get started. If you see where we left off, this is the animation assembly example that is already inside the animation assembly folder with the folder for the animation clips. Now rather than start out with something that's already done, let's go ahead and make this"},{"start":"1:05","end":"1:39","startSec":65.0,"text":"ourselves. So to do that, I'm going to go ahead and right-click in my content browser, move up to my cinematics, and create a new level sequence. I'm going to call this AnimAssembly EX, for example, and go ahead and hit Enter, then double-click to open it on up. From there, I'm going to need a mannequin to put into this level sequence. For that, I'm going to go up to my outliner, select my SKMannequin TS example, and grab this character and drag it into Sequencer. Now if I look at this character, it pops in with the control rig on it."},{"start":"1:39","end":"2:11","startSec":99.1,"text":"Now I don't want to do that. The control rig will override any animation and I need the animation to be what's driving the control rig. So before I get started with my animation clips, I'm going to go ahead and delete the control rig. Now I have a couple ways I can add in my animation. I can either hit the plus button and choose from any animation in my list, or I can go ahead and grab some animation clips from inside the AnimClips folder. Now I'm going to start out with the Mani Walkup. So I'm going to go ahead and drag this on in and I'm going to move this on over."},{"start":"2:11","end":"2:41","startSec":131.1,"text":"And this is a bit long for the walkup. I'm going to keep this pretty short so we can add in more clips. And I actually want a little bit more time, so let's move up into my viewport here and you can see where this red 150 exists. I'm going to go ahead and extend that to 300 frames. Now at the bottom here in my timeline, you can see that it says 300 300. There's no space on the end, but I need a little bit of buffer space just to see and to give myself some room to see where the end of my animation actually is. I'm going to change this to 330."},{"start":"2:41","end":"3:12","startSec":161.9,"text":"And I'm going to change this negative 15 to negative 30. Now I have a little bit more space to work from and I want to see where we're going in my animation. So starting out here, you'll see that the animation is going all the way up to the walkup and I can probably shorten this up a little bit. So let's go to about frame 135 and let's go ahead and grab this blue mark here and just drag this on over to 135."},{"start":"3:12","end":"3:43","startSec":192.9,"text":"From here, I'm going to move to about frame 60. Yeah, about frame 60. If I want to be exact, I can actually type in the number here that will take me exactly to where I want to be. So right at frame 60, I think this is a good cutting point. If I'm on my animation and I right click, I can trim this by right clicking, going up to edit and trim selection left. That's going to give me a shorter animation clip. I'm going to move this all the way down to the zero to start out here."},{"start":"3:43","end":"4:16","startSec":223.3,"text":"Now I'm going to need some more animation. So let's go ahead and choose the head scratch or shrug. Now it's up to you on which ones you want to use or what animation you want to work with. For me, I'm going to go ahead and choose the shrug. So I'm going to start right here, right around 220. I'm going to right click and I'm going to go ahead and edit and trim selection left. Then I'm going to drag my shrug all the way down and with my shrug set, I'm going to go ahead and go until the arms collapse and relax a little bit."},{"start":"4:16","end":"4:53","startSec":256.7,"text":"Right here at about 170. From that, I'm going to go ahead and drag this on over so that this clip is 170 frames total so far. And then from here I need to add in some extra steps. So from this position, I have a couple options. Instead I'm going to start with a big giant sidestep. Now this is a little bit long and it doesn't move quite where I want it to go because it's on the opposite side, but we're going to fix that in just a little bit. So before he starts to move, go ahead and put that right in here."},{"start":"4:53","end":"5:28","startSec":293.3,"text":"And I'm going to go ahead and right click, edit, trim selection left. Move that on over and then let's choose some small sidesteps. Now I'm not going to trim these down. I'm just going to leave these where they are because I'm going to need some extra animation at the end here to make sure that this all lines up. But the first thing that we need to do is our bone matching. So to start off, we're going to bone match the entire clip. I'm going to go ahead and select everything. And I'm going to go to animation, move up and blend first child of root."},{"start":"5:28","end":"6:00","startSec":328.0,"text":"That's going to blend them all together, but it's not going to do all of them. So this is where bone matching comes into play. For that, I'm going to go up and select the second clip in my timeline. I can choose the first clip, but I'm going to choose my second clip. I'm going to move from second clip to previous clip every time I match. So this clip, I'm going to right click and go to match bone in the previous clip. I'm going to choose my root. Then I'm going to go ahead and choose my pelvis. Same thing. And I'm going to scrub through to see how they line up."},{"start":"6:00","end":"6:31","startSec":360.2,"text":"So they pop a little bit. That's OK. I want to match them again. Let's go back up and match with the previous bone clip. And let's choose now the foot. So I'm going to choose part of the foot, which is going to be the ball on the left side. You'll see him popping a place again. And you see that gets us a little bit closer here. Now I'm going to go through quickly and I'm going to go ahead and do the same thing with my sidestep. So if I look at my sidestep, you see it's way over there. I'm going to go ahead and do the same thing. Right clip, match with the previous clip."},{"start":"6:31","end":"7:03","startSec":391.0,"text":"I'm going to choose my pelvis. And since this starts to move pretty quickly and I want my feet to match, I'm going to go ahead and match this with bone in previous clip and choose my left foot again. Ball left, right up in here. And you can see that little pop in place. That's kind of what I want. Now it is still going to pop and we'll have to fix that. There's some shifting that's probably on the root. So let's go ahead and just make sure that we match up our end point in here."},{"start":"7:03","end":"7:33","startSec":423.5,"text":"So same thing here. Right click, match bone with previous clip. And let's go ahead and choose the pelvis first. That gets us in place. And let's see what happens first if we match the previous clip with the foot again. So ball left. And you can see that that's going to turn my character. So unfortunately, that's not a good result. I'm going to go ahead and choose this and let's match in here our bone with the previous"},{"start":"7:33","end":"8:05","startSec":453.5,"text":"clip and just choose our pelvis again. So this still lines up. And since they're standing in almost the same position, it's going to be an okay clip for blending. Next is our blending options. So we need to blend our animation tracks. That's fairly easy. So I'm just going to go ahead and hit the control button and drag across the top of the timeline to zoom in on my blend sections. And then I'm going to grab the next clip and smoosh that into the previous clip. About 10 frames. You can see I'm at 75."},{"start":"8:05","end":"8:37","startSec":485.8,"text":"Let's move that down to about 65. That's going to give us a nice long blend between the two. Now to modify my blend, I can right click directly on it, move up into my options and choose some easing options. For this one, I'm going to go ahead and choose a quartic in and out. Now that's going to give us a fairly decent blend. And I'm just going to move down my timeline to the next section, which will be easily seen because now I have a gap between them. So I'm just going to go ahead and drag that down and same thing, 160 to 150."},{"start":"8:37","end":"9:08","startSec":517.9,"text":"Let's just shove that right in, giving myself a good 10 frame blend between the two. And in this one, I'm going to go ahead and right click on my options for my easing and adjust this one to a cubic in. But I'm blending from here into this a little bit faster towards the end. That's probably going to help out a little bit in the blend itself. Now I could probably make this the opposite direction. So let's go ahead and change this, go right up in here, go to options and let's do a quartic"},{"start":"9:08","end":"9:40","startSec":548.9,"text":"out. And that'll be a little bit faster. So we get down a little bit faster here. I'm going to drag this on over. We have a little bit of a bigger gap now. And I actually have a subframe bleeding over in here. So I'm going to clean this up just a little bit. I'm going to grab my side step small and same thing. I'm at 214. I need enough space. I'm going to go ahead and shove this down into 204. And for this one, I'm going to keep this one pretty clean."},{"start":"9:40","end":"10:11","startSec":580.1,"text":"And you can see that this is my average option. Rather than doing anything really different in here, I'm just go ahead and hit linear and see what that looks like. Yeah, so this is going to give me a pretty even change in here. And that's going to work out just fine. My feet slip a little bit, but that's okay. I think I'll be able to fix that a little bit later. Now I just want to drag all this out to the end. And you can see that I have all this extra space. If I move right to the end or type this in at 300, then I can right click, go into edit"},{"start":"10:11","end":"10:41","startSec":611.1,"text":"and trim my section right. That trims down my animation to fit within my timeline. And that completes our animation assembly. Now to make sure that my mannequin belongs to this level sequence, I'm going to go ahead and right click it and convert this to a spawnable. So now my level sequence is ready to have the inverse solved applied to it. Okay, so let's jump back into our slides. Okay, let's review everything we've just done inside Sequencer to create our animation assembly."},{"start":"10:41","end":"11:14","startSec":641.6,"text":"The first step was placing the animated clips in the timeline. We began by opening an animation assembly level sequence or creating a new animation assembly level sequence to add our animation tracks to. Then we chose any of the clips that were located in the Anim Clips folder. Or if you used your own clips, we selected those and dragged them into the Sequencer animation track to create our animation assembly. We also deleted the control rig from the SK Mannequin actor inside Sequencer to prevent"},{"start":"11:14","end":"11:45","startSec":674.8,"text":"that from getting in the way. Next we applied bone matching. And the first thing we did was right click on the animation track and check on the Blend First Child of Root. That blends the pelvis and was our first blending option to help match with all of our animations based on their pelvis location. Then to do more bone matching, we right clicked on the animation clip to bring up the clip's properties."},{"start":"11:45","end":"12:21","startSec":705.9,"text":"We selected the Motion Blending option and matching the bone with either the previous or next clip. Then we selected the bone we wanted to use for matching. We switched a little bit between the root, pelvis, and ankle just to see how those looked. The third step was blending our animation tracks. To do this, we grabbed the next track in our sequence and smooshed it into the previous track. This created a little blend between the two. To modify the blend, we right clicked directly on the Blend option."},{"start":"12:21","end":"12:52","startSec":741.1,"text":"That brought up our Properties and Options menu and from there we moved into the options for easing and selected our preferred easing option. We played with a few options to see how those looked and then chose whichever one we preferred for our desired animation easing. Doing this completed our animation assembly. And that's it for this section of our hands-on animating and engine. I hope you enjoyed creating your animation assembly and in our next section we will continue"},{"start":"12:52","end":"12:58","startSec":772.4,"text":"our hands-on animation and engine by using that assembly in our exercise Applying the Inverse Solve."}],"08_Inverse_Solve":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In this section, we're going to continue with our hands-on animating an engine, jumping right back into Unreal Engine and walking through using the animation assembly we just created in the last section to apply the inverse solve. As we work through the inverse solve exercise to apply the animation assembly to our control rig, you can once again choose to follow along or skip ahead to when you see the video jump back into the slide deck. There, we will review the steps used applying the inverse solve to the control rig in Sequencer."},{"start":"0:32","end":"1:04","startSec":32.2,"text":"Now let's get to it. Where we left off with our animation assembly is the example that is completed and ready to go. Now, I want to work non-destructively, so I'm going to start with the animation assembly example that we just created and I'm going to duplicate it. And in this case, I'm going to call this inverse solve, is, ex for example. And the reason I keep this short is because I'm going to be adding to this as I go through. Now I've saved it again and I'm going to drag this over to the inverse solve folder. And the reason I'm going to move over to that folder is because here I have some examples."},{"start":"1:04","end":"1:36","startSec":64.8,"text":"Now, if you move things around, you do want to make sure that once you're done, you right-click, go up to the fixed redirectors and hit fixed redirectors to make sure that there are no problems with any of the pathing of your files. Now, I have my IS example. You can see that I'm still in my assembly example, but I want to open up my inverse solve example. I'm in my inverse solve example. And from here, I again want to work non-destructively. But I want to start by adding in and working through the inverse solve."},{"start":"1:36","end":"2:09","startSec":96.1,"text":"This is going to bake this animation track onto the control rig. To do that, I just right-click on the animation for the mannequin and I go right up into the control rig section and I choose mannequin control rig. That's going to bring up a menu and that menu is going to give me some options. I'm going to ignore most of these options right now, especially the export. And I could do some reduce keys, but I want to keep everything just to show you that everything gets added and baked onto this. So I'm going to hit create and it's going to bake pretty quickly."},{"start":"2:09","end":"2:39","startSec":129.1,"text":"So from there, the animation track gets muted. And the mannequin control rig now contains every animated key for every control that is applied to the entire control rig. It also moves me into animation mode. So you can see I have my anim outliner, my anim details panel, and my animation ready. And my control rig is on my character. Now, I'm going to go ahead and save this because again, I want to work non-destructively. And from here, I'm going to go ahead and duplicate this again."},{"start":"2:39","end":"3:14","startSec":159.7,"text":"And I'm going to call this isanim example. And the reason for that is that I want to work on the animation at this point. And the first thing that I want to do for working on my animation is move up to my control rig, choose the plus button, and choose one of the two tracks that I'm going to use for transforms. Now, we're just going to modify this animation. To modify the animation, I'm going to choose additive. Now if I chose the absolute option, the absolute option would have overridden the key frames"},{"start":"3:14","end":"3:45","startSec":194.3,"text":"that are on here. From here, I'm working with my animation example, and I'm ready to start modifying my animation. And I don't need the animation track anymore. So I can select this track and delete it. Now, my animation is driven by my control rig. So you can see that as I move, my controls are moving. Now from here, I can just go through my animation, find some adjustments, and select any control and see where I want to fix things. So if I look at my feet and I see where my feet move or slide, like this move down here,"},{"start":"3:45","end":"4:18","startSec":225.8,"text":"you can see what twists and turns happen. I can go ahead and make adjustments so that things match a little bit. I can fix elbows, I can fix shoulder controls, you can see where any of this stuff is in here. And all I need to do to make these changes is just go ahead and grab some controls and move them on out. So let's move through the timeline and see where we start to get some pass through. So a good rule of thumb is that as this pass through starts to hit here, I'm going to go ahead and keyframe. Just press S to keyframe. And as that moves into place, I'm going to keep another S in here."},{"start":"4:18","end":"4:49","startSec":258.6,"text":"And you can see that's where that shift starts to take place. I'm just going to keep keyframing as I'm ready to make some moves. Grab a control and just push that on out, maybe raise this up a little bit so that the arm moves a little bit back. Maybe go ahead and rotate just a little bit so I get some other motion. Push it back a little, enter a different pose. And as you can see, I've got a pose that now blends in here out of the way. Now I can go ahead and do this for some of the other controls. Let's move to the other side. You can see that it's passing onto the inside of this body. I'm going to go ahead and fix that."},{"start":"4:49","end":"5:22","startSec":289.9,"text":"So where does that happen? Right around here. Let's start with a keyframe. Let's move that hand so it rotates a little bit more. And let's keyframe that out so that it's not passing into it. So let's go ahead and key that pose. Move over here. And this is where we want to move it out. And let's raise it up so it's not fully extended. Because I don't want any hyperextension on my elbow."},{"start":"5:22","end":"5:52","startSec":322.5,"text":"And maybe twist that out so it moves a little bit further out. Just hit S to make sure that my keyframe moves. And let's also add in a little bit right over here so this kind of flows a little bit back out. Flop that arm a little bit more. And let's move that back a little bit right over here. Just to kind of get back into the original position. Now I can blend in here. And one thing you'll note is that as I build in my animations, I do have an option that's in here that's not checked on automatically."},{"start":"5:52","end":"6:25","startSec":353.0,"text":"And that option is the weight. So if I move into this section, you can see if I right click on the additive, I have a weight option. That weight option can be keyframed on and off. Now as I move through, you can see I have the weight here. I can blend this so that if I only add in certain animations and I scroll down to the bottom of the transform, I can adjust the weight of those motions. So you can see the good example here was that arm. If I move between the weight on this control, I can adjust that weight just a little bit."},{"start":"6:25","end":"6:57","startSec":385.9,"text":"Now the value is 0 to 1. So you can see that's where we were. This is where we go. And I can overdrive this to push it further. Now I wouldn't necessarily want to do this. I'm just going to go ahead and leave this as one. But you can see that that option is there. Now as you go through and you animate, you are going to run into the issue where you want to be able to isolate what you're working on. So to isolate, you just select the controls you want, make sure that you're still in sequencer, and go ahead and hit the F10 key."},{"start":"6:57","end":"7:31","startSec":417.4,"text":"Now that will isolate the control that you're working on and show you what you've got for access. Simply return to that to see all of your controls by hitting F10 again. Now if you're hovering over a viewport and you hit F10, like in here where you're working, and you hit F10, it's going to hide everything and you might get a little confused as to what just happened. If you look on your sides, left and right, you can see that all my tabs got hidden and docked to the sides. Now I just want to return to that, go ahead and hit F10 again and it restores your view."},{"start":"7:31","end":"8:02","startSec":451.1,"text":"Now as you work through your animation, feel free to polish that animation as much as you want. Once you're done with your animation and you're happy with it, you can repeat this step and then duplicate this again. By duplicating this again, you can change this animation to AnimTrack, for example, rather than being the inverse solve because this is going to be a baked track. Now you can keep the inverse solve so you know which version or which iteration this is, but again you're working non-destructively."},{"start":"8:02","end":"8:34","startSec":482.9,"text":"So from here you just go ahead and save this, then right click on the mannequin again and now you want to bake an animation sequence. Baking the animation sequence is going to give you a new animation path that's in here and go ahead and name this to whatever the track you want to work with. So in this example I'm going to call this ISNMTrack01. So I want to keep this with my animation clips. I'm going to make sure that I'm in the correct path. For that I'm going to go into my courses folder. I'm going to go into my 20501 section under my course topics."},{"start":"8:34","end":"9:06","startSec":514.1,"text":"I'm going to make sure that I'm in my hands-on section under my animation assembly and since we're actually working with the inverse solve, I'm going to put it in my inverse solve folder. I'll create a new folder for animation revisions and I'll go ahead and load that in here. This way it's separated from my clips even though it's going to be a new clip. Once I hit OK, I have similar options. I have export options that are in here and I have a few to choose from. Now I could make some modifications in here. I could evaluate this in world space. I could record this. I can adjust quite a few different options that are in here, but I'm going to just use"},{"start":"9:06","end":"9:40","startSec":547.0,"text":"the basic defaults for now. Export that's going to create my track and you can see right here this is my animation track. Once that's done, I can apply this to the character and repeat the steps that I've already done to polish my animation further and further and over and over. Alright, let's jump back into our slides. Alright, let's review everything we've just done inside Sequencer to apply the inverse solve and modify the animation assembly. And we started with step one, which was baking to Control Rig."},{"start":"9:40","end":"10:13","startSec":580.3,"text":"This is basically the inverse solve. And to do this, we right-clicked on the SK Mannequin and brought up the options under the Control Rig section. There we selected the baked to Control Rig and chose the Mannequin Control Rig option. This brought up a pop-up menu, which provides us options for baking and we chose the default options for baking and hit Create. This baked the animation assembly onto an SK Mannequin Control Rig that we are now going"},{"start":"10:13","end":"10:44","startSec":613.4,"text":"to use. After that, we duplicated the level sequence and added the Additive Transform track. To do that, we hit the plus button on the Mannequin Control Rig, which contained all of our keyframes and base animation that we didn't necessarily want to modify. Using the Additive option in a duplicate level sequence allowed us to work non-destructively"},{"start":"10:44","end":"11:15","startSec":644.0,"text":"to modify those animations and clean them up inside the Transform track. The third step was just to animate with Control Rig to begin polishing, modifying our animation in order to make it look better or to fix any overpulls or adjustments or anything that didn't look right on our baked animation. We also isolated select Control Rig controls using the F10 hotkey to focus on just the controls that we wanted to work with inside Sequencer."},{"start":"11:15","end":"11:48","startSec":675.4,"text":"The end result is a slightly more polished version of our animation and from there we could bake down the animation into a new level sequence. That level sequence can then be applied back to the Mannequin and round tripped over and over again to continuously polish our animation. That's it for this section of our hands-on animating in-engine. I hope you had fun applying the inverse solve and modifying your animation assembly. Once again, I want to emphasize that this workflow can be used non-destructively and"},{"start":"11:48","end":"12:00","startSec":708.6,"text":"repeated in order to polish and improve your in-engine animations. In our next section, we will start to wrap up the Sequencer Animation Production Workflows course with some final recommendations."}],"09_Organiztion":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Okay, let's begin to wrap things up with a few final recommendations. And we'll begin with project organization. As demonstrated in this slide, there are levels and sublevels that allow for better organization and collaborative compartmentalization. So your environment or your persistent level will contain anything that is universally shared within the entire project. Project sets, environments, or discipline-specific setups can live on their own sublevels and to clarify, when I'm talking about levels, I'm referring to maps or worlds."},{"start":"0:33","end":"1:05","startSec":33.6,"text":"I do not mean level sequences. There is a difference between these two assets. Levels get organized into sublevels and live under your persistent level depending on what is actually needed for your project or department. For example, your main lighting setup should live on your persistent level, as it will be utilized by the entire project or production. Any level sequence-specific lighting setups should live in a sequencer lighting comp's sublevel, so that anything specific to the level sequence that is spawnable can be connected"},{"start":"1:05","end":"1:36","startSec":65.6,"text":"to that specific sublevel. That way, the lights in that level sequence can be called in and out without affecting the persistent level and causing problems between users working within that persistent level by having the sequencer-specific lighting turn on or off when the sublevel containing those lights is not active. Additionally, you can also create level visibility tracks in Sequencer that allow you to turn on and off the visibility of the assets in each of those sublevels so that they don't"},{"start":"1:36","end":"2:11","startSec":96.5,"text":"always have to be active. Now, I want to take a moment to emphasize just how important project organization is. Without it, things can get really messy very fast, so I highly recommend creating nested folder structures inside your content browser and inside your outliner to maintain project organization as you work. Another important factor in organizing level sequences is that actors within a level sequence can be divided into one of two categories, possessable and spawnable."},{"start":"2:11","end":"2:45","startSec":131.8,"text":"Possessable actors are intended to be possessed by each level sequence that calls them into use, but ultimately, these actor types belong to the level and are actively in that level the entire time. Spawnable actors exist within the unique level sequence to which they belong and then disappear when that level sequence is outside of its play range or no longer active. Basically, spawnable is like pulling a book down from a bookshelf, reading the instructions and then putting it back in to be used again later when needed."},{"start":"2:45","end":"3:17","startSec":165.6,"text":"Now, each of these can prove beneficial depending on your needs and workflows, but one of the things to note is that the EPO storyboard tools do not currently support spawnable actors at this time. Now, continuing our discussion about project organization, I want to point out that level sequences can also be deeply nested within each other. So let's jump into the engine and take a look at what that means. Now, if we look in the Content Browser inside Unreal Engine, under the Courses folder, you'll"},{"start":"3:17","end":"3:50","startSec":197.4,"text":"find in the 20501 folder under Course Topics, there is another folder called seqshortex. Inside that folder, you'll find an seqfilm level sequence that if you double click on, you'll find that this level sequence has been set up to contain subnested level sequences that can break down the film into sequences and sequences into shots. Also, shots can be varied thanks to Sequencer's Take system."},{"start":"3:50","end":"4:23","startSec":230.2,"text":"In practice, this works by creating duplicate shots of any shot in your level sequence, as long as they live together in the same folder. For us, seqscene1shots, there are three variations inside their scene1shot folder. If I move over to the Sequencer timeline and right click on this particular shot, I can go and move up to the takes and choose any of those three existing takes that are all different from each other because I've modified the animation, lighting, or even the staging"},{"start":"4:23","end":"4:58","startSec":263.0,"text":"of any actor within that shots level sequence. Now another actor class that has a profound impact on setting up action in Unreal Engine is the use of a subscenes track. A subscene essentially references an existing level sequence for the express purpose of layering multiple actions together. This type of organization allows you to create a departmentalized level sequence organization so that teams of artists can work together in real time to construct distinct portions of the action-based department or discipline that can be utilized in conjunction with sublevel organization."},{"start":"5:00","end":"5:34","startSec":300.6,"text":"Just as we discussed for the lighting scenarios, cinematography can also do this for cine cameras. Character animation can have its own subscene, so all your characters and animations can live on an animation-specific sublevel as well. Level blueprints or level sequence blueprints, level sequence specific effects, anything that could be spotable or triggered can also live on a sublevel under the persistent level and also be organized in Sequencer through subscenes. One thing to note is that while subscene organization works well for most departmental organization,"},{"start":"5:34","end":"6:08","startSec":334.3,"text":"it does not work very well with storyboarding tools at this time. Attempting to use a subscene for storyboards will cause Unreal Engine to crash. Finally, when working with animation in Sequencer, you might find it helpful to create folders for assets inside Sequencer to keep the event manager tidy. Or groups for assets while animating. Just be aware that the groups window does not dock to any part of Unreal Engine, so you will need to keep this window open. Oh, one more thing. When animating or working in Unreal Engine, you can use the F10 key to isolate selected"},{"start":"6:08","end":"6:31","startSec":368.3,"text":"control rig controls or isolate any tab you have active in the engine. F10 acts as a toggle, so if you accidentally dock all your tabs, don't worry. Just hit F10 again to restore your viewport and remember, try to work non-destructively by duplicating an animation asset before making major changes. Alright, that's it for this section. In our next section, we'll continue with more of our final recommendations."}],"10_Workspace":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this section, let's continue our final recommendations with a discussion about workspace layouts. The first thing that I need to point out is that your workspace layout is entirely up to the user. With that established, we do have some recommended layouts for specific tasks and hardware configurations. Our first recommended layout is for single monitor users doing sequencer editorial, assemblies, or layout. The position of your menu tabs is fully customizable, but it is highly recommended that you work"},{"start":"0:31","end":"1:02","startSec":31.0,"text":"using a split view viewport. So let's jump into Unreal Engine and change our layout. The first thing I want to point out is that right now I have a single view in my viewport. And I want to switch that by moving up to the little three dots in the upper left hand corner, moving down to my layouts, and setting this as two panes side by side. You'll notice in other videos I typically have this already set, as this is my preferred recommended layout. Now once they're set side by side, I want to make sure under the perspective option"},{"start":"1:02","end":"1:34","startSec":62.9,"text":"that one of these is set to cinematic control, while the other is set to the default viewport. This will allow me to move around my viewport without impacting the view of my camera that is possessed by my camera cuts track. Once you're all set, you can save any layout that you want by moving up to the windows tab, moving down here, and selecting to save a layout. Just select save layout as. You can also export layouts and share them among other users."},{"start":"1:34","end":"2:05","startSec":94.6,"text":"Once you have a layout saved, to load it, all you need to do is move into the load layout section and choose from any of the user layouts or default layouts that are saved for you to use. Let's look at some other options you may consider for other functions. Here is an example of a single monitor for animation work. The more expansive viewport and stacking for the sequencer is a layout I recommend as the animation tools will open up different menus and tabs but also require a larger viewing area for sequencer."},{"start":"2:05","end":"2:38","startSec":125.7,"text":"Next, we have an example of a layout that users can set if they have a dual monitor or ultra wide monitor hardware configuration. Once more, I want to emphasize that your working layout is entirely customizable in order to meet the individual user preferences. I want to point out again that any workspace layout can be shared among users once it's saved. And finally, I want to warn users that on occasion you might run into a bug when switching back and forth between saved layouts that will cause the engine to crash."},{"start":"2:38","end":"2:46","startSec":158.9,"text":"So just be careful. That's it for this section. In our next section, we will continue with more of our final recommendations."}],"11_Tips":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"Okay, this section will wrap up this course with a few more final recommendations, providing some tips and resources for you to use as you continue your Sequencer training in Unreal Engine. Here are a few tips we've covered before focusing on the Sequencer timeline tricks and notable hotkeys. Now, I used some of these in the previous course videos, so please try them out and see which ones work best for your workflows. Here are a few additional notable shortcuts for Sequencer. And as usual, the 2014 Fortnite Whitepaper is still a valuable resource, providing insight"},{"start":"0:35","end":"1:07","startSec":35.1,"text":"into the Epic Games cinematic process. Feel free to follow the link and download the paper. Once again, I would highly recommend that if you want to learn more, our online documentation has a robust section for cinematics and Sequencer available for free online, as there is even more that can be done in Sequencer than I could possibly cover in these course sessions. Finally, all the online resources and links to some of the tools discussed today can be found by following the URLs on this slide."},{"start":"1:07","end":"1:21","startSec":67.2,"text":"Feel free to pause here or take a screenshot for later reference. That's it for the Sequencer Animation Production Workflows course. I want to thank you for spending your time with me, and I hope that these videos were helpful as you continue working with Sequencer in Unreal Engine."}]},"205.02":{"02_CineCams":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Now, in this section, we're going to begin with a discussion about working with cinecamera actors. Starting out, we're going to look at Unreal Engine's camera basics. When working with cinecamera actors, you're generally going to find that there are two main camera actor types. The first camera actor is the cinecamera actor, which is the most common camera used in film productions or other linear content projects. The cinecamera actor was specifically built to emulate a real-world physical camera inside"},{"start":"0:30","end":"1:02","startSec":30.6,"text":"Unreal Engine. It is very similar to the other camera actor type, but with some additional cinematic film controls such as film back, lens, focus tracking, and post-process, among others. The game camera actor is the most common camera actor found in games, and because of its simplicity, this is more often used as the player's view camera. The only real control here is your field of view, and unlike the cinecamera, those extra cinematic camera controls are not available on the game camera actor."},{"start":"1:02","end":"1:38","startSec":62.9,"text":"Now there are a few ways to actually add camera actors into your levels. The first does not require an active level sequence. Simply navigate over to the Place Actors tab, select the Cinematic section, and drag the cinecamera actor into your level. One thing to note here is that when you place your cinecamera actor from this tab into your level, it is a possessable actor, and can be dragged from the outliner into any active level sequence. Another way to add cinecamera actors to any active level sequence is to click on the camera icon, and that will automatically add a spotable cinecamera actor, and once that camera is"},{"start":"1:38","end":"2:10","startSec":98.7,"text":"active in a level or through sequencer, you will have access to the camera actor details panel. The details panel has several camera settings that we want to look at, and the most notable settings are the ones for the cinecamera. Settings such as the film back presets, which allows you to select a specific type of film back, or to manually adjust your camera sensor aspect ratios, width, and height. Next are the lens settings, and it is here that you can adjust your focal length, f-stop, apply a squeeze factor that will allow you to emulate the look of an anamorphic lens,"},{"start":"2:10","end":"2:44","startSec":130.6,"text":"or adjust the diaphragm blade count. Set that lower to have a polygonal shape, or higher to create a soft, more rounded shape for your bokeh. You'll also find focus settings for the cinecamera here, that allow you to set manual focus distance, activate the debug focus plane, which is a very important tool that I will demonstrate a little later, and the focus offset. Similar to the focus settings, there are also tracking settings, such as enabling look at tracking, that we will look at more in depth in another section of this course."},{"start":"2:45","end":"3:19","startSec":165.0,"text":"Finally, there are also several post-process options connected to the cinecamera, allowing for post-process control to be added to the cinecamera directly. Last, there is one very important topic left to discuss when working with cinecamera actors in Sequencer, and that is the use of the camera cuts track. Every single cinecamera that gets added to Sequencer must be bound to the camera cuts track, which controls the active camera being viewed through the assigned camera bindings. Note, the camera binding IDs can be changed in the properties for any specified camera"},{"start":"3:19","end":"3:47","startSec":199.6,"text":"in your camera cuts track, by right-clicking on the camera cut track, and making the connections through the camera cuts track properties. Without a camera cuts track, the cameras in your level will not be active in the cinematic view, resulting in being unable to render the cinecamera. Okay, that's it for this section of working with cinecamera actors. In our next section, we will take a quick look at the camera components available to use with Sequencer."}],"03_Components":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Now, in this section of working with Cine Camera Actors, we're going to take a brief look at the other optional camera components that you might use frequently in Unreal Engine. When working with Cine Camera Actors, these three camera components can enhance your ability to work with Unreal Engine. The first being a Scene Capture Component 2D. Now, this component captures a simple snapshot of the scene from a camera and feeds it directly into a render target texture. Working with the release of Unreal Engine 5.3, Unreal Engine introduced a new component"},{"start":"0:33","end":"1:04","startSec":33.4,"text":"called the Cine Capture Component 2D. This is a plugin that is in beta, and it extends the capabilities of the Capture Component that respects the Cine Camera settings, allowing you to have color profiles such as OCIO, correct depth of field, lens distortion, and a one-to-one view of the Cine Camera captured and then applied to the render target texture. Just like the Scene Capture Component 2D, but better. The third component that you are likely to work with is the Vcam Actor."},{"start":"1:04","end":"1:30","startSec":64.6,"text":"This virtual camera component is used to transmit camera motion and control settings remotely through the Live Link plugin and companion app found on the Apple Store. Alright, that's it for this camera component section of working with Cine Camera Actors. In our next section, I'm going to walk you through a step-by-step guide that I've created for you to follow along and build a control rig for use with a Cine Camera Actor for more realistic camera animation."}],"07_Modification":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Now, in this section, we will look at modification tracks, which will serve as a precursor to what we will use in Unreal Engine to control sequencer editorial transitions. Starting out, there are two modification tracks that we are going to focus on. And the first is the level visibility tracks. Level visibility tracks can control the visibility of any level or sublevel, and is used to switch between various lighting setups or comps, different staging layouts, and effects."},{"start":"0:34","end":"1:09","startSec":34.2,"text":"Level visibility tracks can also be used in conjunction with the material parameter based transitions controlled through sequencer to create cinematic transitions like the crossfade, to achieve a perceived passage of time, create match cuts, or make location changes. One thing to note though is that if your levels are very heavy, you might see a delay as the assets load into the level. The next modification track that we are going to look at is the material parameter collection, or MPC. And in order to get deeper access to the myriad of properties a static or skeletal mesh actor"},{"start":"1:09","end":"1:41","startSec":69.1,"text":"may have, you'll want to access its mesh components. Exposing the mesh components can help you keyframe specific properties in sequencer such as an asset's material settings. Properties like material elements can be exposed and controlled transitionally and blended through sequencer. Or material switcher properties can be exposed and allow a user to switch between materials applied to the mesh through sequencer keyframes. One thing to note, the switch is an on or off option and cannot be blended like you"},{"start":"1:41","end":"2:15","startSec":101.4,"text":"can with material elements. Now let's jump into the engine and take a look at the modification tracks in action. So let's move over into the mod tracks folder and take a look what's set up for you in this folder. Inside this folder you will find two material parameter collection assets, two level sequence examples and a folder containing two more level sequences that will be used as sub-sequences to demonstrate animated action in the modification tracks examples."},{"start":"2:15","end":"2:46","startSec":135.0,"text":"The parameters collected in the MPC Car Paint will be used in the Material Parameters level sequence. But we're going to start out with the level visibility track level sequence. Double click to open the level visibility track. And then lock the camera to the cinematic viewport so that we can see what's happening within our camera. Next move over to the levels tab."},{"start":"2:46","end":"3:19","startSec":166.2,"text":"It's next to the outliner. Turn that on so that you can see the persistent level, broadcast, desert, oasis and rally sublevels. The broadcast sublevel is not going to be affected by the level visibility track. But before we play through this level sequence, let's move down to the sequencer controls and turn on playback looping. This way the desert and oasis sublevels will turn on and off as we play through our transition a few times. This will give you a chance to make sure that you can see the eyeball icon in the levels"},{"start":"3:19","end":"3:52","startSec":200.0,"text":"tab turn on or off for each sublevel. If we stop and move through the level sequence more deliberately, pay attention to what's happening in the viewport. If we move first from the desert into the active desert scene and then from the desert into the oasis scene, you will see assets appear in the sublevels as you move from section to section. Note, for any of this to work, the sublevel track requires an array to be added to the"},{"start":"3:52","end":"4:25","startSec":232.5,"text":"properties of that level visibility track and the sublevel name must be manually typed into the index field. Spelling is a factor here, so be careful to get the name exactly correct. Of the array in the visibility field, you will be able to switch between hidden and visible inside the pulldown menu. This is how you switch between each section, but each switch requires another copy of each"},{"start":"4:25","end":"4:55","startSec":265.6,"text":"of the visibility tracks themselves. You'll notice a breakpoint between these as the two tracks are turned on and off. Alright, now let's look at the material parameter collections as a modification track. First double-click to open the material parameters level sequence. This level sequence is going to use the same action subsequence track, but by adding a material"},{"start":"4:55","end":"5:29","startSec":295.7,"text":"parameter track to the level sequence from the tracks button, the material parameters have been exposed to sequencer, allowing access to the parameters to make changes that can be keyframed in sequencer. Again, by adding these tracks from the track menu in the material parameter collection and choosing the MPC car paint that we've got, we are able to keyframe these on our timeline and make changes to our transitions. In this collection, we have loaded a vector parameter. By using the plus button and choosing the vector color."},{"start":"5:29","end":"6:01","startSec":329.2,"text":"This color option exposes the RGB values and allows us to choose a 0 to 1 value to modify the car paint. As you can see the keyframes here change the value of the car paint. And as we did before, let's lock our camera to our viewport and make sure the looping is enabled in sequencer and play the level sequence. As the SUV travels through the level, you can see the keyframed car paint blend from one color to the next. If you are interested in how to create material parameter collections, there is a materials"},{"start":"6:01","end":"6:22","startSec":361.2,"text":"course that is available for this specific topic. I encourage you to check that out as you continue your Unreal Engine training. Alright, that's it for sequencer modification tracks. In our next section, we're going to take a look at using modification tracks for editorial control. Thanks for watching!"}]},"205.03":{"01_Introduction_5.1":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Hello and welcome to today's Unreal Engine Training on Sequencer using Live Link V-Cams, which we'll talk about shock creation and editing. So today we'll be talking about getting hands on with the virtual camera, we'll walk you through the setup, we'll talk about the plugins and the different hardware requirements needed and then we'll talk about the V-CAM using Live Link and the Unreal Remote 2 setup. Then we'll talk about using the interface of the Live Link and then we'll recap on Take Creation with Take Recorder and then we'll get hands on in the editor and talk"},{"start":"0:34","end":"0:42","startSec":34.4,"text":"about how you actually start setting up your shots with the Live Link V-CAM and then we'll edit everything with Sequencer to close out the course."}],"02_VirtualCamera_5.1":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Let's get started setting up our virtual camera in Unreal Engine. First thing you'll need of course is a computer running Unreal Engine. Next we'll need either an iPad Pro, which is recommended, but an iPhone X or later can also be used. And then you'll want the LiveLink Vcam app installed on your phone. This is a free app in the iOS app store. You can also download the Unreal Remote 2 app as a backup in case you run into issues here, but hopefully will have success with the Vcam app."},{"start":"0:33","end":"1:08","startSec":33.5,"text":"Over in Unreal, we'll want to enable the virtual camera plugin, which by its nature will actually activate the LiveLink and Pixel streaming plugins when you restart, but you're welcome to enable those on your own as well. Now in your actual Unreal Engine scene, you have two different choices. You can grab the Vcam actor, which is already set up to work with the Vcam app, or with your standard Cine Camera actor, say you've already got a camera with all the settings that you know you want to use, you can go ahead and add that Vcam component to get started"},{"start":"1:08","end":"1:40","startSec":68.2,"text":"in the same way. What we like about the Vcam actor is it already has the user interface that will be demonstrating setup. In either case, in order to access the details of our Vcam, we will actually have to navigate down the hierarchy of our actor down to the Vcam PS for Pixel streaming component. And this is where we will do things like set up our LiveLink subject to be our Vcam Pixel streaming session. A few of the standard setup elements once you've selected your Vcam component would be to hit"},{"start":"1:40","end":"2:12","startSec":100.7,"text":"the checkbox to enable it. If you have an active session, the LiveLink subject should automatically populate as your Pixel streaming session. And then you'll also want to hit the checkbox for lock viewport to camera to keep our Vcam session active inside of the viewport. Under output, you might already see UMG overlay populated, but this is where you could select a different user interface besides the default one that we'll be reviewing. Over on your mobile device, this is what you should see when the app boots up."},{"start":"2:12","end":"2:45","startSec":132.2,"text":"And here we are going to want to input our IPv4 address. This can be found by opening your command prompt and typing an IP config or clicking the drop down in your Pixel streaming menu in your viewport. You'll also want to make sure that in the settings for the app that you have selected Pixel streaming and not remote session. At that point, if you hit connect, you should see a connection form between your computer and your mobile device. And you should see both your viewport in Unreal Engine and your mobile device screen matching"},{"start":"2:45","end":"3:19","startSec":165.6,"text":"complete with the selected UMG. Note that it may be necessary to uncheck and recheck the is active option in the output tab in order for the app to begin tracking. And if Pixel streaming does cause you any issues, you can set up a remote session either with a Vcam app or with the Unreal Remote 2 app. Similarly, you would enter your IPv4 address here and press connect. If you have any issues, we have some troubleshooting steps. First of all, make sure the virtual camera live link plugins as well as either the Pixel"},{"start":"3:19","end":"3:53","startSec":199.4,"text":"streaming and or the remote session plugin are all enabled. Next, make sure your iOS device and computer are directly connected to each other and sure they're on the same Wi-Fi connection. Make sure you're not using a signal repeater to confirm verify that both your iOS device and computer are on the same public IP and you can do this by googling what's my IP to get your public IP address. And here's what I mentioned about using IP config in order to find your IPv4 address. If you're connected to multiple networks, make sure you're looking at the right one."},{"start":"3:53","end":"4:23","startSec":233.2,"text":"For example, if you are connected to Ethernet, look for Ethernet. And if you're connected to a wireless network, look for wireless. Next verify that both devices are on the same subnet. You will often notice a difference between something like a 192 subnet versus a 10.subnet. So make sure, for example, that both your iOS device and your computer start with, for example, 192. And lastly, just verify that you did type in the correct IPv4 address inside the iOS"},{"start":"4:23","end":"4:57","startSec":263.8,"text":"app. If you do want to explore connecting via a remote session, there might be some additional settings you have to configure in your project settings, plugins, UDP messaging. You'll want to make sure that you find that IPv4 address and a few more troubleshooting steps. Make sure only one instance of Unreal is open. Try disabling your firewall. Try whitelisting devices and checking your firewall rules. Verify that the app is on and actively capturing data. And then my last and favorite step for all things broken, just try resetting or restarting"},{"start":"4:57","end":"5:21","startSec":297.9,"text":"all devices involved and try again. If you do not have access to an iOS device, there is a third party app made by By Owls. A stripped down version similar to the Vcam plugin and it is available in the Epic Games marketplace. Just note that it is not free. Next up, we'll take a look at the virtual camera's user interface."}],"03_VCamUI_5.1":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Next, let's take a look at the user interface for the LiveLink V-CAM to better understand some of the options available to us as we start to use this interface. Now the interface will look different depending on whether you're using say an iPad or an iPhone, but the core features will be all here. So some of the elements we have available to us include the application log, kind of your standard output log in Unreal to the device system stats, which will include things"},{"start":"0:30","end":"1:01","startSec":30.5,"text":"like our aspect ratio and our bit rate and our time code. We'll see the ability to disconnect from the session and go back into our standard Unreal Engine editor. We can see our camera stats, in this case 18 millimeters, and a 16 by 9 aspect ratio also translated as 1.778. Over here we can see our aperture stats including our ISO, which is set to auto, a focal distance of 1000 meters, and an f-stop of 2.8."},{"start":"1:01","end":"1:34","startSec":61.2,"text":"The little camera icon over here will tab out to give us additional camera settings, similarly with tools over on the right side. And for 9 and 10, we have a virtual joystick system not unlike the default touch interface that you'll see when developing a mobile game. This is set up so that the left joystick will move us on the XY axis and the right joystick will be for boom and pan. We'll see this in action in the next lesson. A few other elements to take note of, we have of course our viewfinder in the middle."},{"start":"1:34","end":"2:06","startSec":94.9,"text":"We have the ability to add bookmarks if we would like to snap easily to different camera points in our bookmark manager. We have our playback controls, which will look familiar to anyone who has used the sequencer or cinematic viewport, although with the touch interface we can actually scrub our finger along here to also move forward or backward in time. 15 is our record button, very much like the take recorder. 16 shows our axis scale, more about that on the next slide, and our stabilization stats."},{"start":"2:06","end":"2:40","startSec":126.1,"text":"We can tune this up or down depending on how much camera shake we want to have. We have our tilt pan and roll degrees just to get a sense of the current rotation of our camera. And lastly over here we have the name of our slate and the sequence frame that we are currently on. More information as always can be found in the Unreal Engine documentation. Here we see some of the additional options we're presented with when we open up our camera toolbar as well as our tools toolbar. Axis scaling is very similar to the world to meters scale setup for anyone who's worked"},{"start":"2:40","end":"3:10","startSec":160.5,"text":"in virtual reality because this allows you to essentially change how your physical movement will translate from the real world into this virtual world. If you want to be able to cover a lot of ground very quickly by moving your iPad around and using the AR features to cover more territory, you can dial up the axis scale to be able to cover more ground, or if you would like more subtle movements, you can bring that down. You can also set the value to zero in order to lock and play with dialing these up or"},{"start":"3:10","end":"3:43","startSec":190.5,"text":"down with your fingers on the left and right side. So we have the axis scale on the left and the joystick movement gain, joystick rotation gain over on the right. Over here we see some of the dials that give us additional access to our camera controls. So our lens control for a lens preset on the inner dial and the focal length on the outer dial. We have the right dial allowing us to adjust our f-stop as the inner dial and our focal distance as the outer dial. And then over here we have our film back control to select any presets we might have like"},{"start":"3:43","end":"4:16","startSec":224.0,"text":"16 by 9 for example or other aspect ratios. Continuing down here we have the ability to adjust our ISO and exposure control and then we also have our f-stop out here. On the right here we have our exposure compensation so we can dial the perceived brightness of the world up and down. Here allows us to adjust our near clip plane depending on how close we want to be able to get to objects before they start to clip out of existence. A couple more key features to draw your attention to include the reposition button which basically"},{"start":"4:16","end":"4:47","startSec":256.4,"text":"allows you to lock the camera in one spot and then you can physically move in the real world without changing that position. This is great if you are restricted in your physical movement but actually want to cover a larger space. Same idea can be done with tilt. For example if you want to have a very severe Dutch angle that might be harder to achieve in the real world and you need to dial up that rotation depending on your physical movement or just get yourself in a more comfortable physical position while having a potentially"},{"start":"4:47","end":"4:55","startSec":287.2,"text":"more extreme angle. Next up we'll look at filming a shot with the Vcam and then insert that shot into an existing sequence."}],"04_HandsOn_5.1":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Hi, this is Alex Coulomb, and now we're going to take everything Pete has shown in the previous course sections and apply them to create replacement footage for our level sequence. So to get started with the VCam application in Unreal, you're going to want to make sure you have a few plugins on. One will be your virtual cam. One will be pixel streaming. And the final one will be Live Link. Once those are enabled and you've restarted, all you'll have to do is activate pixel streaming"},{"start":"0:34","end":"1:07","startSec":34.9,"text":"in the dropdown here. You can just say launch signaling server. And once that's active, you're going to want to take note of your IPv4 address there, the local one, because we'll put that into the app in a moment. We can also go ahead and just grab in our VCam actor, which you can also find under the plus virtual production and VCam actor right there. And once you have this activated, you might just want to tilt it slightly toward the person you plan on capturing, bring it up a little higher if you want to."},{"start":"1:07","end":"1:40","startSec":67.4,"text":"And then what we're going to do is go under the component for the VCam actor, the one called VCam. And under here, we're going to want to make sure this is enabled, which will activate this nice little UI. And then we can close place actors to give us a little more screen real estate and go to window virtual production live link. And we can see that right now I've got a yellow colored icon here telling me that the VCam app is detected, but it's not actually active right now."},{"start":"1:40","end":"2:12","startSec":101.0,"text":"So over on my iPhone, what I'll now do is go over to pixel streaming and again see 192.168.1.6. And I will match that over here on my iPhone. Don't worry about the port. And I'll just hit connect or go. And if it doesn't connect, make sure under settings you go and change your connection type to pixel streaming. That's key. And let's try one more time, connect. And it says it wants to use our microphone and right away we can see it spring to life."},{"start":"2:12","end":"2:48","startSec":132.6,"text":"I'm going to press OK for our tracking here. And we can see we're now matching up our viewport and what we see in editor. We've got a green light over here. I can click on the UI elements directly in my viewport or use my finger inside the browser. And I can start to actually move around my space. And I can even walk around physically to get exactly the view I want before hitting record to actually create a take. So to start here, I am just walking around just giving a sense of a one to one relationship"},{"start":"2:48","end":"3:21","startSec":168.8,"text":"between my real space and the virtual one. And up, looks like I just lost my connection there. Worth demonstrating. And if you disconnect like what just happened to me, just make sure you go back into your live link subject settings and just reconnect. And here I am just walking around again. And I just tried hitting the record button to show you that you can actually activate"},{"start":"3:21","end":"3:54","startSec":201.2,"text":"recording a take directly from the app. Short one there. We'll review that in a bit. And just demonstrating some of the wheels we have here for changing ISO and a number of other settings that will look familiar to anyone who's ever operated a camera before. Also note that we can move the camera around just using our fingers."},{"start":"3:54","end":"4:25","startSec":234.6,"text":"What registers as our right thumb will be rotation just along the Z axis. And if we manage to get our left hand into there, that starts to register as your movement on the X and Y axis. And here's what it looks like if you are too close to a wall in your real space, you just have to back up a little to find the floor again. Couple other things in here."},{"start":"4:25","end":"4:55","startSec":265.4,"text":"If we hit this, we'll actually lock our augmented reality camera if we wanted to focus more on some other manual settings or if we found a static view we want to keep. And here we are with that left and right navigation that's manual. And we're going to fly mode right now. So now we're also able to navigate on the Z axis."},{"start":"4:55","end":"5:28","startSec":296.0,"text":"And here we are just recording another take. And then we just tap that record button again when we're all done. And when you're all done recording, you can just go ahead and uncheck that enabled setting on the virtual camera. And if we'd like, we can even take a look at some of the recordings we just got. With take recorder, we can say review the last recording and lock to that camera cut view and we can see whatever we've done."},{"start":"5:28","end":"6:02","startSec":328.2,"text":"Let's take a look at a couple others over in cinematics takes today's date. And we can also see the one we made over here. And you get a nice natural handheld camera effect. So we'll see if we can use this one to replace one of the shots in our finished film. So to find that, I'll start by searching for anything called film because that's the name of these final sequences. And we'll see that there is one here in 205.03 that says V cam drop."},{"start":"6:02","end":"6:32","startSec":362.2,"text":"So I'll open up this one to actually put our V cam file inside. And so let's just review what we have in here at the moment. So we'll lock to the viewport and we see we've got our pan up. And you know what, right there, that's probably a good spot for our little shaky cam shot because feels a little bit strange to suddenly have the camera move like that. So maybe we can cut in right there. I was going to scroll through the rest and see if there's anywhere else. We might want to use our little shaky cam shot, but I like it over here."},{"start":"6:32","end":"7:04","startSec":392.4,"text":"So I'm going to double click on here and we'll see that we have a subsequence with additional shots. So I like this first shot as is. And the second one right before that camera moves, that's where I'm going to try to insert my V cam footage. Now the tricky thing is my V cam footage did not record the animation that we have for our mannequin in here. So in order to have that come in correctly, we are going to want to copy that mannequin data. So I'll just grab that whole mannequin object with its animation and do control seed."},{"start":"7:04","end":"7:37","startSec":424.6,"text":"And now I'm just going to insert my V cam shot, which as we might recall is the one that we called scene underscore one underscore O two. We could certainly give that a better name. This is fine for now. And we'll actually drop it into its own track entirely down here. If we wanted to actually overwrite what we have up here, maybe we can just snap it like that because then we can actually leave the existing shot here for the moment. And this one will be on top of it. So there's the shot. But of course you see we do not have our mannequin there."},{"start":"7:37","end":"8:15","startSec":457.7,"text":"So if we want to get our mannequin in, the easiest thing to do will now be to open up in here and to paste in our mannequin with control V. But then we get a message saying the sequences read only. So be sure to go to the upper right and unlock it and we'll try again. And then you might find that there's no animation here because of where the time scale is. We're starting in a different time code here, but that can easily be fixed by going up to here and grabbing the actual animation from here from Manny animation track."},{"start":"8:15","end":"8:49","startSec":495.7,"text":"And we will paste it manually into here. And just drag that back to the beginning. Now because of the alignment we have over here right now, we will want to make sure that we're matching that. So we'll actually snap to the beginning and you'll see that now we are aligning. So we've got the head coming up right there. And you'll see that if I were to disable this, uncheck active, we see that the hand is an exactly the same spot."},{"start":"8:49","end":"9:19","startSec":529.2,"text":"But maybe we like the beginning of what we had there. So we could kind of cut and choose where we want to keep the old animation. So maybe right before that camera starts to move, like right as the hand is coming up, that's where we use it. A little bit of confusion. And then maybe we cut it off right before that shrug. So right about here. So one more time."},{"start":"9:19","end":"9:54","startSec":559.9,"text":"Original new shaky cam, confusion, and there's a shrug. And then everything plays on as normal. So at that point, if we wanted to, we could start to clip this more. I could use my shortcut control forward slash and start to pull this apart. Or just remind myself that this is continuous and leave that on top. Depends how you want to do it. But there's our easy insert of our V cam shot into the larger sequence."},{"start":"9:54","end":"9:59","startSec":594.4,"text":"That's it for the practical application. And in the next section, Pete will review what we've done so far."}],"05_CreationAndRecorder_5.1":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Just doing a quick recap of the take creation with take recorder just to make sure you're familiar with the tool and that you have access to it in your projects. So a take recorder enables you to quickly record and iteratively create sequences inside of Unreal Engine. So takes can be created for virtual cameras, body and facial performances, you can even catch in Niagara or vehicle animation. When it comes to vehicle animation or blueprints and more, you can have in previous courses"},{"start":"0:33","end":"1:05","startSec":33.4,"text":"we referred to them as possessible actors, you could be controlling a character in a game like situation. Have take recorder enabled and be recording the movement, the running around, the jumping, whatever you might be doing. And then that bakes it down into its individual animation sequence, which can be played back. So if you want a very game, game like feel to a performance, for example, you can record that with a keyboard and mouse or gamepad and then play that back with the take recorder,"},{"start":"1:05","end":"1:37","startSec":65.6,"text":"which is a really powerful tool. It saves a lot of iteration time. And then recordings can also be taken iteratively with one or multiple actors added into a sequence. So here's a UI for the take recorder. There is documentation on the take recorder if you'd like to get a deeper look. But essentially, here's a high level of the user interface, which you can dig into. And you can pause the video if you want to really figure out what each of those options does."},{"start":"1:37","end":"2:09","startSec":97.3,"text":"Then we also have the settings here. So you can add access to the sources by dragging from the world outliner. So you can just drag and drop them into the take recorder, or you can use the source panel here up here. You can just click source from actor and then add a specific actor. Make sure to change the record type to the appropriate settings and then select play and then record in the take recorder. And then recording is displayed in real time. So when you are finished, click stop on the recording, and then that will save your animation."},{"start":"2:09","end":"2:40","startSec":129.4,"text":"So it's a pretty straightforward tool to use. Again, we've got documentation down here. A few notes as well is that take recorder allows users to specify which actor properties can be recorded. So if you've selected the meerkat as in this example, you could remove any data that you don't necessarily need. Again, it's sometimes good to record all the data that you're not sure you might need for editing later down the line. But if there's data that you just definitely don't need, sometimes it's easier to just"},{"start":"2:40","end":"3:06","startSec":160.1,"text":"disable that. So it just cleans up that sequence a little bit more and you're not dealing with as many properties. And then the last note is that you can record as many takes as you need by repeating the process or using the existing take as a basic template to combine performances into that single file and then each individual take is saved into a sub folder. So again, documentation is there if you'd like a deeper dive on the take recorder."}],"06_EditingSequencer_5.1":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Now that we've got our performance captured and we understand the whole pipeline of using the virtual camera, let's talk about how to edit our sequences within Sequencer. So a Sequencer allows for the trimming, editing and manipulation of keyframes and animation curves captured within the take recorder. So again, we've got all this data now captured from the live performance. And now we can go in here and clean it up. So anything from the virtual camera moves to a rig inversion animation derived from"},{"start":"0:32","end":"1:07","startSec":33.0,"text":"recorded performance capture data. So the performance capture takes control rig animations, virtual camera movement, live folly, anything that you added to the take recorder essentially will all be visible within here and allows you to really dial in on the specific keys. And you can open the curve editor as well using this button here. So that opens your curve editor, which is this larger window if you really want to dial in some of these keys. And then you can also finalize the recordings with the Sequencer editorial tools."},{"start":"1:07","end":"1:39","startSec":67.3,"text":"So edit the recorded takes with the curve editor, save the takes as a new level sequence, and then the level sequences can be added as sub-scene tracks which we touched upon in previous courses. There's documentation on the sub-scene tracks if you're unsure what they are and it allows you to set camera binding ID in the camera cuts. We can create sub-scene tracks in Sequencer. We can add the V cam track in the timeline and then also adjust the shot duration for the final edit. So all of these can be edited within Sequencer."}],"07_ThankYou_5.1":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"And that brings us to the end of this course today. Hopefully you learned a lot of information about V-Cams and how to set them up. It was a little bit heavy with the technical setup at the start. It's a very kind of step-by-step methodical processor. Hopefully once you've got it set up, you're kind of familiar with what everything does and then the settings don't change too much so you can just next time jump straight into using virtual camera. Without your scenes, use the different app functionalities to really help navigate and"},{"start":"0:32","end":"0:54","startSec":32.9,"text":"scout the locations that you want to use. And then when you actually start beginning the recording using take recorder or any other powerful features of Unreal Engine, it allows you to really quickly record and iterate and dial in those performances and then get them rendered out in sequencer. So hopefully you learned a lot today and we'll see you on the next course."}]},"205.04":{"01_Overview":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Hello and welcome to today's Unreal Engine training on Sequencer with Performance Capture and Take Recorder. So today we're going to be covering what Take Recorder is and how you can use it. We'll talk about some of the features that you can utilize when working with Take Recorder. I will also talk about Active Performance Recording and then dig into how you might capture a vehicle performance, a Live Link Face setup and then talk about MetaHuman Layered Facial Performance Capture. And then we'll talk about how to edit the capture data within Sequencer."},{"start":"0:33","end":"0:34","startSec":33.3,"text":"So let's jump in."}],"02_TakeRecorder":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"We'll start off by looking at take recorder. So take recorder essentially enables you to record quickly and iteratively inside of Unreal Engine. So you can easily record animations from motion capture linked to characters in the level. You can see these two meerkats here. We can record their performances and grab the animations from those performances. And then you can also use live link data for future playback. So recording the takes and adding them into Sequencer, which you can see at the bottom here."},{"start":"0:32","end":"1:02","startSec":32.0,"text":"It allows for productions of all sizes and any number of takes can be accommodated. So it's a really great tool, especially when working in larger teams. And we'll dig into some of those workflows as we go here. So we can actually find our take recorder window. If we go to the window button in the top of the editor. And if you're using more recent versions when Unreal Engine, I believe 5.1 or later, you can actually just type in the take recorder and it should filter through the available windows and find take recorder."},{"start":"1:02","end":"1:39","startSec":62.0,"text":"Alternatively, you can browse through the submenus and find take recorder there. But essentially the interface, once you have it pinned to your editor somewhere, you can see we have 10 key areas to look at here. So we've got the create new take button, pretty self-explanatory there. And then you can also review a previous recording or even start a new recording using that take as a base. So you can kind of layer up the take recording, as we mentioned in the previous slide. You can also show and hide the take browser, the level sequence and also the take recorder project settings up at the top right there."},{"start":"1:39","end":"2:13","startSec":99.0,"text":"And then we can also with the big red button there, record the take that we wanted to capture. We have some timestamp and frame rate information displayed to make sure you're aligned correctly with what you're capturing. And then we also have the various sources for recording. I'll talk about how to add sources to the recording in a short while here. But you can see that we've added two meerkats in this example so that when we press record, any kind of performance data they're presenting to the end user in real time, that will all be captured,"},{"start":"2:13","end":"2:46","startSec":133.0,"text":"which then can be played back offline. Then we have in section nine, we can add a little description for our take, especially when you're working with multiple takes. This can be very useful to add some descriptors there. And of course, in a similar vein, number 10 allows you to edit the slate take name and number to make sure all the takes are being organized correctly. You can find some additional resources at the link at the bottom of the page here, which will dig into any additional information you might need to know about take recorder."},{"start":"2:46","end":"3:18","startSec":166.0,"text":"So as we said, the most common usage of take recorder will be projects using Live Link. So because take recorder enables you to quickly record performances using Live Link, it's an easy way to update and iterate on previous takes. So you can see that this is how we might add the various actors to the performance. You can either click on the source here and from actor and then it'll allow you to select any actors that are currently in the in the world map to this take recorder."},{"start":"3:18","end":"3:48","startSec":198.0,"text":"You can also drag and drop from the world outline panel in your editor. You just drag and drop them into this actor area here and it'll add them there. And then you also just need to make sure you update the take recorder record type to the appropriate settings. So you can edit a certain amount of properties here. So you can see that we have this meerkat selected and we say, OK, how do we want to record? Do we want to reduce any key information? Do we want to record parent hierarchy?"},{"start":"3:48","end":"4:20","startSec":228.0,"text":"But then also we have tracks that are specific to this actor type. So in this instance, it's the blueprint meerkat. So do you want to record whether it's hidden or not hidden? Do you want to record any attached tracks, transform tracks, things like this? Essentially, you can capture all the data and even if you don't feel like you need it right now, you can use it later today. Now, the flip side to that little caveat to add is that you don't want to record too much data that the data becomes overwhelming."},{"start":"4:21","end":"4:53","startSec":261.0,"text":"So if it's just content that you may just never end up needing, you can go ahead and untick that and it won't capture those properties. However, it's always good to have some information to work with. So as we said, we can layer up multiple takes and so you can record as many takes as you need by repeating the process or using existing take as a base, as we showed in the UI section just on the previous slide. So you can see a few settings that you may want to look at and dial in."},{"start":"4:53","end":"5:30","startSec":293.0,"text":"You can even change things like the countdown time. So if a three second countdown is a little bit too short or maybe too long, you can adjust that to your preference. And of course, we've got the additional resources at the bottom there for you to dig into further properties. The way we might start thinking about capturing both cameras and actor performances is through the use of some external hardware. So you could use cine cameras, which can be genlocked to the editor and you can record directly through the cine camera via pixel streaming is also a possibility if you're using an iPad."},{"start":"5:30","end":"6:06","startSec":330.0,"text":"So if you want a slightly lower cost, more low cost solution, you can download the virtual camera app to the iPad. It is a free app supported by Epic on the App Store. Alternatively, there is a paid app on the marketplace for an Android capture app. So just check what kind of motion recording setups you prefer. It's going to depend on the project size and scale. But needless to say, there's a multitude of performance capture and camera motion recording options available."},{"start":"6:06","end":"6:27","startSec":366.0,"text":"Then we also have some actor performance recording. Maybe you want to use something like Xsense or some other kind of performance capture setup. There's a few different options on the market there. And again, it depends on the budget and the scalability of the project, what you're trying to achieve, depending on what approach you decide to take there."}],"03_WorkingWithTakeRecorder":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Let's now look at how Teams may work with Take Recorder. So as we mentioned in the opening slides, you'll capture this Take Recorder content and use it via Sequencer. Now, Sequencer has some great sub scene tools to use. So we can see that there's various tracks as a sub scene within the master sequence. So we can hold a sequence with all our shot information at the top there. And then also the sub scene tracks,"},{"start":"0:32","end":"1:02","startSec":32.0,"text":"you can almost think about them as layers and maybe a DCC app. You can see that different departments can then work and organize depending on what is actually happening in the scene. So you can see that we split the sub scenes into character animation, effects, cameras, lighting, sound. But again, that's going to be dependent on the size of your project and what departments you have. And then we can also say within this animation track,"},{"start":"1:02","end":"1:35","startSec":62.5,"text":"for example, we have multiple animators or multiple character performances that we want to keep isolated. So you can see that we have a meerkat, an eagle and an egg sub scene as well. So you can nest them within each sub scene as well. So you can get as granular as you want here. You don't want to get overly complex unnecessarily and be unable to find the information, but needless to say, using sub scene tracks can help you quickly organize and break down workflows between departments there."},{"start":"1:35","end":"2:08","startSec":95.6,"text":"It's also worth noting that you can record microphone inputs into the tape recorder and therefore be able to edit the audio within Sequencer. So using audio gain multiplies the incoming audio power. So gain can make it a blow out if the gain is too high and the audio is too low, loud, sorry. But the most important feature is the ability to split stereo channels into separate tracks for later editing. So it's good for two person conversations. You can also include more than one input."},{"start":"2:08","end":"2:19","startSec":128.7,"text":"So if you need to record any kind of audio information whilst doing your takes, then that is also an option through the source inside the tape recorder."}],"04_VehiclePerformanceCapture":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Let's now get into a few practical examples of how you can use Tick Recorder within your project. So we'll look at some vehicle performance capture first. So for this example, we're using the vehicle template map. You can see that there's an SUV vehicle in the scene, which is the BP SUV, which you can drag and drop into the level here. You need some kind of input device. I assume you have some kind of keyboard and mouse attached, but if you're working on,"},{"start":"0:33","end":"1:07","startSec":33.8,"text":"say, a mobile device at the moment, just make sure you have some kind of external peripherals plugged in that allow you to control this car. So maybe you have some kind of game controller plugged in as well. That would also be fine. So when we drag and drop in the car, we can add the SUV to the source here. Again, you could either click on source and select the BP SUV. Or as we previously said, you can drag and drop from the world outliner to get the SUV in there. And you can decide what vehicle data you're recording based on the record properties that"},{"start":"1:07","end":"1:38","startSec":67.5,"text":"are listed. So we have seven different options that you might want to look at there. Then it's mainly a case of hit and record. Once you have your Tick Recorder open, again, we have this big red button that we can hit record. The countdown will play. If you change the countdown settings, maybe it'll go from a different number, but you'll essentially get a three, two, one. Then you'll just be able to drive around, capture whatever information you want and then hit stop. And then the take will save and then you'll be able to open it within Sequencer."},{"start":"1:38","end":"2:10","startSec":98.0,"text":"So when you have this recording saved, again, dependent on your naming conventions, as we talked about with the Tick Recorder settings, you'll find your sequence nested within whatever parameters you set within the content browser. So therefore we can locate this and load up the performance data. So once we've loaded the sequence, you can see that we've got our SUV here. And then if we want to use this as an animation for later in the project, we just want to"},{"start":"2:10","end":"2:41","startSec":130.8,"text":"zero out any transforms inside this capture data as the vehicle uses root motion animation. So the skeletal mesh will move away from the root location. So if you want to follow the vehicle, you can select the mesh in the viewport. From the details panel here, you can see that we've got the BP. You can select the vehicle mesh component, hit F to focus on the SUV, which F on the keyboard is a shortcut to focus."},{"start":"2:41","end":"3:09","startSec":161.7,"text":"And then you'll be able to track that vehicle within your recorded data. But essentially that's how you would capture vehicle. Nice, straightforward. Just have a play around with the various setups and especially with the information that you may want to record within that sequence. Because again, it will give you a lot of power, especially in post if you're trying to add certain elements or effects, for example. They've all been captured live for use later on."}],"05_LiveLinkFaceSetup":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Next, we'll look at how to set up our Live Link facial performance inside of Unreal Engine. So to get started, we need a couple of things first. We need to make sure that we have a computer that is running Unreal Engine. If you have Unreal Engine 4.25 or later, the plugins will become automatically active. However, you might need to go in and enable the plugins which we'll touch upon in a second. You also need some kind of iOS device on either iPhone X or later, or an iPad Pro and later,"},{"start":"0:34","end":"1:04","startSec":34.3,"text":"so that we can have this Live Link functionality. And we've got a link to the documentation if you need to understand how to set up blend shapes for the different characters produced by the ARKit's facial recognition there. So we've essentially got five plugins that we want to enable here. If you're unsure where to find plugins, just go to Edit at the top of your editor, go down to the Plugins box, and you can type in in this search box the plugins that you're looking for."},{"start":"1:04","end":"1:36","startSec":64.4,"text":"So first of all, type in Live Link. We want to just enable these three Live Link plugins. Once you start enabling one plugin, it'll ask you if you want to restart your editor. Don't restart it just yet. Just make sure you enable all the plugins first and then restart your editor. So we've got three Live Link plugins and then we've got these two ARKit and the ARKit Face support here. So let's just enable all of these plugins. Then it'll ask you to restart your editor, hit Yes, and then after the restart,"},{"start":"1:36","end":"2:10","startSec":96.3,"text":"all the plugins will automatically be enabled. You could sanity check this and just double check that you've ticked all the right ones after the restart, but just make sure these plugins are loaded before you continue. The next few steps are a little bit more complicated. Just make sure you take your time in this section, go step by step, maybe refamiliarize yourself with the information. We've got a few pages of debugging as well after this section, if things aren't connecting correctly, but essentially you just need to get your computer talking to your iOS device."},{"start":"2:10","end":"2:44","startSec":130.3,"text":"So we need to figure out how to get Live Link connected between our iOS device and the computer. So we can go to the project settings, so go edit project settings in your editor, and then we've got this UDP messaging section. We want to look up the computer Unicast endpoint here and find that, and this will be used as a subject target in a second here. So the Unicast endpoint is the number that we're looking for here. Now we want to launch Live Link Face app on our iOS device."},{"start":"2:44","end":"3:17","startSec":164.7,"text":"We want to then tap the gear icon to open the settings and tap the Live Link settings option and then add the target here, the IPv4 address to the targets, the IPv4 address that we just found. I'll show you how to grab that in a second here if you're unsure how to find your computer's local IPv4 address, but that's essentially what we want. And then the Live Link Face calibration, we want to tap the calibration settings, enable calibration and countdown,"},{"start":"3:17","end":"3:50","startSec":197.6,"text":"and then the calibration icon will appear on the screen there. Now back over in Unreal Engine, we'll need to open our Live Link window. So again, we can go to Windows, Live Link. I believe Live Link is inside the virtual production sub tab there, but again, if you are using a more recent version of Unreal Engine, you can just type out Live Link and it'll open up that window and then you can pin it to your editor somewhere. And then we want to select the source subject as the iOS device, which is this section here. So this should automatically"},{"start":"3:50","end":"4:22","startSec":230.3,"text":"be detected. If you're not getting this green light, you could just hold on a second to check out some debugging tips in a second, or you could repeat the previous step. But at this point, we need to be able to see this green light happening here. And then if we have, say, in this example, we're going to use a MetaHuman for the facial performance. So we've got our MetaHuman in the level here, locate the default tab in the details panels, which you can see here"},{"start":"4:22","end":"4:56","startSec":262.2,"text":"in the default section, select your Live Link face subject, which is the iOS device, and then check on the Live Link face head for rotation. So you can use PlanEdit to view facial performances out of the box here. And then at this stage, it's probably useful for us to get familiar with the interface of the Live Link app setup. So in a similar fashion to how we did the take recorder, we've got an option here to open the settings dialog. We've got an option here"},{"start":"4:56","end":"5:27","startSec":296.7,"text":"that toggles sending facial animation data to all Live Link targets. And then in number three, we've got a toggle for the video display, the facial tracking on and off. Again, we've got a nice big red button which starts and stops the recording. In number five, we've got open a list of all takes previously recorded by the app. Number six is showing the current slate and take, similar to how take recorder operated here. And then number seven basically just displays,"},{"start":"5:27","end":"6:00","startSec":327.2,"text":"essentially indicates that the app can detect your face and capture everything correctly. So again, we've got some great documentation, which is well worth a read, how to approach facial recordings in Unreal Engine, which is worth a read as you're doing this. So as promised, we've got a couple of slides here for some debugging information, just to see if things weren't connecting with Live Link correctly, how you might go about fixing this. So as we stated at the top here, we just want to make sure that the plugins are"},{"start":"6:00","end":"6:31","startSec":360.8,"text":"enabled. Just go ahead and double check that plugins are enabled correctly. Restart your editor as well when you're enabling plugins, you want to make sure that the iOS device and computer are directly connected, which means no signal repeaters as well. And we want to verify both iOS device and computer IPv4 addresses connected. So you can either find out your IP by going on What's My IP, which is a URL that you can follow, or opening the command prompt in Windows, you can"},{"start":"6:31","end":"7:07","startSec":391.8,"text":"type in IP config. And that will give you your IPv4 address at the bottom here, which you can see located there. We want to verify our own the same subnet and also verify computer IPv4 addresses in the settings of the Live Link face app. So just make sure those two addresses match. The static endpoint port number is optional. So you could try if you still have an issues to add that port number, but it is completely optional. And then we also want to check in the UDP messaging section."},{"start":"7:08","end":"7:38","startSec":428.8,"text":"We want to add UDP messaging for stability here, and then verify a single instance of Unreal is active. Then we want to just make sure our firewall is disabled here. Check any whitelist devices and incoming rules, and also verify that the app is on and actively capturing data. If all else fails, reset or restart all devices and just try again. The UDP messaging is located in the plugin section of the Unreal Engine project settings, as we said before. And here"},{"start":"7:38","end":"7:52","startSec":459.0,"text":"is some information on the different endpoints of what you might be looking for if devices aren't connecting correctly."}],"06_LayeredFacialPerformanceCapture":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"Let's now look at how we might capture some layered facial performances. So if you familiarize yourself with the animation blueprint of the MetaHuman, so we're in the FaceAnimBP here that you can see is loaded, we can actually make a couple of additions that allow a bit more user-friendly for when we're working inside of Unreal Engine. So the first thing we want to do here, and we'll get closer into these details here in a second, but just to give you an overview, the first thing we want to do is add the weighted"},{"start":"0:35","end":"1:06","startSec":35.6,"text":"moving average with an alpha node to act as a denoiser. And the second thing we'll do is that we'll add in a layered switch for selecting the driving animation. So if we look at the first setup here, we want to add the weighted moving average. So all we need to do is promote the alpha, which you can see here, so just drag your cursor from the green pin and drag it out and then let go. And then you want to create a variable."},{"start":"1:06","end":"1:39","startSec":66.0,"text":"In this instance, we called it WMA alpha, but essentially you can rename it to whatever you'd like. You just want to make sure you compile your blueprint. Once you've created a new variable, make sure you save it. And then the default value here is going to be 0.8. So just compile and save. And then we have that alpha setup there. And then we also want to make sure that we have the switch setup to switch between the live link face data and also the body animation in the neck."},{"start":"1:39","end":"2:10","startSec":99.3,"text":"So this will allow us to alter the neck performance if we want to with the metahuman. So essentially we begin by duplicating the layer blend per bone, body pose and use cache body pose. So you can see that we've got that duplicated there. We want to rename the new body pose to face pose and then connect it to the open modify curve in teeth controls. I appreciate it. Just listen to my voice. It's going to be a little bit difficult to follow here."},{"start":"2:10","end":"2:44","startSec":130.2,"text":"Essentially we're just copying what we can see in the box here. So in the layer blend per bone, we want to drag out from the blend pose 0 and create the use cache pose, which is a face pose, and then duplicate that. And then we just want to repeat the connections from the original layer blend per bone node in the duplicated node. So then we want to create a blend node, promote it to the alpha and to a variable and name it llface, a live link face or anim neck switch. And then we want to connect the original layer blend per bone nodes to the blend node, which"},{"start":"2:44","end":"3:15","startSec":164.3,"text":"is the original to A and then duplicate to B. And then we just want to connect the blend node to the local component node in the AR kit. And then once you've done all that, we can compile and save. And then if we switch over to the event graph in this face and in BP, we can essentially create an update here to the editor switch, which will allow us to preview the facial performance without having to simulate the meta human, which is really nice update here."},{"start":"3:15","end":"3:46","startSec":195.3,"text":"So if we create update in editor as a bull, so you can see we've created a new bull here that's called update in editor. And if you just drag it out and select the get option, we'll create a get version of this variable. A little shortcut there is if you hold down control on your keyboard and left mouse drag from the bull into the graph, it will automatically create a get. And if you hold alt and left mouse drag from your variable into the event graph, you will"},{"start":"3:46","end":"4:20","startSec":226.2,"text":"create a set variable. So in case you want to speed up that process, that's a little shortcut for you. So essentially, after creating this get node, we want to create a set update animation in editor. So first of all, we want to right click and create a get owning component, drag off that and then type in set update animation in editor. And then you'll be able to create that. And then we just want to create a branch from this bull, go in from the blueprint update animation, check that bull, connect the bull into the update state as well."},{"start":"4:20","end":"4:52","startSec":261.0,"text":"True will go into the update state and then false will return into the branch that was already created in the set ARKit head rotation. And then still in the event graph, we want to go to the end of the chain and find this ARKit set up here. And we want to copy this and then we want to move into our construction script that you can see here on the right. So we'll copy this, paste this or control C from the event graph, control V into the construction script."},{"start":"4:52","end":"5:24","startSec":292.1,"text":"And then at the end of the construction, after the create a dynamic material instance, you can plug that ARKit set up in there and then just plug that into the same node that we were outputting the retarget set up there. So we've just inserted this into the construction script. And then lastly here, we want to go into the function, which is ARKit set up. So that's what we're looking for. You can find the functions on the left hand side of the blueprint. So again, we want to create the update and editor a bullion if we haven't already got"},{"start":"5:24","end":"5:54","startSec":324.3,"text":"one to then create a get into a set. And we can drag in from the CAS to face anim blueprints. So drag off there, we can create a as face anim BP pin searching for the set update and editor. And this creates a set update and editor node with a connected target. And then also connect the get update and editor and set li-link face head to the set update"},{"start":"5:54","end":"6:25","startSec":354.8,"text":"and editor. And then you can compile and save. And that is your complete setup for just modifying the MetaHuman blueprint for a little bit more quality of life settings available to you inside the editor. And then to get everything recorded, we'll use the take recorder again, or you can add the MetaHuman blueprint actor to the source as you've done previously. You can uncheck the MetaHuman BP actor recorded properties here, and then only check back"},{"start":"6:25","end":"6:36","startSec":385.1,"text":"on the face recorded properties, the animation track and the transform track. And that will give you the facial capture information you need for the performance."}],"06_LayeredFacialPerformanceCapture_500_v2":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"Let's now look at how we might capture some layered facial performances. So if you familiarize yourself with the animation blueprint of the MetaHuman, so we're in the face and in BP here that you can see is loaded, we can actually make a couple of additions that allow a bit more user-friendly for when we're working inside of Unreal Engine. So the first thing we want to do here, and we'll get closer into these details here in a second, but just to give you an overview, the first thing we want to do is add the weighted"},{"start":"0:35","end":"1:06","startSec":35.6,"text":"moving average with an alpha node to act as a denoiser. And the second thing we'll do is that we'll add in a layered switch for selecting the driving animation. So if we look at the first setup here, we want to add the weighted moving average. So all we need to do is promote the alpha, which you can see here. So just drag your cursor from the green pin and drag it out and then let go. And then you want to create a variable."},{"start":"1:06","end":"1:39","startSec":66.1,"text":"In this instance, we called it WMA alpha, but essentially you can rename it to whatever you'd like. You just want to make sure you compile your blueprint. Once you've created a new variable, make sure you save it. And then the default value here is going to be 0.8. So just compile and save. And then we have that alpha setup there. And then we also want to make sure that we have the switch set up to switch between the live link face data and also the body animation in the neck."},{"start":"1:39","end":"2:10","startSec":99.3,"text":"So this will allow us to alter the neck performance if we want to with the metahuman. So essentially we begin by duplicating the layer blend per bone, body pose and use cache body pose. So you can see that we've got that duplicated there. We want to rename the new body pose to face pose and then connect it to the open modify curve in teeth controls. I appreciate it. Just listen to my voice. It's going to be a little bit difficult to follow here."},{"start":"2:10","end":"2:44","startSec":130.2,"text":"Essentially we're just copying what we can see in the box here. So in the layer blend per bone, we want to drag out from the blend pose 0 and create the use cache pose, which is a face pose, and then duplicate that. And then we just want to repeat the connections from the original layered blend per bone node in the duplicated node. So then we want to create a blend node, promote it to the alpha and to a variable and name it LLFace, a live link face or anim neck switch. And then we want to connect the original layered blend per bone nodes to the blend node, which"},{"start":"2:44","end":"3:15","startSec":164.3,"text":"is the original to A and then duplicate to B. And then we just want to connect the blend node to the local component node in the AR kit. And then once you've done all that, we can compile and save. And then if we switch over to the event graph in this face and in BP, we can essentially create an update here to the editor switch, which will allow us to preview the facial performance without having to simulate the meta human, which is really nice update here."},{"start":"3:15","end":"3:46","startSec":195.3,"text":"So if we create an update in editor as a bull, so you can see we've created a new bull here that's called update in editor. And if you just drag it out and select the get option, we'll create a get version of this variable. A little shortcut there is if you hold down control on your keyboard and left mouse drag from the bull into the graph, it will automatically create a get. And if you hold alt and left mouse drag from your variable into the event graph, you will"},{"start":"3:46","end":"4:21","startSec":226.2,"text":"create a set variable. So in case you want to speed up that process, that's a little shortcut for you. So we essentially, after creating this get node, we want to create a set update animation in editor. So first of all, we want to right click and create a get owning component, drag off that and then type in set update animation in editor, and then you'll be able to create that. And then we just want to create a branch from this bull, go in from the blueprint update animation, check that bull, connect the bull into the update state as well."},{"start":"4:21","end":"4:52","startSec":261.2,"text":"We will go into the update state and then false will return into the branch that was already created in the set ARKit head rotation. And then still in the event graph, we want to go to the end of the chain and find this ARKit set up here. And we want to copy this. And then we want to move into our construction script that you can see here on the right. So we'll copy this, paste this or control C from the event graph, control V into the construction script."},{"start":"4:52","end":"5:25","startSec":292.1,"text":"And then at the end of the construction, after the create a dynamic material instance, you can plug that ARKit set up in there and then just plug that into the same node that we were outputting the retarget set up there. So we've just inserted this into the construction script. Here it's important to note that we're looking at the event graph on the left hand side here and then the construction scripts on the right hand side. So first we want to locate the ARKit set up node at the terminus of the event graph"},{"start":"5:25","end":"5:57","startSec":325.3,"text":"here, which is the image that you can see here on the left hand side. And then we want to copy the set up node. So we can hit control C to copy it. And then in the construction script, so switching over to this tab here, you can then paste it. So that's control V to paste the ARKit set up node. And then you just want to connect it to the create dynamic material instance node that you can see here. So we go from the output of the material instance and then into the retarget set up to complete"},{"start":"5:57","end":"6:32","startSec":357.5,"text":"the set up. And then lastly here, we want to go into the function, which is ARKit set up. So that's what we're looking for. You can find the functions on the left hand side of the blueprint. So again, we want to create the update and editor a Boolean if we haven't already got to then create a get into a set and we can drag in from the cast to face on in blueprints. So drag off there, we can create a as face anim BP pin searching for the set update and"},{"start":"6:32","end":"7:07","startSec":392.6,"text":"editor and this creates a set update and editor node with a connected target and then also connect the get update and editor and set live link face head to the set update and editor. And then you can compile and save and that is your complete set up for just modifying the meta human blueprint for a little bit more quality of life settings available to you inside the editor. And then to get everything recorded, we'll use the take recorder again, or you can add the meta human blueprint actor to the source as you've done previously."},{"start":"7:07","end":"7:24","startSec":427.7,"text":"You can uncheck the meta human BP actor recorded properties here and then only check back on the face recorded properties, the animation track and the transform track and that will give you the facial capture information you need for the performance."}],"07_EditingSequencer":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"And then lastly, before we close out here, let's talk about how we might look at editing this in Sequencer. So you can see that we've got our curve editor open in the top here. You can find your curve editor by clicking this little curve button here. Maybe you want to maximize the window to see all the curves. It's also worth noting you can save multiple editor layouts depending on the task. So you could set up these windows for a certain type of task and then save a different layout"},{"start":"0:30","end":"1:01","startSec":30.6,"text":"for maybe when you're editing content within an environment. So this is a setup that we'll use to display the curves and also the Sequencer on the bottom. So essentially, Sequencer allows for the trimming, editing, and manipulation of keyframes and animation curves captured with Take Recorder. So anything from the virtual camera, which we saw an example of previously, where we're using Live Link to capture virtual camera data, it moves to rig inversion animation"},{"start":"1:01","end":"1:32","startSec":61.2,"text":"derived from recorded performance capture data. And then the performance capture takes the control rig animations, the virtual camera movement, the live foley, and other Take Recorder assets can all be edited and layered together in-engine with the use of the Sequencer tools such as the Curve Editor. So we can really dial in from the captured performances exactly now what we want to create almost like we're creating it in post, but we have access to all the preserved keys to"},{"start":"1:32","end":"2:11","startSec":92.2,"text":"manipulate any content that we need to. And especially with all the recorded tracks that we captured in the Take Recorder, we have access to all the extra data there. And then we can finalize recordings in the Sequencer editorial tools. There's plenty of documentation on Sequencer if you want to get familiar with how you might operate inside of Sequencer and how to set up shots. But essentially, you can save the takes as a new level sequence, and then the level sequence can be your sub-scene tracks. So we can set the camera binding ID in the camera cuts. So you can"},{"start":"2:11","end":"2:45","startSec":131.8,"text":"see in the properties here, we can find the camera binding, we can create sub-scene tracks in Sequencer, and we can add a V-cam track into the timeline and adjust the shot for a final edit. You can either move around the shot durations in the timeline here, or you can even say about a section, a range, end, and start. So plenty of options with Sequencer to really dial in the performances that you've captured. And there's other courses recorded for you to look at with"},{"start":"2:45","end":"2:48","startSec":165.6,"text":"Sequencer. And also you can find some great documentation."}],"08_ThankYou":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Which brings us to the close of this course today with talking about performance capture with take recorder. So we covered a lot of ground here today. We talked about the take recorder and the different features and functions, and then set up a few examples, whether it be through the vehicle performance, just setting up facial capture support and even working with meta humans inside of Unreal Engine, and then discussing how you might utilize sequencer and tie all these elements together. So hopefully you found that useful and interesting today. So thank you again for watching and we'll see you in the next video."}]},"206.01":{"01_Intro":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Hello everyone and welcome to this session on Datasmith Automation. My name is Amer Yassine and I will be your guide today. Our agenda will review some general aspects of Datasmith Ingestion, and why it's important to clean up incoming data before ingesting it into the engine. We will then explore ways to automate repetitive tasks using two different approaches, one through Python scripting examples, and another by using a tool called Visual Data Prep, which will be the focus of this session."},{"start":"0:33","end":"0:50","startSec":33.4,"text":"To feel comfortable following this class, you should have some knowledge of Datasmith Ingestion techniques, and a working knowledge of CAD or Digital Content Creation applications in order to build the data you wish to import into Unreal Engine. And so, if you're ready, let's start."}],"02_DS-Review":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"First, let's review why you need data preparation. Unlike when you're working in games where you build assets one at a time, when your goal is construction or manufacturing, it often means that your project or design is most likely already fully assembled and arranged in a certain way. In that respect, you may have hundreds or thousands of objects already set up that you need to import into Unreal in a meaningful way, preserving hierarchies and pivot points. This is where Datasmith excels."},{"start":"0:33","end":"1:03","startSec":33.9,"text":"Your existing pipeline may include DCC software that require a dedicated plugin to export to Datasmith, which you can download from the Unreal Engine website. If you are using CAD applications like Solidworks or KTIA to name a couple, then these files will be read natively by Datasmith and you do not need to convert them. Let's look at importing a Datasmith file into Unreal Engine to get a feel for that procedure, and then we'll talk about how the information is processed."},{"start":"1:04","end":"1:37","startSec":64.0,"text":"By this time, you should have downloaded and extracted the project files that have been provided to you. Find the project named VisualDataPrep.vueProject and launch it. It opens in Unreal Engine and the Content Browser has a set of subfolders in it. We'll take a quick look at basic Datasmith ingestion and then proceed to learn about automation. Start a new level. Create a folder in the Content Browser named Tutorial, which we'll use as a working folder."},{"start":"1:39","end":"2:12","startSec":99.5,"text":"To import a Datasmith file, use the Add to Project button on the main toolbar and the Import Datasmith File option. Keep in mind the Datasmith menu section may or may not be available by default based on the template you chose to start the project. If the option doesn't appear, then you need to enable one or more Datasmith plugins in the Plugins dialog. Using Datasmith File Import, browse to select the file gocard.3dm under the project's Assets-Ryno subfolder."},{"start":"2:13","end":"2:47","startSec":133.3,"text":"For a location to store the file, select the tutorial folder you just created and click OK. Next, you are asked to select the type of information you wish to import. This file has no lights, cameras or animations in it, so you can disable these options. You can also adjust tessellation options in this dialog to control the conversion of nerve surfaces into triangulated geometry, but this affects all imported parts globally. Leave these to their default settings. Later, you'll learn ways to use them on selected parts."},{"start":"2:47","end":"3:20","startSec":167.9,"text":"Click Import to bring the model in. Reset the position of the floor to drop it a notch. You might also consider moving the SunSky system to see better. The information is now inside of Unreal Engine and neatly organized in folders in the Content Browser. Note the little stars on the thumbnail, an indication that even though it was imported, the data is not saved yet."},{"start":"3:21","end":"3:59","startSec":201.6,"text":"Click the Save All button in the Content Browser to remedy that. If your level is not saved yet, you'll be asked to give it a name. Call it My Cart and save it to the Tutorial Working folder. The data is now in the engine and you can start adjusting it. For example, you could consider re-tessellating a few parts that look rough when seen up close. Set the camera speed appropriately and investigate the tires, wheels and tubular chassis parts, or the steering wheel for that matter."},{"start":"4:00","end":"4:30","startSec":240.4,"text":"You'll notice they could use a little help. You can also temporarily switch to wireframe mode to better see the problem areas. Let's test the wheels. Their instances are based on a single Static Mesh, as you can see here in the Content Browser. Double-click the wheel or rim Static Mesh to open it in the Static Mesh Editor."},{"start":"4:30","end":"5:02","startSec":270.7,"text":"To view the topology, a classic trick is to enable Complex Collision mode. To re-tessellate this part, use the Re-Tessellate action from the Asset menu. Expand the panel and you can adjust the values to adjust the detail. Try a Core Tolerance of 0.05, a Maximum Edge Length of 2 and leave the Normal Tolerance to 20."},{"start":"5:02","end":"5:35","startSec":302.5,"text":"These parameters are covered in more detail in the Basic Datasmith Ingestion class. Click Tessellate to bring about the necessary changes to the Static Mesh, which now looks much more detailed. Save the information and close the Static Mesh Editor. The wheels now look much better, but of course, you'd need to do this for every other part of the go-kart that needs it, like the tires, the jagged looking tubes that make the chassis, the steering wheel and so on."},{"start":"5:35","end":"6:08","startSec":335.8,"text":"Of course, if the goal was to use the same tessellation values for all meshes, then you could have done that at import time, that process would have been global. But if you're planning different tessellation values for different meshes or groups of meshes, then you'd need to deal with those individually in the Static Mesh Editor. Also, you would need to consider creating LODs for the various parts, and that is also done usually one Static Mesh at a time. And that would require another trip to the Static Mesh Editor to set LODs manually or by LOD group."},{"start":"6:09","end":"6:39","startSec":369.2,"text":"None of it is hard per se, just time consuming, especially if you have too many Static Meshes. Finally, you may need to consider replacing incoming materials with better ones that you may have already in your PBR library. Again, not a hard task but one that could take time. In this case, it is easy enough to select all the chassis parts that are neatly organized in the Outliner, and replace their materials in one sweep."},{"start":"6:41","end":"7:11","startSec":401.2,"text":"Also keep in mind that this particular example is a simple one with only a few meshes and materials to consider, and yet you can appreciate the nature of the repetitive tasks awaiting you. So you can extrapolate and guess how time consuming a larger project might be. And so, let's look at how we can automate these tasks. We'll first look at Python scripting and then move to the Visual Data Prep tool. Click the Save All button to save the project before moving on."}],"03_DS-Python":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"We've just seen how a traditional approach to ingesting data via Datasmith takes you through an import process, desolating geometry in the case of CAD data, adding LODs, replacing materials to name a few actions. Now we'll look at automating some of these repetitive tasks through Python scripting. Start a new level, and reset the position of the floor to drop it a notch. Move the SunSky system away from the center of the scene."},{"start":"0:34","end":"1:08","startSec":34.0,"text":"Next, open Windows Explorer and browse to where you've extracted the zip archive you downloaded for this class. Go to Assets, Rhino. Here you'll find a few Python Script sample files to experiment with. We'll start with a file named dsImport.py script. It's a text file, so open it in Notepad or Notepad+. This simple script is about importing and reconstructing a Datasmith scene without going through the Datasmith standard import process."},{"start":"1:09","end":"1:44","startSec":69.0,"text":"Near the top, it points to a file on disk. You will need to change the path as it certainly points to the wrong one at this stage. In your Windows File Explorer, copy the path where your go-kart.3dm file resides. Paste that path to replace the d-rhinofiles-gokart path listed in the script. Make sure you only replace the path and not the file name. Once you have done that, it is important to also replace the backslashes with double backslashes, as this is how Python understands paths."},{"start":"1:45","end":"2:16","startSec":105.5,"text":"The rest of the script is straightforward, but note the section where you can change the tessellation of all incoming cat parts. This is the same as changing these parameters in the Datasmith Import dialog. Set the Core Tolerance to 0.05 and the Maximum Edge Length to 1. You can also define a subfolder where you store the incoming information in the Content Browser. Note the path listed as Game.DSImport near the end of the script."},{"start":"2:16","end":"2:49","startSec":136.5,"text":"Game refers to the top level of the Content Browser, which in this case means that a new folder named DSImport will be created for you directly under Content. Underneath that, a subfolder named after the Datasmith file will also be created. Make sure you save your script before you try to run it. In UE5, use the Tools menu to locate and run the option listed as Execute Python Script. Locate the file you have just saved, DSImport, and run it."},{"start":"2:51","end":"3:27","startSec":171.0,"text":"And there you have it. You have just imported a Datasmith file and adjusted some of its properties literally with the click of a button. Let's take it up a notch. By specifying tessellation values at import time, you ended up with detailed triangulation that may be important when you're nearby, but a bit much when viewed from a distance. In Wireframe mode, you can see that you have much better details than you had earlier with default tessellation. You can remedy this by adding LODs to the various parts. However, there are quite a few static meshes in the scene."},{"start":"3:27","end":"4:00","startSec":207.5,"text":"So instead, we'll use another script to automate that action. As a side note, you can also batch create LODs using the Property Matrix, but scripting is arguably a more elegant method. Open the script named LogByPresetHD.py and take a look at it. At the very top, you can see that it's using the same path in the Content Browser that the first script generated, so one script is building on top of the other."},{"start":"4:00","end":"4:39","startSec":240.5,"text":"Next, you can see that this script is calling upon the LOD group named HighDetail. If you wish to use a different one, then you can replace HighDetail with SmallProp or Deco or any other LOD group you have available on your site. And that's all you need really. From here, you can simply save and execute the script in your project to have all assets processed with added LODs. This will take a few moments as the script goes into a loop to find assets and apply LODs, and it does so to every static mesh found in the designated folder."},{"start":"4:39","end":"5:19","startSec":279.8,"text":"To test it out, you can temporarily switch from Lit Mode to Level of Detail Coloration, MeshLotColoration, and zoom in and out to see the effect. Finally, we'll look at replacing materials via Python scripting. There are currently five materials applied to the various parts of this vehicle. One way to replace a material manually is to right-click it in the Content Browser and then go to Asset Actions and then select all assets using this material or this asset, so you can edit them in bulk."},{"start":"5:19","end":"5:49","startSec":319.5,"text":"And even then, you may not see the assigned material in the Details panel because one or more null objects may also be selected. You'd need to deselect those to access the material to be replaced, and then of course, you'd need to do that for every other material that needs to be replaced. Again, this kind of repetitive behavior is easily done through scripting. Open the file named SimpleReplaceMaterials.py that has been provided to you."},{"start":"5:50","end":"6:22","startSec":350.0,"text":"The way it operates is simple. It takes a few seconds to load the file and then it will load the file. It takes a named material in one folder and then replaces it by another material in another folder. So Metal Red that is part of the Datasmith ingestion will be replaced by MiCaliperRed that is part of the Automotive Materials library. The same holds true for the other materials that were ingested and need replacements."},{"start":"6:22","end":"6:58","startSec":382.5,"text":"If you run the script, you can see how much faster it operates as opposed to having to do this type of work manually. Python scripting can be very powerful and although it's rather easy to understand the syntax, you still need to have some basic programming skills to make the best of it. Save your work and the level as MyCardPython, and next we'll look at Visual Data Prep that enables you to do this type of work and more, but in a very visual way, which is ideal for non-programmers."}],"04_DS-VDP":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"Visual Data Prep lets you prepare your data for use in Unreal Engine 5 without coding. Its purpose is to let you filter data by using actions and operators to quickly go through redundant and repetitive tasks. Visual Data Prep is based on an asset you create in your scene. Let us see how you can treat the go-kart through this process. Repeat the earlier procedure to start a new level. If you look inside the Content Browser, you'll see that you already have a VDP go-kart folder."},{"start":"0:35","end":"1:09","startSec":35.8,"text":"In that folder there's already a Data Prep asset but you'll create your own to learn more about the process. Right-click inside of that folder and choose Data Prep Asset, Data Prep Asset again. Name the new asset MyVDPAsset. Double-click it to open the Visual Data Prep Editor. You can dock it next to the Main Editor tab to maximize the space. You are now in a new interface and you can stay in here until you have fully edited your incoming file."},{"start":"1:09","end":"1:44","startSec":69.3,"text":"Nothing goes through to the Main Editor until you have made that decision. We'll explore the interface as we go along. The first order of business is to load the Datasmith file. In this case, we'll load up the same go-kart we have experimented with earlier. This is done in the Input section of the UI. Remember that this Data Prep tool is for Datasmith-only type of data, so the incoming files have to be Datasmith-ready. You can load up one file at a time or multiple files in a folder. We'll use just the one for now."},{"start":"1:44","end":"2:16","startSec":104.7,"text":"Select the go-kart.3dm file from earlier, Nothing happens just yet, the file is simply added to a list. Click the Import button to import the file into the interface. It loads up and you can see the card in the viewport. To the right is a panel similar to the World Outliner that shows actors and hierarchies, and to the left is a panel similar to the Content Browser that shows incoming Static Mesh Assets and materials."},{"start":"2:16","end":"2:47","startSec":136.5,"text":"Again, all that you see happens only inside this interface and hasn't made the jump to the regular editor just yet. The idea is to look at this incoming file and decide how you can prep it and optimize it in a way that works for you. For example, look at all these tubes that make the car frame. They are all different pieces, in fact 29 of them in all. There's no good reason for these to remain separate objects. You might consider merging them as one."},{"start":"2:48","end":"3:19","startSec":168.5,"text":"This is where the magic happens. You can select all these tubes based on some selection criteria, and then add an action to merge them together. This is how you start building your recipes. Let's try this. From the criteria list on the left, drag an Actor Label filter into the recipe space. This is similar to adding a node to a blueprint or to the Material Editor. You can then define your search parameters. In this case, you want to select all labels that have Chassis in their title."},{"start":"3:19","end":"3:53","startSec":199.9,"text":"These represent all the tubes in the Outliner. You can also set the search to work with an exact match or use wildcards if you prefer, such as Chassis Star for example. To test if your selection is working, you can right-click the selection node and choose Preview Filter. Fall is well, you'll see the actors selected in the Outliner and in the viewport. You can similarly clear the filtering. Before you merge these objects, let's double-check if they are detailed enough first."},{"start":"3:54","end":"4:25","startSec":234.3,"text":"Zoom in to see if their curvatures are smooth enough or if you need to adjust the tessellation. You can also use the regular Y-Frame mode, or the one in the rendering menu to that effect. The tessellation doesn't look great and some triangles are long and thin. Let's fix that. In the regular editor, you'd have had to treat each tube or static mesh separately or at least use a Python script to adjust them."},{"start":"4:26","end":"4:57","startSec":266.1,"text":"Here, you already made your selection, so it's just a question of adding a new operator. Scroll down the Operations list and drag the Datasmith Tessellation option and set it below the selection filter you have created to add a new action step. Set the tessellation values to, let's say, 0.1, 5 and 40. Next, you'll test these values. If you don't like them, you can change them and rinse repeat, so to speak."},{"start":"4:57","end":"5:27","startSec":297.8,"text":"All of this within the comfort of this interface, which lets us easily iterate on changes. Click the Execute button on the main toolbar to test the recipe. Note the added triangulation to the tubes. It's better, but maybe not good enough just yet. So simply change the tessellation values to 0.05, 2 and 30. And execute again."},{"start":"5:28","end":"6:02","startSec":328.9,"text":"Now that's a lot more detailed. Keep on changing the values until you're satisfied, but I think these values work well here. Now that we're happy with the details, it's time to merge the tubes that make the frame together. Add a Merge operator as the next action step and name the newly merged static mesh mg.chassis. If you execute the recipe one more time, you will notice that all the tubes in the Outliner have now been replaced by a single mesh named mg.chassis."},{"start":"6:03","end":"6:38","startSec":363.3,"text":"However, there are some other bits and pieces that you may consider adding to this chassis piece. The seat, for example, is made of two pieces that may as well be combined with the tubular frame. These platforms at the front and at the rear housing the pedals and motor can be made part of the chassis as well. Here's the problem however. If you consider the seat and try the same procedure that you used earlier and try to cram an actor labeled Filter right underneath the chassis filter, this will not work."},{"start":"6:38","end":"7:14","startSec":398.5,"text":"To prove the point, re-import the scene so it is reset to the original version, and then try to execute the recipe again. You'll notice that nothing happens. The way Visual Data Prep works is that it evaluates steps in an action from top to bottom before it moves on to the next action to the right. Here, it started with the chassis filter and made that selection. Then it moved to the next step and tried to find the actor's named seat from within the current selection, the chassis tube selection, and it didn't find any."},{"start":"7:15","end":"7:45","startSec":435.7,"text":"What we need here is an additive way to making the selection, not one that depends on a previous selection. So remove the second filter, you won't need it. However, you need to edit the first filter and switch its characteristics from Single to Array. Leave the criteria to Contains for now. Add four elements to this array and name them accordingly. The first element would be Chassis,"},{"start":"7:46","end":"8:17","startSec":466.5,"text":"the second would be Seat, the third would be Platt, which takes care of both front and back platforms, and we'll simply add the MechDrive name representing the axles to the list. And so, pretty much every component other than the steering wheel and the four wheel parts is now accounted for. All these parts will now be tessellated with the help of the node you created earlier and merged into one object named Chassis."},{"start":"8:18","end":"8:54","startSec":498.1,"text":"Test your work again, using the Execute button, and note that the Outliner is much simpler to make out now. It also shows a few null objects that are now unused. We'll get rid of those in a moment. For housekeeping purposes, you can give the action you created a name, simply select the top of the node and press F2 to rename this one as Chassis. Let's keep going and look at the steering wheel. It's made of two parts, the steering wheel itself and an inner or core part."},{"start":"8:56","end":"9:29","startSec":536.4,"text":"You can select both using the same technique used earlier with a label filter set to ST Wheel. You can also use tessellation and possibly use different values from earlier. But if you wanted to use the same values as before, you can copy nodes from one action to another by Ctrl-dragging them. You can of course make changes as you see fit. I believe I'll set this action to use tessellation values of 0.1, 1 and 40."},{"start":"9:29","end":"10:04","startSec":569.7,"text":"If anything, it shows that you can have different tessellation values for different parts in your scene. Merge these objects into one steering wheel. Rename the action. And execute the recipe to test it out. Next, we must deal with the wheel assemblies, each made of five different parts."},{"start":"10:06","end":"10:44","startSec":606.6,"text":"The difficulty here lies in the fact that these components share the same names, so it's near impossible to differentiate them using a label filter. But you can use the label filter to set the tessellations before you move on to combining the assemblies. So use a label selection that is based on the Wheel filter, which encompasses all the wheel parts, and add a tessellation node with the values of 0.1, 2 and 20. This will adjust the triangulation on all four wheels and their components, but you still need to separate these four areas of the car."},{"start":"10:45","end":"11:20","startSec":645.5,"text":"You have a couple of ways to do that. Let's start with the front left wheel assembly. Select the top parent named Wheel. Obviously, there are three more similar objects named Wheel in the scene, so using the label filter here is not an option. However, note that if you select this top parent, its properties are displayed in the Details panel. You cannot edit these properties, but you can certainly learn from them. At the bottom of the Details panel, expand the Advanced rollout and then the Tags rollout."},{"start":"11:22","end":"11:52","startSec":682.4,"text":"Note the RhinoID tag listed there. This tag is part of the Rhino file and has been assigned as a unique ID to this particular object. Look at the first few strings of letters and digits. They read 5944 to start the sequence, which is a different string than you will find on another object with the same name. And so instead of filtering through labels, you can filter through tags."},{"start":"11:53","end":"12:24","startSec":713.8,"text":"Add a Tag value filter as a new action, and type in the first four characters or digits, 5944, for the top parent of the front left wheel assembly. You can opt for a longer string, which would be safer still. Ensure the filtering is set to Contains. However, this only would select the top parent or null object at this time. You also need the hierarchy underneath."},{"start":"12:25","end":"13:02","startSec":745.4,"text":"To select the hierarchy, add a Select Hierarchy operator from the Selection Transforms list. Depending on the complexity of the hierarchy, you can choose immediate children or all descendants. In this case, it won't make a big difference because it's a simple one-level hierarchy. You can now add a Merge operator and name the resulting object MGWheelFrontLeft. To deal with the front right wheel, you can simply copy the last action with a Control-drag, but obviously you need to change the Merge object name to MGWheelFrontRight."},{"start":"13:03","end":"13:38","startSec":783.4,"text":"But more importantly, you also need to change the Tag value to cater for that other top parent named wheel, in this case with a string 4DC1. Repeat the procedure for the rear wheels, choosing the correct tags and output names. In terms of housekeeping, you can rename actions as you've learned before. But you can also group actions that belong together, in this case, everything related to the wheel assemblies."},{"start":"13:41","end":"14:12","startSec":821.8,"text":"From this point on, you can apply the same procedure to the front right wheel. From this point on, you can apply global actions, ones that affect all objects in the scene. For example, you can add a Set Mobility operator to set all objects to be movable, as it is likely you want to animate these objects in your project. Another global operator you might consider is an LOG-Modifier operator."},{"start":"14:13","end":"14:44","startSec":853.0,"text":"Mind you, you certainly can add local LOD operators with different values to various objects and various actions. Here, we'll simply add a global one based on a manually adjusted LOD system, as opposed to using a preset. Add a new Set LODs operator, and adjust it to use three LOD levels. Be sure to disable the Auto Screen Size option if you plan to define your own values."},{"start":"14:45","end":"15:20","startSec":885.7,"text":"Set the first LOD, LOD0, to use 100% triangles at 1 or 100% of screen space. This is your starting point. Set LOD1 to 50% triangles at 0.8 or 80% of screen space. This means triangles will be decimated by half when actors occupy less than 80% of screen space. And set the last LOD level to 20% of triangles at 0.8 or 80% of screen space. This means triangles will be decimated by half when actors occupy less than 80% of screen space."},{"start":"15:21","end":"15:51","startSec":921.3,"text":"And set the last LOD level to 20% of triangles at 25% screen space. This will kick in as the lowest level of detail by decimating triangles five times when the actor is small on screen. Finally, let's see what we can do with material replacements. If you check the panel representing the Content Browser, there are only five materials associated with this Rhino model. They can easily be replaced using this recipe."},{"start":"15:51","end":"16:21","startSec":951.7,"text":"Add a Substitute Material operator to the recipe. Note that there is another option to substitute materials by table. This option works well when dealing with a high number of imported materials, but you won't need it here where you have only a few to deal with. To substitute an incoming material with a new one, simply type or copy-paste the name of that material inside the node. You can then choose which material you want to use instead."},{"start":"16:22","end":"16:42","startSec":982.7,"text":"You can then duplicate the substitution node as an additional step and work on substituting a different material. Complete the material list,"},{"start":"16:54","end":"17:30","startSec":1014.4,"text":"exit wireframe mode if it's still enabled and execute once again to test the results. This time, you can see how much simpler the Outliner is and how the car looks in the viewport. If you enable Mesh Slot Coloration, you can see that they're working as designed. And the only thing left is to commit the changes to the main editor. Switch back to Lit mode. One last bit of housekeeping that you can do. You can do away with all these unused null actors by adding a Compact Scene Graph operator to the recipe."},{"start":"17:31","end":"18:01","startSec":1051.1,"text":"This will delete any non-renderable actors that are not being used anymore. Similarly, if you're happy with your end results and you don't need the original static meshes or materials that came with the cat files, basically most assets listed in the Content Browser on the left that are not in use anymore, you can add a Delete Unused Assets operator to the recipe. This would make your project inside of Unreal much lighter."},{"start":"18:01","end":"18:32","startSec":1081.8,"text":"Execute the recipe one last time to see the end results. When you're ready to commit, make sure you save your work, essentially saving the recipe that you put in place, and then click the Commit button on the main toolbar. Only then will the scene get transferred to the main Unreal Editor. Remember that the Data Prep Recipe you created is essentially an asset in the Content Browser, and as any other asset, you can migrate it to another project if you wish to use it again elsewhere."},{"start":"18:33","end":"18:34","startSec":1113.6,"text":"Save your work."}],"05_Outro":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"In this class, we have reviewed some general aspects of Datasmith ingestion, and why it's important to clean up incoming data before ingesting it into the engine. We also explored ways to automate repetitive tasks using two different approaches, one through Python scripting examples, and another by using a tool called Visual Data Prep, which was the focus of this session. Both methods showed you ways to intuitively clean your incoming Datasmith files and cut down the time it takes to clean them up manually."},{"start":"0:34","end":"0:40","startSec":34.5,"text":"I hope you have found this class useful and that you will be able to apply what you have learned to your own projects."}]},"207.01":{"01_Introduction":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Hello and welcome to another Unreal Engine 5 training course. Today we're going to be taking a look at Alembic Importing and Live Link. As an overview of the course, we're going to be taking a look at how to work with Alembic animations in Unreal Engine 5, including a look at some of the tools in Maya for exporting, some information on Alembic caches themselves and some of the uses in Unreal Engine 5. We'll also have an overview of the Live Link feature, so going over the pipeline and seeing how you can stream your animations into Unreal Engine and see it in your scene,"},{"start":"0:31","end":"0:45","startSec":31.0,"text":"and just going over the steps to connect it from Maya to Unreal Engine 5. And along the way we'll take a look at some Blender tools, we'll understand a bit about the Datasmith, and we'll see how to get your Alembic cache animations playing in your scene using some of the sequencer tools."}],"02_Alembic":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"So what is an Alembic cache or an Alembic file? It's a baked geometric animation. So that's basically saying that it's a way to bake down or to store the information of your rigged mesh to the geometry itself and import just the geometry, not the skeleton. Now, something important to note is that Unreal only supports meshes that have faces with three or four sides. So if you're getting errors when you're importing, it's worth checking your mesh just to ensure that it has no faces with more than four sides. The support for Alembic files comes with a plugin built into UE5."},{"start":"0:33","end":"1:07","startSec":33.0,"text":"So this should come already loaded, but if not, just search for Alembic inside your plugin window. Just tick the box to activate it and you'll get access to the import options. Now, you can also bring in multiple assets with an Alembic file, not just the animation itself. And you can combine or you can merge these on import depending on how you want to set up your scene. And the main use for an Alembic file or an Alembic animation would be for use in cinematics. So when you want a pre-baked animation that you can get a great video render with and you don't need any procedural elements to the character's movement or the skeleton,"},{"start":"1:07","end":"1:39","startSec":67.0,"text":"they can be quite computationally expensive. So they're not recommended for use with mobile devices. And they work with most of your external DCC programs that have the ability to export an Alembic cache. So they work with Mair, 3ds Max, Blender, etc. When exporting an Alembic file, there are a couple of options that we just wanted to highlight. So if we take a look at Mair's workflow here, you have two different export options. So you can choose to export everything in the scene, including any baked Alembic caches you might have, along with any of the meshes that you've got in the scene and export everything all as one file."},{"start":"1:39","end":"2:09","startSec":99.0,"text":"Or you can just select a specific mesh or a group of meshes and use the export selection method here. Now, if you select the option box on either of these methods, you'll get a handful of settings that come up and you can change for the export. But again, there's just a couple that we wanted to highlight that we thought might be useful for importing into Unreal. Now, you can choose your frame range, which is to say you can set when the animation starts and ends. So you can get the exact section that you want, or you can choose to export the whole animation itself. There's also the UV write option."},{"start":"2:09","end":"2:41","startSec":129.0,"text":"So for material purposes, you want to make sure that you check this option so that it saves the correct UVs you've made and allows you to apply materials correctly in the engine later on. And there's also the write face sets option. So you want to make sure that with your meshes that you have, you apply the materials to them at the face value in your DCC. So that is to say, go through and select all of the individual faces of the mesh or the meshes and apply the materials to those faces directly so that Unreal can bring them in as elements on your mesh"},{"start":"2:41","end":"3:17","startSec":161.0,"text":"and apply the materials correctly for you. Now, this is specifically for use when importing as a geometry cache, which we'll cover in a moment. When it comes to importing your Alembic file into the engine, you can define how you want to import it in a few different ways. So if you choose to import your Alembic cache as a static mesh, what you'll get is one static mesh per frame of animation that you have based on the frame start and end values under the sampling heading just here. Now, if you exported several meshes within your Alembic file, you can tick the merge meshes option, which will create one single static mesh."},{"start":"3:17","end":"3:48","startSec":197.0,"text":"Now, if you disable this option, each mesh within that Alembic file will be imported into the engine as an individual static mesh itself for every frame that you have. Now, bear in mind, if you do have multiple meshes and you choose to merge them, the origin or the pivot point of all the meshes will snap to world zero as they merge. So if this is something that you don't want, make sure to tick propagate matrix transforms and the meshes will retain their position in world space when they merge together. Now, you also have the option to import as a skeletal mesh."},{"start":"3:48","end":"4:22","startSec":228.0,"text":"This will create several base poses taken from the animation and use them as morph targets to blend between to achieve the correct animation frame. Now, this is done as part of the animation compression. And before you hit import, you have the option to define the percentage or the number of base poses and to tweak that level of compression and get the animation looking how you want it. And lastly, you can import as the geometry cache. Now, this is an experimental feature at the moment and that creates a new type of animation asset that allows the playback of vertex varying sequences."},{"start":"4:22","end":"4:56","startSec":262.0,"text":"So the animation will come in as one file and be played back as a flip book of frames. One thing to note is that the performance of this will depend on the complexity of your mesh. So if you have a very complex mesh, then it's going to be much less performant than a simpler mesh. And with the geometry cache, you also get some extra options to import things like motion vectors of the vertices, which can be really useful to calculate motion blur. Now, you also have the ability to choose the frame range you'd like to import under the sampling heading that we looked at a second ago, as well as choose to import the materials with your meshes that you bring in."},{"start":"4:56","end":"5:27","startSec":296.0,"text":"You have a few different ways you can control the playback of the animation once you've imported into the engine. Now, if you have an Alembic asset like a geometry crash in your level, for example, you have the option to check what's called the running option here. And that is essentially an autoplay option. So when the level starts, if this is checked, this animation will play automatically. You could also set the animation to looping just by checking the looping option. As you can imagine, that just makes the animation continuously loop until the level's over."},{"start":"5:27","end":"6:01","startSec":327.0,"text":"You could also add the asset to your level blueprint and just set up any parameters that you want in there to say when the animation is allowed to play. And another option you have is to use a sequencer track. So this has a very simple setup. And just by adding the mesh to the sequence, you can add a geometry cache track and have your animation play when you scrub through or when you trigger the sequence. And you can also add a geometry cache component, which might be material or property or any sort of other miscellaneous data that you might want to control during the sequence."}],"03_LiveLink With Maya":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Now let's take a look at Unreal Engine's Live Link plugin with Maya. Now we'll look at an overview of the concept, understanding the pipeline and just how we go about setting it up. Live Link, if you've not heard of it before, is a way to stream your animation from Maya into Unreal Engine. Now this allows you to animate directly inside Maya and through the use of Live Link preview what it will look like inside the engine in real time. Now this is great because you get to see how your character looks with all the materials and the lighting and any extra elements on them like cloth that might be applied to them"},{"start":"0:33","end":"1:05","startSec":33.0,"text":"without having to go through the export and import process. When it comes to understanding the pipeline of Live Link, you have a plugin for both Maya and for Unreal that you either need to download or just simply activate. And in Maya you would define the skeleton that you're using and the character's data that you want to send over to Unreal Engine. And then this goes through the Unreal message bus, which is basically a direct channel to the Live Link client within your Unreal project. Now the Live Link client manages a couple of things."},{"start":"1:05","end":"1:36","startSec":66.0,"text":"So it manages the sources of data that are coming in, which represent the connections to other programs like Maya or MotionBuilder that can send data to Live Link. And it also manages the subjects, which is to say the individual streams of data within the client. An example of that would be animation information going through for one character. Now this information is then used in conjunction with a Live Link animation node inside your animation blueprint to convert that data into animation data on the character in the engine."},{"start":"1:36","end":"2:10","startSec":96.2,"text":"Some of the component features of Live Link in Unreal Engine 5 are the Live Link controller and the skeletal animation components. Now the controller component is a quick way of taking the Live Link data and applying that to an actor in your scene. So as you can see in the example we've got below, this might be taking the transform information and applying that to a camera to aid something like a virtual production environment that you're in. We've also got the skeletal animation component. So this sits inside your blueprint and gives you access to the onLiveLinkUpdated event,"},{"start":"2:10","end":"2:42","startSec":130.7,"text":"which effectively takes place of your tick event, but it runs at editor time as well. So you don't need to be playing or simulating to make use of that data. You can also access the Live Link data via several blueprint nodes to gather and use various bits of information like curve data or metadata and different types of transform information. So now that we've taken a look at some of the features that overview the pipeline of Live Link, let's take a look at how to actually get it set up and connect Maya with Unreal Engine to see your animation streaming live."},{"start":"2:42","end":"3:16","startSec":163.0,"text":"So the first thing you'll need to do is go to the Epic Games Marketplace and download the Unreal Live Link for Autodesk Maya plugin. Once you've downloaded this, you need to install it to Maya. Now to load your plugin in Maya, if you've not done this before, if you go to Windows, down to settings and preferences, and then into your plugin manager, you'll get a list of plugins that are already installed on your machine that you can sort of load, activate or deactivate. But if you've not had one installed before and you need to install something new like the Maya Live Link plugin, you should have a browse option."},{"start":"3:16","end":"3:49","startSec":196.2,"text":"Now if you click the browse option and find the folder where the plugin was saved, you need to load two different plugins, one called Maya Live Link plugin and then the date, which may not be 2017 anymore, .ml and then the Maya Live Link UI Python plugin. Now once your plugins are installed and loaded, to access the Live Link UI, you would use the melinput command, Maya Live Link UI. Now you'd put that into your mel line at the bottom of the screen or into your script editor. You can then save that as a button to your shelf just to make accessing it easier each"},{"start":"3:49","end":"4:22","startSec":229.6,"text":"time. Now this UI is where you'd add or remove subjects whose data you want to send over to Live Link in your Unreal Engine project. Now to do that, you just choose add selection and you'd select your mesh and root bone of the character you'd like to stream to Unreal. But before you can do that, we need to ensure that the plugin is enabled in your Unreal project. So by default, the Live Link plugin should be available in a UE5 project, but if it's not for any reason and you're using an older version of the engine maybe, you can download it in the same way that you did with the Maya plugin using the Epic Marketplace."},{"start":"4:22","end":"4:53","startSec":263.0,"text":"Now you can check if it's loaded by going to your plugins window and searching for Live Link and just making sure that it's ticked. And once you have it loaded, you'll have access to a new window inside Window, Virtual Production called Live Link. And inside this window, this is where you'll be controlling the Live Link sources and it'll show you a connection to your DCC like Maya or Motion Builder. Now something to be aware of and something you should check in your project settings would be the use less CPU when in background option."},{"start":"4:53","end":"5:26","startSec":293.7,"text":"Now if that's turned on, it will inhibit the use of the Live Link when you're working in Maya. So if you're tapped out working in Maya, you won't be able to see the animation streaming live. So make sure you disable that. Now to add your source, which would be the information coming from Maya, for example, you just hit the plus source button, go to Message Bus Source, and you should see a list of sources matching the selections that you added in Maya. Now that the Live Link connection is made, you can start to preview the animation on your character by opening up the corresponding skeletal mesh inside Unreal Engine."},{"start":"5:26","end":"5:56","startSec":326.3,"text":"And you should have a new option underneath the animation preview controller drop down Live Link Preview Controller just inside your Preview Scene Settings tab. Now if you select this and then change the Live Link subject name just underneath to match that of your character in Maya, you should see your skeletal mesh begin to match the animation of your Maya character. Now something that can be useful as well is to tick the Enable Camera Sync option in the same Preview Scene Settings tab so that when you move your camera in Maya, the camera in Unreal should mimic that."},{"start":"5:56","end":"6:02","startSec":356.3,"text":"And that should be it. You should now be able to animate your character in Maya and preview it on your skeletal mesh in your Unreal project."}],"04_Thank You":[{"start":"0:00","end":"0:29","startSec":0.0,"text":"So that brings us to the end of this course. Hopefully now you have an understanding of Alembic files and the best way for you to import them for your own use, as well as a variety of ways of playing these geometric animations in your own project, as well as the knowledge to set up a Live Link connection between Maya and Unreal so that you can speed up your workflow when you're wanting to see just how your character is deforming an engine and how any sort of procedural items might be reacting to the animation. So thank you very much."},{"start":"0:30","end":"0:32","startSec":30.0,"text":"Thanks for watching!"}]},"207.02":{"01_AnimBP&TakeRecorder":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Welcome to another Unreal Engine training course. Today we'll be looking at animation blueprints and take recorder. So we'll be looking at animation blueprint blending and the different ways that you can approach blending animations for your character. And we'll actually use some of these methods to make a new weird zombie walk that'll be comprised of blending some pre-existing animations together to create something new. We're also going to see how to simulate physics on the player character, so you can do cool things like make your characters arm dangle when they've been shot."},{"start":"0:30","end":"1:01","startSec":30.0,"text":"And then we'll see how to set up physics on other skeletal meshes so that you can see them react with the environment and with the player character and capture a recording of this using take recorder. And then we'll see how we can preview that back and edit the animation once it's been recorded and save that out as a new animation. We're going to jump straight into the engine, looking at some of the different nodes we can use to blend our animations together and kick off the beginnings of our zombie walk. Our animation blending is all done inside an animation blueprint."},{"start":"1:01","end":"1:32","startSec":61.0,"text":"And we're using the third person template project here so that we've got a full animation blueprint already set up for our money character. And we're just going to use it as a base to preview all the blending that we can do inside the animation blueprint. So if I just search for ABP underscore, that'll give us our animation blueprints in the project. And I'm just going to open up ABP money here. All of the blend logic is set up within the anim graph. So let's just open that up by double clicking here."},{"start":"1:32","end":"2:11","startSec":92.0,"text":"And this is where you would set up your animation logic for what animation should be playing on your character when they're moving and sort of your blend settings and how an animation might blend from one to another. So first of all, we're going to look at three common blending nodes that you can use inside the animation graph. And apply additives is going to be the first one we look at and just see how that works. So if I go right click and search for apply additive, and grab that there. I'm going to disconnect the output pose and just bring that over here because we're going to see, you know, we're going to plug a few animations in and see what they look like when we apply something additively."},{"start":"2:12","end":"2:42","startSec":132.0,"text":"So the apply additive node allows you to blend a pose or an animation on top of a base animation that's playing and then control the strength of this additive animation with the alpha value. So kind of like how an animation layer works in mayor or blender. If you've used that before. So if the alpha is set to zero, it means that there'll be no blend or no additive animation played on top of your base animation. And if it's set to one, it means that it'll be blending the two animations fully together."},{"start":"2:42","end":"3:14","startSec":162.0,"text":"So with this node, the base animation always plays and the additive animation plays on top. So we can connect a few animations up here just to see how that looks. Because we want to create a sort of zombie walk, let's come over to asset browser here and bring in this walk forward. So this is going to be our base animation. So if we just connect these up, just make sure that things are working properly. And we have our character walking there. Now one thing you'll notice is the character stops walking so that this animation doesn't loop."},{"start":"3:14","end":"3:44","startSec":194.0,"text":"And just to make it easy for us to preview animations in this window, I'm going to come over to the details panel and tick loop animation. And hopefully we should see that that's now looping perfect. And next I'll bring in the animation that we want to apply additively. So let's bring in the walk forward. Oh, no, that's wrong. The walk in place because we don't want to walk forwards, do we? So I'm going to do the same with this animation. I'm going to select to intake looping so that it's always looping."},{"start":"3:44","end":"4:14","startSec":224.0,"text":"And I'll plug it into the additive pin that we have on our node here. And when I compile, we can see that things change. But this is a little broken. It's not necessarily what we want here. So an animation that you're applying additively essentially needs to be told that that's how it's being used. It needs to be set up as an additive animation. So if I open the animation up here, you can see in the asset details panel, if I scroll down, we have additive settings as a heading."},{"start":"4:14","end":"4:47","startSec":254.0,"text":"And we've been set to no additive. So by default, all animations that you bring in with the default settings will be set to no additive. Now, if we change this drop down to local space, just move our window out slightly here, we can see that already we've got some better results here. But I think we can improve this slightly if we change the base pose type. So the additive animation's calculation is being done by comparing the additive animation's current pose right now with the skeleton reference pose."},{"start":"4:48","end":"5:24","startSec":288.0,"text":"And what this is doing is calculating the difference of the delta between where all the joints are now and where they would be in the character's default pose when it doesn't have an animation applied to it. But what we want to do is compare the difference between our base animation and our additive animation. So calculating the difference between the two poses of the two animations to get some more appropriate results. So if I change our drop down box here to selected animation frame, we can actually choose our walk forward animation that we have set up as our base animation."},{"start":"5:24","end":"5:59","startSec":324.0,"text":"And you can see already, now that it's comparing between the base animation and the additive animation, we get some better results. So the arms are no longer inside the body and the legs are doing something a bit funky and kind of zombie like, which is pretty cool. So if I just save that and close that animation, something you'll notice as well, when you do set an animation to be additive, it changes to a green color. So you can pretty easily see at a glance inside your anim graph, which animations are additive and which ones aren't, and that can help you troubleshoot if you're getting some weird results."},{"start":"5:59","end":"6:41","startSec":359.0,"text":"So if I change the strength of the alpha value here to 0.5, for example, we should see that the strength of the additive animation just isn't as strong now. Now to 0.1, up to 1, sorry, and we'll add it back on 100%. So because the alpha here is an input pin, you can actually promote this to a variable. And with your event graph, you could set up some logic that drives the strength of the alpha depending on, you know, whatever logic you might want to set up for it. So that you could get this additive animation to apply at runtime basically, depending on perhaps like a health effect of the character and have that update dynamically at runtime."},{"start":"6:42","end":"7:12","startSec":402.0,"text":"The second blending animation we're going to take a look at is the two-way blend node. So if I right-click and search for two-way blend here. Now this node works a little differently than the apply additive in the fact that it cross-blends two animations together rather than applying one animation over the top of a base animation. Now this means that there's no base animation that always plays here. We're transitioning essentially from animation A to animation B."},{"start":"7:12","end":"7:43","startSec":432.0,"text":"And what that also means is that neither animation need to be set up as an additive animation. So let's take a look and see how that works. So if I unplug this, connect these up to A and B and connect them to our output pose. I'll just double-click our walk-in place again and change our additive settings back to no additive. Save that. And when I compile, you can see that when the alpha is set to zero, animation A is always playing."},{"start":"7:43","end":"8:12","startSec":463.0,"text":"And if I was to set this to one, compile, now animation B is the only one that's playing. And the flow of logic kind of indicates and tells you or gives a good indication of the strength of each animation that's playing. So if I was to put 0.2, compile that. Prodominantly, we've got the walk forward playing. We've also got with this lighter gray line here some influence from the walk-in place animation."},{"start":"8:14","end":"8:47","startSec":494.0,"text":"And the third blending node we're going to take a look at is the blend bone by channel node. So if I just search for that here, blend bone by channel. Now this node allows you to assign specific bones that you want to apply the blend to. So if we look across the details panel over here on the right, you can see that we have under the blend heading, bone definitions. And if we hit the plus here, this is where you would specify which bones it is you want to apply the blend to."},{"start":"8:47","end":"9:19","startSec":527.0,"text":"Now this is good if you want to just apply the blend to a couple of specific bones. But if you want to add it to entire bone chains, for example, like the entire left leg or the left arm or whatever, you'd be better off using a layered blend per bone node. But we'll be looking at that a little later on. So for now, we can specify our source bone and our target bone. So our source bone is where we're going to take the transforms from. And our target bone is the bone where we're going to apply the transforms."},{"start":"9:19","end":"9:49","startSec":559.0,"text":"So if we were to do just the leg, for example, I search for the L as our source and also the L as our target. If I connect all the logic up here, so we have our walk forward and our walk in place. Also set our alpha to one. You can see that on our left leg here, at least our left thigh bone, we've got the walk in place animation playing 100%."},{"start":"9:49","end":"10:21","startSec":589.0,"text":"If you wanted to propagate that down to the whole leg, we would just add more bone definitions. So if I hit the plus here, and our next one, we'll add the calf is our source and the same again, calf L as our target. And I'll add one more just for the foot. So foot L as our source and foot L up here is our target. And when we compile, you'll see that our walk in place animation is playing on the left leg 100%."},{"start":"10:21","end":"10:52","startSec":621.0,"text":"And the walk forward animation is playing on the rest of the body. So let's sort of DJ these animations and blend nodes and see if we can get something looking a little bit zombie-ish. We can actually piggyback some of these nodes together to apply different blends on top of one another and get some pretty fun results. So I'm going to kick off with the two way blend node. Let's just stick these back in here. I feel like that was a pretty good position where we can get some awkwardness kind of coming in from these two animations blended together."},{"start":"10:52","end":"11:24","startSec":652.0,"text":"I'm going to bring the second animation in the walk in place a little bit stronger. And you know what I might do as well? Let's grab these. I'm going to offset the walks a little bit so that we get some sort of awkwardness with the foot placements and change the cadence of the walk a little bit. So I'm going to slow down the standard walk to let's try 0.8. You see that starts to feel a little bit awkward and weird."},{"start":"11:24","end":"11:55","startSec":684.0,"text":"And I might even speed up the walk in place by increasing the play rate to let's just say 20%. And that's starting to look kind of funky there. So you get that awkwardness with the legs and the cadence of the zombie walk kind of coming in a little bit there. But let's try adding another layer to that. So I'm going to bring in the apply additive node and I might even bring in a different animation like the run forward for example."},{"start":"11:55","end":"12:26","startSec":715.0,"text":"Now this one, if we're applying additively, you can see it's already been set up as an additive animation. So under local space, we'll change it to the walk forward animation that we're using as our base. Now it's not exactly going to be this because we edited it slightly and made this sort of zombie-ish feel to it. But I'm going to plug in the output of our two-way blend as the base of our apply additive and connect those up and see how that kind of feels."},{"start":"12:26","end":"13:05","startSec":746.0,"text":"Now obviously there's a little bit strong there, but let's just make that animation loop again. And we'll reduce the alpha quite a bit, maybe 0.2 and see how that kind of feels. Yeah, so you're kind of getting some of that weird staggeriness that a zombie might have, that weird cadence to the walk, that awkward feeling. That looks kind of cool. What we can do with this now is record it within the animation blueprint and save it as its own animation and then take a look at some other ways we can blend some other animations on top of it to just add a little more to it and get the sort of top half feeling and a little more zombie-ish."},{"start":"13:05","end":"13:42","startSec":785.0,"text":"So to record, it's actually quite simple. Over in your preview window here, you have a record option. So if we just press that, it'll ask you, you know, where do you want to save it and what do you want to call it. So we'll just call it Creep Walk and we'll leave the default settings as they are and just hit OK. And this will keep recording until you hit stop. So I'm just going to go for like five or six seconds of something here so that we can essentially open the animation up and trim it down to a point where we think we can kind of make a loop with it and then see that it'll be an animation that we can use for our character."},{"start":"13:43","end":"14:14","startSec":823.0,"text":"So if we come back out to our content browser, just in the base content, content folders where we save that. So opening up our Creep Walk, we can see that we now don't have all that animation blueprint logic running. It's just an animation sequence that plays on its own, which just makes things a lot more optimized if we want to do any more blending with it. So what I'm going to try and do is find two poses that are quite similar throughout the animation to make a sort of a loop out of it."},{"start":"14:14","end":"14:49","startSec":854.0,"text":"Now I can see the first pose is kind of similar to this one here. So I think what I might do is hover over here and right click and we can remove from frame 108 to 213. So basically remove everything after frame 108 here. So if I choose to do that and if I hit play, you can see that, all right, it's not quite perfect, but we've got a bit of a loop going on here. I could even cut out maybe a little bit more at the beginning to keep some of that momentum going."},{"start":"14:49","end":"15:24","startSec":889.0,"text":"So if I right click and remove from 0 to 6 and see what that looks like, that's a little bit better. So there is a bit of a hitch, but this is sort of decent start to the lower half of the body zombie walk. So what we can do now is use this animation as a base to experiment with another node that allows us to blend more than just two animations together and see if we can get the upper half of the body feeling good. The blend multi node is what we're going to take a look at. And this is something that allows you to blend as many as many animations together as you want."},{"start":"15:24","end":"15:56","startSec":924.0,"text":"So if I just search for blend multi. Now by default, this works a bit more like the two way blend where depending on your alpha values, it takes sort of an average of all of the input animations and blends them together. Now in the details panel up here, you can however toggle the node to behave additively with the additive node tick box just here. So if that's something that you need, it does have the flexibility to work that way too. Now let's see if we can blend a few different animations together and get this upper body feeling cool."},{"start":"15:56","end":"16:30","startSec":956.0,"text":"So I'm just going to bring in our creep walk that we saved. And I'm also going to bring in the let's have a look. I think the fall loop because that has some arm animation in it. I'll just unhook that so we're not using any of the old blend nodes. And plug in our creep walk just to the first input pin here and our fall loop to the second input pin. Now when we connect it by default, both of the alphas are set to zero."},{"start":"16:30","end":"17:01","startSec":990.0,"text":"So if we set the alpha of pose one to one, you'll see that our creep walk plays. And if you were also to set the alpha of pose one, our falling loop to one, you'll see that the animations play sort of 50 50 strength on top of one another. Now something I have forgotten to do here is just to make sure that these are looping. So we keep seeing the animation loop. There we go."},{"start":"17:01","end":"17:31","startSec":1021.0,"text":"Now to add another pin to this, you would just right click the node in empty space and choose add blend pin. And here we can grab another animation. Well, just double click this and make sure it's not additive anymore. So turn that to no additive and save that and plug the inter pose to. If I was to also set that to one, we'll see that all these animations are playing at the same strength on top of one another."},{"start":"17:31","end":"18:08","startSec":1051.0,"text":"And I have also forgotten to set it to loop again. So let's do that. There we go. So all these animations playing at the same strength on top of one another. So now you can play with these alphas and try and get something that is, oh, well, or we can play with them and get something that's a little unusual or zombie on the top half. So let's just bring the creep walk down to point five. And our fall loop, we're probably going to want to maintain is like the strongest alpha because we want that upper body mo, upper body animation."},{"start":"18:09","end":"18:40","startSec":1089.0,"text":"And then this run, just going to bring that right down in terms of its strength. I mean, it's kind of cool. We get some interesting kind of wobble to it there, which is quite interesting. And the arms are a bit out. So they're looking a little bit like, so I'm steady. And I think even with the run, I might just bring the play rate down. Just so we don't have the legs going as fast. That's something that's looking kind of fun."},{"start":"18:40","end":"19:12","startSec":1120.0,"text":"So you can blend as many animations together as you want with this, but do be mindful that the more animations you add to this node, the less optimized your animation blueprint is going to be. So do have optimization in mind when you're setting this up. And if there's any way you can reduce how many animations you're blending necessarily. I'm just going to do the same process with this again, where we recorded the animation and we tried to get a loop out of it. So hit my record button. I'll leave it under content there. And this is feeling a bit sneaky."},{"start":"19:12","end":"19:46","startSec":1152.0,"text":"So I'm just going to call it sneaky walk. And here, okay, there. And again, we'll let that run five or six seconds. So we get some sort of loop and we increase the chance of us finding the same sort of pose again. And if I hit stop, we can actually open it here with the little pop up. So I might just do that. And then again, just looking for two sort of similar poses. Maybe something like that. And something like this here. So if I remove zero to 14."},{"start":"19:46","end":"20:16","startSec":1186.0,"text":"And then maybe those ones there. That's not too bad. If we just save that there. Now that we've created this sort of sneaking walk loop, let's take a little bit of a sidestep and just look at some other blending nodes that you can think of being as a bit more like a switch for blending based on an input value at runtime. So this could be a bool that you're flipping."},{"start":"20:16","end":"20:46","startSec":1216.0,"text":"So the character knows when they're falling and that they should blend into the falling animation. Or it could be, for example, a sort of maybe a health status update on your character when they've taken some damage, you know, we trigger a blend to a different animation that shows how that character has been affected. Let's take a look at the blend poses by bull first. So this blends from one animation to another based on an input value that turns the bull on and off sort of like a switch. So by default, these switches turned off."},{"start":"20:46","end":"21:17","startSec":1246.0,"text":"So under your false pose, you would want your base animation. And under your true pose, you would want the animation that you want to switch to depending on your logic. I'm going to do a really simple setup here that shows you exactly how this works. So if we grab our walk in place animation and our full loop animation and again set these both to loop. Our default pose or our base pose that we want to play our base animation would be the walking in place animation."},{"start":"21:17","end":"21:49","startSec":1277.0,"text":"If I just connect that up, you can see by default our bull is set to false and compile that. You can see our walk in place animation plays. If I plug in the full loop, you'll see that nothing changes until I set it to true and then we blend to full loop. So this active value, we can actually have turn on and off based on a variable that we have that detects whether or not the player is on the ground. So we have one setup already called is falling."},{"start":"21:49","end":"22:24","startSec":1309.0,"text":"So I'm just going to left click and drag that in and get is falling. And as soon as I plug that in and activate and deactivate this or set it to true or false, you can see that let's compile first actually. You can see that we automatically flip between our two different states or our true and our false poses. So if I set that back to default back to false by default and we go and play, you'll see that the only two animations we have plugged into our character at the moment are our walking place animation."},{"start":"22:24","end":"23:01","startSec":1344.0,"text":"And then when we're not on the ground, so if I fall off the edge here, you'll see that our falling animation plays. And the same thing happens if I jump because it's this variable is just detecting whether or not we're on the ground. And if we're not on the ground, then it will play the fall loop animation. The blend poses by int or integer node allows you to do the same thing as blending by ball. But instead of just flipping a switch on and off and swapping between two different animations, you can hook up as many animations as you need here."},{"start":"23:01","end":"23:36","startSec":1381.0,"text":"Hence the term integer. And you can kind of think of this as a way of switching between different states. So if I hook up a few different animations here, you can see how the switch works. So I'll just drag in three or four animations. Cheve we have here. I will make sure that one of them isn't additive just because this doesn't work with additive animations. And I'll just connect them up to our blend poses by int node. Remember to add more blend pose input pins, you would right click add blend pin."},{"start":"23:36","end":"24:10","startSec":1416.0,"text":"So again, doing that for however many animations you need to add here. And when I connected up, you'll see that by default the active child index, the integer is zero. So that searches for our blend pose zero animation that we have plugged in. And you can just change that and compile. And depending on what number you choose, it'll pick from the list of animations that you have. Now you can promote this active child index to a variable and set that variable based on something like the player's health, for example."},{"start":"24:10","end":"24:45","startSec":1450.0,"text":"So you could maybe trigger something like an injured run when their health is low or whatever logic is that you need for your character. To do that, you would right click promote to variable. And then you'd name it and set up your variable logic inside your event graph. Lastly, we'll look at blending poses by enumeration, which works in a very similar way to blending by integer. An enumeration is essentially just a named list that doesn't contain any information other than the list itself."},{"start":"24:45","end":"25:21","startSec":1485.0,"text":"And these can be used all over the engine in many different ways and are essentially just a really great way of keeping track of something that might have a few different states, like the player character, for example. So an animation enum could just be a list of names of animations that we recognize of all the different states that the character might be able to blend between, instead of using integers and trying to remember what animation the integer relates to. So let's take a look at how we set one up. If we come back to our content browser here, I right click go to blueprint and choose enumeration."},{"start":"25:21","end":"25:51","startSec":1521.0,"text":"Now I'll just rename this to player states. And if I double click to open this up. Inside here, we can give a description for our enumerator or our enum, which we'll just quickly put in. The different states of the player. Oh, the different. And we can add an enumerator, which is essentially just a name in the list."},{"start":"25:51","end":"26:24","startSec":1551.0,"text":"So we'll put walk in here. We'll add a second called run. And a third called jump. And if we save that now back inside our animation blueprint, if we'd right click and search for player states, you'll see under the blend heading here, we've got blend poses by player states. Now we can't see the list of our names that we added just a moment ago."},{"start":"26:24","end":"26:54","startSec":1584.0,"text":"But if you right click at the bottom of the list here, you can see each of the names that we just added. So you can right click and add those in there. And then just as we would have set it with the the bool with the blend via integer, we can bring our animations in. So whatever we got, we've got run, walk. In fact, I'll use walk in place instead. And we've got jump. I'll bring that in as well."},{"start":"26:54","end":"27:28","startSec":1614.0,"text":"And then remember to set these all to loop. And then I'll plug these in and connect it up to our output pose. And you can see by default, it picks our first, first pose. But you can change this value to cycle through each. And obviously we're just changing this by an integer here. But this active enum value, you could set using a variable inside your event graph, so that when certain logic triggers, you would enter the jump pose."},{"start":"27:28","end":"27:43","startSec":1648.0,"text":"And when certain logic triggers, you would enter the run. So you could set it up that so when you hold shift, we trigger the run pose enum. And then that would activate this and put that through to our output pose."}],"02_AnimBP&TakeRecorder":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Coming back to our zombie walk, you know, we're pretty happy with the lower body, but I think maybe we should experiment a bit more with the upper body and with the arms. So for that we're going to use the layered blend per bone node. Now this allows us to selectively blend different animations together on different parts of the body. So we could split up the body into different groups of bones, giving us a really easy way to separate things like the upper and lower body or the arms and the legs and just affect those parts of the body with the animations that we want."},{"start":"0:34","end":"1:05","startSec":34.7,"text":"In our anim graph, I'm going to right click and search for layered blend per bone and bring in our layered blend per bone node here. I'll also bring in the creep walk, which is, if I remember rightly, the basis of our zombie animation and connect that to the output pose and tick looping. And if we compile, there we go, we have our creep walk playing. I'm then going to bring in our full loop animation because if I double click this to open it"},{"start":"1:05","end":"1:39","startSec":65.8,"text":"up, I know it has some upper body animation on there, but I think it adds some coolness to the zombie walk. So if I plug that into our blend pose is zero pin and set that to looping again and compile, you can see that it's not yet having an effect on our animation. And that's just because we haven't defined which bones we want the animation to play on yet. So selecting our layered blend per bone node again. In the details panel under the config heading, we have layer setup."},{"start":"1:39","end":"2:12","startSec":99.2,"text":"And inside there, we've got index zero. Now this is relating to our blend poses zero input pin. If I was to hit add pin, you'll see we get a new index. So when you want to blend multiple animations together, that's how you do it, but we'll take a look at that in a bit. So under this index heading, we have branch filters where we can add multiple branches and split this animation into different parts of the body or apply it to different parts of the body. So if I hit a plus there, we add a new index and I'm going to give it the name of the first"},{"start":"2:12","end":"2:49","startSec":132.9,"text":"bone in the chain that we want to affect. And because we want to affect the upper body, I'm going to give it spine 04. So that's going to affect the upper chest and everything above that. So if I compile, you can see on the lower body, we have the creep walk playing. And then the upper body, the fall loop, because we have our alpha set to one, that's going to play 100% of the fall loop animation. So if I was to change that to 0.5, for example, you can see that we're now blending half of that animation and we've got some of that creep walk movement underneath."},{"start":"2:49","end":"3:24","startSec":169.9,"text":"Now this is looking kind of cool, but I think we can get something a little better if we break the body up into a few more pieces. So back into our layered blend per bone node, I'm going to add another pin here, duplicate this fall loop animation with control D and connect that to our blend poses one pin because I still like the way that this fall loop animation is affecting our pose and our animation, but I want to break it up so that perhaps we have a different strength of this animation on maybe the arms compared to what we have on the spine."},{"start":"3:24","end":"3:54","startSec":204.4,"text":"So we now have this new index here and under the branch filters, I'm going to add two new branches, one for each arm. So our start bone name is going to be clavicle L for the left arm and bone name for the right arm clavicle R. So if I compile, as you can see, because our blend strength, our blend weight should I say is set to one, we're getting 100% of that fall loop animation on the two"},{"start":"3:54","end":"4:27","startSec":234.6,"text":"arms and 50% of the animation on the spine. So I could tweak this again to something like 0.7 maybe and then compile. So we still get some of that underlying creep walk animation on the arms, but we also have the interesting pose from the fall loop. Now this is looking kind of cool so far, but the head is maybe looking a little too stable and I think with zombies they're always a little bit wobbly and maybe the head is like snapping at you trying to bite you and something that I would think would work quite well for"},{"start":"4:27","end":"5:00","startSec":267.0,"text":"that is the run forward animation because this has got a lot more movement in it and a lot more action going on. So if I add a new pin and plug that into blend poses to and just make sure we're looping that animation, I'm going to cut off the head and just apply this run forward to the head. So if I just shrink that down these two indexes and opened upon newest and add a new branch, I'm going to use neck underscore 01 because I know that that's the first neck bone and"},{"start":"5:00","end":"5:30","startSec":300.4,"text":"we're going to affect everything after that, the tip of the head. So already you can see that's something kind of cool there. It's maybe a little bit strong, but you can imagine him kind of snapping and biting at you. Maybe I can reduce it down to 0.8 perhaps. Yeah that's looking kind of cool there. So I think we could probably call the zombie animation done there. Now you could do the same sort of thing with this animation where you could record it out and create a loop of the animation again."},{"start":"5:30","end":"5:41","startSec":330.6,"text":"You could also open the animation sequencer and bake that down to a control rig which will give you much more control over the loop making sure that there's no pop and you can add in any cool little details that you want to add to really polish it up."}],"03_AnimBP&TakeRecorder":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"We've looked at a lot of different blending nodes that we have available inside the AnimGraph. And now we're going to take a look at state machines. Now this is where you can set up all of this animation logic, but in more of a modular fashion, where you can sort of compartmentalize what your character's animations look like in each state, and then define the rules to transition from one state to another, essentially determining when you can transition from something like your running state into your jumping state, and then into your landing and falling states, or anything really that"},{"start":"0:31","end":"1:06","startSec":31.6,"text":"you want your character to do. Now the reason we build this into a state machine is because if we were to directly use the AnimGraph for all of this logic, instead of making use of these modular building blocks of a state machine, you'd end up with a lot of nodes and you'd probably find it quite difficult to keep track of what's going on. So back into the engine, I've unhooked the animation blending tests that we were kind of experimenting with before for our zombie walk, and hooked back up the logic that already existed for our character in this third person template. And I'm just going to open up the state machine here, our main state state machine."},{"start":"1:06","end":"1:38","startSec":66.8,"text":"So this is an example of a fairly simple state machine where we have a character who can idle, they can run around, and they can jump. Just to understand sort of what's going on here and what these different states are doing, I'm going to hit play inside the level and show us transitioning between the different states. So if I hit play, just make sure that our third person character is set as our preview instance. Strike this out of the way a little bit so we can see the character moving. You can see as we're moving around, we're in the locomotion state."},{"start":"1:38","end":"2:10","startSec":98.8,"text":"But as soon as I jump, you can see that we transition between all the different states that we have set up for the jump. So as we jump, we go into the jump state, and then as we're coming back down, we enter the fall loop, and then as we hit the ground, we're going into that land animation. When that finishes, it transitions back to the locomotion state. When you're setting up a state machine, you'll always have an entry node here at the start, which is typically used to define the default state of your character. So in most common cases with a locomotion setup, that's going to be like your character's"},{"start":"2:10","end":"2:41","startSec":130.6,"text":"idle state. You then drag off this and choose add state, or you could right click and add state and rename that to whatever you like, whatever the state is. And then you can connect it up. And if you double click this, this is where you'd set up all of your animation logic for this state. So typically, these tend to be quite straightforward. You would just drag an animation in and connect it up and hit compile. And you'll see that that animation just plays because that's our entry or our default state."},{"start":"2:41","end":"3:12","startSec":161.9,"text":"Now these can get a bit more complex. For example, you can apply additive animations inside here to the current pose that the character's in. So with this example, it looks like the landing animation would play on top of whatever animation locomotion pose we're currently in. If I reconnect those up and just delete this. But as you can see, these can get quite complex. Now once you've created all the different states for your characters, you'll want to determine when your character is allowed to transition into these different states."},{"start":"3:12","end":"3:48","startSec":192.9,"text":"And you do that by setting up some transition rules, which are these white icons here. Now the main purpose of these transition rules really is to output like a true or a false response. So if I open this up, this is where you would set up the logic to say, okay, what information is going to allow me to transition into this state? In this example, when we're transitioning from the falling to the jump state, we're saying, okay, are we falling? If we are, and our velocity in the Z axis is greater than 100, then yes, you can enter"},{"start":"3:48","end":"4:18","startSec":228.4,"text":"that will allow us to enter the jump state. Now when you have one of these transition rules selected inside the details panel here, you get a preview of what that logic might look like. So it's useful to just have that and not have to double click each time. As you can see as well, when you hover over, you also get a bit of a preview of that. You also have access to the blend settings here where you can control, you know, the duration of the blend into this state and how that blend might be calculated using different"},{"start":"4:18","end":"4:54","startSec":258.7,"text":"curves. And oops, you can even add your own custom curves to that as well. So if you wanted to get into the jump a little quicker, for example, you could change this to 0.95 maybe, and then change how the animation blend is calculated and just get that looking how you want. So a state machine is essentially a collection of many animation graphs containing the logic of what your character should look like in those different states, as well as a place to determine the rules that allow your character to transition into these different states."}],"04_AnimBP&TakeRecorder":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Blending is not only reserved for animations, but you can blend using physics too to get some really unique results, and this can be used for things like maybe something hits into your character and affects the animation that they're playing. Or you can use it for things like a ponytail on your character, or a chain on a skeletal mesh. We'll be looking at two of the primary physics blending functions that we have inside the animation blueprint. We set all bodies below simulate physics and set all bodies below physics blend weight."},{"start":"0:31","end":"1:02","startSec":31.8,"text":"Now the primary difference between these two is, as you can imagine, the blend weight version allows you to control the strength of the physics that you're applying to your character or to your skeletal mesh. So the first set all bodies below simulate physics is great for things like ponytails or chains or anything that you want to be like a completely limp ragdoll. The blend weight option allows you to control how strong that physics blend is going to be on top of your animation, which is great for slight changes to reactions where something"},{"start":"1:02","end":"1:38","startSec":62.6,"text":"might hit your character or if you want an arm to dangle if they've been shot, for example. So we'll take a look in the engine and see how you set these two things up. For physics to work with your character, you need to have a physics asset. Now these are already set up for our character engine, but you can create one by right clicking your character, coming up to create and choosing physics asset. If you choose create and assign, this is going to assign, well, this is going to create the new physics asset and then assign it to your character. But if I open ours up here, you'll see that if we come over to the far right side, this"},{"start":"1:38","end":"2:09","startSec":98.7,"text":"will give us access to our assigned physics asset. This is where you get access to all of the physics collision bodies on your character, where you can create and edit and simulate these different bodies to see how your character is going to react with physics. And you add these to each of your joints and then you would manipulate the size of these so that they encompass most of your mesh. And these will be the actual assets that are reacting with the collision rather than the actual mesh of the character. And once you've set it up, if you hit these two little arrows at the top, you can simulate"},{"start":"2:09","end":"2:41","startSec":129.8,"text":"and test how the collision bodies are reacting with one another. So once you've created your physics asset and you've edited it and tested the simulation to make sure it works okay, you're now ready to start simulating the physics on this skeletal mesh. So I'm going to show you how to set that up on two of our characters here and show you how to set it up in two slightly different ways to show how one might react with your character and one might not."},{"start":"2:41","end":"3:14","startSec":161.7,"text":"So the setup is actually quite simple. If I drag two of our characters into the level here, I can set one up so that it reacts to the player's capsule so we can run into this character and we can set the other up so that it doesn't essentially. But on both of these, in order for the physics to work, what I'm going to do is shift select both and in the details panel, I'll search for simulate physics and just enable that. And then with one of our characters, Quinn here, I'll search for collision and change"},{"start":"3:14","end":"3:45","startSec":194.3,"text":"the preset from physics actor to rag doll. Now using rag doll, it means that our player character won't be able to interact with the physics component or the physics asset of Quinn. Whereas with Manny here, if we keep our collision preset to physics actor, we will be able to interact with them. We will be able to run into them and sort of knock them around. So if I hit play here, you can see that instantly both of our characters fall over and the physics is reacting to the world."},{"start":"3:45","end":"4:17","startSec":225.6,"text":"And if I try and nudge Quinn or knock her around, you can see that we're not able to interact with her. Whereas if we nudge Manny around, you can see that our collision capsule is reacting with Manny's physics asset. Now that we can see that happening on a couple of different skeletal measures just sitting in the level, let's see how we can add that to our player character. So there might be a scenario where you want physics to act on your character because they've"},{"start":"4:17","end":"4:47","startSec":257.3,"text":"been shot in the arm and you want the arm to dangle, for example. To get this set up, we need to do the same two things that we did with our skeletal measures in the level to our player character. So we need to activate simulate physics and we need to set our collision type for the character mesh. Now this is something that we'll do inside our player character blueprint. So if we come back to our content browser, go to third person and blueprints and open up our third person and blueprint here."},{"start":"4:47","end":"5:19","startSec":287.7,"text":"So we're going to be using the two functions that we looked at a minute ago. We want to do settle bodies below simulate physics and settle bodies below physics blend weight. We'll look at the two separately. So first of all, let's set our collision profile for our character mesh. I'm going to click and drag and bring in our character mesh from the components tab on the left here. And I'm going to pull off that output pin and search for set collision profile name, which we have here."},{"start":"5:19","end":"5:52","startSec":319.6,"text":"Now this allows us to set the collision profile via the name. And if we select our mesh here and search for collision, we can see that we have several different presets that we could type in here. Now we could change the characters mesh collision preset by default, but this is typically something you'd want to activate as a certain point within your game. So it's best to set it up within the event graph logic. But what we want to do is set up ragdoll on our collision profile name here."},{"start":"5:52","end":"6:23","startSec":352.2,"text":"So what I'm going to do is type that in. And it's case sensitive. So make sure that you're typing it correctly with the correct cases. And I'll just compile that. I'm now going to right click and search for set all bodies below physics, simulate physics. Now this will allow us to specify a bone name from where we want the physics to begin."},{"start":"6:23","end":"6:54","startSec":383.0,"text":"So just connect these two together. And then in our bone name, I'm just going to pull off here and search for make literal name. And this will allow us to just type a name inside here of a bone that we know we want to use as a starting point for our physics. So here I'm just going to put, let's say, spine 01. And we want to tick new simulation so that it activates every time we trigger the event"},{"start":"6:54","end":"7:25","startSec":414.5,"text":"logic. And we're going to trigger it with a keypad press. So if I right click and just press number one on my keyboard, I can search for, or I can pick up this number one. And when we press, what we'll do is we'll set the collision profile name and we'll set all bodies below spine 01 to simulate physics. Now something I have noticed there, actually, is that that shouldn't be a capital letter. So hopefully that'll correct that."},{"start":"7:25","end":"7:57","startSec":445.6,"text":"So if we jump into our test level again and hit play, you can see that nothing has changed on our character yet. But as soon as I press one, you can see that our character slumps over and all of the bones going from spine 01, all the bone chains after spine 01 are now fully simulated. So we can run around and physics will just be reacting to however our character is moving. Now this can give you some pretty cool results."},{"start":"7:57","end":"8:33","startSec":477.1,"text":"But what if you want to control the strength of the physics? So if I hit escape and come back to our character blueprint here, just going to zoom in a little bit and give ourselves a bit more space. We're going to take a look at, or we're going to add on the physics blend weight function that we looked at earlier. So if I right click, search for set all bodies below physics blend weight."},{"start":"8:33","end":"9:03","startSec":513.3,"text":"We can just connect this on the end because we already have our make literal name. We can plug that in. And let's just experiment and try like a 0.5 blend weight and see what difference we get. So hopefully what we'll have here is the animation of our character running around and jumping around will still play. But we'll get a little bit of physics or 50% of the strength of what we normally would have for the physics playing on top. So if I hit one, we can see they relax."},{"start":"9:03","end":"9:33","startSec":543.7,"text":"And as they run around, you can see the arms are kind of trying to run almost as if they're a little bit drunk. And when I jump, you can see the underlying animation is still kind of reacting and is still animating there. And so you can use this as like hit reactions or like I say, if your character loses an arm or gets shot in the arm and you want that to just dangle so they can't use it anymore or use it at 50% percent strength or whatever."},{"start":"9:33","end":"10:05","startSec":573.9,"text":"This is great for that kind of setup. Now that we have an understanding of physics and how to get that set up on our skeletal meshes, we're going to record this as an animation and then play it back through sequencer using take recorder. And this is great for sort of pre-baking physics animations into a predictable sequence. So I've set up a big Pachinko machine obstacle course for our two skeletal meshes and when I hit play or hit simulate, you can see that they all and interact with the blocks on their"},{"start":"10:05","end":"10:37","startSec":605.5,"text":"way down. And you can see that each time we play it, they do something slightly different. So what we're going to do is record one of these and have that as like a reliable playback for a physics animation. We'll be recording using take recorder and you can access that via window, cinematics, take recorder. Now since version 5.1, this is defaultly enabled in the engine, but if you're using an earlier"},{"start":"10:37","end":"11:08","startSec":637.3,"text":"version, you might find that you have to enable it as a plugin. And you would do that by entering the access in the settings here, go into plugins and just searching for take recorder and activating it there. You probably need to restart your engine, but after that you should be able to access take recorder through the options above. Now take recorder is a great tool that allows you to record and save shots of whatever is happening in your level. Now this might be animation of a character or objects in the level or physics simulations"},{"start":"11:08","end":"11:41","startSec":668.4,"text":"like we're about to do now, or you might even have a mocap actor connected directly to the engine and you want to capture their performance. So it's a really strong virtual production tool that allows you to iterate quite quickly and quite easily in a lot of different ways. So how does it work? Well if we take a look at the UI first, up here you can set the name of your capture and then determine which take you're on quite easily at the top. And this big red button is how you'd start your recording. Up the top left here you can use this icon to clear out any pending takes which would"},{"start":"11:41","end":"12:12","startSec":701.3,"text":"delete any tracks that you have in an open sequence at the bottom. This icon allows you to review your last recording. So once you've captured something you could press that icon and then it'll open the sequence that it recorded into and allow you to play it straight away. This icon will allow you to record into an existing sequence. So if you've got something else you want to happen in the level and that's set up in a sequence you could record into that sequence and have the two things happen at the same time. And with this little drop down box here you can pick one of those sequences that you have"},{"start":"12:12","end":"12:44","startSec":732.2,"text":"in the content browser to record into. Here you can access the takes browser which is essentially where you'll be saving all of your recorded takes. This toggles the sequence for you on and off and this settings cog will open up the general settings for the take recorder. So where you can specify things like where you're saving your takes, timecode settings, audio settings, animation settings and there's a useful thing down here called countdown"},{"start":"12:44","end":"13:18","startSec":764.2,"text":"which by default is normally set to three seconds but for our setup here I've set it to zero seconds just so we can capture everything from the beginning a little more easily without having to wait for a countdown. Now let's go ahead and see if we can capture a take. But before we can record anything with take recorder we have to specify what is we want to record it won't just capture the whole scene for you. So if we come up to the take recorder UI here and hit plus source this is where we can choose things that we have inside our level and we have Mali and we have Quinn."},{"start":"13:18","end":"13:49","startSec":798.4,"text":"So I'll just add those two as a source. Now you can set up presets here so if you're constantly finding that you're trying to capture the same few assets or same few actors you could save these as a preset and then each time you load this up you can load that preset in and it means you won't have to load them in individually each time. Now if I come over to simulate and then quickly hit record when we're simulating you'll see that we're capturing your two animations here and then I press stop and that'll save the"},{"start":"13:49","end":"14:21","startSec":829.4,"text":"sequence. Now the sequence isn't immediately available to preview but we can access it by reviewing our last recording or with our drop down box here based on the name and take that we'd set up earlier. So if we just review our last sequence we can see that as we scrub through we have the animation playing on our two characters where we're no longer relying on the unpredictability of the physics we just have the animations baked onto these two characters here. Now the way that these sequences are set up is you record into a master sequence and each"},{"start":"14:21","end":"14:54","startSec":861.7,"text":"actor that you add as a source gets their own subsequence which means that you could double click to open these subsequences and edit all the content individually. Now before you can do any editing you'll find that the sequences by default come locked so if you just click the lock up there that will allow you to move them around, retime things, you can even add and edit animations inside here using control rig and anything that you'd normally be able to do with animations inside a sequencer."},{"start":"14:54","end":"15:30","startSec":894.4,"text":"Whenever you've finished making any sort of animation edits you could always right click your character and then bake animation sequence so that you have that as its own animation sequence that you could use somewhere else in the project. And to return to take recorder to capture something new you just hit the back arrow at the top here. All that will do is reset your sequencer and start you off with a new take. So something else you can do with take recorder is record live gameplay so if we were to hit plus source and add our player to our capture list I'll toggle off the two skeleton meshes"},{"start":"15:30","end":"16:01","startSec":930.0,"text":"that we were capturing before and if I hit play and then record you can see that we're now capturing our character's performance. So if there was some sort of locomotion thing you wanted to capture of your character moving around the level and you wanted to show off all your animation blueprint work that you had this would be a great way to do that. If I hit escape we can review this capture and scrub through and just see the animation playing and you can do the same sort of things here."},{"start":"16:01","end":"16:32","startSec":961.4,"text":"So with this we could throw in a control rig, we could edit the animation, change the timings, clean it up and then bake it out again once you're happy with it and you can use it elsewhere in the project. Just before wrapping up I wanted to share this slide that has some useful links on here for things like more information on blend nodes within the engine, how to set up your physics assets in the editor, also how to connect a mocap solution to the engine so you can preview your actors inside, as well as a pretty useful link for some more information"},{"start":"16:32","end":"17:05","startSec":992.6,"text":"on physics driven animation inside the engine. So just to wrap up we've covered quite a few different things in this course. We've seen a handful of different ways in how we can blend animations together, whether that's blending them additively or cross blending them and then choosing different parts of our skeletal mesh to blend these animations with. Then we took a brief look at state machines and saw how one of those might be constructed and even branched out into blending with physics, before then seeing how we can capture everything with take recorder and save our animations out to use elsewhere in the project."},{"start":"17:05","end":"17:13","startSec":1025.1,"text":"So thank you very much for listening and working along if you did and if you want to keep developing be sure to check out the other animation courses we have available and best of luck with animation blending in the future."}]},"207.03":{"PGT_207.03_01_Introduction":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"I'm Erika Penck. I'm your Unreal Authorized Instructor for today, and we're doing retargeting in crowds. And you guys are in for a treat. So I want to give a big thanks to Alex Paschel, who created the content for this course. And here's what we're going over today. So retargeting is what allows you to download animations from the Marketplace or Mixamo and apply it to your character or apply it to your metahuman, for example."},{"start":"0:30","end":"1:01","startSec":30.7,"text":"We'll cover how to create and control blend spaces, which are useful for transitioning between animations in games. We'll even build off of our retargeting exercise to complete the navigation in crowds portion. And that will allow you to potentially fill out a scene of pedestrians walking along a sidewalk that you don't want to hand anime. And today, all you need to do is open up a third-person template project, turn on the Take Recorder plugin, and then you're ready to follow along."}],"PGT_207.03_02_Animation Retargeting- Setup":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"All right, animation retargeting. Let's get started. So retargeting, it allows animations to be reused between characters with the same skeleton and they could have vastly different proportions. Now Unreal, it uses a concept called a rig, which I would have called bone mapping, and it acts as the translator from one character to another. The character's proportions may be different, but the skeletons need to be similar enough"},{"start":"0:33","end":"1:04","startSec":33.6,"text":"to be mapped to the same bone mapping. And what I mean by that is no inserted or missing bones in the middle of the chain. I mean you could have a winged angel character and, you know, if the angel has a similar skeletal structure to a human that you already have in the level, except the only difference is it has wings, that is fine. You would not be able to retarget motion from a biped character to say a cat that walks on all fours."},{"start":"1:04","end":"1:38","startSec":64.9,"text":"But you could retarget from a quadruped to another quadruped. And I also want to mention the concept of the bind pose. And just for now, I want you to know that if the original pose of your character is different than the one that you are retargeting to, it will affect the fidelity of the animation. And there's ways to work around that, but keep that in mind when you are retargeting. Okay, so I want us to go ahead and dive into Unreal."},{"start":"1:40","end":"2:11","startSec":100.0,"text":"So I'm here in the engine, and what you can do to follow along is go to File, New Project, select the Games Template, hit Next, and grab the Third Person Template. It's got some good animations for this demo. Hit Next. Find a good folder path for your project. I called this project Retargeting Crowds. You can call it whatever you like. Hit Create Project."},{"start":"2:11","end":"2:43","startSec":131.3,"text":"I will close the dialog window because I already have a project. And then the next thing I would like you to do is go to your Epic Games launcher and select the Marketplace tab. And then in the Search Products section, type in Infinity Blade. Now we're looking for the Infinity Blade Warriors pack. And these characters were designed specifically for the skeleton that isn't Unreal, so this"},{"start":"2:43","end":"3:16","startSec":163.8,"text":"is perfect for a retargeting example. Now I already own this pack, so you might have a different button right here. Go ahead and click on that, but then you'll have the option to add to project. And then it says, no compatible projects. It's actually okay. There's no blueprint functionality that would clash with code or anything like that. So just select Show All Projects. Grab your project. And I know the red letters look a little scary."},{"start":"3:16","end":"3:45","startSec":196.4,"text":"It's okay. Just select 4.26, Add to Project, and I promise it will actually be okay. And we'll let that come in. So I'm back in the engine. I'm going to click the Show or Hide Sources panel. And then on the left, you'll notice we now have an Infinity Blade Warriors folder. And next up, we will talk about the Retarget Manager."}],"PGT_207.03_03_Animation Retargeting- Manager":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Okay, so we are talking about the Retarget Manager, and I will dive right back into Unreal, and let's take a look at the Infinity Blade Warriors and go into the Character folder, double-click on Complete Characters, and there we have our different skeletal meshes, our warrior people. And I'm actually going to first rename the skeleton,"},{"start":"0:33","end":"1:03","startSec":33.6,"text":"because if I show you the name of the skeleton for the base character that's in the level right now, and I click on the magnifying glass next to the skeletal mesh in the Details panel, click on that, the name is very similar. I can double-click on UE4 Mannequin Skeleton, and we will use that later, and I'll just keep that tab up at the top, and then if I go back to Third Person Example Map, go back to the Complete Characters folder,"},{"start":"1:03","end":"1:34","startSec":63.9,"text":"let me just click on the SK Mannequin Skeleton, hit F2, and let's change it to Warrior underscore Skeleton, so that will be easier for me to keep track of, and then any time you rename something, any time you move something, any time you delete something, it's a good idea to fix up the Redirectors, so that Unreal is up to date, and it's not accidentally pointing to something that doesn't exist anymore,"},{"start":"1:35","end":"2:06","startSec":95.6,"text":"and then I'm just going to right-click on the Infinity Blade Warriors, choose Fix Up Redirectors in the folder, and let it do its thing, and it's more applicable if I had already brought the assets into the level, because there's more references, but I just wanted to go ahead and show that to you, so you've got it in your back pocket. Okay, so Inside Character, Complete Characters, double-click on the Warrior Skeleton, and dock the tab up at the top."},{"start":"2:07","end":"2:37","startSec":127.4,"text":"Now, I'm going to switch over to the UE4 Mannequin Skeleton tab, and I want to show you these sub-editors, because Unreal Engine 4, it contains four major tools for working with skeletal animations and skeletal meshes. The Skeleton Editor, the Skeletal Mesh Editor, the Animation Editor, and Animation Blueprint Editor, and you can access all of them by using the navigation breadcrumbs up at the top,"},{"start":"2:37","end":"3:10","startSec":157.8,"text":"so I can double-click, and now I'm in the Skeletal Mesh section, and I have a new tab, but I will close that for now, because if we're dealing with the Retarget Manager, I want you to think, okay, Skeletal Sub-Editor. Now, if you don't have the Retarget Manager, what you can do is go to Window, and then find the Retarget Manager, click on that, and then it will pop right up. But first, let's look at the Skeletal Tree,"},{"start":"3:11","end":"3:41","startSec":191.5,"text":"and then if I click on some of these bones, and I can actually go up to Character, Bones, and let's show the entire hierarchy for now, so All Hierarchy. There we go, that's easier to see. And I just want to point out that these finger bones on the middle and the pinky, they actually do exist, but they have zero influence on the mesh, and that's why they're grayed out."},{"start":"3:41","end":"4:13","startSec":221.7,"text":"So I thought that was a clever way of using the exact same bone structure with different functionality by having different influences or lack of influences on the bones. So really, only the index and this middle finger are affecting this clump of finger geometry. But let's get into the Retarget Manager, so click on that tab, and do you see this section that says Setup Rig? This is what I mean by Bone Mapping Section,"},{"start":"4:13","end":"4:46","startSec":254.0,"text":"and first thing you have to do is select the rig and choose Humanoid Rig, and that default is actually based on the exact same bone structure in the base skeleton. So if I look at this Skeleton Tree, you'll see, okay, root, pelvis, spine one, two, etc. If I go back to Warrior Skeleton, look, it's the exact same thing in that Target column. The Source column refers to the bones of the current character. So what I'm going to do is hit Save up at the very top"},{"start":"4:48","end":"5:17","startSec":288.0,"text":"and click on that, and you might be tempted to click this Save button that's in the Bone Mapping section, but that will actually save the bone mapping to its own asset file, and it's useful if you have a complex setup, and then you can load it later, and if your bones have different names, you could try the Auto Map, and Unreal will do its best guess, and then there's also the Show Advanced,"},{"start":"5:18","end":"5:46","startSec":318.7,"text":"and that shows things like fingers and twist bones and IK bones, things like that. So I will go back and click Show Base. Okay, and you would think that we would be done, and we did the bone mapping on one character, so we should be able to move on to the next step, but we actually have to go to UE4 Manic and Skeleton and make sure that they are both talking to the bone mapping translator."},{"start":"5:48","end":"6:17","startSec":348.7,"text":"So I'm going to, again, select Humanoid Rig, even though it's the exact same thing, right, and hit Save. So now these characters can talk to each other, but I want to be a little bit more precise and make sure that the motion that gets transferred looks right. So I will go to the Skeleton Tree, and I'm going to do this for both characters, and under Options, I will go to Show Retargeting Options,"},{"start":"6:18","end":"6:50","startSec":378.8,"text":"and I want to double check and make sure that the root is set to Animation, that Animation Scaled is chosen for Pelvis, and then everything else should be Skeleton except for the IK bones. Those could be set to Animation, and what I'll do is I will click on the IK foot root and right-click and recursively set that to Animation,"},{"start":"6:51","end":"7:22","startSec":411.3,"text":"and then do that one more time for the IK hand root. Okay, let's hit Save, and then I will explain what I just did. Translation Retargeting Now, Translation Retargeting, it's used to make sure that when we retarget, the motion looks appropriate for the proportions of the character. Now, for things like the root and IK bones, you want it to listen strictly to the mocap data."},{"start":"7:23","end":"7:52","startSec":443.5,"text":"For everything except for the pelvis, usually, you want the bone data to also take into account the proportions of the current character, not what was on the mocap data of the original person recording the motion. And then Animation Scaled, it's a combination of the two, and that way you can listen to the mocap data and then multiply it by the difference in height of the pelvis. So we've got that. Let's do the same on the Warrior Skeleton."},{"start":"7:54","end":"8:24","startSec":474.0,"text":"So I'm going to Skeleton Tree, clicking Options, Show Retargeting Options, leave the first one on Animation, change Pelvis to Animation Scaled. It looks like everything else is Skeleton and IK is already set to Animation. Good. All right. So let me save and I'll double check that I saved on the previous one. All right. So step one"},{"start":"8:25","end":"8:58","startSec":505.3,"text":"was to do the bone mapping. Step two is to take care of the Skeleton Tree Translation Retargeting. And then step three would be if the poses of our characters were different. Okay. We would need to make sure that they are the same. Otherwise, maybe the arms would be rotated too far one way or the other. And you can click Modify Pose and find an asset loaded on there and then retarget."},{"start":"8:58","end":"9:28","startSec":538.1,"text":"But the pose is the same so we don't have to worry about that. Okay. So let's do some retargeting. Now there's two methods of retargeting. One deals with retargeting animations. The other has to do with telling the skeletal mesh to look at a different skeleton. But for this section, we'll start with just retargeting the animations. Now I'm going to go to my third person example map and I want to find an animation."},{"start":"9:28","end":"9:57","startSec":568.5,"text":"So under Mannequin Animations, let's do the third person run. I will right click on it, go up to Retarget Anim Assets, Duplicate Anim Assets and Retarget. Okay. Back in our slides, you'll notice a picture of a car. Now this is just to remind you that this would never work. So the bone mapping needs to be the same. So that is just a reminder about that."},{"start":"9:58","end":"10:31","startSec":598.9,"text":"Okay. So I'm back in the Retarget Manager and look, our warrior skeleton. It actually shows up. That's a good sign. So I'm going to click on that. I usually keep the retarget checkboxes set to default, but here's what I will do. Rather than it being called a third person run, how about I change third person using the replace functionality and change that to warrior underscore."},{"start":"10:32","end":"11:01","startSec":632.7,"text":"Or you could choose to have a prefix or a suffix. And then rather than it being saved directly on the top folder level game, same thing as content folder, I'm going to change that. And let's create a new folder underneath Infinity Blade Warriors. Let's right click on Infinity Blade Warriors. Let's do a new folder and call it Animations."},{"start":"11:03","end":"11:34","startSec":663.2,"text":"And let's put it in there. And hit okay. So we've got a new path. We changed the name so we don't get confused. Let's hit retarget. And then if I double click on Warrior run, ta-da, looking pretty snazzy. Okay. And we've got the animation sub editor open. I'm going to hit save. And let me go back to third person example map."},{"start":"11:35","end":"12:05","startSec":695.7,"text":"And let's go back to our mannequin animations. And you can actually retarget multiple animations at a time. So let's do that. We did the run. So let me do a shift click and a control click. So I've got everything except for the run. Right click and retarget anim assets. Duplicate anim assets and retarget. Click on Warrior Skeleton."},{"start":"12:06","end":"12:39","startSec":726.5,"text":"Replace third person with Warrior underscore. Change the folder directory to Infinity Blade Warriors animations. Hit okay. Retarget. Okay. And then let's go to that folder. So Infinity Blade Warriors animations. We could double click on it from here or we could go back to the Warrior run tab."},{"start":"12:40","end":"13:00","startSec":760.2,"text":"And in the asset browser, we can click on other animations too. Cool. So I'll hit save and I'll go back to third person example map and do a control shift S. Save all. So that was one way of retargeting. I will show you another way in the next video."}],"PGT_207.03_04_Animation Retargeting- Skeleton":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this video, I'll go over the skeleton retargeting. This way all of our animations are effectively getting retargeted at once. So I'm here in the engine, I'm going to work my way to complete characters folder. So I'm looking at my skeletal meshes and the warrior skeleton again. Now when we retargeted animations, they were automatically duplicated for us."},{"start":"0:31","end":"1:03","startSec":31.2,"text":"With skeleton retargeting, it's a good practice to duplicate the skeletal mesh first. So that way if you goof and you mess up, you've got a backup. So I'll go to the cardboard skeletal mesh, right click, duplicate, and I'm just going to give it an underscore RT suffix so that I know this is the one that's been retargeted. If you are retargeting with multiple characters, maybe you give a little bit more specific suffix"},{"start":"1:03","end":"1:34","startSec":64.0,"text":"so you know which one goes to which. But for now, underscore RT for this example is fine. So I'm going to right click on this newly created skeletal mesh and go up to skeleton and there's this assign skeleton option. So I'm going to click on that. And there's an extra skeleton that came with this pack. It's called Barbarous."},{"start":"1:34","end":"2:07","startSec":94.7,"text":"We haven't done any retargeting on it. That's why we see all of the angry red letters. If I were to accidentally click on warrior skeleton, it would not be the end of the world. Effectively nothing would happen because that's what it's set to right now. And then UE4 mannequin skeleton, that's the one that we want. And we can see that all the bones are matching up. So that's great. I'll hit accept. And then okay, it looks like something happened."},{"start":"2:07","end":"2:41","startSec":127.2,"text":"We just need to make a save. So let me control shift S. And now the asset is saved. But did anything happen? I can't really tell yet. So let me click on the third person character. And then I have this retargeted card word character selected in the content browser. And then if I click on this left arrow so that I can use the currently selected asset"},{"start":"2:41","end":"3:12","startSec":161.4,"text":"instead, I'll hot swap the two. So I'll just click on the left arrow. And now we have the cardboard man right here. So if I hit play, all of the animations that came with Manny are now accessible for the cardboard. So here we go. He's jumping around, running around doing all the same things that Manny was doing. So I will hit escape. And let's do this a couple more times."},{"start":"3:12","end":"3:47","startSec":192.4,"text":"So let me duplicate the golden character. I'll do control W, give him a suffix to let me know that it's the retargeted version. And then right click, skeleton, assign skeleton, grab Manny, hit accept. And then we'll do that for shell, control W, underscore RT, right click, skeleton, assign"},{"start":"3:47","end":"4:27","startSec":227.2,"text":"skeleton, grab the mannequin and hit accept. And I'll say that's good for now. So control shift S. And so now I could swap the mannequin character for the shell character now. So if I hit the left arrow while having the shell character selected and I hit play, okay, we've got yet another character. Great. Escape. Okay. And then one more time with the golden character, hit the left arrow and there's our character"},{"start":"4:27","end":"5:00","startSec":267.0,"text":"number three. Now let's say I accidentally grabbed the wrong one. Maybe I didn't grab golden RT, but I grabbed the original one and then I swapped that asset. Uh oh, the character is in an A pose. It's just in this default position and it's just sliding around. Oops, I did something wrong. And even if I try to switch it back to, oh yeah, let me switch it to the cardboard RT."},{"start":"5:00","end":"5:32","startSec":300.4,"text":"Okay. And then I hit play. It's still not working. Now the reason is because the animation class got confused when I grabbed a skeletal mesh that was not retargeted. So if that ever happens to you, all you have to do is switch it back to third person anim BP. And then if I hit play, okay, we're back in business. Now this slide, it's just a summary of the different types of retargeting that we've"},{"start":"5:32","end":"6:07","startSec":332.8,"text":"been doing. So in the last video, the first thing we did is set up the bone mapping and bone mapping. That is a mandatory step. The bone mapping is what translates one skeleton to another. Next we edited the translation retargeting to ensure the body proportions match the current skeleton. And then lastly, we briefly talked about bind poses and that is a step that's helpful if your characters have different default poses. Like one is in a pose and the other is in T pose."},{"start":"6:07","end":"6:42","startSec":367.2,"text":"After that, you can retarget the animation, the skeleton, or even the animation blueprints, but that's a topic for another day. And then one more side note, let's say you are retargeting animations from one source and then later you want to retarget a different set of animations that require a different setup. Any new changes that you make won't affect any previously retargeted animations. So new changes will only affect the subsequent animations you retarget."},{"start":"6:42","end":"6:46","startSec":402.1,"text":"So that's animation retargeting. In the next video we're going to talk about blend spaces."}],"PGT_207.03_05_Blend Spaces":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Blend Spaces are assets that allow you to blend animations based on one or more values like speed or direction, for example. And Blend Spaces, they're more of a game design concept and were designed to reduce the amount of animation assets necessary for the unpredictability of dynamic gameplay. So again, Blend Spaces, they use one or more float values to determine how much influence"},{"start":"0:32","end":"1:05","startSec":32.0,"text":"an animation has in the final blended motion. And I'm just going to rebuild the current default Blend Space behavior that's in the engine. So if I hit play, I've got my cardboard man and as I drive around, he transitions from the idle to the running animation based on the speed. So let's create a new Blend Space. You can make a one dimensional Blend Space or a two dimensional Blend Space, which is the default."},{"start":"1:05","end":"1:42","startSec":65.7,"text":"And you can make a Blend Space from a skeletal mesh or a skeleton, actually. I could right click on our cardboard retargeted man and I could go to create Blend Space 1D. Or if you can't remember which skeleton the skeletal mesh is using, you could go to skeleton, find skeleton, and then it zips us to our mannequin skeleton. So since we're here, I'll just right click on the skeleton, create Blend Space 1D and"},{"start":"1:42","end":"2:17","startSec":102.3,"text":"I'll call it BS demo idle one. So I will open that up and dock the tab. And we're looking at our new interface. So let's drop in some animations and adjust the horizontal axis. So if I go back to our Blend Space, let's change the name of the horizontal access to"},{"start":"2:17","end":"2:51","startSec":137.2,"text":"speed and change the maximum value to 375, which is what the engine uses. And I'm going to keep the number of grid divisions to four, but if you need more slots for animations, feel free to increase that in the future. And then there's not much to see right now, but you can preview by dragging the green diamond. But to make things more interesting, if I want to add a run animation, all I have to"},{"start":"2:51","end":"3:24","startSec":171.6,"text":"do is go to the asset browser and then just click drag third person run and a diamond will appear depending on which line I'm closest to with the mouse. So I'll just go to the far right and release. And now Manny is running. And if you did not see the asset browser, you can go to window and you should be able to find asset browser right there. And then I also want my character to idle when it's not in motion."},{"start":"3:24","end":"3:54","startSec":204.8,"text":"So I will drag third person idle all the way to the left and release. And if you don't want to click drag the little diamond, if you hit the shift button on your keyboard, you can release the mouse and all you have to do is move your mouse. You don't have to click. So we are idling and now we're running. Ta-da! Okay."},{"start":"3:59","end":"4:30","startSec":239.8,"text":"And then one more, let's add the walk. Third person walk, I'll drag that to the line that's second from the left. And if you ever decide to change the animation, all you have to do is just drag a new animation on top of that diamond and then it will swap it out. And if you need to reduce the number of transitions, you could just click a diamond, hit the delete key on your keyboard."},{"start":"4:30","end":"5:00","startSec":270.0,"text":"But I want to put the walk animation back. All right, let's hit save. And we could also choose to make a 2D blend space. And you'll notice that instead of just having a horizontal axis, there's also a vertical axis. So you could have both speed and direction or you don't have to be limited to those examples. And the complexity, it increases as you can see."},{"start":"5:00","end":"5:15","startSec":300.7,"text":"And without this system, I mean, imagine having an individual animation represented for each of these different combinations. So it's nice that you don't have to do that. That's a brief introduction to blend spaces. And in the next video, we will work on the crowd simulation."}],"PGT_207.03_06_Crowd Simulation- Character":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Okay, so moving right along, we are going to use the retargeted characters for crowd simulation. So these characters will randomly move from point A to point B within a designated region, useful for crowd scenes because we can record the results. And then there's no need to re-simulate over and over again. Once we record, we can reuse it however we want."},{"start":"0:31","end":"1:04","startSec":31.5,"text":"So first thing is to set up the navigation region. And let's go to Unreal to do that. So I'm going to look at the place actors tab in the top left. And I will just type in the word nav because we're going to bring in the nav mesh bounds of volume. Now we don't see anything green yet. And sometimes if I don't make sure that my viewport is active, this next hotkey to make"},{"start":"1:04","end":"1:38","startSec":64.6,"text":"the navigation region visible doesn't always work. So you know, just kind of click around in there and make sure the viewport is active. Then you should be able to hit P. And look, we are now seeing the happy green region for our crowds to walk around. So it's a very small space right now, but we can adjust it. We can scale up the region. Let's make it a bit larger."},{"start":"1:38","end":"2:09","startSec":98.1,"text":"Keep going a bit more until we are happy with the results. So something like that. Either way, to see the region, if we can't remember P for pathfinding or P for navigation, you can go up to show in the viewport. And then you'll notice that navigation has the P hotkey. It will tell you, or you can just click on the checkbox either way."},{"start":"2:09","end":"2:42","startSec":129.6,"text":"And looking at the stairs right here, I know the green slope looks a little different than the stairs, but the characters will actually be able to go up the stairs and onto the platform. So there's that. And then there's also another volume I want to point out to you. It's called the nav modifier volume. So let's say I don't want these crowd agents getting near the main actors of a scene, or maybe I don't want them bottlenecking in this narrow hallway right here between the cube"},{"start":"2:42","end":"3:15","startSec":163.0,"text":"and the platform. So I'll drag in the nav mesh volume. And let me move it over. Okay. And make sure it's low enough so that it's actually intersecting with the ground. Just hit F to zoom in on that volume and I'll just adjust it a little bit. So if I don't have it low enough, then it's not going to do anything. That path is still green down there."},{"start":"3:15","end":"3:47","startSec":195.1,"text":"But now we're good. And if I want to, I can make that a little more narrow and then more of this top portion of the cube is available. Something like that. You can tweak it more. Now I'm going to use the term agent and crowd interchangeably, so we're going to make a class for the agent, crowd, extra that's roaming around in the scene. And to do that, we are going to duplicate the third person character class that already"},{"start":"3:47","end":"4:21","startSec":227.9,"text":"exists and then we're going to strip out a bunch of behavior so it doesn't listen to the user input. We want it to have a different random motion that we will set up later. So let's go back to Unreal. If I go to the third person BP folder and then go to blueprints and then if I click on the third person character and control W to duplicate, I'm going to call this crowd"},{"start":"4:21","end":"4:54","startSec":261.7,"text":"character. So we've got the main third person character. We now also have a crowd character. Double click on your new blueprint class and let's dock the tab up at the top. And you should be in the event graph tab. If for some reason you're in the construction script or the viewport, just move over to the event graph tab and you should see all of these notes."},{"start":"4:54","end":"5:28","startSec":294.9,"text":"And again, we're not doing a ton of coding. We're just going to delete things and we're simplifying this class. And I'm just going to left marquee drag over all of these nodes because we don't want the mouse or the keyboard to be moving our crowd. So I'm just going to hit delete. Yep. I know that might seem a little scary, but it's fine. Delete all of those. And then if I go over to the viewport tab, we don't really need a camera for these crowd"},{"start":"5:28","end":"5:59","startSec":328.2,"text":"characters. So you can delete the camera boom and the follow camera. Delete both of those. And you could also delete these two variables. We are not going to be using those either. So delete and delete base lookup rate and then compile and save. And then one more thing to point out while I'm in this class, there's this component called character movement."},{"start":"5:59","end":"6:32","startSec":359.0,"text":"Now this is what enables different movement modes like running and flying and swimming and walking. And there's a lot of other features too. And the one I want to point out, it has to do with movement avoidance. And so this feature is called RVO avoidance. And if we turn that on, we could control how far away the characters are before they try to avoid each other. So right now it's if we were to turn this on, it would be 500 centimeters and then the"},{"start":"6:32","end":"7:03","startSec":392.5,"text":"characters would turn and move away from each other. And you can crank up the avoidance weight and then the characters will really run away much more fervently. And it's useful for games, especially if you have an enemy character, things like that. But for the purposes of what we're doing, which is more cinematic, we're actually okay with the behavior that we're going to be setting up. But I just wanted to point that out to you. You might need it in the future."},{"start":"7:03","end":"7:22","startSec":423.7,"text":"Okay, so we made a class for the crowd character. In the next video, we're going to make another blueprint class. And this is going to specify the movement from point A to point B along the navigation mesh. So let's do that."}],"PGT_207.03_07_Crowd Simulation- Controller":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"Next, we're going to work on the crowd controller class. So I'm going to the third person example map tab. I'm still in this third person BP blueprints folder. And I'm going to right click in an empty space in the content browser, go to blueprint class. And I'm not going to use any of these common classes because this is pretty specific."},{"start":"0:36","end":"1:07","startSec":36.4,"text":"And I'm actually going to expand the all classes section right here. And I'm going to type in crowd and see which options come up. So AI controller, that looks promising. Detour crowd AI controller, that's the one we're actually going to use. And I just happen to know that this specific blueprint works with the navmesh, which is what we need."},{"start":"1:07","end":"1:45","startSec":68.0,"text":"So click on detour crowd AI controller, hit select. And we will call this crowd controller. There we go. And then double click on that. And go to your event graph. And if for some reason you don't have this event graph tab, I'll close it. Then another way you can get to it is just double click event graph on the left underneath graphs."},{"start":"1:45","end":"2:15","startSec":105.6,"text":"And it's back. So let's talk about this type of blueprint class. Now, AI controller, that class is the parent class of what we selected. We selected the detour crowd AI controller and an AI controller think artificial intelligence when you hear that. And this class, it fakes being a person."},{"start":"2:15","end":"2:48","startSec":135.8,"text":"It doesn't listen to human input. It listens to the environment, to game logic, and it reacts accordingly. Now detour crowd AI controller, it's a child of that. It has a pathfinding component, which talks to the navmesh for pathfinding and collision avoidance for the agents that it's controlling. So let's hook this up. So I'm back in the engine. I don't need event tick. I just need functionality that happens once we hit play."},{"start":"2:48","end":"3:22","startSec":168.9,"text":"So I'm going to delete event tick. We don't need that. And then I'm going to drag off of the execution wire for our very first node. And overall, what we're going to do is we're going to tell any spawned non-player character to find a random spot within a radius of the navmesh. You know, and then move to that and then repeat over and over again. So first things first, let's just type in move to."},{"start":"3:22","end":"3:58","startSec":203.0,"text":"Let's see what options we have. Now, I'm going to pay attention to these options that are underneath the navigation category, because I know that those know how to talk to the navmesh, which is what we want. Now, we're moving to locations. We're not moving to a specific actor. So that tells me move to location or simple move to location would be what I'd want to try. Now, the simple move to location, it has fewer inputs than move to location and it gets the job done."},{"start":"3:58","end":"4:40","startSec":238.7,"text":"So let's use that one. OK. Now, we have two inputs. The first one is controller. Now, that is wanting to know, OK, which blueprint class is controlling all of these crowd agents? And it just so happens that this blueprint class is the one that is doing that. So in order to tell this node that this blueprint is the one that is the controller, you just left click drag off of the blue dot, type in self and get a reference to this blueprint."},{"start":"4:40","end":"5:14","startSec":280.0,"text":"OK, so that's the first input. The second input goal is talking about a goal location. It's a vector. Now, this goal location, we are going to get our current crowd agent, find its location and then move it to a spot within a certain radius on the navmesh. And then that will be the new location that we use. So let's just right click in an empty space."},{"start":"5:14","end":"5:47","startSec":314.7,"text":"Type in get controlled pawn. OK, so get controlled pawn, so that will get all of our crowd characters. So if you have two crowd characters, it will get two. If you have ninety nine, it will get ninety nine. And then the next node to get its current location, it's a context sensitive node, meaning I have to drag off of this node in order for it to appear in the list of possible options."},{"start":"5:47","end":"6:20","startSec":347.6,"text":"And then let's type get actor. There we go, get actor location. And click that. So we have our crowd person, we have its location. If we were to hook in the return value into the goal, nothing would effectively happen because we would be saying, hey, where is our crowd person? Where is it? OK, move it to the spot that it already is, which is really boring."},{"start":"6:20","end":"6:52","startSec":380.1,"text":"So I'm going to move these nodes over to the left because we've got a couple more coming. So next, if I left click drag off of the return value. And type in. Get random reachable point in radius. Notice it's under the navigation category, so it's working with the navmesh. Click on that and make sure you change the radius to be something other than zero centimeters."},{"start":"6:52","end":"7:26","startSec":412.1,"text":"So I'm going to do three thousand centimeters. We'll try that. And then now we can hook in this new random location into the goal. And let's compile and save that, but it doesn't work quite yet. We need to tell our non-player character to listen to our controller class. They don't talk to each other yet. So if we go to the crowd character class and go up to class defaults up at the top."},{"start":"7:26","end":"8:00","startSec":446.5,"text":"Under pawn. We want to make sure that the AI controller class is not set to the original AI controller, but is set to crowd controller. So the name that you see here should match whatever you typed for your crowd controller class. OK, so switch that to crowd controller, compile and save. And you'll notice the details panel when you have class defaults looks different than if you are selecting a component or something."},{"start":"8:00","end":"8:36","startSec":480.4,"text":"So the detail panel is context sensitive. According to whatever you have selected. So let's go back to third person example and let's drag in a couple crowd characters. OK. And then let's hit play. OK, they moved once and then they stopped. So let's view that one more time and maybe we'll add in a couple more characters."},{"start":"8:36","end":"9:08","startSec":516.5,"text":"Just so it's a little easier to catch. OK, so let's hit play. OK, they moved and stopped. That one went a little further than that one. OK. So I will hit escape. Now, if for some reason this did not work for you, I would say, OK, double check the radius. So if you go to the crowd controller, this radius, make sure that is not set to zero."},{"start":"9:08","end":"9:41","startSec":548.6,"text":"Make sure in your crowd character class under class defaults that the AI controller class is set to your controller class. And then, you know, make sure you actually do have a nav mesh in the level. And those would be the first three things I would double check if it did not work. So we've got our crowd characters set up and the crowd agents and the controller classes that talk to each other."},{"start":"9:41","end":"9:47","startSec":581.0,"text":"They work with the nav mesh. And in the next video, we'll make further adjustments to the movement and the speed of the characters."}],"PGT_207.03_08_Crowd Simulation- Adjustments":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Now I mentioned we're going to make some modifications to the crowd system. So first thing I want to slow down the characters so they're not running around. And to do that let's go to crowd character blueprint. And we're going to go to the character movement component. Let's search for max walk speed."},{"start":"0:32","end":"1:03","startSec":32.5,"text":"Currently it's set to 600. Now we've already talked about blend spaces but let's revisit that concept so we can pick a good value so it's walking comfortably. So if I go to third person example map and go to mannequin animations, double click on third person idle run 2D. And then let's just hover over these values."},{"start":"1:03","end":"1:39","startSec":63.9,"text":"OK so I have a feeling 93.75 is going to be what we want because that is where the third person walk animation is introduced. If it's zero he's idling. If it's 375 he's running. And if the value is 600 he's definitely running. So if you just drag back and forth you can test what the animation would look like at different values. But I'm definitely going to do 93.75. So I will close that."},{"start":"1:39","end":"2:10","startSec":99.3,"text":"And go back to crowd character. And let's change the value to 93.75. OK hit save. And then if you remember last time these crowd characters they moved once and then they stopped. So let's go ahead and add the repeat functionality before we test this again. So let's go to crowd controller."},{"start":"2:10","end":"2:53","startSec":130.0,"text":"And what I want to do is just have this move happen over and over again with a little bit of a delay in between. So it's actually really easy to set up. You don't have to know about for loops and things like that. So if I left click drag off of the execution and I just type in delay and it's not the retriggerable delay it's the straight up delay. Let's add that node. And I'm going to drag it up and above the simple move to location because what I'm going to do is say OK once this delay is completed go right back into the move."},{"start":"2:53","end":"3:25","startSec":173.7,"text":"And then delay and then move and continue that process until we're not in play mode anymore. Now point two seconds that's a little fast. I'm going to change that to two seconds and let's test this compile save. Go back to third person example map hit play. OK we've got some people walking around and they're moving all at the same time."},{"start":"3:25","end":"3:56","startSec":205.6,"text":"So they look a little too synchronized. But we can fix that. So if we go back to crowd controller one more thing I'm going to add I'm going to drag off of the duration input and type in random float in range. So it generates a random number between a minute and Max and floats are just numbers that have decimal points."},{"start":"3:56","end":"4:29","startSec":236.2,"text":"So let's say OK between two and five seconds. OK so that way the delays are a little bit offset breaks it up a bit. So we'll do compile save. Go back to third person example map hit play. Let's take a look. OK he moved but the other character didn't so I'd say it's working."},{"start":"4:29","end":"4:39","startSec":269.6,"text":"All right so we've set up the crowd simulation we've made adjustments and in the next video we're going to introduce the power of take recorder."}],"PGT_207.03_09_Record and Review":[{"start":"0:00","end":"0:39","startSec":0.0,"text":"Now last but not least is the Take Recorder section. So we're going to use the Take Recorder plugin to record our crowd simulation. Now as of Engine 4.27, the Take Recorder plugin is by default enabled, but if for some reason you're using an older version or you accidentally disabled it, you can go to Settings, Plugins, type in Take Recorder, and as you can see it's already enabled for me, but you can enable it."},{"start":"0:39","end":"1:16","startSec":39.3,"text":"Restart, save your project, and come back you'll be good to go. Now before I open up the Take Recorder plugin, I first want to take advantage of the retargeted characters that we spent all this time working on earlier in this class. So let's change our crowd to be not just mannequin characters, right? So I'm going to go to the Infinity Blade Warriors folder, go to Character, Complete Characters,"},{"start":"1:16","end":"1:47","startSec":76.0,"text":"and let me grab the golden retargeted character, and then just use the same technique with the left arrow button next to the skeletal mesh details panel on the right. Click that left arrow button and then the mesh hot swaps just instantaneously, and then I'll click another crowd character or another crowd agent, and let's put the shell retargeted character on him using the same left arrow technique."},{"start":"1:47","end":"2:21","startSec":107.9,"text":"And maybe on this guy we'll find another cardboard character and put him on there, and then in the very back let's put the golden guy on there. Okay, so there is our crowd, and let's actually get the Take Recorder to show up. So all you have to do is go to Window, Cinematics, Take Recorder, and then you should see the"},{"start":"2:21","end":"2:54","startSec":141.4,"text":"Take Recorder tab open up and the Sequencer tab. Now I was messing with the interface and normally by default the Take Recorder is a little bit bigger, but I made my level viewport window larger so that I could see my play button, which is going to be important because you have to hit play before you can record. I mean the record button is kind of grayed out right now. There's no sources for it to record so there's not much for it to do."},{"start":"2:54","end":"3:31","startSec":174.4,"text":"So let's add some sources. Now I have one crowd character selected. I could right click on it, go to Select, Select All Crowd Characters, and then that way if I do that and click right there, all of those characters are selected except for the third person guy, which is what we want. And then another way to do that is if I click on one of the crowd people I do Ctrl Shift A, same thing, and then similar to the sequencer where you have a plus track button and then"},{"start":"3:31","end":"4:06","startSec":211.5,"text":"you can add actors. In the Take Recorder you can add a source for it to pay attention to for it to record. So I'm going to hit the plus source button from Actor, Add Current Selection. So now our crowd of five people is going to get recorded. Now I mentioned you have to play first and then record, but the record part's a little tricky sometimes. So if I hit play, alright, I'm just doing my thing, I'm playing the game, but if I try"},{"start":"4:06","end":"4:40","startSec":246.8,"text":"to move my mouse over to the Take Record section, I'm having a hard time getting to the record button. So in order to eject temporarily from the game and then record, there's a hotkey. I want you to remember it's F8. Now my mouse is free, I can hit record and then we have this countdown delay and then it's recording something and then I hit stop."},{"start":"4:40","end":"5:12","startSec":280.7,"text":"And then I'm still playing, let me hit escape. And now I'm back to where I was. And then you might be wondering, okay, where did my take go because I saw it two seconds ago. In order to see the most recent take, you go up to the top of the take recorder and there's this icon that says review the last recording. It looks like a film strip with a little eyeball. And then now we can see our take."},{"start":"5:12","end":"5:43","startSec":312.4,"text":"So we've got more characters in there because we've got the characters that live in the level normally, but we've also got the recorded versions that are spawning in there from the sequencer. Now what if I don't want that delay? You know, the countdown, the 3-2-1 that we saw earlier? It's useful if let's say you're wearing a motion capture suit, but you're also the one operating at the computer and you need some time to run back to your starting mark."},{"start":"5:43","end":"6:15","startSec":343.7,"text":"But you know, we're not doing that. So in order to change that, let's use this return back to the pending take arrow so that we can get ready for a new recording. And then this show hide settings option right here looks like a bunch of gears. If you click on that and you scroll all the way down to user settings, change countdown to zero."},{"start":"6:15","end":"6:50","startSec":375.5,"text":"And now as soon as you hit the record button, it will not have that countdown delay anymore. So if your motion is fast, it's really helpful so you don't accidentally miss part of the motion. So let's try this again. I'm going to hit play and then I'm going to hit F8 record. Let it record for a bit. Okay, stop record, stop playing."},{"start":"6:50","end":"7:29","startSec":410.8,"text":"And then let's go back to the take that we recorded by using the review the last recording button. And here we are. Now I can actually double click on these individual tracks and go inside and see what it recorded. There's an animation track and then we've got the motion. It gets keyframed on the transform track. And if I actually go up and unlock this scene up in the top right, now the red outlines"},{"start":"7:29","end":"8:11","startSec":449.7,"text":"disappear and when I double click inside of a track, I could actually adjust a lot in here. I could shorten the animation. I could delete keyframes. I could make a character hold in a certain position for much longer than it already does. Or let's say in the scene 1 underscore 2, I like all of the motion except for character 5. Well, you know what? I could just delete him and we're fine."},{"start":"8:11","end":"8:45","startSec":491.3,"text":"And in fact, we could just delete that crowd character 5. And then we've got a curated scene of just four extras. Now if it's a little hard to decipher what's going on because we've got twice the number of crowd people, we can go to the world outliner, which again is just like a table of contents for what's in your scene. We can hide the crowd people that are not currently being driven by the sequence that"},{"start":"8:45","end":"9:17","startSec":525.0,"text":"we recorded. And if you're wondering, okay, well, how do I know which ones those are? So if there's not a lightning bolt icon, then it's a normal character that's living in the level all the time. But if it has this lightning bolt, it means the sequence is spawning it into the level temporarily. And so I'm just going to hide the original crowd people. Now this is what we're actually seeing in the level."},{"start":"9:17","end":"9:50","startSec":557.5,"text":"And it looks like we've got one mannequin that snuck in there. And then if we examine this a little bit further, I'm just clicking inside one of the tracks. If I right click on the animation clip and I go to properties, this will tell you, hey, this is where that animation clip was recorded. And we know it's under games, cinematics, takes, etc, etc. Or you could just double click on the square itself with the image."},{"start":"9:50","end":"10:21","startSec":590.7,"text":"And then we can see the walking animation. It's just walking in place. And then all of the transform information is what's moving the character to and fro the space. But if you wanted, and if your characters had different animations, maybe one was walking, one was running, you could swap these out. And if you want to know where the sequences live, we can go to content browser."},{"start":"10:21","end":"10:51","startSec":621.3,"text":"And let's go to cinematics, takes, and it's got a folder generated for us based on today's date. And then we've got the different level sequences. And then we've got different sub scenes for each of those level sequences. And in here, we've got our animation. And then if I go back up here is the crowd character too."},{"start":"10:51","end":"11:11","startSec":651.8,"text":"Let's double click on that. So it's broken up into different animation clips and level sequences. And then if I'm ready to record yet another take, I can go to the return back to the pending take button. And then we're off to the races."}],"PGT_207.03_10_Recap":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"I just want to say thank you for joining me in the Retargeting and Crowds course. So this is just a recap really quickly. We first went over how to reuse animations between different characters of similar skeletal structure and there were two main methods that we went over. The first was animation retargeting and then the second was skeleton retargeting. After that we went over blend spaces."},{"start":"0:31","end":"1:01","startSec":31.7,"text":"So that was if you need to blend between animations in real time during gameplay. And then after that we used our retargeted characters and set up a crowd simulation. And then we used the take recorder system to record the results. So hopefully by now I hope you see the power of Unreal's retargeting features and I wish you all the best and I'll see you next time."}]},"208.01":{"01_Intro":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"Welcome to the intermediate control rig course in Unreal Engine version 5.5. We're going to be following on from the introduction to control rig course, where we'll be continuing to build the rig that we created in that class. This time we'll look at some new tools and techniques that will help simplify and improve the control rig, as well as some new functions and control types to develop your overall control rig knowledge. We'll be continuing to build our rig from the introductory class, building in a more modular series of exercises this time that you can then learn from and use to build into your own rig."},{"start":"0:35","end":"0:57","startSec":35.0,"text":"We'll take a look at a new function called the IK2Bone function, improving on the basic IK node that we were using last time and simplifying our setup, as well as how to create and utilize your own custom functions in your own function library. And then we'll take a look at two other control types, nulls and floats, to see how you can gain an extra level of control within your rig."}],"02_IKTwoBoneFunction":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"The first thing to take a look at will be rebuilding one of our IK arms using a more tailored function, so the IK 2 bone function. Now just by design, this IK 2 bone function is a simpler setup than the basic IK solver we were using previously, so we won't need as many nodes in the rig graph and that will enable us to work a bit more efficiently. It's also specifically designed and can only be used for three joint chains, like arms and legs, where you have the end of the chain or your effector, like your hand or your foot,"},{"start":"0:31","end":"1:04","startSec":31.7,"text":"and then like a lower limb and an upper limb, where you only really need to worry about controlling the end of the chain and then bending the chain at one point towards the pole vector control like the elbow or the knee. So inside the engine here, if I right click inside our rig graph and search for IK 2 bone, this is our IK 2 bone function. Now we can go over here and break down what information the function needs to work properly. So similar to the basic IK solver, we're going to need a primary and a secondary axis,"},{"start":"1:04","end":"1:34","startSec":64.7,"text":"which would be our axis pointing down the bone, the primary axis, and the secondary axis is our up axis. We also then need our pole vector control and our end control, so the end control will be either your hand or your foot in this example, and then it also needs to know the three bones in the chain that you need to be controlling. So it's actually a very straightforward setup once you have your two controls created. Now let's replace the logic for our left IK arm and use this function instead."},{"start":"1:34","end":"2:08","startSec":94.8,"text":"So I'm going to start off by removing the existing IK logic for our left arm. So let's just bring this over here a little bit, and I'm going to alt click to disconnect the basic IK and just drag that over here because we're not going to need it anymore, and bring in our IK 2 bone function. And we're going to start to input the information for our function here. Now looking at the primary and secondary axes, we know from our previous basic IK setup that"},{"start":"2:08","end":"2:44","startSec":128.8,"text":"the primary x axis is 1 and our secondary axis is y minus 1. And just to double check that, we can see primary axis and secondary axis. Now as a reminder, if you want to check on your own skeleton, if you come up to the option box here and make sure display axes on selection is ticked, that way whenever you select one of these bones here, you'll be able to see the orientation axis. Now all we need to do is input the control information and the bone information."},{"start":"2:44","end":"3:19","startSec":164.8,"text":"So for our control, we have the pole vector node first. Now you can use the drop down here that will just search for whatever type you have set here, so it will search for controls. And we want our pole vector L control. Or you could come into the rig graph here and we need to find our end control, so that's going to be our hand control. And from the hierarchy, select it and hit this little arrow to input the information there. Finally our bone change just needs adding. So we're going to start with bone A from the furthest bone from our end control."},{"start":"3:19","end":"3:49","startSec":199.2,"text":"And that's going to be our upper arm. And then bone B will be our lower arm and bone C will be our hand. So if I search in here for upper arm, make sure we grab the left side here. Bone B is going to be our lower arm and again make sure you grab the left side. And bone C is going to be our hand L. And really that's all this node needs, that's all the information it needs to be set up correctly."},{"start":"3:49","end":"4:24","startSec":230.0,"text":"So if I connect up the logic between our basic IK and our AIM node, just hit compile. We should see, there we go, that our IK2 bone function is set up and working as expected. And it really is that simple to set up once you have your controls set up and once you know your primary and secondary axis. And if I open up the function here, just by double clicking."},{"start":"4:24","end":"4:56","startSec":264.1,"text":"And if I double click to open up the function here, you'll see that it's comprised of a whole network of nodes here doing all the logic and all the calculations behind the scenes. And when it's all wrapped up into a container like this, you don't have all of these nodes and all of this spaghetti visible in the main grid graph. And you can see how it really helped to clean up and simplify the setup of your control rig. So as you can see, functions can be extremely powerful and really speed up a lot of your"},{"start":"4:56","end":"5:12","startSec":296.3,"text":"rigging workflow. And something great about them is that they work kind of like a blueprint. So you could create a library of custom functions like this. And as long as you make them public, you can use them across all of the control rigs within your project. And we're going to take a look at how to create one of these next."}],"03_CustomFunctions":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"So let's take a look at creating a custom function of our own. Now it won't be quite as complex as the IK2 bone function, but we're going to set something up to connect our fingers to our finger controls. There are two ways to create a custom function of our own. So we could highlight a handful of nodes inside the rig graph and right click and collapse that logic to a function. Now this is great if you're only using this specific function within this control rig. But if you want to share the function across your entire project, we're going to need to create a function library."},{"start":"0:34","end":"1:08","startSec":34.6,"text":"Now a function library is essentially a traditional control rig asset that acts like a container where you build all of your custom functions. Now as I said previously, they are similar to blueprints where you can create custom functions and then share them across all the control rigs in your project. You just need to make sure that you've set them to public as they're private by default. Now built in that comes with the engine is a standard function library where we've created a lot of different functions for you that do a lot of different things that you can experiment with and learn how they work when you're"},{"start":"1:08","end":"1:41","startSec":68.0,"text":"setting up your own rigs. And the main sort of bonus of them is that they really do help to clean up your rig graph and compartmentalize all these chunks of logic just to make it easier to understand what's going on and simplify the setup as you're creating your control rigs. Now a function library is essentially a traditional control rig asset that acts like a container where you build all of your custom functions. And as I said previously, they're similar to blueprints where you could create a custom function and then share that across all of the control rigs in your project."},{"start":"1:41","end":"2:11","startSec":101.8,"text":"You just need to make sure that you've set the function to public as they're private by default. Now the engine comes with a pre-built standard function library. And this contains a lot of useful pre-made functions that you can already utilize with your control rigs. And a big bonus of them is that you can really do... And a big bonus of them is that they really do help clean up your rig graph and help compartmentalize all these chunks of logic that make it just easier to understand the flow of your logic and more simple to get things set up as you're creating your control rigs."},{"start":"2:13","end":"2:45","startSec":133.3,"text":"Our custom function will connect the transforms of our finger bones to the finger controls, just like an FK chain. And what we're going to need for that is some new controls for our fingers. So let's head back into the project and get started. Back inside our control rig here, you can see that in the rig hierarchy window, I have selected all of the finger bones that we have on our skeleton. I haven't selected the matter couples just because we don't want to create controls for those. And to create these new controls, we can either press control N or we could right"},{"start":"2:45","end":"3:14","startSec":165.2,"text":"click, come up to new and add controls for selected. And then at the bottom of the rig hierarchy here, you can see all of these new controls that we've just created. Now we're going to customize the look of the controls because they're not really very usable at the moment in their current state. So first of all, I'm just going to change the color of the left hand side to blue, so we can see the difference in the viewport. So if I scroll up a little bit, select all of our underscore L controls here."},{"start":"3:15","end":"3:46","startSec":195.6,"text":"I've shift select down to the ring finger here. And then over in the shape properties, I'm just going to make them one of these blue colors and change the shape to something like a box. And what we'll do as well, we'll just scale those down slightly so that they fit a little nicer around our mesh. And what I'm going to do for the right hand side is keep the color red, but also make a box thick."},{"start":"3:47","end":"4:17","startSec":227.5,"text":"And then we just get them in the viewport here. Scale those down as well, just so they fit around our mesh. So now we have our controls created. The last thing we want to do is just reorganize the hierarchy a little bit so that our controls are following their respective hands. So selecting the parent of each of the finger chains here, I'm going to click and hold and drag those underneath the hand L control for the left hand side."},{"start":"4:18","end":"4:49","startSec":258.6,"text":"I just minimize that. And then doing the same thing, clicking the parent of each, holding control, clicking the parent of each chain of controls here and dragging those inside the right hand side. Now we'll see that when we move our right hand arm or right hand control, our finger joints follow and we'll just double check the left side. The same thing is happening with those. So that's perfect."},{"start":"4:52","end":"5:22","startSec":292.8,"text":"Now that we have the components that we need, let's create a new control rig asset to use as our function library and start building our custom function. So on the left hand side here under the my blueprint tab, under the functions heading, I'm just going to hit plus and that'll create a new function for us. And because this is going to be like a simple FK chain, I'm just going to call it easy FK. Now we need to create a couple of input pins for this function."},{"start":"5:22","end":"5:52","startSec":323.0,"text":"And our input pins are going to be the controls that we just created. So the finger controls and then the finger bones that we want the controls to have control over. So if I select the entry pin here, come up to inputs on the top right, hit the plus, we can add a new input that we'll call FK controls. So hit enter. And we're going to change this to a rig element key."},{"start":"5:55","end":"6:29","startSec":355.6,"text":"And because we want to have more than a single input, we'll change the input type from single to array. That means that we can get all of our FK controls at once and connect them up to this entry pin. And the second input is going to be our bones that we want to control. So I'm just going to call that bones and automatically it reuses the previous type of input pin that you created. So we don't need to set that as an array. Now what we want to do is create the logic to get the transforms of our finger controls, our FK controls and use that information to set the"},{"start":"6:30","end":"7:04","startSec":390.4,"text":"transforms of our bones. So if I was to right click and search for get transforms, we want to use the function here and that's denoted by the F symbol rather than the icon for a node here. And you can see that we have an array that we can plug straight in from our items to our FK controls. So that when we're outside in our normal rig graph and we were to drag in this function in the FK controls pin here, we know that that's going to"},{"start":"7:04","end":"7:33","startSec":424.1,"text":"plug into a get transforms function and that will get the information of those controls. Now we're going to use that if I just drag this over here to set the transforms of our bones. So if I search for set transforms and we need an array again because we're setting multiple items. So if we drop that into the rig graph here and connect the logic up, we want to use the transforms of our controls and plug that straight into the transforms of our bones."},{"start":"7:36","end":"8:08","startSec":456.1,"text":"And if we grab our bones input pin here, that's the information that's going to be fed into this set transform array. If I just connect up the logic from here to here and just clean this up with a reroute node by double clicking just so it's a little easier to see things. That's all it takes right now to set up our function. So we're getting the transforms of our controls and then we're using that information to set the transforms of our bones."},{"start":"8:10","end":"8:44","startSec":490.8,"text":"The last thing we need to do is make this function public so that we can use it throughout all of the other control rigs in our project. And that's done on the right hand side here under access specifier. By default, it will be set to private, but we can change that to public. And if we compile and save that. If we were to come back to our finger control control rig here, right click and search for easy FK. You can see that we have access to what we just created. If I zoom in on that, when I double click to open it, you'll see that brings us"},{"start":"8:44","end":"9:16","startSec":524.5,"text":"to our custom function that we made here. Now that we have a custom function created, let's build the logic to tell the function the names of our bones and our controls. To make things more procedural, we're going to build all of this logic based on the names of our bones. So we'll take an array of our finger bones and then generate the finger controls by adding underscore CTRL to the end. We'll then save this information in a variable so that we could use it in the future if we needed to. So first things first, let's create an array of our finger bones."},{"start":"9:16","end":"9:48","startSec":556.8,"text":"So I'll come over to the rig hierarchy and just find all of our finger bones here. And remember, we're not using the metacarpals, so we can ignore those for now. So we'll do the left arm and then the right side. And we'll drag those in and choose create item array. Now this will contain all the bones we just highlighted. I'll just make ourselves a little bit of space over here. Now we want to find our finger control names."},{"start":"9:49","end":"10:19","startSec":589.2,"text":"And to do this, we're going to create a variable, which is simply a container of information and we'll set the information of the variable to be the bones names plus adding underscore CTRL to the end so that we're matching the controls names. Now we could create a variable over in my blueprint tab here by just hitting the plus on a new variable, renaming it, whatever it might be. If I can spell my variable and then changing the type of variable it is."},{"start":"10:20","end":"10:51","startSec":620.5,"text":"So for this, we'd want it to be a rig element key and then setting it to an array because we need it to be an array. You could either right click here or you could come up to the top here and change it from array, sorry, from single to array. And then we know that we have inside this array 30 elements. So we know we have 30 finger bones that we're looking for, which means we're also looking for 30 finger controls. So inside the variable here, if I just compile first, you can see we don't have"},{"start":"10:51","end":"11:25","startSec":651.3,"text":"any array elements just yet, but we could add 30 array elements and then come in here and set these to be our control names. That'll take quite a long time. So I'm just going to bin that for now and delete that variable. And something you can do is drag off our item array here and actually promote this information to a variable itself. And if we just delete this set variable node here, just because we're not going to need it. The variable that we have here, again, if I compile, you'll see that that now has"},{"start":"11:25","end":"11:55","startSec":685.9,"text":"30 elements and it contains all of the information of the array. So we have all of our bone names in here and it sets the type to bone as well, which is really useful. So if I just rename this to be our FK control array, we're going to use the information here and add underscore CTRL to the end to set the name of our controls."},{"start":"11:58","end":"12:30","startSec":718.0,"text":"Now this essentially just speeds us up a little bit. So we don't have to create a new variable and then populate all the 30 array elements. We could promote the item array to a variable and then it does a lot of that work for us. Now if you have several different limbs you're trying to do this for and you've got maybe hundreds of items in your array, you could see how this could speed you up quite a bit. The other thing that's super useful about this is the variable will maintain the order of the bones that we selected. And this ensures that the controls and the bones are connected to each other in the right order."},{"start":"12:30","end":"13:01","startSec":750.5,"text":"Now the first thing we need to do is reset the variable so that we remove the information in there and just have an array with 30 blank elements. Now the reason we do this is so that we can populate all of our information ourselves. We'll use the item array and add underscore CTRL to the end and then that will give us the names of our controls. So let's drag in our variable and choose get FK control array. And if we drag off the value pin we can search for reset."},{"start":"13:05","end":"13:42","startSec":785.3,"text":"And if we just connect this up to our logic, what I'm going to do is hold S and left click to get a sequence node just so we can break up the logic into two different flows and just understand it a little better. I'll then connect that up to our reset pin. Let's move these out of the way because we don't need them just yet. And what this is doing now is emptying out all the information inside the variable that we have. And just as a bit of proof for that, if we search for a print node and connect up our reset array output pin"},{"start":"13:43","end":"14:19","startSec":823.5,"text":"to the value of the print node, you'll see that as I hover over here we're not really getting any information out of it. Whereas if I connect this straight up, you can see that as we hover over we've got all of the names of our bones in that array. If I just reconnect this and get rid of that. Our next step is to repopulate this variable with the control name information. So I'm going to drag off our item array here that contains all of our bone names and search for or each."},{"start":"14:20","end":"14:45","startSec":860.5,"text":"And this will run over and do some logic for each item inside the array. So if I just connect the executes up there. And what we want to do here if I just open up element is out of the name tab we want to add or concatenate. Underscore CTRL. So for that we'll use the concatenate node. And add underscore CTRL inside the beep in here."},{"start":"14:50","end":"15:21","startSec":890.5,"text":"Now that we have our array information and the name update information, we want to add these two together and add them to the array. So if I right click and search for add and we scroll to the top here make sure under the array here we have our name and the name. And we're going to click on the name tab heading and choose that add node there. I connect up the logic and connect up our empty array here, our variable that contains just those 30 array elements."},{"start":"15:22","end":"15:57","startSec":922.5,"text":"We pop open element make sure we change this to control. Because that's the output that we're looking for. We're looking for our control names. And then I'll just connect up the name pin from our concatenate or the result pin to the name pin of our add node. Now the information outside of this new array if we search for a print again should be giving us our control names now. Because what we've done is we've taken our variable with the bone names in it and we've reset it so we've removed all the information but maintained the fact that there are 30 array elements."},{"start":"15:58","end":"16:28","startSec":958.5,"text":"And then we've taken our array information so our bone information and for each of the elements in the array we have added underscore CTRL. And then we've taken our empty variable or so empty array and added that to the underscore CTRL. And if we hover over here you can see that all the names that we have inside the array now have that underscore CTRL at the end and that will be our control names. We can just delete that again for now."},{"start":"16:30","end":"17:07","startSec":990.5,"text":"And now we should be able to connect up all our logic because we have our control names coming out of here and our bone names coming out of here. So let's see what happens. So if we connect our bones to the bones input pin and our custom function and then connect the control names to our FK controls input pin. To connect this logic up we want to come off the for each completed pin. And the reason we do that is because we want to we want the logic to run after we've completed this extra bit of logic per array element."},{"start":"17:09","end":"17:39","startSec":1029.5,"text":"So now if I compile we can see we've got a little bit of an issue so let's see where that where that problem is. So first things first let's create an array of our finger bones. So I'll come over to the rig hierarchy and just find all of our finger bones here. And remember we're not using the matter couples so we can ignore those for now. So we'll do the left arm and then the right side. And we'll drag those in and choose create item array."},{"start":"17:40","end":"18:17","startSec":1060.5,"text":"Now this will contain all the bones we just highlighted. I just make ourselves a little bit of space over here. Now we want to find our finger control names and to do this we're going to create a variable which is simply a container of information. And we'll set the information of the variable to be the bones names plus adding underscore CTRL to the end so that we're matching the controls names. Now we could create a variable over in my blueprint tab here by just hitting the plus on a new variable renaming it whatever it might mean."},{"start":"18:18","end":"18:48","startSec":1098.5,"text":"If I can spell my variable and then changing the type of variable it is. So for this we'd want it to be a rig element key and then setting it to an array because we need it to be an array. You could add the right click here or you could come up to the top here and change it from array sorry from single to array. And then we know that we have inside this array 30 elements so we know we have 30 finger bones that we're looking for which means we're also looking for 30 finger controls."},{"start":"18:49","end":"19:22","startSec":1129.5,"text":"So inside the variable here if I just compile first you can see we don't have any array elements just yet but we could add 30 array elements and then come in here and set these to be our control names. That'll take quite a long time so I'm just going to bin that for now and delete that variable. And something you can do is drag off our item array here and actually promote this information to a variable itself. If we just delete this set variable node here just because we're not going to need it."},{"start":"19:23","end":"19:59","startSec":1163.5,"text":"The variable that we have here again if I compile you'll see that that now has 30 elements and it contains all of the information of the array. So we have all of our bone names in here and it sets the type to bone as well which is really useful. So if I just rename this to be our FK control array. We're going to use the information here and add underscore CTRL to the end to set the name of our controls."},{"start":"20:02","end":"20:34","startSec":1202.5,"text":"Now this essentially just speeds us up a little bit so we don't have to create a new variable and then populate all these 30 array elements. We could promote the item array to a variable and then it does a lot of that work for us. Now if you have several different limbs you're trying to do this for and you've got maybe hundreds of items in your array you could see how this could speed you up quite a bit. The other thing that's super useful about this is the variable will maintain the order of the bones that we selected and this ensures that the controls and the bones are connected to each other in the right order."},{"start":"20:35","end":"21:09","startSec":1235.5,"text":"Now the first thing we need to do is reset the variable and now we should be able to connect up our logic to our custom function because we have our control names coming out of here and our bone names coming out of here and that's all the information we need to feed into it. So let's test it out. Let's plug in the controls and then let's plug in the bones and the order of logic that we want to connect will be the execute pin from the completed of our four each. And the reason we're doing this is because we want to run all of this information first and then once it's completed we then want to continue the flow of logic."},{"start":"21:10","end":"21:38","startSec":1270.5,"text":"So if we compile and I just select some of these finger controls here and frame up on them with F we should be able to see that our finger controls are now driving our finger bones. And because we set this up procedurally if we were to update this item array with more bones that have corresponding controls that would automatically update and feed into our custom function and then they would automatically connect and start driving the bones."}],"04_AlternateFingerSetup":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Now that we've set up the fingers using a custom function, we're going to explore an alternate setup that will use a couple of different nodes, the getChildren node and the parent constraint node. So instead of using a series of set and getTransform nodes, we're going to use the getChildren node, which does exactly what it implies, it will find all of the children of a specific reg element. And in this case, we'll use our hand bones to find all of the finger bones below, and again, use that information to find all of our finger controls as well."},{"start":"0:33","end":"1:04","startSec":33.0,"text":"So with our getChildren nodes, if I right click, search for getChildren, you can see we can input a name here and essentially an item, a reg element, and it will find all of the children of whatever we input here. Now we do want to look for a bone, and we want to look for handL. Now I'm going to duplicate this because we want to use, well, we want to find the bones for both of our hands. So if I find handR there."},{"start":"1:04","end":"1:35","startSec":64.6,"text":"Now what we want to do, just to make the logic a little bit more straightforward, is add these two arrays together. So if I right click and search for add under the array heading here, we'll plug the first array in here, and then it's not add, what is it? It is append. So we want to append the two arrays together, which is just essentially tagging one onto the end of the other."},{"start":"1:35","end":"2:08","startSec":95.7,"text":"So now that we have a big list of our bones underneath our hand, left and our handR. Now something we need to activate is recursive. What this will do is find all of the children of the hand's children. So if I show you this as an example, under our handR, the real children are the pinky metacarpal, the ring metacarpal, and the middle metacarpal. So essentially the parents of our new smaller chains here. And with recursive ticked, what that will do is search through all the way to the end"},{"start":"2:08","end":"2:39","startSec":128.9,"text":"of the chain. And making sure include parent is unticked means we won't affect the actual hand bone itself. Now what we want to do, something called a forEach, and this will loop through each element of the array. And we're going to connect our appended arrays together to this forEach."},{"start":"2:39","end":"3:11","startSec":159.0,"text":"And then we're going to create a parent constraint node. And what we want to do here is plug in our child, which will be our bones. And then our parent is going to come from the name of our forEach."},{"start":"3:11","end":"3:46","startSec":191.6,"text":"We'll use another concat node, underscore control. So that means that for the end of all of our bone names here, we're going to add underscore control. And then inside the item of parents, we're going to drop the name in there, change that to control. And hopefully we should see if we connect up this logic to the main forward solve. What I'll do here is just create a sequence just to make this a little clearer about how this logic is working, just so we can compartmentalize things a little bit."},{"start":"3:46","end":"4:21","startSec":226.0,"text":"And what we should see now is that our finger control actually controls our bones. So if I was to just disconnect here, just to make sure we're not seeing anything tricky, nothing works yet. And when we reconnect our logic back up, we can see that it works straight away. So that's just another way to simply connect your controls with your bones. By building all of the logic off the name of your bones, appending the two arrays together,"},{"start":"4:21","end":"4:35","startSec":261.1,"text":"and then for each of the elements in the array, adding underscore control to the name so that we can use that as our parent inside the parent constraint, and then adding the element of the array, which is just the bone names themselves as the child of our parent constraint."}],"05_Nulls":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"The next thing that we're going to take a look at are nulls. Now nulls you can imagine work in a similar way to groups in Maya, where they help you add essentially just an extra layer of control within your hierarchy. We're going to add a null into the hierarchy of our control rig to give us control over the head's rotation, whilst it's also aiming at the head control. So we can sort of tilt the head if we want to while it's turning and just add the extra level of control. So the logical workers follows."},{"start":"0:30","end":"1:01","startSec":30.9,"text":"The new head control, which is this ring around our character's head at the moment, will be a child of the null. And the null is this sort of orange, three-pointed shape that you can see inside the character's head. And this control is basically going to follow that null wherever it goes. And the null is going to be pointing towards our head aim control, instead of what was the head bone previously. And then this new head control, we'll use that to set the transforms of the head bone,"},{"start":"1:01","end":"1:31","startSec":61.2,"text":"instead of the head aim control that's doing that at the moment. So back inside the engine, we've opened up the head aim control rig, and this is the one we're going to adjust and add a little bit of extra control to. So the first thing we need to do is create our null. And we want to create that at the location of the head, because ultimately that's what we're going to be controlling. So if you right click the head, come up to new and then new null, that'll create a new null for us as a child of the head bone."},{"start":"1:31","end":"2:05","startSec":91.8,"text":"But we want to bring that out of the hierarchy and I'll press Shift P to do that. And if I scroll down to the bottom, I actually want a hierarchy. I actually want to re-parent that into the Spino 1 control, so that wherever the Spino 1 goes, the head will follow. Now you might find by default that you can't actually see your null within the viewport. And if that's the case, you can come up to the option box up here and tick on display nulls. Something else you notice is you can't actually move the null inside the viewport."},{"start":"2:05","end":"2:33","startSec":125.7,"text":"If you needed to move it, you could adjust the values here. Or come up to the top to your solve direction and actually toggle on construction event. Because that's what allows you to move the null within the viewport. But since we're not going to need to move ours, I'm just going to right click it and set initial transforms from closest bone, just to make sure that we haven't made any adjustments to its initial position when we've done the re-parenting."},{"start":"2:36","end":"3:08","startSec":156.6,"text":"Now we need to create our new head control. And we want it to be a child of the null. So I'm going to right click the null, come up to new and create new control. And then I'll bring that up, drop it inside the head null. And again, I'm going to set offset transforms from closest bone, just to make sure that it matches the rotation of the head bone. And I'll just adjust the look of it here so we can match sort of our spine and our root here."},{"start":"3:08","end":"3:42","startSec":188.2,"text":"And scale it up slightly. And we can see we're off 90 degrees in the y-axis, so I'm just going to add 90 there. And probably make it just a touch bigger. Maybe make that three. There we go, that's a little better. And I'm going to rename that to be our head underscore control. So if I right click rename, head underscore CTRL. So in our hierarchy, we now have a new head null at the location of the head bone."},{"start":"3:42","end":"4:12","startSec":222.1,"text":"A child of that null is our head control, which means wherever that head null goes, this head control is going to follow. Now all we need to do is update our aim logic so that our head null is pointing towards the head aim control. And then set the transforms of our head bone with the new head control that we just created. So inside the head aim setup just here, we're going to change the item to a null and then input our head null."},{"start":"4:12","end":"4:42","startSec":252.1,"text":"And we'll see that as we move this, we can see our control low, which is a child of the null, is actually now moving when we move the head aim control. We come back and make sure display nulls is just turned on. We can also see that the null is now pointing towards this head aim control. Now all we need to do is tell the null to control the head control, sorry, to control the head bone."},{"start":"4:44","end":"5:18","startSec":284.1,"text":"And we'll do that with, well, a set transform and a get transform node. And we'll do that by dragging the head in and choosing set bone and then dragging the head control in and choosing get control. So we're going to set the bones transforms based on the head controls transforms, which means that as we move this, the null is moving and pointing at the head aim control, which is in turn moving the head control because it's a child of the null."},{"start":"5:19","end":"5:40","startSec":319.1,"text":"But then if we move this head control, we also get an extra layer of movement or an extra layer of control on top of the aim. So that if you wanted to make sure something was looking at the aim control and then maybe cocking the head a little bit, that's just a nice little extra level of control that you can have when you're using things like nulls."}],"06_ControlTypes":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"The last thing that we're going to take a look at in this course is a new type of control that we haven't explored yet, and this is going to be the float control. And we want to use it as a slider to make a simple open and close animation for our finger controls. So we're going to use this slider control and convert its translation values along a single axis into rotation values for the finger controls. And we'll do a simple bit of math to then multiply this value just to make sure that it's given us some nice results. And the main thing that we need to know going in is in what axis we want to rotate the fingers."},{"start":"0:35","end":"1:06","startSec":35.6,"text":"So in our case, this is going to be the Z axis, but we'll take a look at that in a moment. So back inside the engine, let's first create our new float control. So I'm just going to right click and come to new control here. And in the details panel, we can change the value type of our control from Euler transform, which is just a traditional control that you can transform with translation and rotation"},{"start":"1:06","end":"1:37","startSec":66.1,"text":"and scale as well. We're going to change that to a float. And now you'll see that the control type changes inside the viewport here. And when we move it, it sort of slides along this line that it's created. So selecting that, I can only move in one axis. Currently that is the X axis. So if we wanted to change that, we could do with the primary axis here, change that to Y and it will move only in the Y axis or Z and it will move only in the Z axis."},{"start":"1:37","end":"2:11","startSec":97.9,"text":"But the X axis works fine for us for now. Now one thing you'll notice as well, we can't move this float control directly in the viewport. So we'll have to create another control as its parent and then use that to move it. So come back to create one more new control and we should probably name these. So let's rename this slider parent and the actual float control will rename slider underscore"},{"start":"2:11","end":"2:43","startSec":131.7,"text":"control. Now we'll drop the slider control inside the slider parent. And then this slider parent, since it's just a Euler transform control, we can actually move that to wherever we'd like it to be. So just for now, I'm just going to put it inside the, up around the waist between the two hands because we're going to set this control up to make fists out of both hands. So something I forgot to do there is actually set the offset transforms so that when we"},{"start":"2:43","end":"3:13","startSec":163.1,"text":"compile it maintains its current location. So we're going to choose set offset transform from current. Now when we compile, that's where the slider parent stays. And what I'm going to do is drop it inside the root control here so that anytime we move our route, this slider is going to come with it. And just so we don't get confused between the two controls, I'm actually going to set the parent to not visible. This means that whenever you use this in a sequence in the engine or whenever we're"},{"start":"3:13","end":"3:44","startSec":193.5,"text":"previewing it in the viewport here, we can't actually see and interact with the slider parent unless we make it visible again. So that when we grab the slider control itself, we're not confusing what we're selecting. So let's customize the look of the slider control a little bit. So I'm just going to change the color to maybe like a purple kind of color. And I'm going to change it to an arrow to solid. And this is just to indicate the direction that the controller is going to move in."},{"start":"3:44","end":"4:16","startSec":224.9,"text":"And currently it's facing the wrong way. So what we can do with this is come to our rotation channels here. And in the Z, we'll put 90. And in the X, I suspect is it minus 90? Nope. And I think it will be in the Y. So minus 90 in the Y. There we go. So now that when we grab our control, let's make it a little bit bigger as well actually. Now that when you grab our control, we know in which direction it's going to move and"},{"start":"4:16","end":"4:51","startSec":256.2,"text":"it just makes a little bit more sense visually. Just as a quick tip, another way that we can actually adjust the position of this control, or at least the rotation of it, is by holding control and pressing the full stop of the period button. That will then set us into the shape transform manipulating mode. So if we wanted to just make sure that we were rotating in the correct direction and not have to worry about using the actual physical sliders over here under the shape transform, we could just do that in the shape transform manipulation mode."},{"start":"4:51","end":"5:21","startSec":291.2,"text":"So if you hold control and press period again, that will just exit that mode for us. Now that we have the slider control looking how we want and positioned in the world where we want, let's take a look at some of its details settings on the right hand side here in the details panel and adjust some of the minimax settings because this line right here at the moment is probably a little bit too long and if you were using this to animate, it would feel probably quite cumbersome inside Sequencer."},{"start":"5:21","end":"5:53","startSec":321.8,"text":"So under the value heading here, we have some minimax settings. Now you might find that this is actually kind of half hidden by default with the width of this details panel. So you can just drag that open a bit bigger and you'll be able to access minimax just here. Now you can see our maximum is set to 100 so I'm just going to bring that down to 20 and you can see in the viewport our line has become a lot shorter and this just means it's going to be easier to manage and we don't need super super fine level of detail to go"},{"start":"5:53","end":"6:30","startSec":353.0,"text":"all the way up to 100 units. But you should adjust this value to whatever works best for your setup. Now that the control is ready to go, let's make a start on the logic. So we're going to set this up in a similar way to our alternate finger controls. We're going to use a couple of get children nodes. So if we search for get children, again we'll get two of these nodes and we're going to look for our right hand control first, duplicate that with control D and then change that to"},{"start":"6:30","end":"7:00","startSec":390.1,"text":"our left hand control. And we're going to add these two together with an append as we did previously. Again making sure that we tick recursive on each of these so that we find all of the children's children and then we're going to pull off here and search for another four each node because we're going to do some logic to each item in the array. And next we want a set transform node because we're going to be setting the transform or"},{"start":"7:00","end":"7:36","startSec":420.6,"text":"setting the rotation of these controls. So if we right click search for set transform. One thing that's important to change here is the space in which these transforms are going to be made. So we want to change it to local space. We're currently set to global space. And this is so that each control rotates around its local axis. And under the item heading here I'm just going to change the type to control. And this is more just for a bit of organization over anything else because when we connect"},{"start":"7:36","end":"8:09","startSec":456.5,"text":"the elements to the item pin here, it doesn't do that. I don't need to do that. And next we need a set transform node to set the transforms of these controls. So if we come across here, search for set transform and we're going to connect our element up to the item pin here and then connect our executes. One thing that's important to change on here, however, is the space that this node is functioning in. And we want to swap from global space to local space."},{"start":"8:09","end":"8:39","startSec":489.3,"text":"This is so that all the rotation happens around the local axis of each control. So this is the logic for our finger controls. We're finding the controls themselves. We're running through each item in the array and then we're going to set the transform as soon as we have the logic set up for the slider control. The first thing we'll need is to bring our slider control into our rig graph and choose get control. And then we're going to be using the float value as our sort of translation input value"},{"start":"8:39","end":"9:14","startSec":519.5,"text":"to drive the rotations of the finger controls. So if we pull off float value and search for from Euler, what this does is it converts the float value information, so that single transform information into rotation values. If I just delete the conversion there, we don't need to convert this into all of our rotation channels. We just want to convert it into the Z rotation. So I'm going to drag that into Z there and plug our result into the value pin here."},{"start":"9:14","end":"9:46","startSec":554.7,"text":"And then what we should see as I move this, if we connect the logic up first, just going to add another sequence pin to hold S and left click. What we should see as we move this control is that our finger bones or our finger controls start to move, which is a great start. But it's not quite right, so we need to do a little bit of maths to get this fixed."},{"start":"9:47","end":"10:19","startSec":587.1,"text":"Now the first thing you'll notice is our fingers are kind of rotating the wrong way. I'll zoom in a little bit here. So as we slide this slider over to the right, they're more extending than they are curling. So we could fix this in one of two ways. We could flip the value that's coming out of our float control, or on the actual control max settings and min settings. We could flip them the other way, so we could go from minus 20 to zero."},{"start":"10:21","end":"10:52","startSec":621.4,"text":"If I just compile that, we'll see that our control goes the other way now. But our finger controls are curling instead of flexing. Now something else we need to do as well is it feels like we need to increase how much they curl, because they don't really curl enough for me. So we could do this by just increasing the length of this line that we have for the float, so coming to the minimum and making that number larger."},{"start":"10:52","end":"11:20","startSec":652.0,"text":"So we could go to minus 80 for example. Or if we like the way it's set up currently, what we can do is multiply the value coming out of that float control. By something like three, I think we found three works quite well here. And we'll see that that just increases how much, or times is the rotation value by three essentially, increases how much the finger controls curl."},{"start":"11:23","end":"11:54","startSec":683.3,"text":"Now the last thing we need to do here is just connect up our bones to our controls. And we're going to do that in a similar way to how we were using the finger controls to find, sorry, the finger bones to find our finger control names in previous setups. But we'll do it in a slightly different way. So this time we are searching for the hand controls rather than the hand bones. So our names currently have underscore CTRL on the end. And we can remove that instead of trying to add it."},{"start":"11:54","end":"12:31","startSec":714.3,"text":"So I'm just going to drag this out here to give us a little bit more space. If I open the element pin here and come down to name, we can search for replace. And under core, we'll get this replace node. And now what we're going to search for, this is essentially a search and replace node. What we're going to search for is underscore CTRL. And we're going to replace it with none because we essentially want to remove it. And then the next thing we're going to do is search for a set transform node."},{"start":"12:35","end":"13:09","startSec":755.6,"text":"Bring that over here. And we want to get the transforms of our controls and set the transforms of our bones. So I'm going to pull off the element pin here and search for get transform. And that means for everything inside the array here, we're going to get the transform off. And then I'm going to plug that into our set transform node here. And for the children or the item of the transform here, I'm going to pop item open,"},{"start":"13:10","end":"13:40","startSec":790.5,"text":"plug the name of our replace pin into the name of our transform pin. And we want to make sure that the type is set to bones. So it's searching for bones. So once we connect this logic up and compile, what we should see is that our bones are now being controlled by the joints. And this with this one control, we're able to make a fist or at least drive the controls of the fingers. And that's your setup. So we're searching for the hand controls."},{"start":"13:41","end":"14:07","startSec":821.2,"text":"We're adding them together inside a single array. And then for each of those items, we are setting the controls rotation using the the translation of the float control. And then we're going to use the same control names, but just by removing underscore control to find our bone names. And then we're going to use the transform of our controls and set the transform of our bones."}],"07_WrapUp":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"So to wrap up, we went over how the IK2Bone function works and how you would set that up in your control rig. We made a custom function and then learned how to set up a function library with the ability to share our custom functions across the entire project. We learned a couple of different ways to set up our finger controls, depending on what possibly works best for your rig. We also did some work with nulls to help add an extra layer of control within your control rig. And lastly, we explored a new control type, the float control,"},{"start":"0:33","end":"1:02","startSec":33.0,"text":"and learned how to convert the values from that control into rotation and drive another set of controls with its movement. So hopefully now you have a better understanding of some more of the functions and features found within control rig that you can take away with you to develop and improve your own rigs. Thank you very much for taking part and following along if you did. Feedback is always welcome for the course, so if you have anything to share, please do get in touch. But otherwise, best of luck with your control rigs."}]},"208.02":{"1_Intro":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Welcome to the Full Body IK Systems Unreal Engine Training Course. This course is going to focus on two different IK assets within the engine, and how you would set them both up to give your characters a Full Body IK setup that you could use to adjust your character's pose over the top of an existing animation. This helps with things like adhering contact points to ground planes, adjusting where a hand might be placed when doing something like pressing a button, and anything else where you want to adjust an existing animation to reach an IK goal."},{"start":"0:32","end":"1:04","startSec":32.0,"text":"We've included a project in the course content folder, so feel free to download that and follow along with the demo steps as we go through the course. We're going to take a look at what type of IK systems exist in Unreal Engine, and when it's appropriate to use each one. We'll then go over how to create a simple IK setup using the IK Rig asset, and then we'll look at a more complex Full Body IK node within a control rig, showing what steps it takes to connect the bones to the effectors, and then we'll also look at the bones settings to see how we can adjust those to get some better results."}],"2_WhatAreThey":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"So what are these systems and when should we be using them? So the two systems that we have are the IK rig or the full body IK or FBIK that we use within the control rig. Now the IK rig is designed for a much more simple setup where you can create different solvers and a full body solver, allowing you to make basic changes to adjust your character's entire pose based on IK goals. Using the FBIK within control rig just gives you a greater degree of flexibility."},{"start":"0:32","end":"1:02","startSec":32.4,"text":"It gives you access to a lot more settings and you have a lot more control over things like squashing stretch, making edits on a per bone basis, like limiting the movement and rotation of some bones, and even setting preferred angles so that the bones are definitely moving in the correct way. Now these two different systems are using the same solvers under the hood, so they're both built upon the same foundation. The IK rig is useful for making basic changes to your character's pose, and the full body IK within a control rig gives you essentially a lot more options"},{"start":"1:02","end":"1:35","startSec":62.4,"text":"to tweak and customize the output of the final pose. Now when is it appropriate to actually use a full body IK system? So the systems are designed for editing your character's existing pose essentially, so they're great for adjusting a pose that you have already, dynamically, so at runtime in real time. And they're great for things like reaching targets, so pulling hands, heads, feet around to reach a given target location, adjusting and aligning so that might be adjusting your spine or tails procedurally"},{"start":"1:35","end":"2:08","startSec":95.4,"text":"if your character's running in there, they're sort of leaning left and right perhaps. And they're great for ground alignment as well, so whenever your character's walking on perhaps like an uneven terrain, it's great for aligning each foot in a different way to the terrain so that things look a bit more natural. Something that it's not great for and not designed for is generating new poses for your character from scratch. So with the body there are just too many degrees of movement then IK solver couldn't guarantee plausible posing for anything like a human or an animal, anything fairly complex,"},{"start":"2:08","end":"2:21","startSec":128.4,"text":"especially when you're moving effectors over great distances. If that's something that you're hoping for, then you'd be much better to build an actual control rig and edit the pose of your character manually because the full body IK system isn't designed to do that."}],"3_SimpleIKRig":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"We're going to open up our project now and take a look at setting up an IK Rig asset. We're going to set this up with a quadruped character and show you how you can really quickly create what you need to start adjusting the pose of your character. We can even preview inside the IK Rig editor to see how it might affect an animation that's playing on the character. And this is our IK Rig editor window. So on the left hand side here, we have the hierarchy, and this will show us the bones that we have inside our Skeletal Mesh, as well as any IK goals or IK settings that we've"},{"start":"0:31","end":"1:03","startSec":31.6,"text":"set up inside this IK Rig. On the bottom left, there is the solver stack, and this will display any IK solvers that we're currently using for the Skeletal Mesh. Then we have the output log along the bottom here, and that displays any errors or warnings that you might have with your Rig. And then top right, we have the details panel, and this is just a universal panel that will display details about anything you currently have selected. And on the bottom right, we have the asset browser. Now this will show you a list of animation sequences that you can use to preview the"},{"start":"1:03","end":"1:35","startSec":63.5,"text":"behavior of your IK Rig, which we'll do in just a moment once we've got it set up. There are two main things that we need to set up for the full body IK system here. We need to set the IK goals, and we need to set the solver root. Now the IK goals are the effective points at the end of your IK chains, and this is the target that the chain will try to reach by adjusting the pose of your character, and they work together with the solver to achieve that. Now since the IK goals are going to be the end points of your bone chains, they'll typically"},{"start":"1:35","end":"2:06","startSec":95.8,"text":"be set up on the hands and the feet of your characters. And the second thing is the solver root, which is typically the starting bone in the chain. This is just so the solver knows which bones it should be adjusting. And in this case with a full body IK, we're going to use the pelvis. That's because this is the true root of where the character's movement comes from, rather than the actual root of the skeleton, and it'll give us much better results. So the first thing we're going to set is the IK goals."},{"start":"2:06","end":"2:37","startSec":126.3,"text":"And to do that, I'm going to select all four feet of our character here. And if I show our skeleton, we'll be able to see that we have the end joints selected currently. And if we right click inside the hierarchy here, we can choose a new IK goal, or we could press control N for that. And it's going to ask us what kind of solver we want to use for this. Now we could use sort of a limb IK for this, which will just set up individual limbs for each of these controls."},{"start":"2:37","end":"3:09","startSec":157.2,"text":"And then we need to set up, you know, individual roots for each of the solvers on sort of the shoulders and shoulder blades and hips down here. But because we want to do like a full body system, we're going to choose the full body IK. So if we choose add solver, you see that in our solver stack here, we now have a new solver full body IK. And it does give us a warning here that it's missing a root bone, which means that although it knows the end of each joint chain, it doesn't know the beginning. It doesn't know where it should be starting from."},{"start":"3:09","end":"3:40","startSec":189.8,"text":"So if we come up to our pelvis here with our solver selected, I'll right click and choose set root bone on selected solver. And what that will do now is it will fill in the full body IK solver here so it's no longer grayed out, which just means that it's active and its settings are set up correctly. So if we were to select a couple of these goals here, these IK goals, you can see that we can instantly move them and the pose of our character changes to compensate for that."},{"start":"3:40","end":"4:11","startSec":220.5,"text":"So one way to quickly test this and see how this looks on an animation would be to just double click one of these animations in the asset browser here and shift our IK goals around and see how that affects our character. And you can see that really, really quickly, we actually have an animation playing our character and we can adjust the pose of it in quite a basic way with just a few IK goals, a full body solver and just making sure we set the root for that full body solver."},{"start":"4:11","end":"4:43","startSec":251.8,"text":"If I quickly set up an individual limb IK here just to compare that with the full body IK solver, you'll see that it's really nice to use the full body IK solver because you get all the extra little bit of nuanced movement. So if I come up to add new solver, choose limb IK, I'll just do this with the back left foot for example. With that limb IK selected, I'll right click and connect that goal to the selected solver. This is just another way to set things up. And the top of that chain is going to be the thigh here."},{"start":"4:43","end":"5:17","startSec":283.7,"text":"So with that limb IK selected, if I right click set root bone on selected solver and I just deactivate the full body solver for now. When I select this rear left foot goal, you can see that we're affecting that entire chain from the tip of the toe to the hip. We're not getting any movement from the full body IK. So if I turn that off and turn the full body IK back on, you can see that instantly everything looks a lot nicer because we do get that extra movement from the whole body."},{"start":"5:17","end":"5:50","startSec":317.6,"text":"And that's really how quick it is to set up the IK rig asset. Now a great advantage of this setting it up with the full body solver is that you end up with that full range of motion and have the whole body reacting to each of the IK goals or effectors. Comparing that to like an individual limb chain where each of the root bones would sort of be locked down to their initial positions in the animation. Now the main sort of disadvantage of this is that you can't really use this within a sequencer for any animation purposes. It is designed for use inside an animation blueprint where you can adjust the pose on"},{"start":"5:50","end":"6:22","startSec":350.2,"text":"the fly based on where you want these IK goals to be. And here's an example of what that logic might look like. So we have the animation playing on our character here where mannequin is pressing a button. We then insert an IK rig node that references our IK rig asset that we've created and essentially feed in a positional update to the goals position and in this case it's for the right hand to adjust where the character is pressing a button before we reach our final output pose."}],"4_FBIKOverview":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Now that we've taken a look at the simple IK rig, we're going to see how the full body IK or FB IK within control rig compares, seeing why you'd use this and when it's a good idea to do so, and we'll cover the steps on how you might set one up for your own character. So what is the full body IK system or FB IK in Unreal Engine? Well the concept behind the system is exactly the same as the simple IK rig, so it is designed as a procedural adjustment tool, but this time to be used within control rig to give"},{"start":"0:34","end":"1:07","startSec":34.4,"text":"you an alternative solution for things like ground alignment or arm reaching behaviour. And as with the simple IK rig, some of the primary reasons to use FB IK are things like maintaining contact, so keeping your feet on the ground or your hands on the table for example. You can also dynamically change the height of your character, so you can force them to crouch by lowering the hips while their feet remain planted. And it's great for reaching a target like with the IK goals in the simple IK rig, adjusting the hand position for example when pressing a button."},{"start":"1:07","end":"1:39","startSec":67.8,"text":"So now that we kind of understand that if it's designed to work in a similar way to the simple IK solution, then why would we use this over any of the other IK systems in the engine? Well, there are a few reasons for that. With the FB IK solution within control rig, you get a greater range of motion and there are more settings available to you to tune your output pose. So when using a single chain IK, if you reach the end of the chain length, the goal can no longer be reached and the chain will just lock up."},{"start":"1:39","end":"2:10","startSec":99.6,"text":"And when using FB IK you can engage the whole body to move the route and reach those goals. It also has multiple effectors, so there may be times when you need multiple contact points to be maintained at the same time or even at different times, which may only be possible if the solver is allowed to move the route of the character. And when it comes to the torso or spine of your character, if you're using a single IK chain, you can't guarantee a great spine pose, so using a full body IK system to engage"},{"start":"2:10","end":"2:40","startSec":130.2,"text":"the whole body is going to give your character a much better final pose. When you're using the FB IK system within control rig, remember that it's something that is meant to operate on top of your existing animation and not generate something from scratch, so you can't expect it to fix bad inputs or bad posing. If your rig scenario doesn't require a full body IK system, do continue to just use single IK chains because there's no sense in having a full body system running if it's not necessary."},{"start":"2:40","end":"3:11","startSec":160.7,"text":"And as with any IK setup, don't start with perfectly straight limbs. Make sure that things like your elbows and your knees have a slight bend in them so that the IK solver can calculate the default bending direction correctly. Something to try and avoid as well is to increase the iterations that the solver has performed to compensate for any bad setup. Make sure to just take your time adjusting the settings to suit your character, giving you the output pose that you want. And make sure never to pull your character outside of the capsule, because this will"},{"start":"3:11","end":"3:18","startSec":191.8,"text":"likely end up with your character misaligning from their collision and could cause things like your character going through walls and other meshes."}],"5_FBIKEngineSetup":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"So let's jump into the engine and see what it takes to get a character set up with a full body AK system within Control Rig. What we're going to need is to make sure that we have the full body AK plugin activated. We'll need a skeletal mesh for our character, a control rig asset and a handful of controls. The first thing we need to do is check that we have the plugin activated. So if we come up to edit in the top left here, down to the plugins window and search"},{"start":"0:30","end":"1:01","startSec":30.9,"text":"for full body, that should get us there. So we can see that we have the plugin activated already, but if you don't in your project, just tick this box here and then I think you get a restart option down at the bottom, that will just restart your project and then have the plugin loaded. Now that we know the plugin is running, let's create a new control rig for our character. So if you find your character skeletal mesh, right click, come up to create at the top here and then down to control rig."},{"start":"1:01","end":"1:35","startSec":61.8,"text":"And that'll create you a new control rig and if we double click that to open, you'll see it's already referencing in your character that you created it from. I'm just going to rename this to be our FBIK control rig. And if I double click to open, I'll just dock it in the top here. The first thing we need to do is create some controls. Now these will be our effectors for the FBIK solver and the goals for our IK chains to"},{"start":"1:35","end":"2:08","startSec":95.6,"text":"reach towards essentially. So we'll want one for the head, one for each hand and one for the ball of each foot. So I'm going to select all of these bones and create controls from them. So our head, our hand left, our hand right and further down here we'll have our ball R and our ball L. I'll right click these, come to new and add controls for selected. And if we scroll to the bottom, we've got all of our new controls here that are at the"},{"start":"2:08","end":"2:43","startSec":128.8,"text":"locations of the bones that we had selected. Now I'm just going to customize the look of these a bit so we can see at a glance which control is which. So for the hands, I'll just change them to box thick. And for the left side, if I select both of the left hand controls here, I'm just going to turn them to a blue color. And with the head control, it's actually inside the head at the moment. So I'm just going to change it to a circle and I'm going to adjust the rotation of the"},{"start":"2:43","end":"3:16","startSec":163.6,"text":"shape transform and scale it up probably to let's say three. And I'll change the color of that as well. So they're all quite distinct now. I think something I might do is just adjust the scale of this in the Z axis alone. Let's go something like eight, just so it's a little easier to select and you can see it a bit better in the viewport. Now as I said, these controls are going to be our effectors for the FBI case over."},{"start":"3:16","end":"3:48","startSec":196.0,"text":"And this means we're going to need to get their locations to feed that into the FBI case node. So if I highlight all of our controls here and I left click and drag them all into our control regraph and choose get control. This is going to get the transforms of all of these controls. If I just space them out a little bit so that we can read them a bit better. You can see that we have an individual get transform node for all of those controls."},{"start":"3:48","end":"4:22","startSec":228.3,"text":"And now we need to set up the logic to tell the system how these controls will be driving our bones. So let's first get the brains of the operation and search for an FBI case node. So if I right click in the rig graph and search for FBI case, it's the full body IK that we're looking for. The first thing we need to do is actually set the root of the solver. And for this, we're going to use the pelvis or the hips of our character. And the reason we do this is to ensure that the solver actually starts from the true base of where the motion occurs rather than the root of our skeletal mesh."},{"start":"4:22","end":"4:56","startSec":262.1,"text":"You can set this to be any bone on your skeletal mesh depending on your setup, but to get the best results from something like a biped or quadruped that's reaching towards something or adjusting its pose to keep aligned with the ground plane, you'll want to set this more often than not as the pelvis or hips of your character. So we'll just set that there. Now we're going to set up the effectors. And this is where we tell the node which bones we want to use essentially as the end of our IK chains and which controls will be the goals for those bones."},{"start":"4:56","end":"5:28","startSec":296.4,"text":"What we're going to do under the effectors heading here, we'll add an array element with the little plus. This will give us just a host of options under our first item in the array. And the first item we're going to set up for the bone is going to be our head. And we'll just work down the effectors that we have here or the controls that we have here. So if we search for our head bone here and then connect the transform of our head control to the transform of our first effector here, that means that the head control is going"},{"start":"5:28","end":"6:02","startSec":328.0,"text":"to drive the head bone. So if we were to connect this up straight away and just hit compile, when we grab our head control here, you can see that we're moving the entire character. And that's just because we haven't pinned anything in place here or we don't have any other effectors set up. But you can see that already we've got some movement there and we've got something working. So let's just do that for the rest of our controls here. So if we add in your effector, this will be the hand L and we connect those transforms"},{"start":"6:02","end":"6:37","startSec":362.9,"text":"up, add another one, hand R, connect those transforms up, add one more, all R and the last one. Oh, if I hit that properly, there we go. This will be ball L. Now, if I compile that, you'll see that when we grab any of these effectors now, all of"},{"start":"6:37","end":"7:12","startSec":397.4,"text":"the other IK chains or the, all of the other effectors essentially are pinning themselves in place. So you can actually pull these around and manipulate your character. And you can see that really it's kind of that quick to get something, something that's able to adjust the pose of your character's whole body with just a few controls and the FBIK node. Now we have a couple of settings we can look at for each of the effectors first. And that is the position, I just zoom in here, position, rotation and strength alphas."},{"start":"7:13","end":"7:44","startSec":433.4,"text":"And the position and rotation alphas work in the same way. One is just for translation and one is for rotation. And they both blend between the bones current position or rotation and the effectors current position or rotation. So if we were to set this on the left hand to zero, for example, you'll see that as we move it around, it's no longer affecting the position of our hand bone. But as we rotate it, it will affect the rotation because that's still set to one."},{"start":"7:44","end":"8:17","startSec":464.1,"text":"So you can kind of customize these and update them and change them to fit your character. And the strength alpha determines how much the bone will pull towards the effector or the control. So if this is set to zero, the bone is not going to pull towards the effector. But the rest of the chain from the root to the effector is going to slightly resist the motion of other effectors, meaning that it can act a bit like a stabilizer of sorts for part of the body that you don't want to behave in a purely FK fashion."},{"start":"8:17","end":"8:49","startSec":497.7,"text":"So if I was to set this on the hand to zero and then try and pull it around, you'll see that it doesn't drive the hand directly, but it still has an effect on the root and the whole chain going from the root to the end bone, which in this case is our left hand. So if I was to grab a different effector, you can see that we get a little bit of resistance. And if someone was leaning to the left, their arm would kind of go out a little bit to kind of stabilize. And it's helpful for things like that, essentially."},{"start":"8:49","end":"9:22","startSec":529.5,"text":"I just send that back to default. So with our current settings, if I just make the window a bit bigger here, because we won't be needing the rig hierarchy, with our current settings, you can see that everything is reacting to the effectors being pulled around. But things I think could look a little better. Like we've got the hips moving quite a lot here, so they're rotating quite a bit. And the legs, both of them, they're very, very stiff. So we expect them to sort of be bending at the knee here."},{"start":"9:22","end":"9:56","startSec":562.0,"text":"And I think the ankle is probably rotating too far when we lift the leg and drop it down. You can see both of them are rotating quite a bit there. So we're going to try and fix these by adjusting the bone settings for the affected bones in the chains. So that's going to be things like the pelvis, our leg bones, and our feet bones. And we do that by adding the affected bones to our bone settings array. So I'm just going to minimize the effectors here just to clear up sort of the visuals of the node. And under the bone settings, I'm going to add a new element to the array."},{"start":"9:56","end":"10:27","startSec":596.2,"text":"And all the settings that come up here are going to allow you to essentially control the stiffness and limit the rotation of the bones that you specify. So first of all, we're going to try and fix the rotation of the hips that they're going a bit too far. So the bone we want to update or we want to add some settings to will be the pelvis. And we're going to increase the rotation stiffness essentially. So if we put that to something like 0.8, now when we lift the foot, you'll see that we"},{"start":"10:27","end":"10:58","startSec":627.7,"text":"get a lot less rotation in the hips there. And it makes things look just a bit more natural for our character. And if we were to increase the position stiffness, say 0.5 for example, you'll see that that doesn't move quite as much. I can put this also up to one. And it's just essentially a lot harder for the hips to move up and down. The controls or the effectors that you're moving need to work a lot harder to pull the"},{"start":"10:58","end":"11:31","startSec":658.7,"text":"hips around. But we're going to leave that at zero for now because I think that's what works best for our character here. Something you can also do is set preferred angles. Now this is essentially controlling which way the bone bends when the limb is compressed by the effector. And it's great for things like your knees or your elbows. And we're going to use this to resolve the stiffness in the legs by adjusting the settings for both the thigh and the calf."},{"start":"11:31","end":"12:01","startSec":691.0,"text":"Coming back to our bone settings, we'll add another array element. Let me just minimize this so we can see a little better when we add it. And let's first search for the thigh. So let's work on the left hand side first. Now under the preferred angles, this is where we can specify which rotation axis we would prefer to rotate around. So we prefer the knee to bend around. And for that, it would be best to check the local rotation axis of our knee joint or our"},{"start":"12:01","end":"12:32","startSec":721.8,"text":"thigh joint. And to do that, if we come up to our options, our view options in the top left and turn on display axis on selection. And then if we search for our thigh L, we can see that if I zoom in here, we'll be bending or rotating around the Z axis. So that'll be going forwards and backwards with our leg. So inside the preferred angles here, if we set our Z axis to minus 45, just because this"},{"start":"12:32","end":"13:05","startSec":752.7,"text":"is something we checked previously, and give our leg a bend, we can see that they almost worked. However, we need to check on something called use preferred angles. So without that, it won't be taking any of these values into account. So if I check that on, you can see immediately we're looking a whole lot better already. So comparing that to the right hand side, where we don't have any preferred angle set up. You can see that as we pull that up and down, it's remaining quite stiff, but the left side"},{"start":"13:05","end":"13:37","startSec":785.5,"text":"is reacting a lot more how you would expect. Now let's do the same thing for the calf. So I'm going to add another bone setting, find our calf L. And under the preferred angles, let's check the preferred angle of our calf again, or the local rotation axis. So it looks to be along the Z axis again. But this time we wanted to rotate backwards, so rotate the other way."},{"start":"13:37","end":"14:11","startSec":817.5,"text":"So inside Z, I'm going to put a value of 90. And again, check on use preferred angles so that it actually takes those values into account. And now when we raise the foot up, you can see that we've got a great bend in the knee. And it's just acting a lot more natural and looking a lot better for our character here with the pose that they're in. And these are some things that you can play with and update for your character to get"},{"start":"14:11","end":"14:41","startSec":851.4,"text":"it looking how you want. And it's great these preferred angles to set things like any sort of bone you want to rotate in a specific direction. It doesn't have to be like arms and legs. It can be anything that your character needs. You can update those angles here and just have a bit more control over how the character is going to react when these effectors are being pulled around. So let's just do the same for the right side so that we have a symmetrical character essentially that's working properly."},{"start":"14:41","end":"15:13","startSec":881.9,"text":"So we add in your bone array, search for our IR. Click on Use Preferred Angles and just test that out. And you can see that whatever value you put in here, it does adhere to. So set that to negative. And add one for the right hand calf."},{"start":"15:13","end":"15:47","startSec":913.6,"text":"So calf R. These preferred angles, 90 degrees. There we go, things are looking a lot nicer now. And both of our legs are acting much more naturally and much more how you would expect if one was being pulled around. And you can see as I go side to side, it's always bending in that Z axis so it's not accidentally sort of breaking the knee at all. Now the last thing we're going to take a look at within the bone settings are the limits."},{"start":"15:47","end":"16:21","startSec":947.6,"text":"And that's these three options here one per axis. Now this isn't super necessary here because we're already getting quite good results. But just for the demo, we'll take a look at how the limit settings work essentially. Now limits, they allow us to clamp or limit the range of motion of a bone on an individual axis. And there are three different settings for it. So we've got free. Now that allows the bone to just move freely. There is limited. Now this allows the movement only within a specific range of the min and max values that"},{"start":"16:21","end":"16:52","startSec":981.5,"text":"we set here. And this is up to or minus 180 degrees. And the values are relative to your reference pose rather than the pose that your character is currently in. And the third option we have is locked. Now this completely disables the movement along the axis that you lock. So what we're going to do is tweak the ankle slightly here and limit its range of motion so that if we were to push this foot up really high, the foot wouldn't penetrate through"},{"start":"16:52","end":"17:22","startSec":1012.2,"text":"the shin there, through the lower leg. So we'll go through the same process, add a new bone setting. This is going to be our foot bone. So foot L will do here. And we'll just double check the rotation axis that we want to edit. And it is along the Z axis again. So here we've already tested these settings and I'm going to set the Z axis to limited"},{"start":"17:22","end":"17:55","startSec":1042.6,"text":"and set the minimum to minus 60 and the maximum to 60. So if I push this foot right the way up now, you'll see that when we reach a certain point, which is just around here, the ankle no longer keeps rotating so it doesn't penetrate through the lower leg. I'll just revert these back to zero."},{"start":"17:55","end":"18:28","startSec":1075.3,"text":"You can see the difference there. As we keep raising it up, that ankle just keeps bending. So if you have any instances with your character where you need to fix that or limit the bone, that's how you would do it. And I'll just duplicate that for the right hand side. So find our foot R, come down to the Z axis, limit that at minus 60 and 60."},{"start":"18:28","end":"18:58","startSec":1108.2,"text":"So now both feet are working in the same way. So with tweaking those various bone settings, we actually fixed our character and got them looking more natural. So with less hip bend there and the knees are bending in the correct direction and the ankles aren't bending too far, so we have something a little more realistic for our character."},{"start":"18:58","end":"19:28","startSec":1138.2,"text":"Now depending on the needs of your rig, there may be cases where you want to exclude bones from the FBIK solve. And this can be useful when correcting unnatural looking poses or if you just want to simplify the FBIK behavior. So excluding bones is highly recommended versus using bone settings and adding lots of bones that are sort of fully stiff or locked because this reduces the calculations that the solver has to do and essentially reduces the impact on performance because there are"},{"start":"19:28","end":"20:00","startSec":1168.8,"text":"fewer things that the solver has to calculate for if you're excluding them. So if we take a look at an example here, what we can do is move the head into an awkward sort of position. And you can see that if the head's being pulled around, the body's not really reacting how you would expect. So I'm going to exclude the neck and the spine here to try and get a bit more of a comfortable pose. So I'm going to add six bones here and I'm just going to start at the top of the chain"},{"start":"20:00","end":"20:30","startSec":1200.2,"text":"and work my way down. So neck two, neck one, you can see they've already gained something a bit more natural, arguably that is still a little strange, but the whole body has come down to meet the head now. If I exclude some more of these spine bones, we should get something as little more as you expect."},{"start":"20:30","end":"21:03","startSec":1230.3,"text":"So as this head is being pulled around, the spine is still bending at the first spine joint because they're not excluded that as well as the pelvis. And it's keeping it a little straighter to try and meet the head effector. So if you have certain scenarios where that's something you need to do and stop sort of a strange pose that you have on your character or improve the pose of your character to reach the effector or the IK goal, then excluding bones is a great way to do that."},{"start":"21:03","end":"21:33","startSec":1263.8,"text":"And again, this removes bones from the solvers calculations. So it makes things a little bit more performant versus adding lots of bones to the bone settings and then setting them as locked or the stiffness to 100%. The last thing to take a look at with the FBIK node here are just some of the settings that are available to tweak things on a more global scale. So if I close that and open settings here, we have the iterations here."},{"start":"21:34","end":"22:08","startSec":1294.3,"text":"Basically, the number of times that the solver will loop through and calculate all the positions of the bones. This helps with convergence, which is essentially trying to make the bones reach the effectors. Increasing this value will increase the CPU cost of the node, but it can be necessary when you have a lot of bones in your character. Next we have the mass multiplier. And this acts as a sort of global stiffness, similar to the position and rotation stiffness that we saw under the bone settings, but it applies to all of the bones at once."},{"start":"22:08","end":"22:38","startSec":1328.3,"text":"And typically you'd work within a range of 0 to 10 for this. So if the IK solve seems to be acting quite erratically, increasing the minimum mass multiplier might just fix that. So for example, this can sometimes happen with very large scale characters. So internally, the body is segmented by the node and held together with constraints. So this is from the effectors to the bones. That's just sort of the behind the scenes working of the IK node."},{"start":"22:38","end":"23:10","startSec":1358.7,"text":"And the mass multiplier is proportional to the length of the body. So that means that longer bones will rotate less than smaller bones. And that means that they'll rotate less per iteration, which means you might just need to play with these values together to get the sort of results that you want. You might need to increase the iterations a little bit, as well as increasing the mass multiplier a little bit. But that tends to apply to, again, just very large characters with either long bones or a lot of bones in their skeleton."},{"start":"23:10","end":"23:41","startSec":1390.7,"text":"Allow stretch does what you think. So it will allow your bones to stretch towards the effector. So with that turned on and off, you can see that actually the length of the bones increases, stretching towards the effector to reach the end goal. Updating the root behavior will determine how the root acts. So you can see here that pre-pull is default, and by default, it will translate and rotate the root and all the children when you're pulling the effectors around."},{"start":"23:41","end":"24:14","startSec":1421.1,"text":"If you pin to input, this locks the root to the current pose that the root is in. So the current animation pose that is playing. If you set it to free, it treats the root bone like any other and allows it to freely move according to whatever bone settings you have applied to it. And these bone settings, if we drop down the box here, will allow you to update the rotation and position along each individual axis to sort of tweak to your heart's content. The global pull chain alpha can be used to rotate the entire limb controlled by an effector"},{"start":"24:14","end":"24:48","startSec":1454.9,"text":"to point at it before the solver runs. So if you use this in conjunction with preferred angles, it can really help to pull the skeleton into a desired shape before the constraints are solved. Now it's on by default, set to one, though it's sometimes desirable to turn it off because it can make limbs a little overreactive or even reduce it. And by that, if I just drag this down here, for example, to show you, if I slowly increase this number, you'll see that the sort of rotation on all the limbs gets multiplied."},{"start":"24:49","end":"25:21","startSec":1489.0,"text":"And you can end up with some funky results, and that's what we mean by overreactive, like they're bending a bit too much. The maximum angle will just determine how much a bone can rotate per iteration. And over relaxation here will essentially push the constraints beyond their normal amount in an attempt to speed up convergence. Now this can help with some of your posing, but it can come at the cost of stability."},{"start":"25:21","end":"25:49","startSec":1521.7,"text":"So the range to work within here is just between one and two. So as you can see, there are a lot of different settings that we just went over and a lot of different options available to tweak and sort of change the posing of your character. Now I would say try not to get too bogged down with them. My advice would be focus mainly on your bone settings and your excluded bones, as they're going to be the thing that help you out the most when fixing your posing in most common scenarios."}],"6_FBIKSubChains":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"A more recent feature added to the FBIK node within Control Rig is something called sub-chains. Now, sub-chains are essentially a way to limit the effect an effector has on the whole body, and you can do this by defining a small chain of bones within it. So for example, you could create a sub-chain from the hand to the shoulder, which will essentially leave the rest of the body unaffected until this sub-chain of the hand has reached its limit, and then it will engage the rest of the body to pull towards the effector."},{"start":"0:34","end":"1:05","startSec":35.0,"text":"So let's take a look at a use case for that with our character. Now I'd like to show this off in a more exaggerated way. So what I've done is I've disconnected our existing logic here with the existing full body IK node, and I've created a new one with a much more simple setup. So we have our right hand in here, and we don't have any bone settings, we're not excluding any bones. The only thing I'm going to change is the root behavior and set that to Pinter Input just to show this off more clearly."},{"start":"1:05","end":"1:39","startSec":65.2,"text":"So when I grab this right hand here, you can see that the whole body from the pelvis to the wrist is reacting to me pulling this effector around. Now when I pull the effector closer to the body, you wouldn't naturally lean that way. The same as when I lift the effector up or when I lift the wrist up. You wouldn't expect the body to be reacting like this. And so this is what sub chains can help you correct. So in our chain depth option here, this allows us to count how many bones up the chain we"},{"start":"1:39","end":"2:10","startSec":99.2,"text":"would like the sub chain to be. So in our case, a value of two would give us our lower arm and then our up arm. And the other thing that we need to change to activate sub chains would be the sub iterations here inside the settings dropdown. And if we set that somewhere between five and 10, that should give us some pretty decent results. So if I select the effector or the hand control here, you'll see that we can now move it towards the body."},{"start":"2:10","end":"2:40","startSec":130.2,"text":"And although it does react a small amount, which is quite nice, it's no longer leaning all the way over. And we can also lift it up and move it around within its limitations without affecting the rest of the body. And as soon as we exceed those limitations, you can see that we do engage the rest of the body. And they can be a quite simple setup. And if we increase this to three, for example, we'll just go slightly higher up the chain to engage the collarbone."},{"start":"2:40","end":"3:09","startSec":160.9,"text":"And you probably want to set some sort of bone settings limits for this eventually, but you can see that as we've added one more bone to the chain depth, it's increased or it's changed which bones we're affecting. And this can really help you get some more natural poses out of your character and fix any sort of awkwardness that you're getting with the whole body moving when you think it shouldn't be when you're lifting a hand, for example."}],"7_TipsAndTricks":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"The last thing I want to go over before we close out the course are just some tips and tricks to help you tune your solver settings and another way of thinking of how to use the FBI case solver. So as I previously mentioned, there are a lot of different settings that you can tweak and change to adjust the pose of your character and get the solver working how you want. But to avoid, you know, that parameter hell of tweaking all these different settings and not being sure really what you're affecting anymore."},{"start":"0:30","end":"1:00","startSec":30.0,"text":"This is the recommended order of tuning your settings. The first would be to adjust the root settings. So adjusting that behavior drop down and tweaking the pre and pull root settings. Then work on excluding the bones. So removing calculations from the solver and just simplifying things for you. Then you can adjust the pull chain alpha per effector. So increasing this could help improve your results for more sparse bone chains."},{"start":"1:00","end":"1:34","startSec":60.0,"text":"Or decreasing this value could actually help improve results for a bit more of a complex skeleton system. And remember to add preferred angles to your bones as well. So these are just determining in which angle your bone should rotate when the AK chain is compressed. These settings should help you fix any issues you have for the most common case scenarios. But we can still make additional adjustments with some of the bone settings. So tweaking things like rotation stiffness. You can even lock down different axes of a joint if it should only rotate in one direction."},{"start":"1:34","end":"2:05","startSec":94.0,"text":"Like a robotic arm for example or anything that should act like a hinge. And applying limits to your axes. So this should be used a bit more of a last resort as adding too many of these will probably require you to increase the iterations. Which makes things a little bit more costly. And it has the potential to cause some unwanted results as your different settings might start fighting one another. And another way of thinking about how to use the full body IK solver is actually to use it for a single IK chain."},{"start":"2:05","end":"2:32","startSec":125.0,"text":"It doesn't have to be full body all the time. Now you do a slightly different setup for this. So in this example with a tail you would set the base of your tail as the root of the solver. So tail 01. And then within the settings under the root behaviour drop down you would choose pin to input. And that just means the root will be playing the character's current animation. And the solver will be prevented from translating the IK chain around."}],"8_Outro":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"To wrap up the course, you should hopefully now have an understanding of some of the different IK systems available within Unreal Engine and when it might be appropriate to use each one. We saw how to create a simple IK rig with our Wolf character at the start, as well as the more complex full body IK system within Control Rig, where you have a few more options available to you to tweak your final output pose and get your character looking how you want. So thank you very much for participating with the course and best of luck with your IK"},{"start":"0:31","end":"0:33","startSec":31.8,"text":"systems for your own characters."}]},"208.03":{"01_Introduction":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Welcome to the Control Rig Mechanical Rigging Unreal Engine Training course. The aim of this course is to go over a handful of useful functions and features available within Control Rig that would help you in creating a rig for a skeletal mesh that needs mechanical accuracy. We'll first take a look at some considerations you might need to make before getting into the engine to help you plan out your Control Rig. Now this will be about things like bone orientations and hierarchies depending on how something might need to move"},{"start":"0:32","end":"1:05","startSec":32.0,"text":"and some thoughts about how you should be skinning your meshes. Then we'll take a look at some specific functions and control types and settings that can be useful when you're creating a mechanical rig to help you set up your controls in such a way that you can achieve more mechanical accuracy. And then we'll jump into the engine to take a look at some of these tools in action, building a control rig for one of the skeletal meshes within the project. And lastly just to wrap up with some additional features that are available within the Control Rig Graph that might be useful when you're building your own Control Rig."},{"start":"1:05","end":"1:16","startSec":65.0,"text":"We've included a project with the course content folder, so be sure to open that up and follow along as we're taking a look at these features and building out the Control Rig."}],"02_PlanningForRig":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"So, let's first take a look at planning for the control rig and some considerations to make when you're thinking about how your mechanical mesh should be deforming. So, it's useful to think of it as sort of rigid body versus organic skinning and thinking about how each particular piece of the mesh needs to deform. So mechanical meshes are typically rigid bodies and should be skinned to one bone each. So, it's very likely that all of your mechanical meshes are broken into many different parts"},{"start":"0:32","end":"1:04","startSec":32.0,"text":"and you know they're all connected and held together with screws and bolts and rivets and they all have different pivot points. So you want these solid parts to only be skinned to one bone so that they don't deform in an unusual way and you know look all bendy when it's animating. But that's not necessarily going to be true for every part of your skeletal mesh. Things like springs should be weighted perfectly evenly between two bones so that when they compress and contract they'll be deforming accurately."},{"start":"1:04","end":"1:36","startSec":64.3,"text":"And you may also have parts like cables or wires on your mesh that are carrying things like hydraulic fluid or electrical cables and these obviously are going to need to deform in a more organic way than this big chunk of solid metal. So they may have several influences from different joints depending on you know how long they are and how they might need to deform. So it's really about considering and thinking how each part of the mesh needs to deform and then just skinning them in the appropriate way to make the rigging in the engine a bit"},{"start":"1:36","end":"2:10","startSec":96.0,"text":"more straightforward for yourself. When it comes to orienting your bones it can be really helpful to orient them in the direction of travel. So typically we would use the X-axis to point down the bone in the direction that that mesh would travel. And this is just going to help speed up your rigging workflow in the engine. So when you're thinking about things like pistons or any sort of telescopic type movement being consistent with your axis that you're pointing down the bone can be really helpful. And when it comes to meshes that act in the same way so like the tires of a car for example"},{"start":"2:10","end":"2:45","startSec":130.8,"text":"they're all going to be rolling the same and sort of turning the same. Setting up all of the bones with the same orientation and this could just be world orienting them for example can be really helpful in simplifying the control rig logic again because you can use the same logic for all of these tires instead of making sort of custom adjustments per tire to account for any differences in their orientations. Mirroring bone orientations by behavior can also be very helpful because if you have something like a claw grabber that we have here we can set things up so that we can feed the same"},{"start":"2:45","end":"3:19","startSec":165.3,"text":"logic into both bones and easily use one control to manipulate both of them. So in this example with this sort of claw grabber that we have here the logic has been set up so that we can move this teal colored controller left and right and as we do that the claw will open and close without having to add any extra logic to account for the differences in their orientation. So we're just grabbing the transform values and converting it to rotations and feeding that straight into the into the claw bones. And there's only possible if you mirror by behavior."},{"start":"3:19","end":"3:51","startSec":199.0,"text":"Something that you might find with your skeleton hierarchy is that you end up having fewer chains of bones and more individual children coming off a shed parent. So in this example here we've got a car where we have a root and then each of the wheels and the doors simply have a single bone to control those meshes. And with this example of the suspension on the car chassis you can see that this rear axle and everything that's fixed to it is a child of the same parent on the right here."},{"start":"3:51","end":"4:20","startSec":231.6,"text":"And that's because any meshes like suspension springs or damper arms here where each end is fixed to a different mesh making those bones a child of the mesh that they're fixed to is going to make things much easier when you're rigging an engine than if you had a chain of bones here instead. So with a mechanical rig you'll probably find that you have fewer chains of joints and more single children coming from shed parents of the things that they're affixed to."}],"03_FunctionsControlTypes":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"When it comes to the tools available in Engine for your control rig, let's take a look at some of the functions and control types that can be useful when you're building a mechanical rig. Very often you'll find that something mechanical will contain a piston, whether this is part of an engine, or a large rubber arm, or just there to support the movement in some other way. And for these scenarios, there is a function built into the engine called the piston function. And that acts as a two-way aim constraint, allowing two elements of the rig, so bones"},{"start":"0:33","end":"1:04","startSec":33.8,"text":"or controls or nulls, to always be pointing towards one another. So if each end of the piston is anchored to a different mesh, say for example like the upper and lower leg of a robotic character, this function will enable those pieces to stay anchored where they are, and then always aim towards one another, maintaining that functionality of the piston. Something else that's useful is the FK chain function. Now this is for a basic forward kinematic setup, where you just need a control to drive"},{"start":"1:04","end":"1:37","startSec":64.6,"text":"the movement of a bone. But something great about this is you can actually filter out different translation and rotation axes, and just have it moving in one direction or rotating in one direction if that's what you need. When it comes to more complex robotic arms or legs, you might have something like a mechanical arm that you're using on an assembly line, for example. And for this you could use the IK3 bone function, which is a great way to get those moving where you need precise movement for the end bone in the chain, maybe it's a claw picking something"},{"start":"1:37","end":"2:10","startSec":97.6,"text":"up on an assembly line, and you need the rest of the arm to calculate its movement automatically. And when it comes to dynamic movement for your mesh, so this would be things like cables or chains on your mechanical mesh. There are a couple of useful functions that help you get some dynamic movement. So there's the local chain dynamics function, which will apply a sort of physics effect to a chain of bones just using maths. And there's the add jiggle function that simulates on just one element of the rig, which might"},{"start":"2:10","end":"2:42","startSec":130.6,"text":"be a bone or a control rather than an entire chain of bones. And it essentially uses a spring interpolate node to try and reach a target, whilst also allowing you to add a delay and damping on its movement. So it looks like it's jiggling as the rest of the mesh is moving. Taking a look at some useful control types here, depending on what type of control you create, you can actually give it different limits and force it to move in different ways."},{"start":"2:42","end":"3:13","startSec":162.4,"text":"So we have a mechanical arm here that's been set up. And for this yellow control here, if we were to select it, you'll see that we can't rotate in either the y or z axis, or can only rotate in the x axis. And that's because for this type of control, we've set it to be a rotator. That means it only has rotation, or it only has the possibility to rotate. And under the settings here, we're actually able to give it some minimax settings."},{"start":"3:13","end":"3:48","startSec":193.9,"text":"So if you were to activate minimax for x and y, sorry, for y and z, and to set them both at zero, that would limit the movement so that it can't move in those axes. And you can only move in the open one. You can also change this to a position, for example, if you wanted to only have translation values, which can also be very handy. Now something else that has a slightly more complex setup is a float control here. If I just zoom in, you can see that as we move this float control down, this claw opens"},{"start":"3:48","end":"4:19","startSec":228.7,"text":"up, and as we move it back, it closes. And that's because we're essentially converting the transform information, or the float that comes out of the movement of this control, into rotation information for these two claw bones. And in utilizing these different control types with their min and max settings, you can quickly get something moving in a mechanical way, when you're locking down the different axes in which it shouldn't be able to move."}],"04-1_BuildingMechanicalRig":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"What we're going to do next is jump into the engine and start utilizing some of these tools to build a mechanical rig of our own. We'll be building it for the mech character inside the project, showing off how to set up a few different control types with their Min and Max settings, setting up the leg with an IK3 bone function, and showing off how we can get pistons moving in a couple of different ways. And then we'll finish off by adding some dynamic movement to our skeletal mesh. So now would be a great time to open up your project if you want to follow along."},{"start":"0:34","end":"1:11","startSec":34.6,"text":"First things first, we need to create a control rig asset. So inside the project here under the content browser, if we go to meshes and then mech, and inside here we have our mech mesh. I'm going to right click, come up to create, and choose control rig. And then I'm just going to rename this cr underscore my control rig. And I'll just double click to open that up and dock it in the window here."},{"start":"1:11","end":"1:45","startSec":71.3,"text":"Now the first controls we're going to set up will be for our turret here and for the turret base. And we're going to use the rotator control type so that they can only rotate. And then we'll limit the movement of the turret using the min and max settings. And then once we've got that set up, we'll utilize the FK chain function to actually connect the controls and the bones together. To create the two controls, I'm going to select the turret base and main gun. And you can either use the shortcut control N, or you could right click, come up to new,"},{"start":"1:45","end":"2:18","startSec":105.4,"text":"and select new control. And down outside the hierarchy here, what that will do is create a new control for each thing you have selected. And it will actually maintain the hierarchy that they have in relation to one another. So we have the main gun, childhood to the turret base. So there's two things we want to do now. We want to change the type of control that this is. And we want to customize the look of it so that we can see it a little better and it's a little more user friendly. So to change the type with both of our controls selected because we want them to both be the"},{"start":"2:18","end":"2:49","startSec":138.9,"text":"same type. We're going to come to the details panel and under the value type drop down, change that to rotator. And you'll see that under the value heading here, we only have rotation as a min, max setting that we can set now, as well as seeing the current and initial values, meaning that these controls are only going to rotate. And what we can do now is just customize the look of these. So with the turret base control, let's make that a circle thick."},{"start":"2:49","end":"3:21","startSec":169.7,"text":"And I'm just going to click this scale icon to lock all these three axes together. So when I edit one, they'll all be edited together. And what I want to do is just keep bringing this up until it's a suitable size. And that should sort of do us for now. And with the turret main gun control, if we zoom in on this one, I'm going to make it a circle thick again. But if I zoom right there, you can see that it's not really oriented in a very useful"},{"start":"3:21","end":"3:52","startSec":201.9,"text":"way for us to know how it's going to work when we're rotating it to move this main gun up and down. So under the shape transforms here, I'm just going to rotate it 90 along the, I think it's the y-axis. Well, let's take a look. Let's just scale that up to around about 30. No, so it's not the y-axis. It's going to be the x-axis that we want. There we go."},{"start":"3:52","end":"4:25","startSec":232.3,"text":"So now this control, we could even go a touch bigger. Now this control indicates that it's going to rotate in this axis just because of the way that it's facing. So what I'm going to do here to make sure that we limit it from moving in any other axis is select the control either from the viewport or from the rig hierarchy window and come up to the min-max settings here. And we know we only want to rotate this gun up and down in the y-axis."},{"start":"4:25","end":"4:58","startSec":265.2,"text":"So what I'm going to do is activate the minimum for the x and z-axis, leave those at zero, and do the same for the max, but set them to zero as well. And this will mean that it won't be able to rotate in those two axes. So you can see now if I move them, nothing's happening. We also know that we want to set some min-max of our y-axis so that when we rotate it downwards,"},{"start":"4:58","end":"5:33","startSec":298.8,"text":"it doesn't pass through the main turret base here. Now I know what those values are, but just to show you the process of how we kind of figured those out, I'm first going to restrict the axes that the turret base control can move in, and then I'll connect them up to the bones to see how they're actually affecting our mesh. So we just want to rotate in the z-axis. So what I'm going to do under the min, I'm going to activate the x and the y, and leave"},{"start":"5:33","end":"6:07","startSec":333.6,"text":"them at zero, and do the same for the max, again setting those to zero as well. So now if we were to connect these up using an FK chain, which we'll do now, we should be able to see how our controls are acting. So I'm going to select these two controls, drag them in and choose create item array. I'll just minimize that for now and plug that into the controls array pin on the FK chain."},{"start":"6:07","end":"6:38","startSec":367.0,"text":"And then I'll come back to the top and find the two bones, do the same thing with those, drag those in, create item array, and I'll plug those into the bones pin. Now it's important that you select these in the right order, and that you have the turret base and the turret base in the same element number, and the main gun and main gun at the same element number. And when I connect up the logic, what we should see is that we can rotate this up and down,"},{"start":"6:38","end":"7:10","startSec":398.2,"text":"and our gun moves up and down. And if we rotate this along the z-axis, we can actually rotate the body of our gun. And we're not able to rotate an x or y for this, and the same with the actual gun itself. We can only rotate in the y, not the z or the x. Now if this gun section was part of the mesh that needed to be super accurate in terms of how many degrees it could rotate up and down, that's likely something that's been"},{"start":"7:10","end":"7:42","startSec":430.8,"text":"calculated when you were creating the mesh. So you'd know how many degrees to limit your rotation in the Minimax settings already. But for us, I'm just going to do this by eye and round the figures to the nearest point five. And to do this, if I come towards the control here and just take a look closer at our mesh, I'm going to open the current tab under the transform heading. And as we move this, you'll see that that value gets updated."},{"start":"7:42","end":"8:19","startSec":462.6,"text":"So what I'm going to say is as we rotate down, maybe we don't want to go any more than something like six degrees there. Or maybe we could go touch further. Yeah, maybe we could go about nine degrees. So that would be our minimum offset. And our maximum, we just want to pull that up ever so slightly. I think from the previous testing, it's around about two and a half degrees. So I'm going to come to our Min setting here and activate the Y and set that to minus nine."},{"start":"8:19","end":"8:50","startSec":499.8,"text":"And under the max, set that to 2.5. So now when I select this and try to rotate it, it'll come down all the way to nine degrees. And then it won't actually let me go any further. And the same when I'm going up. So it's now locked to this range of motion. So if you do have a range of motion, a specific number of degrees that something should rotate in, this is how you'd set up those values."},{"start":"8:50","end":"9:07","startSec":530.5,"text":"So that's how we would go about setting a rotator type control and setting up the min and max axis, min and max values, should I say, on each axis. Next, we'll take a look at the IK3 bone function and set up one of the legs for this mech."}],"04-2_BuildingMechanicalRig":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"To set up the IK3 bone function, we're going to need two new controls, one for the foot and one for the pole vector, and tell the function which bones we want to affect. Let's give ourselves a little bit more space here and search for the IK3 bone function. Now you can see that this function takes a lot of information in, which is predominantly about the axes of our bones, a pole vector node, and then the bones that we're trying"},{"start":"0:31","end":"1:07","startSec":31.9,"text":"to affect along with a foot control. We're not going to create a thigh control today because a foot control will be all we need. So the first thing we're going to do is figure out our primary and our secondary axes. So if we hover over the function, we can see that the primary axis is the axis pointing down the bone, which is typically X, and the secondary axis is our up axis, which is typically Z, or sometimes none. So I pop these open. To figure this out, what we can do if I come to character and bones, then all hierarchy,"},{"start":"1:07","end":"1:37","startSec":67.0,"text":"we'll be able to see all the bones in the viewport here. And the bones that we want to affect will be sort of the upper thigh, lower thigh, the lower leg, and a foot down here. So if I select that from the viewport, we can see that's our leg FR01L. And to see the orientation axes on this, if you come up to the option box at the top and choose display axes on selection, this is not usually turned on by default, so you should"},{"start":"1:37","end":"2:08","startSec":97.9,"text":"have to turn that on. And then if we zoom right into that control, the bones, sorry, we can see that the Z axis, the X axis is pointing along our bone, and the Z axis is the one that's pointing up. So our primary axis is pointing along the bone, that's X, and secondary axis will change that to be Z."},{"start":"2:08","end":"2:42","startSec":128.5,"text":"Now we don't have any all vector node yet, and we don't have a foot control. But what we do have are the bones in the chain. And if we pop each one of these open, we can actually fill this information in now. So bone A is going to be the most, the uppermost bone in our chain, which is going to be the leg FR01L. So with that selected, we can hit this little arrow and fill that information in there. And then just go down the chain and add each of those."},{"start":"2:43","end":"3:13","startSec":163.2,"text":"And if I find O4, the foot base just here, we can plug that in as well. So leg 01, 02, 03, and 04, that represents the chain of our leg. Now that we have our bone information set up, we can create the foot control. And we're going to do that based off of the leg 04 bone. So if I browse to that, I can right click, go to New, Control."},{"start":"3:13","end":"3:44","startSec":193.7,"text":"And down the bottom here, you'll see we've got New, Control with the same name, just out of the hierarchy of the skeleton. And we'll customize the look of this again. So I'll make this a box, and I will just scale it up a little. Maybe that's a bit too big. And so it's not quite so awkward to animate with. What I'm going to do under the offset heading here is reset the rotation of the Y channel,"},{"start":"3:44","end":"4:20","startSec":224.5,"text":"or the Y axis, to zero. Just so that if we were to translate this up and down, or move it forwards and backwards, it's just easier to animate within that sense. And now we can put the information into our IK3 bone function. So we're going to do a little bit of math to make sure that we get this control in the"},{"start":"4:20","end":"4:53","startSec":260.6,"text":"right location, to make sure that it's on the same plane as the leg joints. Luckily, there is a function that already exists to help us do this. So what I'm going to do, if I just drag this out here, give us more space again, right-click, search for compute pole vector. Now this is going to ask us for the three bones that we want to use as our plane to create the pole vector's location from. And the output transforms are going to give us that location."},{"start":"4:53","end":"5:24","startSec":293.8,"text":"So first of all, we need to create a new control. So if I right-click in a blank space, select new control, and just rename this leg underscore pv underscore ctrl. So this is going to be a leg pole vector control. I'll just change this so we can see it more easily in the viewport, to a sort of green sort of color. And I think what we'll probably do is just scale that up to maybe five, for example."},{"start":"5:24","end":"6:01","startSec":324.1,"text":"So this is our new control. But again, it's not in the correct location. So we need to feed this compute pole vector function the three bones that we want to use to calculate its position. And that's going to be our fr02, 03, and 04. So if I plug in 02, plug in 03, and then plug in 04, that's sort of our thigh, knee, and foot bones. And if I then connect up that logic, what we'll do is use this transform information to set"},{"start":"6:01","end":"6:35","startSec":361.2,"text":"the position of this pole vector control. So I'm going to drag that into our rig graph and choose set control, connect up the logic, and connect up the transform pin to the value pin. And you can see that positions our pole vector control along the plane of those three bones and we know that it's perfectly aligned. One thing that I'm going to do is just increase this offset factor value so that we're a little further away from the mesh. And it means it's easier not to get lost inside the mesh."},{"start":"6:35","end":"7:11","startSec":395.4,"text":"Now we don't want this running all the time because if we're setting the transform of our control, we won't be able to move this and animate it. So if we right click the control where it is now and choose set offset transform from current. That sets its new sort of zero pose like freezing transforms in mayor. So we can now delete this small bit of logic, compile, and we'll see that this pole vector control is now positioned in the world along the plane of those three bones."},{"start":"7:11","end":"7:44","startSec":431.1,"text":"So now if we were to grab that, input that into our IK3 bone, we can then connect up the logic. And those are small pop there, but that's something we can fix. But we now have control using the pole vector over where that knee is pointing. And we also have the foot control, which means that we can move this round and place it wherever we need to. And then tie leg is reacting and automatically moving where it needs to. Now that small pop is just due to the fact that we're actually allowing the bones to stretch"},{"start":"7:44","end":"8:17","startSec":464.7,"text":"to 1.5 their original length. So if we set that back down to 1, that'll fix that and bring those bones back in line. So we now have the rig set up with the rotator controls for the gun and for the gun body, as well as our IK leg setup using the IK3 bone function. The next thing we're going to look at is a little bit more exciting. We're going to take a look at the piston function so that whenever we're moving these, the legs"},{"start":"8:17","end":"8:27","startSec":497.1,"text":"around, you can see the pistons inside here just underneath. We'll make sure that they're functioning properly and always pointing towards one another and not deforming in the strange way that they are now."}],"04-3_BuildingMechanicalRig":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"As I said earlier in the course, the Piston function is essentially a two-way aim constraint that keeps both bones pointing towards one another. And we're going to set this up by using some nulls within the bone hierarchy. Now if you haven't used nulls before, they are essentially like using a group in the rig hierarchy when you're rigging in Maya. They give you the extra level of control within the hierarchy, but they can't be selected or transformed in the viewport. So let's set that up for one of the Pistons in our leg to get some automatic movement"},{"start":"0:32","end":"1:03","startSec":32.3,"text":"as the foot is moving. The first thing I'm going to do is find our Piston function. And let's see what variables it needs. So it's looking for a start control and an end control. And these are the controls that the bones are going to be pointing at. And it's looking for a start bone and an end bone. And these, as you probably guess, are the bones that we're going to have point. The up control is something we're not going to worry about or need for now."},{"start":"1:03","end":"1:38","startSec":63.5,"text":"But the axis and the up vector axis are the same sort of idea that we had from the primary and secondary axis of the IK3 bone. So the axis is what's pointing down the bone, and the up vector axis is the up vector, the up axis of our bone. So the first thing we're going to do is actually create some nulls as the children of these bones that we're pointing or that we're aiming. So we're going to use these two bones here. So the Piston 401, if I right click that, choose new null."},{"start":"1:38","end":"2:10","startSec":98.3,"text":"And then the Piston 402, again, right click this and choose new null. Now you'll see that adds a null under the selected bone inside the hierarchy. And again, this isn't something you can see or select in the viewport. It's just something we can use to sort of affect the hierarchy or affect transforms of something else. And these are going to be our start and end controls. So what I'm going to do is just right click, rename, and put underscore start on the end"},{"start":"2:10","end":"2:44","startSec":130.1,"text":"of this one. And underscore end, oops, on the end of this one. And our end bone or end null, should I say, should go into the end control here. You'll see the type starts off as none, but if you use this small arrow with whatever you have selected, it will automatically update that type. And if I select the opposite end to find our start, I'll plug that in there."},{"start":"2:44","end":"3:14","startSec":164.6,"text":"Now let's tell the node or the function what bones we want to use to aim towards one another. So our start bone and our end bone, our start bone should match our start null. So above the start null, we have the piston 0, sorry, piston 4, 0, 2. We just plug that in there. And then I'll use the magnifying glass to find our other null. Oops, it's not working for some reason. Try again. Nope, okay."},{"start":"3:14","end":"3:45","startSec":194.8,"text":"Well, we'll select it from the viewport by finding the bone and then finding our null here. So this is our end bone that we want to use, the parent of the end control or the end null that we're using. So now we have our start and end control and our start and end bone. And what's going to happen essentially is the start bone is going to point towards the end null."},{"start":"3:45","end":"4:18","startSec":225.0,"text":"And the end bone is going to point towards the start null. Now this is made possible because the nulls are children of the bones and they'll follow them wherever they go. If you were to try and make this without the nulls or controls in the hierarchy, it essentially wouldn't function correctly. Now what we need to do is check our axis and our up vector and fill in this information here. Now again, make sure that display axis on selection is checked on."},{"start":"4:18","end":"4:51","startSec":258.1,"text":"And when we select both of these here, we can see that X is pointing in the direction that we want to be, you know, we want this bone to be aiming. So it's pointing in the direction of the mesh and Z is going to be our up axis. So these are actually set up correctly. So if we were to connect the logic up here, we shouldn't see anything change in the viewport yet until we start to move this foot control. So as soon as we start to move that, you can see that our piston is actually compressing"},{"start":"4:51","end":"5:25","startSec":291.7,"text":"and expanding, always pointing towards one another as this leg is moving and as the foot is moving, causing that sort of realistic piston action there. It's not incredibly obvious, but if I just disconnect this, you will be able to see just how clear it is and reconnect it up. And that's how you get a piston functioning with your control rig. Now this has a lot of different pistons on it."},{"start":"5:25","end":"5:42","startSec":325.5,"text":"So you could go around and set this up for each of the pistons inside the character. And every time that you move the leg or the foot or whatever it is, there's a parent of these bones. You're going to get that automatic movement of the piston looking like it's compressing and expanding as the meshes around it are moving."}],"04-4_BuildingMechanicalRig":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Now let's take a look at the offset transform node. We're going to utilize this to get the leg pump bones moving automatically when we rotate the leg. And we'll do that by converting the rotation values of one of the leg bones into translation values. And then apply those offsets to the leg pump bone using the offset transform node. So let's take a look and see how that gets set up. So what we want to do here is as we move this leg, if I just hide the bones to make it a little easier to see."},{"start":"0:33","end":"1:03","startSec":33.6,"text":"Yeah, as we move this leg and move this foot control, we want this leg pump piston out here to actually automatically extend. So that it looks like it's connected mechanically and it's functioning in an interesting way. So let's get that set up. Because we want to convert the rotation information of one of the bones into translation information. The first thing we need to do is find the rotation values."},{"start":"1:03","end":"1:38","startSec":63.9,"text":"So I'm going to find the bone that we want to convert the rotation data from. And that'll just be the top of our chain here. So leg F R O 1. I'm going to drag that into the rig graph and choose get bone. Now that'll give us the information about that bones transforms. So the rotation, the translation and the scale. And to convert this rotation into translation information, we're going to use a two Euler node. And this will essentially break up each of the axes or rather break up the rotation into"},{"start":"1:38","end":"2:12","startSec":98.1,"text":"each of the axes that we have here. And if I connect this straight up to a offset transform node. The item as our leg pump bone, which will be this one just here. And connect up just one of these axes, which is going to be the X axis that we want to affect here. So if I just pop open the offset transform here and open the translation."},{"start":"2:12","end":"2:47","startSec":132.4,"text":"So it's the X axis that we want to affect with the translation for the pump bone. It is actually the Y rotation, if I just show you this here, that Y rotation axis as the leg is rotating up and down. Those are the values that we want to take to feed into the offset transform. So we'll grab our Y rotation, plug it into the X translation. And if I connect that logic up just here, we'll see that instantly we get some movement"},{"start":"2:47","end":"3:16","startSec":167.3,"text":"from the leg pump bone there. So as we're moving this, we can see that our leg pump bone is moving. So we have the logic set up correctly at least. We can see that it's not quite right though, because it's kind of penetrating with its own mesh. In order to fix this, what we need to do is add the initial rotation values of the bone that we're getting the transforms from. So this bone here."},{"start":"3:17","end":"3:49","startSec":197.3,"text":"Back onto the leg pump bone so that it sets its initial position back to zero. And I'll show you that with a demonstration here. So if you select the bone that we're using for the rotation, we can see that we're using the Y axis and its initial value is 44.639769. So if I drag off here and choose add, we can type 44.639769. And as soon as we connect this back up, we should see that shoot back to zero back to its initial position."},{"start":"3:49","end":"4:21","startSec":229.8,"text":"So now when we move it, the leg pump moves forwards and backwards when we're moving the leg. But it still has a slight issue where it's kind of, if we go too high with this leg, so if the leg rotates too far upwards, it's actually penetrating back inside again. So we can actually clamp these values next to say, okay, you're not allowed to go past zero as your minimum and we'll cap it a maximum of around about 35 as well, I think."},{"start":"4:21","end":"4:52","startSec":262.0,"text":"So to do that, if I just make a bit more space here and drag out of this result pin, search for clamp. This is a handy node for when you need to just limit the translation of something that's being driven by, you know, something else. So if we connect up the logic there, we're now going to say your minimum is zero. If we leave it as the maximum zero, you see that that no longer moves. But if we set our maximum to something like 35, whatever's suitable for your machine,"},{"start":"4:52","end":"5:23","startSec":292.3,"text":"you can see as soon as we hit that extent of 35, it stops moving. And when we go backwards, there's no longer any sort of negative movement or the tip of this penetrating into the base of the mesh. So that's a relatively quick solution that you can use to convert rotation information to translation information and then use that to drive the movement of another bone. So you would get the transforms of the bones that you want to use to drive, use a two Euler"},{"start":"5:23","end":"5:50","startSec":323.8,"text":"node to break down the rotation into its individual axes, and then make sure that if you want the bone that you're offsetting to have its initial position at zero, make sure you're either adding or minusing your initial values of this bone that we're using. And then if you want to clamp the values because you know it's going to have limited range of motion, you can do the clamp node and then plug that into the offset node. So it's fairly straightforward."}],"04-5_BuildingMechanicalRig":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"The last thing we're going to take a look at is how we would add some dynamic movement to parts of our mesh, and namely that's going to be the cables of this mech character. For that we'll use the addJiggle function first. So let's see how we set that up. So we're going to add jiggle to some of our toe cables here. And for that we need to find the addJiggle function. So let's just add one of those to the graph. Oops, so I search for addJiggle."},{"start":"0:34","end":"1:07","startSec":34.6,"text":"And the jiggle function takes in two bits of information. It takes in a child to jiggle, which is the bone or the rig element that you want to jiggle. And it takes a control input, which is a control that we're going to create at the origin of this bone that we're jiggling, because it's essentially going to use a spring interpolate node to calculate a vector from the bone's current position to the control's current position and add like an offset delay. And you get control over the strength and critical damping to make the bone jiggle more"},{"start":"1:07","end":"1:43","startSec":67.7,"text":"or jiggle less, giving you control over that delay. So to set this up, let's give the function a control and a child to jiggle. So with the foot here or the cable that we're trying to jiggle, the toe cord, I think it would be the end one, yeah, toe cord 3, FR02L. So that's going to be the bone that we want to jiggle. So I'll just put that in there as a child to jiggle. And I'm going to press control N to create a new control at the location of that bone."},{"start":"1:43","end":"2:14","startSec":103.9,"text":"And I'm going to parent it underneath the foot control that we have here, the Lego 4. And that means that when we remove the leg or the foot, that control is going to come with it. Now if we select this control as our control to use our target, our vector target, and then connect this up to the main logic here, what we should see when we move this foot is that we now have jiggle on that bone there."},{"start":"2:14","end":"2:48","startSec":134.0,"text":"So it really is that quick and that simple to actually get jiggle or some sort of dynamic movement set up on something like a cable on your mesh. Now you have control over stuff like the stiffness, which is the strength here, and the damping, the critical damping here. So we could up that to 4, for example, to customize the look of this. And we can see that it becomes a little bit faster now, a little bit more stiff, a bit more rigid. And if we increase the damping to 1, for example, you'll see that it doesn't have as much jiggle,"},{"start":"2:48","end":"3:19","startSec":168.8,"text":"it doesn't have as much overshoot, it just slowly comes to rest. So you can tweak these values until you get something suitable for your control rig and for your character, depending on how big the chord is, how much you want it to move, and things like that. Now if you have a lot of cables like we do on here that we want to jiggle, what we could do is if we select each one, let's try that again, select each one of these and press"},{"start":"3:19","end":"3:51","startSec":199.1,"text":"control N to create a control for each of them and make sure they go inside the leg control. We can actually do a little bit more logic here to get them all moving together. So we can do an item name search. And what this is going to do is allow us to search for a partial name, so in this case"},{"start":"3:51","end":"4:25","startSec":231.6,"text":"we'll do toe cord because that's the name of our controls. And it'll also allow us to search for a type. And in this case we're going to search for control. And this essentially gives us an array with all of the controls inside the hierarchy that contain toe cord in the name. So what we're going to do is search for a four each, which is just saying, okay, for each of the elements in this array, if I give us a bit more space, shrink that down a touch."},{"start":"4:25","end":"4:58","startSec":265.6,"text":"We're going to use this as the control for our control to jiggle. And for the child, what we're going to do is use the name of the control, or actually going to use a chop node to remove the last five characters from the name. That way we'll be able to find the bones names. If I put five on there, we'll take the remainder pin, plug that into our child to jiggle name"},{"start":"4:58","end":"5:31","startSec":298.6,"text":"here, and then connect up the logic so that we're using that for each, and then using the jiggle function. And now what should happen is if we move this, you see that all of them start to jiggle and all of them start to move. And we've really not had to do a lot of logic here or make a lot of controls or anything like that, or at least much manual work."},{"start":"5:31","end":"6:08","startSec":331.0,"text":"And to make this even more sort of organic and realistic, you could actually randomize the strength of each one of these by using a random float. And what we'll do is grab the index of this, which will grab an individual control that we have in this array, and we'll plug that into the strength. And we can say, okay, we want a minimum strength of two and a maximum strength of six, for"},{"start":"6:08","end":"6:38","startSec":368.0,"text":"example. If I compile that, what we should see now is that all of our feet bones, or our feet cables, should I say, all react ever so slightly differently between random strengths of two and six when we move the foot. And it just gives you that little bit more of sort of organic movement, realistic movement, and not seeing everything sort of mirrored or moving in unison together."},{"start":"6:38","end":"6:52","startSec":398.7,"text":"So that's a great way to add some dynamic movement to the cables on your mesh. And as you can see, it's actually quite fast to get working. Next we'll take a look at the chain dynamics to just see a different way of adding some dynamic movement."}],"04-6_BuildingMechanicalRig":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"The local chain dynamics function is a super simple function to set up. And this is more useful when you have a longer chain of bones compared to the jiggle function. So back into our project here, if we search for local chain dynamics, we'll find our function just here, I just zoom in on that. You can see that all the function really needs as an input is an array of bones. So this will essentially just be from your first to your last bone in your chain."},{"start":"0:32","end":"1:08","startSec":32.4,"text":"Now if I come up to the viewport here and show our bones, we've not got many long chains of bones on this mesh here, but we do have a chain of two bones here for these cables underneath the main gun. And what we're going to do is select those two bones, drag them in and choose create item array. And for this, you would just connect them straight up to the bones input pin. And if we connect the logic up, we should quite quickly see that we get some movement on these or this chain."},{"start":"1:11","end":"1:41","startSec":71.4,"text":"So it's super, super quick to set up. And now you have the option to play with all of the properties of the function here. So we have the strength and damping that we can tweak, which works the same as it does with the jiggle function. You also have access to the blend start and end here, which essentially allow you to determine the strength of the dynamics at the start and end of the chain. And then we have blend twist, which allows you to determine how much twist you want on the chain."},{"start":"1:41","end":"2:12","startSec":101.4,"text":"So what we could do here, if we see it moving perhaps a bit too much, we could increase the strength here, which will increase the stiffness to something like six. And now it feels a little less floaty and there's a little bit more rigidity to it when it's coming back to settle. And you could crank that up to eight just to see how things look. And you can see it doesn't swing out as far and it's a bit more stiff than it was before."},{"start":"2:13","end":"2:46","startSec":133.4,"text":"This chain's not super long, so we're not going to be able to get many settings out of the blend start and end and twist settings here. But what we can do is add our other chain. So we have two cords hanging underneath this gun. So I could select all of these cords like this, connect them up, hit compile. And that will affect both of the chains individually like that. Now you could do this for several chains and they'd use the same settings essentially,"},{"start":"2:46","end":"3:19","startSec":166.4,"text":"but if you wanted to change these, you'd need one function per chain. To demonstrate this with a longer chain of bones, I've just opened up another character here and I very quickly made just a pelvis control that we're copying the transforms from onto the pelvis bone. And then the local chain dynamics function where we've set up an array that contains our spine and our neck. So you can add a bunch of bones in here as long as they're in a chain and then you can see that that affects the whole body in this case."},{"start":"3:20","end":"3:52","startSec":200.4,"text":"And this is how it essentially works just with a longer chain here. And again, you can tweak all these settings to make anything a little bit stiffer. So you can see that if this was kind of moving robotically, you might be able to get some chain movement on any sort of hydronic pipes that you might have or chains that you might have. And obviously you can tweak all these settings here to customize the look of that. But yeah, I just wanted to briefly show that to show that it's not just for short chains of bones that we used it for in the demo here,"},{"start":"3:52","end":"4:05","startSec":232.4,"text":"but you can also use it for long chains. And really that's more what it's designed for in comparison to the jiggle function. But there we go. That's just a quick setup of the local chain dynamics."}],"04-7_BuildingMechanicalRig":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"The last thing that we're going to take a look at in the demonstration is the aim node. And I just want to show you a different way to control where our gun is pointing. Now this might be useful if you want to be able to lock onto or track something, or essentially if you always want something to be aiming at something else and not have to sort of manually animate the rotation to account for that. So to get this setup, the first thing I'm going to do is just bring our forward solve"},{"start":"0:33","end":"1:06","startSec":33.1,"text":"out here a little bit and search for a sequence node. And this is just so we can kind of split the logic into two flows and understand things a bit more clearly. So first we'll plug in all the logic that we had and then down here I'm going to search for an aim node. Now we're just getting a warning there because we haven't set anything up yet, but we have connected the logic. So by default, the thing that the aim node is looking for is a bone. But what we're going to do is actually utilize the setup we have for these controls where"},{"start":"1:06","end":"1:37","startSec":66.8,"text":"we've set the limits and it's already controlling our bones and actually aim the control instead. And to make things a little bit more mechanically accurate, we're actually going to split the rotation between these two controls so that as we move this sort of aim control around that we're going to create in a moment. Our turret will move up and down in this axis with this control and rotate the entire body with this control."},{"start":"1:37","end":"2:08","startSec":97.4,"text":"So we're essentially splitting the yaw and the pitch rotations between the turret base control and the main gun control. So first we'll set up the turret base because that's going to be first in the chain of bones essentially. So if we select our turret base control and just press this arrow here, I'm just going to disconnect it so they don't get any funky results until we've set it up properly. I'm going to pop open the axis, the target, the target space and secondary here."},{"start":"2:08","end":"2:43","startSec":128.7,"text":"So under the axis for this bone, for this control rather, we need turret base to be minus one in y and zero in x. And then we need to be one in z for our target. And our target space is going to be the control that we're going to create that will affect these, the aim of these. So we're going to create it from the main gun bone. So if I select the main gun, press control N, we'll get a new control."},{"start":"2:43","end":"3:15","startSec":163.1,"text":"And I'm just going to call this cannon aim control. And with this control, we want it to be out in front of the cannon so that we can move it around and have it point towards it. So what I'm going to do in just the x axis because that's the axis that our bone is pointing and the axis that this gun is currently aiming is I'm just going to drag that out to some distance in front of the actual mesh."},{"start":"3:15","end":"3:46","startSec":195.9,"text":"And under the scale, I'll just set it to 10. And let's just change the color and perhaps even the shape, something like a wedge might be cool. And one thing I forgot to do there before I compiled is actually set the offset transforms from this control's current position. So that's why it popped back to its original location. So if I drag that back out again, right click, set offset transforms from current."},{"start":"3:46","end":"4:21","startSec":226.4,"text":"When I compile, this is the controls new offset transform. So when we're going to use this as our aim control, so as we move it left and right, up and down, we want our turret and our turret body to be pointing towards it. So with that control selected, I'm going to pop open target space here. Oh, whoops, not under secondary. Target space here just under the primary heading and input that as our control. And when we connect up the logic, if I just grab our sequence node here, hit compile,"},{"start":"4:21","end":"4:56","startSec":261.5,"text":"what we'll hopefully see is that when we move it left and right, our control, which is controlling the main body of the gun is actually rotating left and right with it. And if we move it up and down, forwards and backwards, we're not getting any other movement. There is a little bit just because it's off axis now. But if I compile that, move it up and down, we don't get anything there. Move it backwards and forwards. We don't get anything there. And that's just because we've set up the limits on this control already. So we don't have to do anything extra with the bones to sort of clamp their rotation."},{"start":"4:56","end":"5:27","startSec":296.3,"text":"We're relying on the settings of these controls to do all of that for us. Now let's set up the rotation for the actual gun turret itself. I'm just going to bring this down here a little bit so we have enough space. And drag off here, search for an aim node once more. And our target is going to be the same control. And under the target and axis, this time we're going to leave the settings as they are."},{"start":"5:28","end":"5:57","startSec":328.5,"text":"And selecting our, if I just compile that to make sure it's at zero, selecting our main gun control, that's going to be what we want to use to aim towards this cannon aim control. So now if I move this left and right, we have the movement on the turret body. And if I move it up and down, we should have the movement from the main gun. And again, that's locked in terms of how much it can rotate."},{"start":"5:59","end":"6:31","startSec":359.7,"text":"Because of the settings that we created, or the values that we set up, should I say, for that control itself. So you could pin this somewhere in the world, and then as the rest of the mech is moving around, it would always track this one location. Or you know the mech could be standing still, and you could be moving this location, unlocking it onto some sort of target that it's trying to aim and fire at. Now one thing to note is that it's going to override the control of the turret base and the main gun controls."},{"start":"6:31","end":"6:38","startSec":391.7,"text":"But you could do something like set up a switch that would toggle between these two different control types, depending on which one you'd like to use."}],"05_AdditionalFeatures":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"That about wraps up our exploration with some different tools that are helpful with mechanical rigging specifically. But I just wanted to briefly touch on a few more useful tools that are available in Control Rig, that we don't have time to look at within this course, but might help you out when you're building your own Control Rigs. So you can create your own function libraries, which is essentially a way to package up sections of logic within your Rig Graph into a custom function. And you can then share that across all of the Control Rigs in your project just by setting it public."},{"start":"0:36","end":"1:12","startSec":36.0,"text":"Just the same as how the standard function library was created that comes with the engine, where we've been using functions like the Jiggle function, the FK chain and the local chain dynamics functions. And this can just be super helpful essentially to speed things up when you're creating your rigs. There are also a bunch of nodes and functions that enable you to create splines and attach bones to them. And you can create these procedurally using the construction event, which give you a pretty interesting way of controlling the bones within your mesh and can really increase the flexibility of your rig."},{"start":"1:12","end":"1:44","startSec":72.0,"text":"Now something that's really cool about Control Rig is the hierarchy of your controls isn't necessarily fixed, which means at runtime you're able to dynamically update the hierarchy, giving you a greater degree of control and enabling you to set up the control systems that you wouldn't be able to otherwise. Control Rig also has a very useful debug mode, which has a bunch of features available to help you track down any issues with your rig and get them fixed. So two very useful features for this are breakpoints,"},{"start":"1:44","end":"2:19","startSec":104.0,"text":"which allow you to just step through the logic of your rig graph and find out where things might be going wrong so you can fix them. And visual profiling, which is essentially a visual representation, kind of like a heat map of how costly something might be in terms of computational expense, which is going to help you understand how expensive different features and functions are to help you optimize your rigs. And you can access this specifically from the class settings, so under the VM runtime heading, if you just tick enable profiling, that'll give you access to this."}],"06_Outro":[{"start":"0:00","end":"0:39","startSec":0.0,"text":"So that about wraps up the course. And just to do a recap of the things we've covered today, and hopefully the things you've learned, we went over some of the considerations that you might need to make before you actually bring your Skeletal Mesh into the engine. So things like bone orientations, your hierarchy, and how you might want to skin certain parts of your mesh. Then we set up a few different control types that might be useful for mechanical rigging specifically. As well as setting up a simple rig for our Mesh where we utilize some of the useful functions and nodes that are specifically aimed at mechanical rigging."},{"start":"0:39","end":"1:01","startSec":39.0,"text":"So thank you very much for your time and for following along with the course. And don't forget we have plenty of other courses available to increase your control rig knowledge. So if there's anything else you want to learn, please be sure to check those out. But otherwise, best of luck with your mechanical rigging and thank you once again. Thank you."}]},"209.01":{"01_Overview":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hello and welcome to today's Unreal Engine Training on post-processing and rendering. Today we'll be covering a few different things. We'll mostly be talking about color control flow, post-process, whether it be look and feel, how lumen and ray tracing may affect this. We'll talk about lookup tables and open color I.O. We'll go into some post-process volume exposure settings and then talk a little bit about depth of field. And then on the rendering side, we'll be talking about how to render out movies via"},{"start":"0:30","end":"0:37","startSec":30.6,"text":"a sequencer. We'll go into the movie render queue. We'll talk about console variables and the GPU timeouts."}],"02_Post Process Control":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"So diving into look at post-process control, we're going to be covering the topics that I just mentioned in the previous slide there. And so jumping into color control flow, this is how the color grading workflow works in Unreal Engine. So you want to turn off your auto exposure in the project settings, and the project settings can be found under the edit tab at the top of your editor there. And then you want to set the temperature, which is your white balance. Once you've set the white balance, you then go into the tone mapper and look at the film and the global project settings."},{"start":"0:36","end":"1:07","startSec":36.0,"text":"We can color correct per shot and just make sure all of our colors are set to the right levels before we go in and edit anything else. Then you can go into your shadows, mids and highs if needed, and then also then your in-camera adjustments. So we've got global post-process controls using a post-process volume, which we will dig into in a few slides here. And then you can also layer in multiple post-process volumes if you want some blending happening throughout the scenes."},{"start":"1:07","end":"1:37","startSec":67.0,"text":"You can also edit it per camera as well. So if you'd like some global settings setting, you can use post-process volumes. If you want it per shot, you can do in-camera adjustments there. So the post-process control look and feel, we have the ability to edit color, tone, shadows, mid-tones, highlights and miscellaneous effects. You've got chromatic aberrations and lens flares and you can add dirt masks. And you can see all the properties here on the right hand side."},{"start":"1:37","end":"2:10","startSec":97.0,"text":"The best thing to do is to just dive into these settings and play around. You'll find a workflow that works for you and you'll generally then go into edit similar properties once you set some kind of visual standard. A useful thing to do when editing these properties, because there are so many properties in the post-process control, something I like to do is make sure favoriting is enabled in your project settings. So again, go to edit project settings and just type in favorite."},{"start":"2:10","end":"2:47","startSec":130.0,"text":"And what you can actually do is enable favorites. This may be on by default in the project template that you've got. So if it's already on, that's fine. And then what you can actually do is you can hover over one of these properties. You can right click and say add to favorites. And so you can create a set of favorites of variables that you edit on a consistent basis. And they'll go straight to the top of the list on the details panel. So you have some quick go to options there, which I find really handy when editing similar per camera shots that need certain values editing."},{"start":"2:47","end":"3:18","startSec":167.0,"text":"We also have the color control flow here. So ACS, industry standard for film and TV, the closest approximation of the entire color gamut, which is available to the human eye. It maps to HDR rendered outputs and LDR displays and you use it for a project wide look. So you can see the diagram on the right hand side here of what exactly the film tone mapper properties are editing. You have the five variables here."},{"start":"3:18","end":"3:56","startSec":198.0,"text":"And for each of the variables, you'll see the representation on the diagram. So the slope is looking at the overall slope of this S curve coming through the diagram here. You've got the toe, which is the bottom of the S curve. You've got the shoulder, which is the top right, the black clip, which is this far left side and then the white clip, which is the far right side. So if you're familiar with any color grading software, you'll you'll no doubt be familiar with these variable variables and properties. But just to give you a bit of an overview and just really dig into when you're editing these variable variables, what exactly they're doing here."},{"start":"3:56","end":"4:40","startSec":236.0,"text":"We've also got to make sure that we have our studio office lighting conditions set up. So the monitor, you want it to be 100 percent sRGB, rec 709. We've got high contrast ratio. So maybe 2000 to one or something in that region there. Peak luminance at 100 and the black level at 0.05. And then you just want to calibrate it with some built in calibration tool. So when we go back to that flow diagram that we said at the very start, when we just disable the exposure and when we're talking about setting these white balance levels, you just want to make sure everything is set up correctly before you start digging in."},{"start":"4:40","end":"5:14","startSec":280.0,"text":"Also, you know, if you have any effects on your monitor, maybe you've got some sepia to help with blue light or anything like that. Making sure all these things are just disabled before you start your color grading process. So some best practices for VR here. You want to set SSAO low. You want to set the bloom low or off completely. You want to set SSR low or off completely. Lens of lens flares don't work in VR."},{"start":"5:14","end":"5:49","startSec":314.0,"text":"So you probably want to turn those off and also just turn it off motion blur because that can affect the VR experience. So you don't really want image effects. You don't really want a dirt mask or film grain on the VR. You just want the the viewers kind of purest experience through through the VR headset. When you add a post process volume into the level, you'll find this property infinite extent unbound. And again, this might be something you parent as a variable because you end up going to these quite often."},{"start":"5:49","end":"6:20","startSec":349.0,"text":"If you tick unbound, then it means that even if that post process in your scene is a small box, it will affect the entire map. So it's not that you have to then scale that post process across the entire scene. You can just make sure it's unbound and unbound essentially just means affect the entire world. And depending on then the priority, you can then have other post process volumes blending in and blending out of this this main post process."},{"start":"6:20","end":"6:50","startSec":380.0,"text":"But yet the unbound essentially just means it affects the entire world. And when we talk about these screen effects, you can find these screen effects here. It's also useful to go over the different ways we can approach LUTs in our work. So LUT is essentially a lookup table and this approach is a legacy approach. But it's worth exploring just so you know the pipeline here. So a simple definition of a LUT is a set of instructions for remapping pixel values. So you can see Sean's image here."},{"start":"6:50","end":"7:26","startSec":410.0,"text":"He's put a red violet around this on this scene, whether it be in camera or on a post process volume. And it gives it a certain look and feel. So they're essentially lookup color tables. So you get a snapshot of your scene, some kind of high res screen capture. If you are doing high res screen capture, there's a tool at the top of your editor window to do that. Just in that viewport where you can select the drop down arrow and go to high res screenshot. You can select that or you can also capture them whilst you're in the world just using high res shot."},{"start":"7:26","end":"7:56","startSec":446.0,"text":"So you can look for a console variable there if you want to do a bit of research on that. In Photoshop, you'd run the needed filters to get the contrast and color, etc. The way that you want it. Then you can drag it into a neutral color table provided. Make sure that the mode is 16 bit. Import it into Unreal Engine and then set the LOD and the texture. So you want to when you have imported this into the editor, you want to set the LOD in the texture to no mipmap."},{"start":"7:56","end":"8:26","startSec":476.0,"text":"So what that means is double click the texture. Go to the LOD and just make sure it says no mipmap there. Assign the texture group, color lookup tables. So again, these properties are both in the texture properties when you import them. So import the texture and double click the texture to edit these variables. And then in the post process volume under the mist tab, put the 3D look in the color gradient look section. So again, if you were using this approach, you can maybe favorite this variable and then you'd know exactly where it is."},{"start":"8:27","end":"9:00","startSec":507.0,"text":"You can also just search for LUT in the details panel and that will appear for you. So just a note for this approach, this is a game centric method. It is not HDR efficient for virtual production output as the LUT clamps the bit depth at 8 bit. So probably not a process you want to use a lot of the time or if at all. But it's also worth highlighting for those wanting to know about this this feature if if need be. So there's also another approach for LUTs, which is a 3D volume."},{"start":"9:00","end":"9:36","startSec":540.0,"text":"So you create the image to embody a 3D LUT. The size of the LUT data must be known. So for this example, we will assume that the LUT is 33 by 33 by 33. So the size is 33. And then the dimension should have a width of size by size and the height of the size. So the total number of pixels is going to be size by size by size. So what that means is the arrangement of the pixel values must follow a specific pattern. So this image at the top here shows one zero eight nine by 33."},{"start":"9:36","end":"10:05","startSec":576.0,"text":"You see this image here on the top with the approximate pattern. So the pixel values are RGB and the expression for each pixel is this following formula here. So you get a good idea about how we've generated this this lookup table here. So if these pixel values were written into open XEXR, the image file, it would represent the identity LUT, which reproduces the color that is given for variable values in the range 0 to 1."},{"start":"10:06","end":"10:38","startSec":606.0,"text":"So to make the LUT interesting, each of these values must contain the desired output of the 3D LUT. So by using an image processing program that supports your desired LUT file type, you can index the file LUT with the identity pixel locations given above to find the actual pixel value needed at each location. So once the proper floating point values are known for each pixel, then the image should be written as an open EXR image. So Nuke can be used to produce this and help fill in the color gaps."},{"start":"10:38","end":"11:08","startSec":638.0,"text":"So maybe dig into this approach a little bit more over the legacy version of the lookup tables, especially if you're using any approaches such as virtual production. And if you are using Nuke, you can now take the LUT and use this code in Nuke to fill the color gaps, which essentially just means fill those pixels and that's to be used as a HDR in order to create a 3D LUT. So otherwise use a DCC to make sure you export it at a 16-bit HDR image."},{"start":"11:08","end":"11:41","startSec":668.0,"text":"And in most cases, it's not needed if you know Nuke as it has excellent control and exporters. So if you are using Nuke, open a blank script in Nuke and paste that text into the node region. It should make a small set of nodes that can be used as an input for whatever color correction you are doing. So provided the code there and you can just copy and paste as needed. Once created and edited in a design DCC, you can right click on the imported EXR and select create volume texture."},{"start":"11:41","end":"12:15","startSec":701.0,"text":"So when you're in Unreal, just right click, create volume texture, and then double click on the volume texture it has created. So then we open this 3D volume texture here. And then the volume texture will need to be edited to match the 3D LUT size value. So X is 33 and Y is 33. The shape will be more cube like. So don't worry about the bad size here in the bottom right hand side of the image. To properly embody the floating point data, the 3D LUT without quantization or encoding, change the compression settings."},{"start":"12:15","end":"12:51","startSec":735.0,"text":"So again, on the right hand side, you've got some adjustments that you can make here. And you want to change the compression settings to HDR, which is RGB, no sRGB. And then you can save the volume texture asset so that it can be used in a material. Then you want to make sure the material domain is set to a post-process volume. In the material editor, you can create a texture sample parameter volume node from the menu. And by providing a UVW coordinate to the UV parameter of the param volume node, it will index the volume texture to provide a lookup value."},{"start":"12:52","end":"13:28","startSec":772.0,"text":"So pretty straightforward material editor graph here. And if you set it up in the following way using what we said above, you should be able to get the desired result there. And then just a quick note that by indexing the LUT via the UVW parameter, you might need some slight adjustments to ensure that it behaves like a 3D LUT. So the indexing shown here performs the operation by first scaling it by size minus one and then divided by size and then adding 0.5 to size in all three indices."},{"start":"13:28","end":"14:01","startSec":808.0,"text":"So a break for float component and make float three allow for control. So you can see that in the image here. The scalar parameters are to handle the size of the 3D LUT. The input texture will have a specific size and in this case it's 33 by 33 by 33 as we said before. And the value is labeled 32 by 33 is a fraction of n minus one divided by n, where n is the size of the LUT."},{"start":"14:01","end":"14:34","startSec":841.0,"text":"So the other value is 0.5 by n. And the reason they are needed is to get the texture sampling to work properly. In this material, example applies to a 3D LUT to the post processing input. Other cases are possible, but the correct indexing is required for all uses. So in the example material shown, note that the texture sample parameter volume was renamed to apply 3D LUT. Now load the post process volume material with an instance material."},{"start":"14:34","end":"14:48","startSec":874.0,"text":"And so to do that, you just save out this material. You would then go to your content browser where the material save, right click, create material instance and then use that instance material on the post process volume."}],"03_OpenColorIO":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"To give you an overview of the OpenColor I.O., color management, Unreal Engine offers built-in support for OpenColor I.O. to convert colors of linear media in several ways. So when you use media source like captured clips or live feeds in your project, you can apply the color conversion to make sure those media sources match your computer generated elements in Unreal Engine. So while you're working, you can apply the color conversions to your viewport, and this will be helpful so that the reference frames you see as you are working in the editor will"},{"start":"0:32","end":"1:05","startSec":32.7,"text":"be consistent with your chosen color space. You can then reapply another color conversion to the composited feed, your output from Composure, and this really helps with CG elements and live frames to help them blend more convincingly whilst preserving the colors of the original shots faithfully. So you can export using the movie render queue, which we'll go over in a few slides here, and you can choose to apply a color space transformation to your output video. And then a new asset is the OpenColor Configuration asset, which you'll use to manage the color"},{"start":"1:05","end":"1:21","startSec":65.5,"text":"profiles that you want to work with. So from your plugins, you just want to make sure you go to the edit window, go down to plugins and check for OpenColor I.O. and make sure it's enabled. If it wasn't enabled, you'll just have to restart your editor and then you should be good to go with OpenColor I.O."}],"04_Post Process Volumes":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Next, let's dig into talking about some post-process volume properties that you can edit. And first we'll talk about exposure adjustments versus raw. So you can create an auto exposure, but adjust its range to keep it in the min max. So if you see here, we've got some exposure settings on our post-process volume and you have this min EV100 and max EV100, which you can use to clamp some values. And you can also adjust it under the lit menu inside your editor."},{"start":"0:32","end":"1:03","startSec":32.2,"text":"If you click on lit and go down to game settings, you can tick that or untick it. And then you also have a slider here to compensate for the exposure in this section here. You can also do exposure adjustments and visualize them in the editor. So if you want to visualize the adaptation under show, go to HDR eye adaptation. So you click show at the top here and then go down to visualize and then HDR and you"},{"start":"1:03","end":"1:37","startSec":63.6,"text":"can preview that eye adaptation. And then you can also preview the depth of field in your shots as well. So a cinematic depth of field, green is the foreground, black is the focus object and then blue are any of the background objects. So we've got a procedural diaphragm simulation. So that means that the control, this controls a number of diaphragm blades, which is the iris to directly influence bokeh shape. And then aperture can be as small as desired, but has a maximum based on lens size, which"},{"start":"1:37","end":"2:08","startSec":97.2,"text":"is your f-stop. The aperture does not control light intensity so that you don't have to continually adjust the exposure. So you can see this depth of field diagram here where if you want a shallow depth of field, you want a large aperture. If you want some deep depth of field, you want to really narrow that aperture and make it quite a small source that the light can get through there. And then to touch upon the use of path tracer when working with depth of field."},{"start":"2:08","end":"2:38","startSec":128.2,"text":"In the past versions of path tracer, there was a major issue with translucency and depth And the problem was that the translucent material wouldn't render to the depth buffer. So essentially you weren't getting accurate depth of field. So in the path tracer settings now, you can remedy that by the tick box here. So reference depth of field. And if you enable that, that will fix any legacy issues that you may have had previously. And to close out, there's many different documentation."},{"start":"2:38","end":"2:55","startSec":158.8,"text":"So if you've heard anything in the previous few slides that you think you want to know more about, maybe you want to know more about open color IO or any of the post process effects, any rendering topics, you can find all the documentation here. And these slides were put together by Sean Rod and Cami."}],"05_Rendering Overview":[{"start":"0:00","end":"0:19","startSec":0.0,"text":"Next, we'll talk about rendering in Unreal Engine 5, and we'll talk about Sequencer, which is the movie scene capture, and we'll talk about how to render your movies using the render queue, and then also some tips and tricks with Lumen, Path Tracer, some console variables you can use, and then the GPU timeouts."}],"06_Movie Scene Capture (Legacy)":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"So looking at the movie scene capture in Sequencer, so there's a legacy tool which we're deprecating. It's really good for rendering videos for AVI and the general purpose capture for cinematic output. So it supports custom render passes, HDR exporting, but it doesn't support high resolution rendering. So currently still the only option for exporting self-contained AVI files, but that may change. So from the drop down here, you can see that the movie scene capture tool"},{"start":"0:31","end":"1:04","startSec":31.4,"text":"can still be used. You've got some of your settings here. Again, it outputs an AVI file, but we are moving over to the movie render queue. So just in case you wanted to use the legacy tool, it was worth highlighting there. And then also the HDR exporting, so you can export HDR data in open EXI files. So you can specify a HDR compression quality, and then also specify the capture gamut. So whether it's Rec.709, the P3D65,"},{"start":"1:04","end":"1:35","startSec":64.6,"text":"or even the more recent Rec.2020 and the ACES, and the ACES-CG, and render passes, the limited render pass option is not rendered layers. So at least one of the render passes must be selected, or all render passes options will be rendered. So again, you've got your settings here that you can adjust for the movie render settings. It's worth digging into some of the different options that you wanna capture here. And then also when referencing the capture gamut"},{"start":"1:35","end":"1:39","startSec":95.9,"text":"that you need to specify, that's in this section down below."}],"07_Movie Render Queue":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"If you're using the movie render queue, however, this allows us to add multiple sequences so we can customize the output settings essentially. So you have two different settings here. You've got the render local, which will render locally and the same way the Unreal Engine and similar to how plain editor would work. If you want to render remotely, however, this is more resource intensive and does not run the editor's code. So projects must be saved to do that."},{"start":"0:31","end":"1:03","startSec":31.9,"text":"So the two options are at the bottom here, whether you choose to render local or render remote. And there's additional documentation if you need to know more about both of those options. You can also customize the render settings, whether it be project wide or even shot by shot. So you can select and add the render settings, the export file types and render output options. And you can create some render presets so you can share those presets across the team. You can just share them across different projects if you want."},{"start":"1:03","end":"1:34","startSec":63.6,"text":"And it's a really nice, efficient way of working to get consistent quality output either across many shots in the projects or even across many different projects. And the movie render queue currently supports anti-aliasing and the burn in, whether default or custom. We've got camera shutter control. You can edit the console variables and the movie render queue will take into account any console variables you've set, which again, we've got some tips for later in the slides here."},{"start":"1:35","end":"2:11","startSec":95.0,"text":"We've got some game overrides that you can do. You've got the high resolution output, which the previous render option didn't have. So you've got tile count, which are image breaks, overlap ratio and texture sharpness bias. And we also support ray tracing and lumen with the movie render queue. Which is a great handy feature to have. So the high quality media export user benefits are virtual production is high quality anti-aliasing and motion blur. On the gaming side, you've got higher quality cinematics with less artifacting from motion blur and temporal anti-aliasing."},{"start":"2:11","end":"2:27","startSec":132.0,"text":"For the automotive side, you might have the temporal supersampling, rotational motion blur, high resolution tiling for larger image output. And on the archviz side, you've got spatial supersampling for anti-aliased image with little ray tracing noise."}],"08_Tips and Tricks":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Next, we want to provide a few tips and tricks for your rendering inside of Unreal Engine 5, so that it helps give you some efficiencies in your workflow. So kicking off with Lumen here, Lumen currently doesn't fully support mirror reflections. So it's limited, but on the roadmap, so at the time of viewing, you can just check the support of Lumen on the reflections here. And Lumen does not support static lights either. So you're in a, whereas if you are using baked lighting,"},{"start":"0:31","end":"1:01","startSec":31.0,"text":"you could change your light modes to static, stationary, movable. Lumen just handles the same light type for all. So disabling allow static lighting can help with some overhead and make sure your Lumen AO process is working with no visual hindrances. Lumen supports material ambient occlusion, ideal for characters, cheaper than a bent normal for characters. So with Lumen, temporal super resolution, which is TSR,"},{"start":"1:01","end":"1:34","startSec":61.0,"text":"may blur out the world position offset effect. To remedy that, you can go to your project settings, go down to the render tab, into optimizations, velocity pass, and switch to right during base pass. And making foliage movable in the foliage editor can also correct the blurring caused by the world position offset, which is the wind effect. And then there's just an image to show you about the velocity pass option that you'd change there. With path tracer, we're talking about denoising."},{"start":"1:34","end":"2:04","startSec":94.0,"text":"So even with high sample counts, path tracer will always have a bit of residual noise in the rendered frame. So denoising option in the post-processing volume settings will make use of Intel's open image denoise library to remove noise from the last sample. So the denoiser runs on the CPU and is not currently designed for interactive denoising. So rather to help improve the quality of long running frames, it does not currently guarantee temporal consistency."},{"start":"2:04","end":"2:39","startSec":124.0,"text":"And relatively high samples per pixel are required for stable output. So temporal stability can also be improved by increasing the temporal sample count in the anti-aliasing settings in the movie render queue. And then also animated items may still have flickering shadows. So setting spatial and temporal sampling counts to 10 can help. So path tracer is still evolving, many changes per engine version. So it's always useful checking the path tracer documentation, which we've got in a slide in a second for you to check the latest on path tracer."},{"start":"2:40","end":"3:13","startSec":160.0,"text":"Here are a few common console variables that you may use for when you approach ray tracing. We've got some meta human specific CVAR settings here in orange, which you may want to tweak, but you can also find a list of these online. But again, the render queue supports console variables. So if you want to set any of these when you're outputting, and if you file types, you can set these on the project. And then you've also got some sky and atmosphere systems that you can tweak here."},{"start":"3:13","end":"3:43","startSec":193.0,"text":"So worth digging into all of these, playing around, seeing what you can set and really define the look and feel of what your project requires. The GPU timeouts, so the TDR delay settings, type regedit into the Windows search bar to navigate to this category, select the TDR delay from the list, right click modify, and you can select the base's decimal."},{"start":"3:43","end":"4:13","startSec":223.0,"text":"So change the value data to 1690 or 120, and then hit OK. And if the TDR delay doesn't exist in the category list, move your pointer to the open folder, right click, select new select D word, which is 32 bit value from the options menu, and then select the base's decimal. Hit the value data to 1690 or 120 again, and then hit OK. So all of the documentation that you need for any of these tips and tricks"},{"start":"4:13","end":"4:30","startSec":253.0,"text":"can be found on the resources below. And then just for the credits of the slides again, this was Kevin and Sean. We got further documentation on some sequence of workflows, and then also some additional documentation on the movie render queue."}],"09_Thank You":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Thank you for watching today's video on post-processing and rendering. Hopefully gave you a good overview of exactly how Unreal Engine handles the render buffers, the different settings you can use to really drive home the look and feel of the projects that you're working on. We covered a lot of ground, whether it be some of the plugins that you can use in Unreal Engine or some of the properties that you might be able to edit in post-process volumes or materials and looking at lookup tables, but hopefully gave"},{"start":"0:31","end":"0:36","startSec":31.6,"text":"you a good overview for you to start really defining the look and feel of your project, and we'll see you on the next course."}]},"210.01":{"01_Intro":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Greetings everybody, my name is Sam Dider and I'm a senior Unreal Engine instructor with Epic Games. In the following video tutorial, we're going to be taking a look at Niagara fluids. We're first going to start by taking a look at an overview of Niagara fluids, going over the various fluids that we can make using the system. We're next going to jump into Unreal and look at how we enable the Niagara fluids plugin. Then we'll take a look at the various Niagara fluid content example maps, which show you"},{"start":"0:34","end":"1:08","startSec":34.3,"text":"how you can utilize fluids in many different ways inside of the engine. It's a great resource to come back to to see what you can do with the various fluid emitters that Unreal Engine 5 provides. Next we're going to take a look at creating 2D smoke, liquid and fire effects by actually creating some smoke and 2D liquid effects. We're then going to move on to creating 3D liquid smoke and fire effects. Then finally we're going to finish up with some ways to optimize our smoke, liquid and"},{"start":"1:08","end":"1:23","startSec":68.7,"text":"fluid effects so that they can run more performant and even be used on platforms that might not necessarily support them. With this introduction out of the way, let's go ahead and get started by taking a look at our Niagara fluids overview."}],"02_Overview":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Before we start creating particles using Niagara fluids, I'd like us to have a quick overview look at the system to better understand exactly what it is that the system offers us and what kind of fluids we can make with the Niagara Fluids plugin. So first off, what are Niagara fluids? Well when we say Niagara fluids, what we're actually talking about is a tool set for creating real time liquids. This tool set was designed to be artist friendly and we're going to find that it includes a"},{"start":"0:31","end":"1:04","startSec":31.8,"text":"variety of GP based simulators, reusable modules, and robust data structures that are all accessible within the Niagara editor. We can use all of these various Niagara components to build different 2D and 3D versions of real time fluids and gases and fires that you might find in the real world. The reason we want to use Niagara fluids is actually most of the work is done for you. Since we are trying to recreate a physical phenomena, all we really have to do is just"},{"start":"1:04","end":"1:35","startSec":64.0,"text":"adjust a few values and most of the heavy lifting or underlying work has already been done for us and what we're going to get is a really, really efficient 2D or 3D version of whatever smoke or liquid or fire we're trying to simulate. Now whatever we are trying to simulate, we're going to find that there are different versions. There's a 2D gas, a 2D liquid, a 3D gas, a 3D liquid, and shallow water and each one of these are going to be utilized for something slightly different."},{"start":"1:35","end":"2:10","startSec":95.9,"text":"The 2D gas is where flow only occurs in the X and the Y dimension. This is really suited for real time simulations and while it might only be a 2D representation, it can interact with geometry and the characters. One other thing to note about the 2D gas and 2D flip is that the simulations do face the camera so that no matter where the camera is pointed, it's always going to align with"},{"start":"2:10","end":"2:46","startSec":130.8,"text":"the camera making them good for things like fire or a water effect. Now our 3D gas is going to be the most common type of simulation used to simulate gas or fire or smoke. However, it is going to have a much more complex or higher memory and GPU cost and therefore it's best used for hero effects in real time applications or for cinematics. We can bake the results of these into textures which we'll talk about in a little bit, but"},{"start":"2:46","end":"3:22","startSec":166.3,"text":"if you want to make heavy use of these, remember that it's going to be very expensive in terms of memory and GPU memory. Now the 2D flip stands for fluid implicit particle and it's simply referring to how the particle system is set up behind the scenes which you don't need to talk about right now. The difference between the 2D flip and the 3D flip is this. The 2D flip samples 3D particles but it generates a 2D simulation where pressure is solved and"},{"start":"3:22","end":"3:55","startSec":202.8,"text":"applied to the particles giving it a 3D look but at a 2D cost. The 3D flip on the other hand is simulating full 3D water interaction allowing you to interact with the water with the character or static mesh and the water will then move up and around just as water would in the real world. Actually very very interesting and great particle to mess with and we'll see that here in just"},{"start":"3:55","end":"4:26","startSec":235.0,"text":"a little bit. Now the 3D flip you might think would be something that we would use maybe all over for all types of different bodies of water and unfortunately while it is good at some things it is not good at other things and that is where the shallow water comes in. Now the shallow water is useful for simulating pools of water that don't contain many splash effects. This could be also used to simulate things like boatwakes or simple interactions with objects moving through the water."},{"start":"4:26","end":"4:50","startSec":266.7,"text":"So again the type of fluid that we pick is going to depend on the situation at hand so we don't necessarily need to always use a 3D gas or a shallow water or a 3D flip. We can use combinations of 2D gases and 3D gases and 3D flips and 2D flips and we'll see how all of this gets put together in the next couple of slides."}],"03_ContentExampleMap":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"The Niagara Fluids content example is a great way to get more familiar with how you can use Niagara Fluids in any Unreal Engine project. Inside of this content example map, you're going to find different fluids from fire and water. Let's take a look at this now because there's some really interesting things that we can see inside of here. So here I have the content examples open. I have Niagara Fluids. That's the level name. You can see here there's just a ton of different types of simulations and things here."},{"start":"0:33","end":"1:05","startSec":33.3,"text":"Now some of these we do need to see if I come up here and I'm just going to do a simulate here. Some of these will work. Some of them I actually do need to be playing for this to actually happen. So let me just right click and we will play from here so we can see. There we go. For example, here's a camera facing and non-facing for our 2D. Here is a torch that has a parented so that it's actually following around as the object moves throughout the world. This is 2D collisions and it goes on and on and on."},{"start":"1:05","end":"1:26","startSec":65.7,"text":"There's just a whole bunch of great, great, great examples in here. So again, this is the content examples map. Niagara Fluids, very, very, very useful and something that I suggest that everybody check out to get more information on how to use Niagara in their project, especially when it comes to fluids."}],"04_EnablingPlugIn":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Before we can begin to use the Niagara fluids in our project, we need to enable the Niagara fluid plugin. Now this is pretty simple to do. All we need to do is go to the Plugins menu, look for FX, and then there is Niagara fluid and we just enable it and restart the editor. I'm going to go ahead and do that now. So inside of my editor, I'm going to come over to the Plugins menu, bring this on the screen here, go over to our FX, and we're going to"},{"start":"0:33","end":"1:08","startSec":34.0,"text":"look for Niagara fluids and we are going to enable that. And then we're going to hit Restart Now. Once we have done that, we are going to then right click on the Content Browser, go to Niagara System, and then we will be able to select this little wizard here. And if we click on Niagara fluids, we will then have the ability to see all of the different Niagara fluids that we have access to. So let's just pop back over here to the editor and have a look at that now. So again, hit Control Space. I'm going to disable my Level"},{"start":"1:08","end":"1:39","startSec":68.5,"text":"Filter. Come up to my Content, right click, and then from the menu here, select the Niagara System. And we're going to go to Niagara fluids. And if we want, we can go 2D, 2D Liquid, 3D Gas, 3D Liquid. There is some shallow water is the last one I wanted to show you, or we can look at all of them here. And all we need to do to select one of these and use it as the basis is simply just select it and then hit Create. Now, once we do that behind the"},{"start":"1:39","end":"2:11","startSec":100.0,"text":"scenes, what is actually going on here is our Niagara is built off of very, very, very complex inheritance. And inheritance in our case is actually used to progressively add more and more functionality. So instead of all of the fluid behavior being done in one single module, and we use that one single module to do everything, we have it kind of"},{"start":"2:11","end":"2:42","startSec":131.2,"text":"split up like this. So we have our basic three grid 3D gas emitter at the base here. And then from that, we have the grid gas control. So these are going to be controls that control this. And then we further refine those. We have some controls for just a regular emitter. And then we have some controls for our cinematic version or a higher quality version. And then finally, we actually have our Niagara system that we are going to be creating. So the Niagara"},{"start":"2:42","end":"3:17","startSec":162.4,"text":"system is what we just created here using one of these, the grid 2D flip hose, or the 3D flip hose or something like that, that would be the Niagara system. And that system, again, it's going to be made up of a collection of these different Niagara admitters. Now, the reason I'm bringing this up is because inheritance or knowing that inheritance plays a functionality here is going to be a key to expanding upon these emitters in the future. Or it's just important to know that all of this stuff is built upon multiple emitters, and not"},{"start":"3:17","end":"3:20","startSec":197.9,"text":"just one single massive emitter."}],"05_Creating2DEffects":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Now that we understand a little bit more about the basics of Niagara liquids, including enabling the plugin and how Niagara liquids are built based out of multiple modules, let's take a look at creating some Niagara liquid effects now by creating some 2D smoke, liquid and fire effects. For this example, we're going to be first starting off creating some 2D liquid, but the steps that we're going to be using can be applied to the smoke, liquid or fire depending on what"},{"start":"0:31","end":"1:05","startSec":31.2,"text":"you are doing. To do this, what we're going to do is right click inside of the content browser, select Niagara system, and then from the create Niagara system dialog box that comes up, we are going to go over here to Niagara fluids. Now if we click on Niagara fluids, just the main folder is going to show us every single thing that's inside of here, which is good if you want to see everything that is available. We are going to expose the folder, we're going to uncollapse it so that we can see the 2D gas, 2D liquid, 3D gas, 3D liquid, grid utility and shallow water, and then click on our 2D liquid and select the grid 2D flip hose."},{"start":"1:05","end":"1:40","startSec":65.4,"text":"So let's go ahead and pop over here to the editor. We're going to right click inside of here, go to Niagara system, and I'm already there, but we can click on this. So there's our Niagara fluids. We're going to click down here to our 2D liquid. I'm going to select this grid flip hose and hit create. I'm going to call this NS underscore 2D liquid. All right. Now before I open it up, there's a couple of things that I want to talk about. Now when you first click on your Niagara system and you open it up, one of the things to make"},{"start":"1:40","end":"2:12","startSec":100.2,"text":"note of is that liquid smoke and fire simulations are extraordinarily complex and they are built out of multiple modules. While we're starting off with one that's relatively simple, you're going to see here in a few examples they start to build in complexity and in order to cut down on the amount of settings that you have to mess with or look for, there's this thing called an Admitter Summary. And the Admitter Summary is used to highlight some of the most useful properties that are"},{"start":"2:12","end":"2:46","startSec":132.3,"text":"available to work with this particular system. So when we click on the Admitter and we go to the Details panel, we're going to see something that looks like this, the Admitter Summary here. It's got some different categories, SIM, grid, collisions and all. It's going to be different based on the liquid that you have selected. And then there's all these properties in here that are, again, the properties that you are going to use to adjust this are the most common properties. Now if you want to expose more to the Admitter, you can still do that. All you got to do is just hit this little triangle right here."},{"start":"2:46","end":"3:19","startSec":166.0,"text":"And what that's going to do is it's going to un-collapse the Admitter stack right here and we're going to see an Admitter that looks at something similar to what we are used to. So let's just take a look at that now. So I'm going to double click on my 2D liquid to open it up. Let's just expand this. And then right here, if I click on it, you can see here on my Details panel, I have just the properties I'm going to find super useful, like for example, number of cells max axis. This is how we control the resolution of this. So increasing this number is going to make the water have a higher resolution to work"},{"start":"3:19","end":"3:51","startSec":200.0,"text":"with. It's going to make it more realistic and things like that. Lowering this is going to make it run a little faster and look a little blockier. For us, what I want you to do now is just expose the other properties of our Admitter, again, just by hitting this little drop down here to un-collapse and re-collapse. And now once it's un-collapsed, we can see all of the properties. What we're going to be doing is we're going to go to Particle Spawn and then we're going to adjust the Lifetime and then the Spawn Radius and the Offset."},{"start":"3:51","end":"4:22","startSec":231.2,"text":"And this is going to basically make the particles take a little bit less time to die off. Move the Spawn Radius down. We're going to move the Offset way far back. So let's just take a look at that now. So make more sense once we do this. So we're going to, again, come to our Particle Spawn Lifetime. We're going to set this to a value of 3. And you can see here what it's going to do is those particles are just going to die off a lot sooner than they normally would. Sphear Radius, I'm going to set this to 100. It's just going to give us a little bit of a larger area to have things admit."},{"start":"4:22","end":"4:56","startSec":262.9,"text":"And then right here in the Offset, what we're going to do is I'm going to go negative 900. And that should push this up and it pushed a little bit too far out of our volume. So that is okay. What we're going to do here is we're going to come back to this and we're going to go down to our World Grid Extents right here. We're just going to set this to 2048. And there we go. So the World Grid Extents will come to that in the next slide, but that's going to basically work as our boundary for our particle system."},{"start":"4:56","end":"5:27","startSec":296.1,"text":"So let's go ahead and just pop back over here. Now what we're going to do is we're going to re-collapse everything and we're going to enable the Use Depth Map Collisions. This is going to set it up so that the particles will react to collisions that have been placed into the world via static meshes or skeletal meshes. So let's go ahead and do that now. So we're going to come back over here to the editor. We are going to, remember, collapse this and now we have this available."},{"start":"5:27","end":"5:59","startSec":327.6,"text":"So the other thing we're going to do here is we're going to go Use Depth Map Collisions. And then we've already done this, but the World Grid Extents here, we want to set that to 2048, which is going to push this thing out. Let's do one other thing here. We're going to come back to this. Let's go to our particle spawn real quick. And let's go ahead and set this offset to like 300. Yeah, that looks about good. So remember to pile and save. And what's going to happen now is when we place this into the world like so, we are going"},{"start":"5:59","end":"6:34","startSec":359.0,"text":"to be able to have it not only collide with the world, but also objects that we have manipulated in the world. So let's check that out. All right. So I'm going to close this down. I'm going to hit Control Space and just drag my particle into the world here. And there we go. I'm going to just move it on over a little bit and then watch this. Soon as I put this up, boom, got it ramping right off there. So that's really working right out of the gate with everything set up and ready to go. Now the next thing that we're going to take a look at is creating a smoke and fire effect"},{"start":"6:34","end":"7:07","startSec":394.4,"text":"kind of getting smoke and fire in the same one because actually smoke and fire are kind of the same thing. You can't have smoke without a fire source or something like that or so I'm told. So let's go ahead and create this new one. So I'm actually going to delete this out of the scene. Whenever you're dealing with any types of liquids, you want to make sure that your scene stays as clean as possible for performance sake. So I'm going to hit Control Space and then we're going to right click Niagara System. And then this time from Niagara fluids, we're going to go to a 2D gas and we want this 2D"},{"start":"7:07","end":"7:39","startSec":427.7,"text":"gas moving fire. We're going to hit create and then we're going to call this NS underscore 2D fire gas. And let's go ahead and double click on it to open it up. Now when we open this up, we're going to see things that look a little bit different. First off, we're going to have a new node here, which is going to look like this and it's going to be similar to our source particles node. But this additional node, what this is actually taking care of is all of the information from"},{"start":"7:39","end":"8:09","startSec":459.1,"text":"the fluid sim is going to happen inside of this node. We're also going to have our Niagara overview node, which is going to allow us to add things like user parameters and other interesting bits that we want to expose when this is either added to a world or it's spawned through blueprints and then our source particles. So again, it works like this. Our source particles are how we are going to shape our particles as they move through the world. We might want to skin them to something within the world or we might want to have them admit"},{"start":"8:09","end":"8:39","startSec":489.3,"text":"from something. All of that's going to happen here in our source particles. Then once those particles have been spawned, we're going to take the information from this grid 2D gas smoke simulation and skin that to those particles locations, giving us a the illusion that this really complicated fluid simulation is happening. But where in reality, what's really going on is we're running this Niagara SIM and then we're putting the fluid simulation on top of that. And the reason we do it in this manner is it allows us full control over where the particles"},{"start":"8:39","end":"9:10","startSec":519.6,"text":"are going. And as the particles move, we apply that fluid simulation. So again, we don't have to worry about making the fluid simulation go in that direction. It will go in that direction because it's attached to the particles that are already headed that way. So let's go ahead and just pop into the editor here real quick and have a look at our 2D fire. So there's our 2D fire effect. Again, we have our source here and then our fluid simulation."},{"start":"9:10","end":"9:44","startSec":550.8,"text":"And notice that the fluid simulation is set into the Admitter Summary. If I was to expose this, you're going to see here it is a very, very, very complex system. There's all types of different pressure solves and compute shaders and things like that. But using it just like this will allow me to see the properties that I'm going to use most often. Again, our Admitter Summary right up here at the top, we can also edit this by clicking on Admitter Summary and then adjusting the things that are inside of here. As for what the Admitter Summary is going to contain, well, each one is going to be"},{"start":"9:44","end":"10:15","startSec":584.2,"text":"broken down into a different area. Each liquid is going to also be slightly different. So you might find some of these and you might not find some of these. So simulation is going to be dealing with how the simulation changes over time. Forces is, I'm sorry, sources is going to be adjusting source parameters to control information based off incoming particles. Our forces is going to affect on properties like density, temperature, buoyancy."},{"start":"10:15","end":"10:46","startSec":615.7,"text":"Collisions will deal with how this will collide with the world, other and other effects. And then finally, our renderer is how this will work with rendering and lighting. So again, it's all been set up to work in a way that makes it easier to kind of digest each one of the parameters. Now, one of the other things to note about this, since we are simulating how smoke and fire work, which is our natural phenomena, we don't need to adjust that many parameters"},{"start":"10:46","end":"11:17","startSec":646.7,"text":"to get something that looks realistic or something that behaves in a realistic manner, but still is artistically driven. So oftentimes it just comes down to simply maybe changing something like the temperature to like 0.1 or 0.5 or, you know, if I set it to 2, it gets extraordinarily hot. So maybe I have this temperature multiplier, maybe it's something that I have exposed so that I can scale it over time."},{"start":"11:17","end":"11:53","startSec":677.3,"text":"So it starts at 0.1 and then goes to 2 and 3 and 4 and 5 and 6 and so on, and will increase over time. There isn't a magic property in here that's also going to make your fire look better or more realistic. What is going to help give you the most realistic options are very subtle changes in your numbers. I'm talking like, you know, maybe I set this to 5 to see what happens, maybe set it to 1, but doing something like maybe 100 or 500, these are all going to give you values that"},{"start":"11:53","end":"12:26","startSec":713.1,"text":"don't really look that realistic. So just be careful when doing things like that. Now, the next thing that I want to talk about is collision. So your 2D and your 3D particles will all collide with objects that have placed in the world. We saw that with the water. Now, one thing to note, if you're using an older version of Unreal or for some reason things are not working, check that the object that you wish to collide with your effect. So in this case here, we have this static mesh that we want to collide and the actor"},{"start":"12:26","end":"13:01","startSec":746.7,"text":"tags, we put this tag collider all lowercase c-o-l-l-i-d-e-r that will make this object collide with your smoke effects. Now the reason that I bring this up is in Unreal 5.6, apparently you do not need to do this anymore. So let me show you what I'm talking about. We're going to come here. I'm going to re-rotate that. We're going to go to add geometry, not geometry, I'm sorry, shapes. I'm going to add a cube here and just move this cube over and down. And then we're going to grab our gas 2D, put that in here and check this out."},{"start":"13:01","end":"13:33","startSec":781.7,"text":"If I bring this over like so, it's kind of cool. It makes it almost like I'm dampening the fire here. And it's actually blocking it. The reason it comes through from the top is because we're using the depth to block it. And from this particular viewpoint, my depth information is signifying there isn't anything up there. That's why it's working in this view. But you can see here, I can block half of the smoke. And again, if that's not working, just come here, look for your tag, add a tag called"},{"start":"13:33","end":"14:04","startSec":813.1,"text":"Collider. And you should see the exact same results. And again, this is going to work with any static mesh that you have. It will also work with the... Let me just actually move that out of the way because I can't move the player with that, but it's also going to work with the player as well. Let's look at that right out of the box. It's working. You can see here, the player is kind of disrupting the gas of...or I should say the smoke of the fire. And it's actually very, very cool. And it gets even cooler when we add a 3D effect to it."},{"start":"14:04","end":"14:13","startSec":844.2,"text":"So that is going to wrap up our 2D section. We're going to look next at creating 3D versions of our smoke and fire in the next part of this tutorial."}],"06_Creating3DEffects":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Now that we have created some 2D fire liquids and smoke, let's take a look at creating their 3D counterparts. Now creating the 3D version of these effects is very similar to creating the 2D version. We right click inside of the content browser, we select Niagara System, and then from the Create Niagara System dialog box, we look for Niagara Fluids, and then for this example, we are going to select the grid, 3D, gas, and fire, and then hit the Create button. So let's go ahead and do that now. So we are going to right click inside of our content browser, then we are going to look"},{"start":"0:34","end":"1:06","startSec":34.6,"text":"for our grid, 3D, gas, and fire, and hit Create NS underscore 3D gas fire. And let's go ahead and double click on that to open it up. Now this is going to look very similar to our other setup where we have a particle admitter source, but instead of everything being done in one single admitter, we actually have two. And it's going to work like this. So across the top here, this is our Niagara overview node."},{"start":"1:06","end":"1:38","startSec":66.3,"text":"This is going to show us things like exposed user parameters and properties and things like that. We have our particle source admitter. This is going to work as our node for admitting the particles. So however the particles are going to be admitted and then behave and move around the world we will be taking care of inside of this node, the grid 3D gas master node, what that's going to do is handle how the fluid simulation takes place. Then we are going to take that fluid simulation and actually skin it to the particle source"},{"start":"1:38","end":"2:10","startSec":98.9,"text":"admitter. And the really cool thing about that is we now have the ability to make our particles move in any which way we want and then have our simulation put on top of those particles and by sim taking the simulation for the fluid and the simulation for the particles and making this separation again allows us to do really, really interesting things like we can have a trail of fire that follows a specific path or other interesting effects like that."},{"start":"2:10","end":"2:41","startSec":130.8,"text":"One of the other things to note when you click on the grid 3D gas master effect, the details panel, even though it's going to be by default in admitter summary mode is going to be full of options. Don't worry about all of the options that are there. The cool thing is is that you only need to adjust a few of them to actually really affect how the look and the feel of the smoke and the fire reacts and that's because we're trying"},{"start":"2:41","end":"3:13","startSec":161.2,"text":"to create something that is life like. So remember when we are adjusting these things, we want to use very small values and we don't want to push things too far or it's going to make stuff look weird because it's not going to be physically correct. And what we want to do is we want to be able to have things look maybe a little artistic, but in the end still be physically accurate so that we can maintain artistic control and we don't really have to worry too much about the feasibility of building the effect."},{"start":"3:13","end":"3:48","startSec":193.8,"text":"So let's go ahead and just pop over to the editor really quick and have a look at our effect here. So here we go. Here's our fire effect. So again, we have our particle, admitter source and this is going to work just like it does normally if we do something like, I don't know, like change the sprite size or something like that, it's going to change the size of the particles that are admitted and then that's going to have a resulting on the end flame there."},{"start":"3:48","end":"4:18","startSec":228.6,"text":"So this is pretty standard, but then if we come over here to our grid 3D gas, this is where we're going to be able to start adjusting all of the various properties for our gas and smoke and fire simulation. Now to make things a little bit easier for us, I'm going to highlight here some of the things that you might want to consider adjusting to start with. So first off, there is the pressure solve iterations by reducing that number. You're going to be reducing the number of times that we solve for pressure and you're"},{"start":"4:18","end":"4:51","startSec":258.7,"text":"going to make the fire well run a little faster, but it is not going to be as realistic. If we increase this number, which it defaults to 200, I believe we are going to make the fire have more pressure iterations and become more realistic at the expense of memory and compute time. So again, this is set to, I'm sorry, pressure solve, not 200 by default, it's set to three. Let's go ahead and just set this or set this to three. It's set to 10 by default. I'm going to set it to three. It's going to just make things run a little bit faster."},{"start":"4:51","end":"5:22","startSec":292.0,"text":"Our pressure relaxation, this is a, I'm going to turn this up to three here. These values don't really correlate to anything that I got. They're just values that I happen to pick as I was crafting things. So feel free to adjust these or use other values. These are just some areas that I know of that we can get some good results. So then finally, I'm going to do our density buoyancy to 0.1 and our temperature buoyancy to three or I'm sorry, not three, a 0.3."},{"start":"5:23","end":"5:55","startSec":323.4,"text":"And then our velocity dissipation, we're going to set that to a value of one. All right. And then we're just going to compile and save this. All right. Just to mess with some of the values to, you know, give us something to work with here. And the other cool thing that we can do with this one is we can actually have this be admitted right from a static mesh. So all we need to do is place a static mesh and then inside of our particle system"},{"start":"5:55","end":"6:26","startSec":355.8,"text":"underneath the static mesh here and the user parameters, we have this source actor. We can actually sample this and use it to admit our particles from. So let's take a look at that now. So got this, we're going to go ahead and close this down. There we go. We're going to hit control space, bring our admitted in to the level. So there we go. And then I'm going to come up here to our quickly add to our shapes. We're going to add a sphere, move this up and then make sure that we do have our particles selected here. There's our 3D gas."},{"start":"6:26","end":"6:56","startSec":386.1,"text":"And then we come down here. Static measures will probably be collapsed. So you need to un-collapse it. And then we're going to select this and right there. Oh, wrong one. Not the one I wanted. I wanted this sphere right here. It will not work if it's not in the volume. So we do need to make sure that that is in the volume. But check that out. It is now admitting from the surface of this sphere. So that is actually really, really cool. And if we were to, like, you know, move this around, you can see here, well, we need to actually move both of them around in order to get the effect there."},{"start":"6:57","end":"7:28","startSec":417.1,"text":"But that's actually really, really cool. So we've got that fire following that sphere and it's already set up to work like that. All right. So the next effect we're going to be taking a look at is liquid. Now, in particular, we're going to be taking a look at our grid 3D flip hose. There are a few other ones such as the flip pool and the flip splash. And these work similar to their 2D counterparts here. The other one, shallow water."},{"start":"7:28","end":"7:59","startSec":448.4,"text":"This is great for if we're simulating something like a small puddle or maybe a boat wake. But for now, we're going to focus mainly on the grid 3D flip hose as this is one of the ones that's a little bit cooler. And also this is pushing modern VFX to its limits. This is actually a really, really advanced technique and something that's really, really cool and fun and interesting to work with inside of the editor. So like we do with all of our other particles, we're going to go to the content browser, right click Niagara system."},{"start":"8:00","end":"8:32","startSec":480.1,"text":"And then from the create Niagara system browser, we're going to select our grid 3D flip hose and hit the create button. Let's go ahead and do that now. So make sure we delete, oops, delete this effect here. And I was just saying that because I had deleted the sphere and it was referenced. So I'm going to delete that. And then we're going to come into our content browser, right click Niagara system. We're going to look for our flip grid 3D flip hose and hit create NS underscore 3D."},{"start":"8:32","end":"9:08","startSec":512.8,"text":"Just call us water. And let's double click on this to open it up. Now, again, depending on how fast your system is and a whole bunch of other things, this could take a little bit to open up. It could take a little while to compile. So just keep that in mind. This is going to look a little bit different than what we are used to, even though it is kind of similar. Let me just move the details panel over a little bit here because we actually have this grid flip. And then there's going to be another one right over here. And this other one, you're like, oh, it's got two. It doesn't actually, this is another admitter that is used to create white water."},{"start":"9:08","end":"9:44","startSec":548.4,"text":"So we're going to focus on this other meter right here for now and look at the white water one in just a little bit. So again, remember, we are creating a natural phenomena. So while this might look like it, absolute ton of parameters, there's not too many that we actually need to adjust inside of here. In fact, for this particular effect, many of the things that we need to adjust are actually already exposed to us under user parameters such as our collision velocity, our number of cells, max axis, this is going to control the quality of it,"},{"start":"9:44","end":"10:14","startSec":584.6,"text":"the water height and the great extents. That's pretty much all that we need to have exposed because remember, water is going to work exactly the same way in the digital world as it does in the physical one, because we are using the laws of physics to actually run this simulation. Now, with that said, there are some properties that we need to be aware of so that we can make sure that our water uses only the resources that it needs. Now, the first thing that I'm going to do is enable this show bounds."},{"start":"10:14","end":"10:45","startSec":614.8,"text":"And what this is going to do is it's going to show us with this red outline here, the maximum and minimum area that the simulation is going to take place in. If I come over here to my world grid extents and I was to increase or decrease these numbers, as you can see like this, what we've done here is we have taken the height of that and instead of being 500 with a bunch of empty space up here, we put it down to 400, which brings it way closer to the admission point. Again, the reason that we're doing this is we don't ever plan to have water go"},{"start":"10:45","end":"11:16","startSec":645.5,"text":"all the way up here. So all that area is going to be unused inside of our simulation. And just because it's used doesn't mean that it doesn't need to occupy memory. So we want to bring this down as low as possible. So let's look at how we can set this up now. So inside of here, I'm going to close this because we don't actually need that. I hit control space, bring in my water by just control dragging that in. And again, by default, it's not actually going to show me the bounds. So we come over here with it selected and we go to show bounds."},{"start":"11:16","end":"11:48","startSec":676.4,"text":"And there is the bounds for this particular object. And then what I can do here is let's just set this as something like 300. There we go. And this also highlights something else, even though it is actually admitting outside and it's cutting the bounds off, that's something that you need to be aware of. You want to set this something low, but not so low that your emission source kind of gets cut off or it starts to make things look unrealistic. Now, some of the other things that we can adjust here, this numb cells max per axis. If I set this as something like 16, check this out."},{"start":"11:48","end":"12:17","startSec":708.0,"text":"It's going to give us this very wobbly and blobby looking water right there. If I was to increase this to like 64, or let's just see what was the default. I think the default was 92. So let's try 128. It's going to give us this very, very, very, very finite water that actually is having problems pooling. You can see here that the water is so fine that it's not actually collecting with other stuff. So we might need to turn this down to maybe like 100."},{"start":"12:18","end":"12:50","startSec":738.5,"text":"And there we go. We get some better pooling action. So just remember water and liquids is going to be really balancing act between getting your settings and the performance just right. Other thing to note here are pressure iterations. This is going to control basically how many pressure time, how many times pressure is used to push the water around the world. And the more we increase this, the more realistic results we're going to get."},{"start":"12:51","end":"13:22","startSec":771.4,"text":"Just remember though, as we increase this, it is going to crease the memory footprint of our particular project. So we might run into performance issues as we do that. One of the other cool things we can do with the water is make it collide with static meshes. Now, all you need to do for this to work is just simply add the object and make sure you have the tag collider added to it. So we're going to come over here and we're just going to come down to our quickly add to projects. We're going to come to our shapes and add a sphere."},{"start":"13:22","end":"13:55","startSec":802.9,"text":"Now, with the sphere like this, notice that nothing is actually happening. It's not actually doing anything. But if I come to this, I search for my tag and we add the tag of collider. And let me just move this now. Check that out. Look at that. It's actually colliding with the water. You can see here that the water is actually bouncing off of it now, going around it instead of directly through it. And again, I just added the tag collider. Now you can also do this with the third person character or any other"},{"start":"13:55","end":"14:27","startSec":835.9,"text":"skeletal mesh. Just make sure that you have the tag collider added to your character blueprint. If you don't have a character blueprint in your current project, you can add a feature of content pack and then select the third person character. Once you've added that look for the BP third person character blueprint, open it up and then in the details panel, search for tag and add collider. And let's do that now because right now, if I was to play this, nothing is going to happen. I'm just going to kind of sit here and not really collide."},{"start":"14:27","end":"14:57","startSec":867.9,"text":"So I'm going to hit control space. We are going to look for our third person, our blueprint open to open it up. Come over to our details panel. We're going to search for tag and then we're going to add the tag collider. Compile save. Let's close that now and we hit play. And we'll see here that as this starts to fill up, I will start to move the water around. You can see I'm kind of doing it a little bit now."},{"start":"15:03","end":"15:30","startSec":903.0,"text":"And there we go. As it starts to fill up, you can see I'm making a little bit more of a splash note pun intended. So let me close this off and I'm going to hit control R to stop that from rendering because what I want to do now is I want to come back to our water here and I'm going to enable this extra one right here and we'll do a compile and we'll do a save and you can see already I've got the white water going on there. So we're going to close this down."},{"start":"15:34","end":"16:05","startSec":934.3,"text":"And while that closes down, let's take a look at what's going to happen next. So you can see here as I enter the volume, it's actually going to be displaced by the water, the character. We can also adjust the water height, which will allow the water to only be spawned to a certain height. This is fantastic. If you want to use this to say fill a puddle of some particular area instead of having to adjust how long the water lasts or figure out how to get rid of extra water or something like that, you just simply adjust the water height to be the height of whatever object it is that it is meant to occupy."},{"start":"16:05","end":"16:33","startSec":965.7,"text":"And the simulation will take care of the rest. Also, the water does react like real water. As you'll see here in just a second, when that white water splashes or when the water gets displaced by the character, it's actually creating particles that are coming off of the main water as a real splash in real life would be. So it's a very, very complex simulation we have going here. So let's close this down. There we go."},{"start":"16:36","end":"17:06","startSec":996.0,"text":"Oops, we don't want to close the whole thing down. We're going to hit play. And there we go. Look at that. We've got the white water coming off of it. So it's splashing around. And then as I as I move through, I will kick up more white water. And again, these are just the default settings. So it might not look as realistic as it could, but this is just the default. We can come in here and adjust, you know, how long the white water stays around and all types of other things. But yeah, look at this."},{"start":"17:06","end":"17:39","startSec":1027.0,"text":"We're getting some really, really great results inside of here. So all right, that is going to bring us to the end of this part. And the next part of our tutorial, we're going to take a look at how we can utilize some of the built in features of Niagara to help optimize our smoke, liquid and fire effects by rendering their complex effects down to a texture and then using a sub UV particle to help play that back in real time, giving us the illusion of"},{"start":"17:39","end":"17:44","startSec":1059.2,"text":"this really complex matter taking place. But in fact, it's just a flip book playback."}],"07_OptimizingEffects":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"In the final part of our tutorial we're going to talk about ways to optimize smoke, liquid, and fire effects. And the manner in which we're really going to primarily focus has to deal with taking our very complex fire, smoke, or liquid effects and baking them down into a series of images that can then be played back in real time to give the illusion that this really complex behavior is happening when in fact we are basically pre-computing that behavior to a"},{"start":"0:35","end":"1:07","startSec":35.4,"text":"texture frame by frame and then playing it back. This is commonly for all the flip book, but here is what the texture would look like. So we'd start it here at frame zero and we'd go eight by eight, which would give us 64. So this is it turning on and then going down and we would get something, it's not video here, but something like this that we can then play back. Now to do this inside of Niagara, it's actually very simple. All we need to do is come up to the editor and the effect we want and enable the baker."},{"start":"1:07","end":"1:38","startSec":67.2,"text":"Once we click on the little button, we're going to get exposed some tools that will allow us to basically select our file name, position a camera, set the size that we want the output object to, and then actually render that out. And here's an image of that work. Or I should say tool set. Let's go ahead and pop over to the editor and look at how to do this. I'm going to hit control space. I'm going to bring up my NS gas fire and just double click on it."},{"start":"1:38","end":"2:12","startSec":98.7,"text":"Remember, we can do this with pretty much any effect. Just keep in mind that some effects will be easier to capture than others. Again, we're going to bring up our baker here. So there we go. I'm going to come down and do the front viewport. It's just going to make it easier to kind of like zoom in on stuff. And I don't know why it is not. There we go. I'm going to go click back to perspective to zoom in a little bit. It will not be this crazy when we go to look and render this out."},{"start":"2:12","end":"2:43","startSec":132.8,"text":"Sorry, I'm horrible at saying and working on stuff at the same time. So here we go. We're going to set this to 512 by 512. This should give us a little bit more resolution. There we go. And then if we come down to, there is a camera setting here somewhere that will allow us to adjust our previews."},{"start":"2:43","end":"3:15","startSec":163.2,"text":"And maybe I'm not. Ah, here we go. That's what I was looking for. It's right next to it. The reason I want to do this is I want to bring this down a little bit so I get the smoke a little bit closer. There we go. The smoke and the fire. All right. We're also going to give this a name of, call this T underscore fire underscore sub UV. And then when we're ready to bake this, all we need to do is press this little bake button"},{"start":"3:15","end":"3:46","startSec":195.9,"text":"here. This is really cool. It's going to bake it and then we're going to see it rendered out right here. It just needs a second to stream in. But this is the textured output. We can actually look at that. There's our texture right here to save all the alpha. So you can see here it starts and then goes all the way down through. What we're going to do next is we are going to make a material out of this. All we need to really do is just change the blend mode to translucent and then connect the alpha here into the opacity. So let's do that now."},{"start":"3:46","end":"4:17","startSec":226.8,"text":"So we're going to right control space to open up the content browser. Right click. We're going to look for our material. I go this mat underscore sub UV underscore fire. And let's double click on that to open it up. And I'm just going to select this right here. And a quick way to quickly add this is to hold down the T key and left click that I have that texture sample. We're going to click the RGB into base the A and to our opacity and then set our blend"},{"start":"4:17","end":"4:49","startSec":257.7,"text":"mode here to translucent, which maybe we are RGB A. There we go RGB A and let's hit apply and save. So that is good. The next thing that we need to do is we're going to make a new particle system inside of the learning content. We're going to select a sub UV animation and hit create. And let's go ahead and do that now. So again, right click Niagara system. We're going to come here to learning content and then our sub UV animation."},{"start":"4:49","end":"5:22","startSec":289.1,"text":"We're going to hit create in S underscore fire sub UV. Then let's double click on that to open it up. And all we need to do to this is just change the material. We're going to enable cut out cut out as a way to optimize the unused part of your translucent geometry. It basically cuts the geometry to fit more or less kind of the outline of your smoke"},{"start":"5:22","end":"5:53","startSec":322.9,"text":"or your fire. This is a way to just optimize this in our particular case. This isn't going to matter as much as it would if we were using multiple effects. But anyway, we're going to set that up and then we're also going to change the uniform sprite size to 500 to make it a little bit larger. So let's go ahead and we can close the baker for now. And then our system overview right here are material. I'm going to hit control space. We're going to grab our mat sub UV fire. Bring that in right there. Okay."},{"start":"5:53","end":"6:23","startSec":353.0,"text":"And that's actually our fire working right there. Now there are a couple of other things. So we can do our cut out. Up there it is right there. And what we'll need to do is change this to the red channel. And that will give us our cut out here. All right. And then we're going to go to our initialize particle and set our size here to 500. It's going to make things a little bit bigger."},{"start":"6:23","end":"7:00","startSec":383.8,"text":"So we'll compile and save that. And I'm just going to move this out of the way so I can bring it into the world. So there we go. There is our fire. And he does not seem to be working for some reason. Let's save this and browse really quick. Oh, it's because I have real time off. There we go. You need to turn that real time renderer back on. And there is our fire. Let me just delete this. So there we go. Again, it's not looking the best because I just did a very simplistic render."},{"start":"7:00","end":"7:30","startSec":420.1,"text":"But if you were to apply a little bit more time and a few other just a couple of these, you could get some actual really good results using this particular method. And again, this is extraordinarily cheap compared to running the actual fire effect like this right here. So you know, you are losing a little bit of depth and things like that. But again, this could be used as something like, you know, for a level of detail when it's really far away, something like that."},{"start":"7:30","end":"7:52","startSec":451.0,"text":"Or there's a bunch of use cases where being able to use the baker right here can really help optimize your effects, no matter if they use liquid or just standard particle effects. You can use this for any type of effect inside of Niagara to help optimize it. So this is our end result."}],"08_Outro":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"And with that, that's going to wrap it up for this tutorial series about how to utilize liquid inside of Niagara with the Niagara Fluids plugin. Real quickly to recap what we did today, we first started out by going over the Niagara Fluids overview, just covering what Niagara Fluids is and what you can create with the system. We then took a look at enabling the Niagara Fluids plugin, how to enable that inside of the editor, where to find it, and also make sure to restart once you have enabled it."},{"start":"0:32","end":"1:03","startSec":32.9,"text":"We then talked about the Niagara Fluid content example, which is a great map in the content example collection that shows you how to use all of the various Niagara liquids as well as features such as collision, multicolored smoke, and other various bits of interaction. We then moved on to creating 2D smoke, liquid, and fire effects, followed up by creating the 3D version of smoke, liquid, and fire effects."},{"start":"1:03","end":"1:29","startSec":63.8,"text":"And finally, we finished up looking at how we can optimize our smoke, liquid, and fire effects using the Baker inside of Niagara to bake our complex Niagara liquids to a series of still images that allow them to be played back, mimicking that real time behavior. Well, that's all that I have for you. Again, my name is Sam Dider. I'm a senior Unreal Engine instructor, and I will see you next time."}]},"213.01":{"01_Introduction":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Hello, and welcome to MetaHuman Blueprints in Animation. My name is Gabriella Crusenio-Cacchus, and I will be your host for this course. In this course, we will begin by exploring the various components that make up the MetaHuman Blueprint. We will go through each component in detail in order to understand the assets associated with them, such as the skeletal meshes and rigs, the grooms, the LOD sync and MetaHuman"},{"start":"0:32","end":"1:06","startSec":32.4,"text":"component, rig logic, and the animation blueprints used by all MetaHumans. From there, we will delve into ways you can animate MetaHumans by creating and fine-tuning animations using the body and face control rigs, touching upon the IK Retargetor assets for the body, and facial animation tools that are set up to work with MetaHumans. We will also take a look at the quality differences between optimized and cinematic MetaHumans,"},{"start":"1:06","end":"1:37","startSec":66.7,"text":"and then we will wrap up this course with some final recommendations as we make adjustments to the properties of various MetaHuman components. And I will also provide you with some tips and resources for you to use as you continue your work and training with MetaHumans. This course will be using the project MEH9130055 and a level map should load automatically."},{"start":"1:37","end":"2:11","startSec":97.5,"text":"The map is located in the Content Browser under the Courses folder labeled MEH21301 in the Course Maps folder and it is named MEH21301MAP. In the Course Assets folder, I have included body animations from the Game Animation Sample project. In the folder named MHMocap, there is a body and facial animation."},{"start":"2:11","end":"2:45","startSec":131.7,"text":"The facial animation has been captured using MetaHuman Animator with an iPhone device, and the body has been captured with motion capture data and also includes finger data. In the Source Files folder named 21301AnimAsset, I have also provided a body animation UAsset file. If at any point you need to reference the location of the course map, that can be found at the beginning of the slide deck after the training outline."},{"start":"2:45","end":"3:11","startSec":165.1,"text":"Now as we go through this course, you will find that many slides in this presentation contain a lot of information. And I will summarize all of that, but if at any point you want to read what is on each of those slides, feel free to pause and dive right in. Now let's move on to the first section of this course by exploring the MetaHuman Blueprint and its components."}],"01_Introduction_55":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Hello, and welcome to MetaHuman Blueprints in Animation. My name is Gabriella Crusenio-Cacchus, and I will be your host for this course. In this course, we will begin by exploring the various components that make up the MetaHuman Blueprint. We will go through each component in detail in order to understand the assets associated with them, such as the skeletal meshes and rigs, the grooms, the LOD sync and MetaHuman"},{"start":"0:32","end":"1:06","startSec":32.4,"text":"component, rig logic, and the animation blueprints used by all MetaHumans. From there, we will delve into ways you can animate MetaHumans by creating and fine-tuning animations using the body and face control rigs, touching upon the IK Retargetor assets for the body, and facial animation tools that are set up to work with MetaHumans. We will also take a look at the quality differences between optimized and cinematic MetaHumans,"},{"start":"1:06","end":"1:37","startSec":66.7,"text":"and then we will wrap up this course with some final recommendations as we make adjustments to the properties of various MetaHuman components. And I will also provide you with some tips and resources for you to use as you continue your work and training with MetaHumans. This course will be using the project MEH9130055 and a level map should load automatically."},{"start":"1:37","end":"2:11","startSec":97.5,"text":"The map is located in the Content Browser under the Courses folder labeled MEH21301 in the Course Maps folder and it is named MEH21301MAP. In the Course Assets folder, I have included body animations from the Game Animation Sample project. In the folder named MHMocap, there is a body and facial animation."},{"start":"2:11","end":"2:45","startSec":131.7,"text":"The facial animation has been captured using MetaHuman Animator with an iPhone device, and the body has been captured with motion capture data and also includes finger data. In the Source Files folder named 21301AnimAsset, I have also provided a body animation UAsset file. If at any point you need to reference the location of the course map, that can be found at the beginning of the slide deck after the training outline."},{"start":"2:45","end":"3:11","startSec":165.1,"text":"Now as we go through this course, you will find that many slides in this presentation contain a lot of information. And I will summarize all of that, but if at any point you want to read what is on each of those slides, feel free to pause and dive right in. Now let's move on to the first section of this course by exploring the MetaHuman Blueprint and its components."}],"02_MetaHumanBP":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this section of our course, we will begin by exploring the MetaHuman Blueprint and we'll go through each of the components in detail. We will take a close look at the skeletal meshes and rigs, the grooms, the LOD sync and MetaHuman component, rig logic, and the animation blueprints used by all MetaHumans. All of the assets that can be found in the MetaHuman Blueprint are located inside of the MetaHuman's folder."},{"start":"0:31","end":"1:06","startSec":31.0,"text":"Let's begin by taking a look at what's inside the MetaHuman's folder and then we will delve into the MetaHuman Blueprint and all of its assets. Once a MetaHuman has been exported from Quixel Bridge to Unreal Engine and all of the necessary plugin and project settings have been enabled, you can navigate to the MetaHuman's folder in the Content Browser. The Common folder contains assets that are shared by some or all MetaHumans in a project."},{"start":"1:06","end":"1:38","startSec":66.0,"text":"Those assets include the shared MetaHuman-based skeleton for the body and the face archetype along with the skeletal meshes for the tops, bottoms, and shoes. The Common folder also contains the face and body control rigs, the IK Retargetor assets, the FacePose library, and shared materials and textures. The folder with the name of the MetaHuman that was added to the project will contain assets that are unique to that character."},{"start":"1:38","end":"2:10","startSec":98.0,"text":"Something to note is that it is not recommended to rename the MetaHuman's folder or move assets from existing folders such as the Common folder as they are referenced by other assets. You can however duplicate assets and move or rename those copies if you wish. Now let's jump into Unreal Engine and start exploring how all of these assets are brought together inside of the MetaHuman Blueprint."},{"start":"2:11","end":"2:43","startSec":131.0,"text":"Inside of Unreal Engine, in the viewport, we have the MetaHuman that we created from the RealityCaptureFaceScan data. In the Content folder, let's navigate to the MetaHuman's folder and locate the folder for this character. This character is named RCScan01 and I have added CQ to indicate that this was downloaded with the Cinematic Quality settings."},{"start":"2:43","end":"3:18","startSec":163.0,"text":"When we open up this folder, we will see the blueprint for this character. I will double click on this to open it. Inside of the MetaHuman Blueprint, by default the Event Graph will be visible. Over here we have the Construction script and over here we have the viewport where we can see our character. Every MetaHuman has their own blueprint consisting of skeletal mesh components for the body, the feet, the legs, the torso, and the face."},{"start":"3:19","end":"3:51","startSec":199.0,"text":"Attached to the face are the groom components which are the eyelashes, the peach fuzz, the eyebrows, the hair, the mustache, and the beard. Then there is the MetaHuman component which was added in Engine version 5.4 and this allows users to turn on and off animation features for each LOD and the LOD Sync component which controls and synchronizes the switching of MetaHuman LODs."},{"start":"3:51","end":"4:27","startSec":231.0,"text":"Each of these components will have their own unique properties that will appear inside of the Details panel. Now before we move on, let's do a quick review of the MetaHuman Blueprint. Every MetaHuman has its own blueprint consisting of the following components. The skeletal mesh components include the body, feet, legs, torso, and face. The groom components include the hair, eyebrows, eyelashes, peach fuzz, mustache, and beard."},{"start":"4:28","end":"4:59","startSec":268.0,"text":"There is also the MetaHuman component which allows you to turn on and off animation features for each LOD and the LOD Sync component which controls and synchronizes the switching of MetaHuman LODs. The construction script and event graph contain dedicated functions for ARKit and animation retargeting setups that can be customized. Now let's take a closer look at each of the MetaHuman components."}],"02_MetaHumanBP_55":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this section of our course, we will begin by exploring the MetaHuman Blueprint and we'll go through each of the components in detail. We will take a close look at the skeletal meshes and rigs, the grooms, the LOD sync and MetaHuman component, rig logic, and the animation blueprints used by all MetaHumans. All of the assets that can be found in the MetaHuman Blueprint are located inside of the MetaHuman's folder."},{"start":"0:31","end":"1:06","startSec":31.0,"text":"Let's begin by taking a look at what's inside the MetaHuman's folder and then we will delve into the MetaHuman Blueprint and all of its assets. Once a MetaHuman has been exported from Quixel Bridge to Unreal Engine and all of the necessary plugin and project settings have been enabled, you can navigate to the MetaHuman's folder in the Content Browser. The Common folder contains assets that are shared by some or all MetaHumans in a project."},{"start":"1:06","end":"1:38","startSec":66.0,"text":"Those assets include the shared MetaHuman-based skeleton for the body and the face archetype along with the skeletal meshes for the tops, bottoms, and shoes. The Common folder also contains the face and body control rigs, the IK Retargetor assets, the FacePose library, and shared materials and textures. The folder with the name of the MetaHuman that was added to the project will contain assets that are unique to that character."},{"start":"1:38","end":"2:10","startSec":98.0,"text":"Something to note is that it is not recommended to rename the MetaHuman's folder or move assets from existing folders such as the Common folder as they are referenced by other assets. You can however duplicate assets and move or rename those copies if you wish. Now let's jump into Unreal Engine and start exploring how all of these assets are brought together inside of the MetaHuman Blueprint."},{"start":"2:11","end":"2:43","startSec":131.0,"text":"Inside of Unreal Engine, in the viewport, we have the MetaHuman that we created from the RealityCaptureFaceScan data. In the Content folder, let's navigate to the MetaHuman's folder and locate the folder for this character. This character is named RCScan01 and I have added CQ to indicate that this was downloaded with the Cinematic Quality settings."},{"start":"2:43","end":"3:18","startSec":163.0,"text":"When we open up this folder, we will see the blueprint for this character. I will double click on this to open it. Inside of the MetaHuman Blueprint, by default the Event Graph will be visible. Over here we have the Construction script and over here we have the viewport where we can see our character. Every MetaHuman has their own blueprint consisting of skeletal mesh components for the body, the feet, the legs, the torso, and the face."},{"start":"3:19","end":"3:51","startSec":199.0,"text":"Attached to the face are the groom components which are the eyelashes, the peach fuzz, the eyebrows, the hair, the mustache, and the beard. Then there is the MetaHuman component which was added in Engine version 5.4 and this allows users to turn on and off animation features for each LOD and the LOD Sync component which controls and synchronizes the switching of MetaHuman LODs."},{"start":"3:51","end":"4:27","startSec":231.0,"text":"Each of these components will have their own unique properties that will appear inside of the Details panel. Now before we move on, let's do a quick review of the MetaHuman Blueprint. Every MetaHuman has its own blueprint consisting of the following components. The skeletal mesh components include the body, feet, legs, torso, and face. The groom components include the hair, eyebrows, eyelashes, peach fuzz, mustache, and beard."},{"start":"4:28","end":"4:59","startSec":268.0,"text":"There is also the MetaHuman component which allows you to turn on and off animation features for each LOD and the LOD Sync component which controls and synchronizes the switching of MetaHuman LODs. The construction script and event graph contain dedicated functions for ARKit and animation retargeting setups that can be customized. Now let's take a closer look at each of the MetaHuman components."}],"03_SkeletalMeshes":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"We will begin by looking at all of the skeletal mesh components, which include the body, the feet, the legs, the torso, and we will finish off with the face. So let's jump back into Unroll Engine and take a closer look at each of these. Let's begin by looking at the body component on the left over here. When selected, in the Details panel on the right, we can see all of the properties and"},{"start":"0:32","end":"1:06","startSec":32.7,"text":"assets associated with this component, such as the material and skeletal mesh. If we open up the skeletal mesh, it will have skinning for the hands and ankles, as this character also has clothes. If we go up here to the top right and we select the Skeleton tab, it will open up the MetaHuman based skeleton, which is shared by all MetaHumans. It will always be the female medium normal body weight and it is located in the common"},{"start":"1:06","end":"1:40","startSec":66.3,"text":"folder. If I go to the Animation tab over here, I can search for mh body animation and select it. We can see this animation sequence in this window. All of the animations over here are shared by all MetaHumans in the project, and this is because they all share the MetaHuman based skeleton. Let's return back to the MetaHuman blueprint. And before we move on, let's do a quick review of what we just covered."},{"start":"1:40","end":"2:13","startSec":100.9,"text":"The body component has a skeletal mesh with its own material. The skeletal mesh will have its own unique skinning and body proportion, and it will be located in the folder with the name of your MetaHuman. The MetaHuman based skeleton is shared by all MetaHumans in a project and is located in the common folder. This will always be the female medium normal body weight. The body component also includes animation sequences, animation blueprints, and a physics"},{"start":"2:13","end":"2:45","startSec":133.8,"text":"asset. Now let's continue by taking a look at the feet and legs components. Let's move on to the feet component. If I select the feet, over here on the right, we can see that this has its own skeletal mesh and material associated with it. Since MetaHumans are modular, we are able to switch between skeletal meshes and groom assets if we wish."},{"start":"2:45","end":"3:16","startSec":165.1,"text":"There are other MetaHumans that have been added to this project with their own unique skeletal meshes for the feet, so we can switch between those by going over here. For example, we could switch these boots out with flip flops, but keep in mind differences in body proportions and skinning when replacing assets. Now let's move on to the legs component. In the Details panel on the right, this component will have its own skeletal mesh assigned and"},{"start":"3:16","end":"3:48","startSec":196.7,"text":"its associated material. There may be cases where you want to add additional custom clothing. In this case, you can add a new skeletal mesh component. To do this, go to the Add sign and search for skeletal mesh. In the Details panel on the right, you would assign the skeletal mesh asset. And then, with the skeletal mesh selected, you would drag this over the body to make"},{"start":"3:48","end":"4:18","startSec":228.3,"text":"it a child of the body. The next step is to go to the construction script. Inside of here, drag the skeletal mesh component into the construction script. We can see how all of the skeletal mesh components are connected to Enable Master Pose nodes and are all set up to follow the body. We will need to do the same for this skeletal mesh component."},{"start":"4:18","end":"4:50","startSec":258.5,"text":"To do this, select this Enable Master Pose node and press Ctrl D to duplicate it. Then, connect the skeletal mesh component to the Enable Master Pose node. And then connect this to the other master pose nodes so that it follows the body. Now before we move on, let's review what we just covered."},{"start":"4:50","end":"5:23","startSec":290.5,"text":"For clothing components such as the feet and legs, you can replace these with custom skeletal mesh assets. Or, if you have metahumans in your project with different skeletal meshes for these components, you can switch between them. Just keep in mind differences in skinning and proportions. If you want to create your own custom clothes, you can download the Maya file from the Quixel Bridge standalone application and use the clothes as a starting point to get skinning"},{"start":"5:23","end":"5:54","startSec":323.9,"text":"and LOD templates transferred to your skeletal mesh. If you wish to add a skeletal mesh clothing component, ensure you make it a child of the body component, then add it into the construction script, connect it to its own Enable Master Pose node, and then connect it to the rest of the Enable Master Pose nodes so that it follows the body. Now let's continue by looking at the torso component."},{"start":"5:54","end":"6:30","startSec":354.6,"text":"I'm going to select it and go to the details panel and open up the skeletal mesh. Some clothing assets will have physics such as this hoodie sweater. If I go here to the top right and then go to the physics tab, inside of here we have the physics asset for the hoodie. On the left here we can select the hoodie strings or specific portions of the hoodie strings. On the right hand side in the details panel we can modify the physics properties."},{"start":"6:30","end":"7:07","startSec":390.5,"text":"Now if we go to the animation blueprint tab, this will open up the animation blueprint of the hoodie. Inside of here we can enable and disable the rigid body simulation and make other adjustments to the LOD threshold for the rigid body and control rig. If you want to have further control over the rigid body settings, you can do so in the clothing post-process animation blueprint. To access this I have the body skeletal mesh docked over here."},{"start":"7:07","end":"7:40","startSec":427.1,"text":"Inside of here I can go to the animation blueprint tab and drop this down and select the clothing post-process animation blueprint. Inside of here we can see how the rigid body node is set up and by selecting it we can adjust its properties. Now before we move on let's review what we just covered. We just took a look at the torso component."},{"start":"7:40","end":"8:14","startSec":460.1,"text":"Some of the clothing assets such as the hoodie sweater may have physics. The physics properties can be adjusted inside of the physics window of that skeletal mesh. The clothing animation blueprint will allow you to enable and disable rigid body simulation and control the LODs. In the animation graph of the clothing post-process animation blueprint, the rigid body node allows you to modify additional simulation properties."},{"start":"8:14","end":"8:49","startSec":494.1,"text":"Now let's continue by taking a look at the face component. Let's move on to the face component. In the details panel we will see that the face skeletal mesh has several materials assigned to different portions of the face such as the skin, the eyes and so on. Let's open up the skeletal mesh. Now let's go here to character, select bones and select all hierarchy."},{"start":"8:49","end":"9:21","startSec":529.9,"text":"We can see that the face has a large number of joints. I'm going to go back to character, then bones and set the joints to none. Over here on the right in the morph target panel you will find that the metahuman face also has a large number of blend shapes and corrective blend shapes. Now let's go to the skeleton tab. This will open up the face archetype skeleton which is shared by all metahumans and this"},{"start":"9:21","end":"9:55","startSec":561.8,"text":"is located in the common face folder. If we go to the blueprints tab, the face will have two animation blueprints. The face NMBP which has dedicated AR kit and animation retargeting functions and the face post process blueprint. The face post process blueprint is where Rik logic and the net correctives are set up. From here we can enable and disable certain features related to optimization and animation"},{"start":"9:55","end":"10:27","startSec":595.4,"text":"quality. Now before we move on let's review what we've just covered. The face component assets include the face archetype located in the common face folder, the face skeletal mesh which will be unique for your character, animation sequence assets and animation blueprints."},{"start":"10:27","end":"11:02","startSec":627.0,"text":"The face post process animation blueprint is where the Rik logic node lives. Rik logic is responsible for allowing animations to be shared across all metahumans and LODs. It's also responsible for triggering corrective blend shapes and animated wrinkle maps when animations are applied. By disabling the face post process blueprint it will only trigger joint deformations which will reduce the animation quality but improve performance."},{"start":"11:02","end":"11:05","startSec":662.1,"text":"Now let's move on and take a look at the groom components."}],"03_SkeletalMeshes_55":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"We will begin by looking at all of the skeletal mesh components, which include the body, the feet, the legs, the torso, and we will finish off with the face. So let's jump back into Unroll Engine and take a closer look at each of these. Let's begin by looking at the body component on the left over here. When selected, in the Details panel on the right, we can see all of the properties and"},{"start":"0:32","end":"1:06","startSec":32.7,"text":"assets associated with this component, such as the material and skeletal mesh. If we open up the skeletal mesh, it will have skinning for the hands and ankles, as this character also has clothes. If we go up here to the top right and we select the Skeleton tab, it will open up the MetaHuman based skeleton, which is shared by all MetaHumans. It will always be the female medium normal body weight and it is located in the common"},{"start":"1:06","end":"1:40","startSec":66.3,"text":"folder. If I go to the Animation tab over here, I can search for mh body animation and select it. We can see this animation sequence in this window. All of the animations over here are shared by all MetaHumans in the project, and this is because they all share the MetaHuman based skeleton. Let's return back to the MetaHuman blueprint. And before we move on, let's do a quick review of what we just covered."},{"start":"1:40","end":"2:13","startSec":100.9,"text":"The body component has a skeletal mesh with its own material. The skeletal mesh will have its own unique skinning and body proportion, and it will be located in the folder with the name of your MetaHuman. The MetaHuman based skeleton is shared by all MetaHumans in a project and is located in the common folder. This will always be the female medium normal body weight. The body component also includes animation sequences, animation blueprints, and a physics"},{"start":"2:13","end":"2:45","startSec":133.8,"text":"asset. Now let's continue by taking a look at the feet and legs components. Let's move on to the feet component. If I select the feet, over here on the right, we can see that this has its own skeletal mesh and material associated with it. Since MetaHumans are modular, we are able to switch between skeletal meshes and groom assets if we wish."},{"start":"2:45","end":"3:16","startSec":165.1,"text":"There are other MetaHumans that have been added to this project with their own unique skeletal meshes for the feet, so we can switch between those by going over here. For example, we could switch these boots out with flip flops, but keep in mind differences in body proportions and skinning when replacing assets. Now let's move on to the legs component. In the Details panel on the right, this component will have its own skeletal mesh assigned and"},{"start":"3:16","end":"3:48","startSec":196.7,"text":"its associated material. There may be cases where you want to add additional custom clothing. In this case, you can add a new skeletal mesh component. To do this, go to the Add sign and search for skeletal mesh. In the Details panel on the right, you would assign the skeletal mesh asset. And then, with the skeletal mesh selected, you would drag this over the body to make"},{"start":"3:48","end":"4:18","startSec":228.3,"text":"it a child of the body. The next step is to go to the construction script. Inside of here, drag the skeletal mesh component into the construction script. We can see how all of the skeletal mesh components are connected to Enable Master Pose nodes and are all set up to follow the body. We will need to do the same for this skeletal mesh component."},{"start":"4:18","end":"4:50","startSec":258.5,"text":"To do this, select this Enable Master Pose node and press Ctrl D to duplicate it. Then, connect the skeletal mesh component to the Enable Master Pose node. And then connect this to the other master pose nodes so that it follows the body. Now before we move on, let's review what we just covered."},{"start":"4:50","end":"5:23","startSec":290.5,"text":"For clothing components such as the feet and legs, you can replace these with custom skeletal mesh assets. Or, if you have metahumans in your project with different skeletal meshes for these components, you can switch between them. Just keep in mind differences in skinning and proportions. If you want to create your own custom clothes, you can download the Maya file from the Quixel Bridge standalone application and use the clothes as a starting point to get skinning"},{"start":"5:23","end":"5:54","startSec":323.9,"text":"and LOD templates transferred to your skeletal mesh. If you wish to add a skeletal mesh clothing component, ensure you make it a child of the body component, then add it into the construction script, connect it to its own Enable Master Pose node, and then connect it to the rest of the Enable Master Pose nodes so that it follows the body. Now let's continue by looking at the torso component."},{"start":"5:54","end":"6:30","startSec":354.6,"text":"I'm going to select it and go to the details panel and open up the skeletal mesh. Some clothing assets will have physics such as this hoodie sweater. If I go here to the top right and then go to the physics tab, inside of here we have the physics asset for the hoodie. On the left here we can select the hoodie strings or specific portions of the hoodie strings. On the right hand side in the details panel we can modify the physics properties."},{"start":"6:30","end":"7:07","startSec":390.5,"text":"Now if we go to the animation blueprint tab, this will open up the animation blueprint of the hoodie. Inside of here we can enable and disable the rigid body simulation and make other adjustments to the LOD threshold for the rigid body and control rig. If you want to have further control over the rigid body settings, you can do so in the clothing post-process animation blueprint. To access this I have the body skeletal mesh docked over here."},{"start":"7:07","end":"7:40","startSec":427.1,"text":"Inside of here I can go to the animation blueprint tab and drop this down and select the clothing post-process animation blueprint. Inside of here we can see how the rigid body node is set up and by selecting it we can adjust its properties. Now before we move on let's review what we just covered. We just took a look at the torso component."},{"start":"7:40","end":"8:14","startSec":460.1,"text":"Some of the clothing assets such as the hoodie sweater may have physics. The physics properties can be adjusted inside of the physics window of that skeletal mesh. The clothing animation blueprint will allow you to enable and disable rigid body simulation and control the LODs. In the animation graph of the clothing post-process animation blueprint, the rigid body node allows you to modify additional simulation properties."},{"start":"8:14","end":"8:49","startSec":494.1,"text":"Now let's continue by taking a look at the face component. Let's move on to the face component. In the details panel we will see that the face skeletal mesh has several materials assigned to different portions of the face such as the skin, the eyes and so on. Let's open up the skeletal mesh. Now let's go here to character, select bones and select all hierarchy."},{"start":"8:49","end":"9:21","startSec":529.9,"text":"We can see that the face has a large number of joints. I'm going to go back to character, then bones and set the joints to none. Over here on the right in the morph target panel you will find that the metahuman face also has a large number of blend shapes and corrective blend shapes. Now let's go to the skeleton tab. This will open up the face archetype skeleton which is shared by all metahumans and this"},{"start":"9:21","end":"9:55","startSec":561.8,"text":"is located in the common face folder. If we go to the blueprints tab, the face will have two animation blueprints. The face NMBP which has dedicated AR kit and animation retargeting functions and the face post process blueprint. The face post process blueprint is where Rik logic and the net correctives are set up. From here we can enable and disable certain features related to optimization and animation"},{"start":"9:55","end":"10:27","startSec":595.4,"text":"quality. Now before we move on let's review what we've just covered. The face component assets include the face archetype located in the common face folder, the face skeletal mesh which will be unique for your character, animation sequence assets and animation blueprints."},{"start":"10:27","end":"11:02","startSec":627.0,"text":"The face post process animation blueprint is where the Rik logic node lives. Rik logic is responsible for allowing animations to be shared across all metahumans and LODs. It's also responsible for triggering corrective blend shapes and animated wrinkle maps when animations are applied. By disabling the face post process blueprint it will only trigger joint deformations which will reduce the animation quality but improve performance."},{"start":"11:02","end":"11:05","startSec":662.1,"text":"Now let's move on and take a look at the groom components."}],"04_GroomsLODs1":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"We have just finished looking at the skeletal mesh components and will now move on to the groom components and dive into the groom asset editor. Then we will look at the LOD sync and metahuman component. Now let's jump back into Unreal Engine and begin exploring the groom components. Back inside of Unreal Engine, I have opened up the blueprint for Lena CQ from the metahuman introduction course."},{"start":"0:32","end":"1:08","startSec":32.3,"text":"I will use this blueprint as I go through the groom components. The groom components are children of the face component as they follow the head. The components include the eyelashes, peach fuzz, the eyebrows, the hair, the mustache and the beard. When looking at the groom components, we will see that even though this metahuman does not have a mustache or beard, those groom components will serve as placeholders for those assets."},{"start":"1:08","end":"1:45","startSec":68.1,"text":"When we select the hair component in the details panel, each groom asset comes with its own material instance and depending on the style, it will have one for the hair, the helmet and carts. If we open this material instance, there will be a number of parameters you can adjust to control the appearance of the hair without ever having to open the master material. Now if we go back to the metahuman blueprint, right below the materials, we will have a"},{"start":"1:45","end":"2:20","startSec":105.2,"text":"groom asset and groom binding asset. The binding asset is used to attach and skin a groom component to a skeletal mesh. If importing your own custom groom, ensure you assign the skeletal mesh that this groom should be bound to in the groom binding asset. Let's open up this groom asset and dock it here. With the groom asset editor, we can manage aspects of our groom, such as how the groom"},{"start":"2:20","end":"2:53","startSec":140.6,"text":"is rendered, how it handles physics simulation and manages LODs. Starting with the LOD panel, this is where we can control the switch between LODs based on screen size in the viewport and specify what type of geometry it should switch to. For example, for this groom, LOD0 uses strands and LOD1 uses strands. For LOD2 and 3, it uses cards."},{"start":"2:53","end":"3:27","startSec":173.9,"text":"Next, we have the interpolation panel. Interpolation defines how groom curves should move with respect to skinning and physics simulation. For large skeletal mesh deformations and simulation, when RBF interpolation is enabled, it will help to preserve the original groom's position, regardless of the physics simulation and deformation. Next, we have the strands panel."},{"start":"3:27","end":"4:01","startSec":207.1,"text":"This controls the rendering properties related to the strand geometry. It can be used to control physical properties of the hair, such as the hair tip scale, for example, which can make the hair look finer if the value is set to a lower number. Next, we have the cards panel. This is where you can set up the card geometry and specify if you want the engine to generate cards procedurally or if you want to import your own cards."},{"start":"4:01","end":"4:31","startSec":241.1,"text":"The Meshes panel manages the mesh geometry that is used for LODs. When LODs switch for the grooms, they go from strands to cards to meshes. And this is where you can manage those assets. The Materials panel is where you define what materials are used by the groom asset. The Physics panel is where you can enable or disable physics simulation and control"},{"start":"4:31","end":"5:04","startSec":271.8,"text":"the simulation properties, such as the external forces, the bend, stretch, and collision constraint, and strand parameters. Now before we move on, let's do a quick review of what we just covered. If we open up a groom asset, we can use the groom asset editor to adjust a variety of properties. The LOD panel is where we can control and configure what the groom switches to for each"},{"start":"5:04","end":"5:38","startSec":304.8,"text":"LOD by setting the visibility, screen size, and geometry types that are used. For example, strand based grooms may perform poorly when using multiple metahumans at the highest LOD setting. By changing the geometry to use cards or meshes, this will boost performance. If you want to force card based geometry for all hair grooms instead of strands when working in a level, you can use the console variable shown on the bottom right."},{"start":"5:38","end":"6:10","startSec":338.9,"text":"The interpolation panel is used to control how a groom's curves should move with respect to the skinned meshes and physics simulation when a groom is bound to a skeletal mesh and skinning is used for deformation. During deformation and physics simulation, RBF interpolation is what preserves the original groom shape. By disabling this, the groom will use the local skin rigid transform it is bound to."},{"start":"6:10","end":"6:42","startSec":370.6,"text":"And disabling this may come in handy if for instance, the eyebrows on your metahuman begin to flutter even when there is no animation applied. The strands panel is where we can control the rendering properties related to the strand geometry of a groom. Some of those properties include the hair width, root scale, and hair tip scale. The hair shadow density reduces or increases the amount of shadow on the groom as we can"},{"start":"6:42","end":"7:16","startSec":402.0,"text":"see on the images on the right. We can decrease the amount to help with flickering hair shadows and transmission. The cards panel is where you can set up your card geometry and textures and specify if you want the engine to procedurally generate them or to import your own. The meshes panel is where you can set the mesh, textures, and mapping to specific hair grooms and LODs. And the materials panel is where you can define what materials are used by a specific groom"},{"start":"7:16","end":"7:49","startSec":436.9,"text":"asset. And finally, the physics panel is where you can enable or disable physics simulation and the simulation properties of things such as the external forces, collision, and strand parameters. Keep in mind that some groom assets will have more than one solver setting, so if you wish to disable simulation for a groom asset, you may want to scroll down and check that you have disabled it in the additional solver settings."},{"start":"7:49","end":"8:01","startSec":469.7,"text":"Now that we have a better understanding of the groom component and have also looked at the groom asset editor, let's jump back into Unreal Engine and now take a look at the LOD sync component."}],"04_GroomsLODs1_55":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"We have just finished looking at the skeletal mesh components and will now move on to the groom components and dive into the groom asset editor. Then we will look at the LOD sync and metahuman component. Now let's jump back into Unreal Engine and begin exploring the groom components. Back inside of Unreal Engine, I have opened up the blueprint for Lena CQ from the metahuman introduction course."},{"start":"0:32","end":"1:08","startSec":32.3,"text":"I will use this blueprint as I go through the groom components. The groom components are children of the face component as they follow the head. The components include the eyelashes, peach fuzz, the eyebrows, the hair, the mustache and the beard. When looking at the groom components, we will see that even though this metahuman does not have a mustache or beard, those groom components will serve as placeholders for those assets."},{"start":"1:08","end":"1:45","startSec":68.1,"text":"When we select the hair component in the details panel, each groom asset comes with its own material instance and depending on the style, it will have one for the hair, the helmet and carts. If we open this material instance, there will be a number of parameters you can adjust to control the appearance of the hair without ever having to open the master material. Now if we go back to the metahuman blueprint, right below the materials, we will have a"},{"start":"1:45","end":"2:20","startSec":105.2,"text":"groom asset and groom binding asset. The binding asset is used to attach and skin a groom component to a skeletal mesh. If importing your own custom groom, ensure you assign the skeletal mesh that this groom should be bound to in the groom binding asset. Let's open up this groom asset and dock it here. With the groom asset editor, we can manage aspects of our groom, such as how the groom"},{"start":"2:20","end":"2:53","startSec":140.6,"text":"is rendered, how it handles physics simulation and manages LODs. Starting with the LOD panel, this is where we can control the switch between LODs based on screen size in the viewport and specify what type of geometry it should switch to. For example, for this groom, LOD0 uses strands and LOD1 uses strands. For LOD2 and 3, it uses cards."},{"start":"2:53","end":"3:27","startSec":173.9,"text":"Next, we have the interpolation panel. Interpolation defines how groom curves should move with respect to skinning and physics simulation. For large skeletal mesh deformations and simulation, when RBF interpolation is enabled, it will help to preserve the original groom's position, regardless of the physics simulation and deformation. Next, we have the strands panel."},{"start":"3:27","end":"4:01","startSec":207.1,"text":"This controls the rendering properties related to the strand geometry. It can be used to control physical properties of the hair, such as the hair tip scale, for example, which can make the hair look finer if the value is set to a lower number. Next, we have the cards panel. This is where you can set up the card geometry and specify if you want the engine to generate cards procedurally or if you want to import your own cards."},{"start":"4:01","end":"4:31","startSec":241.1,"text":"The Meshes panel manages the mesh geometry that is used for LODs. When LODs switch for the grooms, they go from strands to cards to meshes. And this is where you can manage those assets. The Materials panel is where you define what materials are used by the groom asset. The Physics panel is where you can enable or disable physics simulation and control"},{"start":"4:31","end":"5:04","startSec":271.8,"text":"the simulation properties, such as the external forces, the bend, stretch, and collision constraint, and strand parameters. Now before we move on, let's do a quick review of what we just covered. If we open up a groom asset, we can use the groom asset editor to adjust a variety of properties. The LOD panel is where we can control and configure what the groom switches to for each"},{"start":"5:04","end":"5:38","startSec":304.8,"text":"LOD by setting the visibility, screen size, and geometry types that are used. For example, strand based grooms may perform poorly when using multiple metahumans at the highest LOD setting. By changing the geometry to use cards or meshes, this will boost performance. If you want to force card based geometry for all hair grooms instead of strands when working in a level, you can use the console variable shown on the bottom right."},{"start":"5:38","end":"6:10","startSec":338.9,"text":"The interpolation panel is used to control how a groom's curves should move with respect to the skinned meshes and physics simulation when a groom is bound to a skeletal mesh and skinning is used for deformation. During deformation and physics simulation, RBF interpolation is what preserves the original groom shape. By disabling this, the groom will use the local skin rigid transform it is bound to."},{"start":"6:10","end":"6:42","startSec":370.6,"text":"And disabling this may come in handy if for instance, the eyebrows on your metahuman begin to flutter even when there is no animation applied. The strands panel is where we can control the rendering properties related to the strand geometry of a groom. Some of those properties include the hair width, root scale, and hair tip scale. The hair shadow density reduces or increases the amount of shadow on the groom as we can"},{"start":"6:42","end":"7:16","startSec":402.0,"text":"see on the images on the right. We can decrease the amount to help with flickering hair shadows and transmission. The cards panel is where you can set up your card geometry and textures and specify if you want the engine to procedurally generate them or to import your own. The meshes panel is where you can set the mesh, textures, and mapping to specific hair grooms and LODs. And the materials panel is where you can define what materials are used by a specific groom"},{"start":"7:16","end":"7:49","startSec":436.9,"text":"asset. And finally, the physics panel is where you can enable or disable physics simulation and the simulation properties of things such as the external forces, collision, and strand parameters. Keep in mind that some groom assets will have more than one solver setting, so if you wish to disable simulation for a groom asset, you may want to scroll down and check that you have disabled it in the additional solver settings."},{"start":"7:49","end":"8:01","startSec":469.7,"text":"Now that we have a better understanding of the groom component and have also looked at the groom asset editor, let's jump back into Unreal Engine and now take a look at the LOD sync component."}],"05_GroomsLODs2":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"We just finished looking at the groom component. In this section, we will delve into the LOD sync component and then take a close look at the metahuman component. So let's jump into Unreal Engine and begin by exploring the LOD sync component. Each of the components that make up a metahuman use different types of geometry and different numbers of LODs."},{"start":"0:31","end":"1:07","startSec":31.7,"text":"If we look at the face skeletal mesh, the face and groom components will have up to eight individual LODs. If we set this to LOD 7, we can see a change in the grooms, the geometry, and skeleton. Now if we take a look at the body skeletal mesh, over here we will have up to four LODs. When we switch this to LOD 4, we can see a change in the skeletal mesh geometry and a"},{"start":"1:07","end":"1:41","startSec":67.7,"text":"more simplified skeleton without correctives. Now let's return to our metahuman blueprint. Over here, the LOD sync component is what manages and synchronizes the LODs across all of the different metahuman components so that they switch at the same time. As we saw, the face and groom components have up to eight individual LODs. The body, feet, legs, and torso have up to four individual LODs."},{"start":"1:41","end":"2:15","startSec":101.9,"text":"This means that for every two LOD quality changes on the face and grooms, there will be one LOD quality change for the body, feet, legs, and torso. In the details panel of the LOD sync component, the custom LOD mapping option is where you can control how LODs switch. We can see how this is set up for the body component. For every two LOD quality changes, the body will switch from LOD 0 to LOD 1 and so on."},{"start":"2:15","end":"2:52","startSec":135.9,"text":"The number of LOD settings is where you can set the maximum number of LODs that are available. By default, it will be set to eight. The forced LOD setting is where we can set an LOD to be used by all metahuman components. By default, this is set to negative one. If for example we only want to use LOD 0, we would enter 0. The minimum LOD setting is where you can set the minimum LOD. So for example, if you set this for LOD 2 to be the minimum LOD when synchronizing components,"},{"start":"2:52","end":"3:26","startSec":172.7,"text":"LOD 0 and 1 will be skipped. Now before we move on, let's do a quick review of what we just covered. The LOD sync component is responsible for managing and synchronizing the LODs across the different metahuman blueprint components so that they switch at the same time. As we just saw, the face and grooms have up to eight individual LODs. The body, feet, legs, and torso have up to four."},{"start":"3:26","end":"3:57","startSec":206.5,"text":"We saw in the custom LOD mapping that for every two LOD quality changes on the face and grooms, there is only one LOD quality change for the body, feet, legs, and torso. In the LOD sync settings, you can set the maximum number of available LODs in the number of LODs setting. By default, this is set to eight. You can also set an LOD to be used across all metahuman components with the forced LOD setting."},{"start":"3:57","end":"4:35","startSec":237.7,"text":"And by default, this is set to negative one. Now let's return to Unreal Engine and take a look at the metahuman component. The metahuman component was added in engine version 5.4. This allows us to turn on and off animation features for each LOD. We can control at what LOD certain things are evaluated at, such as the body and neck correctives, rig logic, procedurally running control rigs, and rigid body simulation."},{"start":"4:35","end":"5:05","startSec":275.5,"text":"In the body parts settings, which apply to the torso, legs, and feet, we can control the maximum LOD level that the procedural control rig and rigid body simulation is applied to the physics asset that has been assigned. For example, for the control rig LOD threshold setting of the hoodie, if we set this to two, physics simulation will only be enabled for LOD zero, one, and two on this body part with control rig."},{"start":"5:05","end":"5:39","startSec":305.8,"text":"For the rigid body LOD threshold, we can control the maximum level to simulate the rigid bodies of the hoodie. If we were to set this to one, the hoodie will simulate for LOD zero and one. Another thing we can do is to enable and disable body and neck correctives. Enemies are responsible for preserving the volume of the skin, resulting in higher quality animations and more believable movement. However, this comes at the cost of performance."},{"start":"5:39","end":"6:10","startSec":339.3,"text":"By default, the body and neck correctives and the neck procedural control rig are only applied at LOD zero. If we disable the body and neck correctives, we will see a boost in performance at the cost of quality. For the neck corrective LOD threshold, we can control the maximum level where these post drivers are evaluated. We can also control the maximum level where the neck procedural control rig is evaluated."},{"start":"6:10","end":"6:42","startSec":370.4,"text":"For example, if we change that value to two, correctives will be evaluated for LOD zero, one, and two. The face animation LOD threshold controls the maximum LOD level where rig logic is evaluated. If we change the threshold to two, rig logic will be evaluated at LOD zero, one, and two. When this is set to negative one, rig logic will always be evaluated and will disable"},{"start":"6:42","end":"7:15","startSec":402.2,"text":"LODing, which results in a boost in quality but lower performance. Now let's do a quick review of the metahuman component before we move on. The metahuman component allows us to enable and disable animation features for each LOD. We can control the LOD level we want correctives, rig logic, procedurally running control rigs, and rigid body simulation to be evaluated at."},{"start":"7:15","end":"7:51","startSec":435.9,"text":"When correctives are enabled, the volume of the skin is preserved during animation at the expense of performance. Disabling correctives will result in a boost in performance but at the cost of quality. For clothing with physics properties such as the hoodie sweater, we can set the maximum LOD level we want physics to be simulated for this asset using the rigid body LOD threshold setting. We can also set the maximum LOD we want physics to be simulated when used with control rig"},{"start":"7:51","end":"8:21","startSec":471.4,"text":"by adjusting the control rig LOD threshold. For example, if we set this to two, simulation will be enabled for LOD zero, one, and two. The facial animation LOD threshold allows us to set the maximum LOD level for rig logic to be evaluated. Setting this to zero or one will mean that rig logic will only be evaluated at this LOD level."},{"start":"8:21","end":"8:53","startSec":501.4,"text":"The LOD threshold for the neck correctives and neck procedural control rig controls the maximum LOD at which correctives are evaluated. Deactivating these or setting the LOD threshold to a lower value will result in a boost in performance but at the expense of quality. Now let's move on to uncover what role rig logic and the metahuman animation blueprints have on quality and performance."}],"05_GroomsLODs2_55":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"We just finished looking at the groom component. In this section, we will delve into the LOD sync component and then take a close look at the metahuman component. So let's jump into Unreal Engine and begin by exploring the LOD sync component. Each of the components that make up a metahuman use different types of geometry and different numbers of LODs."},{"start":"0:31","end":"1:07","startSec":31.7,"text":"If we look at the face skeletal mesh, the face and groom components will have up to eight individual LODs. If we set this to LOD 7, we can see a change in the grooms, the geometry, and skeleton. Now if we take a look at the body skeletal mesh, over here we will have up to four LODs. When we switch this to LOD 4, we can see a change in the skeletal mesh geometry and a"},{"start":"1:07","end":"1:41","startSec":67.7,"text":"more simplified skeleton without correctives. Now let's return to our metahuman blueprint. Over here, the LOD sync component is what manages and synchronizes the LODs across all of the different metahuman components so that they switch at the same time. As we saw, the face and groom components have up to eight individual LODs. The body, feet, legs, and torso have up to four individual LODs."},{"start":"1:41","end":"2:15","startSec":101.9,"text":"This means that for every two LOD quality changes on the face and grooms, there will be one LOD quality change for the body, feet, legs, and torso. In the details panel of the LOD sync component, the custom LOD mapping option is where you can control how LODs switch. We can see how this is set up for the body component. For every two LOD quality changes, the body will switch from LOD 0 to LOD 1 and so on."},{"start":"2:15","end":"2:52","startSec":135.9,"text":"The number of LOD settings is where you can set the maximum number of LODs that are available. By default, it will be set to eight. The forced LOD setting is where we can set an LOD to be used by all metahuman components. By default, this is set to negative one. If for example we only want to use LOD 0, we would enter 0. The minimum LOD setting is where you can set the minimum LOD. So for example, if you set this for LOD 2 to be the minimum LOD when synchronizing components,"},{"start":"2:52","end":"3:26","startSec":172.7,"text":"LOD 0 and 1 will be skipped. Now before we move on, let's do a quick review of what we just covered. The LOD sync component is responsible for managing and synchronizing the LODs across the different metahuman blueprint components so that they switch at the same time. As we just saw, the face and grooms have up to eight individual LODs. The body, feet, legs, and torso have up to four."},{"start":"3:26","end":"3:57","startSec":206.5,"text":"We saw in the custom LOD mapping that for every two LOD quality changes on the face and grooms, there is only one LOD quality change for the body, feet, legs, and torso. In the LOD sync settings, you can set the maximum number of available LODs in the number of LODs setting. By default, this is set to eight. You can also set an LOD to be used across all metahuman components with the forced LOD setting."},{"start":"3:57","end":"4:35","startSec":237.7,"text":"And by default, this is set to negative one. Now let's return to Unreal Engine and take a look at the metahuman component. The metahuman component was added in engine version 5.4. This allows us to turn on and off animation features for each LOD. We can control at what LOD certain things are evaluated at, such as the body and neck correctives, rig logic, procedurally running control rigs, and rigid body simulation."},{"start":"4:35","end":"5:05","startSec":275.5,"text":"In the body parts settings, which apply to the torso, legs, and feet, we can control the maximum LOD level that the procedural control rig and rigid body simulation is applied to the physics asset that has been assigned. For example, for the control rig LOD threshold setting of the hoodie, if we set this to two, physics simulation will only be enabled for LOD zero, one, and two on this body part with control rig."},{"start":"5:05","end":"5:39","startSec":305.8,"text":"For the rigid body LOD threshold, we can control the maximum level to simulate the rigid bodies of the hoodie. If we were to set this to one, the hoodie will simulate for LOD zero and one. Another thing we can do is to enable and disable body and neck correctives. Enemies are responsible for preserving the volume of the skin, resulting in higher quality animations and more believable movement. However, this comes at the cost of performance."},{"start":"5:39","end":"6:10","startSec":339.3,"text":"By default, the body and neck correctives and the neck procedural control rig are only applied at LOD zero. If we disable the body and neck correctives, we will see a boost in performance at the cost of quality. For the neck corrective LOD threshold, we can control the maximum level where these post drivers are evaluated. We can also control the maximum level where the neck procedural control rig is evaluated."},{"start":"6:10","end":"6:42","startSec":370.4,"text":"For example, if we change that value to two, correctives will be evaluated for LOD zero, one, and two. The face animation LOD threshold controls the maximum LOD level where rig logic is evaluated. If we change the threshold to two, rig logic will be evaluated at LOD zero, one, and two. When this is set to negative one, rig logic will always be evaluated and will disable"},{"start":"6:42","end":"7:15","startSec":402.2,"text":"LODing, which results in a boost in quality but lower performance. Now let's do a quick review of the metahuman component before we move on. The metahuman component allows us to enable and disable animation features for each LOD. We can control the LOD level we want correctives, rig logic, procedurally running control rigs, and rigid body simulation to be evaluated at."},{"start":"7:15","end":"7:51","startSec":435.9,"text":"When correctives are enabled, the volume of the skin is preserved during animation at the expense of performance. Disabling correctives will result in a boost in performance but at the cost of quality. For clothing with physics properties such as the hoodie sweater, we can set the maximum LOD level we want physics to be simulated for this asset using the rigid body LOD threshold setting. We can also set the maximum LOD we want physics to be simulated when used with control rig"},{"start":"7:51","end":"8:21","startSec":471.4,"text":"by adjusting the control rig LOD threshold. For example, if we set this to two, simulation will be enabled for LOD zero, one, and two. The facial animation LOD threshold allows us to set the maximum LOD level for rig logic to be evaluated. Setting this to zero or one will mean that rig logic will only be evaluated at this LOD level."},{"start":"8:21","end":"8:53","startSec":501.4,"text":"The LOD threshold for the neck correctives and neck procedural control rig controls the maximum LOD at which correctives are evaluated. Deactivating these or setting the LOD threshold to a lower value will result in a boost in performance but at the expense of quality. Now let's move on to uncover what role rig logic and the metahuman animation blueprints have on quality and performance."}],"06_RigLogicAnimBP":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"Rig logic and the metahuman face and body animation blueprints have a variety of functions. Let's begin by answering the question, what is rig logic? Rig logic is a runtime facial rig evaluation solver system developed by 3Lateral and it relies on a universal set of rules for defining the muscular system of a human face. For rig logic to work, it needs metahuman DNA, a proprietary file format that stores"},{"start":"0:35","end":"1:09","startSec":35.7,"text":"the complete description of a metahuman's face rig and geometry. Some important elements that make up the metahuman face rig include joint, skin weight, and blend shape deformers, base and animated texture maps setups, the rig logic plugin and metahuman DNA, the user interface of the face control rig, and built in LODs. Simply put, rig logic allows for animations to be shared by all metahumans and LODs."},{"start":"1:09","end":"1:41","startSec":69.7,"text":"And it is responsible for activating blend shapes, corrective blend shapes, and joint transformations while triggering animated maps during animation. Let's jump into Unreal Engine for a moment to take a closer look at these animated maps and see how they are activated by rig logic. Inside of the metahuman blueprint, let's begin by selecting the face component."},{"start":"1:41","end":"2:12","startSec":101.7,"text":"Over here in the details panel, let's open up the head synthesized material instance. Inside of here, we have a variety of parameters we can adjust. The base color texture maps are located over here. We have the main albedo texture, and then right below we have three blood flow maps. If we open these blood flow maps up, we will see a bit of redness added to certain areas"},{"start":"2:12","end":"2:44","startSec":132.6,"text":"of the face. When the face muscles contract during certain expressions, causing the skin to wrinkle in those areas, the blood flow is pushed towards the edge of the skin. Each of these blood flow maps are triggered by specific facial poses. Let's go back to the material instance. Over here are the normal maps. We have our main normal map, which is 8K for cinematic metahumans."},{"start":"2:44","end":"3:17","startSec":164.5,"text":"And right below are three animated wrinkle maps. These normal maps work together with the blood flow maps and are set up in the same way so that when certain muscles are activated for specific facial poses, wrinkles will appear in those areas. Rig logic activates all of these textures while also triggering blend shapes, corrective blend shapes, and joint transforms. To better see how these texture maps are set up to be triggered by Rig logic, let's scroll"},{"start":"3:17","end":"3:47","startSec":197.1,"text":"to the bottom of this material instance, and then double click on this, and then double click on this. This will open up the M-head baked material. This is the master material where everything is brought together and connected. If we look at this section over here, where the normal maps are set up, we will see several material functions."},{"start":"3:47","end":"4:23","startSec":227.5,"text":"If I double click on this material function, we will see more material functions. And if we open up this material function, inside of here, we can see how some of the animated wrinkle maps are set up to be triggered by specific facial expressions. And all of these are activated and evaluated through the face post-process animation blueprint. Now, before we move on, let's do a quick review of what we just covered."},{"start":"4:23","end":"5:00","startSec":263.7,"text":"The face component has materials that use animated wrinkle maps. Rig logic is responsible for triggering when the face is animated. The M-head baked material is the master material that contains several material functions set up to trigger the different texture maps for specific facial poses. One of the benefits of the way this is all set up is that you can use the existing blood flow and normal wrinkle maps as a base for customizing your own textures, and then easily"},{"start":"5:00","end":"5:30","startSec":300.0,"text":"replace the existing ones with yours in the head synthesized material instance. The rig logic node lives in the face post-process animation blueprint. If the blueprint is disabled, it will only trigger joint deformations, resulting in a boost in performance but at the expense of quality. The images on the right are examples of what a smile looks like when the face post-process"},{"start":"5:30","end":"6:00","startSec":330.3,"text":"is enabled and disabled. With complex expressions, some joints are affected by more than one expression, resulting in multiplied deformations. Corrective blend shapes on the metahuman face have been defined to correct the joint overlap for complex expressions such as the smile. The face post-process blueprint is also where the neck correctives for the head component"},{"start":"6:00","end":"6:37","startSec":360.9,"text":"are set up. The animated gif all the way on the right shows these at work. When the neck moves, the volume in these areas of deformation are preserved so that it looks natural. When disabled, we will see a boost in performance but at the expense of quality. The body animation blueprint contains corrective poses through a pose driver setup. These trigger specific combinations of poses and joints that correct certain skeleton poses."},{"start":"6:37","end":"7:13","startSec":397.2,"text":"We can see these corrective poses at work in the animated gif on the left. When the upper arm is rotated, the volume is preserved by these corrective poses. Using the pose driver connect tool set in Autodesk Maya, you can author your own corrective poses and import those into Unreal Engine. And we touch on this in the metahuman DNA calibration courses. There are cases where individual body correctives can be adjusted when retargeting animations"},{"start":"7:13","end":"7:44","startSec":433.2,"text":"from skeletons that have different proportions. So let's jump into Unreal Engine for a moment to take a look at this process. Inside of the animation sequence window, I have applied an animation to Lena's skeletal mesh. I'm going to bring the upper arms closer to view so that we can see the changes that will occur once we make some adjustments to the skeleton retargeting options of the correctives."},{"start":"7:44","end":"8:14","startSec":464.1,"text":"In the skeleton tree panel on the left, I'm going to go to the cogwheel and select show retargeting options. For the main joints such as the spines, the upper and lower arms, and so on, I have changed the retargeting options for those to skeleton and left all of the correctives set to animation. If we search for the upper arm in the skeleton tree search bar, the upper arm joints will be displayed."},{"start":"8:14","end":"8:49","startSec":494.8,"text":"This here is one of the many correctives for the left upper arm. And these down here are correctives for the right upper arm. If I select all of the correctives for the left upper arm and right click on them and select recursively set translation retargeting to skeleton, the volume in the upper arm area will be lost. Using this setting is helpful for the main joints when retargeting animations from different"},{"start":"8:49","end":"9:22","startSec":529.1,"text":"skeletons and skeletons of different proportions. Now if I right click and select recursively set translation retargeting to animation, we can see the volume returns. Before we move on, let's do a quick review of the steps we just covered. We just went through an example showing how we can adjust the bone translation retargeting options settings for the body correctives."},{"start":"9:22","end":"9:56","startSec":562.5,"text":"By changing the retargeting options for the main joints to skeleton, this takes differences in skeleton proportions out of the equation so that animations can be applied to different skeletons. Leaving the correctives to animation preserves the volume in areas of deformation regardless of differences in skeleton proportions. To do this, in the skeleton tree, go to the cogwheel and check on show retargeting options."},{"start":"9:56","end":"10:31","startSec":596.2,"text":"From there you can either change the translation retargeting of individual joints, or select a group of joints, then right click and select recursively set to and choose either skeleton, animation, animation scaled and so on. The bone retargeting options are helpful when retargeting and applying animation data from skeletons of different proportions. Now let's move on to the next section of our course where we explore a few different ways"},{"start":"10:31","end":"10:33","startSec":631.6,"text":"we can animate metahumans."}],"06_RigLogicAnimBP_55":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"Rig logic and the metahuman face and body animation blueprints have a variety of functions. Let's begin by answering the question, what is rig logic? Rig logic is a runtime facial rig evaluation solver system developed by 3Lateral and it relies on a universal set of rules for defining the muscular system of a human face. For rig logic to work, it needs metahuman DNA, a proprietary file format that stores"},{"start":"0:35","end":"1:09","startSec":35.7,"text":"the complete description of a metahuman's face rig and geometry. Some important elements that make up the metahuman face rig include joint, skin weight, and blend shape deformers, base and animated texture maps setups, the rig logic plugin and metahuman DNA, the user interface of the face control rig, and built in LODs. Simply put, rig logic allows for animations to be shared by all metahumans and LODs."},{"start":"1:09","end":"1:41","startSec":69.7,"text":"And it is responsible for activating blend shapes, corrective blend shapes, and joint transformations while triggering animated maps during animation. Let's jump into Unreal Engine for a moment to take a closer look at these animated maps and see how they are activated by rig logic. Inside of the metahuman blueprint, let's begin by selecting the face component."},{"start":"1:41","end":"2:12","startSec":101.7,"text":"Over here in the details panel, let's open up the head synthesized material instance. Inside of here, we have a variety of parameters we can adjust. The base color texture maps are located over here. We have the main albedo texture, and then right below we have three blood flow maps. If we open these blood flow maps up, we will see a bit of redness added to certain areas"},{"start":"2:12","end":"2:44","startSec":132.6,"text":"of the face. When the face muscles contract during certain expressions, causing the skin to wrinkle in those areas, the blood flow is pushed towards the edge of the skin. Each of these blood flow maps are triggered by specific facial poses. Let's go back to the material instance. Over here are the normal maps. We have our main normal map, which is 8K for cinematic metahumans."},{"start":"2:44","end":"3:17","startSec":164.5,"text":"And right below are three animated wrinkle maps. These normal maps work together with the blood flow maps and are set up in the same way so that when certain muscles are activated for specific facial poses, wrinkles will appear in those areas. Rig logic activates all of these textures while also triggering blend shapes, corrective blend shapes, and joint transforms. To better see how these texture maps are set up to be triggered by Rig logic, let's scroll"},{"start":"3:17","end":"3:47","startSec":197.1,"text":"to the bottom of this material instance, and then double click on this, and then double click on this. This will open up the M-head baked material. This is the master material where everything is brought together and connected. If we look at this section over here, where the normal maps are set up, we will see several material functions."},{"start":"3:47","end":"4:23","startSec":227.5,"text":"If I double click on this material function, we will see more material functions. And if we open up this material function, inside of here, we can see how some of the animated wrinkle maps are set up to be triggered by specific facial expressions. And all of these are activated and evaluated through the face post-process animation blueprint. Now, before we move on, let's do a quick review of what we just covered."},{"start":"4:23","end":"5:00","startSec":263.7,"text":"The face component has materials that use animated wrinkle maps. Rig logic is responsible for triggering when the face is animated. The M-head baked material is the master material that contains several material functions set up to trigger the different texture maps for specific facial poses. One of the benefits of the way this is all set up is that you can use the existing blood flow and normal wrinkle maps as a base for customizing your own textures, and then easily"},{"start":"5:00","end":"5:30","startSec":300.0,"text":"replace the existing ones with yours in the head synthesized material instance. The rig logic node lives in the face post-process animation blueprint. If the blueprint is disabled, it will only trigger joint deformations, resulting in a boost in performance but at the expense of quality. The images on the right are examples of what a smile looks like when the face post-process"},{"start":"5:30","end":"6:00","startSec":330.3,"text":"is enabled and disabled. With complex expressions, some joints are affected by more than one expression, resulting in multiplied deformations. Corrective blend shapes on the metahuman face have been defined to correct the joint overlap for complex expressions such as the smile. The face post-process blueprint is also where the neck correctives for the head component"},{"start":"6:00","end":"6:37","startSec":360.9,"text":"are set up. The animated gif all the way on the right shows these at work. When the neck moves, the volume in these areas of deformation are preserved so that it looks natural. When disabled, we will see a boost in performance but at the expense of quality. The body animation blueprint contains corrective poses through a pose driver setup. These trigger specific combinations of poses and joints that correct certain skeleton poses."},{"start":"6:37","end":"7:13","startSec":397.2,"text":"We can see these corrective poses at work in the animated gif on the left. When the upper arm is rotated, the volume is preserved by these corrective poses. Using the pose driver connect tool set in Autodesk Maya, you can author your own corrective poses and import those into Unreal Engine. And we touch on this in the metahuman DNA calibration courses. There are cases where individual body correctives can be adjusted when retargeting animations"},{"start":"7:13","end":"7:44","startSec":433.2,"text":"from skeletons that have different proportions. So let's jump into Unreal Engine for a moment to take a look at this process. Inside of the animation sequence window, I have applied an animation to Lena's skeletal mesh. I'm going to bring the upper arms closer to view so that we can see the changes that will occur once we make some adjustments to the skeleton retargeting options of the correctives."},{"start":"7:44","end":"8:14","startSec":464.1,"text":"In the skeleton tree panel on the left, I'm going to go to the cogwheel and select show retargeting options. For the main joints such as the spines, the upper and lower arms, and so on, I have changed the retargeting options for those to skeleton and left all of the correctives set to animation. If we search for the upper arm in the skeleton tree search bar, the upper arm joints will be displayed."},{"start":"8:14","end":"8:49","startSec":494.8,"text":"This here is one of the many correctives for the left upper arm. And these down here are correctives for the right upper arm. If I select all of the correctives for the left upper arm and right click on them and select recursively set translation retargeting to skeleton, the volume in the upper arm area will be lost. Using this setting is helpful for the main joints when retargeting animations from different"},{"start":"8:49","end":"9:22","startSec":529.1,"text":"skeletons and skeletons of different proportions. Now if I right click and select recursively set translation retargeting to animation, we can see the volume returns. Before we move on, let's do a quick review of the steps we just covered. We just went through an example showing how we can adjust the bone translation retargeting options settings for the body correctives."},{"start":"9:22","end":"9:56","startSec":562.5,"text":"By changing the retargeting options for the main joints to skeleton, this takes differences in skeleton proportions out of the equation so that animations can be applied to different skeletons. Leaving the correctives to animation preserves the volume in areas of deformation regardless of differences in skeleton proportions. To do this, in the skeleton tree, go to the cogwheel and check on show retargeting options."},{"start":"9:56","end":"10:31","startSec":596.2,"text":"From there you can either change the translation retargeting of individual joints, or select a group of joints, then right click and select recursively set to and choose either skeleton, animation, animation scaled and so on. The bone retargeting options are helpful when retargeting and applying animation data from skeletons of different proportions. Now let's move on to the next section of our course where we explore a few different ways"},{"start":"10:31","end":"10:33","startSec":631.6,"text":"we can animate metahumans."}],"07_MHControlRig1":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In this section of our course, we will take a look at the face and body control rig assets and how we can use these for a forward and backward solve. We will also look at how to apply animations with and without sequencer and then go over the body IK retargetor assets and facial animation tools. We can instantly start to animate metahumans with the body and face control rig which become"},{"start":"0:32","end":"1:06","startSec":32.7,"text":"accessible once we add a metahuman into sequencer. Let's jump into Unreal Engine and take a look at the control rig assets. Inside of Unreal Engine, we can locate the body and face control rig assets a few different ways. One way is to select the metahuman in the level. Then in the details panel, we will start by selecting the body component and then opening up the skeletal mesh."},{"start":"1:06","end":"1:36","startSec":66.1,"text":"Inside of the skeletal mesh asset, in the asset details panel, we can scroll all the way down to the default animating rig. This is where the body control rig asset is assigned. When we double click on this, it may take a moment to open. In the viewport, the female medium normal body weight preview mesh will be assigned as this is the shared skeleton."},{"start":"1:36","end":"2:13","startSec":96.3,"text":"In the rig graph, over here, we have the forward solve control rig setup. This is what allows us to create animations by selecting controls that can be adjusted using forward or inverse kinematics. Over here, we have the backwards solve setup, which allows us to bake animations to the control rig and adjust existing animations. Now, let's go back to the main viewport and locate the face control rig the same way."},{"start":"2:13","end":"2:47","startSec":133.4,"text":"With the metahuman still selected in the viewport, we can go to the details panel and select the face component. Let's open up the face skeletal mesh and then locate the default animating rig in the asset details panel. And now let's open this. In the viewport, the face archetype skeleton is assigned as this is shared by all metahumans. This also has a forward and backward solve setup."},{"start":"2:47","end":"3:22","startSec":167.8,"text":"This is where the forward solve is located. You can take some time if you wish to inspect this and see how this is constructed. Over here, this is where the backward solve is located. This has been organized so that we can locate where certain controls have been mapped out. If we move over and zoom in on the jaw controls, we can see the minimum and maximum values"},{"start":"3:22","end":"3:54","startSec":203.0,"text":"they have assigned to them. Now before we continue, let's do a quick review of what we just covered. The body control rig asset located in the common folder is set up with a forward solve and backward solve. It is also set up for controls to be adjusted using forward and inverse kinematics. We can also locate the control rig assets by either going to the common folder or by"},{"start":"3:54","end":"4:25","startSec":234.9,"text":"opening up the skeletal mesh and then inside of the asset details panel, it will be assigned as the default animating rig. The face control rig asset can be found in the common face folder and is also set up to use a forward and backward solve. A forward solve allows you to create animations by moving the controls and setting keys for those controls."},{"start":"4:25","end":"4:57","startSec":265.5,"text":"A backward solve allows you to adjust an existing animation by baking the animation to the control rig. You can then edit the existing animation curves or you can add on top of the existing animation with an additive layer. Let's return back to Unreal Engine and take a look at how we can use the control rigs. We saw in the metahuman introduction class that we can use a forward solve to create"},{"start":"4:57","end":"5:30","startSec":297.5,"text":"an animation. You can choose if you want to use FK or IK for certain controls. To do this, first locate the global control track. If I use this drop down arrow and then scroll down to here, this is where we can switch between FK and IK. We can switch the arms from FK to IK by checking these on. By default, the legs are set to IK."},{"start":"5:30","end":"6:02","startSec":330.0,"text":"There is also a switch for the spine where we can move all three spine controls together and there is a switch for the head and neck. To create an animation using the control rig, select a control. I'm going to change the gizmo to translate and then set a neutral key by pressing the letter S or by setting a key inside of the animation details panel or inside of sequencer"},{"start":"6:02","end":"6:36","startSec":362.8,"text":"over here. Then move a few frames over and move the control. I will set this to rotate and we'll make a few adjustments to the arm IK control. And then I will press S to set a key. You can continue adjusting controls until you are happy with the animation. If you want to export this animation as an animation sequence, you can go to the body"},{"start":"6:36","end":"7:06","startSec":396.5,"text":"component by scrolling all the way up here and then right click on the body component and select bake to animation sequence. Once you select this, you can name your animation. I will name this forward solve and then select a folder you want to direct it to. I will save it in the course topics folder and when you press OK, leave everything at"},{"start":"7:06","end":"7:39","startSec":426.9,"text":"default and then select export to animation sequence. Now we can go to the course topics folder. I will double click on this to open it and I will dock this window up here. Now it will be easier to see our animation by changing the skeletal mesh in this window. Go up here to the top right and in the preview mesh, use the drop down and select this skeletal"},{"start":"7:39","end":"8:13","startSec":459.3,"text":"mesh. With this skeletal mesh assigned, if we scrub through here, we can see the animation we just created using a forward solve. Now before we move on, let's do a quick review of what we just covered. When a metahuman is added to sequencer, the body and face control rigs will appear by default. We can use the body control rig with a forward solve by moving controls and setting keys"},{"start":"8:13","end":"8:45","startSec":493.6,"text":"for them. You can set keys by pressing the letter S or in the animation details panel or in sequencer. The body control rig comes with both forward and inverse kinematics. FK allows you to rotate individual controls by adjusting the pitch, roll and yaw. IK allows you to move a hierarchy of joints and you can adjust the pitch, roll, yaw and"},{"start":"8:45","end":"9:18","startSec":525.7,"text":"also move it in the X, Y and Z location. You can switch between FK and IK in the global control track and there are switches for the arms, legs, spine, neck and head. Just keep in mind, each FK-IK switch is keyable. If you are switching between FK and IK, the FK-IK keys will be disabled in that track if a switch key is not set."},{"start":"9:18","end":"9:22","startSec":558.7,"text":"Now let's continue by taking a look at the face control rig."}],"07_MHControlRig1_55":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In this section of our course, we will take a look at the face and body control rig assets and how we can use these for a forward and backward solve. We will also look at how to apply animations with and without sequencer and then go over the body IK retargetor assets and facial animation tools. We can instantly start to animate metahumans with the body and face control rig which become"},{"start":"0:32","end":"1:06","startSec":32.7,"text":"accessible once we add a metahuman into sequencer. Let's jump into Unreal Engine and take a look at the control rig assets. Inside of Unreal Engine, we can locate the body and face control rig assets a few different ways. One way is to select the metahuman in the level. Then in the details panel, we will start by selecting the body component and then opening up the skeletal mesh."},{"start":"1:06","end":"1:36","startSec":66.1,"text":"Inside of the skeletal mesh asset, in the asset details panel, we can scroll all the way down to the default animating rig. This is where the body control rig asset is assigned. When we double click on this, it may take a moment to open. In the viewport, the female medium normal body weight preview mesh will be assigned as this is the shared skeleton."},{"start":"1:36","end":"2:13","startSec":96.3,"text":"In the rig graph, over here, we have the forward solve control rig setup. This is what allows us to create animations by selecting controls that can be adjusted using forward or inverse kinematics. Over here, we have the backwards solve setup, which allows us to bake animations to the control rig and adjust existing animations. Now, let's go back to the main viewport and locate the face control rig the same way."},{"start":"2:13","end":"2:47","startSec":133.4,"text":"With the metahuman still selected in the viewport, we can go to the details panel and select the face component. Let's open up the face skeletal mesh and then locate the default animating rig in the asset details panel. And now let's open this. In the viewport, the face archetype skeleton is assigned as this is shared by all metahumans. This also has a forward and backward solve setup."},{"start":"2:47","end":"3:22","startSec":167.8,"text":"This is where the forward solve is located. You can take some time if you wish to inspect this and see how this is constructed. Over here, this is where the backward solve is located. This has been organized so that we can locate where certain controls have been mapped out. If we move over and zoom in on the jaw controls, we can see the minimum and maximum values"},{"start":"3:22","end":"3:54","startSec":203.0,"text":"they have assigned to them. Now before we continue, let's do a quick review of what we just covered. The body control rig asset located in the common folder is set up with a forward solve and backward solve. It is also set up for controls to be adjusted using forward and inverse kinematics. We can also locate the control rig assets by either going to the common folder or by"},{"start":"3:54","end":"4:25","startSec":234.9,"text":"opening up the skeletal mesh and then inside of the asset details panel, it will be assigned as the default animating rig. The face control rig asset can be found in the common face folder and is also set up to use a forward and backward solve. A forward solve allows you to create animations by moving the controls and setting keys for those controls."},{"start":"4:25","end":"4:57","startSec":265.5,"text":"A backward solve allows you to adjust an existing animation by baking the animation to the control rig. You can then edit the existing animation curves or you can add on top of the existing animation with an additive layer. Let's return back to Unreal Engine and take a look at how we can use the control rigs. We saw in the metahuman introduction class that we can use a forward solve to create"},{"start":"4:57","end":"5:30","startSec":297.5,"text":"an animation. You can choose if you want to use FK or IK for certain controls. To do this, first locate the global control track. If I use this drop down arrow and then scroll down to here, this is where we can switch between FK and IK. We can switch the arms from FK to IK by checking these on. By default, the legs are set to IK."},{"start":"5:30","end":"6:02","startSec":330.0,"text":"There is also a switch for the spine where we can move all three spine controls together and there is a switch for the head and neck. To create an animation using the control rig, select a control. I'm going to change the gizmo to translate and then set a neutral key by pressing the letter S or by setting a key inside of the animation details panel or inside of sequencer"},{"start":"6:02","end":"6:36","startSec":362.8,"text":"over here. Then move a few frames over and move the control. I will set this to rotate and we'll make a few adjustments to the arm IK control. And then I will press S to set a key. You can continue adjusting controls until you are happy with the animation. If you want to export this animation as an animation sequence, you can go to the body"},{"start":"6:36","end":"7:06","startSec":396.5,"text":"component by scrolling all the way up here and then right click on the body component and select bake to animation sequence. Once you select this, you can name your animation. I will name this forward solve and then select a folder you want to direct it to. I will save it in the course topics folder and when you press OK, leave everything at"},{"start":"7:06","end":"7:39","startSec":426.9,"text":"default and then select export to animation sequence. Now we can go to the course topics folder. I will double click on this to open it and I will dock this window up here. Now it will be easier to see our animation by changing the skeletal mesh in this window. Go up here to the top right and in the preview mesh, use the drop down and select this skeletal"},{"start":"7:39","end":"8:13","startSec":459.3,"text":"mesh. With this skeletal mesh assigned, if we scrub through here, we can see the animation we just created using a forward solve. Now before we move on, let's do a quick review of what we just covered. When a metahuman is added to sequencer, the body and face control rigs will appear by default. We can use the body control rig with a forward solve by moving controls and setting keys"},{"start":"8:13","end":"8:45","startSec":493.6,"text":"for them. You can set keys by pressing the letter S or in the animation details panel or in sequencer. The body control rig comes with both forward and inverse kinematics. FK allows you to rotate individual controls by adjusting the pitch, roll and yaw. IK allows you to move a hierarchy of joints and you can adjust the pitch, roll, yaw and"},{"start":"8:45","end":"9:18","startSec":525.7,"text":"also move it in the X, Y and Z location. You can switch between FK and IK in the global control track and there are switches for the arms, legs, spine, neck and head. Just keep in mind, each FK-IK switch is keyable. If you are switching between FK and IK, the FK-IK keys will be disabled in that track if a switch key is not set."},{"start":"9:18","end":"9:22","startSec":558.7,"text":"Now let's continue by taking a look at the face control rig."}],"08_MHControlRig2":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"In this section, we continue by taking a look at how we can use the face control rig with the face pose library to create animations using a forward solve, and then we will go over how we can adjust an existing animation with the face control rig using a backward solve. So, let's jump into Unreal Engine and begin exploring the face control rig. When using the face control rig, make sure that the gizmo is set to translate and is"},{"start":"0:34","end":"1:11","startSec":34.6,"text":"in local space and snapping is turned off. Since the face board has over 200 controls, one way to quickly pose the face is to use the face pose library. To do this, in the animation panel, select poses. The pose library is located in the metahumans common folder, so in order to add that in here, right click over here and select add existing folder to view."},{"start":"1:11","end":"1:44","startSec":71.5,"text":"I have already added the metahumans folder in here. Now, I will open up the metahumans folder, then open up the common folder, then open up the second common folder, then open up the pose library folder, and select the face folder. Inside of here, we can select from a variety of expressions and visims. If I open up the expressions folder, inside of here, we can choose a face pose we want"},{"start":"1:44","end":"2:18","startSec":104.2,"text":"to add. I will double click on this pose. Right below, I will click on select controls. Then with key checked on, I will select paste the pose. That pose will be keyframed in sequencer. We can move a few frames over and select another pose. Double click on another pose, and since select controls is still enabled, we can select paste"},{"start":"2:18","end":"2:50","startSec":138.5,"text":"the pose. And this is how we can use the face pose library to quickly pose and create animations using a forward solve. Now before we move on, let's do a quick review of what we just covered. When using the face control rig, you may find it helpful to also go through all of the face controls in order to learn what each control does."},{"start":"2:50","end":"3:21","startSec":170.1,"text":"For a detailed breakdown on each of the face controls, you can reference the facial description standard portion of the metahuman documentation, and that is linked in the resources portion of this course. Now let's jump back into Unreal Engine and go over how we can use the metahuman control rigs for a backward solve. Now let's use a backward solve."},{"start":"3:21","end":"3:53","startSec":201.1,"text":"First we need to delete the face control rig. Now I will add an animation track by going to the plus sign on the face component, and then go to animation and select the mh face animation sequence. This is 644 frames. Next I will change the sequencer length by going down here, and I will enter 644."},{"start":"3:53","end":"4:23","startSec":233.1,"text":"I will now use the end bracket to change the length of the sequence, and now I will go to the start of the sequence and play this. Now there may be some areas of this animation that you may want to adjust. In this case you can use a backward solve by baking the animation curves to the control rig. To do this I will go to the start of the sequence, I will right click on the face component,"},{"start":"4:23","end":"4:57","startSec":263.3,"text":"and then select bake to control rig, and select the face control rig. I will leave everything at default, and select create. Depending on the length of the animation this may take a moment. Once this process completes, we can see that this animation has been baked to the face control rig. Now we can either adjust the existing keys of this animation using the curve editor,"},{"start":"4:57","end":"5:33","startSec":298.0,"text":"or we can add on top of this animation using an additive backward solve. To add on top of this existing animation, let's go to the start of the sequence, and then go to the plus sign on the control rig track, and select additive. Now to create an offset, I will select the brow lateral control, then hold down shift and select the other brow lateral control, and then select the brow down controls."},{"start":"5:33","end":"6:07","startSec":333.3,"text":"Now if I move these controls and set a key by pressing the letter S, this offset will remain throughout the entire animation. Another thing we can do is add animations to specific sections. If I scrub through this animation, and decide that at this section, when the character is smiling, I want to adjust the cheek raise controls only when the smile is occurring."},{"start":"6:07","end":"6:45","startSec":367.4,"text":"I can select the cheek raise controls over here, and I will scrub back to the section right before the smile occurs. Here I will create a neutral key by pressing the letter S. Now I will go back to the section where the smile is occurring, and use the slider to move the controls, and set a key. I will now move a few frames over, and use the slider to decrease the cheek control values,"},{"start":"6:45","end":"7:17","startSec":405.7,"text":"and set another key. And this is how we can use an additive backward solve to either create an offset, or edit specific areas of an animation by adding on top of it. To export this as a new animation sequence, I will go all the way back to the top of a And then I will right click on the face component, and select Bake Animation Sequence."},{"start":"7:17","end":"7:47","startSec":437.8,"text":"Now, before we move on, let's do a quick review of what we just covered. We have just taken a look at how we can edit an existing animation using a backward solve with the face control rig. For a backward solve, we first have to delete the default control rigs from Sequencer, and then assign an animation to either the face or body component."},{"start":"7:47","end":"8:19","startSec":467.9,"text":"Then right click on the face or body component, and select Bake to control rig. From there, you can either use the curve editor to make adjustments to the animation curves, or use an additive layer to add on top of an existing animation. To create a new animation sequence with all of the changes that you've made, right click on the face or body component, and select Bake to animation sequence."},{"start":"8:19","end":"8:30","startSec":499.9,"text":"Now that we have seen what we can achieve with the metahuman control rigs, let's move on to different ways we can apply animations to our metahuman characters."}],"08_MHControlRig2_55":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"In this section, we continue by taking a look at how we can use the face control rig with the face pose library to create animations using a forward solve, and then we will go over how we can adjust an existing animation with the face control rig using a backward solve. So, let's jump into Unreal Engine and begin exploring the face control rig. When using the face control rig, make sure that the gizmo is set to translate and is"},{"start":"0:34","end":"1:11","startSec":34.6,"text":"in local space and snapping is turned off. Since the face board has over 200 controls, one way to quickly pose the face is to use the face pose library. To do this, in the animation panel, select poses. The pose library is located in the metahumans common folder, so in order to add that in here, right click over here and select add existing folder to view."},{"start":"1:11","end":"1:44","startSec":71.5,"text":"I have already added the metahumans folder in here. Now, I will open up the metahumans folder, then open up the common folder, then open up the second common folder, then open up the pose library folder, and select the face folder. Inside of here, we can select from a variety of expressions and visims. If I open up the expressions folder, inside of here, we can choose a face pose we want"},{"start":"1:44","end":"2:18","startSec":104.2,"text":"to add. I will double click on this pose. Right below, I will click on select controls. Then with key checked on, I will select paste the pose. That pose will be keyframed in sequencer. We can move a few frames over and select another pose. Double click on another pose, and since select controls is still enabled, we can select paste"},{"start":"2:18","end":"2:50","startSec":138.5,"text":"the pose. And this is how we can use the face pose library to quickly pose and create animations using a forward solve. Now before we move on, let's do a quick review of what we just covered. When using the face control rig, you may find it helpful to also go through all of the face controls in order to learn what each control does."},{"start":"2:50","end":"3:21","startSec":170.1,"text":"For a detailed breakdown on each of the face controls, you can reference the facial description standard portion of the metahuman documentation, and that is linked in the resources portion of this course. Now let's jump back into Unreal Engine and go over how we can use the metahuman control rigs for a backward solve. Now let's use a backward solve."},{"start":"3:21","end":"3:53","startSec":201.1,"text":"First we need to delete the face control rig. Now I will add an animation track by going to the plus sign on the face component, and then go to animation and select the mh face animation sequence. This is 644 frames. Next I will change the sequencer length by going down here, and I will enter 644."},{"start":"3:53","end":"4:23","startSec":233.1,"text":"I will now use the end bracket to change the length of the sequence, and now I will go to the start of the sequence and play this. Now there may be some areas of this animation that you may want to adjust. In this case you can use a backward solve by baking the animation curves to the control rig. To do this I will go to the start of the sequence, I will right click on the face component,"},{"start":"4:23","end":"4:57","startSec":263.3,"text":"and then select bake to control rig, and select the face control rig. I will leave everything at default, and select create. Depending on the length of the animation this may take a moment. Once this process completes, we can see that this animation has been baked to the face control rig. Now we can either adjust the existing keys of this animation using the curve editor,"},{"start":"4:57","end":"5:33","startSec":298.0,"text":"or we can add on top of this animation using an additive backward solve. To add on top of this existing animation, let's go to the start of the sequence, and then go to the plus sign on the control rig track, and select additive. Now to create an offset, I will select the brow lateral control, then hold down shift and select the other brow lateral control, and then select the brow down controls."},{"start":"5:33","end":"6:07","startSec":333.3,"text":"Now if I move these controls and set a key by pressing the letter S, this offset will remain throughout the entire animation. Another thing we can do is add animations to specific sections. If I scrub through this animation, and decide that at this section, when the character is smiling, I want to adjust the cheek raise controls only when the smile is occurring."},{"start":"6:07","end":"6:45","startSec":367.4,"text":"I can select the cheek raise controls over here, and I will scrub back to the section right before the smile occurs. Here I will create a neutral key by pressing the letter S. Now I will go back to the section where the smile is occurring, and use the slider to move the controls, and set a key. I will now move a few frames over, and use the slider to decrease the cheek control values,"},{"start":"6:45","end":"7:17","startSec":405.7,"text":"and set another key. And this is how we can use an additive backward solve to either create an offset, or edit specific areas of an animation by adding on top of it. To export this as a new animation sequence, I will go all the way back to the top of a And then I will right click on the face component, and select Bake Animation Sequence."},{"start":"7:17","end":"7:47","startSec":437.8,"text":"Now, before we move on, let's do a quick review of what we just covered. We have just taken a look at how we can edit an existing animation using a backward solve with the face control rig. For a backward solve, we first have to delete the default control rigs from Sequencer, and then assign an animation to either the face or body component."},{"start":"7:47","end":"8:19","startSec":467.9,"text":"Then right click on the face or body component, and select Bake to control rig. From there, you can either use the curve editor to make adjustments to the animation curves, or use an additive layer to add on top of an existing animation. To create a new animation sequence with all of the changes that you've made, right click on the face or body component, and select Bake to animation sequence."},{"start":"8:19","end":"8:30","startSec":499.9,"text":"Now that we have seen what we can achieve with the metahuman control rigs, let's move on to different ways we can apply animations to our metahuman characters."}],"09_ApplyingAnimation":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Let's begin by going over how we can apply animations to metahumans with and without sequencer. Then we will take a look at the bodyik retargetor assets and facial animation tools that are already set up to work with metahumans. We previously saw how we can apply existing body and facial animations to our metahumans in sequencer. Once added to a level sequence, we delete the default control rigs, then use the plus"},{"start":"0:34","end":"1:08","startSec":35.0,"text":"sign on either the face or body component to add an animation track. There may be cases where you want to quickly visualize a body or face animation without opening up a level sequence. So let's jump into Unreal Engine for a moment and see how we can apply an animation to a metahuman without using sequencer. In Unreal Engine, with our metahuman selected in the level, if we go to the details panel,"},{"start":"1:08","end":"1:40","startSec":68.5,"text":"we can select if we want to apply an animation to the body or face component by simply selecting that component. Right below in the animation setting, we can change the animation mode from use animation blueprint to use animation asset. And over here, we can apply an animation sequence to the body. I will search for mh body animation and select it."},{"start":"1:40","end":"2:12","startSec":100.4,"text":"To see the animation play from this camera position, we can go up here to the play and editor options and select simulate. Our animation will start to play in the viewport. And this will allow us to quickly visualize a body animation on our metahuman without using sequencer. I'm going to press stop and select the metahuman again and go back to the body component and"},{"start":"2:12","end":"2:47","startSec":132.2,"text":"I will clear the animation asset from here. And then reset the animation mode back to use animation blueprint. Now let's review the steps we just covered before moving on. We can apply animation sequences to either the body or face component by changing the animation mode to use animation asset. With this setting, we can select any animation we want to apply to a metahuman."},{"start":"2:47","end":"3:25","startSec":167.8,"text":"Then we can change the play and editor setting to simulate and view the animation in the viewport without having to open up sequencer. Just remember when you are done to clear the animation sequence and reset the animation mode. Now let's return to Unreal Engine and take a look at the body ik retargetor assets we can use with metahumans. In Unreal Engine, to locate the ik retargetor assets, inside of the metahumans folder, go"},{"start":"3:25","end":"3:56","startSec":205.4,"text":"to the common folder, then to the other common folder, then inside of the animation folder is the retargeting folder. Here we will find retargeting assets. Over here we have an ikrig asset for each of the metahuman body proportions that we have brought into this project. If I open this up, we can see on the right that all of the joints have been mapped out as chains."},{"start":"3:56","end":"4:29","startSec":236.0,"text":"So for example, spine 1 to spine 5 makes up the spine chain. Now let's go back and open up the ik retargetor asset. Inside of here we have a source and a target. Our source has the existing animation curves we want to transfer to our character which is the target. On the bottom right we can see the animation curves are transferred from the source to"},{"start":"4:29","end":"4:59","startSec":269.3,"text":"the target by matching the bone chains. We can do a lot more things with the ikrig and retargetor assets. Let's go back and look for the animation blueprint retargetor asset and then open this up. In the animation graph, if we select the retarget post from mesh node, in the details panel we can see the ikretargetor asset is assigned."},{"start":"4:59","end":"5:34","startSec":299.7,"text":"This allows us to stream in live motion capture data and transfer source data to our target while using the ikretargetor tools to make adjustments in real time. Let's do a quick review before we move on. Animations can be animated using real time or offline animation retargeting workflows. Retargeting involves transferring animation curves from one skeleton to another."},{"start":"5:34","end":"6:06","startSec":334.6,"text":"Unreal Engine 5 uses ikrigs and ikretargetor setups which involve mapping out joints to bone chains and then transferring animation curves from the source to a target by matching the bone chains. Meta humans are also set up to work with facial animation tools. Facial animation tools that meta humans can be used with include LiveLink face, Meta"},{"start":"6:06","end":"6:37","startSec":366.5,"text":"Human Animator and Audio Driven Animation. LiveLink face is a real time facial animation tool allowing you to bring your meta human to life instantly in Unreal Engine and uses up to 52 ARKit control curves. Meta Human Animator is an offline facial animation tool using over 200 control curves to produce high quality facial animation data by utilizing depth footage from an iPhone"},{"start":"6:37","end":"7:08","startSec":397.0,"text":"or vertical stereo HMC. Audio driven animation allows you to process audio in order to produce realistic facial animations and all of these tools are available to use for free with your Epic Games account. It is worth mentioning that because Meta humans use a shared skeleton for the body and for the face you can easily transfer animations from one project to another or from older"},{"start":"7:08","end":"7:43","startSec":428.3,"text":"engine versions to new ones. Let's jump into Unreal Engine and take a look at this process. In the source files folder of this course there is a body animation sequence UAssetFile. If you wish to transfer Meta Human Animation Sequences from one project to another or from older engine versions to newer ones, in File Explorer copy the UAssetFile you wish to transfer."},{"start":"7:43","end":"8:19","startSec":463.3,"text":"Then select a folder you wish to add it to by right clicking on that folder and selecting Show in Explorer. Then paste it in the desired File Explorer folder of your Unreal Engine project. The animation sequence asset will appear in your project. Now let's review the steps we just completed. We have just seen how we can easily add Meta Human Animation Sequence UAssetFiles to Unreal"},{"start":"8:19","end":"8:52","startSec":499.5,"text":"Engine projects. Simply copy the animation sequence UAssetFile from File Explorer then inside of your Unreal Engine project select any folder you wish to add it to and right click on that folder and select Show in Explorer. Then paste the UAssetFile into the File Explorer folder of your Unreal Engine project. Since there have been changes to the Meta Human Skeletons in newer versions of Unreal"},{"start":"8:52","end":"9:22","startSec":532.6,"text":"Engine you may be prompted to assign this newly added animation sequence to the face archetype for facial animations and the Meta Human Base Skeleton for the body animations. Now that we have touched on some of the ways we can apply animations to Meta Humans let's move on to the next section of this course where we explore the optimized Meta Humans that we can download from Quixel Bridge."}],"09_ApplyingAnimation_55":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Let's begin by going over how we can apply animations to metahumans with and without sequencer. Then we will take a look at the bodyik retargetor assets and facial animation tools that are already set up to work with metahumans. We previously saw how we can apply existing body and facial animations to our metahumans in sequencer. Once added to a level sequence, we delete the default control rigs, then use the plus"},{"start":"0:34","end":"1:08","startSec":35.0,"text":"sign on either the face or body component to add an animation track. There may be cases where you want to quickly visualize a body or face animation without opening up a level sequence. So let's jump into Unreal Engine for a moment and see how we can apply an animation to a metahuman without using sequencer. In Unreal Engine, with our metahuman selected in the level, if we go to the details panel,"},{"start":"1:08","end":"1:40","startSec":68.5,"text":"we can select if we want to apply an animation to the body or face component by simply selecting that component. Right below in the animation setting, we can change the animation mode from use animation blueprint to use animation asset. And over here, we can apply an animation sequence to the body. I will search for mh body animation and select it."},{"start":"1:40","end":"2:12","startSec":100.4,"text":"To see the animation play from this camera position, we can go up here to the play and editor options and select simulate. Our animation will start to play in the viewport. And this will allow us to quickly visualize a body animation on our metahuman without using sequencer. I'm going to press stop and select the metahuman again and go back to the body component and"},{"start":"2:12","end":"2:47","startSec":132.2,"text":"I will clear the animation asset from here. And then reset the animation mode back to use animation blueprint. Now let's review the steps we just covered before moving on. We can apply animation sequences to either the body or face component by changing the animation mode to use animation asset. With this setting, we can select any animation we want to apply to a metahuman."},{"start":"2:47","end":"3:25","startSec":167.8,"text":"Then we can change the play and editor setting to simulate and view the animation in the viewport without having to open up sequencer. Just remember when you are done to clear the animation sequence and reset the animation mode. Now let's return to Unreal Engine and take a look at the body ik retargetor assets we can use with metahumans. In Unreal Engine, to locate the ik retargetor assets, inside of the metahumans folder, go"},{"start":"3:25","end":"3:56","startSec":205.4,"text":"to the common folder, then to the other common folder, then inside of the animation folder is the retargeting folder. Here we will find retargeting assets. Over here we have an ikrig asset for each of the metahuman body proportions that we have brought into this project. If I open this up, we can see on the right that all of the joints have been mapped out as chains."},{"start":"3:56","end":"4:29","startSec":236.0,"text":"So for example, spine 1 to spine 5 makes up the spine chain. Now let's go back and open up the ik retargetor asset. Inside of here we have a source and a target. Our source has the existing animation curves we want to transfer to our character which is the target. On the bottom right we can see the animation curves are transferred from the source to"},{"start":"4:29","end":"4:59","startSec":269.3,"text":"the target by matching the bone chains. We can do a lot more things with the ikrig and retargetor assets. Let's go back and look for the animation blueprint retargetor asset and then open this up. In the animation graph, if we select the retarget post from mesh node, in the details panel we can see the ikretargetor asset is assigned."},{"start":"4:59","end":"5:34","startSec":299.7,"text":"This allows us to stream in live motion capture data and transfer source data to our target while using the ikretargetor tools to make adjustments in real time. Let's do a quick review before we move on. Animations can be animated using real time or offline animation retargeting workflows. Retargeting involves transferring animation curves from one skeleton to another."},{"start":"5:34","end":"6:06","startSec":334.6,"text":"Unreal Engine 5 uses ikrigs and ikretargetor setups which involve mapping out joints to bone chains and then transferring animation curves from the source to a target by matching the bone chains. Meta humans are also set up to work with facial animation tools. Facial animation tools that meta humans can be used with include LiveLink face, Meta"},{"start":"6:06","end":"6:37","startSec":366.5,"text":"Human Animator and Audio Driven Animation. LiveLink face is a real time facial animation tool allowing you to bring your meta human to life instantly in Unreal Engine and uses up to 52 ARKit control curves. Meta Human Animator is an offline facial animation tool using over 200 control curves to produce high quality facial animation data by utilizing depth footage from an iPhone"},{"start":"6:37","end":"7:08","startSec":397.0,"text":"or vertical stereo HMC. Audio driven animation allows you to process audio in order to produce realistic facial animations and all of these tools are available to use for free with your Epic Games account. It is worth mentioning that because Meta humans use a shared skeleton for the body and for the face you can easily transfer animations from one project to another or from older"},{"start":"7:08","end":"7:43","startSec":428.3,"text":"engine versions to new ones. Let's jump into Unreal Engine and take a look at this process. In the source files folder of this course there is a body animation sequence UAssetFile. If you wish to transfer Meta Human Animation Sequences from one project to another or from older engine versions to newer ones, in File Explorer copy the UAssetFile you wish to transfer."},{"start":"7:43","end":"8:19","startSec":463.3,"text":"Then select a folder you wish to add it to by right clicking on that folder and selecting Show in Explorer. Then paste it in the desired File Explorer folder of your Unreal Engine project. The animation sequence asset will appear in your project. Now let's review the steps we just completed. We have just seen how we can easily add Meta Human Animation Sequence UAssetFiles to Unreal"},{"start":"8:19","end":"8:52","startSec":499.5,"text":"Engine projects. Simply copy the animation sequence UAssetFile from File Explorer then inside of your Unreal Engine project select any folder you wish to add it to and right click on that folder and select Show in Explorer. Then paste the UAssetFile into the File Explorer folder of your Unreal Engine project. Since there have been changes to the Meta Human Skeletons in newer versions of Unreal"},{"start":"8:52","end":"9:22","startSec":532.6,"text":"Engine you may be prompted to assign this newly added animation sequence to the face archetype for facial animations and the Meta Human Base Skeleton for the body animations. Now that we have touched on some of the ways we can apply animations to Meta Humans let's move on to the next section of this course where we explore the optimized Meta Humans that we can download from Quixel Bridge."}],"10_OptimizedMH":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In this section of our course, we are going to take a look at the optimized metahumans. We have the option of downloading from Quixel Bridge. And look at how they differ from the cinematic quality metahumans that we have been looking at up until now. Optimized metahumans are available to download for Unreal Engine versions 5.4 and later. They allow for better performance while offering comparable levels of fidelity to the cinematic"},{"start":"0:32","end":"1:05","startSec":32.8,"text":"ones. You can choose between high, medium, and low optimized. The average file size is under 100 megabytes as opposed to the cinematic ones that range between 2 to 3 gigabytes. They come with compressed textures and optimized materials as opposed to the full resolution textures with separate materials. The harems are also optimized and the LODs have been adjusted with animation settings"},{"start":"1:05","end":"1:39","startSec":65.9,"text":"that enable and disable correctives based on LOD. Now let's jump into Unreal Engine and take a look at these differences. Throughout this course, we have been using the cinematic quality version of this metahuman. In the metahumans folder, we also have a low optimized version of this character. I have opened up the blueprints for both the cinematic and low optimized versions of this"},{"start":"1:39","end":"2:10","startSec":100.0,"text":"character. Going back to the cinematic quality version, let's compare some of the components. With the body components selected, let's open up the skeletal mesh for this metahuman. We will see all of the joints and correctives are present. Now if we go to the low quality version and open up the skeletal mesh, we will notice that this has a simplified version of the skeleton."},{"start":"2:10","end":"2:48","startSec":130.8,"text":"If we toggle between the two skeletons, we will notice that the cinematic quality skeleton has the correctives and the low optimized one does not. Now let's compare the face components of these two. If we select the face component on the cinematic quality version and then open up the skeletal mesh, we will see all of the joints and correctives are present. Now if we go to the low optimized version, select the face component and then open up"},{"start":"2:48","end":"3:18","startSec":168.5,"text":"the skeletal mesh, we will notice we have a more simplified skeleton. We can compare the two if we toggle between them. Going back to the cinematic quality blueprint, we will also see all of the material instances this has for the face. If we compare this with the low optimized version, we can see this only has four simplified material instances."},{"start":"3:18","end":"3:53","startSec":198.9,"text":"Now going back to the cinematic version, if we select the metahuman component, we will see that we have physics for the clothing and can choose if we want to disable correctives. If we compare this with the low optimized version by selecting the metahuman component, we will see that there is no physics for the clothing and the correctives are disabled by default. Now going back to the cinematic version, if we select the lod sync component, we have"},{"start":"3:53","end":"4:29","startSec":233.5,"text":"eight lod's. If we compare this with the low optimized version by selecting the lod sync component, we will see that this has only two lod's. Now before we move on, let's do a quick review of what we just covered. When comparing the face and body skeletons of the optimized and cinematic metahumans, the optimized ones will have reduced bone count and may not have any correctives for"},{"start":"4:29","end":"4:51","startSec":269.3,"text":"the neck and body. Optimized metahumans have been specifically tailored with performance in mind, especially when working in games, mobile or with real time experiences. Now let's begin to wrap up this course with some final recommendations."}],"10_OptimizedMH_55":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In this section of our course, we are going to take a look at the optimized metahumans. We have the option of downloading from Quixel Bridge. And look at how they differ from the cinematic quality metahumans that we have been looking at up until now. Optimized metahumans are available to download for Unreal Engine versions 5.4 and later. They allow for better performance while offering comparable levels of fidelity to the cinematic"},{"start":"0:32","end":"1:05","startSec":32.8,"text":"ones. You can choose between high, medium, and low optimized. The average file size is under 100 megabytes as opposed to the cinematic ones that range between 2 to 3 gigabytes. They come with compressed textures and optimized materials as opposed to the full resolution textures with separate materials. The harems are also optimized and the LODs have been adjusted with animation settings"},{"start":"1:05","end":"1:39","startSec":65.9,"text":"that enable and disable correctives based on LOD. Now let's jump into Unreal Engine and take a look at these differences. Throughout this course, we have been using the cinematic quality version of this metahuman. In the metahumans folder, we also have a low optimized version of this character. I have opened up the blueprints for both the cinematic and low optimized versions of this"},{"start":"1:39","end":"2:10","startSec":100.0,"text":"character. Going back to the cinematic quality version, let's compare some of the components. With the body components selected, let's open up the skeletal mesh for this metahuman. We will see all of the joints and correctives are present. Now if we go to the low quality version and open up the skeletal mesh, we will notice that this has a simplified version of the skeleton."},{"start":"2:10","end":"2:48","startSec":130.8,"text":"If we toggle between the two skeletons, we will notice that the cinematic quality skeleton has the correctives and the low optimized one does not. Now let's compare the face components of these two. If we select the face component on the cinematic quality version and then open up the skeletal mesh, we will see all of the joints and correctives are present. Now if we go to the low optimized version, select the face component and then open up"},{"start":"2:48","end":"3:18","startSec":168.5,"text":"the skeletal mesh, we will notice we have a more simplified skeleton. We can compare the two if we toggle between them. Going back to the cinematic quality blueprint, we will also see all of the material instances this has for the face. If we compare this with the low optimized version, we can see this only has four simplified material instances."},{"start":"3:18","end":"3:53","startSec":198.9,"text":"Now going back to the cinematic version, if we select the metahuman component, we will see that we have physics for the clothing and can choose if we want to disable correctives. If we compare this with the low optimized version by selecting the metahuman component, we will see that there is no physics for the clothing and the correctives are disabled by default. Now going back to the cinematic version, if we select the lod sync component, we have"},{"start":"3:53","end":"4:29","startSec":233.5,"text":"eight lod's. If we compare this with the low optimized version by selecting the lod sync component, we will see that this has only two lod's. Now before we move on, let's do a quick review of what we just covered. When comparing the face and body skeletons of the optimized and cinematic metahumans, the optimized ones will have reduced bone count and may not have any correctives for"},{"start":"4:29","end":"4:51","startSec":269.3,"text":"the neck and body. Optimized metahumans have been specifically tailored with performance in mind, especially when working in games, mobile or with real time experiences. Now let's begin to wrap up this course with some final recommendations."}],"11_FinalTipsComponent":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"In this section of our course, I will share some final recommendations, providing tips and resources for you to use as you continue your training with MetaHumans. We will look at ways we can approach making adjustments to MetaHuman components and how we can make adjustments to our project render settings and environment when working with MetaHumans in a level. As we have seen throughout this course, we can make a variety of customizations to MetaHuman"},{"start":"0:33","end":"1:08","startSec":34.0,"text":"components, their properties and assets. Let's jump into Unreal Engine and take a look at a few simple adjustments we can make when working with MetaHumans in a project. Inside of Unreal Engine, let's begin making adjustments to MetaHuman components by first going to our course topics folder and open the folder named Final Output. Here we will find a cinematic sequence that contains various cameras along with a body"},{"start":"1:08","end":"1:40","startSec":68.2,"text":"and facial animation. I am going to double click on this to open it and now I will play the sequence. To view this from the different cameras, click here on the Camera Cuts track. Now I want to pause the sequence right here. If for example we would like to make adjustments to the roughness of the skin, we can do this inside of the skin material instance. Let's select our MetaHuman in the viewport."},{"start":"1:40","end":"2:11","startSec":100.4,"text":"Then in the Details panel, select the face component and then go here and double click on this. To open up the material instance, I will double click on this. Inside of here we have several parameters we can adjust. For example, the artist delights allow us to control the makeup properties. To adjust the roughness, I will scroll all the way down here and open up the roughness"},{"start":"2:11","end":"2:43","startSec":131.2,"text":"parameters. We can adjust the minimum and maximum roughness values and this will affect the roughness on the entire face. Another thing we can do is uncheck Baked Roughness Modulation over here. This will unlock all of these parameters allowing us to control the roughness in specific areas of the face. If for instance we would like to reduce the roughness in the cheeks, we can lower the"},{"start":"2:43","end":"3:18","startSec":163.9,"text":"value of the cheek front multiplier to something like .8. We can do the same to the nose. Here we can change the nose multiplier to something like .7. The face material instance gives us control over even the finest detail. Now let's close these and continue playing the sequence. When we get to the section of the sequence where we can see the teeth, I will press pause."},{"start":"3:18","end":"3:55","startSec":198.8,"text":"Here we may want to adjust the way the teeth and light are interacting and we can do this with the subsurface profile of the teeth. I'm going to select the MetaHuman Blueprint in the viewport. And in the details panel, select the face component. Over here we can open up the teeth material instance. The teeth material instance allows us to control things such as the base color of the teeth and gums and we can also fine tune things such as the teeth and gum roughness."},{"start":"3:55","end":"4:31","startSec":235.9,"text":"Another thing we can do is go down here to the material property overrides and adjust the subsurface profile. By default this will be disabled but I have already enabled this by checking this on. If we open this up, inside of here we can control the way light scatters as it passes through semi-translucent surfaces such as the teeth and gums. For example, the Mean Free Path Color controls how far light goes into the subsurface of"},{"start":"4:31","end":"5:02","startSec":271.9,"text":"the red, green and blue channel. If we change the red to something like 0.19 we can see that the teeth and gums become more translucent. The Mean Free Path Distance controls the distance that the Mean Free Path Color goes into subsurface. So for instance if we change the value to something like 0.19 we can see that the teeth and gums become even more translucent."},{"start":"5:02","end":"5:32","startSec":302.9,"text":"Let's close these and continue. I will continue playing the sequence. When we get to this section here perhaps we want to change the color of the hair. To do this I will select the metahuman, then go to the Details panel and select the Hair component. I will go here and open up the Hair Material instance."},{"start":"5:32","end":"6:04","startSec":333.0,"text":"Here we have a variety of parameters we can adjust. For example we can adjust the Hair Melanin parameter. If I change this value to something like 0.5 we can see the hair color changes. We can also adjust the roughness and control the way hair and light interact. Depending on the hairstyle we can also control properties such as the highlights and ombre."},{"start":"6:04","end":"6:38","startSec":364.1,"text":"These are a few simple adjustments we can make just through the material instances of the metahuman components. Now before we move on let's review what we just covered. Something to note is that many of the selections we have made in the metahuman creator to things such as the color of the eyes, the hair and some of the skin details can also be modified in engine with the component material instances."},{"start":"6:38","end":"7:14","startSec":398.2,"text":"We have control over even the finest details such as the roughness for specific areas of the face by unchecking the baked roughness modulation setting. We can also control how light scatters as it passes through translucent and semi-translucent surfaces such as the teeth, skin and eyes with the subsurface profile located in the material property overrides of these material instances."},{"start":"7:14","end":"7:49","startSec":434.7,"text":"We can use the hair material instance to fine tune the appearance of the hair and adjust things such as color, ombre and highlights. We can also control the way hair reflections and lighting interact by adjusting the roughness parameters. Now there may be cases where we want to make adjustments to a metahuman blueprint while preserving the original version. An easy way we can approach this is to make adjustments to a child blueprint of a metahuman."},{"start":"7:49","end":"8:21","startSec":470.0,"text":"Let's jump back into Unreal Engine and go over this. Inside of Unreal Engine with the folder of the metahuman we wish to adjust already opened, select the blueprint and then right click on it. Then select create child blueprint class. Now we can make adjustments to this child metahuman blueprint and those changes will not affect the original one."},{"start":"8:21","end":"8:55","startSec":501.5,"text":"You can open up this child blueprint and make changes such as switch the groom component asset with a different hairstyle, assign a different animation blueprint to the face or body or even do something as simple as forcing the LOD to something like 3. Now if we go back to our main viewport and drop this into a level we can see the changes we made are only applied to the child blueprint of this metahuman."},{"start":"8:55","end":"9:32","startSec":535.4,"text":"For certain shared assets such as materials those assets will have to be duplicated and a copy can be assigned and then adjusted otherwise those types of adjustments will affect the original blueprint. Let's review what we've just covered before we move on. We have just touched upon how we can approach making changes to a copy of an existing metahuman blueprint without those changes affecting the original by using a child blueprint."},{"start":"9:32","end":"10:09","startSec":572.9,"text":"To create a child blueprint simply right click on the metahuman blueprint and select create child blueprint class. From there you can change things such as forcing the LOD to something specific, switching out the hair grooms or assigning a different animation blueprint to one of the skeletal mesh components with the exception of shared assets such as materials. Now let's move on to the next section of this course."}],"11_FinalTipsComponent_55":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"In this section of our course, I will share some final recommendations, providing tips and resources for you to use as you continue your training with MetaHumans. We will look at ways we can approach making adjustments to MetaHuman components and how we can make adjustments to our project render settings and environment when working with MetaHumans in a level. As we have seen throughout this course, we can make a variety of customizations to MetaHuman"},{"start":"0:33","end":"1:08","startSec":34.0,"text":"components, their properties and assets. Let's jump into Unreal Engine and take a look at a few simple adjustments we can make when working with MetaHumans in a project. Inside of Unreal Engine, let's begin making adjustments to MetaHuman components by first going to our course topics folder and open the folder named Final Output. Here we will find a cinematic sequence that contains various cameras along with a body"},{"start":"1:08","end":"1:40","startSec":68.2,"text":"and facial animation. I am going to double click on this to open it and now I will play the sequence. To view this from the different cameras, click here on the Camera Cuts track. Now I want to pause the sequence right here. If for example we would like to make adjustments to the roughness of the skin, we can do this inside of the skin material instance. Let's select our MetaHuman in the viewport."},{"start":"1:40","end":"2:11","startSec":100.4,"text":"Then in the Details panel, select the face component and then go here and double click on this. To open up the material instance, I will double click on this. Inside of here we have several parameters we can adjust. For example, the artist delights allow us to control the makeup properties. To adjust the roughness, I will scroll all the way down here and open up the roughness"},{"start":"2:11","end":"2:43","startSec":131.2,"text":"parameters. We can adjust the minimum and maximum roughness values and this will affect the roughness on the entire face. Another thing we can do is uncheck Baked Roughness Modulation over here. This will unlock all of these parameters allowing us to control the roughness in specific areas of the face. If for instance we would like to reduce the roughness in the cheeks, we can lower the"},{"start":"2:43","end":"3:18","startSec":163.9,"text":"value of the cheek front multiplier to something like .8. We can do the same to the nose. Here we can change the nose multiplier to something like .7. The face material instance gives us control over even the finest detail. Now let's close these and continue playing the sequence. When we get to the section of the sequence where we can see the teeth, I will press pause."},{"start":"3:18","end":"3:55","startSec":198.8,"text":"Here we may want to adjust the way the teeth and light are interacting and we can do this with the subsurface profile of the teeth. I'm going to select the MetaHuman Blueprint in the viewport. And in the details panel, select the face component. Over here we can open up the teeth material instance. The teeth material instance allows us to control things such as the base color of the teeth and gums and we can also fine tune things such as the teeth and gum roughness."},{"start":"3:55","end":"4:31","startSec":235.9,"text":"Another thing we can do is go down here to the material property overrides and adjust the subsurface profile. By default this will be disabled but I have already enabled this by checking this on. If we open this up, inside of here we can control the way light scatters as it passes through semi-translucent surfaces such as the teeth and gums. For example, the Mean Free Path Color controls how far light goes into the subsurface of"},{"start":"4:31","end":"5:02","startSec":271.9,"text":"the red, green and blue channel. If we change the red to something like 0.19 we can see that the teeth and gums become more translucent. The Mean Free Path Distance controls the distance that the Mean Free Path Color goes into subsurface. So for instance if we change the value to something like 0.19 we can see that the teeth and gums become even more translucent."},{"start":"5:02","end":"5:32","startSec":302.9,"text":"Let's close these and continue. I will continue playing the sequence. When we get to this section here perhaps we want to change the color of the hair. To do this I will select the metahuman, then go to the Details panel and select the Hair component. I will go here and open up the Hair Material instance."},{"start":"5:32","end":"6:04","startSec":333.0,"text":"Here we have a variety of parameters we can adjust. For example we can adjust the Hair Melanin parameter. If I change this value to something like 0.5 we can see the hair color changes. We can also adjust the roughness and control the way hair and light interact. Depending on the hairstyle we can also control properties such as the highlights and ombre."},{"start":"6:04","end":"6:38","startSec":364.1,"text":"These are a few simple adjustments we can make just through the material instances of the metahuman components. Now before we move on let's review what we just covered. Something to note is that many of the selections we have made in the metahuman creator to things such as the color of the eyes, the hair and some of the skin details can also be modified in engine with the component material instances."},{"start":"6:38","end":"7:14","startSec":398.2,"text":"We have control over even the finest details such as the roughness for specific areas of the face by unchecking the baked roughness modulation setting. We can also control how light scatters as it passes through translucent and semi-translucent surfaces such as the teeth, skin and eyes with the subsurface profile located in the material property overrides of these material instances."},{"start":"7:14","end":"7:49","startSec":434.7,"text":"We can use the hair material instance to fine tune the appearance of the hair and adjust things such as color, ombre and highlights. We can also control the way hair reflections and lighting interact by adjusting the roughness parameters. Now there may be cases where we want to make adjustments to a metahuman blueprint while preserving the original version. An easy way we can approach this is to make adjustments to a child blueprint of a metahuman."},{"start":"7:49","end":"8:21","startSec":470.0,"text":"Let's jump back into Unreal Engine and go over this. Inside of Unreal Engine with the folder of the metahuman we wish to adjust already opened, select the blueprint and then right click on it. Then select create child blueprint class. Now we can make adjustments to this child metahuman blueprint and those changes will not affect the original one."},{"start":"8:21","end":"8:55","startSec":501.5,"text":"You can open up this child blueprint and make changes such as switch the groom component asset with a different hairstyle, assign a different animation blueprint to the face or body or even do something as simple as forcing the LOD to something like 3. Now if we go back to our main viewport and drop this into a level we can see the changes we made are only applied to the child blueprint of this metahuman."},{"start":"8:55","end":"9:32","startSec":535.4,"text":"For certain shared assets such as materials those assets will have to be duplicated and a copy can be assigned and then adjusted otherwise those types of adjustments will affect the original blueprint. Let's review what we've just covered before we move on. We have just touched upon how we can approach making changes to a copy of an existing metahuman blueprint without those changes affecting the original by using a child blueprint."},{"start":"9:32","end":"10:09","startSec":572.9,"text":"To create a child blueprint simply right click on the metahuman blueprint and select create child blueprint class. From there you can change things such as forcing the LOD to something specific, switching out the hair grooms or assigning a different animation blueprint to one of the skeletal mesh components with the exception of shared assets such as materials. Now let's move on to the next section of this course."}],"12_FinaTipslOutput":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"When working with metahumans, there may be cases where we want to adjust our project render settings and lighting in order to get the best visual results. Let's take a look at some of these settings and how they affect a metahuman in a level. In the project settings, in the engine rendering section, the global illumination and reflection method setting will be set to Lumen by default,"},{"start":"0:30","end":"1:02","startSec":30.0,"text":"and support hardware ray tracing will also be enabled by default in Engine versions 5.5 and later. It is worth mentioning that in Engine versions 5.4 and later, ray tracing is no longer available as an option for reflection method, as ray trace reflections are built into Lumen's reflection system. For settings you may want to adjust, the first one is the Lumen ray lighting mode."},{"start":"1:02","end":"1:34","startSec":62.0,"text":"This setting allows us to control how Lumen reflections are lit. We can adjust this in the project render settings or through a post-process volume that is placed in a level. The second setting you may want to adjust is in the direct lighting section. You can enable ray trace shadows here and this setting will be applied globally in a project. Or you can enable this inside of each individual light."},{"start":"1:34","end":"2:08","startSec":94.0,"text":"Now, let's jump into Unreal Engine and take a look at how these render and light settings can change the appearance of a metahuman in a level. In the Outliner, I have turned off the Key Light 1 and the Top Light to better see the effects some of these settings will have. Let's begin by selecting the post-process volume. Then, go to the Lumen Global Illumination settings."},{"start":"2:08","end":"2:46","startSec":128.0,"text":"Here, we can control the ray lighting mode. As mentioned, this setting will allow Lumen to use hardware ray tracing and to control how the Lumen reflections are lit. By changing this from surface cache to hit lighting, Lumen will calculate the overall lighting at the hit point. If we change this to hit lighting for reflections, Lumen will calculate the lighting at the hit point, resulting in higher quality reflections but at the cost of performance."},{"start":"2:46","end":"3:18","startSec":166.0,"text":"Now, let's see how we can enable and disable ray trace shadows for individual lights. I'm going to select Key Light 2 in the Outliner and in the Light search bar, I will search for ray trace. Under the Advanced Light settings, we can enable or disable cast ray trace shadows for this light. When we change this to Enabled, we can see the shadows are softer."},{"start":"3:18","end":"3:53","startSec":198.0,"text":"If we change this back to Disabled, we can see the shadows are hardened. Let's leave this enabled. Inside of individual light settings, we can also control the shadows of hair strands. I'm going to search for Deep Shadow. Over here, notice the appearance of the grooms. Once we enable Deep Shadow, this light will cast high quality hair strand shadows and we can see the grooms have a bit more detail."},{"start":"3:53","end":"4:27","startSec":233.0,"text":"With this setting enabled, we can also use the Groom Asset Editor to fine tune the appearance of the strands even more. I'm going to select our MetaHuman. In the Details panel, I'm going to select the Eyebrows component and then go to the Groom Asset and open it. In the Strands panel of the Groom Asset Editor, over here, we can check on Use Hair Ray Tracing Geometry."},{"start":"4:27","end":"5:04","startSec":267.0,"text":"This may not be as noticeable with the eyebrows, but enabling this will help improve the strand rendering quality for Groom Assets. Over here, we can also adjust the hair shadow density. If we set this to 1, this will increase the amount of shadows on the groom. And if we set this to a lower value like 0.3, this will decrease the amount of shadows on the groom. And this is especially helpful if you encounter flickering with hair shadows and transmission."},{"start":"5:04","end":"5:37","startSec":304.0,"text":"Now, let's do a quick review of what we just covered. We just looked at a few different render and light settings we can adjust in a project when working with MetaHumans in a level. Using a post-process volume, in the Lumen Global Illumination settings, we can control how Lumen Reflections are lit through the Ray Lighting Mode options. When set to Surface Cache, Lumen will prioritize performance."},{"start":"5:37","end":"6:10","startSec":337.0,"text":"When set to Hit Lighting, Lumen will calculate the overall lighting at the hit point. And when set to Hit Lighting for Reflections, Lumen will calculate lighting at the hit point, prioritizing the highest quality reflections. Ray Trace shadows result in softer shadows, as opposed to harder shadows when disabled. For this to work, support hardware ray tracing must be enabled in the project settings."},{"start":"6:10","end":"6:47","startSec":370.0,"text":"If we wish to have Ray Trace shadows affect our entire project, we can enable this in the project settings. If we wish to have control over which lights cast Ray Trace shadows, we can do this in the individual light settings. We can also control the quality of hair strand shadows inside of individual light settings. By enabling Cast Deep Shadows in the Advanced Light Options, we can get high quality hair strand self-shadowing."},{"start":"6:47","end":"7:24","startSec":407.0,"text":"To improve the strands rendering quality, we can enable Use Hair Ray Tracing Geometry. And we can also increase or decrease the amount of shadows on a groom by adjusting the hair shadow density. We just finished going over how we can make adjustments to the various metahuman components and project render settings and the environment when working with metahumans in a level. Now, let's wrap up by moving on to the final section of our course by going over some resources for you to use."},{"start":"7:24","end":"7:32","startSec":444.0,"text":"As you continue your training with metahumans in Unreal Engine."}],"12_FinaTipslOutput_55":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"When working with metahumans, there may be cases where we want to adjust our project render settings and lighting in order to get the best visual results. Let's take a look at some of these settings and how they affect a metahuman in a level. In the project settings, in the engine rendering section, the global illumination and reflection method setting will be set to Lumen by default,"},{"start":"0:30","end":"1:02","startSec":30.0,"text":"and support hardware ray tracing will also be enabled by default in Engine versions 5.5 and later. It is worth mentioning that in Engine versions 5.4 and later, ray tracing is no longer available as an option for reflection method, as ray trace reflections are built into Lumen's reflection system. For settings you may want to adjust, the first one is the Lumen ray lighting mode."},{"start":"1:02","end":"1:34","startSec":62.0,"text":"This setting allows us to control how Lumen reflections are lit. We can adjust this in the project render settings or through a post-process volume that is placed in a level. The second setting you may want to adjust is in the direct lighting section. You can enable ray trace shadows here and this setting will be applied globally in a project. Or you can enable this inside of each individual light."},{"start":"1:34","end":"2:08","startSec":94.0,"text":"Now, let's jump into Unreal Engine and take a look at how these render and light settings can change the appearance of a metahuman in a level. In the Outliner, I have turned off the Key Light 1 and the Top Light to better see the effects some of these settings will have. Let's begin by selecting the post-process volume. Then, go to the Lumen Global Illumination settings."},{"start":"2:08","end":"2:46","startSec":128.0,"text":"Here, we can control the ray lighting mode. As mentioned, this setting will allow Lumen to use hardware ray tracing and to control how the Lumen reflections are lit. By changing this from surface cache to hit lighting, Lumen will calculate the overall lighting at the hit point. If we change this to hit lighting for reflections, Lumen will calculate the lighting at the hit point, resulting in higher quality reflections but at the cost of performance."},{"start":"2:46","end":"3:18","startSec":166.0,"text":"Now, let's see how we can enable and disable ray trace shadows for individual lights. I'm going to select Key Light 2 in the Outliner and in the Light search bar, I will search for ray trace. Under the Advanced Light settings, we can enable or disable cast ray trace shadows for this light. When we change this to Enabled, we can see the shadows are softer."},{"start":"3:18","end":"3:53","startSec":198.0,"text":"If we change this back to Disabled, we can see the shadows are hardened. Let's leave this enabled. Inside of individual light settings, we can also control the shadows of hair strands. I'm going to search for Deep Shadow. Over here, notice the appearance of the grooms. Once we enable Deep Shadow, this light will cast high quality hair strand shadows and we can see the grooms have a bit more detail."},{"start":"3:53","end":"4:27","startSec":233.0,"text":"With this setting enabled, we can also use the Groom Asset Editor to fine tune the appearance of the strands even more. I'm going to select our MetaHuman. In the Details panel, I'm going to select the Eyebrows component and then go to the Groom Asset and open it. In the Strands panel of the Groom Asset Editor, over here, we can check on Use Hair Ray Tracing Geometry."},{"start":"4:27","end":"5:04","startSec":267.0,"text":"This may not be as noticeable with the eyebrows, but enabling this will help improve the strand rendering quality for Groom Assets. Over here, we can also adjust the hair shadow density. If we set this to 1, this will increase the amount of shadows on the groom. And if we set this to a lower value like 0.3, this will decrease the amount of shadows on the groom. And this is especially helpful if you encounter flickering with hair shadows and transmission."},{"start":"5:04","end":"5:37","startSec":304.0,"text":"Now, let's do a quick review of what we just covered. We just looked at a few different render and light settings we can adjust in a project when working with MetaHumans in a level. Using a post-process volume, in the Lumen Global Illumination settings, we can control how Lumen Reflections are lit through the Ray Lighting Mode options. When set to Surface Cache, Lumen will prioritize performance."},{"start":"5:37","end":"6:10","startSec":337.0,"text":"When set to Hit Lighting, Lumen will calculate the overall lighting at the hit point. And when set to Hit Lighting for Reflections, Lumen will calculate lighting at the hit point, prioritizing the highest quality reflections. Ray Trace shadows result in softer shadows, as opposed to harder shadows when disabled. For this to work, support hardware ray tracing must be enabled in the project settings."},{"start":"6:10","end":"6:47","startSec":370.0,"text":"If we wish to have Ray Trace shadows affect our entire project, we can enable this in the project settings. If we wish to have control over which lights cast Ray Trace shadows, we can do this in the individual light settings. We can also control the quality of hair strand shadows inside of individual light settings. By enabling Cast Deep Shadows in the Advanced Light Options, we can get high quality hair strand self-shadowing."},{"start":"6:47","end":"7:24","startSec":407.0,"text":"To improve the strands rendering quality, we can enable Use Hair Ray Tracing Geometry. And we can also increase or decrease the amount of shadows on a groom by adjusting the hair shadow density. We just finished going over how we can make adjustments to the various metahuman components and project render settings and the environment when working with metahumans in a level. Now, let's wrap up by moving on to the final section of our course by going over some resources for you to use."},{"start":"7:24","end":"7:32","startSec":444.0,"text":"As you continue your training with metahumans in Unreal Engine."}],"13_FinalResources":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"Now, let's wrap up our course with some resources that you may find helpful when working with metahumans. When rendering image sequences with metahumans, the following console variables can assist with high quality renders. Feel free to take a snapshot of these. You do not have to use all of them at the same time, as they each have their own use, which depends on several factors. For example, the Hairstrands Holdout Mode console variable can be helpful if using Movie Render"},{"start":"0:36","end":"1:09","startSec":36.6,"text":"Graph. This will apply the Hairstrand separation to the Holdout node for creating better alpha layers for compositing. Finally, all of the resources and links to some of the tools discussed today can be found by following the URLs on this slide. Feel free to pause here or take a screenshot for later reference. This brings us to the end of the Metahuman Blueprints and Animation course."},{"start":"1:09","end":"1:17","startSec":69.2,"text":"I want to thank you for spending your time with me, and I hope these videos help you as you continue working with metahumans in Unreal Engine."}],"13_FinalResources_55":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"Now, let's wrap up our course with some resources that you may find helpful when working with metahumans. When rendering image sequences with metahumans, the following console variables can assist with high quality renders. Feel free to take a snapshot of these. You do not have to use all of them at the same time, as they each have their own use, which depends on several factors. For example, the Hairstrands Holdout Mode console variable can be helpful if using Movie Render"},{"start":"0:36","end":"1:09","startSec":36.6,"text":"Graph. This will apply the Hairstrand separation to the Holdout node for creating better alpha layers for compositing. Finally, all of the resources and links to some of the tools discussed today can be found by following the URLs on this slide. Feel free to pause here or take a screenshot for later reference. This brings us to the end of the Metahuman Blueprints and Animation course."},{"start":"1:09","end":"1:17","startSec":69.2,"text":"I want to thank you for spending your time with me, and I hope these videos help you as you continue working with metahumans in Unreal Engine."}]},"213.02":{"01_Introduction":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Hello and welcome to MetaHuman Fitting and DNA Calibration. My name is Gabriela Crusenio-Tacis and I will be your host for this course. In this course, we will be going over recommended workflows that can be used to modify and customize the neutral pose of the MetaHuman face using the MetaHuman Framework Toolset. Due to the number of workflows that are involved on this topic, this class has been split up into two courses."},{"start":"0:32","end":"1:03","startSec":32.3,"text":"The next course, MetaHuman DNA Calibration and Finalization, will be the continuation of this course where we explore more advanced use cases using DNA calibration and go over how we can bring the modified assets back into Unreal Engine. It is worth noting that the DNA calibration workflows we will be covering in both courses have changed in later Engine versions and we will be exploring those changes in a future update."},{"start":"1:03","end":"1:36","startSec":63.9,"text":"In this course, we begin by exploring the complexity of the MetaHuman face and MetaHuman Framework Tools such as the DNA calibration repository that can be used for making adjustments to the neutral pose. We then touch upon expectations as to how far customizations can be pushed before encountering issues. Next, we will cover common workflows for fitting MetaHuman topology to scan our sculpted meshes."},{"start":"1:36","end":"2:07","startSec":96.2,"text":"From there, we move on to two hands-on exercises. In the first one, we will export a MetaHuman identity conformed mesh from Unreal Engine to be used for additional fitting. And for the second one, we will use the mesh to MetaHuman workflow with the template mesh option to generate a MetaHuman identity that will be solved based on geometry. From there, we will delve into best practices for fitting the additional head geometry assets."},{"start":"2:07","end":"2:40","startSec":127.1,"text":"Then we move on to the DNA calibration section of this course. We will cover setting up the DNA calibration repository and we'll get acquainted with the files and scripts that we will be using. We will use the example script from the repository to modify the neutral pose inside of Autodesk Maya. We will make some minor adjustments directly on the head mesh and with the joints and skin clusters. Then we will update the MetaHuman DNA and export the head LODs as FBX."},{"start":"2:40","end":"3:11","startSec":160.9,"text":"Finally, we will wrap up this course with some final recommendations and I will share some tips and resources for you to use as you continue your work and training with MetaHumans. This course will be using the project MEH9130055 and there are two level maps. Both maps are located in the content browser under the courses folder labeled MEH21302"},{"start":"3:11","end":"3:43","startSec":191.9,"text":"in the course maps folder. The first map is named MEH21302MAPS which should load automatically. S stands for Standard MetaHuman. In this map we have two versions of the preset LENA. We have the original version and the version that has been modified using the 2023 UnrealFest DNA calibration script. The second map is named MEH21302MAPC for Custom."},{"start":"3:44","end":"4:18","startSec":224.4,"text":"I will double click on this to open it. This map has a stylized MetaHuman named Atomic Savage that has been customized using more advanced DNA calibration scripts. The assets that we will be using in this project are located in the course assets folder. The folder named ATOMICSAnom contains a body animation that has been retargeted to this character. The folder named CONFORMEDMASH contains the fitted conformed mesh that we will use for"},{"start":"4:18","end":"4:51","startSec":258.5,"text":"one of the hands-on exercises. The folder named SEQUENCES contains two level sequences you can play that include a body and face animation. The ATOMICS sequence can be used in the map with ATOMICSavage and the sequence labeled LENADNA can be used in the map with the modified version of LENA. The source files folder named 21302 FITTADNA assets will contain the assets that have been used for the modified MetaHumans in both maps if you wish to inspect them."},{"start":"4:52","end":"5:28","startSec":292.6,"text":"If at any point you need to reference the location of the course maps, they can be found at the beginning of the slide deck after the training outline. As we go through this course you will find that many slides in this presentation contain a lot of information and I will summarize all of that. But if at any point you want to read what is on each of those slides, feel free to pause and dive right in. Now let's begin with the first portion of this course by exploring the complexity of the MetaHuman face, DNA calibration, and expectations"},{"start":"5:28","end":"5:32","startSec":328.1,"text":"for achieving likeness."}],"01_Introduction_55":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Hello and welcome to MetaHuman Fitting and DNA Calibration. My name is Gabriela Crusenio-Tacis and I will be your host for this course. In this course, we will be going over recommended workflows that can be used to modify and customize the neutral pose of the MetaHuman face using the MetaHuman Framework Toolset. Due to the number of workflows that are involved on this topic, this class has been split up into two courses."},{"start":"0:32","end":"1:03","startSec":32.3,"text":"The next course, MetaHuman DNA Calibration and Finalization, will be the continuation of this course where we explore more advanced use cases using DNA calibration and go over how we can bring the modified assets back into Unreal Engine. It is worth noting that the DNA calibration workflows we will be covering in both courses have changed in later Engine versions and we will be exploring those changes in a future update."},{"start":"1:03","end":"1:36","startSec":63.9,"text":"In this course, we begin by exploring the complexity of the MetaHuman face and MetaHuman Framework Tools such as the DNA calibration repository that can be used for making adjustments to the neutral pose. We then touch upon expectations as to how far customizations can be pushed before encountering issues. Next, we will cover common workflows for fitting MetaHuman topology to scan our sculpted meshes."},{"start":"1:36","end":"2:07","startSec":96.2,"text":"From there, we move on to two hands-on exercises. In the first one, we will export a MetaHuman identity conformed mesh from Unreal Engine to be used for additional fitting. And for the second one, we will use the mesh to MetaHuman workflow with the template mesh option to generate a MetaHuman identity that will be solved based on geometry. From there, we will delve into best practices for fitting the additional head geometry assets."},{"start":"2:07","end":"2:40","startSec":127.1,"text":"Then we move on to the DNA calibration section of this course. We will cover setting up the DNA calibration repository and we'll get acquainted with the files and scripts that we will be using. We will use the example script from the repository to modify the neutral pose inside of Autodesk Maya. We will make some minor adjustments directly on the head mesh and with the joints and skin clusters. Then we will update the MetaHuman DNA and export the head LODs as FBX."},{"start":"2:40","end":"3:11","startSec":160.9,"text":"Finally, we will wrap up this course with some final recommendations and I will share some tips and resources for you to use as you continue your work and training with MetaHumans. This course will be using the project MEH9130055 and there are two level maps. Both maps are located in the content browser under the courses folder labeled MEH21302"},{"start":"3:11","end":"3:43","startSec":191.9,"text":"in the course maps folder. The first map is named MEH21302MAPS which should load automatically. S stands for Standard MetaHuman. In this map we have two versions of the preset LENA. We have the original version and the version that has been modified using the 2023 UnrealFest DNA calibration script. The second map is named MEH21302MAPC for Custom."},{"start":"3:44","end":"4:18","startSec":224.4,"text":"I will double click on this to open it. This map has a stylized MetaHuman named Atomic Savage that has been customized using more advanced DNA calibration scripts. The assets that we will be using in this project are located in the course assets folder. The folder named ATOMICSAnom contains a body animation that has been retargeted to this character. The folder named CONFORMEDMASH contains the fitted conformed mesh that we will use for"},{"start":"4:18","end":"4:51","startSec":258.5,"text":"one of the hands-on exercises. The folder named SEQUENCES contains two level sequences you can play that include a body and face animation. The ATOMICS sequence can be used in the map with ATOMICSavage and the sequence labeled LENADNA can be used in the map with the modified version of LENA. The source files folder named 21302 FITTADNA assets will contain the assets that have been used for the modified MetaHumans in both maps if you wish to inspect them."},{"start":"4:52","end":"5:28","startSec":292.6,"text":"If at any point you need to reference the location of the course maps, they can be found at the beginning of the slide deck after the training outline. As we go through this course you will find that many slides in this presentation contain a lot of information and I will summarize all of that. But if at any point you want to read what is on each of those slides, feel free to pause and dive right in. Now let's begin with the first portion of this course by exploring the complexity of the MetaHuman face, DNA calibration, and expectations"},{"start":"5:28","end":"5:32","startSec":328.1,"text":"for achieving likeness."}],"02_GettingStarted":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"In this portion of our course, we begin by looking at the complexity of the metahuman face. Then, we delve into metahuman DNA, the DNA calibration repository, and go over expectations for achieving likeness with our characters. Let's get started by first exploring the complexity of the metahuman face. In this section of our course, we begin by looking at the complexity of the metahuman"},{"start":"0:30","end":"1:06","startSec":30.5,"text":"face. We will take a look at the metahuman face component and its associated assets, including all of its geometry and how these work with rig logic. Let's begin by answering the question, what is the metahuman framework? The metahuman framework is a single product made up of a variety of collaborating parts, carefully designed to work together seamlessly. The assets that make up the metahuman framework include the body and head meshes, skeletons"},{"start":"1:06","end":"1:38","startSec":66.6,"text":"and control rigs, animation blueprints, materials and animated maps, clothing, grooms, metahuman DNA and rig logic. In this course, we are focused on one of those assets, the metahuman face. The face is tied to all of these assets, and for this reason, a few things should be considered when making modifications to the neutral pose so that it behaves correctly."},{"start":"1:38","end":"2:12","startSec":98.3,"text":"The metahuman face component is made up of several assets. Let's take a look at the head geometry first. Inside of Maya, we can see the assets that make up the head geometry. These meshes include the head, the teeth, the saliva, the left and right eye, the eye shell, the eyelashes, the eye edge and cartilage. And each of these have their own LODs. There are also the joints, skin clusters and blend shapes."},{"start":"2:12","end":"2:47","startSec":132.0,"text":"Now let's take a look at the assets that make up the metahuman face component in Unreal Engine. In Unreal Engine, the face component assets include the skeleton, the skeletal mesh, animation sequences, animation blueprints and the face pose process animation blueprint. As we saw in the metahuman blueprint and animation course, the face pose process animation blueprint is where the rig logic node lives, and is responsible for triggering the animated blood"},{"start":"2:47","end":"3:17","startSec":167.5,"text":"flow and normal maps. Now let's delve into rig logic a bit more. Rig logic is a runtime, facial rig evaluation solver system developed by 3Lateral and has taken over a decade's worth of research and development to parameterize the human face. It relies on a universal set of rules for defining the muscular system of the face and utilizes"},{"start":"3:17","end":"3:52","startSec":197.7,"text":"the proprietary file format called metahuman DNA. At the core of facial animation, the important elements that the metahuman face rig includes are the joint and skin weight deformers, blend shape deformers, base and animated texture setups, the rig logic plugin and metahuman DNA, the user interface of the face control rig and built in LODs. In simpler terms, rig logic is what allows animations to be shared by all metahumans"},{"start":"3:52","end":"4:12","startSec":232.0,"text":"and LODs, while working under the hood to activate blend shapes, corrective blend shapes, joint transforms and animated maps. Now we have just gone over the assets that make up the metahuman face. In the next section, we will take a closer look at metahuman DNA."}],"03_MetaHumanDNA":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"In this section, we will learn about metahuman DNA. For rig logic to work, it needs a metahuman DNA file. Let's answer the question, what is metahuman DNA? Metahuman DNA is a file format that stores the complete description of a 3D object's rig and geometry. DNA files store only the faces of metahuman characters."},{"start":"0:30","end":"1:00","startSec":30.0,"text":"The data is separated into logical layers, and each layer depends on the previous one to make sense of the data. At the top of the DNA file data layer is the descriptor. This has information about the character that a DNA file is representing, such as the character's name. Next is the definition. This tells us about the elements of the rig and how those are divided into LODs."},{"start":"1:00","end":"1:34","startSec":60.0,"text":"This has two layers, the behavior layer and the geometry layer. The behavior layer is what makes a character unique and how it behaves when it is animated. This is split into input and output. The input is how the information maps from the faceboard controls to the raw controls that also trigger corrective expressions. The output is how the joint attribute values are stored, how different LODs affect joint behavior,"},{"start":"1:34","end":"2:10","startSec":94.0,"text":"and how the activation for each expression for blend shapes and animated maps is affected by LODs. The geometry layer contains information about the mesh, the skinning, and corrective blend shapes. This includes information about the topology and vertex position of meshes and skinning information such as the values of weights for each vertex of every mesh. This is why when making modifications to the neutral pose, those changes need to be updated in the DNA file."},{"start":"2:10","end":"2:26","startSec":130.0,"text":"We have just gone over what metahumanDNA is. In the next section we will look at the DNA calibration repository and how we can use this to make adjustments to the neutral pose and update the metahumanDNA file."}],"04_DNACalib":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"In this section, we will explore the MetaHuman DNA calibration repository. Throughout this course, I will be referencing the 2023 Unreal Fest DNA calibration deep dive presentation delivered by part of the three-lateral team. This is one of the greatest resources and explanations of the DNA calibration library, and I have linked the presentation in the resources section of this course."},{"start":"0:30","end":"1:08","startSec":30.0,"text":"Now, let's review what the DNA calibration repository is. The DNA calibration repository is a C++ library that gives users access to the contents of the MetaHuman DNA file. It has a Python wrapper making it accessible to use with DCCs outside of Unreal Engine such as Autodesk Maya. The tools enable users to further customize the MetaHuman rig as well as to modify DNA files and use read and write operations on DNA files to change the rig."},{"start":"1:08","end":"1:47","startSec":68.0,"text":"The tools include the DNA Calib C++ library which is used to manipulate DNA files and DNA viewer which is used to visualize DNA in Autodesk Maya. In simple terms, DNA viewer allows users to look at the DNA file and do things such as choose what LODs you want to assemble and what properties you want in them. DNA calibration allows you to take these things and through commands you can manipulate the rig, the joints, the meshes, and blend shapes for specific pipeline needs."},{"start":"1:47","end":"2:17","startSec":107.0,"text":"Some of the things users can achieve include setting the number of LODs, renaming or removing joints or meshes, setting skin weights, vertex positions, or blend shape target deltas, and once finished making modifications, users can export the DNA and bundle it with the FBX so that when the modified DNA and FBX files are brought back into Unreal Engine, the MetaHuman face will behave correctly."},{"start":"2:17","end":"2:54","startSec":137.0,"text":"DNA calibration is the recommended toolset for calibrating MetaHuman DNA when finalizing customizations to the neutral pose for Engine versions 5.5 and earlier. Now let's take a look at the MetaHuman DNA repository. The MetaHuman DNA repository is available on GitHub and can be accessed using the URL listed on this slide. A good place to start is by going to the readme file which includes information on how to set up the library and what can be achieved."},{"start":"2:54","end":"3:36","startSec":174.0,"text":"Inside of the examples folder which we will be taking a closer look at later on, users will find examples of code that perform functions such as removing joints, viewing the rig with textures, and exporting the DNA head LODs as FBX. Users can combine different functions from here and create their own scripts. The Unreal Fest zip contains the assets and scripts from the 2023 Unreal Fest DNA calibration deep dive presentation, and this is a great example of how users can combine simple and advanced functions and bundle them into a single script."},{"start":"3:36","end":"3:55","startSec":216.0,"text":"Now that we have a better understanding of the DNA calibration repository and some of the things that can be achieved, in the next section we will touch upon different approaches and expectations for achieving likeness using various MetaHuman framework tools."}],"05_MetaHumanLikeness":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"In this section, we will touch upon different approaches for achieving likeness using the MetaHuman Framework tools. We will also address expectations regarding how far customizations to the neutral pose can be pushed before encountering issues. We can approach achieving likeness with MetaHuman characters using the various MetaHuman Framework tools. A good place to start is with the MetaHuman Creator."},{"start":"0:33","end":"1:08","startSec":33.2,"text":"Something to keep in mind is that the MetaHuman presets come from a database of real-world scanned people. This means the more faces that are added to the database, the larger the options will be to achieve specific facial features. Another option is to use the mesh to MetaHuman workflow. The MetaHuman plugin allows users to create a MetaHuman identity from a mesh, from footage, or from a template mesh. The MetaHuman identity can be solved based on image or geometry."},{"start":"1:08","end":"1:44","startSec":68.4,"text":"With the DNA calibration tools, MetaHuman customizations can be pushed even further. This workflow requires some knowledge in rigging, modeling, and Python. Let's move on and address expectations for achieving likeness with our characters. It is important to keep in mind the golden triangle of the face when making changes to the neutral pose. The triangle is related to the database that the MetaHuman presets come from. Stylized faces with exaggerated facial features introduce large deltas outside of the database"},{"start":"1:44","end":"2:19","startSec":104.5,"text":"range. And this can result in issues with range of motion when animation is applied. Here are a few considerations when working with stylized MetaHuman faces. For cinematics, if using only LOD0, certain facial features can be pushed further, such as a stronger jawline, bigger ears, a larger forehead, or a larger upper nose and cheekbones. It is possible to see breaks in the golden triangle area of the face. However, you can get away with a lot more when using only LOD0."},{"start":"2:19","end":"2:52","startSec":139.3,"text":"For games where LODs in optimization are crucial, it is likely to see issues with range of motion with exaggerated facial features such as a big or tiny nose, lips, or eyes. In addition, customizations to LOD0 will not be passed down to the lower LODs, as those are joints only and require joint matching. In cases like these, the mesh to MetaHuman workflow using the template mesh option may help to transfer the larger shapes to the lower LODs."},{"start":"2:52","end":"3:24","startSec":172.7,"text":"However, there will still be more work to do. And that is where DNA calibration comes in. Now something to note about using a globally applied blend shape for customizations. At first, it might appear that this can help achieve more likeness with the neutral pose. But since the vertex and joint positions of the rig are not updated in the DNA file, the face may not behave correctly when animations are applied, and that shape will not be present for lower LODs."},{"start":"3:24","end":"3:41","startSec":204.9,"text":"Now that we have addressed expectations and considerations when working with stylized MetaHuman faces, let's move on to the next portion of our course, where we explore a variety of customization workflows that can be used to modify the MetaHuman neutral pose."}],"06_CustomizationWorkflows":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"In this portion of our course, we will explore various workflows that can be used to make changes to the metahuman neutral pose. We begin with pipeline considerations for achieving likeness using DNA calibration. Then we cover different approaches for fitting metahuman topology to face scan data and sculpted 3D head meshes. From there, we move on to two hands-on exercises. For the first exercise, we will export a metahuman identity-conformed mesh from Unreal Engine"},{"start":"0:35","end":"1:06","startSec":35.5,"text":"that can be used for additional fitting. For the second one, we will solve a metahuman identity based on geometry using the mesh-to-metahuman workflow with the template mesh option. We then delve into best practices for fitting the metahuman head geometry and its additional assets, such as the eyes, eyelashes, and so on, to our target delta. Let's begin by exploring workflows for achieving likeness using 3D sculpted head meshes and"},{"start":"1:06","end":"1:38","startSec":66.4,"text":"face scan data. In this section, we begin by looking at pipeline considerations for achieving likeness using DNA calibration. We then delve into different approaches for fitting metahuman topology to face scan data and sculpted 3D head meshes. To finalize changes that have been made to the metahuman neutral pose, metahuman DNA needs to be updated before bringing the modified assets back into Unreal Engine."},{"start":"1:38","end":"2:12","startSec":98.5,"text":"To do this, we can use the DNA calibration toolset. The main step we will see when working with either scan or sculpted mesh workflows is that metahuman DNA will need to be recalibrated before bringing any changes back into Unreal Engine. One of the reasons is due to the relationship the vertex and joint positions have with each other. Each joint name has a value assigned as a vertex index. Once we start to work with DNA calibration, you will notice two commands we will be running,"},{"start":"2:12","end":"2:46","startSec":132.9,"text":"which is to save the current vertex and joint positions, then update the vertex and joints to their new positions, and save those changes to the DNA. The images in the top right demonstrate the surface joint positions before and after they have been updated once the vertex positions have been changed. Surface joints are responsible for preserving volume, especially for lower LODs. So once a change is made to the vertex positions, using commands, we are able to snap the surface"},{"start":"2:46","end":"3:22","startSec":166.3,"text":"joints to their new vertex positions so that the volume is preserved. Simply put, when making changes to the vertex positions or joint positions, the DNA file needs to account for these changes by updating the behavior and geometry layer of the DNA file. When we do this so that when we bring our finalized rig back into Unreal Engine, along with the updated DNA file, it will behave correctly. Now, let's take a look at pipeline considerations when working with a face skin or sculpted"},{"start":"3:22","end":"3:55","startSec":202.1,"text":"head mesh. When working with a head sculpt, the focus will be on fitting the metahuman topology to the sculpt first, and then fitting the additional face geometry assets to it. The first step would be to select a metahuman preset and wrap the LOD0 head topology to the head sculpt. The second step would be to use the mesh to metahuman workflow with the template mesh option to create a metahuman identity that is solved based on geometry, as this will"},{"start":"3:55","end":"4:28","startSec":235.1,"text":"get the geometry and joints closer to the target delta. This differs from the standard mesh to metahuman workflow, which solves a metahuman identity based on image and how the tracking markers are positioned. The third step would be to refit any details that may have been lost from the solve, and then manually fit all of the additional face geometry assets to the metahuman identity head mesh vertex by vertex. This is the most time consuming portion of this workflow."},{"start":"4:28","end":"5:01","startSec":268.5,"text":"The fourth step would be to use DNA calibration to update the vertex and joint positions and save those changes to the DNA file. The head LODs can then be exported as FBX, along with the new DNA file. And the final step would be to bring the modified assets back into Unreal Engine and configure the new assets. This workflow chart represents what a pipeline might look like, and it is not a hard roadmap as the steps may vary depending on a pipeline's needs."},{"start":"5:01","end":"5:31","startSec":301.1,"text":"Now, let's take a look at how this workflow may differ if using face scan data. For face scan data, the focus may be more on transferring the texture maps correctly by aligning the head geometry with the original face scan. Step one would be to use the standard mesh to metahuman workflow to create an initial metahuman identity that is solved based on image, which relies on where the tracking markers are placed on the facial features."},{"start":"5:31","end":"6:02","startSec":331.3,"text":"This would align the head geometry with the scan in order to transfer the textures. Step two would be to export the conformed mesh from the metahuman identity asset and refit any details that were lost from the solve. Step three would be to use the mesh to metahuman workflow with the template mesh option in order to get the geometry and joints closer to the target delta. And step four would be to use this new metahuman identity to refit any lost details and then"},{"start":"6:02","end":"6:34","startSec":362.7,"text":"fit the additional head geometry assets. Step five would be to update the changes to the vertex and joint positions and save those changes to the DNA and then export the head LODs as FBX bundled with the new DNA file. Step six would be to finalize the rig by bringing the modified assets into Unreal Engine and then configure them. The process of transferring textures is not included in this workflow chart. As mentioned, these charts are not a hard roadmap."},{"start":"6:34","end":"7:03","startSec":394.8,"text":"They simply demonstrate different approaches for fitting and that by adding DNA calibration to a workflow, this ensures that the metahuman DNA file will take into account changes that have been made to the neutral pose. And once those changes have been brought back into Unreal Engine, the metahuman face will behave correctly. In the next section, we will delve into approaches for fitting metahuman topology to a skin or sculpted mesh."}],"07_GeoFittingPresets":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"In this section, we will delve into fitting metahuman topology to scan in sculpted meshes. One approach is to use the metahuman presets for fitting metahuman topology to a target delta. And another approach is to use the standard mesh to metahuman workflow to generate an identity. We will first explore using metahuman presets for fitting and how the metahuman identity texture can be a helpful reference for the fitting process."},{"start":"0:33","end":"1:04","startSec":33.2,"text":"The goal of fitting is to first wrap metahuman topology to a scanner sculpt as this will be the target delta. From there, that asset can be used with the mesh to metahuman workflow using the template mesh option to generate a metahuman identity whose geometry and joints are closer to the target delta. Begin by going to the metahuman creator and selecting a preset. Then download the metahuman source assets from the Quixel Bridge standalone application"},{"start":"1:04","end":"1:38","startSec":64.7,"text":"and using the LOD0 head mesh from the Maya scene, fit it to the model. The metahuman identity texture can be used as a reference during the fitting process. When fitting important polygon flow transitions, the metahuman identity texture can be a helpful reference. It can be found inside of Unreal Engine by going to all, plugins, metahuman content, identity template. In the material named metahuman identity head, you can locate the texture there and export"},{"start":"1:38","end":"2:10","startSec":98.6,"text":"it. Some important polygon flow transition regions include the eyes, particularly the inner edge of the eyelid. For the mouth area, pay close attention to the inner and outer vermilion and the contact edge of the lips, as well as the transition regions of the nose bridge and middle of the neck. Now that we have a better idea of how we can approach fitting metahuman topology using metahuman presets, in the next section we will review some important terminology that"},{"start":"2:10","end":"2:19","startSec":130.8,"text":"relates to metahuman identity conforming before delving into fitting metahuman topology using the mesh to metahuman workflow."}],"08_MHIdentityConforming":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"In the previous section, we covered fitting metahuman topology to metahuman presets. Another approach is to use the Mesh to Metahuman workflow, with the standard Mesh or Template Mesh option also referred to as Conformed Mesh. In this section, we will review some important terminology that relates to metahuman identity conforming, and go over what a metahuman identity asset is, what conforming means and how it works, what exporting the conformed mesh means and how it can be used."},{"start":"0:36","end":"1:06","startSec":36.0,"text":"A metahuman identity asset contains the template of a head mesh and a reference to the matching rig that is generated from the input source data such as a scanner sculpt. Conforming refers to the process of configuring the metahuman identity to approximate the volume that is found from the metahuman preset database. The results may not match the source data precisely as this process uses the metahuman standard topology."},{"start":"1:06","end":"1:36","startSec":66.0,"text":"The conformed mesh of the metahuman identity that has been generated can be exported directly from the metahuman identity asset window, locally on the user's workstation. Since this is of metahuman topology, it can be used for refitting any lost details to the scanner sculpt. In the next section, we will go through a hands-on exercise where we will export the conformed mesh from the metahuman identity asset window."}],"09_HandsOn_ExportConform":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"In this section of our course, we will go through a hands-on exercise where we will export the conformed mesh that is generated from a metahuman identity solve from the metahuman identity asset window. This exercise demonstrates one approach to fitting metahuman topology to a scanner sculpt by using the conformed mesh to refit any details that were lost from the solve. If you already fitted the metahuman head topology to your scanner sculpt using a metahuman preset,"},{"start":"0:34","end":"1:09","startSec":34.9,"text":"you would skip these steps. We will primarily work in Unreal Engine. As we work through this exercise, you will note that this is broken down into a step-by-step process that is found in your slide deck. As we complete portions of the practical exercise, I will review the completed steps. Now, let's jump into Unreal Engine and go through the steps of exporting the conformed mesh from the metahuman identity asset window. Inside of Unreal Engine, to get started, we would first need to go through the steps of"},{"start":"1:09","end":"1:39","startSec":69.3,"text":"generating a metahuman identity that will be used for fitting metahuman topology to a scan using the standard mesh to metahuman workflow. Since we already went through those steps and generated one in the metahuman introduction class, let's locate that metahuman identity asset. Under the courses folder, in the folder named MEH11301, let's navigate to the course topics folder."},{"start":"1:39","end":"2:16","startSec":99.3,"text":"In the folder named mesh to metahuman identity, it is located in the folder named EX for example. The metahuman identity is named RCSCAN. Let's double-click on this to open it. Inside of here, the first step is to go down here to the command PROPT. Then enter the command MHIDENITY EXPORT MESHES and the number 1 and press ENTER. Now go up to the main toolbar and select metahuman identity solve."},{"start":"2:16","end":"2:46","startSec":136.0,"text":"What this does is it exports the metahuman identity conformed mesh. Once this process completes, we can close this window. The next step is to locate the exported conformed mesh which will be in the file explorer saved folder of the Unreal Engine project. To locate this easily, I'm going to go to the content folder and then right-click on it and select SHOW AN EXPLORER."},{"start":"2:46","end":"3:17","startSec":166.1,"text":"This will open up the file explorer of our course project. We want to navigate to the main project folder and then open up the SAVED folder. Inside of here, at the bottom here, is an obj file named RCSCANED MESH. This is the scanned mesh that was used for the solve. In the folder named RCSCAN, which is the name of our metahuman identity, we will see"},{"start":"3:17","end":"3:51","startSec":197.0,"text":"an obj file named CONFORMAL FACE MESH. This is the metahuman identity conformed mesh that is of metahuman topology. Now before we move on, let's do a quick review of the steps we just covered. We just went through the process of exporting the conformed mesh from the metahuman identity asset window. Instead of manually fitting a metahuman preset to your scanner sculpt, you can simply use the standard MESH to metahuman workflow to generate an initial metahuman identity."},{"start":"3:51","end":"4:25","startSec":231.2,"text":"The benefits of this is that you can align the metahuman identity with the headscan, making it easier to transfer textures from the scanned data to the identity. To get started, you will first create an initial metahuman identity by importing and preparing the mesh. Since this is an image-based solve, using a texture can help to track the facial features better. Next, create a metahuman identity asset and populate it. Create and track a neutral pose and run the identity solve."},{"start":"4:25","end":"4:57","startSec":265.5,"text":"From there, you can enable and adjust additional trackers and spend a good amount of time on the eyes and mouth to get a more precise solve. Once you are finished, submit the template mesh to the metahuman backend. To export the metahuman identity conformed mesh from the metahuman identity asset, in the command prompt, enter, mh, identity, export meshes, and the number 1."},{"start":"4:57","end":"5:28","startSec":297.6,"text":"Once you hit enter, in the main toolbar, select metahuman identity solve. Next, locate the conformed mesh. To locate the conformed mesh, go to the File Explorer folder of the Unreal Engine project. In the saved folder, the obj file of the mesh that was used for the solve will include the name ScannedMesh. In the folder with the name of the metahuman identity asset, the obj file that includes"},{"start":"5:28","end":"5:59","startSec":328.4,"text":"the name conformal face mesh will be the conformed mesh of the metahuman identity and it will be of metahuman topology. The next step of this workflow is to bring these meshes into your choice of 3D software to inspect them. And from there, you can refit any details that were lost during the solve back onto the conformed mesh. Let's jump into Autodesk Maya and inspect the meshes."},{"start":"5:59","end":"6:30","startSec":359.3,"text":"In a new Maya scene, I have added the scanned and conformed mesh obj files. Over here in the Outliner, this is the scanned mesh, which is what was used for the solve. Over here, I'm going to unhide the conformed mesh that was generated from the solve. Since this is already of metahuman topology, we can use this to refit accents that may have been lost during the solve while preserving the existing polygon flow."},{"start":"6:30","end":"7:03","startSec":390.3,"text":"Let's do a quick review before we move on. The conformed mesh can be used to bring back volume and large accents that may have been lost in the solve while preserving the existing polygon flow. Just ensure to mask and protect important polygon flow regions, such as the eyes and inside of the mouth, when projecting details onto the conformed mesh. Once the metahuman topology has been refitted to the scanner sculpt, this can be used with"},{"start":"7:03","end":"7:32","startSec":423.4,"text":"the mesh to metahuman workflow using the template mesh option to generate a metahuman identity that will be solved based on geometry. This method will give us a more precise match and better joint positioning for lower LODs. In the next section, we will review the mesh to metahuman workflow using the template mesh option before moving on to the next hands-on exercise where we go through the steps of this workflow."}],"10_ConformMHIdentity":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"In this section, we will review the Mesh to MetaHuman workflow using the Template Mesh option. This workflow allows for a metahuman identity to be solved based on the geometry input, which results in a more precise match and better joint positioning for LODs. Let's take a look at the requirements and steps of this workflow. The Mesh to MetaHuman workflow using the Template Mesh option, which can also be referred to as the Conformed Mesh option,"},{"start":"0:33","end":"1:04","startSec":33.0,"text":"allows users to conform a metahuman identity by directly assigning a specific template mesh. This forces a precise fit of the metahuman topology. In order for this to work, the main requirement is that the input mesh must already be conformed to the topology of the metahuman template mesh. In the previous sections, we went over different approaches for fitting metahuman topology to a scanner sculpt."},{"start":"1:04","end":"1:30","startSec":64.0,"text":"This workflow allows us to use the fitted metahuman head geometry asset as an input and results in getting the geometry and joint positions closer to the target delta across all LODs. Now let's move on to the next section where we will work through a hands-on exercise to create a metahuman identity with the Mesh to MetaHuman workflow using the template mesh option."}],"11_HandsOn_ConformTemplate":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In this section of our course, we will go through a hands-on exercise where we will use the Mesh to MetaHuman workflow with the template, or also known as the conformed mesh option to create a metahuman identity. We will primarily work in Unreal Engine, and as we work through this exercise, you will note that this is broken down into a step-by-step process that is found in your slide deck. As we complete portions of the practical exercise, I will review the completed steps."},{"start":"0:32","end":"1:02","startSec":32.0,"text":"So let's jump into Unreal Engine and begin going through the steps of this workflow. Inside of Unreal Engine, let's begin by going to our course folder named MEH21302. In the assets folder in the folder named conformed mesh atomic savage, I have already gone through the steps of importing the fitted head mesh of the stylized character atomic savage. I will double-click on this to open it."},{"start":"1:02","end":"1:32","startSec":62.0,"text":"If you wish to go through the steps of importing this yourself, you can find the original obj file in the source files folder of our course. For this workflow, we will be using this head mesh. You do not need to apply a material to this, as this will not be solved based on image. I have gone ahead and applied a material that is using the metahuman identity texture to demonstrate that this has been fitted in a way that respects all of the important edges and loops."},{"start":"1:32","end":"2:03","startSec":92.0,"text":"I am going to close this and return to the main viewport. Now let's navigate to our course topics folder. In the folder named conformed mesh to metahuman, you will find a metahuman identity that has been solved with the template mesh option that you can inspect. Now let's go to the conformed mesh to metahuman example folder. Inside of here, I have created a blank metahuman identity asset and named it. Let's double-click on this to open it."},{"start":"2:03","end":"2:33","startSec":123.0,"text":"As you can see, this is empty and we are going to populate it. For the first step, instead of going to the create components dropdown over here in the toolbar, we will go up here to asset and select it. Then all the way down here, we will select configure components from conformed. We are going to search for the static mesh named atomic as conformed, which is right here and then select it."},{"start":"2:33","end":"3:04","startSec":153.0,"text":"Now that this head mesh is loaded, I am going to navigate to the front of it so that we can see it better. The second step is to select the body component and right below select a body type. In this case, I want to choose medium masculine overweight. The third step is to go to the mesh to metahuman dropdown here and select auto rig metahuman identity, skeletal mesh and full metahuman."},{"start":"3:04","end":"3:37","startSec":184.0,"text":"You may be prompted to sign in with your Epic Games account. Once you do, it will send this to the metahuman backend. When this process completes, a notification will appear, letting us know that the skeletal mesh has been embedded with metahuman DNA and that this is also available in the creator and bridge. Since atomic savage is much larger than standard metahumans, this also informs us that the identity face scale is 1.329 times that of an average metahuman,"},{"start":"3:37","end":"4:10","startSec":217.0,"text":"which may indicate an issue with the input data. It recommends that the input mesh be less than 25% away from the scale of an average metahuman face. This is fine for our specific character, so I'm going to click OK. Now I will navigate to our main viewport and in the content browser, we will see the skeletal mesh that was generated. I'm going to double click on this to open it and I will dock it up here."},{"start":"4:10","end":"4:42","startSec":250.0,"text":"Even though there is still more work to do, this workflow helps to get the geometry and joint positions closer to the target delta. The atomic savage character is a good example for demonstrating the kinds of results you may get when using a stylized face whose facial features go beyond the golden triangle of the face. The last step of this workflow is to go to the metahuman creator, inspect the results and make adjustments if needed before downloading the source assets."},{"start":"4:42","end":"5:12","startSec":282.0,"text":"Now let's do a quick review before we move on. We have just gone through the steps of the mesh to metahuman workflow using the template mesh option. The requirement for this workflow is that we use a mesh that has been fitted to metahuman topology. To get started, import the head mesh, which in our case we use the atomic savage conformed OBJ file that has been fitted to a custom sculpt already."},{"start":"5:12","end":"5:42","startSec":312.0,"text":"With the head mesh imported, the first step is to create a metahuman identity asset and configure it. Inside of the metahuman identity asset window, go to asset and select configure components from conformed and from there search for the head mesh and select it. An error will appear if the mesh is not compatible with metahuman topology. Next, select the body component and then select a body type."},{"start":"5:42","end":"6:15","startSec":342.0,"text":"The second step is to go to the mesh to metahuman drop down option and select auto rig metahuman identity, skeletal mesh and full metahuman, as we will want the source assets for the final fitting. The metahuman identity will be solved using the input mesh we have assigned, which will result in the geometry and joint positions closer to our target delta and across all LODs. When working with stylized characters such as this one, there will still be more work to do."},{"start":"6:15","end":"6:54","startSec":375.0,"text":"One of the things that can help to reduce the amount of work that is needed is to use the metahuman creator. For stylized characters such as atomic savage, the region influence in the metahuman creator can help save considerable time, but at the expense of losing likeness. The top two images show us what the tear duck region of the head mesh looks like with and without using the region influence. The tear duck region of the head mesh as well as the majority of the additional assets such as the cartilage and the eye shell are fitted to the eye region."},{"start":"6:54","end":"7:28","startSec":414.0,"text":"And these may also need to be manually adjusted if the region influence is not used to correct issues. The mouth region, particularly the lip contact, is another area that may need adjusting. Again, the region influence will save considerable time, but as demonstrated in the animated gift below, at the expense of losing likeness. Once you are finished making adjustments in the creator, the last step is to download the source assets in order to complete the final fitting process."},{"start":"7:28","end":"7:37","startSec":448.0,"text":"Now, let's move on to the next section where we will go over best practices for finalizing the fitting process."}],"12_FittingGeometry_PT1":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"In this section, we will go over the final fitting process before DNA calibration is used. We will go over how to assemble and prepare the assets for fitting. In the following section, we will continue with best practices for the final fitting process. The goal of the fitting process is to get the head geometry and the additional assets fitted as close to the target delta as possible. In by downloading the source assets of your character from the Quixel Bridge standalone"},{"start":"0:33","end":"1:06","startSec":33.2,"text":"application. Then assemble the necessary geometry for the final fitting process. If you would like to inspect the assets in the Maya scene I will be showing, it is located in the source files folder of our course, inside of the atomic savage folder, in the folder named Modeling Assets. Now let's jump into Maya to review the assets. Inside of the Maya scene named Atomic S01 fitting, over here on the left in the Outliner"},{"start":"1:06","end":"1:36","startSec":66.2,"text":"you will find all of the assets that have been used for this character. The first group over here named Original Metahuman Creator contains the Atomic Savage head geometry assembled from the source assets. This includes the head LOD2 and LOD0 along with all of the LOD0 additional assets. I'm going to bring the head mesh closer to view to show you that for this version the region influence has been used on the eye area."},{"start":"1:36","end":"2:08","startSec":96.4,"text":"In the Outliner, right below this there is a version of the head geometry that demonstrates what the polygon flow of the eye area looks like without using the region influence. Now let's take a look at the original ZBrush head sculpt. Over here in this group named ZBrush Initial Fitting, this mesh here is the original head sculpt and here we have the version that the Metahuman Topology has been fitted to. This asset is the target delta."},{"start":"2:08","end":"2:43","startSec":128.9,"text":"Now the assets that would need to be assembled in a new Maya scene include the fitted mesh, this here is a copy of it and I will hide it for now along with all of these right below that I am selecting. These assets include the head LOD0 mesh and the head LOD2 mesh. The LOD2 mesh is used for easier fitting and manipulating polygons. Then we have all of the LOD assets which include the teeth, the saliva, the eye shell, the"},{"start":"2:43","end":"3:16","startSec":163.1,"text":"eye right, the eye left, the cartilage, the eyelashes and the eye edge. Finally over here we have a copy of the left and right eye. With the assets assembled, the next step is to prepare these assets for the final fitting process. I am going to hide the fitted head until we meet it. Something to note is that the following steps I will show have already been performed but I will go through them in order to demonstrate what this process looks like."},{"start":"3:16","end":"3:49","startSec":196.1,"text":"So let's begin by preparing these assets for fitting. The first step is to wrap all of the additional assets and the head LOD2 to the head LOD0 mesh. To do this, select head LOD2 and all of the additional assets first, then select LOD0. Next go up here to deform, then go to wrap and open up the wrap options. Leave everything at default and select apply."},{"start":"3:49","end":"4:20","startSec":229.2,"text":"As mentioned, these steps have already been performed, I am just demonstrating these for you. The second step is to blend shape the head LOD and wrapped assets to the fitted head. To do this I will unhide the fitted head mesh. Now select the fitted head mesh first and then select head LOD0 that everything has been wrapped to, then go up here to deform and go to blend shape and open up the blend shape options."},{"start":"4:20","end":"4:52","startSec":260.2,"text":"Leave everything at default and apply. Now if I press G to bring up the shape editor, we can use the slider to inspect the result of the blend shape. As a best practice, select all of these assets and then go to mesh display up here and select unlock normals and then select soften edge."},{"start":"4:52","end":"5:22","startSec":292.2,"text":"Now I am going to hide the fitted head again. If we inspect these assets, such as the eye shell, I will bring this closer to view. These will need to be adjusted vertex by vertex to the fitted head mesh. I am going to hide the eye shell and select the right and left eye. These have been warped from the wrapping process, hence this is why we keep a copy of the eyes."},{"start":"5:22","end":"5:53","startSec":323.0,"text":"If you wish to inspect the final fitted assets, they are in the group labeled final fitted head additional geo. Now we have just gone over the assembly and preparation process for the final fitting process. Let's do a quick review of the steps we just covered before moving on. The goal of the final fitting process is to fit the metahuman identity solve and its additional head geometry assets to the fitted LOD0 head mesh."},{"start":"5:53","end":"6:26","startSec":353.4,"text":"To get started, begin by assembling the assets that will be needed for the final fitting. Download the source assets from the Quixel Bridge standalone application and assemble the head geometry in a new scene. The meshes include the original LOD0 head mesh of the 3D model which is the target delta, and the metahuman identity solve, the LOD2 head mesh and the LOD0 head mesh along with all of the additional LOD0 head geometry assets which include the teeth, the saliva, the eye"},{"start":"6:26","end":"6:59","startSec":386.9,"text":"shell, the left and right eye, the cartilage, the eyelashes and the eye edge. With everything assembled, the next step is to prepare the assets for fitting. The first step is to wrap everything to the LOD0 head mesh. Select the LOD2 head mesh and the additional assets, then select the LOD0 head mesh. Go to deform and select wrap. The reason why we wrap LOD0 and LOD2 is because LOD2 makes it easier for fitting and manipulating"},{"start":"6:59","end":"7:34","startSec":419.6,"text":"polygons. Subdividing LOD2 results in LOD0. Once everything has been wrapped to LOD0, the next step is to create a blend shape between the wrapped assets and the fitted 3D head model. To blend shape the wrapped assets to the fitted 3D head model, first select the fitted head model and then select the LOD0 head mesh. Then go to deform and select blend shape. As a best practice, you can unlock the normals and soften the edges by selecting the wrapped"},{"start":"7:34","end":"8:04","startSec":454.7,"text":"geometry, then going to mesh display and selecting unlock normals and soften edge. Before you create the blend shape, ensure you keep a copy of the eyes as they will become deformed during the process. The wrapped eyes will be used as a positional reference later on. We have just gone over the steps for assembling and preparing the neutral pose assets for the final fitting process. In the next section we will continue going over the final fitting process."}],"13_FittingGeometry_PT2":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this section, we will continue with the remainder of the steps for the final fitting process. First, we will look at best practices for positioning the eye geometry and capturing the eye gaze. We will then look at how to approach manipulating the tear duct region polygons of the head mesh and all the additional assets. We will also go through the steps for preparing the body skeleton Maya file that is needed before DNA calibration is used."},{"start":"0:31","end":"1:01","startSec":31.0,"text":"So let's resume with the final fitting process by looking at how to position the eye geometry. Since the majority of the additional assets are fitted to the eye region, it is important to position the eyes first. The clean copy of the eyes should be positioned while using the wrapped eyes as a reference. When positioning the eyes, ensure the eye gaze is correct. You can use the pupil and iris textures as a reference."},{"start":"1:01","end":"1:35","startSec":61.0,"text":"Combine the sclera and iris textures which are located in the metahuman face textures folder in Unreal Engine with the iUV coordinates texture for Maya. On the UV coordinates texture, the fifth loop is where the iris should be. Once the eyes have been positioned and the eye gaze is correct, the next step is to inspect and adjust the tear duct region of the head geometry. The tear duct region is where the inner eye edge of the eyelid and the eyeball geometry make contact."},{"start":"1:35","end":"2:10","startSec":95.0,"text":"We can see the precise location in the animated GIF. If the polygon flow around the eye region has deviated, the vertices may need to be manually moved and repositioned. Use the head LOD2 to make adjustments and ensure all the edges and loops correspond to a standard LOD0 preset metahuman, especially when manipulating polygons in high density areas. Once the eye region of the head mesh has been manually adjusted, the additional assets can be fitted vertex by vertex."},{"start":"2:10","end":"2:47","startSec":130.0,"text":"In the images on this slide, we can see what each of the geometry assets look like before and after the fitting process. For the head mesh, ensure the tear duct region is correct. For the eye edge, it should fit the eye geometry. The cartilage should fit around the eyelids and lacrimal interior. The eye edge should be concave and not overlap with the eyeball geometry, and the eyelashes should be within the cartilage area. Once everything has been fitted, correctly name and export the geometry assets individually as OBJ files."},{"start":"2:47","end":"3:20","startSec":167.0,"text":"With the fitted geometry ready to be used with DNA calibration, the final asset that will be needed is the prepared body skeleton Maya file. Let's jump into Maya and go through the steps of preparing this asset. Inside of Maya, I will be demonstrating how to prepare the body skeleton Maya file, and I will be using a portion of the Unreal Fest scaling script for this. We will be going over DNA calibration in the next section, so don't worry, we will go through how to set this up and use it later on."},{"start":"3:20","end":"3:55","startSec":200.0,"text":"Over here, I've opened up the script editor. In the file explorer, I have the Unreal Fest folder open. The scaling script is located in the script folder and it is named UFScale. I copied the contents of the script and pasted it in a new Python window that I created by using this plus sign and selected Python. To use this script, for the root directory, point it to the location of the DNA calibration folder, which in my case is my C drive."},{"start":"3:55","end":"4:25","startSec":235.0,"text":"I have changed the backward slash to a forward slash. The work directory is pointed to the location of the Unreal Fest folder, which is on my D drive. Now to prepare the body skeleton Maya file, the first step is to open up the body rig Maya file of the character you are using. I have opened up the Maya scene for the female short underweight body rig. The second step is to delete the geometry and driver skeleton."},{"start":"4:25","end":"4:57","startSec":265.0,"text":"I'm going to select the geometry and delete this. Next, I will select the driver skeleton and delete this. The third step is to unconstrained the skeleton. One way to do this is to use a portion of the Unreal Fest DNA calibration scale script. As mentioned, we will be going over how to use DNA calibration later, but for now I will be showing what command you can run to unconstrained the skeleton."},{"start":"4:57","end":"5:32","startSec":297.0,"text":"I'm going to select the root. Inside of the script editor, I will select the first portion of the script and initialize it by right clicking on it and selecting execute. Now that this is in memory, I'm going to make sure that the root is selected and I will scroll down here to step three, where it says scale body and unbind driver skeleton. And I will select this portion here from line 44 to 46, then right click and select execute to unconstrained the skeleton."},{"start":"5:32","end":"6:09","startSec":332.0,"text":"The third step is to delete joints that are not needed. I will delete the skeleton and unhide the root. The next step is to collapse this and delete the legs and lower arms. We do not need the thighs, so I will select these and delete them. We also do not need the lower arms, so I will collapse the spine and then the clavicles and the upper arms."},{"start":"6:09","end":"6:44","startSec":369.0,"text":"I'm going to select the left lower arm and lower arm twists and then the right lower arm and lower arm twists and delete these. And this is what is needed for the prepared body skeleton Maya file that will be used with DNA calibration. The last step is to save the scene and rename it however you wish. Now let's do a quick review of the steps we just covered before we move on."},{"start":"6:44","end":"7:19","startSec":404.0,"text":"The body skeleton Maya scene is needed when using DNA calibration to export the head LODs as FBX. The workflow for preparing the body skeleton Maya file was showcased step by step in the 2023 Unreal Fest DNA calibration deep dive. And the link to the presentation can be found in the resources slide of this course. To summarize the workflow, begin by going to the source assets folder of your character and locate the body rig Maya scene that has your character's body proportion."},{"start":"7:19","end":"7:53","startSec":439.0,"text":"From there, the first step is to delete the geometry and driver skeleton. Then select the root and break the constraints. You can use the Unreal Fest scaling script to do this. Paste the entire script into the script editor, initialize the first portion of the script and then run step 3 with the root selected. Then unhide the root and then delete the legs and the lower arms and lower arm twists joints. The last step is to save the scene and rename it however you wish."},{"start":"7:53","end":"8:08","startSec":473.0,"text":"Now with the fitted geometry OBJ files and body skeleton Maya scene, we are ready to use these with DNA calibration. In the next portion of our course, we will delve into setting up the DNA calibration repository."}],"14_DNACalibSetup":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"When finalizing customizations to the MetaHuman Neutral Pose, DNA calibration can be used for updating MetaHuman DNA. In this portion of our course, we delve into setting up the MetaHuman DNA calibration library. So let's get started with the requirements for using the library and how to set it up. In this section, we will be setting up the DNA calibration library. We will also look at the folder contents and become acquainted with some of the scripts."},{"start":"0:32","end":"1:08","startSec":32.7,"text":"First, let's review the instructions and requirements for using the repository. To get started with setting up the DNA calibration repository, sign in to GitHub and then locate the MetaHuman DNA calibration repository. Next, download the latest release and then unzip the folder. Place the DNA calibration folder in a desired location. In my case, I saved it to my C drive. Next, go to Edit Environmental Variables and create a new variable named Maya Module Path"},{"start":"1:08","end":"1:42","startSec":68.3,"text":"in all caps as shown on the slide. Then set the path location of the DNA calibration folder as the variable value. Python 3.9 or higher is required for Maya versions 2023 or later, and the Quixel Bridge Maya plugin needs to be installed. Now that we have reviewed the setups and requirements, let's go over the folders and files of the repository. Inside of the DNA calibration folder, the main files we will be using are located in the Data"},{"start":"1:42","end":"2:16","startSec":102.6,"text":"folder and Examples folder. The Data folder contains the files that are needed to load the DNA. The Body folder is where the prepared skeleton Maya files are placed, and the DNA files folder is where the DNA files are placed. Other important files include the GUI and Analog GUI Maya scenes and the additional assembly script. At the time of the release of MetaHuman Animator in 2023, the number of joints and expressions increased with the latest version of MetaHuman."},{"start":"2:16","end":"2:47","startSec":136.7,"text":"The MH4 folder contains the GUI scene and assembly script for these current rigs. Update the paths in the scripts you use so that they switch to the new rig version. The Examples folder contains scripts with common commands. We will be looking at the DNA viewer run in Maya script, the grab changes from scene and propagate to DNA script, and the export FBX script. The Unreal Fest script is also included in the repository."},{"start":"2:48","end":"3:20","startSec":168.5,"text":"And you will find the Assets and Scripts showcased at the Unreal Fest MetaHuman DNA calibration deep dive presentation. Now let's review the scripts that we will be using. The three scripts that we will be using are located in the Examples folder. The DNA viewer run in Maya script allows you to use a GUI window in Maya to create a scene with a functional rig. We can use this to load a DNA file and view the MetaHuman face inside of Maya."},{"start":"3:21","end":"3:51","startSec":201.5,"text":"The grab changes from scene and propagate to DNA script allows you to transfer changes from the Maya scene to the DNA file. If we want to adjust the head geometry, we can first save the current state, make our changes, and then save those changes and update the DNA file. The export FBX script allows you to generate a functional rig in a new Maya scene, and then export the head LODs as FBX files."},{"start":"3:51","end":"4:18","startSec":231.8,"text":"All of the scripts in the Examples folder contain step-by-step instructions at the beginning. In the Unreal Fest Script folder, you will find that these scripts include a combination of different functions bundled into one script, including commands from the Examples folder. In the next section, we will go through a few simple use case scenarios for using the DNA calibration library with Autodesk Maya."}],"15_DNAViewer":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In this portion of our course, we will go through a few simple use case scenarios using the DNA calibration library in Maya. Using the scripts from the examples folder, we will use the DNA viewer runinMaya script to view metahumanDNA. We will use the Propagate changes from Scene to DNA script to EditDNA files for exporting the head LODs as FBX. So let's get started with DNA viewer."},{"start":"0:34","end":"1:08","startSec":34.0,"text":"The DNA viewer runinMaya script allows us to look at a DNA file and do things such as choose what LODs we want to assemble and what properties we want in them. Now let's switch over to Maya and go through the steps for using this script to read a DNA file and assemble a functional rig. Inside of a new Maya scene, I have opened up the script editor and docked it over here. Over here, in File Explorer, I have the DNA calibration examples folder open."},{"start":"1:09","end":"1:41","startSec":69.0,"text":"I will select the DNA viewer runinMaya script and then right click on it and select Open with Notepad. I will copy all of this and in the script editor, I will use the plus sign over here to add a new Python window. Then I will paste the script here. Next, I will select all of this, right click and select Execute."},{"start":"1:41","end":"2:15","startSec":101.0,"text":"The DNA viewer window will pop up. Now the first thing we will do is go over here to assign the path of the DNA file we want to look at. I will click here and search for the file. The DNA files will be located in the DNA calibration data folder in the folder named DNA files. I am going to select the DNA file named Lena that I have added from the Unreal Fest Zip and now I can select Load DNA."},{"start":"2:15","end":"2:51","startSec":135.0,"text":"Next, we can select what LODs we want to assemble and what properties we want in them. For example, if we only want to assemble LOD 0 and the head mesh only, we can select only those two things. To assemble a fully functional rig, we will want to select all of the LODs and all of their contents. We can do this by choosing Select All Meshes. Now for the build options, I will check on Joints, Blend Shapes and Skin Clusters."},{"start":"2:51","end":"3:22","startSec":171.0,"text":"Notice that the rig logic will be grayed out. Let's go here and assign the GUI path. This is located in the data folder and since we are using the latest version of MetaHuman, I will open up the MH4 folder and select the GUI that's in here. This will load the faceboard and selectable controls. Next, we will assign the Analog GUI path."},{"start":"3:22","end":"3:53","startSec":202.0,"text":"This is located in the data folder right here. This loads the GUI for the controls affecting the I direction. Next, we will assign the Additional Assembly Script. This is located in the data folder and again since we want to use the latest version of MetaHuman, I will open up the MH4 folder and select this one. Now that we have assigned these, the RigLogic option can now be checked on"},{"start":"3:53","end":"4:23","startSec":233.0,"text":"and this will connect all of the functions of the rig giving it behavior. We can now select Process. We will get a warning from Maya asking us if we want to save the existing scene. I will select Discard. This will begin to assemble the full rig and everything in the DNA file and this may take a moment."},{"start":"4:23","end":"4:56","startSec":263.0,"text":"Now that it is loaded, I can minimize this and over here we can see the Lena DNA file. Since we enabled RigLogic, we can select a control and we'll see that when we move it, the face is fully functional. And this is how you can use the DNA viewer run in Maya script. Now let's do a quick review before we move on."},{"start":"4:56","end":"5:26","startSec":296.0,"text":"We just went through the steps of using the DNA viewer run in Maya script. This script allows us to visualize a DNA file, choose what LODs we want to assemble and what properties we want in them. To read and create a functional rig in Maya, start by pasting the entire script in the script editor and then run the entire command. Once DNA viewer pops up, assign the path of the DNA file you wish to view."},{"start":"5:26","end":"5:57","startSec":326.0,"text":"This will commonly be located in the data DNA files folder. Then select low DNA. Next, select the LODs and the contents you want to assemble. If you want all the LODs, then select all meshes. Next, choose the build options. To assemble a fully functioning rig, check on joints, blend shapes and skin clusters. To enable rig logic, you will need to assign the GUI path,"},{"start":"5:57","end":"6:31","startSec":357.0,"text":"which is located in the data folder. This will load the faceboard GUI and as mentioned, you will want to use the updated rig, so select the GUI file located in the data MH4 folder. Assign the analog GUI path, which is the GUI for the controls affecting the eye direction. And then assign the additional assembly script path, which is used for final tweaks or metadata. And this is located in the data MH4 folder for the updated rigs."},{"start":"6:31","end":"6:58","startSec":391.0,"text":"Once all of these paths have been assigned, rig logic and the build options can be enabled. This will connect all of the functions of the rig. Finally, you can select process, and this will assemble the full rig and everything in it. Now, let's move on to the next section, where we will use the propagate changes to DNA script, and make some minor modeling changes to the rig, and edit the DNA file."}],"16_EditNeutral":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"In this section, we will go over the Propagate changes from Scene to DNA script. This script allows us to save the deltas between the current and new vertex and joint positions of meshes, and then saves those changes to the DNA file. We will look at two simple use case scenarios using this script to edit the neutral pose. In the first scenario, we will make some simple changes to the vertex positions, and in the second scenario, we will make some minor modeling changes using the joints and skin clusters."},{"start":"0:36","end":"1:09","startSec":36.0,"text":"So, let's jump into Maya and begin by taking a look at the script and going over the workflow. Inside of Maya, I have taken the Propagate changes from Scene to DNA script from the examples folder, and I have pasted it in the script editor in a new Python window. This has step-by-step instructions at the beginning. To summarize the workflow for using this script, begin by loading the DNA file in a new Maya scene using the DNA viewer run in Maya script."},{"start":"1:09","end":"1:40","startSec":69.0,"text":"Then, save the current vertex and joint positions, make modifications to the neutral pose, and once finished, set the new vertex and joint positions, and update the DNA file to include those changes. To use the script, we will have to input the paths of the files we want to use. If we scroll down to line 50, here we will input the name of the DNA file we are going to use."},{"start":"1:40","end":"2:15","startSec":100.0,"text":"If I go to the DNA files folder, this is the same name of the DNA file I want to use. You can use Ada or Taro as those are already in the DNA files folder. Next, we will need to specify the root directory where the DNA calibration repository is located. In my case, it's in my C drive. Something to note is that the backward slash needs to be replaced with a forward slash. The output path is created through commands, and it will by default be named output."},{"start":"2:15","end":"2:45","startSec":135.0,"text":"This is where our modified DNA file will be saved. Some of these paths we do not need to worry about as they are already set up for us, such as the path of the DNA files folder and the analog GUI folder. As mentioned earlier, if we wish to use the newer version of MetaHumans with the additional face controls, we would change the path of the GUI and additional assembly script to point to those assets in the MH4 folder."},{"start":"2:45","end":"3:16","startSec":165.0,"text":"You would add MH4 forward slash here for the GUI, and then do the same for the assembly script path. If you do not use the older version of MetaHuman, you can replace the GUI file and the additional assembly script file from the MH4 folder with those in the main data folder so that you do not have to keep updating the paths for these, which is what I have done. This is the only input that is needed for this script."},{"start":"3:16","end":"3:50","startSec":196.0,"text":"Now, before we use this script, let's do a quick review of what we just covered. We can use the Propagate changes from Scene to DNA script to edit the neutral pose. This script records the current vertex and joint positions for all meshes. Once changes are made, it saves the delta between those two states and updates the DNA file. The workflow is as follows. First, run the commands that save the current vertex and joint positions of the head mesh."},{"start":"3:50","end":"4:22","startSec":230.0,"text":"Then, make modifications to the neutral mesh. When finished, run the rest of the commands to set the new vertex and joint positions, and then update the DNA file to include those changes. For the script input, on line 50, enter the name of the DNA file you wish to edit. For the root directory, enter the path that points to the DNA calibration folder and make sure you use a forward slash."},{"start":"4:22","end":"4:45","startSec":262.0,"text":"Then, update the paths for the GUI and additional assembly script to point to the MH4 folder if using the newer versions of MetaHumans. Now that we have an idea of the workflow and what input we need to use, in the next section we will go through executing the various commands and will edit the neutral pose."}],"17_EditNeutralMesh":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this section, we will be making minor changes to the metahuman neutral pose by adjusting vertex positions using the Propagate changes from Scene to DNA script. We will first assemble the scene for this specific scenario using the DNA viewer run in Maya script. Then we will save the current vertex and joint positions, adjust the mesh vertex positions, and then save those changes to the DNA file."},{"start":"0:31","end":"1:07","startSec":31.2,"text":"Let's return to Maya and go through this workflow. Back inside of Maya, in a new python window, I have added the Propagate changes script with the correct input for the files and paths. To use this script to edit the neutral pose, first we will need to assemble the scene using the DNA viewer run in Maya script. I have the DNA viewer run in Maya script over here in this window. I'm going to select all of this and then right click and select execute."},{"start":"1:07","end":"1:40","startSec":67.2,"text":"In the DNA viewer window, I'm going to select the path of the DNA file. I will go to the DNA calibration folder and then open up the data folder and then open up the DNA files folder. I will select the DNA file named lina and then select open. Now I will select load DNA. Next, I want to assemble all of the LODs and their contents, so I will choose select all"},{"start":"1:40","end":"2:13","startSec":100.2,"text":"meshes. For the build options, we will only need to load the joints for this scenario. Now we can select process and I will select discard any changes for this scene. Now that this is assembled, I can minimize this window and go to the top view. We can see that everything we chose to be assembled has been loaded into this Maya scene."},{"start":"2:13","end":"2:49","startSec":134.0,"text":"Down here in the bottom right in the display panel, since I do not need all of the lower LODs visible, I will hide everything except for LOD 0. Now the first step of this script is to save the current affairs. To do this, in the script editor, I will switch over to the Python window with the Propagate Changes script. In the Outliner, I will select the head group. Then in the script editor, I will scroll past all of this code."},{"start":"2:49","end":"3:25","startSec":169.4,"text":"We have already changed the input for these paths. I am going to go all the way down to the end of sub-step 3 where it says loaded data end of third step. I am going to select all of this and go all the way to the top and now I will right click and select execute. Once this process is complete, as a best practice, I am going to save this Maya scene by going"},{"start":"3:25","end":"3:57","startSec":205.0,"text":"to File, Save Scene As and since I have already gone through this process, I will select the Save Current Affairs scene and overwrite it. Now before we move on, let's do a quick review of the steps we just went through. We begin this workflow by first assembling the scene using the DNA viewer run in Maya script. First, we will load the DNA file located in the DNA files folder."},{"start":"3:57","end":"4:29","startSec":237.8,"text":"Next, we want all of the LODs and their contents so we will click on Select All Meshes. And in the build options, we only need to load the joints and then select process. This will assemble a new Maya scene. Next we will want to save the current affairs. For this step, we want to save the current vertex and joint positions of Meshes. To do this, in the script editor, with the Python window that has the entire script pasted"},{"start":"4:29","end":"5:02","startSec":270.0,"text":"in there and configured with the name of the DNA file and the paths to the root directory and updated GUI and assembly script, we will select the head group in the outliner and then run the entire script up to the end of step 3 which reads loaded data, end of third step. As a best practice, we want to save this Maya scene. Now let's return to Maya and continue by making some adjustments to the vertex positions."},{"start":"5:02","end":"5:38","startSec":302.4,"text":"Back inside of Maya, over here in the show panel, I'm going to uncheck joints. Now before I start moving vertex positions, let's say I want the changes that I make to also be on LOD 1, 2 and 3. In this case, it would be easier if I wrap those other LODs to LOD 0 first so that the changes I make to LOD 0 will be transferred to those other LODs. To do this, in the outliner, I'm going to collapse the geometry group."},{"start":"5:38","end":"6:16","startSec":338.8,"text":"Since I'm going to be making changes to LOD 0, 1, 2 and 3, I'm going to go here and collapse the head LOD 0 group, the head LOD 1 group, the head LOD 2 group, and the head LOD 3 group. To wrap these LODs to LOD 0, select the head LOD 1 mesh and then select the head LOD 0 mesh. Go to deform and open up the wrap options to make sure everything looks okay."},{"start":"6:16","end":"6:49","startSec":376.3,"text":"And now select apply. Repeat this for LOD 2. Select it and then select LOD 0. In the wrap options, select apply and repeat this one more time for LOD 3. And then select LOD 0 and select apply. As a best practice, I'm going to save this Maya scene by going to file, save scene as,"},{"start":"6:50","end":"7:21","startSec":410.1,"text":"and overwrite the file named modify mesh since I've already gone through this workflow a few times. Now with everything wrapped to LOD 0, we can edit the mesh. I will select the head LOD 0 and adjust the position of the head. I will switch from object mode to vertex. I'm just going to select this random section of the nose region, switch over to translate,"},{"start":"7:26","end":"7:57","startSec":446.0,"text":"and then simply move these vertices. The purpose here is to show how this script can be used when we change vertex positions. I will switch back to object mode. Now we can see this minor adjustment to the nose area. If I go down here to the display panel and turn off LOD 0 and turn on LOD 1, we can see that this adjustment is there."},{"start":"7:58","end":"8:29","startSec":478.4,"text":"And it is also there for LOD 2 and LOD 3. Since we did not wrap the other LODs, those adjustments will not be transferred to them. I'm going to save the scene again by going to file, save scene. Now before we move on, let's review these steps. When making adjustments to the neutral pose by moving vertices, wrap the LODs you wish to"},{"start":"8:29","end":"8:59","startSec":509.9,"text":"change to LOD 0 first so that they can all be adjusted at the same time. To do this, select the head LOD 1 mesh and then select the head LOD 0 mesh, go to deform and select wrap. Repeat this for all of the head LODs you wish to make changes to. Then edit the vertex positions of the head LOD 0 mesh and check that those changes are visible across the LODs that were wrapped."},{"start":"9:00","end":"9:32","startSec":540.6,"text":"Now let's return to Maya and continue. Back inside of Maya, before we run the rest of the script to save these changes to the DNA file, we will want to delete the wrap nodes. I will first demonstrate this by selecting the head LOD 0 mesh. And then we'll select the first head LOD base mesh wrap node. Then I will go to edit, select delete all by type and select history."},{"start":"9:33","end":"10:06","startSec":574.0,"text":"Now that I have demonstrated this step, I'm going to select the head LOD 0 mesh and then select the rest of the wrap nodes and repeat this step. I will go to edit, delete all by type and select history. We can now delete the wrap nodes. I will go here in the display panel and I will make LOD 1 visible just to make sure that when I delete the wrap node, the changes I made are still there. So with the LOD 1 wrap node selected, I will delete it."},{"start":"10:07","end":"10:38","startSec":607.2,"text":"We can see the change I made is still there. Repeat this step for LOD 2. Making it visible down here and then deleting the wrap node over here. And finally repeat this for LOD 3. Make it visible down here and then delete the wrap node over here. I will save the scene again. Before we move on, let's review these steps."},{"start":"10:40","end":"11:13","startSec":640.8,"text":"Before saving the changes to the DNA file, delete the wrap nodes and check that the changes are still visible on the other LODs. To do this, select the head LOD 0 mesh and then select all the base mesh wrap nodes. Go to edit, delete all by type and select delete history. Then delete each wrap node while making sure those changes are still visible by toggling through the LODs in the display panel."},{"start":"11:13","end":"11:43","startSec":673.5,"text":"Now let's return to Maya and continue with the rest of this workflow. Back inside of Maya, we can now save the changes that have been made to the DNA file. I will select the head group and I will go back here to show and make the joints visible again. With the head group selected, we will go to the script editor and scroll all the way down here below sub-step 3."},{"start":"11:46","end":"12:18","startSec":706.2,"text":"We have completed step 4 which is to modify the rig and now we can execute step 5 where we see propagate changes to DNA. This portion will update the vertex and joints to their new positions and it will save the changes to the DNA file. This portion will assemble a new Maya scene with the updated DNA. Select everything and execute it. This script will create an output folder and will add the modified DNA file in there."},{"start":"12:22","end":"12:51","startSec":742.8,"text":"Once the new Maya scene has loaded, we can see our modified DNA and the changes we made. We can go here and toggle through the LODs to make sure that the changes have been saved to the other LODs. It is worth mentioning something about this workflow where we move the vertex positions. I will reposition the head and I will make the joints visible over here."},{"start":"12:53","end":"13:26","startSec":773.2,"text":"The surface joints are positioned by vertices. When pronounced changes to the vertex positions are made, the surface joints may need to be manually repositioned. This is because surface joints preserve the volume for lower LODs. You can either manually reposition them or use a script to automate this process. Now this script does not have that command. There is a script that does. I will search for it in the Python windows I have open."},{"start":"13:27","end":"13:57","startSec":807.2,"text":"It is this one which is the UnrealFest calibration script. This contains commands that save the current surface joint positions as a JSON file. All of these here are the surface joints that it loads into memory. Once the vertex positions are moved, the surface joints will snap to the new vertex positions. This demonstrates how you can use code from other scripts such as this one so that you do not have to manually reposition these."},{"start":"13:58","end":"14:28","startSec":838.6,"text":"Now let's do a quick review of what we just covered. Once you are finished making changes to the vertex positions of the neutral pose, to save the new vertex and joint positions and update the DNA, select the head group, and then run the rest of the lines. And then run the rest of the script from step 5 that reads propagate changes to DNA. This will update the joints and vertex to their new positions."},{"start":"14:28","end":"15:00","startSec":868.8,"text":"And these changes will be saved in a new DNA file in the output folder the script creates. This will also assemble a new Maya scene so that you can inspect the updated DNA. If changes to the vertex positions are pronounced, the surface joints may need to be manually repositioned. Surface joints preserve the volume for lower LODs. The UnrealFest calibration script contains commands that save the current surface joint positions"},{"start":"15:00","end":"15:31","startSec":900.5,"text":"as a JSON file. And once changes to the vertex positions have been made, it will snap the surface joints to the new vertex positions. Saving you time and having to manually move them by hand. This is a great example of how you can use code from other scripts. Now let's move on to the next section where we go over another simple use case scenario that uses the propagate changes from scene to DNA script"},{"start":"15:31","end":"15:36","startSec":931.9,"text":"to make minor modeling changes using the joints and skin clusters."}],"18_EditNeutraLJoints":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"In this section, we will go over a simple use case scenario using the Propagate changes from Scene to DNA script to make some minor modeling adjustments to the neutral head mesh using the joints and skin clusters. This approach might be useful if, for instance, you need to reposition the joints around the neck region to fit the head to a different body, or you simply want to make some minor modeling changes."},{"start":"0:30","end":"1:01","startSec":30.3,"text":"We will assemble the scene for this specific scenario using the DNA viewer run in Maya script. Then, we will save the current positions of the vertex and joints. We will make a simple modeling adjustment using the joints and skin clusters, and then save those changes to the DNA file. So let's return to Maya and go through the steps. Back inside of Maya, we will first assemble the scene using the DNA viewer run in Maya"},{"start":"1:01","end":"1:35","startSec":61.0,"text":"script. I will switch to the Python window with the DNA viewer run in Maya script, and then select everything and execute it. In the DNA viewer window, assign the path to the DNA file. In the DNA files folder, I will select the DNA file named Elina, and then load the DNA. For this example, I want to assemble all of the LODs and their contents, so I will click"},{"start":"1:35","end":"2:11","startSec":95.8,"text":"on Select All Meshes. In the build options for this workflow, we can load the joints, the blend shapes, and the skin clusters. And now, I will select Process. This will create a new scene, so I will discard any changes. And this may take a moment. Now that the scene has been assembled, I will minimize this window and go to the top view. I'm going to go down here to the bottom right, and will hide everything except LOD 0 for"},{"start":"2:11","end":"2:44","startSec":131.0,"text":"now. In the script editor, I will switch over to the Python window with the Propagate Changes script to save the current affairs. In the Outliner, select the head group. And then in the script editor, I will scroll past all this code and select everything all the way to the end of step 3. With this selected, I'm going to execute this. As a best practice, save this Maya scene."},{"start":"2:44","end":"3:19","startSec":164.7,"text":"Now let's do a quick review of these steps before we move on. We begin the workflow of making adjustments using the joints and skin clusters by first assembling the scene using the DNA viewer run in Maya script. Load the DNA file located in the DNA files folder. We will want all the LODs and their contents, so choose Select All Meshes. In the Build Options, load the joints, blend shapes, and skin clusters, and then select"},{"start":"3:19","end":"3:52","startSec":199.0,"text":"Process. This will assemble a new Maya scene. Next, we will want to save the current affairs. For this step, we want to save the current vertex and joint positions. To do this, in the script editor, with the Python tab that has the entire script pasted in there, select the head group in the Outliner, and then run the entire script up to the end of step 3, which reads Loaded Data, End of Third Step."},{"start":"3:52","end":"4:26","startSec":232.1,"text":"As a best practice, save this Maya scene. Now let's return to Maya and continue with the steps. Back inside of Maya, with everything saved, we can now make some modeling changes using the joints and skin clusters. Something to note is that if you have loaded the DNA file with RigLogic enabled, you will need to break the connections before you make any changes using the joints and skin clusters. Otherwise, you can go directly into making simple modeling changes."},{"start":"4:26","end":"5:02","startSec":266.9,"text":"If RigLogic is enabled, to break the connections, select Spine 4, then go to Select, and select Hierarchy. Go over here to the Transforms, select All the Transforms, and right-click and select Break Connections. We do not need to do this, but I am mentioning this in the event you have assembled the full Rig. Now what's great about this particular workflow is that by moving the joints and skin clusters,"},{"start":"5:02","end":"5:32","startSec":302.2,"text":"those changes will influence the other LODs. I will switch this to Translate. And over here on the head, I'm going to select this group over here on the nose and adjust the nostril area. I will repeat this for the other side. Now this can be especially helpful if perhaps we need to fit the head to a custom body."},{"start":"5:32","end":"6:06","startSec":332.9,"text":"We can move the joints in order to align them with the custom metahuman body skeleton. Another benefit is that these changes are passed down to the lower LODs. In the Display panel, if I toggle through the lower LODs, the changes that were made to LOD 0 will be visible for all of these without having to wrap anything. Now let's do a quick review of what we just covered before we move on."},{"start":"6:06","end":"6:41","startSec":366.6,"text":"To make modeling changes using the joints and skin clusters, if RigLogic is enabled and a full Rig has been assembled, first break the connections, otherwise you can go directly into making modeling changes. To break the connections, select Spine 4, go to Select and select Hierarchy. Select all the transforms, right click and select Break Connections. You can then use the joints and skin clusters to make modeling changes."},{"start":"6:41","end":"7:16","startSec":401.7,"text":"The benefits of this workflow is that changes to the joints influence all the LODs so that there is no need to wrap LODs. This can also be helpful if you need to align the head skeleton with the custom metahuman body skeleton. Once you are finished making adjustments, the next step is to save these changes to the DNA. So let's return to Maya and continue. Back inside of Maya, we are finished making adjustments and now want to save these changes"},{"start":"7:16","end":"7:46","startSec":436.3,"text":"to the DNA file. To do this, select the head group, then in the script editor, go down here and select Step 5 and execute this. This will save the changes to the DNA file and a new DNA file will be added to the output folder that the script creates. A new Maya scene will be assembled so that we can inspect the results."},{"start":"7:46","end":"8:17","startSec":466.5,"text":"In this new Maya scene, I will go to the top view. We can see that the changes we made to the clavicle have been saved and the changes to the nose region are present. And these changes have also been applied to the lower LODs. And this is how we can use the Propagate Changes script to make changes using the joints and skin clusters."},{"start":"8:17","end":"8:48","startSec":497.8,"text":"Now let's do a quick review of the steps we just covered before moving on. Once finished making changes using the joints and skin clusters to save the new vertex and joint positions, and update the DNA, select the head group and then run the script from the fifth step that reads Propagate Changes to DNA. These changes will be saved to a new DNA file in the output folder and a new Maya scene"},{"start":"8:48","end":"9:04","startSec":528.1,"text":"will be assembled so that we can view the updated DNA. In the next section, we will go over how we can export the head LODs of our modified DNA with the Export FBX script from the Examples folder."}],"19_ExportFBX":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"Once the changes to the neutral pose have been saved to the DNA file, in order to bring those changes back into Unreal Engine, the head LODs will need to be exported as FBX files. In this section, we will go over how to use the export FBX script from the examples folder to achieve this. Let's return back to Maya and go through the steps. In a new Maya scene, I have pasted the export FBX script in a new Python window."},{"start":"0:36","end":"1:12","startSec":36.0,"text":"Now, if we wish to use the modified DNA we generated from the previous section, in the DNA calibration folder, inside of the output folder, we will need to copy the modified DNA file. Then, go over to the data folder and place this in the DNA files folder. For this example, I will be using the DNA file named linafinal that was generated for the preset lina from the UnrealFest calibration script."},{"start":"1:12","end":"1:48","startSec":72.0,"text":"You can locate this DNA file in the source files folder of our course in the folder named linaunrealfest. Now, the export FBX script will need a prepared body skeleton Maya file, which should be placed in the body folder inside of the data folder. The body folder will automatically come with two prepared body files for Ada and Taro. Ada uses the female medium normal body weight and the Maya file is named femskeleton."},{"start":"1:48","end":"2:19","startSec":108.0,"text":"Taro uses the male medium normal body weight and it's named mask-skeleton. If your character uses either of these proportions, you can use these files instead of having to prepare one. I have taken the prepared skeleton from the UnrealFest zip folder named lina-skeleton and have placed it in this folder. This is for the female short underweight body proportion without the arms and the legs."},{"start":"2:19","end":"2:49","startSec":139.0,"text":"With the assets we will be using for this script in the data folder, let's configure the paths for this script. In the script editor, on line 36, set the path of the root directory to point to the location of the DNA calibration folder and replace a backward slash with a forward slash. On line 45, add the name of the DNA file that will be used."},{"start":"2:49","end":"3:21","startSec":169.0,"text":"On line 58, configure the path of the body Maya file. This is already directed to the body folder. All you need to do is change this to the name of your body Maya file. This script will create an output folder if one does not already exist and will place the exported fbx files in there. With everything configured, select this entire script and execute it."},{"start":"3:21","end":"3:57","startSec":201.0,"text":"This will take some time to finish, so once it is done we will continue. Now that the process has finished, inside of this Maya scene, we will see the last head LOD that an fbx has been created for, which is LOD 7. Now let's review the steps we just covered before we move on. Once we are finished making adjustments to the metahuman neutral pose and have saved the changes to the DNA file,"},{"start":"3:57","end":"4:29","startSec":237.0,"text":"the next step is to export the head LODs as fbx in order to bring those assets along with the updated DNA file back into Unreal Engine. To do this, we can use the export fbx script that can be found in the examples folder. First, ensure you copy the modified DNA file that is added to the output folder after using the propagate changes from scene to DNA script and paste it in the DNA files folder."},{"start":"4:29","end":"5:01","startSec":269.0,"text":"In Maya, paste the script in a new Python window. The next step will be to configure the paths. We will need to configure the path for the root directory so that it points to the DNA calibration folder. And just remember to replace the backward slash with the forward slash. On line 45, the character name should have the name of the DNA file that will be used. On line 58, assign the path to the prepared body Maya file."},{"start":"5:01","end":"5:33","startSec":301.0,"text":"As mentioned, the feminine and masculine skeletons in the body folder are for the medium normal body weight proportions. Next, select the entire script and execute it. This process will take a bit of time and once it is complete, all of the head LOD fbx files will be added to the output folder. The final step is to assign material placeholders to the head geometry assets for each head LOD."},{"start":"5:33","end":"6:08","startSec":333.0,"text":"So, let's return to Maya and go over this. Back inside of Maya, in the File Explorer output folder, we can see all of the LODs that were exported. In this new Maya scene, I have added the head LOD 0 fbx. Something to note is that this script does not create material placeholders for each of the head geometry assets. When using the script, we will need to create new material placeholders for each of the head geometry assets"},{"start":"6:08","end":"6:41","startSec":368.0,"text":"and use the same naming convention these assets have assigned inside of Unreal Engine. I'm going to hide the joints for a moment. Now, we can manually add a material. Select the head mesh, right click and select Create New Material. Then repeat this for all of the head geometry assets and for all of the other LOD fbx files. I have already created a material placeholder for every head geometry asset for this example,"},{"start":"6:41","end":"7:16","startSec":401.0,"text":"so that as I go through each one, you can see the naming convention for each of these. The head is named Shader Head Shader. This is the name for the teeth, the saliva, the eye left, the eye right, the eye shell, the eyelashes, the eye edge and the cartilage. Since this can be very time consuming, you can write a script to automate the creation, naming and assigning of these shaders."},{"start":"7:16","end":"7:55","startSec":436.0,"text":"The Unreal Fest calibration script has commands that you can use that will do this for you. Now, before we move on, let's do a quick review of what we just covered. If using the export fbx script, all of the head LODs and their assets will need material placeholders assigned. Name each of the geometry assets with the same naming convention as they are labeled inside of Unreal Engine. To do this manually, select the LOD0 head mesh, assign a new material to it and label it Shader Head Shader."},{"start":"7:55","end":"8:30","startSec":475.0,"text":"Something to note is that you can write scripts to automate the creation and naming of Lamberts to speed this process up. Another option is to take the commands from the Unreal Fest calibration script that will create and name materials for all of the head mesh geometry assets and LODs. Now that we have gone through the process of using DNA calibration to make simple changes to the metahuman neutral pose and save those changes to the DNA file and then export the head LODs,"},{"start":"8:30","end":"8:52","startSec":510.0,"text":"the last step is to bring these assets back into Unreal Engine to finalize the rig. As mentioned, we will be continuing this workflow in the metahuman DNA calibration and finalization course. Now let's wrap up this course with some final recommendations and some tips and resources for you to use."}],"20_FinalTips":[{"start":"0:00","end":"0:39","startSec":0.0,"text":"Up until now, we have explored a variety of workflows for modifying the metahuman neutral pose. Using the DNA calibration repository allows us to do a variety of other things which we will explore in the next course. But for now, let's wrap up our course with some tips and resources for you to use as you continue your training with metahumans and Unreal Engine. In this final section of our course, we will go over some tips and resources that you may find helpful when adding DNA calibration to your metahuman customization workflow."},{"start":"0:39","end":"1:13","startSec":39.0,"text":"We will take a look at the latest release of the DNA calibration repository and then review some resources that are related to the topics we covered in this course. So let's jump back into Maya one last time and look at a script from the latest release of the DNA calibration repository that allows us to build a rig with textures. Back inside of Maya, in the DNA calibration folder, you will find in the examples folder a script named DNAViewerBuildRigWithTextures."},{"start":"1:13","end":"1:54","startSec":73.0,"text":"This script allows users to generate a functional rig in Maya with applied textures. The assets this uses are located in the data folder. This script has already been configured to load the eta DNA file from the mh4 folder. I have already assembled eta with Oliver Textures. To use this script, ensure that DirectX11 has been enabled. To do this, go to Preferences, Display, and then to Viewport 2.0 and ensure the rendering engine is set to DirectX11."},{"start":"1:54","end":"2:24","startSec":114.0,"text":"In a new Python window, with the entire script pasted in here, ensure that you have assigned the path for the root directory pointing to the DNA calibration folder. If you wish to use this with your own character, scroll down here and assign the paths for the DNA file and the maps folder. Then select this entire script and execute it."},{"start":"2:24","end":"3:00","startSec":144.0,"text":"Now, let's review these steps before we move on. The latest update of the DNA calibration repository includes support for Maya 2024 and the DNAViewerBuildRigWithTextures script located in the examples folder. This script allows users to generate a functional rig with applied textures. In Maya, ensure that DirectX11 is enabled. To do this, go to Preferences, Display, Viewport 2.0, and select DirectX11."},{"start":"3:00","end":"3:33","startSec":180.0,"text":"In the script editor, paste the entire script in a new Python window. Assign the root directory to point to the DNA calibration folder and then execute the entire script. This will load a fully functional rig with textures. Now, let's finish off with some resources for you to use. All of the online resources and links to some of the tools discussed today can be found by following the URLs on this slide."},{"start":"3:33","end":"4:06","startSec":213.0,"text":"Feel free to pause here or take a screenshot for later reference. You will find the links to the DNA calibration repository on GitHub, the Mesh to MetaHuman tutorial on the Unreal Engine YouTube channel, the UnrealFest 2022 scan and texture-based workflow presentation, and the 2023 DNA calibration deep dive presentation. This brings us to the end of the MetaHuman fitting and DNA calibration course."},{"start":"4:06","end":"4:35","startSec":246.0,"text":"In the next course, we will continue by exploring more advanced use cases using the DNA calibration library. We will also go through the steps of bringing the modified assets back into Unreal Engine in order to finalize the changes of our MetaHuman characters. I want to thank you for spending your time with me, and I hope that these videos help you as you continue working with MetaHumans in Unreal Engine."},{"start":"4:36","end":"4:42","startSec":276.0,"text":"Thank you for watching."}]},"218.01":{"01_Introduction_v02":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hello and welcome to your Unreal training. In this section, the ICVFX calibration, we'll be covering lens data and mapping. My name is Kevin Miller and I am your instructor for this two-part series and in this course, we will cover calibration, camera configuration, camera hardware, media profile implementation. We will do an overview of the tracking solutions, talking about the plugins and the system options that you have available to you. We will also talk about camera control systems and create a virtual live link subject. We'll talk a little bit about the time data monitor"},{"start":"0:30","end":"0:41","startSec":30.8,"text":"and adjusting sync and timecode, then we'll walk through lens file creation and go through our lens distortion mapping. In the second course that follows this, we will cover our nodal point calibration as well."}],"02_OverviewCalibration_v02":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"Now let's begin with another view of calibration. So you're probably wondering, why is calibration required? Well, in order to create accurate compositions from CG renders and live video in Unreal Engine, a virtual camera that accurately simulates the physical camera used to capture the real-world video footage is required. This is also really useful if you're going to do any kind of set extension. If you don't do lens calibration before you do any of your set extension, you're not going to have the data necessary to pass on to the departments requiring that information in order to complete your shots."},{"start":"0:35","end":"1:05","startSec":35.0,"text":"The virtual camera position and orientation in these situations must closely match the position and orientation of the physical camera and the physical camera tracking information that must match the exact timing of the video feed to ensure each video frame is accurately synced to the position and orientation of the camera at any given time. Now, when completed correctly, it is possible to evaluate the calibrated lens file for any focus and zoom position by interpolating between the stored focus and zoom points."},{"start":"1:05","end":"1:38","startSec":65.0,"text":"Now as we go through the calibration process, the camera calibration and OpenCV lens distortion plugins allow Unreal Engine to model the physical lens distortion needed to accurately align the virtual camera to the physical camera and introduces the lens file asset used to store all of the calibration data for camera and lenses. One thing to note is that the calibrated lens data can vary depending on the camera's focus and zoom. In order to achieve a high quality calibration, multiple focus and zoom points should be captured during the calibration process."},{"start":"1:38","end":"2:11","startSec":98.0,"text":"Now, before we get started, I do want to jump into Unreal Engine. There are a few folders that we need in our calibration folder in order to actually put things in order and keep them organized as we calibrate our camera for the engine. Now, you'll see here that I'm over in my content browser and I already have an existing calibration folder. I also have my media profile and my media profile bundle folder located within my calibration folder. So you see here I've got my media profile and my media profile inner assets."},{"start":"2:11","end":"2:42","startSec":131.0,"text":"Now, the folders I need in my calibration folder are my Aruco wall textures. So I'm going to go ahead and create a brand new folder and I'm going to name this Aruco Wall Textures. This is going to be used to store our Aruco wall textures in our next course. Next, we're going to need another new folder. We're going to call this one Checkerboard. We're going to need this when we create our Checkerboard for calibration of our lens distortion map. Next, we need to get another folder here that we're going to call Lens Files."},{"start":"2:42","end":"3:15","startSec":162.0,"text":"Now, this is where we're going to keep all the lens files that we create for each individual camera and lens combination. Any time that you create a new lens and camera combination, you will need a new lens file. And finally, we're going to create a new folder for NotalPoint. And this is where we store the objects we use for NotalPoint calibration. Now, if you want to stay organized and just keep these separate, you can go ahead and create a new folder and call this Media Profiles and move your inner assets along with your media bundle, media source, media output,"},{"start":"3:15","end":"3:41","startSec":195.0,"text":"and media profile in one single location. It is recommended, though, when you do create your media profiles that you generate this folder before you do that. Now, in order to make sure that you have this working correctly, you'll notice that this folder is now empty and a duplicate was created inside this Media Profiles folder. So, that's it for this section. In our next section, we will discuss some of our camera configurations."}],"03_ReviewCameraConfiguration_v02":[{"start":"0:00","end":"0:39","startSec":0.0,"text":"Now in this section we're going to review our camera configuration. Now before we begin we're going to run you through a series of topics to prepare you for your lens calibration. The first of those is a quick review of our camera configuration. Now your camera configuration is going to be different than what we have but here at the latte stage we actually use a black magic Ursa Mini. We also have a Zeiss 25mm compact prime 3 lens and for reference we use Atomos Shogun. We have that sitting on a Leibach LX10 tripod and we also have the optional ProAIM Swift Dolly if we want to use Dolly moves."},{"start":"0:39","end":"1:27","startSec":39.0,"text":"We connect all of that through our AJA key Pro Ultra 12G recorder using also the AJA Kona 5 as our master clock but that's optional. Now for our optical tracking system we use OptiTrackMotive and we use the 209 Groups tracking mine as our active tracking system. On top of that we have the option of the Epic Games Sputnik created by Kevin Cushing using 3D printed tools and passive markers. Now we also want to review the media profile implementation from our previous classes. What is the media profile used for? Well the media profile is a required asset that the lens file uses to locate the video source used by Composure to overlay our CG elements in Unreal Engine inside the lens file asset editor that we use for calibration."},{"start":"1:27","end":"1:57","startSec":87.0,"text":"Note your media profile proxies configuration will automatically detect the number of sources available in your configuration. However you don't have to use or configure for both or more of them if you have multiples. Just configure for the profile that you're going to be using. In this case we have two sources but we only calibrated for one profile. That's it for this section. In our next section we're going to go ahead and take a look at some of our other tracking solutions and other options."}],"04_OverviewTrackingSolutions_v02":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"In this next section, we want to do a quick overview of our tracking solution, plugins, and system operations as we prepare for our Lens file calibration. You'll see here in virtual production in ICDFX a list of our plugins. The plugins that you have here in blue, the Aja Media Player, Blackmagic Media Player, Camera Calibration, LED Wall Calibration, Live Link Camera, Live Link Lens, and Open CV Lens Distortion are all the plugins that we need active for our calibration."},{"start":"0:30","end":"1:01","startSec":30.5,"text":"As I mentioned before, the Latte stage uses the OptiTrack system with Motive, and we need to have those OptiTrack Live Link and Streaming Client plugins made available for our Unreal Engine plugin. Anything that you see here in orange, those are our virtual production-related plugins, and those can be implemented as well. Now, our options for our tracking system. The Latte stage, as I've mentioned, uses the OptiTrack Motive system for performance capture and for our camera and object tracking."},{"start":"1:01","end":"1:36","startSec":61.3,"text":"We also use this for nodal point calibration and lens distortion mapping, but there are other options that are available to you, Vicon Showgun, the Vive Tracker, as well as the Vive Mars system. Note, you want to make sure that when doing camera tracking, it should be active as part of your stage setup. Your tracking setup, including setting the origin point, or the 000 of your tracking volume for camera calibration and lens distortion mapping, are also covered in some of this course. However, there is plenty of documentation on the various vendors' tracking solution"},{"start":"1:36","end":"1:54","startSec":96.6,"text":"websites, and there's a lot of video documentation that you can follow to go through these steps on your own. Now, in our next section, we're going to take a look at some of our camera control systems before we build ourselves a virtual Live Link subject. Thanks for watching. I hope you enjoyed this video. I'll see you in the next one. Bye. Bye."}],"05_CameraControlSystems_v02":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Now in this section, we're going to talk about camera control systems and then create a virtual live link subject so that we can do it ourselves if you don't have one of these camera control systems. Camera control systems can stream lens data directly into Unreal Engine using any one of the optional peripheral devices that you can pick up from vendors such as Preston's hand view it. Now to calculate lens distortion, the lens file asset needs to know both the focal length and focus distance of the lens that's being used. There are several available hardware options"},{"start":"0:32","end":"1:04","startSec":32.1,"text":"that are capable of streaming Fizz data from production cameras to Unreal Engine through a live link plugin. The Master Lock It, Preston MDR and the DCS plugin are all viable options, but most vendors should have an optional plugin that you can download from their website and use in conjunction with Unreal Engine. Now some hardware connects to smart lenses made by Zeiss and Cook. Other devices connect directly to focus systems such as the Preston and these are commonly used by first ASCs for adjusting or pulling focus and controlling the aperture or"},{"start":"1:04","end":"1:36","startSec":64.2,"text":"iris of the camera. Now the DCS lens data translator can convert smart lens data in addition to streaming lens data from different focus systems. Additionally, RE also has a hand focus system and the RE-CAM metadata plugin for streaming that Fizz data. Note this is required using the pre-built 5.0 plugin and it is up to RE to determine when this plugin will be updated for 5.1. Additional notes here that you want to be aware of is that distortion of a real"},{"start":"1:36","end":"2:12","startSec":96.1,"text":"lens needs to be emulated by the CG lens to have the same distortion characteristics when adding AR or CG extensions that are not seen in camera view, but are added as a composite layer. These distortion parameters will change as the focus is changed during a tape and by streaming the Fizz data, the camera in the Unreal Engine can be updated in real time by the lens file and apply these values to the CG composite elements. If you don't have this, your post team is likely to throw away everything that you've shot and redo this in post. So if we want to pull our camera control"},{"start":"2:12","end":"2:47","startSec":132.0,"text":"systems for calibration and we want to do this on our own, we're going to need a live link virtual subject. So let's jump over to the Unreal Engine. Now if you don't have access to per-refrials for streaming, a virtual live link subject blueprint can be used to manually input focus, aperture, and focal length values with the following steps. To begin, we're going to move over to our calibration folder and we are going to create a folder for lens files. Let's go new folder, lens files, and inside that folder, we are going to create a new blueprint. So let's go ahead and right click"},{"start":"2:47","end":"3:17","startSec":167.6,"text":"here and go to live link because we need a virtual subject. So we're going to create a blueprint virtual subject. So again, right click, move up to our live link and go to blueprint virtual subject. Now the role that we're going to choose for this is going to be our live link camera role. So we're going to choose this from our drop-down menu and go ahead and click OK. Now this is going to give us our blueprint, which we are going to rename BP for blueprint, live link virtual subject or LLVS"},{"start":"3:17","end":"3:49","startSec":197.8,"text":"and we're going to give this the black magic Zeiss underscore 25 for our lens name. We want to do that so that we know what subject this is actually controlling with our lens camera combination. Once that's done, we can go ahead and double click on this to open it up so that we can start building our blueprint. Now as we get started in here, you are going to want to create a few variables. So we're going to move up to the upper left hand corner here and you're going to see this option called variables and I'm going to start with hitting this plus button. My first variable,"},{"start":"3:49","end":"4:24","startSec":229.6,"text":"I'm going to change this type from Boolean to float and I'm going to rename this variable the focus. So this is the F in our fizz for focus. Now I want to make sure that this is instance editable. So I'm just going to go ahead and click on this little eyeball and that makes it instance editable. Now I'm going to need a few more versions of this. So let's go ahead and duplicate this by hitting control D and let's rename this one to iris and do control D one more time and let's call this one zoom. So now we have focus iris and zoom or as we like to call them for"},{"start":"4:24","end":"4:59","startSec":264.2,"text":"short fizz. Now we need to go into our event graph and from here we need to create some event options. So we're going to start out here with our event on initialize. Let's move this up to the corner so we can kind of focus on it. I'm going to drag out from my executable and I'm going to create a new node and this one I'm going to type in update virtual subject and I want to select the subject from my static data. So I'm going to choose update virtual subject static data. Now with my static data I do want to hover over my static data pin and I want to right click on this"},{"start":"4:59","end":"5:34","startSec":299.5,"text":"and split my structure pin. Splitting my structure pin is going to give me a number of options to work with and I want to make sure that these options that I want to work with are enabled. So the first one I want to enable here is the static data is focal length supported. Next I want to make sure that my static data is aperture supported and finally let's make sure that my static data is focus distance supported. Now I have my virtual subject ready to go and I need to create a few more options here. So I'm going to do the same thing over on my event on update"},{"start":"5:34","end":"6:08","startSec":334.8,"text":"and in my event on update I'm going to drag this out and I'm going to go ahead and search again for update virtual subject but I'm going to look this time for my frame data. So in this version I'm going to on my update choose my frame data. Now just like before I'm going to move this over and I'm going to hover over my frame data and I'm going to right click on this I'm going to split this structure pin. Now I've split my structure pin and I can see that I've got a couple options here frame data focal length frame data aperture and frame data focus distance. Now I'm going to"},{"start":"6:08","end":"6:40","startSec":368.0,"text":"start with my focus distance and what I'm going to do here is I'm just going to drag for my focus distance and I'm going to look for a variable and that variable is going to end up being my focus. So I'm going to get my focus my focus is the variable that I created so let's go ahead and grab that. Now I can also drag one of these in so let's drag in my iris and let's get my iris and you can see it's the same kind of node I'm going to connect that to my data aperture. Now again I can always drag this off and I can always search so I'm looking for my zoom and I"},{"start":"6:40","end":"7:13","startSec":400.6,"text":"can just get my zoom and now I have my variables controlling my focal length. So each of these variables actually grab all of my focus distance my aperture and my focal length. Once this is done and assembled all I really need to do right now is go ahead and hit compile and then save and that's pretty much it for our virtual live link subject creation. Now we need to make sure that this subject is accessible so I'm going to go ahead and close my blueprint and you can see I've got my virtual subject in here and I'm going to move over to the right side of my screen to my live link"},{"start":"7:13","end":"7:43","startSec":433.4,"text":"section. If you don't have your live link tab you just go under window you can move on down to virtual production and open up this live link tab that'll give you this option in here and now I need to create and add a virtual subject to my source. So inside my live link tab I'm going to go ahead and hit this source button and I'm going to go add virtual subject. I'm going to go ahead and click that button. Now I'm going to give myself a virtual subject name and so I want to make sure that I rename this subject so I'm going to call this live link virtual subject black magic Zeiss"},{"start":"7:43","end":"8:15","startSec":463.6,"text":"25 and that's going to give me my live link virtual subject and then I'm going to choose the virtual subject that we just created so I'm going to choose the blueprint that we created here. That's going to allow me to add the subject name telling me what this is that I'm using and add that to my source here. Now you can see I've got my black magic subject name in here and that's going to give me the option to control my focus iris and zoom in my live link virtual camera. Now in order to make this work you'll see over here I've got my NBC camera. I'm going to move"},{"start":"8:15","end":"8:45","startSec":495.3,"text":"up to my outliner and select my camera. With my camera selected I need to add in a new option so let's look at our details panel. Now in my details panel I should have a tracked object in here and I don't have my tracking setup just yet but we're going to need that in order to track our camera for our option. What I'm going to do is I'm going to need to first create my live link fizz data in order to control that so hit this add button and in my add button I'm going to type in live link and you can see I've got two options live link skeletal animation and live link controller so"},{"start":"8:45","end":"9:16","startSec":525.6,"text":"I'm going to use controller and this is a live link component controller so I'm going to call this ll underscore cc for live link component controller black magic underscore zice and this is my fizz data so I'm just going to type fizz on the end of this. I'm going to hit enter and I'm going to choose my subject representation. For this you can see I've got my black magic zice 25 I'm going to choose my camera roll and this is actually going to control my camera roll so now my fizz data is going to be controlled from my camera and that's going to actually control and allow me to make"},{"start":"9:16","end":"9:45","startSec":556.2,"text":"those changes so that any of my focus iris and zoom are going to be set in here. Now if you have forgotten how to do a tracked object in here you just want to make sure that your source is active and you want to load in a source for your opti track and then connect that source and make sure that's set for your preset. That's it for creating your virtual live link subject. Next we're going to talk about one more little tool before we do our lens calibration."}],"06_TimedDataMonitor_v02":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this section, we're going to talk about our time data monitor and using that for adjusting sync and time code. Now, the time data monitor is used to monitor the sync and time code of different devices. It can also be used to synchronize devices using buffers and offsets to the incoming data by evaluating the time code properties of your devices. Now, there are three evaluation types that you're going to typically run into. Time code, which uses time code when evaluating your source. Platform time, which uses the engine's time when evaluating the source. Or none."},{"start":"0:31","end":"1:03","startSec":31.0,"text":"There's no special synchronization. It just uses whatever the latest sample time is. Now, there are some source indicators that you're going to see in your time data monitor. And those are green, which shows that your input is actually connected. Yellow, where your input is connected, but there is no data available. And red, in which nothing is connected. So let's jump into the engine and take a look. Now, let's locate the time data monitor if you first want to go into window, virtual production, and time data monitor. Once that comes up, you'll see here that we are synchronized through our AJA time code provider."},{"start":"1:03","end":"1:34","startSec":63.0,"text":"Now, we also have our OptiTrack active. And if I take a look at this, you see a timing diagram here showing a buffer and sample count. Now, you'll see that we're synchronized currently, but you may see this pop on and off while we're having our discussion today. So there are several evaluation types here. And if I click on this little clock here, you're going to see that I have a couple of options for evaluating my devices. One of those that we generally want to use is time code. So we just make sure that this is active by switching over to time code."},{"start":"1:34","end":"2:06","startSec":94.0,"text":"Now, as I switch over to time code, there are some adjustments that we like to make. Now, there are some additional evaluation types. Obviously, time code uses your time code when you're evaluating your source, but the platform time that we switched away from, which was the little clock, that's using the engine's time when evaluating your source. Obviously, if you don't want any synchronization, you can choose no synchronization, which has no special synchronization and just uses your latest sample time. Now, there are some things to keep in mind as you go through here. Up in your time code provider, there is a global frame offset."},{"start":"2:06","end":"2:38","startSec":126.0,"text":"Now, you may notice that this has been popping on and off a little bit with our synchronization. If our training diagram here has our sync kind of pop out just a little bit. In order to help that along, we want to make sure that our global frame offset is set to three. Now, that's going to offset us and pull us outside of our range. What we need is a larger range for our buffer size. And in order to fix that, we move right over here to where our buffer size says 10. And we generally recommend that you change your tracking system buffer size from 10 to about 50."},{"start":"2:38","end":"3:14","startSec":158.0,"text":"And now you can see that our timing diagram is a lot wider here. And time step and our adjustments are going to be pretty much okay here. Now, if I take a look over my source indicators here, you'll notice that my indicators are showing that they are green. Green tells me that my input is connected and yellow inputs, if they ever change to that color, tells me that the input is connected, but there's no data available. And obviously, if it's red, then there's no connection at all. Now, the top of the window shows your incoming sync and your timecode connection connected to your AJA timecode provider."},{"start":"3:14","end":"3:46","startSec":194.0,"text":"And this is what we set up in our media profile. Now, in Unreal Engine 5.1, you may run into an issue where your media profile is not connecting to the time data monitor after loading the project through your version control. Now, in order to fix this, you may need to set the media profile as your startup media profile in your project settings. To do that, you just go under your edit project settings. And if you type in media at the top, it'll bring up some options here. The first one is you want to make sure that your general settings for your frame rate is using your AJA custom time step."},{"start":"3:46","end":"4:22","startSec":226.0,"text":"Your timecode provider should also be your AJA timecode provider and that your media profile is using your AJA media profile for your startup profile, as well as choosing your source proxy and your media output proxy. Make sure these are located in and save them into your .ini file. Next, I want to point out that the Unreal Engine can receive capture frames from our camera on SDI as well as position and orientation of our camera. There is another option here for our buffer visualizer. So if I look in the time data monitor, there is a button here that looks like a little visualizer and that allows me to open our buffer visualizer."},{"start":"4:22","end":"4:57","startSec":262.0,"text":"Now the buffer visualizer is just an extension and it has a simple UI that has a couple of elements in here. It tells me what's active, it tells me what's in my buffer and it tells me what I'm looking for in here. Now the vertical line here that you see this green line, it represents the evaluation time. The line is green when inside the buffer and red when it jumps outside the buffer because then it's outside your available samples. Now the light gray rectangle that you see in here represents your current time samples available for the channel. And the dark gray rectangle that you see above here represents the average of the time sampled available in your channel."},{"start":"4:57","end":"5:30","startSec":297.0,"text":"And then the white rectangle here is going to represent the standard deviation of your oldest time sample and newest time sample available. During calibration, the time data monitor will modify the global offset of the timecode provider and buffer sizes of the sources so that all channels have enough samples in the range of the evaluation time. You can adjust the timing offsets and buffers to make sure that the CG elements are in sync within the video source and tracking data. Now a pro tip here, the bigger the white rectangle is, the more variation or jitter in the sample buffer."},{"start":"5:30","end":"5:48","startSec":330.0,"text":"When you see this larger variation, you'll probably need more buffer between the evaluation time and the newest time sample available to be sure you are always able to evaluate a sample at the desired time. Next, we're going to go ahead and create our lens file creation in the next video in this course."}],"07_LensFileCreation_v02":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Okay, in this section we're going to simply focus on lens file creation. This is the latest thing that we need in order to actually do our lens file calibration. Now the lens file stores the lens distortion parameters, camera intrinsics and nodal point offset data along with the associated focus and zoom values specific to each lens to camera combination. Now let's just jump into the engine here and take a look. Create the lens file folder that we created earlier and right click in the content browser"},{"start":"0:30","end":"1:02","startSec":30.7,"text":"area in order to open up the content browser create events asset menu, move up to the miscellaneous section and go ahead and select our lens file. Once you've done that, rename it to lens file Zeiss 25 millimeter P3 and double click it to open it up. Now the lens file asset editor has multiple calibration tools for automatically populating the lens file with calibrated data. They are your calibration steps tab and the lens file tab and the calibration steps tab"},{"start":"1:02","end":"1:34","startSec":62.5,"text":"contains four sub tabs for lens information, lens distortion, image center and nodal offset. Now in order we are going to be using our lens information first and for that we want to make sure that inside this you have viewport settings so you can adjust the transparency here. Typically it's set to 0.5. Choose your camera and make sure you're using the camera that you want to calibrate with in the engine to match the real world camera so that is our NDC cam black magic Zeiss 25 P and that makes sure our media source is already connected."},{"start":"1:34","end":"2:05","startSec":95.0,"text":"Now there is an overlay you can choose for crosshairs and adjust that as well and you can use that for our image center but we're not going to be using that today. Instead we are just going to focus on finishing our lens file creation. So in the lens info under the lens information section you want to make sure that you set up some lens info to identify what lens you're using. So for this I'm going to use black magic and I'm going to go Zeiss and I'm going to call this my 25 millimeter P3 because it's prime 3 lens."},{"start":"2:05","end":"2:38","startSec":125.3,"text":"If you have the serial number information go ahead and put that in as well. If you have multiple versions of the same camera type your serial number is generally going to help you know which camera you're actually using. So if you have that information it's going to be helpful to get that. Next you want to make sure that you modify your sensor dimensions and for the Zeiss it is the 25.34 millimeter by 14.25 millimeter sensor. So make sure that these match exactly what the settings are for your camera. Now your image dimensions here are 1920 by 1080 that's what's coming in for your feed"},{"start":"2:38","end":"3:08","startSec":158.6,"text":"so you don't necessarily need to make any kind of adjustment in there. Now taking a quick look at our lens file panel this allows you to see our focus, our iris and some of our other parameters such as focal length, distortion, image center and nodal offset. Additionally there is an option for ST maps. ST maps here can be loaded in through this section. Now back to our calibration steps you'll notice if I look down here there is no raw fizz input there is no connection in here and there is no evaluated camera settings."},{"start":"3:08","end":"3:41","startSec":189.0,"text":"In order to fix that we are going to need to make sure that some of the options that we have available in here that we'll come back to are connected. So let's move back into the engine itself and make sure that our lens file that we've created is available and able to be used inside our camera. So I'm going to move up to our NDC asset here in the outliner and I'll move down to my NDC camera here. Now if I go in here you're going to notice that there are several options and available functions that are in here such as film back lens settings etc. But we're actually going to be tracking our fizz data so we remember we created a live"},{"start":"3:41","end":"4:12","startSec":221.2,"text":"link camera controller for our Blackmagic ZEISS fizz and I'm going to click on that and you'll notice I don't have a subject representation right now. So my live link didn't actually remember my default source being connected into my camera's subject representation. So I'll save that when I finish here today. But in order to get this to work just choose your subject representation for your live link virtual subject for your Blackmagic ZEISS. Now once that's done you'll notice that there are some options available down here including camera roll."},{"start":"4:12","end":"4:45","startSec":252.7,"text":"And we go down to our camera roll we want to actually go down to our camera calibration so you can expand them and see that we've got lens file picker and we're going to choose the lens file that we've created. Now I can pull this from the lens file that's available in here or I can just drag this right in. Now once that's connected if I go back into my lens file one thing to remember before we go through here it should be noted that we only support spherical lens models at this time and that you must match your physical camera sensor to the camera itself."},{"start":"4:45","end":"4:57","startSec":285.3,"text":"Once you're done here go ahead and save the camera information. We'll come back and use this a little bit later when we do our lens distortion mapping and from here we are ready to go. Let's move into our lens distortion mapping and get started calibrating our camera."}],"08_LensDistortionMapping_v02":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Okay, in this last section, we're actually going to go through the steps and the tools that we need for lens distortion mapping, and then we're going to complete this course by finishing with our actual lens distortion calibration. So as we get started with lens distortion mapping, the lens distortion requires the use of a CG checkerboard and matching physical checkerboard that is printed and mounted on a rigid surface to hold in view of the production camera. Let's take a look at what we've actually got up on our stage. This is printed on a rigid sign. It's actually aluminum with the black checkers and white checkers mapped on it."},{"start":"0:33","end":"1:06","startSec":34.0,"text":"We created this using Adobe Illustrator, but you can also use programs such as Inkscape, Vectornator, or Vector when creating your physical checkerboard. I need to ensure the exact accurate measurements of your checkerboard squares in centimeters matches what we're going to build inside the engine. Now if I jump back to my slides, you're probably wondering why the checkerboard? Well that's because lens distortion is calculated or mapped using the Quadrant Intersection Points or quips in the physical checkerboard pattern. One thing you want to note here is the quips used for distortion mapping and calculation"},{"start":"1:06","end":"1:37","startSec":66.3,"text":"are the literal intersection points of each four square quadrant section as set by your corner rows and corner columns when creating your CG checkerboard asset and matching that to the physical checkerboard. So let's just jump right into the engine and get started building our checkerboard here. So if we take a look in the engine, we're going to first want to have a folder for our materials that we're going to need for our checkerboard itself. So let's go ahead and start with our folder. First I'm going to call this new folder checkerboard because that's what we are building."},{"start":"1:37","end":"2:10","startSec":97.7,"text":"Now we can have multiple checkerboards. The one that we're going to build is a four and a half centimeter checkerboard with seven corner rows and number corner columns are 11. To find and build our checkerboard, you just move over to our place actors, which is a hidden up in the upper left hand corner of our tab. And then go ahead and move over to our virtual production tab and just drag your checkerboard in here. Now before I do that, I want to point out that I am in my current level for my NBC. This is the NBC sub level located in my persistent level."},{"start":"2:10","end":"2:40","startSec":130.2,"text":"And my checkerboard is going to need to live in my track offset actor inside my end display asset. So that has to live inside the NBC level itself. So again, let's go up to our place actors and just go ahead and drag my checkerboard in and that should make sure that my checkerboard is living here in my NBC level. So let's go ahead and rename that checkerboard so that we have cam calibration checker 01. Now with that named, we are going to need to make some adjustments to our checkerboard."},{"start":"2:40","end":"3:13","startSec":160.4,"text":"If I look in my viewport at my checkerboard, there's not really anything that's visible here yet. That's because the checkerboard itself is quite small. So to adjust that, we're going to move over into our details panel with my checkerboard selected. I'm going to move down here to the calibration tab. It's right below our transform tab. And I'm going to skip my calibration points because these are automatically generated for me. And I'm going to go ahead and change my corner rows and corner columns. As I mentioned before, I need seven corner rows and 11 corner columns. And then for my thickness, I'm going to go ahead and leave that as it is."},{"start":"3:13","end":"3:43","startSec":193.0,"text":"And my square side length, let's change that to 4.5 centimeters. Now we are going to need some materials to make that show up. Right now there's no materials, so we need to build those. That's going to take place inside our checkerboard folder. So go ahead and open that up and then right click to create our first material. Now this first material we're going to call M underscore checker and call this BLK for black. And for that, I'm going to go ahead and open this one right away. And I'm going to hold down the hotkey three and then just click in my space."},{"start":"3:43","end":"4:17","startSec":223.6,"text":"That's going to give me my vector three constant. And from here, I'm going to connect that right into my base color. Now it's going to be a little bit shiny. So from here, I'm going to need another constant. So let's just go ahead and right click and type in constant. And it only works if you spell it correctly. So constant. And then I'm going to change that value to 0.1 so that I have some specularity, but not completely. And then let's connect that to our specular. And then let's go ahead and hit apply and save. And that's going to give me my first checker. Now from here, I am going to close that window, jump back into the engine and to make my life"},{"start":"4:17","end":"4:51","startSec":258.0,"text":"a little bit easier. I'm just going to go ahead and duplicate this. So you could just build this again, but instead I'm going to go ahead and duplicate it. And then I'm going to change the BLK at the end to COL color. And I'm going to do that because that is going to give me the option of having a new color. And if I just go right in here, I can quickly make that adjustment by selecting my color wheel and moving on up to the color that I want and make this nice and bright pink color here for me to use. And I want this pink color because I want to be able to differentiate between the white checkers that are on the physical checker board and the CG checkers that we're going"},{"start":"4:51","end":"5:24","startSec":291.2,"text":"to get on our CG checker board. And you'll understand that once we actually do our calibration, because we'll be able to transparently view a properly calibrated checker board. So let's go ahead and apply and save this change as well. And then once that's saved, we'll see our checker board itself. Now my checker board isn't quite showing up and that's because I haven't assigned the colors just yet. One thing to note is that I want to make sure that the top left corner of my physical checker board is my odd cube material color. And my odd cube material color is actually going to be my black material."},{"start":"5:24","end":"5:57","startSec":324.6,"text":"So let's go ahead and connect that black material in just by dragging it into my odd cube material and take my color and move that into my even cube material color. And that's going to give me the colors for my actual checker board. Now as I zoom in a little bit, you can kind of see my checker board showing up here. I want to move this a little bit closer so that it's visible here. That way I can kind of move this around and you can see what's going to happen here as it moves. So this gives me my physical checker board. And again, this has to actually live underneath my OptiTrack offset actor. So let's put that into place. And now you can see that's giving us a lot more location information."},{"start":"5:57","end":"6:29","startSec":357.1,"text":"Let's go ahead and zero out that value. And that's going to zero that out on the floor. And let's zero out our rotation and then let's move that up. Now you can see that this is going to appear on the screen, but it's not going to align because of its position. Now let's just move that out of the way because we don't want that to show up in my calibration. And as we're getting ready for calibration itself, let's move on over to our calibration folder and into our lens file folder. Now if I jump back into my slides really quick, I just want to point out that there are some things that we need to note as a difference between Unreal Engine 5.03 and Unreal Engine"},{"start":"6:29","end":"7:02","startSec":389.5,"text":"5.1. OK, so in our lens distortion mapping, we now need to apply our lens to the tracked camera. In 5.0, typically as you go through here, you're going to find that there is a lens file component that isn't necessarily needed to be added in order to select our lens file. In order to select that, follow the same rules for 5.0. Scroll down, expand your camera roll dropdown in your details panel. Go ahead and then expand the lens file picker. Select your lens file, which is the LF Zeiss 25 millimeter in our case, and then double"},{"start":"7:02","end":"7:36","startSec":422.7,"text":"click to reopen that lens file asset. Now in 5.1, it's a little different here. You're going to need both a lens component attached to your camera and a live link component controller for our Fizz data. You're also going to need to make sure that your virtual subject is virtual. Don't rename it. That way it's going to connect the correct virtual subject to that as well in 5.1. So as a point out here in my slides, you can see that there is a lens black magic Zeiss in here. If we jump on over to the engine, you will see that we have this selected as well."},{"start":"7:36","end":"8:09","startSec":456.5,"text":"And as I'm looking through the engine, and if I scroll up here, the very first thing that's selected is my lens file Zeiss 25 millimeter P3. If I skip down to my Zeiss Fizz here, you can see that I've got my subject representation as virtual. This is my virtual subject and my subject itself is a virtual subject. That virtual subject is actually using this blueprint class, the blueprint live link virtual subject black magic Zeiss. And if I switch over to my live link here, you can see if I select my virtual subject, I've got it set where they focus iris and zoom that is set at 25 millimeters."},{"start":"8:09","end":"8:39","startSec":489.4,"text":"If I go back to my details panel and scroll down just a little bit under the camera roll as we have expanded, we can now see that my lens file is connected here in my LF Zeiss 25 millimeter P3. That is the same lens file that we are using here. So I can go ahead and double click that. And that will actually launch my lens file. Now you can see here that I've got my lens files, my track camera and my lens component is the lens black magic Zeiss. My raw fizz input is actually coming from my live link virtual subject."},{"start":"8:39","end":"9:11","startSec":519.5,"text":"And I'm just going to move this down and kind of resize this a little bit so you can see what's happening. And as you can see here, if I move over to my live link section, I've got a 25 millimeter zoom here and it matches my raw fizz input. If I change that information, I'm going to change that to 35 millimeter. And you can see that changes my lens and my view as well and the zoom information here at 35. Now because we're at a fixed lens with 25 millimeter, we want to make sure that that is set correctly at 25 millimeter. And then I can actually adjust my focus and iris controls as well."},{"start":"9:11","end":"9:45","startSec":551.4,"text":"So as I start to update this for my camera and my zoom, I can go ahead and pull that information and kind of figure out how far we are away from our subject and make those updates as well. Now as I'm in my lens information and my lens information is correct, again, my transparency allows me to switch between these two so I can see what is a full and transparent here. And now I can go ahead and just kind of leave that at 0.5. Although it's a lot easier to work with if I set this transparency to zero as we are ready to capture images through our lens distortion. So let's kind of move over to our lens distortion tab and let's make sure that we are correct"},{"start":"9:45","end":"10:18","startSec":585.6,"text":"in here as well. And I've got my camera, which again is my black magic's ice, make sure that's selected. My media source is correct so you can see I'm coming through my Aja device and I've got an overlay. This is really for my crosshair. I'm not going to make much use of this. And then for my lens distortion algorithm, I want to make sure I choose my lens distortion checker board that we've created and that we're using the actual camera calibration checker that exists in here as well. Now I also want to show a coverage overlay and show detection so that I can get some visual feedback in here. Now to get started, all I got to do right now is just click on the first image."},{"start":"10:18","end":"10:50","startSec":618.6,"text":"And as you can see, I get feedback that shows me that I've got all of my quips showing up in here so they're calibrated correctly. It shows me my calibration in a feedback image. And if I close this image, you can see that I've got my index showing up here as well. Okay, so as we're getting ready to do our calibration, let's take a quick look at some of the tools in the real world that we're actually going to be using. If I first look up at my checker board, which you can see through the camera itself, the checker board is on a stand and is our first image. But now we want to take a look over at our camera because we want to be able to measure"},{"start":"10:50","end":"11:24","startSec":650.8,"text":"specifically what our camera's position and make adjustments to our FIS data in the engine here as well. Now, I am going to be using a laser measuring tool here. So you can see this is my Bosch professional measuring tool. And if I look at the top of my camera here, there is a little mark. This is going to mark and show where my sensor's position is actually located. So inside my camera, this is where my camera sensor is located. Now if I put my Bosch right up against this, so it's kind of lined up in the same position and just push this button, you can see a little laser kind of show up on the sensor"},{"start":"11:24","end":"11:55","startSec":684.0,"text":"itself. And if I look down here and just press the button one more time, that's going to give me a distance of about six feet, three inches from the camera's sensor all the way to the wall. As you can see here, that's six, three. Now I want to make the adjustment here on my lens. So if I kind of come back around and Sean joins me over here, I need to make the adjustment from 4.6 feet to a little bit over six feet here. So now I'm all set up in that position. Now my T stop here, we are set to four, but I want to open this up as high as I can to"},{"start":"11:55","end":"12:26","startSec":716.0,"text":"get it not as much light in as possible. So I'm going to set this as 2.1. So now these two things are set on my camera and I'm ready to go back into the engine. And from there, I'm going to need to make some adjustments to my Fizz data that matches that information. Now to make that adjustment, let's just go ahead and pull this aside a little bit. And I'm going to go ahead and change my focus, which is my focus distance to 190.5. And my iris was set at my T stop of 2.1."},{"start":"12:26","end":"12:57","startSec":746.8,"text":"So I'm going to make that change as well. And you'll notice those changes get adjusted here inside my Fizz data. Now with that ready to go, I do need to actually do my images over again. So I'm going to go ahead and hit clear all on this. So first let's click on this. Here's my first image. This is just going to give me a nice central image. And while that's set, let's have Sean go ahead and move that up into the upper left hand corner. And you'll notice there's an overlay. So my quips are calibrated and collected and they stay on screen."},{"start":"12:57","end":"13:31","startSec":777.8,"text":"You want to make sure that this fills the frame, but doesn't get too high. And it gets closer to the edge if you can right in here. Now it doesn't need to be too high on the top. It just needs to fill in the top corner here. And the reason for that is so as we move over, this black part is actually going to obscure it and may cause a error here. Now to continue our calibration collection of images, we can go ahead and collect this image. And again, I'm not going to keep you through all of these. We'll finish this up and you'll see this in another section. So expect a little bit of a jump. Okay, so now that we finished our distortion mapping collection, you'll notice here that"},{"start":"13:31","end":"14:02","startSec":811.0,"text":"we have an index series of images. Now I have 35 images from my collection right here. And you can see as I scrub through them that Sean moved his way from left to right in different various locations and then created a couple of images that were from various angles. This is going to allow us some distortion and kind of see how the camera lens is going to read some of that information. Now once that's done, you just go ahead and apply our calibration data. And to do that, we're going to go down to the bottom here and add to lens distortion"},{"start":"14:02","end":"14:32","startSec":842.2,"text":"calibration. Now we are going to get an RMS reprojection error and we are going to want a number that is below 0.1 or better. Right now we have an RMS number of 0.51. That's actually still pretty good and it's going to give us a fairly decent set to work from. Now this is our first calibration point. So if I go ahead and hit OK to apply that, you can see everything is going to disappear and we're going to go into our lens file panel. And if I look at my focus and my iris, you're going to see that I've got a specific point"},{"start":"14:32","end":"15:04","startSec":872.2,"text":"here at a focus of 190.5. That's going to give me my first point at my zoom and calibration and it's going to allow me to kind of create some other points in here. Now to create additional points, I'm going to make the adjustments in our FIS data to a new focal length. So we would change our iris here. You'll notice it's going to get a little bit darker in what you're seeing in here. I'm going to change my T stop and I'm going to put that all the way as dark as I can at 22 and you can see how dark that is. Now, probably not going to need to be quite that dark."},{"start":"15:04","end":"15:38","startSec":904.1,"text":"So I'm going to open this up just a little bit. Let's go to 11 so we can still see things that's in here. But realistically, we'll probably want to push this to the extremes, the farthest distance that we're going to see in here. And then we want to actually create a new distance length as well. So if I go in here and make the adjustment, we want to get a little bit closer. So we would create another set with Sean and we'd move this up to about three feet. So we're at three three right now and we're pretty much filling the frame. Since we don't want to go quite that far, we're actually going to adjust our lens to three three in here and that way we can kind of come on back and we're going to make the"},{"start":"15:38","end":"16:10","startSec":938.3,"text":"adjustment inside our FIS data to match that. So as I mentioned, we changed our iris from 2.1 to 11 and we changed our focus distance from six feet, three to three feet, three. And that's about 99 centimeters. So with that set, we can go ahead and collect our first image. So let's have Sean move that in the upper left hand corner and we're ready to grab that first image. Now it's really dark, but it's still a good image. And I want Sean to move around the four corners here so that we can get these four images in here."},{"start":"16:11","end":"16:42","startSec":971.8,"text":"And we can stop right there. And now let's lower it down and let's move back to the other corner. Okay, now these were four points. Typically you want to have no fewer than eight to 10 points. So for this, I would have Sean move this so it's dead center, which is good right there. And then he can pull the checkerboard that we have mounted on a specifically set up mount. And we can move this around to create some specific angles on this and rotate that a little bit."},{"start":"16:42","end":"17:13","startSec":1002.4,"text":"There we go. A little bit turn your angle just a little bit less. There we go. So everything fits because it's going to look for the corner points that they're not all in there. It's not going to show up. Okay, so let's rotate again. Okay, and let's add another rotation on the other side. And let's rotate it the opposite direction. Okay, and that's going to give us eight images, which is the bare minimum here. So with that done, I'm going to have Sean just go ahead and put that back in a place. And you're going to see me actually add this to my lens distortion calibration."},{"start":"17:14","end":"17:46","startSec":1034.2,"text":"This is my RMS projection error is at point two now. So it's a lot smaller with fewer images, which is actually pretty good. So we're going to hit OK. And as we go over to our lens file, you can see now that a new distortion point. So this is my distortion map and my distortion map is starting to work. Now let's jump back to our slide so that you have this information available to you to look at. And as we walk through, I want to point out that, yes, we created a couple of images and it looks just like this. And we added that to our last section. Now, as I mentioned, there is an RMS error that you're actually going to look for."},{"start":"17:46","end":"18:18","startSec":1066.6,"text":"And we need to make sure that our calibrator is actually correct. So the last section that we need to do is to go back and apply this to our calibrator. So if I go ahead and jump back in the engine again and look at my calibration steps, there is a couple of other options that are in here. So to get this to work, the distortion parameters need to update here in our lens editor. And we need to verify our lens distortion with our nodal offset tab. So let's move over to our nodal offset tab and we're going to need to bring all that information into our section."},{"start":"18:18","end":"18:52","startSec":1098.1,"text":"So with the nodal point offset selection, we want to go and change our offset points method to our checkerboard. I want to choose the checkerboard that we are actually using and it is going to have multiple values. Now to get this to work, all we got to do is click into our viewport and that's going to add in our corner data. Now all I got to do on this is hit apply to calibrator and this will apply that to my lens distortion map. And you can see I've got my focal length adjustments that are in here, but I didn't get any focus distance or aperture because we're going to control that on our own and we have a fixed lens on here."},{"start":"18:52","end":"19:22","startSec":1132.6,"text":"But what I did get was my distortion parameters. So you can see I've got my distortion parameters that are in here and now we want to be able to see whether or not this is actually going to work. So if I scrub through here and I adjust my transparency, you can see that my checkerboard is now filled in with my pink checkers. This tells me visually that my lens distortion mapping is accurate. If my CG overlay matches my video feed, then my calculations here are visually confirmed."},{"start":"19:22","end":"19:42","startSec":1162.9,"text":"Again, scrubbing through here, you can see how these are actually lining up correctly. Now we did a short quick calibration with just two points. So there is a little bit of fuzziness in here, but this is still pretty good. So with that in mind, the next step is to go on and do our nodal point calibration from this point."}]},"219.00":{"01_Introduction":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hi, everyone. My name is Sean Spitzer, instructor for Epic Games and master mentor for virtual production. What we're going to go through here is talk about how virtual production and the pipeline can be used to your advantage using some of our tools, such as Quixel Mixer and Quixel Bridge, and some of the tools within Unreal to be able to make world building for virtual production. So let's get started. The first thing we'll look at is the scope and initial setup."},{"start":"0:30","end":"1:03","startSec":30.8,"text":"For this is very important to look at your scene and how to actually efficiently build it. Some of the topics we're going to cover is examining workflow, determining shots and assets, and then also using mega scans. So first up, we're going to examine our workflow scope. It's obvious when starting and constructing a virtual set, the scope needs to be examined and the overall amount of work needed. When it comes to Unreal, it comes into play, it actually will work as a new type of tool. And the fact that it can fill the gap of what you would normally"},{"start":"1:03","end":"1:36","startSec":63.8,"text":"use from a designated 3D package that we could use in Unreal to be able to create our sets and in real time have an update of our scene and to be able to use that for our virtual production. It fills that gap that you would normally see from a standard workflow, as you can see here in our chart. It bridges the gap and makes it so that our final output is in real time and our visuals will update on the fly. This is ideal in this workflow and allows us to have virtual sets in the current climate."},{"start":"1:36","end":"2:07","startSec":96.8,"text":"So we have to determine our shots in the very beginning. It determines what's going to be or going to have the highest priority. Our hero shots versus our shots and items in that camera shot, which are less important. How many polygons are we going to have? What's our texture resolution? So once we determine exactly what our items and assets are, then we can push back and move things around exactly where we need them and also take into account what the textures are going to be and the poly counts. So your scene layout is going to be"},{"start":"2:07","end":"2:39","startSec":127.4,"text":"huge in determining exactly how your assets will be evolving. So using Megascans, let's go and take a look at Megascans and what we can do to get things going in the right direction. So let me pull up Bridge here. And you can see in Bridge, it actually allows us to have a quick access of all the things that we need and want. Now again, Quixel Bridge is free if you have an Unreal account. It allows you to be able to access all these and have unlimited downloads for these assets."},{"start":"2:39","end":"3:10","startSec":159.4,"text":"And at your fingertips, you can easily go to the Home button here and see what's new on what is the new collections that popped up within Quixel Bridge. These are fantastic. They allow you to get them quickly, download them, and once they are downloaded, it will go to my Purchased area. You can see that the colors of the icons will change in the fact that now I can export it. There's the export for it. And these, and you can also favorite them too."},{"start":"3:10","end":"3:41","startSec":190.2,"text":"So you can say, hey, I want to remember this asset. You have an icon to click on. And you'll see in your favorites, you'll see that now I have one, which is this rock set, which is fantastic as you work and edit and collect these. So you can see also what they look like. You can see that the size is large. You can see that it has some openings. And you can see that you can also use it as an assembly piece. You can actually put them in groups. And you can also see down here that there is a collection that is all connected. These assets are all connected within this collection here."},{"start":"3:41","end":"4:11","startSec":221.5,"text":"And that's actually pretty great to be able to work in this particular type of tool and to be able to get this done quickly and fast. You'll see down below, we also have our settings we can control, such as our download settings. We can choose what kind of texture output we want. We can look at the models that we want too. And you can choose your LODs. Now this is really important to consider when it comes to virtual production. You want to be able to choose your LODs wisely. If you have a larger scene and the camera's floating over and maybe you're rendering to final pixels,"},{"start":"4:11","end":"4:42","startSec":251.7,"text":"you may want a lot of these LODs. But if you have a set that's up close and the camera doesn't move as much and it's really static and your actors are in front of that, in front of that scene, you might want to limit it to more of the zero and one polygon counts for LODs and not have to load all of these. Because these can start to add up after a while if you're not careful. So let's go back. And in here, you can also see, you can choose your resolution, 4K, 8K, and keep those things in mind based on what hero objects you need."},{"start":"4:42","end":"5:14","startSec":282.8,"text":"We also have the export settings. So we saw the download settings here, but there's also the export settings and we can click on those. And in here, we can choose if we're going to go for Unreal or any other Disney 3D package, we can choose the engine version that we want. And you also want to make sure you have your plugin going to the right directory for the version of Unreal that you have and you make sure it goes into the plugins directory. The default project you want to keep that blank. You can, you have the option to change that if you want to,"},{"start":"5:14","end":"5:47","startSec":314.6,"text":"but I will easily forget as I'm in the pipe and I'm really trying to get stuff done. So I would leave this blank so that whatever Unreal I have open, it will automatically export my stuff into my scene. You also want to make sure when you do install the plugins for Quixel Bridge, that your Unreal is closed at that moment. And only open up Unreal once that plugin's all set in and then whenever you export, we'll go into that open Unreal. So make note of that. We have textures here. You can choose different surfaces that you want."},{"start":"5:47","end":"6:18","startSec":347.2,"text":"What will your 3D asset textures be and your decals and so forth. And they also have models here. So what you will bring by default in your LODs. And then finally, we have file names. So here you can choose what your names are going to be. So try to keep that as organized as possible. And you can also edit that later on if things change within your pipeline. You'll see I'm saying the same thing here. So I personally, again, do not have a default project to set that in. Keep that pretty blank. And as I said before, you'll see check boxes"},{"start":"6:18","end":"6:49","startSec":378.7,"text":"which are little check marks off of the corner which will tell you whether you have an asset or whether it can be downloaded and exported. And you'll see the blue right here. It is ready to be exported. So choosing your LODs wisely, like I said before, and I will re-emphasize this because this is really important to understand with virtual production. And Unreal is only going to do, and Quixel is only going to do what you tell it to do. So the LOD is very important."},{"start":"6:49","end":"7:21","startSec":409.2,"text":"You have to determine what and how much screen time that object's going to have. And if that object, now LODs are level of detail if you're unfamiliar with that. And that level of detail is determined how far the camera is from that object. But if that camera never really zooms out or zooms in or doesn't do it very much, you want to keep the highest level of detail for your virtual production if you can. And that's the wisest thing to do. And you can always go back in Unreal if you need to generate these. You can, maybe for another shot. Maybe there's another shot you want to use Unreal for"},{"start":"7:21","end":"7:52","startSec":441.3,"text":"and that one isn't virtual production based. It's maybe a sweeping camera shot. Then you can go in there and either export this out again or simply go in here and in Unreal, generate some more LODs to be used. So here's a link that you'll see in our documentation which gives you some further explanation for that. I'm going to give shouts out here to Brendan Jones for the donating the concept art and King Chen for the concept art that we'll be referencing in the next few slides. So in the next video, we're going to be looking at editing assets"},{"start":"7:52","end":"7:57","startSec":472.4,"text":"and how to work with them. And I'll show you exactly what we need to do to really get our stuff to come together."}],"02_Editing Assets - Part 1":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this lesson, we'll talk about editing assets using several of our tools that we have at our disposal. Some of the topics we'll be covering is Quixel Mixer, creating blueprints for quick edits, and the Variant Manager. When using Quixel Mixer, you want to make sure that your asset is in the center of your world, and the pivot is in the right spot in the zero-zero point in the grid of your"},{"start":"0:31","end":"1:03","startSec":31.1,"text":"designated 3D application. This is very important. You can do some edits when you bring it into Mixer and also Unreal, but it's better to have this stuff done ahead of time. If we look at Mixer up close, you'll see right within our setup, we can choose what we're going to bring into our scene. I can have generic assets or have a custom model. You'll see we have Crunch in here, who is a custom model imported into our scene."},{"start":"1:03","end":"1:34","startSec":63.0,"text":"You can also bring in assets from our local library and online. The hotkeys for that are L for the local library and O for online. You can bring in those assets and immediately edit them as you work. This is very convenient and helpful, and allows you to have quick access. Another thing is when you're adjusting your assets, if you need to, you can also adjust the scale within our setup options."},{"start":"1:34","end":"2:06","startSec":94.7,"text":"You can see here that we can control exactly how our size is going to be. This works in centimeters, so keep that in mind. If you're working in centimeters in your designated 3D application, just make sure that is equivalent to a 6 foot aspect ratio, which is about 183 centimeters in your designated 3D package. If you're building in that 3D package, just create a cube or a block or some sort of rectangle"},{"start":"2:06","end":"2:42","startSec":126.8,"text":"object that will represent that 183 centimeters for that 6 foot person, so that you keep everything within context and then you can put things in place the way that you need. We can bring in any material that we wish. We're going to probably leave Crunch for a moment and go to a more simpler one and just go back to Crunch. Let's go in here and open our mixes. We'll look at this alien stone to start out and we'll get back to Crunch in just a minute."},{"start":"2:42","end":"3:13","startSec":162.1,"text":"We'll see it load down here off in the very corner, so that it's loading the assets. This is one complete asset all by itself, no extras, no extra parts, as Crunch does have different pieces that come in. In this asset, we have several different layers that we've created. Up here at the top, you'll see that we have several layers that we can work from. One of them here is we can add a surface layer if we wish. This takes us directly into our local library and allows us to grab what we need, but we"},{"start":"3:13","end":"3:45","startSec":193.9,"text":"can also go to the online library and find anything else that we need. We see that we're working in all, but we probably more than likely want to work either with different displacements or the overall just materials in general. Whenever you're selecting an actual object, Unreal will want to know if you want to edit that or excuse me, Mixer, and it will give you a prompt for that. We're going to mainly focus with materials. Let's go back to the viewport. You'll see that I have a few already in here. You'll also see that I created a liquid layer, which you can do here."},{"start":"3:45","end":"4:15","startSec":225.5,"text":"You'll see the icon that looks like a drop of water. I can turn this off and you'll see the liquid layer get removed. It works similar to what you would see out of a smart material, where it tries to take into account every aspect of our edges and our normals and changes in shape and tries to apply the liquid accordingly. It does a really cool job of doing it. Again, we can change the color of that. If I wanted this color to be, I don't know, more of a blue, I can add a blue to it. You'll see a blue tint."},{"start":"4:15","end":"4:46","startSec":255.8,"text":"And we can truly get like that alien landscape we've always dreamt and wanted. It's really great to be able to edit that. You'll see the threshold, the radius, and the detail. All these things can be edited. And you'll also see if you wanted to add more of some custom masks and so forth, you can do so. You also see a thing called an add a layer set. Now this is new to Unreal and this allows us to be able to paint within particular pieces or different items that are separate within our model."},{"start":"4:46","end":"5:17","startSec":286.6,"text":"If we go back to Krunk, let me make sure I get him here. Always say his name wrong. Krunk or Krunk. It is Krunk. Krunk. Sorry, Krunk. Didn't need to get your name wrong. I'll say don't say it. Load him. You'll see that we have several of these layers already established and created here. And in with each one, as soon as he pops up here, it's populating right now. Within each one, we can paint in those pieces and those parts of that model, which makes"},{"start":"5:17","end":"5:50","startSec":317.9,"text":"it really great to work from. And you can see as I turn these off and on, you'll see that that ability is there. And you also can isolate as you're painting. So if you decide to make a new layer, you can say I don't want these particular target texture sets to be included in this new layer set that I've made. So I can turn these off and you can see these are isolated. This is new to Mixer, which allows us to be able to have more finite control. It's really great. You can even create metal masks if you need to in particular areas."},{"start":"5:50","end":"6:23","startSec":350.2,"text":"And that's all available for you. You can also see we can add decals. So say we just wanted to do a hand smear in this case. We haven't loaded anything else in our local library, but we can if we go online. We can find some decals and in those decals, we can add some more things and items to our stuff. We can add a lot of different decals that we can choose. Maybe he has some graffiti that someone's put on his chest. We can do that too. So but we'll just say he's part of the Lord of the Rings hand clan. So we can click on this one here."},{"start":"6:23","end":"6:54","startSec":383.4,"text":"And this hand smear is now in place within our scene. And we can actually paint with it if we need to too. So if we go to a new paint layer, we can also load different brushes, save different brushes, but also go and replace them if we have that isolated. So we can also place that within here. So there's a lot of control that you can do within these, which is really exceptional. In this paint layer, if we have another one we just made, we can go in here and paint"},{"start":"6:54","end":"7:25","startSec":414.5,"text":"the details that we need. You can increase or decrease using a displacement effect. You can push up or push down. This will give you that raised displacement or just set displacement in general so that when you paint, you can accordingly change that based on our brush shape and jitter size, all these different things such as angle. You can control some of these effects as you go through in here."},{"start":"7:25","end":"7:56","startSec":445.1,"text":"And if you don't want displacement, simply turn it off. So now when we paint, it's just raw paint. We'll undo those because we don't want to affect crunch too much. We don't want to upset him. So using Mixer, again, we can turn our eyeball on and off to turn them on, but we can also choose which type of things we want to paint. I did mention and show you that you can also load brushes, whether in Photoshop or an existing brush. You can turn those decals into painting because right now what we did before, we just loaded"},{"start":"7:56","end":"8:31","startSec":476.7,"text":"the decal. But if you wanted to be able to paint the decal, that is available. And you can also do a masking effect. You can also control how textures are projected and how they are controlled on an object. If we go back into Mixer, you'll see that we can actually go to, let's go to one of these sets that are in here. And you'll see, we'll open up placement here. So this is the hand paint that's been done."},{"start":"8:31","end":"9:03","startSec":511.4,"text":"And I can control how the placement is on here. Right now it's just box projection, but I can choose tiling if I wanted to. And let's actually tweak this out a little bit here. I didn't undo all the way. Let's actually undo from our last stuff. And let's pick, let's mess with scratches. It'll be a little bit more distinct and we can see that a bit better. We see some scratches that we see on his knees. So let's go ahead and rotate and move those scratches, or actually on his arm."},{"start":"9:03","end":"9:37","startSec":543.7,"text":"We'll see that move and rotate. We can choose how that projection is going to be. We can control tiling. We can go to free form. Adds a little bit more edge detail, but you can control again the tiling and the scale. And we can go back to box projection. All in here is underneath placement. You'll see many of these, which are active, we'll be able to have that. You'll also see that you can add a material ID if you need to. So you can separate your materials and paint with that particular material on a particular area if you need that."},{"start":"9:37","end":"10:09","startSec":577.9,"text":"You can also add a group if you need to. So you can make grouping folders. You'll see right here is a metal mask. As we click on this, you'll see it's isolated to what is associated with that object. We can control its opacity if we need to. That's on the hands distinctly. And you can add some more details in here if you need to. So we're not going to add a channel here. We're not going to get that deep with this, but I want to show you the power of this particular tool and what you can do."},{"start":"10:09","end":"10:44","startSec":610.0,"text":"You'll see the demonstration here within the GIFs within the lecture documentation provided for you. I'm showing how you can paint and you can also isolate. You can say, hey, I want to work with the arms. I can work with a textured set editor here. And that actually makes it a lot more easy for you. So if we go into your layers, you can see the isolation that I talked about. You can say, hey, I just want to paint on these items in this particular layer set. And your layer sets up in that corner. That makes it so you can isolate things a lot better and will help you with your workflow."},{"start":"10:44","end":"11:16","startSec":644.6,"text":"If you go into your actual layer sets that you have established, and I'm glad we have Krunk here with us today, you can actually double click on it and you'll see, or actually just simply click on it, you'll see what is being isolated for that object. And that's really helpful. And again, having that is going to be a very strong benefit to be able to paint on your objects. We can now, once we are finished, go ahead and export this out to Bridge. This is a new feature and extremely helpful."},{"start":"11:16","end":"11:50","startSec":676.5,"text":"So if I go back into Mixer, you'll see that options in here so that we can control exactly what it's going to be. And we can also customize what we want it to be. So we can select a category and we can make a brand new category. And in that Bridge, if we go to our local library and let's go to online and we can see all the ones that we have. So once I've exported it, let's go back to the very top."},{"start":"11:50","end":"12:20","startSec":710.2,"text":"Let's go to all our categories here. And let me open up the Bridge real quick. So in Bridge, we're going to be able to see exactly what we've made custom for our own. Again, this is all going to be super helpful with your workflows. So if I bring Bridge over here, we'll see any favorites that we've made. We have local showing everything that we've downloaded."},{"start":"12:20","end":"12:51","startSec":740.5,"text":"We can say purchased collections. I can also make a new one for myself. So if I go in here and make a new one, brand new category, do a new category, new robots, or just call it robots in general, and hit OK. I can now export this one if I need to. Export to library."},{"start":"12:51","end":"13:23","startSec":771.3,"text":"And it's now going to export this object. And you'll see the exporting happening here. It's going to be looking at all the maps, all the accessories, and everything that's been painted. And it's going to crunch that down a bit so that we can have this quick and easily brought out of Bridge into any Unreal scene. So this is a brand new feature, which allows us to really be able to maintain and control exactly what we want. And again, we can categorize new things that we've created, and then we'll take it into"},{"start":"13:23","end":"13:54","startSec":803.8,"text":"Bridge. Now, this just takes a little bit of time. So I'll pause the video for a bit and let that run through because it's kind of squishing things down. You'll notice our texture is at 2048. But when we initially set this guy up, it is set to a 4096 in some cases. Looks like he might be done. He may not even have to pause. So let's go ahead and take a look at that in our library. So in Bridge, we're going to click on our local library, and we're going to click on Mixer."},{"start":"13:54","end":"14:14","startSec":834.4,"text":"And there he is. There's Crutch, our robot, with our materials. And there's a rock that you saw me messing with earlier. There's that rock right there. So both of these we've exported. And now that we've exported them to Bridge, we can send them to Unreal. It's really that easy."}],"03_Editing Assets - Part 2":[{"start":"0:00","end":"0:29","startSec":0.0,"text":"In this video, we're going to talk about how to create a Blueprint in Unreal in which we can populate it with Static Meshes and to be able to edit them quickly and duplicate them and make changes all across the board. So let's get started. So first we're going to create a Blueprint Actor, and let me show you how this works. We also have a step-by-step in the notes, which takes you through some of these details."},{"start":"0:30","end":"1:02","startSec":30.6,"text":"So let's go and do that. In Unreal, we have a seed here, and we want to be able to maybe make a set of stalactites type of objects sticking through the ground. I'm probably using that word incorrectly. There's stalagmites, stalagdites, I forget which one sticks up and which one sticks down. But in this case, there are spikes. So let's just say spikes. So these spikes, I'm going to have different versions of them, and I want to be able to actually change and edit them and not only change them individually, but also maybe change"},{"start":"1:02","end":"1:36","startSec":62.0,"text":"them all across the board. And it's actually pretty simple to do that. Unreal itself has an amazing instancing system within it in which you can duplicate things, and it really does look at the last one, and it allows for a quick calculation of that object. Now it does require a draw call, so many times emerging is more ideal. But when we're using Blueprints, it allows us to house different items within there, duplicate them, and maybe even change them all across the board so that Blueprint instance is being able to affect all different ones or separate ones as you work."},{"start":"1:36","end":"2:10","startSec":96.4,"text":"So let me show you how to do that. It's actually not that difficult. So we're going to go to our Blueprints here. I'm going to make a brand new NT Blueprint. You can select an object and say, hey, I'm going to make this instantly into a Blueprint. The only disadvantage you get with this is you can lose some of your scale, rotation, and translation within how's within that Blueprint. I like to be able to have the option of it still being there plus having it here within the details. So I like to do it here, do it raw. So I'm going to go in and right click here, and I'm going to create a new Blueprint class."},{"start":"2:10","end":"2:44","startSec":130.0,"text":"We'll just choose Actor because Actor is the most diversified. So if we needed to program right within this and edit it and make maybe special features, maybe you want to control how they work, maybe you want them to be more random, we can do so if we have an empty Actor. So it allows us to use our Blueprint programming scripting language to be able to make it more robust. So this is the most diversified. So we're going to hit on Actor. We're going to call this Blueprint underscore Spire control, and you can call it whatever"},{"start":"2:44","end":"3:17","startSec":164.7,"text":"you want if you're following along. So I'm going to double click on this. We're going to pop this up. And what we want to do is add a component. So component we want to add is our Spire. Unreal is pretty smart. In older versions of Unreal, you would do add a component and have to hunt it down. But many times if you haven't already selected, you can add a component and it'll actually recognize the one that you have selected, but not all the time. So sometimes there is a little bit of refresh. So we'll have to do Static Mesh. And you'll see here we can do an Static Mesh."},{"start":"3:17","end":"3:48","startSec":197.1,"text":"We want to do this one, not the Instance one because these are great too. They just give you a lot more options. If you have things already, say you've merged stuff such as a hierarchal instance Static Mesh, it will actually allow you to populate it. But we just want to do a Static Mesh in general. It's fine. And that works just fine because we don't have thousands of these. And if we did have a ton of them, we'd want to probably lean more towards foliage at that point. So I'm going to go Static Mesh here. I'm going to call this Spire 01."},{"start":"3:48","end":"4:18","startSec":228.2,"text":"And we'll hit Enter. Now if we go to our, now we're not going to create anything within our Event Graph. And we have that option that we can. But you'll see with this Spire selected, we have a Static Mesh component ready to go. If I wanted to be able to program in here some more, I can grab my Static Mesh from my, say it's populated in my environment. And I can drag that Static Mesh reference in here if I needed to. But we're not going to go that far into the weeds here."},{"start":"4:18","end":"4:52","startSec":258.4,"text":"So I'm going to go in here and grab that Spire. I can grab any Spire that I want. And I'll grab this first one here. And you'll see that it's now connected within our Blueprint. I'm going to go to my Viewport and we'll see that Spire is there. And that's perfect. That's exactly what we need. So we need to actually make sure we also have the correct material for him. So you'll see default material came in when we brought him in because we built this guide before Mixer had the option to be able to export immediately."},{"start":"4:52","end":"5:25","startSec":292.4,"text":"So what we can do is grab that material that we need for this Spire. And we're going to connect it to him. Now we're just going to grab one in the scene. I'm going to hit the magnifying glass. I'm going to cheat a little bit. And we're going to grab this and just drag it into this particular character. That's perfect. So I'm cheating a little bit and that's fine just to speed things up. I'm going to rotate this. It's good cheating. And I'm going to now hit my Spacebar. And I'm going to set this rotation to a world and keep my finger on the Alt key and drag"},{"start":"5:25","end":"6:00","startSec":325.6,"text":"and duplicate just one more within this Blueprint environment. So let me hit Alt drag this through. Actually I need to create another one. So sorry I was thinking in the Viewport. So we don't want to do that. What I do here and just do another static mesh. So what you got not enough coffee. You can grab a static mesh and we'll call this guy. And we don't want this guy to be parented underneath him. So we want to make it separate. We don't want to attach it in any way so we can move him and move him right on top there."},{"start":"6:00","end":"6:28","startSec":360.0,"text":"And it'll actually separate this. Let's give it a name. We'll call this static mesh 02. Or 02. That's perfect. There we go. And we'll move this one over. Oh it's not populated yet. Let's go and populate it with the same static mesh. Spire I should say."},{"start":"6:30","end":"6:56","startSec":390.4,"text":"So what happens when you attack and move things around. Grab the same material. Put it in there. Rotate it a bit so it looks a little bit different here. I hit spacebar and accident. It took into the material and that's fine. Let's rotate this though a little bit more. There we go. It looks a little bit different material wise. Rotate that down. Let's scale that down a bit. So let's switch that to vocal. We'll scale that down just a tad."},{"start":"7:00","end":"7:31","startSec":420.7,"text":"And we'll move this one a little bit past there. Make them kind of reflect on top of each other. And we'll do one more. Just for the heck of it. We'll do this guy here. And if you need to you can also duplicate it. So I just showed you how you can load them if you need it to be unique. But you can also duplicate it there. So with that duplication selected. Then I'll move this one over. And that's a little bit faster. But I wanted to show you that you can also load them one more time. Just in case you might have missed that the first time."},{"start":"7:31","end":"8:01","startSec":451.8,"text":"Move that down. And let's actually scale this one up. Every time I look at this it reminds me of chicken fingers. I'm not sure why. So we'll go ahead and grab this here. And move this up there. Alright so just a little quick clump of spires here. We can play with. Cool. So this fellow we can hit compile. We can find out where he's at by hitting browse. There's our new spire set. That we've made."},{"start":"8:01","end":"8:32","startSec":481.9,"text":"And this is the cool thing about the power of this. So I can move this spires in here. And I can scale them down. We can also do that within the blueprint itself. So I'll just do it here. Scale that down. My scale's a little funky so let's go and change that real quick here. Scale that down. There we go. One more fluid. And now I have a set of spires that I can control. Let me control so you won't see it too far."},{"start":"8:34","end":"9:04","startSec":514.0,"text":"Set of spires that I can place in the world any way that I want. I'll go to my camera here. You can see it's a false set here. There we go. And the cool thing about this. Is now I can pull this here. And I can hit alt and move this over. Rotate this one. About one, two. And we'll do this on an object basis rotation. So let's do that. Kind of rotate. It's kind of the same thing."},{"start":"9:04","end":"9:35","startSec":544.0,"text":"It's all good. And then we'll move this over. And. Go back to the world. We can rotate this any way that we desire. Give it a little bit of a different angle. And I can change these to make them individual. So with this one set here I can simply go into one. I can go into the blueprint itself. And I can change the angle. And I can change the angle."},{"start":"9:35","end":"10:05","startSec":575.2,"text":"And I can go into the blueprint itself. And edit it here. And the cool thing about this is if you want to change all of them you can. So I can hit the space bar. Let me move just a tad here. You can see it moving real time. Let me shrink this down just a little bit more. So you can see this actively happening. Because it's getting cut off. So as I rotate this you'll see both of them change. And that's actually kind of nice. So if you want to say hey I need to change all of them."},{"start":"10:05","end":"10:35","startSec":605.3,"text":"You can make a quick change for that. And I can hit compile. And it'll update them all on the fly. But the benefit also of doing this is the fact that I can go in here. Select this particular blueprint. And I can go individually here. And I can also rotate them without affecting the other ones. Which is really convenient to be able to do that. Scale it down and you'll notice we're keeping this blueprint still unique. So you can have a bunch of these in the scene. Do some quick editing. And it allows you to be able to control and edit things the way that you want."},{"start":"10:35","end":"11:05","startSec":635.4,"text":"And this is a really great way to maintain your scenes look and feel. And I kept it pretty simple. This can actually go for houses. If you need a door open it over here. But they're all the same type of copy of each other. And all you're doing is changing them quickly on the fly. Either as a whole or individually. And keeping them kind of like in a group setting with the other ones. And you can also do that with the other ones. And I can also do that with the other ones. And I can also do that with the other ones. And keeping them kind of like in a group setting with these blueprints. It's really great. And it allows you to add some more functionality. So if I wanted to make this more random."},{"start":"11:05","end":"11:15","startSec":665.5,"text":"Which is some of our other classes. Which talks about the introduction to blueprints for virtual production. You can actually go in there and make it more random. So it rotates randomly as you move things around. And shovel things around."}],"04_Variant Manager":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"The next tool we're going to talk about is the Variant Manager. We'll do a quick take on this and show you exactly how to get started with it and how many cool things you can do with it to really help with your production and to be able to help some of the people such as your art director or your director decide where they want to place things in the world quickly and easily. So one of the reasons to use it is to manage multiple assets at the same time with changes."},{"start":"0:30","end":"1:02","startSec":30.4,"text":"This can include rotation, scale, movement, color and multiple different aspects of this object. And you'll see that list when I pull it up. It's really a lot to name but you'll see that you really have a lot of control with this tool. One thing before we get started I want to mention is you have to be aware that if you are moving assets around in a virtual production that your light needs to be movable in some way. And that way if you are moving things around you don't necessarily have to do a full bake."},{"start":"1:02","end":"1:33","startSec":62.2,"text":"So if it's movable, if you add an asset or change an asset, Unreal won't get confused with your shadows and that movable light can update on the fly. This can also be set with ray tracing but again your systems need to support that efficiently and for the highest quality that you can get. Alright so let's actually look at what we can do. One of the first things we want to do is go to miscellaneous and then we want to set in a level variant set. And that's what we're going to do right now. So in here I just have a blank scene."},{"start":"1:33","end":"2:05","startSec":93.6,"text":"I just pulled in a house from our structures folder. Just slap that in here. And I'm going to go in here and just right click and I'll just do it here for now and that's fine. I'm going to go in here and go to my miscellaneous tab. In my miscellaneous tab we're going to go to our level variant sets and open that up. We'll call this level variant so LV underscore house set 01 and we'll double click on it."},{"start":"2:05","end":"2:35","startSec":125.3,"text":"In here we want to click on the variant set. So this is going to give us our first set. This is basically kind of a grouping method. It's going to now be ready to be populated. And I'm going to hit the plus button and in here this will make us our new variant. Now you can also just right click and say hey man let's add a variant or you can just hit that add button and that makes your life easier. With this object selected in our scene I easily just go in here right click and add selected actors."},{"start":"2:35","end":"3:06","startSec":155.7,"text":"This could be multiple actors or just one or whatever you choose you can add the actor here. Now you'll see instantly when I add that actor we have so many different things that we can choose from to be able to actually change this actor on the fly. If you want to change the material if you want to change mobility all these things are in here is a dynamic or not all these things are available in here which is really really convenient. It's specifically if you need to change positioning on an object or material quickly you can actually"},{"start":"3:07","end":"3:38","startSec":187.8,"text":"and the art director be able to see the changes suggested and what is available at their fingertips to be able to get the scenes that they need and want. So in here what we're going to be messing with is mainly the relative location the relative rotation and the relative scale. That's mainly what we're going to be messing with here. So we make sure we have those active. Now this is going to make it so that our static mesh we can control its positioning anywhere."},{"start":"3:38","end":"4:12","startSec":218.2,"text":"We can choose material and a few others but we won't go through all of these. They're pretty straightforward. So I'm going to hit select. Now this object in our 3D space with it selected I can go in here and just you know try to place it and put it in the right spot. Now what happens is a recording feature happens. You see this little dot active. If I move this around get this in the right spot that I need and I can click on this and you'll now see a little on the whole set of our regular translation rotation and scale"},{"start":"4:12","end":"4:44","startSec":252.0,"text":"that shows up in details will populate here. Sometimes it'll need a little refresh. You'll notice I clicked on it moved around a little bit click on it again. It'll pop up. So now that it's populated I can keep this in here. It's going to record that positioning but maybe I want to show the director a different type of position for this. So I can right click in here and duplicate that object and control W will do the same. And in here I now have this same geometry I double clicked on it active in this slot"},{"start":"4:44","end":"5:14","startSec":284.6,"text":"here and I can choose that position. I can move this position. I can rotate it just a tad and I can hit these two recording of those changes here. You'll see a little arrow with a flat kind of rectangular white icon pointing to it. So record that and record that change. So now when your director looks at your stage and says hey man that looks great but you been talking to the storyboard artist the concept artist and there's a few different"},{"start":"5:14","end":"5:47","startSec":314.6,"text":"things he wasn't maybe he couldn't quite make his decision on the art director or the director and you can now show them the switching between these. So I can click on this position that we've already have set in the defaults and then the new one that we rotated and we can keep duplicating these. We can keep making more with different positioning and this is allowing me to shuffle between these and this is what I meant by making sure that your light is movable for the fact that your shadow won't have to be set and you have to marry to a particular positioning of your"},{"start":"5:47","end":"6:18","startSec":347.3,"text":"shadow you'll just have that movable so as you flip through these different pieces of the model you're not going to have to re-bake every single time. Those are things to keep in mind when using this tool. You can see quickly we're switching between these and again this can be through material this can be all sorts of different dependencies in here and you saw the full list that you can do and this makes the variant manager really powerful and really great especially if you want to be able to show different varieties of layout and set dressing for a virtual production."}],"05_Managing Levels":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In this lesson, we're going to talk about managing levels and how we can maintain and create an environment in which we can have better workflows. So let's get started. The topics we'll cover is editing levels and why, and separating items and how that works. So editing levels and why. Most times when levels are simple, they can be managed in one persistent level. So oftentimes that is not the case, as others will need to edit specific items."},{"start":"0:32","end":"1:02","startSec":32.2,"text":"So in your team, they may be a group of people that are working with lighting, maybe working with the effects, maybe working with the geo. The level system in Unreal allows many people to work on a project and edit different aspects such as lights and geo, as well as effects without interfering with other items. This system keeps things clean and easier to maintain. But many people can also get confused on the difference between layers and working with our level system. Layers, you can think of it as a typical layer system that you would see in 3D Studio Max and Maya."},{"start":"1:02","end":"1:33","startSec":62.8,"text":"We won't get too much into this, but it works exactly the same way where you can just manage things more to that particular work area that you're in. And you can populate this any way that you need. But we're going to mainly focus on levels, which is a little bit more powerful because here, or actually I should say quite more powerful, because here we can actually load other levels that we've created that have separate pieces that have been built by someone else. Like someone could build, hey, I built this new city, this new building, these new rocks and terrain, and I'm going to give you this level."},{"start":"1:33","end":"2:04","startSec":93.6,"text":"So they can immigrate that level to you. And then now you may be the one person in charge or multiple people charge of assembling this. You can now go in here and say, hey, I'm going to now edit and add that existing level in here. So you can add existing. And that's kind of what I did here. And if you look down below, you'll see the spires level. It is actually loaded here. And if I hit this eyeball icon, you'll see that most of those, except for a few that I just plopped in recently, will actually disappear. So most of our spires are gone. And that makes it a lot easier."},{"start":"2:04","end":"2:34","startSec":124.5,"text":"So if you're that way, you can actually bring in what someone else has worked on. And at the same time, you can make some edits without affecting anybody else's stuff. You can say, hey, I'm going to make this current or I'm going to work on this particular one. In this case, we're working off the persistent level. Now one thing I do want to mention, though, when working with levels, when it comes to your lighting, make sure that your lighting, for the most part, is in your persistent level. This is actually a really good practice. Now is it a hard rule? Not all the time. Sometimes you can nest these in a different areas, but you do want to be careful if you"},{"start":"2:34","end":"3:04","startSec":154.7,"text":"nest them too deeply. You can make it have a disconnect when it comes to like baking your lights or even working with ray tracing. So you want to be careful of that and be aware of that situation. So as long as you're organized and keep things in a clean fashion and make sure you don't put these things in too many sub levels, you should be OK. So also I'll notice I'll point out to you when it comes to your streaming method. So you change streaming method. Right now we're set to blueprint. That makes it easy for us to just bring this item in here."},{"start":"3:04","end":"3:38","startSec":184.7,"text":"If you have it always loaded, just make sure you're aware of everything that's in that scene. If there's extra lights that are in that particular level that you're bringing in, you make sure that that's removed. So you're only using the lighting that's in your persistent level or whatever you're using for lighting. So there is no conflict. So when you're baking, there isn't any weirdness going on. There isn't double lights or double items. So organization again is super key to this. You'll see right here there's a save level icon. There's a save level and you also can change the level color so you can actually keep things a little bit more organized as well as create new folders for any items that you want to"},{"start":"3:38","end":"4:09","startSec":218.1,"text":"populate. So just keep those things in mind. And that's really beneficial. If I say I grab this select type and I said, hey, you know what? I want to add that select type. So just when I hit the eyeball button, everything is gone except for that. I can right click and I can go to move selected actors to level so I can move that right to that level if I needed to. You can deselect actors. You can convert external level actors. So there's a lot of different options here, which makes it a lot easier for you. You can even lock them if you need to or even make it current."},{"start":"4:09","end":"4:41","startSec":249.4,"text":"Now this is important to consider these things because having this edit control is really beneficial for your full production. Again, you can see you can add existing and you can even create new. When you create new, you literally are making a brand new scene and you can populate it really quickly. And in that new level, you will immediately have access to it. But just make sure again, housekeeping. You know exactly what's in that level and what's coming into your existing production. So I'm going to hit cancel here."},{"start":"4:41","end":"5:14","startSec":281.0,"text":"And we can see again, separating items. So there's two ways you can add the levels. And I'll reemphasize this because it can be kind of confusing in the very beginning when people try to understand how this works. You select your geolights or et cetera, what you wish to separate in a persistent level and go to levels, create new with selected actors. You can also load other outside levels, as mentioned before, to a persistent level and stream them via blueprint to call on it when needed or always loaded if you need it in the level right away while you work. Now the benefit of streaming levels, I'm going to point this out, of doing it through a blueprint"},{"start":"5:15","end":"5:46","startSec":315.3,"text":"you could also cycle through levels, lighting scenarios. Now most of that's a little bit geared more towards pre-visualization because most of the time when you're in a virtual set, you kind of determine exactly the lighting that you want because you want to make sure that everything's linking correctly. And when you're flipping through your persistent level, that can be a bit of an issue. So just keep that in mind. But having that blueprint allows you if you did need to cycle through a lighting system, it's not possible. It just takes a bit of work. You can actually do that within your environment, but it's better to change the light that you"},{"start":"5:46","end":"6:17","startSec":346.7,"text":"have existing on that case because there's a lot more involved, especially if you're working with such things as your tracking, your identifying, your linking your stage to what you're doing in your Unreal environment. So just keep those things in mind. There's a lot of work involved. But for the most part, you want to use your lighting. So if you are deciding to do blueprint and switching between streaming levels, that leans more towards pre-visualization. And then when it comes to the lighting, like I mentioned before, try to keep your linings not so much on the sub levels if you can."},{"start":"6:17","end":"6:36","startSec":377.9,"text":"Keeping it on your persistent level is a bit more ideal because then you have quick access to it. If you run into any problems, you make sure that things are linking cleanly. You're at the top level of everything. And it's not a golden rule because there are ways around that. It's just this is different from a game environment. This is more of a virtual production environment. So keep those things in mind."}],"06_Placement and Model Editing":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"In this video, we'll talk about placement and model editing using some of the newer tools for Unreal. So let's get started. The topics we'll look at first is placement and adjusting pivots, and model editing will come next when we look at some of the sculpting tools that Unreal has to offer. The first thing we'll need to do is turn on these new tools in our plugins in Unreal."},{"start":"0:30","end":"1:01","startSec":30.4,"text":"So let's go and do that real quick. So in Unreal, we're going to go to our settings, plugins, and you can also go there through edit plugins. And as we call this up, we're going to go and type in model. You can type in mesh too if you want to. Oh, kind of make sure I type it correctly. You can also type in mesh and turn on anything that you need with mesh editing. But in this case, we just need the modeling tools for editor mode. This will give us our ability to be able to edit interactively and make our models and"},{"start":"1:01","end":"1:36","startSec":61.8,"text":"shapes the way that we need on the fly. And that's pretty convenient to be able to do so. But there are some aspects of this tool that are still evolving and getting better and stronger. We'll go ahead and close that out. Now when you do turn it on, Unreal will ask you to reboot. So just keep that in mind. So as it reboots, you're going to now have the option to have modeling. Be able to activate that. You want to hit Shift 6 if you want to use those hotkeys. Now one of the first things I want to mention, which is super important to consider, is if"},{"start":"1:36","end":"2:08","startSec":96.1,"text":"you are going to change maybe you want to change the pivot on an existing instanced object, it's best to be able to make a copy of that first and then drag it in and work with that instanced object. So if you are changing any pivots or even sculpting, you want to be able to make sure and understand that Unreal's instancing feature is going to change things all across the board. So right now if I changed the pivot on this object here and I hit apply, it would affect"},{"start":"2:08","end":"2:39","startSec":128.8,"text":"everything in there that's already been duplicated in the scene and related to it. So what you want to do is go to your object's original area, original source, and I right click and I can duplicate this object and then now I can bring this object in the scene. And then now if I want to change its pivot, we know that it's only going to affect this new duplicate and not everything else. So just keep that in mind. In older versions of Unreal with this tool, it may not have been as much of a problem,"},{"start":"2:39","end":"3:09","startSec":159.5,"text":"but here you do want to keep in mind the instancing that occurs. So if I did sculpt on this object and he was duplicated in the world, it would actually show up on all the different assets. So keeping a copy can be helpful specifically if you want things to be unique. But I sculpted mine in such a way that even rotating these, they look like a brand new spike. So you can also do that too. It's kind of tricky. It's kind of like doing things like with a tree, you rotate it, it looks like a brand new tree. It's just the way you made it."},{"start":"3:09","end":"3:41","startSec":189.8,"text":"You made it asymmetrical. So those are things to consider. So now we have this object here and say we want to change its pivot. Now there is the old way to change pivots where you would simply just go in here and there's multiple ways to get this done. But what I normally do is go to pivot and I'll say, hey man, I'm going to reset my pivot offset and then I would change my pivot to what I want. And then I would say, set my pivot offset. Those were the two steps that I would do. But you can also just say, hey, move if you need it to temporarily be at a particular"},{"start":"3:41","end":"4:11","startSec":221.3,"text":"spot. So I can say, set my pivot offset here temporarily, move your piece of geometry or rotate it for that particular aspect of whatever you're doing. And then you can just click away and go back and it will go back to its default. So that could be helpful in some instances. But our new tool works pretty well. In the fact that you can go in here and you can go to our transform, I can edit the pivot, move the pivot physically as you would in a regular designated 3D application."},{"start":"4:12","end":"4:41","startSec":252.1,"text":"I can move this here or I can choose center, bottom, top, left, right, back and front. All of these things can be quickly, can quickly give you access to those position aids. And then you would hit apply, which is super helpful. But remember, if he's duplicated in the world and maybe there's another copy of him that's truncated and is rotated that is tweaked in some way and you change that pivot, it will affect that duplicate in this current version of Unreal. So let's keep those things in mind."},{"start":"4:42","end":"5:13","startSec":282.5,"text":"Another tool that we have to is if we want to sculpt this item. Now we can cut into it, we can offset it, we can even displace it and we can even warp it. So if I wanted to go in here and do some warping, that's available too. So you got to be careful though. Anything if you go beyond a particular amount, you can stretch your UVs beyond their limit. So let's keep that in mind. But we're going to mainly focus on the two sculpting tools here. So I'm going to go to the generic sculpt initially and I'm going to click on this one and I'm going to zoom in on my scene."},{"start":"5:13","end":"5:45","startSec":313.9,"text":"Let me hit the control button so you can see exactly where my mouse is at. So I can start sculpting on this object in such a way and it does it pretty cleanly using the default sculpt. Now again, everything has its limit. So if you go beyond the UV space or the shape, you may get some push and pull on your texture and you may at times even get holes in the geometry. So you might want to smooth these out and hitting the shift key allows you to do a little bit more of the smoothing. You can see there are a few options here and the ones we'll mainly focus on is in the sculpting"},{"start":"5:45","end":"6:16","startSec":345.0,"text":"area and also brush size and fall off. And our fall off is at one, which actually works pretty well. But you can also adjust that according to what you need. There's even a freeze a target area if you need and we're not going to get into that just here. But you can also control how this smoothing is going to occur with your fall off. And in our sculpt, you can see we have definitely a lot of different choices to choose from. Now again, we're using the default normal sculpt and it works pretty well with the UVs. But where you can really run into some problems and you got to be careful is when you decide"},{"start":"6:16","end":"6:46","startSec":376.2,"text":"to do, let me hit accept on this, when you decide to do a Dinosculpt. Now the Dinosculpt is awesome. The fact that it's really tries to imitate what you get from like 3D code and ZBrush where you get a little bit more dynamic, a little bit more organic with your sculpting. But in that case, it also can be at the cost of your UVs where you can get some stretching in your texture. So when you do play with this, just keep that in mind that you may have to go back in there tweak your UVs. Now we do have some UV tools and they're great, but they are also coming in a little hot."},{"start":"6:46","end":"7:17","startSec":406.8,"text":"They're evolving. So when you experiment with these and work with them, just make sure you save as you go as well as make sure that you understand the concepts of working with it. Now we're not going to get into in this particular case, we're mainly going to be working at looking at shape and positioning for this particular course. All right. So as I go in here and I edit these, you'll see the Dinosculpt come into play. You can see here, this is was a normal sculpt, but over here I can do Dinosculpting. We can kind of push things a little bit."},{"start":"7:17","end":"7:48","startSec":437.5,"text":"I'll do a little bit of smoothing again, hitting the shift key, do some smoothing and that can help any weirdness with your UVs, your textures being hit. And then we can hit accept. And we can see it did a pretty good job. There's a little bit of weirdness right here where we're pushing the shapes beyond the polygon limit. And in that case, we can go in here and maybe do a little bit more of a shift and smoothing aspects and fix some of those issues that may occur."},{"start":"7:48","end":"8:24","startSec":468.5,"text":"It still gets a little bit of the stretching there. And that's something you do need to be aware of because we really sculpted it pretty hard on that one. The generic sculpt versus the Dinosculpt is where you're going to see a lot of that type of effect happening, where you're going to get some really weird, obscure effects in here when it comes to warping and distorting things. Escape for a second, we'll go back to Dinosculpt and we'll then again, you can do some smoothing."},{"start":"8:24","end":"8:54","startSec":504.8,"text":"We can go up a little bit here in this case, pushing things back a little bit more to normal. And you may still see a bit of warping because this shape isn't the regular shape of this object. And I used a bit of moving in some cases. Some of the stuff had already been there. So we can use the move tool, move some of this back in based on the range of my brush."},{"start":"8:54","end":"9:10","startSec":534.9,"text":"And hit accept. So it's a little bit less, but they're still getting a little bit of warping here because we created space that didn't exist before. So just keep those things in mind when you're doing that."}],"07_Setting Up Base Materials":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"In this video, we're going to talk about setting up base materials and how we can get that foundation down and make sure that's a doorway to be able to create instance materials, which is going to help with our overall draw calls and overhead for our scenes. So let's get started. Some of the topics we're going to cover is a simple material setup and instancing those materials. First up, let's go and take a look at our spire material that we have set up and how"},{"start":"0:33","end":"1:06","startSec":33.6,"text":"we can actually open up some of these parameters to be able to have full control of how they look and feel. And we'll keep this pretty simple because we do have a materials class, but this for the most part just reminds you of the theory and the practice of this and how this actually will help your overall scenes. So let's go and take a look at this in Unreal. So in our Unreal scene here, we have our spire here that we can play with. So let's go and take a look at his material. I'm going to double click on this material. And we keep these concepts pretty simple, but so that you understand why and the purpose"},{"start":"1:06","end":"1:38","startSec":67.0,"text":"of this. So you'll see that we have a specular. He's always going to be active and set to a 0.5. The one thing you do need to keep in mind when working with a specular material is it can interfere with the strength of your roughness. So sometimes just lowering this to a simple zero can be kind of helpful. So all your texture information, as in your roughness and surface information is pulled from your roughness texture or whatever number of variables you're working with. Now this is the material editor."},{"start":"1:38","end":"2:09","startSec":98.6,"text":"At this point, you should be familiar with this concept, as in, excuse me, with this tool and how it works. And in here, you'll see that we have several different modes for our material. I'm just clicking right here, left clicking in the grid. You can see that you can choose whether it's a simple surface, defer decal, light function, volume, post-process. Those are actually pretty heavy lifters in changing the dependencies of how this material is going to look. And also we have a blend mode, which will allow us to even push further how our visuals"},{"start":"2:09","end":"2:40","startSec":129.5,"text":"are going to be for our material. So we're going to keep things pretty simple. We're going to have a surface opaque default lit. All that's good. Now remember, as you change things, such as turn things and make them more translucent, they can't get expensive. So keeping your materials in mind of exactly what you want, what your output is, is really important because as your material gets more complicated, such as with translucency, things can get expensive. Now what we can do to maybe help that out a bit, because the draw calls look at each"},{"start":"2:40","end":"3:09","startSec":160.2,"text":"one of your materials, is we can help out those draw calls a bit with some instancing. And instancing can be very helpful. Now you can have multiple instances off a parent or master mold material. You can have multiple instances derived from it. And you can have it so like there's 50, you can even go as far as 100. That's a limitation based on your GPU. But to be able to do that, to open this up, to open this master material, master mold"},{"start":"3:10","end":"3:44","startSec":190.5,"text":"To open it up, to be able to do that, we have to actually open up our parameters. So we have to go to each one of these textures, right click it here, and do a thing called convert to parameter. And we'll call this the albedo. And when you create these, you can also have the option when you open up these parameters to add a group. So we can call this the albedo. And I'm keeping this pretty simple. In the most part, what we might want to do is maybe introduce a multiply."},{"start":"3:44","end":"4:19","startSec":224.3,"text":"In that multiply, we maybe have a scalar parameter, which is a more upgraded version of this constant parameter here. To get there, you can either right click a constant parameter and convert to a parameter. Then we'll change it to a scalar parameter. Or simply keep your finger on the S key and the left click and you'll create a scalar parameter. And then in here, we could call this a, you know, I'm going to maybe change the color output of this individual texture. Maybe introduce a three constant vector."},{"start":"4:19","end":"4:51","startSec":259.2,"text":"This will be for color. We can keep it black and we can pull this albedo in here. You can get a preview what it's going to look like. You can see if we right click, start preview mode, you can see that we're all black. So you have to watch out between add and multiply what you're going to get. And in this case, we would set this to white. And they'll see your color information come through. And if you wanted to, let's stop that preview. We can control maybe how strong that's going to be."},{"start":"4:51","end":"5:23","startSec":291.9,"text":"So with this multiply in place, we can maybe pull in the strength of that albedo. By temporarily disconnecting this, moving this over here. Simply make another multiply. Put this in here. This in here. And then connect that right here."},{"start":"5:23","end":"5:54","startSec":323.7,"text":"And you'll see that it's dark at first, right? So this parameter, we can set that to one or even higher if we wanted to. And let's add this to the base. And you'll see now it's still a bit dark, right? Not quite exactly what we're looking for. So as you increase your multiply, you'll see that it's going to magnify things. So the nice thing about working with a scalar, we can keep things within a range. So I can say, hey, man, I want my default to be 10."},{"start":"5:54","end":"6:26","startSec":354.4,"text":"I want my slider. Or actually, that might be too strong. We'll do like maybe a five. And I want my slider minimum to be zero and my maximum to be five. So this all depends how you want to pull this through. But this gives you the magnification based on whatever color you've chosen. And that's one way you can do it. So there's multiple ways. And whenever you make these, make sure you comment them out. So you can say, hey, I want to comment this right here. We'll leave the C key. We'll leave this guy out just temporarily. And we'll just say here, color experiments."},{"start":"6:30","end":"7:00","startSec":390.2,"text":"And there's multiple ways to actually match this up. I just did this super generically. And in our classes, you'll see me talk about, as well as other instructors, how to set this up. And this is just a quick way. You could even just add. But this multiply and add kind of act a little bit like Photoshop, allowing us to stack. But you have to keep in mind what kind of color output you're going to get. And you can get that through a preview by right clicking, which you saw me do just a minute ago for previews and so forth. We could even lower this to maybe two if we wanted."},{"start":"7:02","end":"7:32","startSec":422.2,"text":"That's too dark. Let's do something like that. Or four. There we go. That's fine. All right. So that gives you a little bit of control. Gives you an idea of how that works. And you can also keep it simple. This just depends on how much control you want of this object. But if we are going to do this, again, we have to actually open up the parameters. Convert that to a parameter. Call this color overlay. And we've got to put them in a group. We're going to put them in that albedo group."},{"start":"7:32","end":"8:05","startSec":452.8,"text":"Do the same thing with the scalar parameter. Want to give it a name, though. We'll call this intensity color. So color intensity. Let's just put that there. And just put that into an albedo group. And then again, we want to open up each one of these. Convert to a parameter. Rough. Yes. And normally, you could put a multiply in here. And you can choose scalar parameter. I'll do this slightly quickly here."},{"start":"8:05","end":"8:37","startSec":485.6,"text":"Rough intensity. Because you should have had these classes at this point. Move that in there. We'll set his limitation to. And you can cheat a little bit. Because when it comes to roughness, it's typically a 0 to 1. That's really how it works. But you can cheat a little bit with Unreal. If we introduce a multiply, we can go a little bit higher. And I actually like to work with a little bit higher numbers. Instead of getting carpal tunnel and typing in 0.00.5, that's the intensity I'm looking for. You can cheat when it comes to the multiply in this particular case. And metallic, not so much."},{"start":"8:37","end":"9:07","startSec":517.5,"text":"So I'm going to go in here and put a 10. We'll do a 5 as default. If we want to increase that, we can set the minimum to 0 and maximum to 10. So then we can go higher. That's there. And we probably have to mute this a bit, because it's probably still too high. But that's fine. And we just set that to roughness there. And we also have ambient occlusion."},{"start":"9:07","end":"9:38","startSec":547.6,"text":"We'll leave that. We'll leave normal. Now, normal, if you want to control this, is a little bit counterintuitive artist-wise. But what you want to do is use a flatten normal. Sometimes I'll be lazy in my flatten normal. I'll just simply put in a scalar and flatten this. But the only problem is it works in a negative space. So it gets a little weird. So we'd have to actually flip that so it goes back to a positive. So since this works in an opposite direction, so negative is pushing forward the way you maybe"},{"start":"9:38","end":"10:10","startSec":578.2,"text":"have intended it, going positive numbers goes negative, that's going to be counterintuitive. So you have to actually use a 1 minus node. Back, there it is. I literally typed a node. And I can put that in my flatness here. And I would connect this to my scalar parameter. And we'll call it normal intensity. And I keep in this pretty basic."},{"start":"10:10","end":"10:40","startSec":610.3,"text":"Regularly, you would create a whole UV set where you can control how many times the UVs are tiling. In this case, since UV is very specific with his UVs, we probably should do that. Otherwise, you could really ugly fast. But if you have a more encompassing texture that is more generic and not really dependent on UVs, you can actually play with that a bit more. So I'm going to go and move this to the normal. And in that normal, we bring that into the normal. And in that normal, we bring that into the normal space there."},{"start":"10:40","end":"11:10","startSec":640.4,"text":"There we go. And again, we can control the intensity. In this case, we can set the intensity to, say, 5 if you want to go really strong, minimum 0. And then, say, we want to invert it. We could do a negative 5 for actually, I did that backwards. Here we go. Minimum is negative 5. My bad. That's negative 5. And the maximum is going to be just a little 5. There we go. Cool."},{"start":"11:10","end":"11:39","startSec":670.7,"text":"And if you ever wanted to bring in your geometry, just make sure you select your geometry in your content browser. With it selected, just click on the teapot, and it will load it in this viewer. All right, so with this all set up, we want to make sure, again, we open up the parameters. And this will be a normal. We're going to create a normal group. And we'll just add this to the normal group, too."},{"start":"11:45","end":"12:16","startSec":705.6,"text":"And we'll create a roughness group. Add this roughness intensity to that roughness group. Also, make sure this guy is connected to the roughness group. There he is. For some reason, I thought I didn't do that. And we'll just leave Albedo by himself, because nobody cares about him right now. So there we go. We even got commenting. We got this all set up. And I would hit Say. So I'm just going to apply in this case"},{"start":"12:16","end":"12:50","startSec":736.0,"text":"so I can rebuild this for another course. And I'm going to pull this across here. And then now I can right click this particular piece of geometry. It looks like it's a little bright. So we can probably go over that a little bit. It's all shiny. I actually kind of like it. But we can change that in the instance, believe it or not. So we'll do that in the instance. And you can see the update on the fly. So let's move this off to the side. I'm going to right click here. And we'll do Create Material Instance. And we're going to call this mi for Material Instance."},{"start":"12:50","end":"13:21","startSec":770.7,"text":"We go across. Let's get rid of that suffix. Enter. Open it up. Now when we open this, you're automatically going to notice the interface is quite different. So I'm going to turn on my Albedo. And that means I can switch any texture I want. So maybe I'm working with this texture in Mixer, 3D Co, or some other substance painter. And Color Intensity, Color Overlay. We got the Normal, Normal Intensity, Roughness, and Rough Intensity."},{"start":"13:21","end":"13:51","startSec":801.0,"text":"All of this can be controlled on the fly. So the Color Intensity, we can choose the darkness of it if we wanted to. And we can choose what color we want for it. Apply. And we can choose, make sure that's working here. Maybe double check. Got the parameter open."},{"start":"13:51","end":"14:22","startSec":831.3,"text":"Multiply Albedo. We're good. Cool. Go back to our real-time spire here. And we're going to Control Normal Intensity. We can lower the Normal Intensity or increase it. Now you'll notice nothing's happening here, because I forgot I have to actually apply it. So let's go on to Reset. And we're going to go back to the real-time spire. And we're going to have to actually apply it. So let's go ahead and slap it on this guy."},{"start":"14:22","end":"14:54","startSec":862.7,"text":"And we can control the Color Intensity. Now you'll see the updates. We can choose the color that we want. So in this case, we'll say, hey, man, I want this to be more white in nature. I want to give it a little red to it. There we go. Green, blue. I had to check my work there, because I noticed that I needed to go back a little bit. I thought, why isn't it working? Because I have to apply it. It's crazy. And then you can see all the color changes here."},{"start":"14:54","end":"15:25","startSec":894.5,"text":"And as we change those colors, let's get something that's really going to show up on screen. Blood, pinkish red. And we can now change the strength of that, which is pretty nice. And even in Sequencer, if you wanted to, you can open these parameters and animate this, which is actually pretty cool. And then we have Normal Intensity. We can decrease the Normal Intensity or increase it. You'll see it there. We can go Negative or Positive, Inverting. There's the Roughness Intensity. You can see it there."},{"start":"15:25","end":"15:50","startSec":925.0,"text":"Working my full spectrum of my slider here. And we can also choose to turn off my roughness if we don't want to use it at all. Decrease my roughness so there's no changes in it whatsoever. And all that's available for you to play with."}],"08_Foliage Quicktake":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this video, we're going to look at foliage, do a quick take of it, and see what the things that we can do to build our worlds. So let's get started. So foliage is a tool that can help populate our items in our world to get things in the right spot relatively quickly. We can get it in there quickly and get the look and visual display that we need, but is limited when using ray tracing due to photon counts."},{"start":"0:31","end":"1:01","startSec":31.1,"text":"Plants, assets with small details are a lot harder on your calculations and noise may occur, which will force you to use CVARs in some cases. For the most part, when it comes to ray tracing and foliage, you kind of maybe want to stir away from that, but if you do have foliage, keep it farther away from the camera. This will prevent anything in your virtual production from giving you some bad displays. Now, if you're going for final pixels, you can run some CVARs to get you the best possible results."},{"start":"1:01","end":"1:35","startSec":61.8,"text":"And if your GPU is strong, you should be able to get some good results with it. But just keep those things in mind. It's very important to consider. Ray tracing is evolving and is improving gradually. And also eventually we'll absorb that, as you can see with our Unreal 5 release, that Lumens is kind of taking over that particular area and getting stronger and stronger. So you just need to optimize your scene accordingly if you're to introduce foliage and lots of small assets if you're working with ray trace."},{"start":"1:35","end":"2:06","startSec":95.0,"text":"So if you are having trees move around, make sure you evaluate WPOs, works with your ray trace foliage. It's more geared towards final pixels. In a virtual production environment, ray trace is not really needed all the time, but it may be. It just depends on the art director. They may want to see that bounce immediately. And that also depends on your hardware and GPU and exactly what you're pushing to be able to get these results. And sometimes you could use screen space, global illumination, but you just keep those things in mind too, because as the camera changes and moves, there may be some clipping"},{"start":"2:06","end":"2:37","startSec":126.7,"text":"involved. Hero Static Meshes is ideal to work up close. So sometimes you may not even need foliage. You just grab that tree, put it right next to the camera, and that can be a bit more ideal in many cases. But let's take a look at foliage up close. So in my scene, you'll see, and let me get rid of this guy. He's pretty distracting. And we'll change our material back to its regular state."},{"start":"2:37","end":"3:07","startSec":157.0,"text":"It's going to ask me to save, and I'm going to say no. Oh, nope. It decided to stick around. I might have hit save, and that's fine. In that case, we'll go in here and lower the strength of it. A little more gray there. Kind of closer to what we had before. Maybe get a little bit wider."},{"start":"3:08","end":"3:41","startSec":188.6,"text":"So let's go ahead and take a look at that foliage up close. Just a little small thing there. All right. So we have some plants in here, and I'm going to go ahead and activate my Foliage tool. In my Foliage tool, Unreal and older versions wouldn't always populate here of what you had before, but now it does remember what you had, which is fantastic. And we're going to go ahead and turn all these on for a moment. Now let's pick on one of them for a second and look at some of our settings. You'll notice we have some settings here, but there's also some settings up top."},{"start":"3:41","end":"4:12","startSec":221.1,"text":"You can also control size, your density, and you can also have some... You can place it in the current level if you want to, and there's also filter. So what are you going to paint on? You want to paint on other foliage on top of foliage, which is... That's crazy talk. Your BSPs, which is your generic volume structures. They can be pieces of geometry for blocking, and Static Mesh and Landscape. So right now we're going to... Mainly Static Mesh would be our main point of contact here. So see we have density."},{"start":"4:12","end":"4:43","startSec":252.3,"text":"You can see that my density have increased. I've also messed with my scale size. So when I paint, we have a range between a smaller and a bigger size there, and it's free formed here. You can keep it uniform if you want to, or lock it within an axis. That actually can be pretty helpful. See my brush here? I'm going to change the scale of that brush by hitting the bracket keys, because I don't want to paint everywhere. There we go. Lower that down, just like with the modeling tool, and I can paint some foliage in place."},{"start":"4:43","end":"5:17","startSec":283.5,"text":"Pretty nice. And I have it so it's creating a really nice density in here. And we can even edit some of that here as well, some generic sizes. You can also do selecting of your individual assets by clicking on the Select tab. It allows you to select these individually. So you see, oh, you know what? I don't want this plant here. You can select it and pick on it if you needed to. That's up to you. You can also lasso, which activates your brush tool. You'll select a certain set that you want to do something with, or you want to change"},{"start":"5:17","end":"5:48","startSec":317.7,"text":"them in some way. Or you can even un, you can erase by hitting the Shift key. It allows you to erase. But there's also an Erase option up at the top, which is pretty great. And I'll just erase some more, get rid of some of these. We don't need all these plants everywhere. It's crazy talk. So you have some of these nice selection options and even Fill. Now you've got to be careful with Fill. You don't want to initially fill the whole world in the target area because that may"},{"start":"5:48","end":"6:18","startSec":348.2,"text":"bog things down. So there is a limit with this. As amazing as this tool is, it can make your scene come to a crawl. So you have to use it sparingly and you have to use it wisely. And that means you know exactly where you're going to put it and how you're going to use it. Now, if you come into issues in areas where you're like, you know, I think this is great. But up close, I mean, I've edited some of the plants and I think they're okay. But up close, I want to be able to have maybe the best, highest quality."},{"start":"6:18","end":"6:52","startSec":378.7,"text":"You don't always have to rely on foliage. You can bring in actual pieces of geometry, just pull them in. You can bring in the plant on its highest level of detail. It's up to you how you work that. But you can do that. And that's fine too, especially for virtual production. Because not everything has to be, when it comes to foliage, has to be an actual foliage item. If you're up close and looking at something, you may want that tree in its highest level of detail without, because what happens, it'd be up close to the camera, because what happens"},{"start":"6:52","end":"7:23","startSec":412.7,"text":"as you load things into foliage, it does become incidents. There is a little bit of a hit with it, especially on how far you are from the camera. But you can edit some of this too. So if I go to this plant that we have active, scroll up, click on the magnifying glass, I can go into this foliage actor and I can tell exactly how I want to, or how much detail I want out of this group. So I can say, hey man, I want high detail. And when you, or even foliage."},{"start":"7:23","end":"7:54","startSec":443.9,"text":"I usually choose high detail when it comes to virtual production because I want to get the best possible detail. When you select that, it'll say it's going to change it for all of them. Are you sure you want to do this? I'm going to say no in this case. And it will change it and make it so that you can have the highest amount of detail for that foliage. And it can't get expensive if you have a lot everywhere. So keep in mind too with ray tracing, like I said before, it is expensive and not always ideal because you want to avoid that noise. And if you do use it for ray tracing, a lot of times it's better to do that with final"},{"start":"7:54","end":"8:25","startSec":474.9,"text":"pixel, but you can have some plants and trees in the background. And a lot of times you're doing a mix of that. Here's my virtual tree and my virtual production. Here's my physical tree next to the actor. So you can actually do a trade off where you have stuff in the distance versus here's an actual item, a physical prop and get it to match and look like it believes it's believable for your environment. So you can do a lot of cheating with that. So the foliage shul is pretty great in the fact that if you needed stuff and it doesn't have to be limited to just plants. Now you can do rocks."},{"start":"8:25","end":"8:57","startSec":505.8,"text":"Say we turn all these plants off, even books in a library. So if I go in here and select these two rocks, like, hey man, I need some rocks. I can add some rocks in here. It's really great. And I can put them on static meshes if I want to. I may have it deactivated in this particular case for this guy. You can add it there. So it's really cool. It doesn't have to be plants. It doesn't necessarily have to be trees all the time. It can just be just some fodder, just some stuff that you have all over the place, stuff"},{"start":"8:57","end":"9:25","startSec":537.8,"text":"that you just want to populate. And again, you can control how it looks. There's a calling distance control too. Now this is a little bit more gamey and less virtual production. Specifically for virtual production, a lot of times your camera is pretty fixed. If it does move, it's very light with its movement. So some of these you may not even have to worry about, such as collisions and so forth. I wanted to point that out and show you the strength of what you can do and how you can control and get your scenes in the right area."}],"PGT_219.00_01_Introduction":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hi, everyone. My name is Sean Spitzer, instructor for Epic Games and master mentor for virtual production. What we're going to go through here is talk about how virtual production and the pipeline can be used to your advantage using some of our tools, such as Quixel Mixer and Quixel Bridge, and some of the tools within Unreal to be able to make world building for virtual production. So let's get started. The first thing we'll look at is the scope and initial setup."},{"start":"0:30","end":"1:03","startSec":30.8,"text":"For this is very important to look at your scene and how to actually efficiently build it. Some of the topics we're going to cover is examining workflow, determining shots and assets, and then also using mega scans. So first up, we're going to examine our workflow scope. It's obvious when starting and constructing a virtual set, the scope needs to be examined and the overall amount of work needed. When it comes to Unreal, it comes into play, it actually will work as a new type of tool. And the fact that it can fill the gap of what you would normally"},{"start":"1:03","end":"1:36","startSec":63.8,"text":"use from a designated 3D package that we could use in Unreal to be able to create our sets and in real time have an update of our scene and to be able to use that for our virtual production. It fills that gap that you would normally see from a standard workflow, as you can see here in our chart. It bridges the gap and makes it so that our final output is in real time and our visuals will update on the fly. This is ideal in this workflow and allows us to have virtual sets in the current climate."},{"start":"1:36","end":"2:07","startSec":96.8,"text":"So we have to determine our shots in the very beginning. It determines what's going to be or going to have the highest priority. Our hero shots versus our shots and items in that camera shot, which are less important. How many polygons are we going to have? What's our texture resolution? So once we determine exactly what our items and assets are, then we can push back and move things around exactly where we need them and also take into account what the textures are going to be and the poly counts. So your scene layout is going to be"},{"start":"2:07","end":"2:39","startSec":127.4,"text":"huge in determining exactly how your assets will be evolving. So using Megascans, let's go and take a look at Megascans and what we can do to get things going in the right direction. So let me pull up Bridge here. And you can see in Bridge, it actually allows us to have a quick access of all the things that we need and want. Now again, Quixel Bridge is free if you have an Unreal account. It allows you to be able to access all these and have unlimited downloads for these assets."},{"start":"2:39","end":"3:10","startSec":159.4,"text":"And at your fingertips, you can easily go to the Home button here and see what's new on what is the new collections that popped up within Quixel Bridge. These are fantastic. They allow you to get them quickly, download them, and once they are downloaded, it will go to my Purchased area. You can see that the colors of the icons will change in the fact that now I can export it. There's the export for it. And these, and you can also favorite them too."},{"start":"3:10","end":"3:41","startSec":190.2,"text":"So you can say, hey, I want to remember this asset. You have an icon to click on. And you'll see in your favorites, you'll see that now I have one, which is this rock set, which is fantastic as you work and edit and collect these. So you can see also what they look like. You can see that the size is large. You can see that it has some openings. And you can see that you can also use it as an assembly piece. You can actually put them in groups. And you can also see down here that there is a collection that is all connected. These assets are all connected within this collection here."},{"start":"3:41","end":"4:11","startSec":221.5,"text":"And that's actually pretty great to be able to work in this particular type of tool and to be able to get this done quickly and fast. You'll see down below, we also have our settings we can control, such as our download settings. We can choose what kind of texture output we want. We can look at the models that we want too. And you can choose your LODs. Now this is really important to consider when it comes to virtual production. You want to be able to choose your LODs wisely. If you have a larger scene and the camera's floating over and maybe you're rendering to final pixels,"},{"start":"4:11","end":"4:42","startSec":251.7,"text":"you may want a lot of these LODs. But if you have a set that's up close and the camera doesn't move as much and it's really static and your actors are in front of that, in front of that scene, you might want to limit it to more of the zero and one polygon counts for LODs and not have to load all of these. Because these can start to add up after a while if you're not careful. So let's go back. And in here, you can also see, you can choose your resolution, 4K, 8K, and keep those things in mind based on what hero objects you need."},{"start":"4:42","end":"5:14","startSec":282.8,"text":"We also have the export settings. So we saw the download settings here, but there's also the export settings and we can click on those. And in here, we can choose if we're going to go for Unreal or any other Disney 3D package, we can choose the engine version that we want. And you also want to make sure you have your plugin going to the right directory for the version of Unreal that you have and you make sure it goes into the plugins directory. The default project you want to keep that blank. You can, you have the option to change that if you want to,"},{"start":"5:14","end":"5:47","startSec":314.6,"text":"but I will easily forget as I'm in the pipe and I'm really trying to get stuff done. So I would leave this blank so that whatever Unreal I have open, it will automatically export my stuff into my scene. You also want to make sure when you do install the plugins for Quixel Bridge, that your Unreal is closed at that moment. And only open up Unreal once that plugin's all set in and then whenever you export, we'll go into that open Unreal. So make note of that. We have textures here. You can choose different surfaces that you want."},{"start":"5:47","end":"6:18","startSec":347.2,"text":"What will your 3D asset textures be and your decals and so forth. And they also have models here. So what you will bring by default in your LODs. And then finally, we have file names. So here you can choose what your names are going to be. So try to keep that as organized as possible. And you can also edit that later on if things change within your pipeline. You'll see I'm saying the same thing here. So I personally, again, do not have a default project to set that in. Keep that pretty blank. And as I said before, you'll see check boxes"},{"start":"6:18","end":"6:49","startSec":378.7,"text":"which are little check marks off of the corner which will tell you whether you have an asset or whether it can be downloaded and exported. And you'll see the blue right here. It is ready to be exported. So choosing your LODs wisely, like I said before, and I will re-emphasize this because this is really important to understand with virtual production. And Unreal is only going to do, and Quixel is only going to do what you tell it to do. So the LOD is very important."},{"start":"6:49","end":"7:21","startSec":409.2,"text":"You have to determine what and how much screen time that object's going to have. And if that object, now LODs are level of detail if you're unfamiliar with that. And that level of detail is determined how far the camera is from that object. But if that camera never really zooms out or zooms in or doesn't do it very much, you want to keep the highest level of detail for your virtual production if you can. And that's the wisest thing to do. And you can always go back in Unreal if you need to generate these. You can, maybe for another shot. Maybe there's another shot you want to use Unreal for"},{"start":"7:21","end":"7:52","startSec":441.3,"text":"and that one isn't virtual production based. It's maybe a sweeping camera shot. Then you can go in there and either export this out again or simply go in here and in Unreal, generate some more LODs to be used. So here's a link that you'll see in our documentation which gives you some further explanation for that. I'm going to give shouts out here to Brendan Jones for the donating the concept art and King Chen for the concept art that we'll be referencing in the next few slides. So in the next video, we're going to be looking at editing assets"},{"start":"7:52","end":"7:57","startSec":472.4,"text":"and how to work with them. And I'll show you exactly what we need to do to really get our stuff to come together."}],"PGT_219.00_02_Editing Assets - Part 1":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this lesson, we'll talk about editing assets using several of our tools that we have at our disposal. Some of the topics we'll be covering is Quixel Mixer, creating blueprints for quick edits, and the Variant Manager. When using Quixel Mixer, you want to make sure that your asset is in the center of your world, and the pivot is in the right spot in the zero-zero point in the grid of your"},{"start":"0:31","end":"1:03","startSec":31.1,"text":"designated 3D application. This is very important. You can do some edits when you bring it into Mixer and also Unreal, but it's better to have this stuff done ahead of time. If we look at Mixer up close, you'll see right within our setup, we can choose what we're going to bring into our scene. I can have generic assets or have a custom model. You'll see we have Crunch in here, who is a custom model imported into our scene."},{"start":"1:03","end":"1:34","startSec":63.0,"text":"You can also bring in assets from our local library and online. The hotkeys for that are L for the local library and O for online. You can bring in those assets and immediately edit them as you work. This is very convenient and helpful, and allows you to have quick access. Another thing is when you're adjusting your assets, if you need to, you can also adjust the scale within our setup options."},{"start":"1:34","end":"2:06","startSec":94.7,"text":"You can see here that we can control exactly how our size is going to be. This works in centimeters, so keep that in mind. If you're working in centimeters in your designated 3D application, just make sure that is equivalent to a 6 foot aspect ratio, which is about 183 centimeters in your designated 3D package. If you're building in that 3D package, just create a cube or a block or some sort of rectangle"},{"start":"2:06","end":"2:42","startSec":126.8,"text":"object that will represent that 183 centimeters for that 6 foot person, so that you keep everything within context and then you can put things in place the way that you need. We can bring in any material that we wish. We're going to probably leave Crunch for a moment and go to a more simpler one and just go back to Crunch. Let's go in here and open our mixes. We'll look at this alien stone to start out and we'll get back to Crunch in just a minute."},{"start":"2:42","end":"3:13","startSec":162.1,"text":"We'll see it load down here off in the very corner, so that it's loading the assets. This is one complete asset all by itself, no extras, no extra parts, as Crunch does have different pieces that come in. In this asset, we have several different layers that we've created. Up here at the top, you'll see that we have several layers that we can work from. One of them here is we can add a surface layer if we wish. This takes us directly into our local library and allows us to grab what we need, but we"},{"start":"3:13","end":"3:45","startSec":193.9,"text":"can also go to the online library and find anything else that we need. We see that we're working in all, but we probably more than likely want to work either with different displacements or the overall just materials in general. Whenever you're selecting an actual object, Unreal will want to know if you want to edit that or excuse me, Mixer, and it will give you a prompt for that. We're going to mainly focus with materials. Let's go back to the viewport. You'll see that I have a few already in here. You'll also see that I created a liquid layer, which you can do here."},{"start":"3:45","end":"4:15","startSec":225.5,"text":"You'll see the icon that looks like a drop of water. I can turn this off and you'll see the liquid layer get removed. It works similar to what you would see out of a smart material, where it tries to take into account every aspect of our edges and our normals and changes in shape and tries to apply the liquid accordingly. It does a really cool job of doing it. Again, we can change the color of that. If I wanted this color to be, I don't know, more of a blue, I can add a blue to it. You'll see a blue tint."},{"start":"4:15","end":"4:46","startSec":255.8,"text":"And we can truly get like that alien landscape we've always dreamt and wanted. It's really great to be able to edit that. You'll see the threshold, the radius, and the detail. All these things can be edited. And you'll also see if you wanted to add more of some custom masks and so forth, you can do so. You also see a thing called an add a layer set. Now this is new to Unreal and this allows us to be able to paint within particular pieces or different items that are separate within our model."},{"start":"4:46","end":"5:17","startSec":286.6,"text":"If we go back to Krunk, let me make sure I get him here. Always say his name wrong. Krunk or Krunk. It is Krunk. Krunk. Sorry, Krunk. Didn't need to get your name wrong. I'll say don't say it. Load him. You'll see that we have several of these layers already established and created here. And in with each one, as soon as he pops up here, it's populating right now. Within each one, we can paint in those pieces and those parts of that model, which makes"},{"start":"5:17","end":"5:50","startSec":317.9,"text":"it really great to work from. And you can see as I turn these off and on, you'll see that that ability is there. And you also can isolate as you're painting. So if you decide to make a new layer, you can say I don't want these particular target texture sets to be included in this new layer set that I've made. So I can turn these off and you can see these are isolated. This is new to Mixer, which allows us to be able to have more finite control. It's really great. You can even create metal masks if you need to in particular areas."},{"start":"5:50","end":"6:23","startSec":350.2,"text":"And that's all available for you. You can also see we can add decals. So say we just wanted to do a hand smear in this case. We haven't loaded anything else in our local library, but we can if we go online. We can find some decals and in those decals, we can add some more things and items to our stuff. We can add a lot of different decals that we can choose. Maybe he has some graffiti that someone's put on his chest. We can do that too. So but we'll just say he's part of the Lord of the Rings hand clan. So we can click on this one here."},{"start":"6:23","end":"6:54","startSec":383.4,"text":"And this hand smear is now in place within our scene. And we can actually paint with it if we need to too. So if we go to a new paint layer, we can also load different brushes, save different brushes, but also go and replace them if we have that isolated. So we can also place that within here. So there's a lot of control that you can do within these, which is really exceptional. In this paint layer, if we have another one we just made, we can go in here and paint"},{"start":"6:54","end":"7:25","startSec":414.5,"text":"the details that we need. You can increase or decrease using a displacement effect. You can push up or push down. This will give you that raised displacement or just set displacement in general so that when you paint, you can accordingly change that based on our brush shape and jitter size, all these different things such as angle. You can control some of these effects as you go through in here."},{"start":"7:25","end":"7:56","startSec":445.1,"text":"And if you don't want displacement, simply turn it off. So now when we paint, it's just raw paint. We'll undo those because we don't want to affect crunch too much. We don't want to upset him. So using Mixer, again, we can turn our eyeball on and off to turn them on, but we can also choose which type of things we want to paint. I did mention and show you that you can also load brushes, whether in Photoshop or an existing brush. You can turn those decals into painting because right now what we did before, we just loaded"},{"start":"7:56","end":"8:31","startSec":476.7,"text":"the decal. But if you wanted to be able to paint the decal, that is available. And you can also do a masking effect. You can also control how textures are projected and how they are controlled on an object. If we go back into Mixer, you'll see that we can actually go to, let's go to one of these sets that are in here. And you'll see, we'll open up placement here. So this is the hand paint that's been done."},{"start":"8:31","end":"9:03","startSec":511.4,"text":"And I can control how the placement is on here. Right now it's just box projection, but I can choose tiling if I wanted to. And let's actually tweak this out a little bit here. I didn't undo all the way. Let's actually undo from our last stuff. And let's pick, let's mess with scratches. It'll be a little bit more distinct and we can see that a bit better. We see some scratches that we see on his knees. So let's go ahead and rotate and move those scratches, or actually on his arm."},{"start":"9:03","end":"9:37","startSec":543.7,"text":"We'll see that move and rotate. We can choose how that projection is going to be. We can control tiling. We can go to free form. Adds a little bit more edge detail, but you can control again the tiling and the scale. And we can go back to box projection. All in here is underneath placement. You'll see many of these, which are active, we'll be able to have that. You'll also see that you can add a material ID if you need to. So you can separate your materials and paint with that particular material on a particular area if you need that."},{"start":"9:37","end":"10:09","startSec":577.9,"text":"You can also add a group if you need to. So you can make grouping folders. You'll see right here is a metal mask. As we click on this, you'll see it's isolated to what is associated with that object. We can control its opacity if we need to. That's on the hands distinctly. And you can add some more details in here if you need to. So we're not going to add a channel here. We're not going to get that deep with this, but I want to show you the power of this particular tool and what you can do."},{"start":"10:09","end":"10:44","startSec":610.0,"text":"You'll see the demonstration here within the GIFs within the lecture documentation provided for you. I'm showing how you can paint and you can also isolate. You can say, hey, I want to work with the arms. I can work with a textured set editor here. And that actually makes it a lot more easy for you. So if we go into your layers, you can see the isolation that I talked about. You can say, hey, I just want to paint on these items in this particular layer set. And your layer sets up in that corner. That makes it so you can isolate things a lot better and will help you with your workflow."},{"start":"10:44","end":"11:16","startSec":644.6,"text":"If you go into your actual layer sets that you have established, and I'm glad we have Krunk here with us today, you can actually double click on it and you'll see, or actually just simply click on it, you'll see what is being isolated for that object. And that's really helpful. And again, having that is going to be a very strong benefit to be able to paint on your objects. We can now, once we are finished, go ahead and export this out to Bridge. This is a new feature and extremely helpful."},{"start":"11:16","end":"11:50","startSec":676.5,"text":"So if I go back into Mixer, you'll see that options in here so that we can control exactly what it's going to be. And we can also customize what we want it to be. So we can select a category and we can make a brand new category. And in that Bridge, if we go to our local library and let's go to online and we can see all the ones that we have. So once I've exported it, let's go back to the very top."},{"start":"11:50","end":"12:20","startSec":710.2,"text":"Let's go to all our categories here. And let me open up the Bridge real quick. So in Bridge, we're going to be able to see exactly what we've made custom for our own. Again, this is all going to be super helpful with your workflows. So if I bring Bridge over here, we'll see any favorites that we've made. We have local showing everything that we've downloaded."},{"start":"12:20","end":"12:51","startSec":740.5,"text":"We can say purchased collections. I can also make a new one for myself. So if I go in here and make a new one, brand new category, do a new category, new robots, or just call it robots in general, and hit OK. I can now export this one if I need to. Export to library."},{"start":"12:51","end":"13:23","startSec":771.3,"text":"And it's now going to export this object. And you'll see the exporting happening here. It's going to be looking at all the maps, all the accessories, and everything that's been painted. And it's going to crunch that down a bit so that we can have this quick and easily brought out of Bridge into any Unreal scene. So this is a brand new feature, which allows us to really be able to maintain and control exactly what we want. And again, we can categorize new things that we've created, and then we'll take it into"},{"start":"13:23","end":"13:54","startSec":803.8,"text":"Bridge. Now, this just takes a little bit of time. So I'll pause the video for a bit and let that run through because it's kind of squishing things down. You'll notice our texture is at 2048. But when we initially set this guy up, it is set to a 4096 in some cases. Looks like he might be done. He may not even have to pause. So let's go ahead and take a look at that in our library. So in Bridge, we're going to click on our local library, and we're going to click on Mixer."},{"start":"13:54","end":"14:14","startSec":834.4,"text":"And there he is. There's Crutch, our robot, with our materials. And there's a rock that you saw me messing with earlier. There's that rock right there. So both of these we've exported. And now that we've exported them to Bridge, we can send them to Unreal. It's really that easy."}],"PGT_219.00_03_Editing Assets - Part 2":[{"start":"0:00","end":"0:29","startSec":0.0,"text":"In this video, we're going to talk about how to create a Blueprint in Unreal in which we can populate it with Static Meshes and to be able to edit them quickly and duplicate them and make changes all across the board. So let's get started. So first we're going to create a Blueprint Actor, and let me show you how this works. We also have a step-by-step in the notes, which takes you through some of these details."},{"start":"0:30","end":"1:02","startSec":30.6,"text":"So let's go and do that. In Unreal, we have a seed here, and we want to be able to maybe make a set of stalactites type of objects sticking through the ground. I'm probably using that word incorrectly. There's stalagmites, stalagdites, I forget which one sticks up and which one sticks down. But in this case, there are spikes. So let's just say spikes. So these spikes, I'm going to have different versions of them, and I want to be able to actually change and edit them and not only change them individually, but also maybe change"},{"start":"1:02","end":"1:36","startSec":62.0,"text":"them all across the board. And it's actually pretty simple to do that. Unreal itself has an amazing instancing system within it in which you can duplicate things, and it really does look at the last one, and it allows for a quick calculation of that object. Now it does require a draw call, so many times emerging is more ideal. But when we're using Blueprints, it allows us to house different items within there, duplicate them, and maybe even change them all across the board so that Blueprint instance is being able to affect all different ones or separate ones as you work."},{"start":"1:36","end":"2:10","startSec":96.4,"text":"So let me show you how to do that. It's actually not that difficult. So we're going to go to our Blueprints here. I'm going to make a brand new NT Blueprint. You can select an object and say, hey, I'm going to make this instantly into a Blueprint. The only disadvantage you get with this is you can lose some of your scale, rotation, and translation within how's within that Blueprint. I like to be able to have the option of it still being there plus having it here within the details. So I like to do it here, do it raw. So I'm going to go in and right click here, and I'm going to create a new Blueprint class."},{"start":"2:10","end":"2:44","startSec":130.0,"text":"We'll just choose Actor because Actor is the most diversified. So if we needed to program right within this and edit it and make maybe special features, maybe you want to control how they work, maybe you want them to be more random, we can do so if we have an empty Actor. So it allows us to use our Blueprint programming scripting language to be able to make it more robust. So this is the most diversified. So we're going to hit on Actor. We're going to call this Blueprint underscore Spire control, and you can call it whatever"},{"start":"2:44","end":"3:17","startSec":164.7,"text":"you want if you're following along. So I'm going to double click on this. We're going to pop this up. And what we want to do is add a component. So component we want to add is our Spire. Unreal is pretty smart. In older versions of Unreal, you would do add a component and have to hunt it down. But many times if you haven't already selected, you can add a component and it'll actually recognize the one that you have selected, but not all the time. So sometimes there is a little bit of refresh. So we'll have to do Static Mesh. And you'll see here we can do an Static Mesh."},{"start":"3:17","end":"3:48","startSec":197.1,"text":"We want to do this one, not the Instance one because these are great too. They just give you a lot more options. If you have things already, say you've merged stuff such as a hierarchal instance Static Mesh, it will actually allow you to populate it. But we just want to do a Static Mesh in general. It's fine. And that works just fine because we don't have thousands of these. And if we did have a ton of them, we'd want to probably lean more towards foliage at that point. So I'm going to go Static Mesh here. I'm going to call this Spire 01."},{"start":"3:48","end":"4:18","startSec":228.2,"text":"And we'll hit Enter. Now if we go to our, now we're not going to create anything within our Event Graph. And we have that option that we can. But you'll see with this Spire selected, we have a Static Mesh component ready to go. If I wanted to be able to program in here some more, I can grab my Static Mesh from my, say it's populated in my environment. And I can drag that Static Mesh reference in here if I needed to. But we're not going to go that far into the weeds here."},{"start":"4:18","end":"4:52","startSec":258.4,"text":"So I'm going to go in here and grab that Spire. I can grab any Spire that I want. And I'll grab this first one here. And you'll see that it's now connected within our Blueprint. I'm going to go to my Viewport and we'll see that Spire is there. And that's perfect. That's exactly what we need. So we need to actually make sure we also have the correct material for him. So you'll see default material came in when we brought him in because we built this guide before Mixer had the option to be able to export immediately."},{"start":"4:52","end":"5:25","startSec":292.4,"text":"So what we can do is grab that material that we need for this Spire. And we're going to connect it to him. Now we're just going to grab one in the scene. I'm going to hit the magnifying glass. I'm going to cheat a little bit. And we're going to grab this and just drag it into this particular character. That's perfect. So I'm cheating a little bit and that's fine just to speed things up. I'm going to rotate this. It's good cheating. And I'm going to now hit my Spacebar. And I'm going to set this rotation to a world and keep my finger on the Alt key and drag"},{"start":"5:25","end":"6:00","startSec":325.6,"text":"and duplicate just one more within this Blueprint environment. So let me hit Alt drag this through. Actually I need to create another one. So sorry I was thinking in the Viewport. So we don't want to do that. What I do here and just do another static mesh. So what you got not enough coffee. You can grab a static mesh and we'll call this guy. And we don't want this guy to be parented underneath him. So we want to make it separate. We don't want to attach it in any way so we can move him and move him right on top there."},{"start":"6:00","end":"6:28","startSec":360.0,"text":"And it'll actually separate this. Let's give it a name. We'll call this static mesh 02. Or 02. That's perfect. There we go. And we'll move this one over. Oh it's not populated yet. Let's go and populate it with the same static mesh. Spire I should say."},{"start":"6:30","end":"6:56","startSec":390.4,"text":"So what happens when you attack and move things around. Grab the same material. Put it in there. Rotate it a bit so it looks a little bit different here. I hit spacebar and accident. It took into the material and that's fine. Let's rotate this though a little bit more. There we go. It looks a little bit different material wise. Rotate that down. Let's scale that down a bit. So let's switch that to vocal. We'll scale that down just a tad."},{"start":"7:00","end":"7:31","startSec":420.7,"text":"And we'll move this one a little bit past there. Make them kind of reflect on top of each other. And we'll do one more. Just for the heck of it. We'll do this guy here. And if you need to you can also duplicate it. So I just showed you how you can load them if you need it to be unique. But you can also duplicate it there. So with that duplication selected. Then I'll move this one over. And that's a little bit faster. But I wanted to show you that you can also load them one more time. Just in case you might have missed that the first time."},{"start":"7:31","end":"8:01","startSec":451.8,"text":"Move that down. And let's actually scale this one up. Every time I look at this it reminds me of chicken fingers. I'm not sure why. So we'll go ahead and grab this here. And move this up there. Alright so just a little quick clump of spires here. We can play with. Cool. So this fellow we can hit compile. We can find out where he's at by hitting browse. There's our new spire set. That we've made."},{"start":"8:01","end":"8:32","startSec":481.9,"text":"And this is the cool thing about the power of this. So I can move this spires in here. And I can scale them down. We can also do that within the blueprint itself. So I'll just do it here. Scale that down. My scale's a little funky so let's go and change that real quick here. Scale that down. There we go. One more fluid. And now I have a set of spires that I can control. Let me control so you won't see it too far."},{"start":"8:34","end":"9:04","startSec":514.0,"text":"Set of spires that I can place in the world any way that I want. I'll go to my camera here. You can see it's a false set here. There we go. And the cool thing about this. Is now I can pull this here. And I can hit alt and move this over. Rotate this one. About one, two. And we'll do this on an object basis rotation. So let's do that. Kind of rotate. It's kind of the same thing."},{"start":"9:04","end":"9:35","startSec":544.0,"text":"It's all good. And then we'll move this over. And. Go back to the world. We can rotate this any way that we desire. Give it a little bit of a different angle. And I can change these to make them individual. So with this one set here I can simply go into one. I can go into the blueprint itself. And I can change the angle. And I can change the angle."},{"start":"9:35","end":"10:05","startSec":575.2,"text":"And I can go into the blueprint itself. And edit it here. And the cool thing about this is if you want to change all of them you can. So I can hit the space bar. Let me move just a tad here. You can see it moving real time. Let me shrink this down just a little bit more. So you can see this actively happening. Because it's getting cut off. So as I rotate this you'll see both of them change. And that's actually kind of nice. So if you want to say hey I need to change all of them."},{"start":"10:05","end":"10:35","startSec":605.3,"text":"You can make a quick change for that. And I can hit compile. And it'll update them all on the fly. But the benefit also of doing this is the fact that I can go in here. Select this particular blueprint. And I can go individually here. And I can also rotate them without affecting the other ones. Which is really convenient to be able to do that. Scale it down and you'll notice we're keeping this blueprint still unique. So you can have a bunch of these in the scene. Do some quick editing. And it allows you to be able to control and edit things the way that you want."},{"start":"10:35","end":"11:05","startSec":635.4,"text":"And this is a really great way to maintain your scenes look and feel. And I kept it pretty simple. This can actually go for houses. If you need a door open it over here. But they're all the same type of copy of each other. And all you're doing is changing them quickly on the fly. Either as a whole or individually. And keeping them kind of like in a group setting with the other ones. And you can also do that with the other ones. And I can also do that with the other ones. And I can also do that with the other ones. And keeping them kind of like in a group setting with these blueprints. It's really great. And it allows you to add some more functionality. So if I wanted to make this more random."},{"start":"11:05","end":"11:15","startSec":665.5,"text":"Which is some of our other classes. Which talks about the introduction to blueprints for virtual production. You can actually go in there and make it more random. So it rotates randomly as you move things around. And shovel things around."}],"PGT_219.00_04_Variant Manager":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"The next tool we're going to talk about is the Variant Manager. We'll do a quick take on this and show you exactly how to get started with it and how many cool things you can do with it to really help with your production and to be able to help some of the people such as your art director or your director decide where they want to place things in the world quickly and easily. So one of the reasons to use it is to manage multiple assets at the same time with changes."},{"start":"0:30","end":"1:02","startSec":30.4,"text":"This can include rotation, scale, movement, color and multiple different aspects of this object. And you'll see that list when I pull it up. It's really a lot to name but you'll see that you really have a lot of control with this tool. One thing before we get started I want to mention is you have to be aware that if you are moving assets around in a virtual production that your light needs to be movable in some way. And that way if you are moving things around you don't necessarily have to do a full bake."},{"start":"1:02","end":"1:33","startSec":62.2,"text":"So if it's movable, if you add an asset or change an asset, Unreal won't get confused with your shadows and that movable light can update on the fly. This can also be set with ray tracing but again your systems need to support that efficiently and for the highest quality that you can get. Alright so let's actually look at what we can do. One of the first things we want to do is go to miscellaneous and then we want to set in a level variant set. And that's what we're going to do right now. So in here I just have a blank scene."},{"start":"1:33","end":"2:05","startSec":93.6,"text":"I just pulled in a house from our structures folder. Just slap that in here. And I'm going to go in here and just right click and I'll just do it here for now and that's fine. I'm going to go in here and go to my miscellaneous tab. In my miscellaneous tab we're going to go to our level variant sets and open that up. We'll call this level variant so LV underscore house set 01 and we'll double click on it."},{"start":"2:05","end":"2:35","startSec":125.3,"text":"In here we want to click on the variant set. So this is going to give us our first set. This is basically kind of a grouping method. It's going to now be ready to be populated. And I'm going to hit the plus button and in here this will make us our new variant. Now you can also just right click and say hey man let's add a variant or you can just hit that add button and that makes your life easier. With this object selected in our scene I easily just go in here right click and add selected actors."},{"start":"2:35","end":"3:06","startSec":155.7,"text":"This could be multiple actors or just one or whatever you choose you can add the actor here. Now you'll see instantly when I add that actor we have so many different things that we can choose from to be able to actually change this actor on the fly. If you want to change the material if you want to change mobility all these things are in here is a dynamic or not all these things are available in here which is really really convenient. It's specifically if you need to change positioning on an object or material quickly you can actually"},{"start":"3:07","end":"3:38","startSec":187.8,"text":"and the art director be able to see the changes suggested and what is available at their fingertips to be able to get the scenes that they need and want. So in here what we're going to be messing with is mainly the relative location the relative rotation and the relative scale. That's mainly what we're going to be messing with here. So we make sure we have those active. Now this is going to make it so that our static mesh we can control its positioning anywhere."},{"start":"3:38","end":"4:12","startSec":218.2,"text":"We can choose material and a few others but we won't go through all of these. They're pretty straightforward. So I'm going to hit select. Now this object in our 3D space with it selected I can go in here and just you know try to place it and put it in the right spot. Now what happens is a recording feature happens. You see this little dot active. If I move this around get this in the right spot that I need and I can click on this and you'll now see a little on the whole set of our regular translation rotation and scale"},{"start":"4:12","end":"4:44","startSec":252.0,"text":"that shows up in details will populate here. Sometimes it'll need a little refresh. You'll notice I clicked on it moved around a little bit click on it again. It'll pop up. So now that it's populated I can keep this in here. It's going to record that positioning but maybe I want to show the director a different type of position for this. So I can right click in here and duplicate that object and control W will do the same. And in here I now have this same geometry I double clicked on it active in this slot"},{"start":"4:44","end":"5:14","startSec":284.6,"text":"here and I can choose that position. I can move this position. I can rotate it just a tad and I can hit these two recording of those changes here. You'll see a little arrow with a flat kind of rectangular white icon pointing to it. So record that and record that change. So now when your director looks at your stage and says hey man that looks great but you been talking to the storyboard artist the concept artist and there's a few different"},{"start":"5:14","end":"5:47","startSec":314.6,"text":"things he wasn't maybe he couldn't quite make his decision on the art director or the director and you can now show them the switching between these. So I can click on this position that we've already have set in the defaults and then the new one that we rotated and we can keep duplicating these. We can keep making more with different positioning and this is allowing me to shuffle between these and this is what I meant by making sure that your light is movable for the fact that your shadow won't have to be set and you have to marry to a particular positioning of your"},{"start":"5:47","end":"6:18","startSec":347.3,"text":"shadow you'll just have that movable so as you flip through these different pieces of the model you're not going to have to re-bake every single time. Those are things to keep in mind when using this tool. You can see quickly we're switching between these and again this can be through material this can be all sorts of different dependencies in here and you saw the full list that you can do and this makes the variant manager really powerful and really great especially if you want to be able to show different varieties of layout and set dressing for a virtual production."}],"PGT_219.00_05_Managing Levels":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In this lesson, we're going to talk about managing levels and how we can maintain and create an environment in which we can have better workflows. So let's get started. The topics we'll cover is editing levels and why, and separating items and how that works. So editing levels and why. Most times when levels are simple, they can be managed in one persistent level. So oftentimes that is not the case, as others will need to edit specific items."},{"start":"0:32","end":"1:02","startSec":32.2,"text":"So in your team, they may be a group of people that are working with lighting, maybe working with the effects, maybe working with the geo. The level system in Unreal allows many people to work on a project and edit different aspects such as lights and geo, as well as effects without interfering with other items. This system keeps things clean and easier to maintain. But many people can also get confused on the difference between layers and working with our level system. Layers, you can think of it as a typical layer system that you would see in 3D Studio Max and Maya."},{"start":"1:02","end":"1:33","startSec":62.8,"text":"We won't get too much into this, but it works exactly the same way where you can just manage things more to that particular work area that you're in. And you can populate this any way that you need. But we're going to mainly focus on levels, which is a little bit more powerful because here, or actually I should say quite more powerful, because here we can actually load other levels that we've created that have separate pieces that have been built by someone else. Like someone could build, hey, I built this new city, this new building, these new rocks and terrain, and I'm going to give you this level."},{"start":"1:33","end":"2:04","startSec":93.6,"text":"So they can immigrate that level to you. And then now you may be the one person in charge or multiple people charge of assembling this. You can now go in here and say, hey, I'm going to now edit and add that existing level in here. So you can add existing. And that's kind of what I did here. And if you look down below, you'll see the spires level. It is actually loaded here. And if I hit this eyeball icon, you'll see that most of those, except for a few that I just plopped in recently, will actually disappear. So most of our spires are gone. And that makes it a lot easier."},{"start":"2:04","end":"2:34","startSec":124.5,"text":"So if you're that way, you can actually bring in what someone else has worked on. And at the same time, you can make some edits without affecting anybody else's stuff. You can say, hey, I'm going to make this current or I'm going to work on this particular one. In this case, we're working off the persistent level. Now one thing I do want to mention, though, when working with levels, when it comes to your lighting, make sure that your lighting, for the most part, is in your persistent level. This is actually a really good practice. Now is it a hard rule? Not all the time. Sometimes you can nest these in a different areas, but you do want to be careful if you"},{"start":"2:34","end":"3:04","startSec":154.7,"text":"nest them too deeply. You can make it have a disconnect when it comes to like baking your lights or even working with ray tracing. So you want to be careful of that and be aware of that situation. So as long as you're organized and keep things in a clean fashion and make sure you don't put these things in too many sub levels, you should be OK. So also I'll notice I'll point out to you when it comes to your streaming method. So you change streaming method. Right now we're set to blueprint. That makes it easy for us to just bring this item in here."},{"start":"3:04","end":"3:38","startSec":184.7,"text":"If you have it always loaded, just make sure you're aware of everything that's in that scene. If there's extra lights that are in that particular level that you're bringing in, you make sure that that's removed. So you're only using the lighting that's in your persistent level or whatever you're using for lighting. So there is no conflict. So when you're baking, there isn't any weirdness going on. There isn't double lights or double items. So organization again is super key to this. You'll see right here there's a save level icon. There's a save level and you also can change the level color so you can actually keep things a little bit more organized as well as create new folders for any items that you want to"},{"start":"3:38","end":"4:09","startSec":218.1,"text":"populate. So just keep those things in mind. And that's really beneficial. If I say I grab this select type and I said, hey, you know what? I want to add that select type. So just when I hit the eyeball button, everything is gone except for that. I can right click and I can go to move selected actors to level so I can move that right to that level if I needed to. You can deselect actors. You can convert external level actors. So there's a lot of different options here, which makes it a lot easier for you. You can even lock them if you need to or even make it current."},{"start":"4:09","end":"4:41","startSec":249.4,"text":"Now this is important to consider these things because having this edit control is really beneficial for your full production. Again, you can see you can add existing and you can even create new. When you create new, you literally are making a brand new scene and you can populate it really quickly. And in that new level, you will immediately have access to it. But just make sure again, housekeeping. You know exactly what's in that level and what's coming into your existing production. So I'm going to hit cancel here."},{"start":"4:41","end":"5:14","startSec":281.0,"text":"And we can see again, separating items. So there's two ways you can add the levels. And I'll reemphasize this because it can be kind of confusing in the very beginning when people try to understand how this works. You select your geolights or et cetera, what you wish to separate in a persistent level and go to levels, create new with selected actors. You can also load other outside levels, as mentioned before, to a persistent level and stream them via blueprint to call on it when needed or always loaded if you need it in the level right away while you work. Now the benefit of streaming levels, I'm going to point this out, of doing it through a blueprint"},{"start":"5:15","end":"5:46","startSec":315.3,"text":"you could also cycle through levels, lighting scenarios. Now most of that's a little bit geared more towards pre-visualization because most of the time when you're in a virtual set, you kind of determine exactly the lighting that you want because you want to make sure that everything's linking correctly. And when you're flipping through your persistent level, that can be a bit of an issue. So just keep that in mind. But having that blueprint allows you if you did need to cycle through a lighting system, it's not possible. It just takes a bit of work. You can actually do that within your environment, but it's better to change the light that you"},{"start":"5:46","end":"6:17","startSec":346.7,"text":"have existing on that case because there's a lot more involved, especially if you're working with such things as your tracking, your identifying, your linking your stage to what you're doing in your Unreal environment. So just keep those things in mind. There's a lot of work involved. But for the most part, you want to use your lighting. So if you are deciding to do blueprint and switching between streaming levels, that leans more towards pre-visualization. And then when it comes to the lighting, like I mentioned before, try to keep your linings not so much on the sub levels if you can."},{"start":"6:17","end":"6:36","startSec":377.9,"text":"Keeping it on your persistent level is a bit more ideal because then you have quick access to it. If you run into any problems, you make sure that things are linking cleanly. You're at the top level of everything. And it's not a golden rule because there are ways around that. It's just this is different from a game environment. This is more of a virtual production environment. So keep those things in mind."}],"PGT_219.00_06_Placement and Model Editing":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"In this video, we'll talk about placement and model editing using some of the newer tools for Unreal. So let's get started. The topics we'll look at first is placement and adjusting pivots, and model editing will come next when we look at some of the sculpting tools that Unreal has to offer. The first thing we'll need to do is turn on these new tools in our plugins in Unreal."},{"start":"0:30","end":"1:01","startSec":30.4,"text":"So let's go and do that real quick. So in Unreal, we're going to go to our settings, plugins, and you can also go there through edit plugins. And as we call this up, we're going to go and type in model. You can type in mesh too if you want to. Oh, kind of make sure I type it correctly. You can also type in mesh and turn on anything that you need with mesh editing. But in this case, we just need the modeling tools for editor mode. This will give us our ability to be able to edit interactively and make our models and"},{"start":"1:01","end":"1:36","startSec":61.8,"text":"shapes the way that we need on the fly. And that's pretty convenient to be able to do so. But there are some aspects of this tool that are still evolving and getting better and stronger. We'll go ahead and close that out. Now when you do turn it on, Unreal will ask you to reboot. So just keep that in mind. So as it reboots, you're going to now have the option to have modeling. Be able to activate that. You want to hit Shift 6 if you want to use those hotkeys. Now one of the first things I want to mention, which is super important to consider, is if"},{"start":"1:36","end":"2:08","startSec":96.1,"text":"you are going to change maybe you want to change the pivot on an existing instanced object, it's best to be able to make a copy of that first and then drag it in and work with that instanced object. So if you are changing any pivots or even sculpting, you want to be able to make sure and understand that Unreal's instancing feature is going to change things all across the board. So right now if I changed the pivot on this object here and I hit apply, it would affect"},{"start":"2:08","end":"2:39","startSec":128.8,"text":"everything in there that's already been duplicated in the scene and related to it. So what you want to do is go to your object's original area, original source, and I right click and I can duplicate this object and then now I can bring this object in the scene. And then now if I want to change its pivot, we know that it's only going to affect this new duplicate and not everything else. So just keep that in mind. In older versions of Unreal with this tool, it may not have been as much of a problem,"},{"start":"2:39","end":"3:09","startSec":159.5,"text":"but here you do want to keep in mind the instancing that occurs. So if I did sculpt on this object and he was duplicated in the world, it would actually show up on all the different assets. So keeping a copy can be helpful specifically if you want things to be unique. But I sculpted mine in such a way that even rotating these, they look like a brand new spike. So you can also do that too. It's kind of tricky. It's kind of like doing things like with a tree, you rotate it, it looks like a brand new tree. It's just the way you made it."},{"start":"3:09","end":"3:41","startSec":189.8,"text":"You made it asymmetrical. So those are things to consider. So now we have this object here and say we want to change its pivot. Now there is the old way to change pivots where you would simply just go in here and there's multiple ways to get this done. But what I normally do is go to pivot and I'll say, hey man, I'm going to reset my pivot offset and then I would change my pivot to what I want. And then I would say, set my pivot offset. Those were the two steps that I would do. But you can also just say, hey, move if you need it to temporarily be at a particular"},{"start":"3:41","end":"4:11","startSec":221.3,"text":"spot. So I can say, set my pivot offset here temporarily, move your piece of geometry or rotate it for that particular aspect of whatever you're doing. And then you can just click away and go back and it will go back to its default. So that could be helpful in some instances. But our new tool works pretty well. In the fact that you can go in here and you can go to our transform, I can edit the pivot, move the pivot physically as you would in a regular designated 3D application."},{"start":"4:12","end":"4:41","startSec":252.1,"text":"I can move this here or I can choose center, bottom, top, left, right, back and front. All of these things can be quickly, can quickly give you access to those position aids. And then you would hit apply, which is super helpful. But remember, if he's duplicated in the world and maybe there's another copy of him that's truncated and is rotated that is tweaked in some way and you change that pivot, it will affect that duplicate in this current version of Unreal. So let's keep those things in mind."},{"start":"4:42","end":"5:13","startSec":282.5,"text":"Another tool that we have to is if we want to sculpt this item. Now we can cut into it, we can offset it, we can even displace it and we can even warp it. So if I wanted to go in here and do some warping, that's available too. So you got to be careful though. Anything if you go beyond a particular amount, you can stretch your UVs beyond their limit. So let's keep that in mind. But we're going to mainly focus on the two sculpting tools here. So I'm going to go to the generic sculpt initially and I'm going to click on this one and I'm going to zoom in on my scene."},{"start":"5:13","end":"5:45","startSec":313.9,"text":"Let me hit the control button so you can see exactly where my mouse is at. So I can start sculpting on this object in such a way and it does it pretty cleanly using the default sculpt. Now again, everything has its limit. So if you go beyond the UV space or the shape, you may get some push and pull on your texture and you may at times even get holes in the geometry. So you might want to smooth these out and hitting the shift key allows you to do a little bit more of the smoothing. You can see there are a few options here and the ones we'll mainly focus on is in the sculpting"},{"start":"5:45","end":"6:16","startSec":345.0,"text":"area and also brush size and fall off. And our fall off is at one, which actually works pretty well. But you can also adjust that according to what you need. There's even a freeze a target area if you need and we're not going to get into that just here. But you can also control how this smoothing is going to occur with your fall off. And in our sculpt, you can see we have definitely a lot of different choices to choose from. Now again, we're using the default normal sculpt and it works pretty well with the UVs. But where you can really run into some problems and you got to be careful is when you decide"},{"start":"6:16","end":"6:46","startSec":376.2,"text":"to do, let me hit accept on this, when you decide to do a Dinosculpt. Now the Dinosculpt is awesome. The fact that it's really tries to imitate what you get from like 3D code and ZBrush where you get a little bit more dynamic, a little bit more organic with your sculpting. But in that case, it also can be at the cost of your UVs where you can get some stretching in your texture. So when you do play with this, just keep that in mind that you may have to go back in there tweak your UVs. Now we do have some UV tools and they're great, but they are also coming in a little hot."},{"start":"6:46","end":"7:17","startSec":406.8,"text":"They're evolving. So when you experiment with these and work with them, just make sure you save as you go as well as make sure that you understand the concepts of working with it. Now we're not going to get into in this particular case, we're mainly going to be working at looking at shape and positioning for this particular course. All right. So as I go in here and I edit these, you'll see the Dinosculpt come into play. You can see here, this is was a normal sculpt, but over here I can do Dinosculpting. We can kind of push things a little bit."},{"start":"7:17","end":"7:48","startSec":437.5,"text":"I'll do a little bit of smoothing again, hitting the shift key, do some smoothing and that can help any weirdness with your UVs, your textures being hit. And then we can hit accept. And we can see it did a pretty good job. There's a little bit of weirdness right here where we're pushing the shapes beyond the polygon limit. And in that case, we can go in here and maybe do a little bit more of a shift and smoothing aspects and fix some of those issues that may occur."},{"start":"7:48","end":"8:24","startSec":468.5,"text":"It still gets a little bit of the stretching there. And that's something you do need to be aware of because we really sculpted it pretty hard on that one. The generic sculpt versus the Dinosculpt is where you're going to see a lot of that type of effect happening, where you're going to get some really weird, obscure effects in here when it comes to warping and distorting things. Escape for a second, we'll go back to Dinosculpt and we'll then again, you can do some smoothing."},{"start":"8:24","end":"8:54","startSec":504.8,"text":"We can go up a little bit here in this case, pushing things back a little bit more to normal. And you may still see a bit of warping because this shape isn't the regular shape of this object. And I used a bit of moving in some cases. Some of the stuff had already been there. So we can use the move tool, move some of this back in based on the range of my brush."},{"start":"8:54","end":"9:10","startSec":534.9,"text":"And hit accept. So it's a little bit less, but they're still getting a little bit of warping here because we created space that didn't exist before. So just keep those things in mind when you're doing that."}],"PGT_219.00_07_Setting Up Base Materials":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"In this video, we're going to talk about setting up base materials and how we can get that foundation down and make sure that's a doorway to be able to create instance materials, which is going to help with our overall draw calls and overhead for our scenes. So let's get started. Some of the topics we're going to cover is a simple material setup and instancing those materials. First up, let's go and take a look at our spire material that we have set up and how"},{"start":"0:33","end":"1:06","startSec":33.6,"text":"we can actually open up some of these parameters to be able to have full control of how they look and feel. And we'll keep this pretty simple because we do have a materials class, but this for the most part just reminds you of the theory and the practice of this and how this actually will help your overall scenes. So let's go and take a look at this in Unreal. So in our Unreal scene here, we have our spire here that we can play with. So let's go and take a look at his material. I'm going to double click on this material. And we keep these concepts pretty simple, but so that you understand why and the purpose"},{"start":"1:06","end":"1:38","startSec":67.0,"text":"of this. So you'll see that we have a specular. He's always going to be active and set to a 0.5. The one thing you do need to keep in mind when working with a specular material is it can interfere with the strength of your roughness. So sometimes just lowering this to a simple zero can be kind of helpful. So all your texture information, as in your roughness and surface information is pulled from your roughness texture or whatever number of variables you're working with. Now this is the material editor."},{"start":"1:38","end":"2:09","startSec":98.6,"text":"At this point, you should be familiar with this concept, as in, excuse me, with this tool and how it works. And in here, you'll see that we have several different modes for our material. I'm just clicking right here, left clicking in the grid. You can see that you can choose whether it's a simple surface, defer decal, light function, volume, post-process. Those are actually pretty heavy lifters in changing the dependencies of how this material is going to look. And also we have a blend mode, which will allow us to even push further how our visuals"},{"start":"2:09","end":"2:40","startSec":129.5,"text":"are going to be for our material. So we're going to keep things pretty simple. We're going to have a surface opaque default lit. All that's good. Now remember, as you change things, such as turn things and make them more translucent, they can't get expensive. So keeping your materials in mind of exactly what you want, what your output is, is really important because as your material gets more complicated, such as with translucency, things can get expensive. Now what we can do to maybe help that out a bit, because the draw calls look at each"},{"start":"2:40","end":"3:09","startSec":160.2,"text":"one of your materials, is we can help out those draw calls a bit with some instancing. And instancing can be very helpful. Now you can have multiple instances off a parent or master mold material. You can have multiple instances derived from it. And you can have it so like there's 50, you can even go as far as 100. That's a limitation based on your GPU. But to be able to do that, to open this up, to open this master material, master mold"},{"start":"3:10","end":"3:44","startSec":190.5,"text":"To open it up, to be able to do that, we have to actually open up our parameters. So we have to go to each one of these textures, right click it here, and do a thing called convert to parameter. And we'll call this the albedo. And when you create these, you can also have the option when you open up these parameters to add a group. So we can call this the albedo. And I'm keeping this pretty simple. In the most part, what we might want to do is maybe introduce a multiply."},{"start":"3:44","end":"4:19","startSec":224.3,"text":"In that multiply, we maybe have a scalar parameter, which is a more upgraded version of this constant parameter here. To get there, you can either right click a constant parameter and convert to a parameter. Then we'll change it to a scalar parameter. Or simply keep your finger on the S key and the left click and you'll create a scalar parameter. And then in here, we could call this a, you know, I'm going to maybe change the color output of this individual texture. Maybe introduce a three constant vector."},{"start":"4:19","end":"4:51","startSec":259.2,"text":"This will be for color. We can keep it black and we can pull this albedo in here. You can get a preview what it's going to look like. You can see if we right click, start preview mode, you can see that we're all black. So you have to watch out between add and multiply what you're going to get. And in this case, we would set this to white. And they'll see your color information come through. And if you wanted to, let's stop that preview. We can control maybe how strong that's going to be."},{"start":"4:51","end":"5:23","startSec":291.9,"text":"So with this multiply in place, we can maybe pull in the strength of that albedo. By temporarily disconnecting this, moving this over here. Simply make another multiply. Put this in here. This in here. And then connect that right here."},{"start":"5:23","end":"5:54","startSec":323.7,"text":"And you'll see that it's dark at first, right? So this parameter, we can set that to one or even higher if we wanted to. And let's add this to the base. And you'll see now it's still a bit dark, right? Not quite exactly what we're looking for. So as you increase your multiply, you'll see that it's going to magnify things. So the nice thing about working with a scalar, we can keep things within a range. So I can say, hey, man, I want my default to be 10."},{"start":"5:54","end":"6:26","startSec":354.4,"text":"I want my slider. Or actually, that might be too strong. We'll do like maybe a five. And I want my slider minimum to be zero and my maximum to be five. So this all depends how you want to pull this through. But this gives you the magnification based on whatever color you've chosen. And that's one way you can do it. So there's multiple ways. And whenever you make these, make sure you comment them out. So you can say, hey, I want to comment this right here. We'll leave the C key. We'll leave this guy out just temporarily. And we'll just say here, color experiments."},{"start":"6:30","end":"7:00","startSec":390.2,"text":"And there's multiple ways to actually match this up. I just did this super generically. And in our classes, you'll see me talk about, as well as other instructors, how to set this up. And this is just a quick way. You could even just add. But this multiply and add kind of act a little bit like Photoshop, allowing us to stack. But you have to keep in mind what kind of color output you're going to get. And you can get that through a preview by right clicking, which you saw me do just a minute ago for previews and so forth. We could even lower this to maybe two if we wanted."},{"start":"7:02","end":"7:32","startSec":422.2,"text":"That's too dark. Let's do something like that. Or four. There we go. That's fine. All right. So that gives you a little bit of control. Gives you an idea of how that works. And you can also keep it simple. This just depends on how much control you want of this object. But if we are going to do this, again, we have to actually open up the parameters. Convert that to a parameter. Call this color overlay. And we've got to put them in a group. We're going to put them in that albedo group."},{"start":"7:32","end":"8:05","startSec":452.8,"text":"Do the same thing with the scalar parameter. Want to give it a name, though. We'll call this intensity color. So color intensity. Let's just put that there. And just put that into an albedo group. And then again, we want to open up each one of these. Convert to a parameter. Rough. Yes. And normally, you could put a multiply in here. And you can choose scalar parameter. I'll do this slightly quickly here."},{"start":"8:05","end":"8:37","startSec":485.6,"text":"Rough intensity. Because you should have had these classes at this point. Move that in there. We'll set his limitation to. And you can cheat a little bit. Because when it comes to roughness, it's typically a 0 to 1. That's really how it works. But you can cheat a little bit with Unreal. If we introduce a multiply, we can go a little bit higher. And I actually like to work with a little bit higher numbers. Instead of getting carpal tunnel and typing in 0.00.5, that's the intensity I'm looking for. You can cheat when it comes to the multiply in this particular case. And metallic, not so much."},{"start":"8:37","end":"9:07","startSec":517.5,"text":"So I'm going to go in here and put a 10. We'll do a 5 as default. If we want to increase that, we can set the minimum to 0 and maximum to 10. So then we can go higher. That's there. And we probably have to mute this a bit, because it's probably still too high. But that's fine. And we just set that to roughness there. And we also have ambient occlusion."},{"start":"9:07","end":"9:38","startSec":547.6,"text":"We'll leave that. We'll leave normal. Now, normal, if you want to control this, is a little bit counterintuitive artist-wise. But what you want to do is use a flatten normal. Sometimes I'll be lazy in my flatten normal. I'll just simply put in a scalar and flatten this. But the only problem is it works in a negative space. So it gets a little weird. So we'd have to actually flip that so it goes back to a positive. So since this works in an opposite direction, so negative is pushing forward the way you maybe"},{"start":"9:38","end":"10:10","startSec":578.2,"text":"have intended it, going positive numbers goes negative, that's going to be counterintuitive. So you have to actually use a 1 minus node. Back, there it is. I literally typed a node. And I can put that in my flatness here. And I would connect this to my scalar parameter. And we'll call it normal intensity. And I keep in this pretty basic."},{"start":"10:10","end":"10:40","startSec":610.3,"text":"Regularly, you would create a whole UV set where you can control how many times the UVs are tiling. In this case, since UV is very specific with his UVs, we probably should do that. Otherwise, you could really ugly fast. But if you have a more encompassing texture that is more generic and not really dependent on UVs, you can actually play with that a bit more. So I'm going to go and move this to the normal. And in that normal, we bring that into the normal. And in that normal, we bring that into the normal space there."},{"start":"10:40","end":"11:10","startSec":640.4,"text":"There we go. And again, we can control the intensity. In this case, we can set the intensity to, say, 5 if you want to go really strong, minimum 0. And then, say, we want to invert it. We could do a negative 5 for actually, I did that backwards. Here we go. Minimum is negative 5. My bad. That's negative 5. And the maximum is going to be just a little 5. There we go. Cool."},{"start":"11:10","end":"11:39","startSec":670.7,"text":"And if you ever wanted to bring in your geometry, just make sure you select your geometry in your content browser. With it selected, just click on the teapot, and it will load it in this viewer. All right, so with this all set up, we want to make sure, again, we open up the parameters. And this will be a normal. We're going to create a normal group. And we'll just add this to the normal group, too."},{"start":"11:45","end":"12:16","startSec":705.6,"text":"And we'll create a roughness group. Add this roughness intensity to that roughness group. Also, make sure this guy is connected to the roughness group. There he is. For some reason, I thought I didn't do that. And we'll just leave Albedo by himself, because nobody cares about him right now. So there we go. We even got commenting. We got this all set up. And I would hit Say. So I'm just going to apply in this case"},{"start":"12:16","end":"12:50","startSec":736.0,"text":"so I can rebuild this for another course. And I'm going to pull this across here. And then now I can right click this particular piece of geometry. It looks like it's a little bright. So we can probably go over that a little bit. It's all shiny. I actually kind of like it. But we can change that in the instance, believe it or not. So we'll do that in the instance. And you can see the update on the fly. So let's move this off to the side. I'm going to right click here. And we'll do Create Material Instance. And we're going to call this mi for Material Instance."},{"start":"12:50","end":"13:21","startSec":770.7,"text":"We go across. Let's get rid of that suffix. Enter. Open it up. Now when we open this, you're automatically going to notice the interface is quite different. So I'm going to turn on my Albedo. And that means I can switch any texture I want. So maybe I'm working with this texture in Mixer, 3D Co, or some other substance painter. And Color Intensity, Color Overlay. We got the Normal, Normal Intensity, Roughness, and Rough Intensity."},{"start":"13:21","end":"13:51","startSec":801.0,"text":"All of this can be controlled on the fly. So the Color Intensity, we can choose the darkness of it if we wanted to. And we can choose what color we want for it. Apply. And we can choose, make sure that's working here. Maybe double check. Got the parameter open."},{"start":"13:51","end":"14:22","startSec":831.3,"text":"Multiply Albedo. We're good. Cool. Go back to our real-time spire here. And we're going to Control Normal Intensity. We can lower the Normal Intensity or increase it. Now you'll notice nothing's happening here, because I forgot I have to actually apply it. So let's go on to Reset. And we're going to go back to the real-time spire. And we're going to have to actually apply it. So let's go ahead and slap it on this guy."},{"start":"14:22","end":"14:54","startSec":862.7,"text":"And we can control the Color Intensity. Now you'll see the updates. We can choose the color that we want. So in this case, we'll say, hey, man, I want this to be more white in nature. I want to give it a little red to it. There we go. Green, blue. I had to check my work there, because I noticed that I needed to go back a little bit. I thought, why isn't it working? Because I have to apply it. It's crazy. And then you can see all the color changes here."},{"start":"14:54","end":"15:25","startSec":894.5,"text":"And as we change those colors, let's get something that's really going to show up on screen. Blood, pinkish red. And we can now change the strength of that, which is pretty nice. And even in Sequencer, if you wanted to, you can open these parameters and animate this, which is actually pretty cool. And then we have Normal Intensity. We can decrease the Normal Intensity or increase it. You'll see it there. We can go Negative or Positive, Inverting. There's the Roughness Intensity. You can see it there."},{"start":"15:25","end":"15:50","startSec":925.0,"text":"Working my full spectrum of my slider here. And we can also choose to turn off my roughness if we don't want to use it at all. Decrease my roughness so there's no changes in it whatsoever. And all that's available for you to play with."}],"PGT_219.00_08_Foliage Quicktake":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this video, we're going to look at foliage, do a quick take of it, and see what the things that we can do to build our worlds. So let's get started. So foliage is a tool that can help populate our items in our world to get things in the right spot relatively quickly. We can get it in there quickly and get the look and visual display that we need, but is limited when using ray tracing due to photon counts."},{"start":"0:31","end":"1:01","startSec":31.1,"text":"Plants, assets with small details are a lot harder on your calculations and noise may occur, which will force you to use CVARs in some cases. For the most part, when it comes to ray tracing and foliage, you kind of maybe want to stir away from that, but if you do have foliage, keep it farther away from the camera. This will prevent anything in your virtual production from giving you some bad displays. Now, if you're going for final pixels, you can run some CVARs to get you the best possible results."},{"start":"1:01","end":"1:35","startSec":61.8,"text":"And if your GPU is strong, you should be able to get some good results with it. But just keep those things in mind. It's very important to consider. Ray tracing is evolving and is improving gradually. And also eventually we'll absorb that, as you can see with our Unreal 5 release, that Lumens is kind of taking over that particular area and getting stronger and stronger. So you just need to optimize your scene accordingly if you're to introduce foliage and lots of small assets if you're working with ray trace."},{"start":"1:35","end":"2:06","startSec":95.0,"text":"So if you are having trees move around, make sure you evaluate WPOs, works with your ray trace foliage. It's more geared towards final pixels. In a virtual production environment, ray trace is not really needed all the time, but it may be. It just depends on the art director. They may want to see that bounce immediately. And that also depends on your hardware and GPU and exactly what you're pushing to be able to get these results. And sometimes you could use screen space, global illumination, but you just keep those things in mind too, because as the camera changes and moves, there may be some clipping"},{"start":"2:06","end":"2:37","startSec":126.7,"text":"involved. Hero Static Meshes is ideal to work up close. So sometimes you may not even need foliage. You just grab that tree, put it right next to the camera, and that can be a bit more ideal in many cases. But let's take a look at foliage up close. So in my scene, you'll see, and let me get rid of this guy. He's pretty distracting. And we'll change our material back to its regular state."},{"start":"2:37","end":"3:07","startSec":157.0,"text":"It's going to ask me to save, and I'm going to say no. Oh, nope. It decided to stick around. I might have hit save, and that's fine. In that case, we'll go in here and lower the strength of it. A little more gray there. Kind of closer to what we had before. Maybe get a little bit wider."},{"start":"3:08","end":"3:41","startSec":188.6,"text":"So let's go ahead and take a look at that foliage up close. Just a little small thing there. All right. So we have some plants in here, and I'm going to go ahead and activate my Foliage tool. In my Foliage tool, Unreal and older versions wouldn't always populate here of what you had before, but now it does remember what you had, which is fantastic. And we're going to go ahead and turn all these on for a moment. Now let's pick on one of them for a second and look at some of our settings. You'll notice we have some settings here, but there's also some settings up top."},{"start":"3:41","end":"4:12","startSec":221.1,"text":"You can also control size, your density, and you can also have some... You can place it in the current level if you want to, and there's also filter. So what are you going to paint on? You want to paint on other foliage on top of foliage, which is... That's crazy talk. Your BSPs, which is your generic volume structures. They can be pieces of geometry for blocking, and Static Mesh and Landscape. So right now we're going to... Mainly Static Mesh would be our main point of contact here. So see we have density."},{"start":"4:12","end":"4:43","startSec":252.3,"text":"You can see that my density have increased. I've also messed with my scale size. So when I paint, we have a range between a smaller and a bigger size there, and it's free formed here. You can keep it uniform if you want to, or lock it within an axis. That actually can be pretty helpful. See my brush here? I'm going to change the scale of that brush by hitting the bracket keys, because I don't want to paint everywhere. There we go. Lower that down, just like with the modeling tool, and I can paint some foliage in place."},{"start":"4:43","end":"5:17","startSec":283.5,"text":"Pretty nice. And I have it so it's creating a really nice density in here. And we can even edit some of that here as well, some generic sizes. You can also do selecting of your individual assets by clicking on the Select tab. It allows you to select these individually. So you see, oh, you know what? I don't want this plant here. You can select it and pick on it if you needed to. That's up to you. You can also lasso, which activates your brush tool. You'll select a certain set that you want to do something with, or you want to change"},{"start":"5:17","end":"5:48","startSec":317.7,"text":"them in some way. Or you can even un, you can erase by hitting the Shift key. It allows you to erase. But there's also an Erase option up at the top, which is pretty great. And I'll just erase some more, get rid of some of these. We don't need all these plants everywhere. It's crazy talk. So you have some of these nice selection options and even Fill. Now you've got to be careful with Fill. You don't want to initially fill the whole world in the target area because that may"},{"start":"5:48","end":"6:18","startSec":348.2,"text":"bog things down. So there is a limit with this. As amazing as this tool is, it can make your scene come to a crawl. So you have to use it sparingly and you have to use it wisely. And that means you know exactly where you're going to put it and how you're going to use it. Now, if you come into issues in areas where you're like, you know, I think this is great. But up close, I mean, I've edited some of the plants and I think they're okay. But up close, I want to be able to have maybe the best, highest quality."},{"start":"6:18","end":"6:52","startSec":378.7,"text":"You don't always have to rely on foliage. You can bring in actual pieces of geometry, just pull them in. You can bring in the plant on its highest level of detail. It's up to you how you work that. But you can do that. And that's fine too, especially for virtual production. Because not everything has to be, when it comes to foliage, has to be an actual foliage item. If you're up close and looking at something, you may want that tree in its highest level of detail without, because what happens, it'd be up close to the camera, because what happens"},{"start":"6:52","end":"7:23","startSec":412.7,"text":"as you load things into foliage, it does become incidents. There is a little bit of a hit with it, especially on how far you are from the camera. But you can edit some of this too. So if I go to this plant that we have active, scroll up, click on the magnifying glass, I can go into this foliage actor and I can tell exactly how I want to, or how much detail I want out of this group. So I can say, hey man, I want high detail. And when you, or even foliage."},{"start":"7:23","end":"7:54","startSec":443.9,"text":"I usually choose high detail when it comes to virtual production because I want to get the best possible detail. When you select that, it'll say it's going to change it for all of them. Are you sure you want to do this? I'm going to say no in this case. And it will change it and make it so that you can have the highest amount of detail for that foliage. And it can't get expensive if you have a lot everywhere. So keep in mind too with ray tracing, like I said before, it is expensive and not always ideal because you want to avoid that noise. And if you do use it for ray tracing, a lot of times it's better to do that with final"},{"start":"7:54","end":"8:25","startSec":474.9,"text":"pixel, but you can have some plants and trees in the background. And a lot of times you're doing a mix of that. Here's my virtual tree and my virtual production. Here's my physical tree next to the actor. So you can actually do a trade off where you have stuff in the distance versus here's an actual item, a physical prop and get it to match and look like it believes it's believable for your environment. So you can do a lot of cheating with that. So the foliage shul is pretty great in the fact that if you needed stuff and it doesn't have to be limited to just plants. Now you can do rocks."},{"start":"8:25","end":"8:57","startSec":505.8,"text":"Say we turn all these plants off, even books in a library. So if I go in here and select these two rocks, like, hey man, I need some rocks. I can add some rocks in here. It's really great. And I can put them on static meshes if I want to. I may have it deactivated in this particular case for this guy. You can add it there. So it's really cool. It doesn't have to be plants. It doesn't necessarily have to be trees all the time. It can just be just some fodder, just some stuff that you have all over the place, stuff"},{"start":"8:57","end":"9:25","startSec":537.8,"text":"that you just want to populate. And again, you can control how it looks. There's a calling distance control too. Now this is a little bit more gamey and less virtual production. Specifically for virtual production, a lot of times your camera is pretty fixed. If it does move, it's very light with its movement. So some of these you may not even have to worry about, such as collisions and so forth. I wanted to point that out and show you the strength of what you can do and how you can control and get your scenes in the right area."}]},"219.01":{"01_Intro":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hi, how are you doing? My name is Elena Felice and I'm a content presenter for Epic Games. It's nice meeting you. So, in this course, we'll dive deep into worldbuilding for virtual production. First, we will learn about the concept of derived data cache or DDC, understanding how it works in Unreal Engine and in a real-time scenario. Then, we will dive on a journey learning some basics of the engine,"},{"start":"0:30","end":"1:01","startSec":30.1,"text":"spanning from lighting to assets editing using different tools like modeling, procedural content generation, and blueprints. We will also learn how to manage levels with the Stage Monitor and level snapshots. We'll conclude with exploring some material and foliage basics, together with checking out the engine profiling tool. In the next video, we'll get an overview of our agenda for the upcoming lessons, as well as learning about derived data cache. Guess I'll see you there."},{"start":"1:01","end":"1:03","startSec":61.1,"text":"Alright, bye."}],"02_CourseOutline":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Welcome back and thank you for your interest in learning more about world building for virtual production. In this class, we'll review our agenda for the upcoming lessons, and then we'll take a look into derived data cache and its importance. As I just anticipated, in this first module we'll explore derived data cache. We'll be starting out with some ground theory on it, understanding what DTC is, its different types, and where it's located and how to change that. Once the theory is covered and out of the way,"},{"start":"0:32","end":"1:03","startSec":32.2,"text":"we'll be ready to dive into world scopes and initial setup. We'll be exploring different ways of dealing with a project, breaking it down into shocks and assets, and importing outside assets from libraries like Megascans or Fab. And after that, we'll be uncovering some basic lighting concepts and briefly talk about a very useful tool called Environment Light Mixer, which is used to quickly set up our maps with realistic lighting. Alright, spicing it up a bit, we'll explore different approaches of editing assets,"},{"start":"1:03","end":"1:37","startSec":63.9,"text":"whether using construction blueprints or blueprints in general, procedural content generators, or modeling tools. We'll also discuss about how to manage levels using the Stage Monitor and increment them easily using the Level Snapshot tool. Then we'll get an overview on materials and how to use them efficiently using material instancing. Lastly, we'll conclude this course by learning about the foliage tool and we'll be getting a little nerdy checking out the profiling tool of the engine. Cool, let's get started with some draft data cache theory."},{"start":"1:37","end":"2:11","startSec":97.5,"text":"First of all, in basic computer terms, a cache is a small, fast storage area of your computer memory where your computer temporarily keeps copies of frequently used information so it can access that information much more quickly than going back to the original source each time. This is similar to keeping your most used items on your desk rather than just storing them in a cabinet across the room. In Unreal Engine terms, the draft data cache holds a very similar function. DDC is like a smart finding system that saves your time when working with assets."},{"start":"2:11","end":"2:43","startSec":131.8,"text":"Imagine you have assets like textures or models that need to be processed before the engine can use them. Instead of processing these assets from scratch every time you need them, Unreal stores the processed versions into DCC's. When Unreal needs a processed asset, it first checks the fastest, closest storage location. If not found there, it checks progressively slower storage locations. And when found, it copies that data to the fastest storage for quicker access next time."},{"start":"2:43","end":"3:15","startSec":163.4,"text":"If not found anywhere, Unreal processes it from scratch, then saves it to all storage locations so it's available to you or your team in the future. Now the DCC contains only 10 Ferrari copies that Unreal Engine can just throw away and recreate whenever it needs them. The original files are the U-Asset ones and those contain all the important information. So make sure not to delete them or just move them around. Now this setup is really helpful because Unreal Engine can change"},{"start":"3:15","end":"3:48","startSec":195.8,"text":"how it works with our assets without ever changing their original files. Kind of like making different versions of a photo without changing the original image itself. There are two main types of DCC's. The boot DCC, which consists of startup files loaded into memory to increase boot times. And then the local DCC, which includes the derived data for our projects. If you're interested in learning about the different DCC types in depth, I'd encourage you to follow the link in the slide down here"},{"start":"3:48","end":"4:19","startSec":228.6,"text":"because it will provide you with all the information and specifics you need. Let's jump into the engine for a moment to take a glimpse at the Zen server and other cache statistics. Alright, so if we take a look down here, we can find the green check mark with Zen server written right next to it. And the Zen server or the Unreal Zen storage is an EpicMate program that manages our local DCC's separately from the main editor. Now by default, when we launch the editor,"},{"start":"4:19","end":"4:51","startSec":259.6,"text":"the Zen server automatically starts too. And when we close the editor down, then the Zen server does the same. And that's why we have this green check mark here. All it says is that the Zen server is on. Now if we click on Zen server, we get access to a few options. The first one being the launch dashboard. And if we launch it, we'll get an overview of how our Zen server is doing. We can see that it is running on the engine version 5.6"},{"start":"4:51","end":"5:22","startSec":291.4,"text":"and that the disk space that this project is occupying is 4.2 gigs. Now under tools here, we have the option of stopping, restarting or starting the Zen server if we wanted to. And then we have something really useful down here. We could actually launch a garbage collection process and then free some unused disk space. So this process will basically just delete some unused asset and we can choose whether we want to just delete all the unused asset"},{"start":"5:22","end":"5:56","startSec":322.2,"text":"or the asset we haven't used in a week or the ones we haven't used in the past day. And then our project will get lighter. Okay, let's check out some few different options that we have down here. So if I click on cash settings, we will go into the editor preferences. We'll be able to change the global local DDC and shared DDC paths if we wanted to. Or the individual project local and shared DDCs. We will be able to enable all disabled notifications for the derived data cache"},{"start":"5:56","end":"6:27","startSec":356.2,"text":"as well as enable or disable the AWS S3 cache. And then we will be able to input the Horde server URL. We would be using the Horde server if we needed help distributing build tasks. So if we were building a game or a project across multiple computers in a theme environment. Okay, what else do we have down here? We have the cache statistics, which would tell us what's been loaded here in the project and how it's working."},{"start":"6:27","end":"6:57","startSec":387.3,"text":"And then we also have the cache resource usage, which would tell us how our resources are being used. All right, let's go back to our slides and see how to set up shared DDCs. So a shared draft data cache in Unreal Engine is a system where processed asset data is stored in a central location that all team members can access, like a shared drive. Instead of each person having to process the same asset individually,"},{"start":"6:57","end":"7:31","startSec":417.8,"text":"which can take a long time, the first person processes it and everyone else can use that same processed version. By default, the editor is not set up to use a shared DDC and instead each person's Unreal installation uses a local DDC stored in the wrong computer. But we can easily enable shared DDC either by adding an override in the default engine configuration file to set the path of the project to a shared location. By setting an environment variable to the shared folder or setting the shared draft data cache variable in the editor."},{"start":"7:31","end":"8:04","startSec":451.8,"text":"Now, in order to work together with a team on a single or multiple projects, those projects would first need to be accessible by every member of the team on their own individual computers. Now, there are various ways of setting that up. The simplest would probably be mapping a network drive on your local network. This will allow you to share this mapped network or folder across your team as long as they're connected to the same network as yours. You can find further information at this link to understand how to do that in a Windows environment."},{"start":"8:04","end":"8:32","startSec":484.6,"text":"And a simple research online will let you find different solutions for different operating systems too, like Linux or Mac OS. All right, that was it for this class. But you can find some additional documentation at this link if you're interested in further expanding your knowledge in the RAP data cache and mapped network drives. Thanks for sticking around. And in the upcoming lesson, we will look into world scopes and initial setups when building our environments for virtual production."}],"03_WorldScope":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Hello, and welcome back. Our goal for this class is to break down how to assess scope when developing our environments for virtual production. We will also be learning how to import FAB or Quixel Megascans, free fabricated assets into the engine. Let's get right into it. So if you're here, it's probably because you're looking to expand your knowledge in world building, specifically in a virtual production setting. Before diving into the engine and starting to design our environment, it's important"},{"start":"0:31","end":"1:03","startSec":31.8,"text":"to assess the implication of working with a real-time engine. Because a lot of the steps happening sequentially in a traditional pipeline would actually evolve organically when working in real-time, and a real engine will allow you to alleviate a lot of the heavy lifting in that matter. You'll be able to see the changes in a snap immediately apply to your environment as you move along. So after understanding what real-time really means, we need to assess the scope of what we're aiming to create in our virtual set. So how much work would that actually involve?"},{"start":"1:03","end":"1:34","startSec":63.8,"text":"I'm gonna give you a hint. Something that would help us would be to create for ourselves an asset library, basically collecting all the assets we expect to be using in our environment based on our story and overall our direction. You can ask yourself questions like, which feeling are you trying to recreate with your environment? And which composition would best pick that? Pre-production and production tracking are essential steps of both traditional but also real-time productions."},{"start":"1:34","end":"2:04","startSec":94.4,"text":"So make sure to take your time and have everything ready before diving into environment design in Unreal Engine. So once you have an overall idea, have collected a good amount of references and sketched out your intentions with detailed concept art, you can start breaking all of this down into an asset list. You wanna make sure to flag out the assets that would be the longest in focus in your composition. Those assets are typically referred to as hero assets in production terms."},{"start":"2:04","end":"2:39","startSec":124.5,"text":"In our environment, hero assets will probably hold the highest level of detail or resolution in our map. Once you have an asset list, you can start importing or migrating all the assets you'll be using to develop your environment into the engine. If using asset packs, you might want to delete assets you wouldn't be using and just keep those that you would. This will prevent your project size to overblot with unnecessary items. Keep in mind that sometimes it might be good to keep similar assets or textures within a pack at your disposal to create nice variations in your design and not to make it look too"},{"start":"2:39","end":"3:13","startSec":159.7,"text":"repetitive. Once everything is imported into the Content Browser, it's a good habit to create a test scene with all your assets aligned on the floor to get a clear overview of how they look like and whether there are any migration issues. When working with external assets, whether modeled and textured by yourself or not, there are a few things to consider. First, you wanna make sure those assets are to scale and share the same scaling system. Remember that centimeters are one-to-one to unreal units."},{"start":"3:13","end":"3:44","startSec":193.4,"text":"Your assets are your friend. The more you build items into separate pieces, the easier it's going to be to A. Create variations and B. For unreal to swap different level of details based on the distance of thus separated objects from the camera. Try not to scale objects that are relatively small and have nanite enabled, rather enlarge them into a separate DCC and then migrate them into unreal. If you merge different assets with nanite enabled in Engine, you might add heavy calculations"},{"start":"3:44","end":"4:17","startSec":224.8,"text":"to the editor. This is relevant for games but also for virtual production, since the environment displayed on the LED screens should run at a minimum of 60 or 30 FPS. Lastly, when using Lumen with thin assets, you could experience light leaking and shadow artifacts, so make sure to add some volume or depth to them to prevent that. Alright, let's have a look at the Fab plugin directly in Engine. Alright, so you could have any project opened up here in the editor, but just make sure"},{"start":"4:17","end":"4:50","startSec":257.1,"text":"to go under Edit and Plugins and check that the Fab plugin is enabled as well as the Bridge plugin if you wanna use Quick Fill Bridge. Today, we're gonna be focusing on Fab only since it contains all the mega scans already. So you can access that either by the QuickCAD menu down here and then clicking on Fab, or by clicking on the Add button in the Content Browser and then clicking on Fab. So the Fab window will open in its default homepage, which will display some featured"},{"start":"4:50","end":"5:22","startSec":290.3,"text":"Unreal Engine products as well as some Quixel products down here, some UE samples that are free and you can just download and explore and play around with, some MirrorHemant content and then some extra content down here. Here on the left, you can see some different categories you can filter your asset through, like 3D assets, Materials, Sprites, Decals and more. And if you ever get lost into a rabbit hole just like filtering through assets, you can always just click here to go back to your homepage."},{"start":"5:22","end":"5:54","startSec":322.2,"text":"Now when looking through assets, you have a few filters at your disposal. You can filter through the style, so the rendering style or the period and theme of your asset. You can also check out the compatibility if you're developing for games, some technical features like whether they're animated or rigged, whether those are blueprint assets, they're compatible with Nainite or more. Some formats, if you want them to be compatible with Metahemons, and then you have some more"},{"start":"5:54","end":"6:26","startSec":354.1,"text":"filters down here like the tags, the price and more. You can sort them by relevance, rating or other priorities. And then here, something that could be relevant for you guys is that if you click on these options, you can choose whether you want to show or not products created with artificial intelligence. You can also choose whether you want to hide, blur or display mature content. Okay, then if I wanted to filter through Megafkind's asset only, I could do it by searching through"},{"start":"6:26","end":"6:59","startSec":386.4,"text":"Quixel and then switching my view from products to publishers, and here you would find the Quixel products. Now these products need to be purchased, but if you filter through free assets down here by clicking on price and then flagging the free checkbox, you will be able to see only the free Quixel assets. If you wanted to filter through Megafkind's only, you can just type Megafkind's in the search bar, and this will show you results from the Quixel publisher only titled Megafkind's."},{"start":"6:59","end":"7:31","startSec":419.2,"text":"So you will be able to find all the Megafkind's assets. Now for today, I had something specific in mind to download, which is a chicken nugget. So if I search for chicken, I will be able to find my chicken nugget down here. That was also wishlisted by me. So if I click down here on the right icon right next to my library, I'll be able to find my wishlist and I can find my chicken nugget. If I wanted to, I could also remove it from my library, which I'm going to do right now. And then if I go back one tab,"},{"start":"7:31","end":"8:02","startSec":451.8,"text":"I will be able to find my chicken research again and wishlisted again if I wanted to. So if I click on this chicken nugget, I will get access to some further details on this asset. So down here, you can choose the quality you want to download this asset in, whether you want it low, medium, high, or low, which is uncompressed. Make sure to choose the resolution of the assets you download wisely based on your environment composition. So if this chicken nugget was going to be a"},{"start":"8:02","end":"8:38","startSec":483.0,"text":"hero asset, I will probably download it as raw or high quality. But if it were an asset far in the background that would be seen really small in the camera, then I'll probably choose something like a low quality. Okay, so if we scroll down in our asset details, we can find here some included formats. Right now you can see that I don't have access to the UF add or the C brush formats, because we're within the Unreal editor. But if I click on FBX, I can find some details on the total amount of triangles and vertices, as well as the overall size of this asset and the textures"},{"start":"8:38","end":"9:09","startSec":518.7,"text":"that it will come with. All right, so now that I've chosen my asset, as well as the quality that I want to download it in, I can just click on add to project. My asset will be downloaded. And then Unreal Engine will open my downloaded asset directly into the content browser. So if I double click here, I will find my static mesh, and I can open it up if I wanted to. All right, let's go back to our slides for a moment. All right, so when importing external assets from"},{"start":"9:09","end":"9:44","startSec":549.6,"text":"FAB, you not only want to make sure to download the correct resolution, but also set up your level of detail wisely, because this could have a high impact on your scenes. Now, if you're using Nanite, things would be a little different, and we'll be talking about it in the next video. If Nanite is disabled, the LOD would swap based on the distance of the object from your camera. You can see here in the slide, I outlined a few steps that you can take to customize the level of detail of your asset. Let's go back to the engine and see this option in further depth. All right, first of all,"},{"start":"9:44","end":"10:20","startSec":584.2,"text":"by right clicking on any static mesh actor in the content browser, we can check up here whether Nanite is toggled on or off and disable it if we wanted to. Now, this chicken nugget has only one level of detail, so it wouldn't be a good example to show you how to set up different LODs. So I'm going to close it down and then just click on this rock here in my environment. And then in the details panel, I will just double click on the assigned actor to open the static mesh editor up. And here we can see our boulder. Now, in the details panel, I can see that Nanite is enabled on it. So I'm"},{"start":"10:20","end":"10:51","startSec":620.1,"text":"going to disable it just to get access to the different LOD options and to show you. Now, under the LOD picker section, you can see that LOD is set to auto. This means that if I distance myself from the object with the camera, the different LODs will automatically swap to optimize my viewport. And you can see as I go back with my camera that the current screen size of the object will decrease, as well as the fallback triangles and vertices. Now, if you wanted to, we could force the editor to"},{"start":"10:51","end":"11:24","startSec":651.4,"text":"use just one specific LOD we have here at our disposal. The LOD zero would have the best quality and the LOD four would be the most optimized. So if I switch this to all LOD form, you can see that my fallback triangles lower to 600 and vertices to 500 compared to an LOD zero of 10,000 and 5,000 vertices. Now in virtual production, this could be relevant because you might want to isolate the hero asset to an LOD of zero, then perhaps the rest of the assets or assets that are further away"},{"start":"11:24","end":"11:57","startSec":684.6,"text":"from the camera to an LOD of four, for example, then if we wanted to, we can just activate this custom checkbox and we would be able to deactivate specific LODs on this asset. So if we wanted to keep it to a high resolution range, then we could disable LOD four, three and two. Now, even if we zoomed back from the object, the resolution will still stay on a high level versus if we did the opposite, if we just kept the LOD three, four and two, then we would just be using those three types"},{"start":"11:57","end":"12:29","startSec":717.5,"text":"of LODs. Now turning them all on again, if I scroll down here, you can see that I will get access to the specific details and settings to all the different LODs, the LOD zero, one, two, three and four. And then if I open up the reduction settings menu, you can see that you have it on all the different LODs, you can actually choose the percent of triangles you want to have on the static mesh on this specific LOD. So for example, for the LOD four, you would have the six percent of the total"},{"start":"12:29","end":"13:04","startSec":749.7,"text":"vertices and then on the LOD zero, you would have a hundred percent triangles. When trying to optimize the scene for virtual production, sometimes even the LOD four settings might still be too detailed and in that case, it's really useful to use this reduction settings option to reduce the geometry of the mesh at this specific LOD. This is useful to optimize your map, especially if you find yourself unable to hit that 30 or 60 FPS mark on the LOD screens. Now if I scroll down even more, you can see that you can assign a different LOD group based on the type of prop or asset that this is."},{"start":"13:05","end":"13:37","startSec":785.8,"text":"And then down here, you can see that you can choose the number of LODs you want to use, as well as choosing whether you want to automatically compute the LOD distances or not. So if you turn this off, you will get access to the screen size option here to the different LODs and define the screen size that the object needs to have in the viewport when swapping to the different LODs. All right, I hope this provided you with a good overview on the different LOD settings that we have at our disposal in the static mesh editor. And now we're going to switch back to our slides"},{"start":"13:37","end":"14:09","startSec":817.9,"text":"to conclude this video. All right, that was it for this class. Shout out to Sean Spitzer for the creation of these slides. And I want to also thank Brandon Jones and King Chen for allowing us to display their concept art in the beginning slides of this presentation. You can find some additional documentation at this link if you're interested in learning more about FEB and the Quixel Bridge plugin for Unreal Engine. Thanks for sticking around and in the next course, we'll be learning some basic lighting concepts and how they work together with Nanite. Will I see you there?"},{"start":"14:10","end":"14:15","startSec":850.2,"text":"All right, bye."}],"04_BasicLightingConcepts":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Hi. In this class, we'll be reviewing some basic lighting concepts when working in virtual production. Let's get right into it. All right, full disclosure. I'm going to be throwing at you a few complicated terms and then explain what they mean because I think it's going to help you understand how Unreal Engine works under the hood. Let's first discuss what global illumination means in Unreal Engine. Global illumination or GI simulates how light bounces around the scene,"},{"start":"0:32","end":"1:05","startSec":32.6,"text":"creating indirect lighting effects that make an environment look more realistic. In Unreal Engine, GI can be either baked, meaning calculated once and stored, which is faster but very static because it doesn't move, or dynamic, meaning calculated in real time, therefore changing as it gets either animated or interacted with by a player. Just so you know, in the same scene, it is possible to have both dynamic and baked GI."},{"start":"1:05","end":"1:36","startSec":65.8,"text":"One doesn't exclude the other. Now talking about baked lighting, lighting data in Unreal Engine can be baked on the CPU or the GPU using the Lightmass global illumination system. Whenever you hear Lightmass, it means that the lighting has been baked. CPU-based Lightmass uses the CPU to compute and generate lighting data, and it can also be distributed across a computer farm. GPU-based Lightmass uses your computers and"},{"start":"1:36","end":"2:07","startSec":96.3,"text":"Bedia GPU to generate those lighting data. Now Lumen, on the other hand, is a fully dynamic global illumination and reflection system that's enabled by default in the Engine. Compared to Lightmass, it responds instantly to any moving object and allows us to iterate our lighting setup without having to wait for baking times, which can take really long sometimes. Lumen also provides infinite light bounces, so to infinity and beyond."},{"start":"2:07","end":"2:38","startSec":127.3,"text":"Now, there is a trade-off though, because Lumen is more demanding on our machine, and it sacrifices some accuracy for the ability to have a fully dynamic real-time GI. In this class, we'll only be focusing on Lumen, as it's mostly compatible with virtual production and in-camera visual effects. It's the standard way of working with the Engine, because it's very fast and it's flexible. Lumen GI best functions with its sidekick, Nanite Virtualized Geometry,"},{"start":"2:38","end":"3:09","startSec":158.1,"text":"or simply referred to by friends as Nanite. Together, they achieve full resolution shading. Nanite Simplified Geometry Representation helps Lumen provide more accurate indirect lighting. So they really help each other out. They're best friends basically. Now, down here, I talk about skylighting. The skylighting takes care of the ambient light that comes from the entire skydome and not just the sun. In its last step in calculating the light,"},{"start":"3:09","end":"3:43","startSec":189.5,"text":"also referred to as final gather in this sentence, Lumen calculates how the skylight is solved across a scene. This makes indoor areas properly dark compared to outdoor ones, and recreates very realistic lighting where interiors only get lit by the sky through openings like windows or doors. Also, just so you know, Lumen works best with solid objects rather than transparent ones. When working with translucency or volumetric fog, the lighting calculations will be simplified and unfortunately not as detailed,"},{"start":"3:43","end":"4:15","startSec":223.4,"text":"but it's getting better and better. As anticipated today, we'll only be focusing on Lumen and we will create a basic lighting setup in an empty level. Overall, Lumen is going to be your go-to solution when working with lights in Unreal, but if your machine struggles to compute a heavy environment or your FPS drop below optimal rate, you could also consider to use Lightmass instead, either the GPU or the CPU. The GPU would be faster, while the CPU a little slower. And also, when working with baked lighting,"},{"start":"4:15","end":"4:46","startSec":256.0,"text":"you'll be sticking to standard shadow maps compared to the virtual shadow maps with Lumen, unfortunately. Light baked lighting, standard shadow maps have a fixed resolution for the entire scene. They're simpler and less efficient compared to the virtual shadow maps, which adapt to the complexity of the scene and get more detailed the closer they get to the camera. Now, I said Lumen is well optimized, but be mindful that if using a ton of lights in your scene, your performance will still be impacted."},{"start":"4:46","end":"5:18","startSec":286.2,"text":"Alright, let's jump into the engine and create our first basic lighting setup using the environment light mixer. Alright, so before diving into creating our first lighting setup, we want to make sure that our project is correctly set up to use Lumen. So let's go up here under Edit and then open up the project settings. Here on the left, you will find different sections, and we will find under Engine, a section called Rendering."},{"start":"5:18","end":"5:51","startSec":318.1,"text":"Alright, so we want to make sure that first of all, virtual texture support is enabled, and then we want to check that dynamic global illumination is set to Lumen, as well as the reflection method set to Lumen. The ray lighting mode should be set to Surface Cache, and the shadow map method should be virtual shadow maps. After that, we just want to make sure that Nanite is turned on. Now let's go up here in the search bar and type SM6. Down here on the platform windows, if you're on the Windows machine,"},{"start":"5:51","end":"6:24","startSec":351.7,"text":"you want to make sure that the DirectX 12 targeted Shitter format SM6 is enabled. Now if you're on Windows, you should really just take care of this little checkbox down here, and not the one below here, which is the Vulkan one. Unless you plan to port your project to Linux or Android, or somehow your GPU performs better with Vulkan for some reason. Enabling both of them would just increase compilation time, as well as the size of the project, so I wouldn't recommend that. Okay, let's close down this window, and now we can create a new level."},{"start":"6:24","end":"6:57","startSec":384.6,"text":"So let's go under File, New Level, and the level we're going to be creating today is completely empty, because we want to start from scratch, building our light system. Alright, now if we go under Window, we can open up the Environment Light Mixer. Environment Light Mixer is a very simple tool that allows artists to edit their environment lighting components quickly, and get access to their properties all at once. So if we click all these little nice buttons over here, we should be able to create our first very basic lighting setup."},{"start":"6:57","end":"7:27","startSec":417.2,"text":"Let's start with the skylight, and Unreal is going to give us an error. That's just because the sky atmosphere is not there yet, and they're best friends. So let's move on with the directional light, then the sky atmosphere, and now Unreal is happy, the volumetric cloud, and the high fog. Now if we close the Environment Light Mixer, we can see that we have a beautiful and well-lit scene, and we can start building our environment in."},{"start":"7:27","end":"8:00","startSec":447.8,"text":"So this is a very quick and fun way to setting up realistic lighting in a scene from scratch. Now let's go back to our old level by clicking on Levels, and then open up the Assembly Small Map. And I'm not going to save these changes. Now you see this big purple cube up here? If you click on it, you will see that it is a post-process volume. A post-process volume allows us to define the overall look and feel of a scene through some properties that we get exposed to in its settings."},{"start":"8:00","end":"8:31","startSec":480.2,"text":"Today, we'll just use it to review different properties we can tweak to increase the quality of our illumination system using Lumen. So if we type Lumen up here in the search bar, we would get access to the Lumen global illumination properties of this post-process volume. Okay, so I'm going to get a little bit technical here, and I'm not going to dive too deep into the technicalities of what each setting of this post-process volume really means. But if interested, there are some courses that focus only on lighting in Unreal Engine,"},{"start":"8:31","end":"9:04","startSec":511.8,"text":"so I'd encourage you to watch those if you're interested in learning more about this. All right, so the first one we get access to is the ray lighting mode, which controls how Lumen rays are lit when Lumen is using hardware ray tracing. And right now, we have set it to Surface Cache. Surface Cache is a memory system that stores information about the surfaces in our scenes to calculate lighting quickly. After that, we have the Lumen scene lighting quality, which is set to one. A higher setting would help Lumen render with higher fidelity,"},{"start":"9:04","end":"9:35","startSec":544.3,"text":"but it can cost more GPU. So just so you know, any setting that you increase here is going to have a GPU cost. We can tweak the Lumen scene detail if we wanted to and increase it to two. And larger values here would help render smaller objects. Then we have the final gather quality that was set to two, so it was increased compared to the default value of one. The final gather quality helps remove overall noise in the scene, but again, it can be expensive."},{"start":"9:36","end":"10:06","startSec":576.9,"text":"Lastly, we have the scene capture cache resolution scale, which is a scale factor for the Lumen surface cache resolution for scene capture. Again, the higher this value, the more it's going to cost GPU-wise, so be careful. Okay, we're ready to go back to our slides now. Now, we've already taken a look at how to enable and disable NANIT on our assets, but let's just review it one more time in the engine. All right, so I'm going to be selecting my usual rock down here"},{"start":"10:06","end":"10:37","startSec":607.0,"text":"that we have selected also in the previous video. Then I'm going to clear out my filters. So I want to be able to navigate to the place in the content browser where this asset is stored by clicking on this little icon down here. Okay, so now if I right click on this asset, like in the last video, if I navigate up here, I can either enable or disable NANIT on it. If I wanted to, I could also select multiple static matches like this four,"},{"start":"10:37","end":"11:11","startSec":637.9,"text":"and then right click on all of them, and you can see down here that we could disable NANIT on all four of them if we wanted to. Okay, now let's double click on our boulder, and then let's review one more time that if you search for NANIT, up here you can also enable or disable NANIT support from the static mesh editor settings directly. All right, we're done with our review on NANIT, and we can switch back to the slides now to conclude this video. So that was it for this class. Thanks to Sean Spitzer for the creation of this lesson."},{"start":"11:11","end":"11:39","startSec":671.1,"text":"You can find some additional documentation at this link if you're interested in further expanding your knowledge in Lumen Global Illumination. I'd also encourage you to take a look at our courses focused on lighting on our platform, because they will dive into these concepts in better detail, and they're pretty cool. Thanks for sticking around, and in the upcoming lesson, we'll be looking to editing assets in the engine. Bye!"}],"05_Construction":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hey everyone, how are you doing? Ready to learn a bit about editing assets in the engine? All right. In this video, we'll be focusing on construction blueprint tools to edit assets in our maps. Let's get right into it. So we said construction blueprints, but those blueprints are actually just blueprint classes or actors, and you can distinguish them in the content browser by their blue bars and little thumbnails with a sphere on it."},{"start":"0:30","end":"1:03","startSec":30.2,"text":"We call them construction blueprints because they primarily work in the construction script graph of our blueprint editor. Now, keeping it simple, blueprint visual scripting is a node-based visual programming language in Unreal Engine. And before I said blueprint class, what is it? A blueprint class, often referred to as blueprint, is just an asset that allows you to easily wrap some functionality code into it. This blueprint asset can be placed into maps and will behave like any other type of actor."},{"start":"1:03","end":"1:34","startSec":63.6,"text":"Now, the construction script specifically is a type of graph in a blueprint class that executes when an actor is placed in the editor, meaning in our map, but not during gameplay. It basically helps creating customizable tools that improve the artist's workflows. And we will take a look at one of them in just a second. You can also use construction blueprints in conjunction with procedurally generated content or PCG that we will check out in the next video."},{"start":"1:34","end":"2:05","startSec":94.2,"text":"The construction blueprint we will review today is the BP-Crixle Spline scatter and was extracted from a Crixle asset pack. This specific construction blueprint will allow us to add assets along a spline. So let's take a look at it in the engine. So if we navigate a little bit higher here and towards the beach of this map, you can see that if you click on this asset, it's actually a blueprint actor. You can see the sphere up here."},{"start":"2:05","end":"2:40","startSec":125.0,"text":"Now if we take a look at its details, we can see down here that we have some meshes assigned to this blueprint actor. And those are the meshes that are actually in populating this spline. Now this construction blueprint will be populated with the static mesh assets we input into it just like here. These assets will be instanced into our map. What does instancing mean? Instancing basically means that these assets will be copied but in a very specific way because instancing helps efficiently group identical static meshes into one actor as"},{"start":"2:40","end":"3:15","startSec":160.3,"text":"you can see here. And this helps reducing performance and workflow costs. So let's take a look at this spline. If you click on this white squares here either at the beginning or the end of this spline curve, you can either move them directly around into the map and this will either add or decrease the amount of meshes you see populating our spline. Or you can also, you see these little purple squares either here or here. You can also move those and those are the tangents of the points of the spline."},{"start":"3:15","end":"3:49","startSec":195.9,"text":"And the points of the spline are the white squares while the tangents are the purple ones. If you move around the tangents they will just be impacting the shape of the spline but not the length of the spline directly. In order to do that you will need to move the original white squares. Okay, let's try to populate one of these construction blueprints from scratch. So if you navigate into the content and blueprint folder you can find the blueprint quicksand spline scatter tool down here. And if we drag and drop it into our map you can see that we just get our spline."},{"start":"3:49","end":"4:23","startSec":229.1,"text":"Now we have it selected up here quicksand spline scatter tool. And we can start selecting our meshes by clicking on this add element button here. So let's start with some rock and anything will do. I will just choose four different rocks now. Okay, so now if we click on one of the two squares and we start extending it we can see that the meshes will be randomly populated around our spline."},{"start":"4:23","end":"4:57","startSec":263.9,"text":"We can also just move our tangents around. Now you can see that if you have one of the points selected you don't get access to the static meshes or the rest of the details of your construction blueprint. So make sure to select it directly into the outline in order to get access to these different settings. Now what else can we do here? We can also bake these meshes to the level so we can access to them individually. We can change how they're randomized along our spline. We can choose the spacing between them, the random rotation."},{"start":"4:57","end":"5:30","startSec":297.6,"text":"You would probably need to add very high numbers here like 2000 and then the random scale. You can also access to further additional transforms by pressing shift on the keyboard and clicking on this little arrow here you will be able to expand all the different sections of these nodes. And here you can see that you get access to the individual location and node mesh of the assets populating our spline. Alright, so since we mentioned that I just want to show you really quickly what visual"},{"start":"5:30","end":"6:04","startSec":330.1,"text":"scripting looks like. So if I click on edit in blueprint up here in the details panel or here in the outliner, I will be able to open my blueprint actor. And here you can see that we have the event graph and the construction script. We're not going to dive into visual scripting right now, but this was just to give you a hint on how these tools are developed. Now let's go back to our slides to conclude this video. Alright, that was it for this class, but you can find some additional documentation at this link if you're interested in further expanding your knowledge in blueprints, specifically"},{"start":"6:04","end":"6:23","startSec":364.6,"text":"the construction script. I'd also encourage you to take a look at our courses focused on blueprinting on our platform because they will dive into this concept in great details. Thanks for sticking around and in the upcoming lesson we will look into procedural content generation and how to use it in our environment. Bye!"}],"06_PCG":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Hi, welcome back. In this class, we'll be learning some basics of procedural content generation in Unreal Engine to support our world-building workflows. There are a few settings in our project we need to take care of before starting to work with PCGs, so let's jump for a moment in the engine and review them one by one. Back in our project, we want to go under Edit and Plugins. Then in the search bar, type Procedural."},{"start":"0:32","end":"1:05","startSec":33.0,"text":"And specifically, these three plugins should be activated. So Procedural Content Generation Framework, Content Generation Framework External Data Interrupt, and Content Generation Framework Geometry Script Interrupt. Besides that, you also want to make sure that Procedural Mesh Component is activated. Those four plugins should be already activated in this specific project, but if they're not, make sure to activate them manually yourself and then restart the engine. Alright, once your engine is wired up again and running, we can close this window."},{"start":"1:05","end":"1:39","startSec":65.4,"text":"And then if you wanted to get started with your PCGs, you would first need to create a PCG Graph Asset. So you would need to right-click on the Content Browser, go under PCG, and then create a PCG Graph. An Unreal Engine here gives you the option to start from a template, or if you prefer, you can also create an empty graph. Now unfortunately today, we're not going to build a whole PCG Graph from scratch. This series of lessons only aims to give you an overview of these workflows. But you can find courses on our platform that you can just follow to dive deeper into PCGs."},{"start":"1:39","end":"2:13","startSec":99.7,"text":"So let's go back to the slides and we will take a look at the further steps we will need to take when getting started with PCGs. Alright, once your PCG asset has been created, you want to drag it in your scene and adjust the size of it as you need it. Later on, you want to open up your PCG Graph Asset and start out by defining the way you'd like to populate your map, either by spawning these meshes on your terrain or landscape using a surface sampler or through a spline using a spline sampler, for example."},{"start":"2:13","end":"2:47","startSec":133.7,"text":"After that, you want to add a few nodes to assess how the ISM or instance aesthetic meshes are going to be placed into your map. And that's what the transform points would be for. So usually the nodes expressing which meshes will be spawned are at the end of the graph. And it's useful as you move along in the development of a PCG Graph to just enable debug mode by pressing D on a node or just double-clicking on it to inspect it and view it in the Data Viewport. This will display little squares as preview meshes and will give you an overview of where"},{"start":"2:47","end":"3:20","startSec":167.7,"text":"you're at in the development of your PCG. OK, let's jump into the engine and see a complete example of a PCG using a surface sampler. You're totally welcome to use an Examine this graph as a starting point to create your own or just learn from it. Let's go. Alright, so if we pan a little bit around, we can find up here this big purple cube encompassing most of the trees down here in our set. And if we click on it, we will find out that this is actually a PCG Graph."},{"start":"3:20","end":"3:51","startSec":201.0,"text":"And once we have it selected in our Outliner, we can go down here into the Details panel and if we scroll down, we will find the graph that is connected to this asset. So let's double-click on it to open it up. Alright, so if we zoom into this graph, we can see that we have one main input point, which comes from the landscape. And then we have five different set of nodes or different static meshes. The plants and the rocks, the small bushes, the many trees, the large trees and the large"},{"start":"3:51","end":"4:23","startSec":231.6,"text":"rocks. This different set of nodes will basically be spawning different meshes. We're using surface samplers to generate a point cloud that follows the topology of the input surface, in this case the landscape. And if we click on the surface sampler, we will get access to a few settings, especially the points per square meters. With this setting specifically, we can control the density of the point distribution. So if we click on the node and then press A, we can start inspecting it and it will be displayed in the data view board."},{"start":"4:23","end":"4:59","startSec":263.4,"text":"These little cubes are actually just temporary preview meshes. So if I, for example, were to increase the points per square to something like 26, you will see that the density of these points will highly increase. So I'm just going to control Z to keep it to its original value. Now after the surface sampler, we have a transform points nodes. And transform points simply add spatial transformations to the point data we output from the surface sampler. They basically let us define minimum and maximum position, rotation and scale values of our"},{"start":"4:59","end":"5:31","startSec":299.4,"text":"points and add some variation to them. After that, we have a union and difference set of nodes. Now the difference node performs a subtraction on the sample points, removing specific ones from the source that fall within the bounds of that difference. For now, there is nothing connected to the difference input. So if we double click on this node, we will see that nothing is actually happening in the view board. And that's because we're actually not subtracting anything to it. If we click on the difference node, we will see in the setting that the density function"},{"start":"5:31","end":"6:04","startSec":331.3,"text":"will be set to binary. It's important to leave it like that because this way we will be treating all the points as either present, so once, or absent, zeros, and get very predictable results or very predictable cuts. We usually use a union node before the difference node to resolve multiple point sources into a single merged point cloud before performing a subtraction operation with a difference. Now this last node over here is a static mesh spawner."},{"start":"6:04","end":"6:37","startSec":364.2,"text":"So if you simply right click in the graph and then add a static mesh spawner, you will see that it will have the same look and input and outputs. And if you press F2 or right click on it and then rename, you will be able to rename it large rocks. So this is how this node was created. Static mesh spawners basically just spawn static meshes positioned based on whatever we expressed in the nodes before it. And we can define the meshes we want to spawn through the static mesh spawner down here"},{"start":"6:37","end":"7:09","startSec":397.2,"text":"in the details under mesh entries. We would need to add one more, then open up the index, the descriptor, and then down here we would be able to input our static meshes. I will just go on and delete it. Now if I pan down here in the graph, you will find this self pruning node. A self pruning node will basically remove any overlapping points from a point cloud based on their bounds. So it basically checks all the points for self intersection and an emulates those conflicting"},{"start":"7:09","end":"7:39","startSec":429.3,"text":"with each other. In this specific setup down here, we could actually bypass the union and different nodes as right now we're basically subtracting the same points from each other, resulting in zero points. So if I double click on the difference, you will see that our view board will be completely empty and we wouldn't have any preview meshes. But if we press Alt on our keyboard and then click on the input pin of large trees to disconnect it, and then connect the self pruning output directly to large trees, and then inspect"},{"start":"7:39","end":"8:12","startSec":459.7,"text":"these large trees node, some large trees would actually end up being spawned. Alright, so you can take a look at this further, but for now we'll just go back to the slides and check out a different type of PCG workflow. There is one thing to keep in mind, even though PCG graphs are optimized and using mesh instancing, they do have limitations and your performance will be impacted if you add too many items to them, especially if those static meshes are too heavy. They're not invincible. So let's acknowledge that when creating an environment, there won't be always one tool"},{"start":"8:12","end":"8:46","startSec":492.8,"text":"fitting all our needs. And in this course, we're presenting you with multiple options to allow you to pick and choose the ones that best aligns with your goals. So let's go back into Unreal and check out a different PCG setup. Alright, let's go back to our map. And then if I pen around here, I will find a different PCG cube. So let's select it in our map. And then down here on the right in the details panel, we'll get access to the graph. So let's double click to open it up. Alright, we can immediately see that this graph is a little different from the one of"},{"start":"8:46","end":"9:18","startSec":526.7,"text":"the PCG sample 01. Simply because it doesn't generate a point cloud from a landscape, but from spline data. So simply we can see that we are defining the spline that we will be sampling through an actor selection tag that is specified here in the details. The first spline data is sampled from a spline with a tag assigned to it of test spline. And the second spline data is taken from a spline or an actor with the path tag assigned"},{"start":"9:18","end":"9:53","startSec":558.2,"text":"to it. So let's go briefly to our map and then zoom into this PCG graph. We can see that we actually do have two splines here. One is outlining the trees and the other one is like a path cutting through them. So let's select our first spline here that is encompassing the trees. It's going to be a little bit tricky at first. You will be selecting the landscape, but finally you will succeed and select the correct spline. So this is BP underscore samspline. And if I search down here in the details for tag, I can see that I do have a tag assigned"},{"start":"9:53","end":"10:26","startSec":593.0,"text":"to it and it is test spline. If I click on BP path spline in the outliner, I will be able to select the path going to the trees. And down here in the details, you will see that the tag assigned to it is path. So that's how the PCG graph is getting that spline data. After that, we're using the spline samplers to generate a point cloud that follows the splines. And we're using two because with one, we're defining the area encompassing the spline. And the other one, if we zoom into it like this, it's a little bit hard to see, but I"},{"start":"10:26","end":"10:56","startSec":626.6,"text":"hope you will be able to see it in the video. We're basically defining the outline of the spline. And then we're subtracting the two, thus limiting the spawn trees to be only within the spline. We're self-rooting to make sure that there are no overlapping trees. And then we're moving them a bit around and scaling them down. Then on this other set of notes below, we're getting the spline data from the path. We're sampling the point cloud along the spline."},{"start":"10:56","end":"11:28","startSec":656.6,"text":"We're using a bounce modifier, which allows us to explicitly modify the extent of the points in our point cloud, which in this case, we're basically using this to create a larger exclusion zone around our points, larger than our spline path. And then we're basically subtracting this from the areas of the trees. And thus we're creating a path that is cutting to the trees. And this is easier to see in our map. So if I go back to our map, you can see here that if I start moving these points around"},{"start":"11:28","end":"12:02","startSec":688.0,"text":"with my spline selected, I will be able to define how this path or road will be going through the trees. And if I were to be painting the terrain here and adding a different materials like some rocks or pebbles, it would really look as if a road will be cutting through this forest. Now let's select this other spline over here. And if I move the points of the spline here, you can see that the trees will always fall within the spline area. But if I increase the surface area of the spline, more trees will be spawned."},{"start":"12:02","end":"12:39","startSec":722.6,"text":"And if I just reduce it, less trees will be spawned. All right, now that we have an overview on different PCG workflows, let's go back to our slides to conclude this video. So that was it for this class, but you can find some additional documentation at this link if you're interested in further expanding your knowledge in PCGs. I would also encourage you to take a look at our courses focused on procedural content generation on our platform, because they will walk you through the development of PCGs. Thanks for sticking around, and in the upcoming lesson, we will be looking into Blueprint"},{"start":"12:39","end":"12:42","startSec":759.0,"text":"and Modeling Tools in Unreal Engine. I'll see you there."}],"07_BPModeling":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Hi, welcome back. In this class, we'll be exploring Blueprint and Modeling Tools for managing assets in Unreal. Let's get right into it. In Unreal, a Blueprint class defines the type of actor that you can place into your scene as instances. Editing that Blueprint class will update every instance of it in our project, and that's really handy. There are various types of Blueprints you can create. Based on their parent classes, they will inherit different kinds of properties."},{"start":"0:32","end":"1:02","startSec":32.7,"text":"Today, we're going to be using the Actor class type, which is an object that can be easily placed in the world. A Blueprint Actor specifically can hold various components in it, like static mesh components, collision components, audio components, and more. These components define the actor's appearance, behavior, and how it interacts with the world. This all comes quite useful to us,"},{"start":"1:02","end":"1:32","startSec":62.8,"text":"because a Blueprint Actor will basically be a basket to which we will add all the eggs we'd like. With the click of a button, we could easily swap the eggs with cubes, as well as change their appearance if we wanted to. Thus, changes would be applied not only to the Blueprint Actor, but also to all the instances of it in our Maps. I know this whole Blueprint-Majorowska concept can feel quite abstract at the beginning. Let's jump into the Engine and see it in action."},{"start":"1:33","end":"2:06","startSec":93.8,"text":"I want to keep things simple for this video, so I'm just going to go under File, New Level, and then Create a Basic Level. Down here, we can just click on the Player Start and delete it, because we're not going to be using it today. Then up here in the Quick Ad menu, we can go under Shapes and create a Simple Cube. If we wanted to add this Simple Cube to a Blueprint, we could just click on this Blueprint button up here, and then convert the selection to a Blueprint class."},{"start":"2:08","end":"2:40","startSec":128.2,"text":"You can choose different creation methods. The one that I find the most modular is the Harvest Component one. We can choose the parent class to be whatever we want. We can also choose it to be an Actor, but for now, I'm going to keep it to Static Mesh Actor. The parent class of this Blueprint will be Static Mesh Actor. The Blueprint name, I'm going to assign it to BP underscore cube, and then I'm going to just save it under the Blueprints folder up here. All right, so this will open my default BP cube,"},{"start":"2:40","end":"3:11","startSec":160.9,"text":"and I'm just going to dock it up here. So you can see up here that we have two different components assigned to our Blueprint, and the third one is the Static Mesh Component with our cube assigned to it. Up here, you can find the parent class of this Blueprint, which is the Static Mesh Actor. Now, if we wanted to, we could just move this cube around. We could change this to a different mesh, and we could also change the material assigned to it. But first, I want to show you how to do things a little bit differently, because if we go back to our map,"},{"start":"3:11","end":"3:43","startSec":191.8,"text":"we can see that since the parent class of this BP cube is a Static Mesh Actor, its thumbnail up here is the one of a Static Mesh, which can be a little bit confusing, because it's not a Static Mesh, it's actually a Blueprint. And if you simply click on it, it looks as if there is no Static Mesh assigned to it, and that's simply because we selected the parent of the class, not the single component. So if we click on Static Mesh Component 1, we'll get access to the single component, and we would be able to change it if we wanted to. Since this method can be a little bit confusing,"},{"start":"3:43","end":"4:13","startSec":223.0,"text":"I'm going to show you a different one. So let's right-click in the Content Browser, and then create a Blueprint class. We can choose Actor as Parent Class, and then we're going to call this BP cube Actor. Now, you can already see from the thumbnail up here that those two Blueprints have two different Parent Classes. The one of the Actor usually has this little sphere with a plane underneath it. So let's double-click on it to open it up, and you can see that it's completely empty."},{"start":"4:13","end":"4:45","startSec":253.9,"text":"That's because we haven't added any components to it. So if we go here on the left, we can click on Add, and then Static Mesh. And if we click on our Static Mesh, we can go into the Details, and then choose any Static Mesh Actor we want to down here, and I'm just going to choose the cube. All right. Now that I've made my changes to the Blueprint, I want to make sure to Compile. You need to always compile your Blueprints, and then I'm just going to Save. Now, if I go back to my map, and then I drag and drop this BPQ Actor"},{"start":"4:45","end":"5:16","startSec":285.8,"text":"into the Scene, it will be spawned in my map. Now, let's say we wanted to apply more changes to this Blueprint container. So I'm just going to go right into it, and then I'm going to be adding a new Static Mesh. And if you, like me, had the cube Static Mesh Component selected and then clicked on Add, and then added a new Static Mesh, you might have added a child of this Static Mesh Component. I'll show you what I mean. So if I click on Static Mesh 1, which is the second Static Mesh we created,"},{"start":"5:16","end":"5:46","startSec":316.8,"text":"and then add a different Static Mesh to it, like a cone, you will see that we can move this cone independently. But then if I click on the first Static Mesh, which is supposed to be the parent, and then I move it around, the cube will go with it. That's because the cone is attached to it. But if I just drag and drop it on top of it, it will be side by side. So I could move the cube independently of the cone. Okay, let's compile and save these changes,"},{"start":"5:46","end":"6:17","startSec":346.9,"text":"and then go back to our map, and you can see that the changes were immediately applied to our map. And if I alt and drag onto the gizmo, I could duplicate this Blueprint instance, and I could do it as many times if I want. Now, if I go back to my Blueprint cube actor, I could assign a different material to this, like a basic yellow material to the cone, and then a basic red material to the cube. I would compile and save, and if I go back to my map,"},{"start":"6:17","end":"6:49","startSec":377.6,"text":"you can see that the changes were applied to all of them. Now, the ones you see here are instances of the Blueprint actor. So the Blueprint actor, we can say it's the father of all these different children. If I wanted to, I could apply individual changes to each one of them. If I double click on a Blueprint actor, I get access to their individual components. So this means that I could just move this cube around and the cone, and I could even just change the whole static mesh assigned to it if I wanted to, as well as the material."},{"start":"6:49","end":"7:19","startSec":409.0,"text":"But these changes would just be applied to this individual instance, and they won't actually appear in my Blueprint actor, that's because the Blueprint actor is the father, and those are the children. Let's jump back into the slides to take a look at modeling tools and how to use them. Now, modeling tools lets us create, sculpt, and edit 3D geometry directly in Unreal Engine. But before diving into them any further, we need to make sure that the modeling tools editor mode plugin is enabled in our project."},{"start":"7:19","end":"7:51","startSec":439.7,"text":"The other two that you see here in the slide don't really matter for what we're going to be doing today, so the modeling tools editor mode would suffice. Make sure to restart the engine after you enable the plugin. So today, we're going to keep it quite simple and we're just going to learn how to adjust pivot points on our static mesh actors using the modeling tools. So let's jump into the engine and learn how to do that. Okay, first of all, I'm just going to go file, new level, and create another basic map just to keep it simple."},{"start":"7:51","end":"8:22","startSec":471.0,"text":"And we don't need to save these changes. Then I'm just going to be deleting my player start. And in this map, we just want to add a mega scan asset, any asset would do. So I'm just going to choose a dead tree. And then I'm going to be importing it into my map. Now, if our aim for today were to be changing the pivot of this mesh temporarily, we could simply do it by pressing alt on our keyboard and then middle mouse button on our mesh or anywhere else where we wanted our pivot to be positioned."},{"start":"8:22","end":"8:53","startSec":503.0,"text":"So I'm just going to be setting it there. And then if I were to perform a transform action, so just rotate scale or move this object, it would be performed from this pivot point. Now, since that's at temporary position, the pivot point would immediately snap back to its original position. And now I'm just going to reset the location and rotation to its original values. And if you wanted that temporary pivot to actually stick and be permanently replaced, then you would need to again,"},{"start":"8:53","end":"9:26","startSec":533.9,"text":"press alt on the keyboard and middle mouse button to whatever you want it to be positioned. And then right click on the mesh, pivot and set as pivot offset. Now, even if we perform any changes to the position of this mesh or rotated it around, as well as clicking away and then back on the tree, the pivot would stay as it was. And if you wanted to reset it, you could just right click on the tree, pivot and reset pivot offset. And now we'll go back to its original position. Now, this method of changing the pivot position"},{"start":"9:26","end":"9:56","startSec":566.2,"text":"is not very precise and it's a little bit finicky, as you could see. So let's take a look at how to achieve this using the modeling tools instead. Now, you got to be careful. And before you apply any changes to a static mesh actor in your map using the modeling tools, you want to make sure to duplicate it first in the content browser. This might sound a little unintuitive based on the behavior we just saw using the blueprint actors because modeling tools actually work the opposite. Basically, any changes you apply to a static mesh actor"},{"start":"9:56","end":"10:27","startSec":596.4,"text":"using the modeling tools in your map is also going to be applied to the static mesh asset itself, the one we have here in the content browser. So these changes won't just stick to our map only, but to our entire project. Meaning that if we use this static tree mesh into a different scene within our project and we edited it here into this map using the modeling tools, those changes will be applied to the three in the other scenes too. So that's why it's extremely important to duplicate the asset you'd like to change"},{"start":"10:27","end":"10:59","startSec":627.3,"text":"in the content browser first. So let's do that. I'm going to right click on the SMDat tree and then duplicate it. Now I'm just going to call it that tree changed. And then with the dat tree, a static mesh actor selected into my map, I'm just going to go into the details panel and then click on this little button down here to use the selected asset that we have in the content browser. As assigned mesh to this actor. Now nothing will change in your map because this is simply a duplicate of the original tree."},{"start":"10:59","end":"11:30","startSec":659.4,"text":"But this will make sure that any changes that we apply on this dat tree will just be applied to this changed pivot asset and not to the original one that we also used in the other map. Now let's switch our mode from selection mode to modeling mode. And then under the XForm section, you can see the edit pivot tool. And here you want to make sure that you apply the changes to all the LODs. This is really important. And you can also snap drag the position of the pivot or snap drag the rotation of the pivot"},{"start":"11:30","end":"12:02","startSec":690.6,"text":"if you needed to. And then this box position will basically be based on the bounding box of the tree. And I could choose to position the pivot at the center of the bounding box at the bottom, the top, the left, the right, the back, the front, and the world origin. I'm going to stick to center for now. And then apply my changes. OK, so this will be a permanent change, meaning that if I drag out of this tree to create a different instance of it, the pivot position will stay the same as well as if I drag another instance of it"},{"start":"12:02","end":"12:35","startSec":722.9,"text":"from the content browser directly into my map, the pivot point would be the one that we just changed. If we import the 01, meaning the original tree, you will see that the pivot point would be in a different position. So there are a lot of other tools here you can use to deform or edit your mesh with the modeling tools, but that's going to be it for today's class. But you're nice, so I'll give you a quick tip nonetheless. If you're going to apply drastic modeling changes to any asset, make sure to go under Edit Project Settings."},{"start":"12:35","end":"13:05","startSec":755.8,"text":"And then in the search bar, type Enable, Raytracing, while editing, and you want to turn this on. This will prevent weird artifacts to appear in your viewport while you're editing your assets. Then also, if you aim to deform the shape of your mesh, it might be good to check out once you're done that your UVs are still correctly tiling on your object and reproject them if necessary. You can find the UV Editor under More and UVs up here."},{"start":"13:06","end":"13:38","startSec":786.8,"text":"But luckily for today, we just wanted to change the pivot position of our mesh, so no drastic changes on your resin for now. I hope this gave you a good glimpse at modeling tools and how to use them in your project. Let's go back to our slides to conclude this video. So that was it for this class, but you can find some additional documentation at this link if you're interested in further extending your knowledge in blueprint assets and modeling tools. I'd also encourage you, as usual, to take a look at our courses"},{"start":"13:38","end":"13:55","startSec":818.3,"text":"focused on in-editor modeling tools to learn more about the specific set of tools in the engine. Thanks for sticking around, and in the upcoming lesson, we will look into level editing, as well as the stage monitor and level snapshots. I'll see you there. Bye."}],"08_LevelEditing":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"Hello again. I really appreciate you sticking with me through this course and hope you're learning a lot from it. In this lesson, we'll be exploring level management as well as checking a peek at the Stage Monitor and Level Snapshots tool we have at hand. Alright, first and foremost, what is a level? We've been interacting with some since the beginning of this course but we never actually sat down and accurately defined them. A level also commonly referred to as a map is a self-contained 3D environment or scene that serves as the"},{"start":"0:36","end":"1:07","startSec":37.0,"text":"stage for our content. Now, the concept of level management in this case is a hot topic for linear and legacy production, but not really for game development. In games, you would rather use something called world partition instead, which lets you basically slice a large map into smaller ones and use level streaming to load or unload them as the player moves across the scene. Depending on the complexity of your environment, you could handle using"},{"start":"1:07","end":"1:42","startSec":67.8,"text":"a single level only, especially if you're flying solo, but as soon as you start working with a team on a real-time production, level management becomes an essential part of your pipeline. That's because it allows different artists to collaborate on a scene at the same time and that's without interfering with each other. You basically chop the elements composing your environment into different tasks assigned to different artists and each one of these tasks, like lighting, props, vegetation, could be allocated to a separate"},{"start":"1:42","end":"2:13","startSec":102.0,"text":"map and all of these maps together would generate the final scene. Level management could also improve your viewport performance, especially when working on a cinematic or animation production, because camera or animation artists could isolate the areas of an environment where the animation could be taking place and save resources to increase the frame rate on their viewport to play the work in progress animations in real time. So, level management is really important and learning how to work with it"},{"start":"2:13","end":"2:45","startSec":133.4,"text":"will make you a true real-time team player. Alright, the main tool behind level management lies in the Levels tab. And there are a few ways of adding a level to your Levels tab, so let's review them directly in the engine. Alright, we want to navigate to Window and then down here you can find Levels. That's not to be confused with the Layers panel, even though the naming is quite similar and they're next to each other, so I get that it can be a little bit confusing. But compared to the Levels tab, the Layers panel gives"},{"start":"2:45","end":"3:15","startSec":165.8,"text":"you the ability to control the visibility of groups of actors in your scene, so it doesn't handle the visibility of your maps entirely, but simply the visibility of the assets that are already in that map. But today we want to take care of the maps individually, so let's click on Levels instead. So you will see up here that there is the Persistent Level. The Persistent Level is the father of all the sub-levels or the levels that are within it. The Persistent"},{"start":"3:15","end":"3:46","startSec":195.8,"text":"Level in this case is the Assembly Small Level. Now the Text in bold means that this specific level is active. The Active Level is the one where the changes will be applied to if any changes are applied to the scene. And if you double click on any of the levels within the Levels tab, you will make that level active. This asterisk icon right next to the text means that there are unapplied changes to the map. So if, for example, we make the Geo Level active,"},{"start":"3:47","end":"4:22","startSec":227.2,"text":"and then we add a cube in it, you will see that the change would be applied to the Geo Level, and here there would be an asterisk because there are unsaved changes. So if you Control Shift-Test, we would apply your changes to all maps and save all. And then if we toggle the visibility on and off of the Geo Level, you will see that the cube would be in it. Now there is this NDC level out here, which is basically just a tool to send red letters to the LED volumes. Okay, let's delete this cube and Control Shift-Test again. Now if you wanted to, you could add an"},{"start":"4:22","end":"4:56","startSec":262.0,"text":"existing level to your Levels tab. You can do that either by selecting the level you want to add in the Content Browser and then drag and dropping it into the Levels tab. Or I'm just going to delete this. We can just click on these Levels down arrow and then add existing. And you can select that you want to add as sub-level to our Persistent one. Now if the level you're trying to create doesn't exist yet and should contain assets that are currently present in your scene, then you can easily select them in the Viewport and then go to Levels, create new with selected actors,"},{"start":"4:57","end":"5:31","startSec":297.2,"text":"choose a name and then save. I'm not going to do it right now because I don't want to mess around with my levels. Also, if you wanted to, you have the option to merge multiple levels. So you can just select them in the Levels tab and then go under Levels and Merge. And this will create a new level with all these sub-levels merged into one. To keep things organized, you can also create new folders and name them as you want, like sub-levels or whatever you need. Then you can just drag and drop the levels you want into them. Now if I click this icon up here, I will be able to"},{"start":"5:31","end":"6:06","startSec":331.0,"text":"summon the level details. And I can choose the level I want to spec in either from up here or just by selecting it in the Level tab. And something really cool that you can do here is adding some offset to the entire level. And if you click on this Viewport Edit button here, you will be able to reposition it directly in the Viewport. Now these changes will be applied to the entire map. Right now the cube sub-level just contains a cube, but if we had multiple assets, those would be moved together with it. Alright, we can close this down. So once your desired maps have been added to the"},{"start":"6:06","end":"6:40","startSec":366.8,"text":"Level tab and everything is properly organized, you can choose whether you'd like that scene to be always loaded or loaded via Blueprint. You can access this option by right-clicking on any sub-level and then changing the streaming method. Now this can be a little confusing because when working within the Editor Viewport, it doesn't matter whether a level is always loaded or loaded via Blueprint. As long as its visibility is turned on in the Levels tab, then it will be displayed in the Editor Board as we work in our level. The difference though stands in how these levels will be streamed"},{"start":"6:40","end":"7:13","startSec":400.5,"text":"at runtime, meaning that if we were to either play or I'm just going to click on this hamburger or simulate, and I'm just going to click on simulate, our map, the always loaded maps will be displayed, but the ones that are added via Blueprints will be disabled unless correctly added via Blueprints. So as you can see here, our cube streaming method is via Blueprint. The Geometry Level is also loaded via Blueprint and the NDC is also loaded via Blueprint. If we change the Geo Level to be"},{"start":"7:13","end":"7:47","startSec":433.6,"text":"always loaded and then try to simulate again, you will see that just the cube and the NDC Level would be disabled because we have no Blueprints actually loading these levels. So unless you plan on setting up a Blueprint to load the levels at runtime, it's a good idea to just set the streaming method of your maps to always loaded. All right, let's go back to the slides and check out the Stage Monitor plugin. Now, full disclosure, the Stage Monitor doesn't have anything to do with level management. They serve completely different purposes,"},{"start":"7:47","end":"8:20","startSec":467.4,"text":"so I just wanted to point that out. But since this course is designed to introduce you to the fundamentals of world building for virtual production, we felt it would be important to mention it nonetheless. The Stage Monitor is a tool that lets you review and manage multiple computers running Unreal Engine at the same time. This is typically used in a virtual production setup where you often have many computers working together, one displaying the background of your scene on an LED wall, another editing the scene itself, another for Niagara FX, and so on. The"},{"start":"8:20","end":"8:50","startSec":500.8,"text":"Stage Monitor acts basically like a control center and gives you an overview of what all these computers are doing. To get started with the Stage Monitor, there are three plugins you need to enable. So let's jump into the Engine and check them out. I'm gonna stop simulating, and then I'm gonna go under Edit, plugins, and then search for Stage Monitor and make sure that the Stage Monitor plugin is turned on. After that, I will search for virtual production"},{"start":"8:50","end":"9:20","startSec":530.9,"text":"utilities and make sure that this plugin is turned on. And then there is a third one that is optional, which is called Switchboard, that in our case is gonna be turned off because we don't need it. But just so you know, the Switchboard is basically a remote control for all your Unreal Engine instances across different computers. Okay, we can close this down. And once all of the required plugins are enabled and the Engine has been restarted, we can go to Windows,"},{"start":"9:21","end":"9:57","startSec":561.7,"text":"Virtual Production, and Stage Monitor. Now in this class, unfortunately, we won't be exploring much of the Stage Monitor as we don't have any machines synchronized to it and neither any end display preconfigured. But there is an entire course dedicated to it on our educational platform, so I'd encourage you to check it out. All right, let's go back to the slides and check out the Level Snapshots tool. So, Level Snapshots allow you to basically take a picture of your scene setup so that you can return to it anytime you like. The Snapshots save the exact position and"},{"start":"9:57","end":"10:29","startSec":597.9,"text":"settings of everything in your World Outliner. You can even choose whether you want to restore an entire scene back to how it was when you took the snapshot or just bring back some specific parts. This tool is very useful for virtual production because it lets you revert your changes on the fly if your Creative Director or DP changes their mind about the look of the scene. It's important to note though that while Level Snapshots work flawlessly with dynamic lighting or Lumen, if you're trying to use them with light mess or big lighting, restoring light changes might be a"},{"start":"10:29","end":"11:03","startSec":629.9,"text":"little tricky because the lighting would need to be rebaked at each instance, so it wouldn't be a very smooth change. All right, let's jump into the Engine and see how the Level Snapshots work. We can close the Stage Monitor and then we want to go to Edit, Plugins, and then search for Level Snapshots. So, the Level Snapshots plugin needs to be enabled in order for us to use them. After you've restarted the editor and the plugin is enabled, you will find this low icon up here"},{"start":"11:03","end":"11:32","startSec":663.1,"text":"and right next to it these three dots and if we click on them, we will be able to open the Level Snapshots Editor. So, before we apply any changes to our map, let's just take a snapshot of its current stage and we can name it Original Assembly Small, which is the name of the map, and then we want to save it under Levels and I'm just going to add a slash back up to add a new folder. I don't want it to be saved into any other subfolder, so I'm going to delete this"},{"start":"11:33","end":"12:07","startSec":693.6,"text":"and the name of the default Level Snapshot is fine. So, let's click on Create Level Snapshots. Okay, now if we navigate to Backup, we can find the Level Snapshot Asset. All right, let's apply some changes to this map. So, I'm going to go into my Outliner. I'm going to click on this cube up here and then I'm just going to move it around. I could also change the material on it and assign a different one like red, a red material, and I could also just select the directional light and rotate it around by making it more like the sun is almost setting. Okay, so once I'm done with"},{"start":"12:07","end":"12:42","startSec":727.5,"text":"my changes, I can either click on this take snapshot button or I can also just click on the one up here in my toolbar and I'm going to call it Dawn Assembly Small. Again, we want to save it to Levels slash backup. We want to delete any further subfolders and then create our Level Snapshot. Okay, perfect. So, now if our DPO director wanted to revert the changes to their original stage, we could just select our original snapshot by double clicking on it and then restore the Level"},{"start":"12:42","end":"13:15","startSec":762.9,"text":"Snapshot and it would even tell us the actors that would be modified compared to the current settings. So, let's click on restore Level Snapshot and you will see that all the changes would be applied. And if they change the menu again and wanted the Dawn, you could just double click on it and that'll restore the Level Snapshot. Now, these changes were applied to the World Outliner and it didn't matter whether the assets we changed were in any of these sub levels. In fact, the cube asset is part of our cube sub level, but we still changed it and reverted it back. That's because"},{"start":"13:15","end":"13:49","startSec":795.5,"text":"it is part of our World Outliner. But there are certain changes that our Level Snapshots want to detect. For example, if we were to add a new level to our Levels tab and then take a snapshot, the Level Snapshot would just detect the changes in the World Outliner, not in the Levels tab. So, you wouldn't understand these meshes are part of a separate sub level. It would add them, but to the persistent level. So, you gotta be careful with that. If you apply any changes to your level management structure, those won't matter in the Level Snapshots. I hope this gave you an"},{"start":"13:49","end":"14:25","startSec":829.0,"text":"idea of using Level Snapshots in the editor and how you can use it to your advantage in a virtual production setting. Now, let's go back to the slides to conclude this lesson. Alright, that was it for this class. And at this link, you can find other extensive documentation and resources to further expand your knowledge in managing multiple levels, the stage monitor, and the Level Snapshot tool. In the next lesson, we will be getting an overview of working with materials in Unreal Engine. Have fun building some stunning environments and I'll see you soon. Bye."}],"09_MaterialOverview":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hi, welcome back and thank you for your interest in learning more about world building for virtual production. In this lesson, we'll be quickly getting an overview of parent and instance materials. So let's get right into it. To display it, you can find a few steps you can follow for the development of a very basic material setup. But let's dive directly into the engine and review a parent material together with its material instance."},{"start":"0:30","end":"1:01","startSec":31.0,"text":"All right, so we're in our original map. But to keep things simple, I'm just gonna go under file and new level and create a very basic level. All right, down here, we're not gonna use the player start. So I'm just gonna click on it and delete it. And then I want to add from the quick add menu, a very simple cube. So I'll navigate to shapes and cube. All right, then I want to zero out the location down here in the details panel."},{"start":"1:01","end":"1:36","startSec":61.4,"text":"And I want to swap out this cube with a preview mesh, preview material zero one mesh, which is typically used to preview materials. All right, now we want to assign a different material to this preview mesh. And I already have something in mind. So I'm gonna make sure to have the highest folder in our project here key selected. And then I'm gonna search for MI for material instance on the score floor. Now a material instance is a child of a parent material that lets you change specific parameters"},{"start":"1:36","end":"2:10","startSec":96.3,"text":"without creating an entirely new material. And we'll open it up in just a second. So you understand what I mean, using material instances saves performance because our engine just needs to compile the parent materials shader once and all its instances can share that compiled the shader code and just swap out the parameters values in real time. So let's assign this specific material to our preview mesh by clicking it in the content browser and then drag and dropping it on top of the preview mesh. Now if we navigate again into a details panel down here into the element zero, you will"},{"start":"2:10","end":"2:41","startSec":130.7,"text":"find the MI floor assigned. So if we double click on the thumbnail, we'll be able to open this material instance up. You can see that we have a few parameters here that we can play around with. And if we click on them, it will be activated. These parameters are values that we have consciously exposed in the parent material to have them accessible in each instance of it. So if we wanted to up here, we could for example, change the color. And if I undo this material instance and then start changing the color right here, you can"},{"start":"2:41","end":"3:12","startSec":161.9,"text":"see that these changes are happening in real time. OK, now let's scroll a little bit down here and we can find the parent material connected to this instance. So if we double click again on this thumbnail, we will be able to open up the parent material. So let's just talk both of them back into our workspace and navigate to M underscore backing, which is the parent material. OK, if we zoom into the material graph, you can see that we have the base color, the metallic and the roughness exposed as parameters."},{"start":"3:13","end":"3:44","startSec":193.1,"text":"Let's try to add a texture to our preview mesh. So if I right click in an empty area of the graph and then search for texture, you will see up here already selected the texture sample. So let's click on it to create a texture sample node. And then we want to be able to expose it to our material instance. So I'm just going to right click on it and then convert to parameter. We can call this parameter main texture, and I'm going to connect the RGB to the base color of our material."},{"start":"3:44","end":"4:15","startSec":224.9,"text":"Now, Unreal is going to complain because we haven't assigned any texture to our texture sample. So if we select the node and then scroll down here, we can find a main texture slot and I'm just going to add to it the icon green. Now let's save these changes and apply. Now if we go back to our material instance and then open up the global texture parameter values, you will find our main texture parameter here exposed. If we enable it, we will be able to change it on the fly."},{"start":"4:15","end":"4:45","startSec":255.1,"text":"So if we end up this window again, and we navigate to our level, you will be able to find this main texture, apply to our preview mesh. And if we change it to something else, like the analog hat, then it will change to this bullseye directly. So I know this little demo was short, but I hope it helped giving you an overall idea of what materials are and how to use them. Let's switch back to the slides and take a look at how we can best use the material instances to our advantage in a project."},{"start":"4:45","end":"5:18","startSec":285.4,"text":"All right, so we mentioned already that material instances are really useful to save memory overhead and performance. But keep in mind that if all the texturing and shading of a whole environment were to originate from one single master material, and then there were like 1000 material instances assigned to each element of this environment, then your GPU performance will still be quite impacted. For this reason, it's a good practice to create different parent materials for different kinds of surfaces like rocks, trees, water, and so on."},{"start":"5:18","end":"5:52","startSec":318.6,"text":"And then create instances of those different categories of surfaces directly. This way, you'll still be using material instances in your project that will keep your VRAM in place. All right, that was it for this class. I hope you had a good time. Thank you to Sean Spitzer for the creation of this course. You can find some additional documentation at this link if you're interested in further expanding your knowledge in physically based materials or materials overall. I'd also encourage you to take a look at our courses focused on materials on our platform,"},{"start":"5:52","end":"6:02","startSec":352.1,"text":"because they will dive into this concept in better details. Thank you for sticking around, and in the upcoming lesson, we will look into the foliage tool. I'll see you there. Bye."}],"10_FoliageQuickTake":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hi, welcome back. Our goal for this class is to learn to use the foliage tool to populate our worlds in a short amount of time. So let's get started. The foliage mode is a tool that allows you to quickly add lots of objects like trees, bushes, rocks, or even cubes if you wanted to, to your scene by simply painting them in. Instead of placing hundreds and hundreds of single objects one by one, you can just paint"},{"start":"0:30","end":"1:02","startSec":30.8,"text":"them in. The foliage tool is incredibly optimized for rendering large number of objects. It uses instance rendering, meaning that our GPU will draw a lot of copies of the same mesh in a single draw call rather than processing each one of them individually. Unreal environment artists commonly use the foliage tool to fill large areas with natural details like vegetation or small rocks. However, for hero assets that we will see up close, it's better to place those manually"},{"start":"1:02","end":"1:35","startSec":62.5,"text":"for precise control. The foliage mode is absolutely perfect for background decoration, but placing assets by hand is still best if you have specific compositions in mind. So let's jump into the engine and see this tool in action. So first of all, let's create a quick landscape we can paint the foliage on. I'm going to switch from selection mode to landscape. Then down here, I just want to set the scale to 100, the section size to seven by seven quads, so the smaller and the rest of it is all right as it is."},{"start":"1:35","end":"2:06","startSec":95.6,"text":"And then we can click on create. Okay, now from landscape mode up here, let's switch to foliage mode. Up here on our toolbar, we will find a few tools which will allow us to differently interact with our painted foliage. But by default, we're painting. Well actually right now we wouldn't be able to paint anything because we have not specified which assets we'd like to paint with. But if we click on this button plus foliage, we can see that we have a few assets already prepared at our disposal."},{"start":"2:06","end":"2:41","startSec":126.5,"text":"So we can click all three of them. One, two, and three. And their checkboxes will be ticked automatically. This means that right now we would be painting with all the three assets. But we could also just toggle one of them off if we wanted to just isolate the painting with those two. So if we hover over on landscape now, you will see this purple selection bulb. And if we click anywhere, we will be able to paint our foliage, which is incredibly satisfying. Now if we're not happy with whatever we painted, we can press shift on our keyboard and we would"},{"start":"2:41","end":"3:13","startSec":161.4,"text":"be switching directly into the erase tool. And then we can click anywhere we want to erase our foliage. Now if we wanted to, we could also select each individual foliage asset we have painted and then move it around. We could also select all of them or deselect all of them. We have a few other tools here at our disposal, but we won't get into them right now. Now if we select any of our foliage assets, a few settings down here will be displayed."},{"start":"3:13","end":"3:47","startSec":193.6,"text":"You would be able to change the mesh that we want to be painting with this foliage asset, the density, so how much of it we want to paint with a single brush stroke, the radius, the scale and more. And if you wanted to, you could also select multiple assets at once and then apply those changes to all of them. There is something I want to change down here and that's the mobility of our foliage. Right now it's set to static, but we actually want to switch it to movable. This way we'll make sure our foliage receives accurate indirect lighting and contributes"},{"start":"3:47","end":"4:18","startSec":227.8,"text":"to the scene global illumination. If we left the foliage too static with Lumen enabled, we could see some artifacts, so make sure you switch the mobility to movable. Now for foliage or translucent objects, Lumen can still struggle a little bit, especially when they're placed in front of other translucent or objects that are highly emissive. So make sure not to overlap them too much with other translucent objects, like the clouds for example, because you might see some artifacts."},{"start":"4:18","end":"4:48","startSec":258.6,"text":"So unfortunately we won't dive any deeper than this into the foliage today, but you can find some designated classes explaining how to use it on our educational platform. So I'd encourage you to check them out if you're interested in learning more about it. Now one last thing I wanted to mention is that if you're working in a pretty heavy environment, you can also convert the specific foliage assets to Nanite. So if we scroll up here, then select one asset, we can find the mesh that is assigned to it,"},{"start":"4:48","end":"5:19","startSec":288.6,"text":"and then navigate to it in the content browser. Now down here, if you right click on this specific asset, we can find up here Nanite, and right now it's already enabled. But this is something that you can check out if your performance start being impacted with the amount of foliage you have added to your scene. So I hope this little demo gave you an overall idea of how to work in foliage mode. Let's switch back to the slides now to conclude this video. Alright, that was it for this class, and at this link you can find other extensive documentation"},{"start":"5:19","end":"5:30","startSec":319.1,"text":"and resources to learn more tips on adding foliage to your environment. In the next lesson, we will take a look at profiling in Unreal Engine. Have fun building your environments, and I'll see you soon. Bye!"}],"11_ProfilingQuickTake":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Hi, in this class, we'll be learning some basics of performance profiling in Unreal Engine. This will help us optimize our world building workflows and find performance bottlenecks in our scene. Now before we get started, I just wanted to point out that this class aims to only give you a very quick overview of the profiling tunes in Unreal Engine. We won't dive too deep today into this topic because we already have some courses specialized and dedicated to it."},{"start":"0:31","end":"1:02","startSec":31.4,"text":"So if you want to get down to the nitty-gritty details of profiling in Unreal, I'd encourage you to also check those out. So what we mean by profiling is analyzing our projects used of system resources like CPU, GPU processing, memory usage, or network bandwidth. In Unreal, we have two main tools at our disposal to do that, the stat commands and Unreal Insights. The stat commands are console commands we can type into the command prompt of our editor"},{"start":"1:02","end":"1:34","startSec":62.3,"text":"and will display real-time performance information on our viewport, like how much memory we're using, GPU and CPU load, and more. There are a ton of stat commands we can type into the log, but today we're going to be focusing on stat GPU profiling only. Unreal Insights on the other hand helps find performance bottlenecks in our project by showing us what's slowing things down, and is much more complete and detailed than the profile GPU stat command. So let's check out these couple of tools directly into the Engine."},{"start":"1:34","end":"2:09","startSec":94.8,"text":"Okay, we're into the assembly small map of the project that comes together with this course. Let's first start reviewing the stat GPU command. So if we go down here, you will find the enter console command prompt. And if we type stat GPU and then press enter, Unreal will display the GPU statistics of whatever we have in frame on our viewport. So if we move the camera around, you'll see this number changing slowly. This tool is quite useful in a virtual production setting, because if your scene is running at"},{"start":"2:09","end":"2:41","startSec":129.2,"text":"a low frame rate, you can easily identify what might be causing those frame drops. The queue total number you see up here represents the time the GPU spends waiting for commands to be processed in its render queue. So if you see a really high number up here in a virtual production scene, this could be causing latency issues. So be mindful of that. To stop the stat GPU command, you would just need to go down here into the console command. And then if you press the up arrow, you will find the recently entered commands. So you can just select the first one and then press enter again."},{"start":"2:41","end":"3:13","startSec":161.7,"text":"OK, next we will take a look at Unreal Insights. And that's found down here under trace and clicking on Unreal Insights session browser. It will open directly into the trace store window where we will find a log of all the traces we performed in our session. As you can see, I have performed a few ones when preparing this class. But if we wanted to start a new tracing session, we could just click in this button down here and Unreal will start tracing in the background. And it will tell us trace started."},{"start":"3:13","end":"3:46","startSec":193.4,"text":"It's also a good idea to just move the camera around and focus on different areas of our scene to get a complete performance analysis of our map. Also zooming out and just viewing all the meshes we have down here might be a good idea. Now in simple words, a tracing session will capture detailed performance data about our map. It creates basically a detailed log of everything happening under the hood that we simply can playback and analyze to find performance problems. OK, so if we wanted to stop the tracing session, we could just click on this red button down"},{"start":"3:46","end":"4:16","startSec":226.4,"text":"here and this will stop tracing. Now if we open up again the Unreal Insights session browser, we will find a new log down here. And if we simply double click on it, we will be able to open it up. So in this timing insights window, we will be able to analyze all the collected performance data in milliseconds. What we're looking for if we pan with left click is actually areas of this log where Unreal Engine sold a little bit. You can see here that we have a high bar."},{"start":"4:16","end":"4:47","startSec":256.7,"text":"So this means that anything that was calculated here was probably pretty heavy. And if I just zoom into it with my mouse wheel, I can actually just click on this high bar and it's going to give me some further details. Down here I can find the single processes of the GPU and the CPU. And then here on the right, I can analyze the single elements and how long it took on real to compute them. We can also isolate the CPU and the GPU processes individually."},{"start":"4:47","end":"5:20","startSec":287.7,"text":"And up here we could also just toggle on and off different windows. OK, I hope this brief introduction helps you getting a better understanding of profiling performance in Unreal. And now let's go back to the slides to conclude this video. So that was it for this class. But at this link you can find other extensive documentation and resources to learn more about performance profiling, bad commands, and the Unreal Engine set-stool in Unreal Engine. Unfortunately, we're almost at the end of this entire series of classes on world building"},{"start":"5:20","end":"5:35","startSec":320.5,"text":"for virtual production. We won't be diving into demos or theories any further. But in the upcoming lesson, we will do a recap on everything we've learned so far and say are goodbyes. Thank you very much for sticking around. And I'll see you there. Bye."}],"12_Outro":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"You've made it to the end of this course on world building for virtual production. Congratulations! And thank you for being part of this class. Let's take a moment to review what we learned in the past lessons. First of all, we learned about the concept of derived data cache and how Unreal makes use of it. We explored workflows to assess scope when developing our environments for virtual production and reviewed how to import external assets into our seeds. Further on, we also got a quick overview on basic lighting, editing assets, materials,"},{"start":"0:36","end":"1:06","startSec":36.0,"text":"foliage, and profiling. Lots of small bytes of information there, but hopefully they helped you get an overall idea over where things are in the engine and how to use them. Thank you again for sticking around. I really hope you enjoyed this course and learned a few tricks from it. You're welcome to take a look at the other courses on our platform. Prefer to expand your understanding of the engine. Now I wish you lots of fun building some crazy worlds in Unreal that I can't wait to see and I'll see you soon. Bye!"}]},"227.02":{"01_IntroCourseOutline":[{"start":"0:00","end":"0:41","startSec":0.0,"text":"Greetings everybody, my name is Sam Dider and I'm a senior Unreal Engine instructor with Epic Games. In the following video tutorial series, we're going to take a look at creating user interfaces using UMG and Blueprints. We're going to do this by first taking an overview look at Blueprints to make sure that everyone who's following this video tutorial series understands some basic Blueprint concepts that we'll be using throughout this project. We're then going to take a look at Unreal Motion Graphics or UMG to familiarize ourselves with the editor and what it's used for so that when we use it in our workshop, it'll make a little more sense."},{"start":"0:42","end":"1:17","startSec":42.0,"text":"Speaking of our workshop, what we're going to be doing after we go over our Blueprint overview and the overview of UMG is we're going to be using the vehicle template to create a game that involves pickups and writing things to the HUD, as well as a menu system so that we will complete a complete game loop including a start level with a clickable UI that allows us to start the game. Once we're inside the game, we'll update our UI so that we can see things like time as well as score and all of the various components that we'll need to make in order for this to happen."},{"start":"1:17","end":"1:24","startSec":77.0,"text":"So we've got a lot in store for this video tutorial series and let's now start with our Blueprint overview."}],"02_BlueprintOverview":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Before we go further, I'd like for us to have a quick blueprint overview so that we can make sure that everyone understands a few of the blueprint concepts we're going to be making heavy use of inside of our example. Now the first one is understanding blueprint flow. Now this is a term that's used to describe how the blueprint graph goes from left to right, just like you read in English. So no matter what we're doing, we're always going to be starting at the left hand side. So we'll start here, and then we will go to the right, process"},{"start":"0:32","end":"1:07","startSec":32.6,"text":"our output, and then we will be able to choose something here at the end. But it's very important to understand this because this is going to happen a lot inside of our projects. Now there are some nodes that we will be looking at using as well as some additional nodes here that I just want to call out. But first off is the node I want to talk about here is the branch. And the branch allows us to do things on a true or a false. And this is unreal. If then node. So if something is true, we're going to do this. If something is false, we're going to do this. Notice the condition"},{"start":"1:07","end":"1:40","startSec":67.8,"text":"here, this allows us to tie this to a variable. So we can have a bunch of different variables, one that looks for something like, you know, the player has the key. And if they do, then we will open the door. If not, we'll give them a message that says, you know, you don't have the key. There's a lot of things that we can do with this one simple branch node, in terms of flow controller, how our project is going to progress from one area to another. Next, we have a flip flop. So the flip flop allows us to have something input here. And then what's going to happen is it's going to go"},{"start":"1:40","end":"2:12","startSec":100.0,"text":"a and then B, and it's going to repeat this behavior for the entire way the project is running. So I like these because we can put these on a button. And if we click the button, it's going to do something like turn on the light. And then if we click it again, it will turn off the light without us having to develop a really complicated trigger to you know, is it been turned on? Yes, then we reset something. This is just really did we turn it on? Toggle a, did we toggle again, then toggle B? After that, we have a sequence. Now a sequence allows us to execute a sequence"},{"start":"2:12","end":"2:46","startSec":132.5,"text":"of events based off of an input. If we want, we can use this add pin here to add more than inputs, or I should say then outputs and fire off as many things as we want. Next to that, we have a switch on int. This allows us to add again, additional outputs here, but instead of just firing them off in succession, this like the sequence node, this allows us to enter an integer here that will execute that particular output that we have. So if we put a zero, it's going to do"},{"start":"2:46","end":"3:18","startSec":166.4,"text":"default. If we were to add a pen here and do one, it will do the next one to the next one, and so on, and so on. Last but not least, we have gate and multi gate net. While we won't be making use of these nodes in this project, it's just something I wanted to call out, because these do allow us to do some very complex flow control gates allow us to do actually execution based conditional checks so we can check for have things been entered into or states and things of that"},{"start":"3:18","end":"3:53","startSec":198.6,"text":"nature using these. And again, while we don't necessarily utilize them in this particular tutorial, it is good to know about them. Now, this slide deals with time control, because flow control is again, how our project is going to deal with data time control is how our project is going to be dealing with times and turn off things like maybe a countdown for a level, or maybe you're keeping time to do a time trial or some other nature, but time control is very important. And the first"},{"start":"3:53","end":"4:27","startSec":233.2,"text":"thing that we can do to control time with our delays. Now, there is a delay, a delay in delay until the next tick and a retrogable delay. Now, while delays are great when you're prototyping, the problem with any of these delays is that once you have started the delay, there is no way to stop it or restart it or go around it. A delay, if you say, let me put a delay in the five seconds, there is no way to stop that delay from happening, you have to wait for the full five seconds, so"},{"start":"4:27","end":"5:00","startSec":267.2,"text":"you can't say interrupt it. Now, if you want something that you could interrupt or something that's just a lot easier to keep time with, there are actual two nodes called set timer by event and set timer by function name, but we're actually going to be utilizing these in our code here to create a timer for our example in a little bit. But these timer nodes are really cool because you can set multiple timers for whatever you need. And then anywhere through blueprint, you can actually call the timer and stop it or start it. So they're extremely useful."},{"start":"5:01","end":"5:36","startSec":301.0,"text":"The last thing that I want to talk about is a timeline. So a timeline allows us to animate between two values. So let's say we wanted to go between zero and one, we can use a timeline to animate that going from zero to one. The last thing that I want to talk about here is with a delay, just a little pro tip. If you set the duration down here to zero, that's actually going to give you a one frame delay. And that's actually one of the best use cases for a delay is if you"},{"start":"5:36","end":"5:57","startSec":336.6,"text":"are trying to act as a single frame delay, you can set it to point zero, and it will act as a single frame delay. And this is great if you need to slow spawning down or delay something just by a single frame until something else happens. This can be a really great way to do that inside of blueprints."}],"03_UnrealMotionGraphics":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Now that we've gone over Blueprints, we're next going to take a look really quickly at Unreal Motion Graphics or UMG to understand more about what it is as we're going to be using this tool with the accompanying workshop. So what is UMG? Well UMG or Unreal Motion Graphics is a visual UI authoring tool that can be used to create UI elements such as in-game HUDs, menus, or other interface related graphics you wish to present to your users."},{"start":"0:31","end":"1:02","startSec":31.7,"text":"You can use UMG to create menus, full screens, or pop-ups, HUDs, and even 3D displays. Right here is an image of the UMG editor and the editor itself is actually broken up into a couple of different tools. There's two different tools. There's the designer which we see right here. The designer is broken up into the following little areas here. Over one, we have the palette. This is where we're going to find all of the pre-built UI elements that we want to work with."},{"start":"1:02","end":"1:36","startSec":62.7,"text":"So the great thing about this is that we can pull in something like a generic button and either use the existing imagery or bring in all of our own imagery. This is really handy because we don't actually have to worry about building code to make a button. We simply just bring in different common UI elements like buttons and images and sliders and things like that. And then we can use those to do things in our UI. Underneath our palette here, we have our hierarchy which is going to show us the hierarchy"},{"start":"1:36","end":"2:07","startSec":96.6,"text":"of this UI. So if we have a bunch of buttons here, it will show us the buttons. And if we have things nested underneath those buttons, it will show us what those items are. In the middle, this is going to be our UI preview area. What we do with our UMG widgets is we bring these common elements in to three right here and then we can place them around the scene in order to make them more in line with our UI needs."},{"start":"2:07","end":"2:39","startSec":127.3,"text":"Finally, or I shouldn't say finally, but next we have four, which is our details panel. The details panel is context sensitive. So that means that based on what we have selected, the details inside of here are going to be different. But this is how we modify the properties of these common elements that we put inside of our UI right here. Last but not least is number five, which is our animations. This allows us to animate objects. So if I was to click on this, we'd get a little animation window coming up."},{"start":"2:39","end":"3:11","startSec":159.8,"text":"And while we're not going to be utilizing this in today's tutorial, it is nice to know that we can fully animate all of our UI elements, their positions, but we can also animate their visibility or we can make them fly up and then get bigger or smaller. Lots of cool things that we can do with that. Now the second part of our tool is called the graph. So I like to refer to them like this. The designer is how we make our UI pretty. The graph is how we make our UI functional."},{"start":"3:11","end":"3:44","startSec":191.5,"text":"If you notice that this actually looks very similar to a blueprint, and that's because you are actually using blueprints to build your UI. So over here under the my blueprint, this is we're going to find different functions that we have built or right now we're seeing preexisting functions in there. Or we can also override and add variables and things like that. Two is our details panel. And again, this is context sensitive. So based on what we have selected, the details is going to be different. And then three is our event graph. This is going to work exactly the same like the event graph does inside of blueprints."},{"start":"3:44","end":"4:16","startSec":224.8,"text":"We're going to put down various nodes inside of here. And then based off of the events that happen when those nodes are clicked on, we will then do things. So for example, if we were to be inside of our, I'm going to click back to our designer here. Inside of our designer, we could put something like a button here. And then on that button, we're going to have a little behavior that says on clicked. And when we press that, we'll see that inside of our event graph here, we'll have a little on clicked that will allow us to then execute some code. So this might look overwhelming or a little daunting."},{"start":"4:16","end":"4:27","startSec":256.9,"text":"Do not worry. You're going to see how easy these tools are to use and how much blueprints and UMG all have together. And our workshop, which are going to start right after this slide."}],"04_WorkshopPart1":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"With the UMG overview and blueprint overview now out of the way, we are ready to get started with our workshop. Now our workshop is going to have the following goals. It is to create a simple driving game, implement a game time limit, build a reusable pickup object and then create UMG display and menus. So to do this, what we're first going to do is we are going to select a from the Unreal project browser, select the games template and we're going to select vehicle."},{"start":"0:30","end":"1:00","startSec":30.2,"text":"Make sure the variant is set to none and then we can do something like blueprint UMI UMG. Let's go ahead and just pop over here. So again, we're coming to our games project here vehicle, no variant and we're just going to call this like BP U I UMG. There we go. And then I'm going to hit create to create this. And once that gets created, the first thing that we're going to do is we're going to go to our vehicle template blueprints and we're going to look for this BP GM vehicle base."},{"start":"1:00","end":"1:31","startSec":60.7,"text":"This is going to the GM stands for game mode and we always want to make sure that whenever we are building stuff, we're building it in the right area. So game modes are rules that your game will follow. So if we were building a tag, we would put the rules for tag inside of our game mode. So for us, what we're going to be doing is once we open up this game mode, we're going to be using this to build our countdown timer. And this is just good blueprint usage."},{"start":"1:31","end":"2:02","startSec":91.1,"text":"So let me pull our project over here. So again, here's our project. So it should be something like this where we press play. We've got a car is going to go around the circle. So that's fantastic. We're going to come up to our content browser. So I hit control space to bring that up and go to our vehicle template blueprint and we want our BP GM vehicle basic. Now when that opens up, we aren't actually going to see anything. We're just going to see our game session and things like that. What we want to do here is we want to open in full blueprint editor."},{"start":"2:02","end":"2:34","startSec":122.0,"text":"And what that's going to do is that's going to turn that from a data only blueprint into a blueprint that we can edit. Now with that blueprint editable, we are going to create a timer. So what we're going to do is we're going to add an event begin play notes. So when we start our game, we're going to first create a timer and we're going to set it to a time of one second and we're going to have this loop. And this is basically going to be creating our looping timer. So as it goes from, you know, whatever 10 down to zero, this is going to help do that."},{"start":"2:34","end":"3:07","startSec":154.1,"text":"So let's pop back over here to the editor now. So again, we're going to right click and we're going to look for event begin and we want this event begin play. Yep. Event begin play. And when we do that, actually, I'm not going to pull off that just yet because I'm going to click in here and look for set timer by and we want this set timer by event. Now we're going to connect these two together. And with the time we're going to set this to one and we're going to keep this on looping."},{"start":"3:07","end":"3:41","startSec":187.3,"text":"Now the next thing that we need to do is we need to make a custom event. So we're going to look for a custom and then there's our add custom event. And we're going to call it countdown. I'm going to take that and bring that right over here. Now if we were to like do something like this, do a print string, then we go compile and save, we should get something. And yes, he's saying hello there. So that's definitely working. And we can see here just to verify if we go here to this game vehicle spawn, we should"},{"start":"3:41","end":"4:13","startSec":221.1,"text":"see this counting down. Every second just printing out hello. So that's what we should be having right there. We could see that working. So that's that's good start for us. So I'm going to go ahead and delete that because it is not needed. But the next thing that we're going to do here is we are going to create a new variable called time remaining. We're going to set it to an integer. The reason we set it to an integer is because our time is going to be, you know, one, two, three. We're not necessarily going to have 30.5 seconds or 30.26 seconds."},{"start":"4:13","end":"4:44","startSec":253.2,"text":"So anywhere where we know that we're going to be using integers versus floats, we want to make sure that we make a variable type that will work with that data appropriately. So you maybe you're used to just using all floats. That's not the best thing to do. The best thing in our case to do is to make that an integer because again, we know that we're not going to have any half seconds or quarter seconds. It's going to be 10 seconds or 15 seconds. So let's go over to our editor now. We're going to come over to our variables."},{"start":"4:44","end":"5:17","startSec":284.6,"text":"We're going to add a new one. We're going to call it time remaining and we are going to set it to an integer. There we go. And let's just compile this and save. Now every time we add a variable, we always need to compile in order to give that variable a default value. So there we go. We're going to set this to 10 and let's just compile and save that again. So what we're going to do next is we're going to pull in that time remaining and then we're going to use this integer decrement."},{"start":"5:17","end":"5:49","startSec":317.6,"text":"And basically we're going to check to see when the time remaining is less than zero. We're going to do something. If it's not less than zero, we're going to continue to do what we're doing right now, which is nothing. So let's go ahead and set this up. So we're going to come over here and then we're going to take our time remaining and we're going to left click and drag and we're going to go get time remaining. And then we're going to pull off of this countdown custom event and we're going to go minus minus"},{"start":"5:49","end":"6:22","startSec":349.8,"text":"and this is going to get our we have a float here, but we want the integer. So we're going to say decrement int. And then we're going to plug our to like so. Then what we're going to do is we're going to pull off of our results here and we're going to look for less than. And then last, we're going to get a branch. Now we can add this branch a couple of different ways. We can pull out of here and look for a branch."},{"start":"6:22","end":"6:49","startSec":382.6,"text":"Here's the branch right there. Or if you want, you can hold down the B key and you will add a branch as well. That's usually the way that I add branches by holding down the B key. So that is going to make up the first part of this. And now what we're going to do in the next section is we're going to take a look at blueprint interfaces as they are a great way to cheaply and efficiently send data back and forth between multiple blueprints."}],"05_WorkshopPart2":[{"start":"0:00","end":"0:29","startSec":0.0,"text":"Blueprint interfaces are a way to efficiently communicate with various blueprints throughout your project without having to load the entire blueprint into memory. Now with our particular project, it's relatively small. So this introduction to blueprint interfaces is to do just that and to introduce you to blueprint interfaces because as your project grows in complexity, these are going to be"},{"start":"0:30","end":"1:03","startSec":30.9,"text":"very, very important to your project's success. So to create them, what we do is we come over to the content browser and we right click and we look for the blueprint category and then we select our interface. Inside the interface, it's going to look very familiar to a blueprint graph, but the big difference is that it's going to say read only across the top here and we're only going to be able to actually add inputs and outputs. But for our case, what we're going to be doing is we're going to create a new blueprint interface and we are going to add two inputs to it, a score and a time."},{"start":"1:03","end":"1:35","startSec":63.8,"text":"And that way we can more easily pass these values around to our interface and our car and things like that. So let's pop over to the editor and do this right now. So I'm actually going to close this. I'm going to hit control space and I'm going to navigate up to our content folder. Right click. We're going to go to blueprint and add a blueprint interface. Now I like to call mine BPI for blueprint interface. We're to call this think vehicle. All right. And then let's double click on it to open it up."},{"start":"1:37","end":"2:08","startSec":97.6,"text":"Now, once you have it open, we have a new function. So we're going to right click on this and rename it to. Hicked up objects. And then what we're going to do is under our inputs, we're going to add one and two. And we're going to call this one score. We're going to call the other one time. We also need to change these from Booleans to integer values."},{"start":"2:08","end":"2:38","startSec":128.2,"text":"So there we go. Both sets integers. And once we're done, we do need to compile and save. What we need to do after that is we need to assign this blueprint interface to the blueprint we wish to work with. In our case, that's going to be the BP P sports car. So what we're going to do is we're going to come back over here to the editor. We're going to hit control space."},{"start":"2:38","end":"3:09","startSec":158.6,"text":"We're going to go look for our blueprints and then we're going to go sports car. And there's our BP P sports car. So that's the one that we want right there. We double click on it to open it up. And to add a interface, we come over to our class settings and then under our interfaces, you can see we have this implemented interfaces. Right now we have no interfaces. So what we're going to do is we're going to go to add and then from the search, we're going to type in BP I and that's going to bring everything down a little bit easier for us to navigate."},{"start":"3:09","end":"3:39","startSec":189.6,"text":"And there's our BP I vehicle. So we're going to click on that and compile and save. Now, once we've done that, we are going to now create the following bit of code. So what we're going to do is event picked up objects. We're going to get the current score. We're going to set the current score. And then we're going to cast to our game mode to get the time remaining and then set the time remaining. And this is going to set up the logic for us to work with our pickups."},{"start":"3:39","end":"4:13","startSec":219.6,"text":"So to do this, what we're going to do here. As we're going to come over to our BP sports car, we do need to add some variables. So we're going to add one and two. And this first one, we're going to right click and we're going to rename this one to current score. And actually, we don't need the second one right now. We're actually just going to delete that. So also need to change our current score to a integer and compile and save"},{"start":"4:13","end":"4:46","startSec":253.9,"text":"so that we can use it. So let's go ahead and just move somewhere off to the side here. And what we're going to do now is we're going to look for our event picked up. And there we go. Event picked up objects. And what are we going to do with this? Well, for our, we need to get our current score. So we're going to grab this and we're going to go get because we want to get the current value of that. So let's set up our score and then our time. So we're going to take our score. We're going to hit the plus sign here. I'm going to go, you tell these operators add, we're going to add these two together."},{"start":"4:46","end":"5:17","startSec":286.8,"text":"All right. So we want to take our current, our score from the pick up here, and then we want to add that to our current score. And then what we want to do is we want to take our current score. We're going to bring this out again and we're going to go. Set current score. And what we're basically going to be doing is incrementing our score. So as our score updates, we're going to take our current score. We're going to add that to our score value that comes in here and then update our current score again. So basically we're going to iterate on our current score."},{"start":"5:17","end":"5:53","startSec":317.3,"text":"And we're going to do something similar with the time remaining. So we're going to get game mode because I remember our time is set up inside of our game. But we could have set the time up in here, but it's better to set the time up inside of the game mode. And again, remember our game is very small. This is just good practice for how things should be built inside of blueprints as your projects grow longer. So what we're going to do here is from this return value, we are going to cast, not cast, but cast to BPGM Vehicle Basic."},{"start":"5:57","end":"6:28","startSec":357.7,"text":"There we go. And we're also going to right click on this and convert this to a pure cast. Now the difference is that basically pure cast is assuming that we know exactly what we're doing and the values that we are getting. It's not going to involve any error checking. So we're going to right click on this, convert to a pure cast. And then what we're going to do here is we are going to go time and we are going to get the time remaining. So there we go. And then from our time here, what we're going to do is we're going to hit the plus sign."},{"start":"6:28","end":"6:58","startSec":388.4,"text":"So we have an ad operation. And basically, again, we're going to do something very similar here. I'm going to actually double click on this line to add what's known as a redirector to make this a little bit easier for us to see. But we're going to take our from our game mode, we are going to get our time remaining and then we're going to take what the time remaining is. And we are going to add that to the time that comes in from our pickup. And then what we're going to do here is we are going to pull off of this set. And we might be able to get this set time."},{"start":"6:58","end":"7:29","startSec":418.7,"text":"Nope. What we're going to have to do is pull off of here. So we're going to pull off of this and we're going to go a set time. And there we go. Set time remaining is the value that we are looking for. And what we want to do here is we want to grab from this set and plug in like so. And then we want to take the output of this addition and plug this in. And I'm also going to double click on these lines to clear this up. So for some reason, we have this extra node here. So let's just move that out of the way. So there we go. That is what we're looking at."},{"start":"7:29","end":"7:44","startSec":449.7,"text":"Now, if you need a second or two to get caught up, we're going to pause right here now before we go into the next part. Which is a score and time pickup. So this is all we have for this part. And when you are done, you should have something that looks like this."}],"06_WorkshopPart3":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"All right, so now we're going to look at creating the score and time pickup. This is going to act as the object that we place inside of the world that the user will run into and then fire off the different variables or values that we want for our score and our time. And to do this, what we're going to do is we're first going to create a new blueprint based off of Actor. So let's pop over to the editor now. We can close whatever blueprints we have open. We're going to hit control space and then we're going to navigate up to our content"},{"start":"0:31","end":"1:06","startSec":31.8,"text":"folder. I'm going to right click and go blueprint class. And then from the pick parent class, we're going to select our actor and we're going to call this one BP underscore pickup. Now, once we've done that, we're going to go ahead and double click on it to open it up. And we're going to need to do a few things to this. So first off, we're going to need to put two things on this. We're going to need to put a sphere collision and some type of static mesh. And the things are going to work like this. The sphere collision is what we're going to use to notify our system when the user has"},{"start":"1:06","end":"1:35","startSec":66.1,"text":"actually collided with this. And the static mesh is going to represent a visual representation of that. So we have something to look at in the world. So let's go ahead and set that up now. So inside of our pickup, let's go add. We're going to look for a SPH and we want the sphere collision. I'm also going to make sure I have it selected when it's added and change its radius here to 96. And the other thing that I'm going to do is I'm going to add a cube right here."},{"start":"1:36","end":"2:06","startSec":96.4,"text":"And that's just going to add a static mesh. It's the same as adding a static mesh. This just does it in one step for us. So the next thing that we're going to be doing is we're going to take our sphere here. And one of the cool things about many of the objects that you add inside of blueprints is if you select them and then you go over to the details panel under events, you're going to find a whole bunch of different events that you can use to interact with this. And the event that we want is this on component begin overlap of our sphere collision."},{"start":"2:06","end":"2:40","startSec":126.5,"text":"So let's go over to the editor again, select our sphere collision and the details panel. We're going to come all the way down to the bottom and we're going to look for our on component begin overlap. I'm going to press this plus right here. And what that's going to do is it's going to bring us over to the event graph and boom, right there we have our on component begin overlap sphere. Now the next part of this involves us setting up an interface check and then a branch condition"},{"start":"2:40","end":"3:15","startSec":160.7,"text":"as well as creating some variables. So let's take a look at our logic before we set everything up. What we're going to basically doing is when we overlap this, we are going to look at the other actor. So what actor overlap this does that actor implement our vehicle interface or BPI vehicle interface using the branch condition. If it does, then we are going to add a score and a time to our blueprint interface, which is going to signal our code that we should increment our time and our score."},{"start":"3:15","end":"3:46","startSec":195.4,"text":"So let's do this in the editor now. So what we're going to do is I'm just going to pull my details panel over a little bit. So I have a little more real estate. So we're going to pull off of this and we're going to look for our branch node. It'd help if I spelled that right. So there we go branch. There we go. And then on our other actor, we're going to pull off and we're going to look for does and right there under utilities does implement interface. We're going to under interface select class, we're going to look for our BPI. And there we go. There's our BPI vehicle."},{"start":"3:46","end":"4:16","startSec":226.7,"text":"So that's the interface that we want. And then we want to take the return value and plug that in right here to our condition. Okay. And the next thing that we're going to do is when this is true, we're going to pull off. And we're going to look for picked up. And there we go class BPI vehicle picked up objects message. And now we need to fill in a few things here. The other actor is the target here, right? Because that is the actor that is making that request there."},{"start":"4:16","end":"4:48","startSec":256.9,"text":"So we need to make sure that that is filled in and then our score and our time. Here's a little thing that we can do here. We want to fill these in, but there's two things that we want to do. We want to turn these to variables, but we also want to expose those variables so that they can be modified. So first off, let's right click on these and go promote to variable and then do the same thing for time. So now we have a time and a score. Now to make these variables so that we can modify them when we're placed in the level,"},{"start":"4:48","end":"5:21","startSec":288.2,"text":"all we need to do is make sure that the instance editable option is set, or we click on this little eyeball next to the variables to turn them from private variables into public variables. So let's do that now. We'll select time and then we'll come here and we'll do instance editable and then for score, we can just come over here and press this little eyeball and it does the exact same thing. So if we have both of these selected, we won't be able to do anything. But again, we can select the time and make it instance editable or public by pressing this eyeball,"},{"start":"5:21","end":"5:53","startSec":321.6,"text":"or we can select the score and again, instance editable will make this public. Now once we're done with that, we do need to compile and save. And the next and last thing we're going to do is we're going to add this destroy actor. So what this does is basically once we run into this, it should destroy this or remove it from the world. So let's go ahead and try to add that now. So we're just going to pull off of our picked up objects. We're going to look for destroy and there under actor, we have our destroy actor. So let's just compile and save."},{"start":"5:53","end":"6:23","startSec":353.5,"text":"I'm going to close this. And what should happen now is if I bring up my BP pickup here, we're going to hit run and all the way over there. Now, I'm not going to see any updates, but I should see it disappear. So if you see it disappear, that is what we want. We want it to do that disappearing act for us. That way we can make sure that everything is working. And what you're seeing me do here now, just a little pro tip is I was really far away. I'm going to make it a little easier to test that. Right. So all I did is it just press play."},{"start":"6:24","end":"6:44","startSec":384.1,"text":"When I escaped from play, it brings me back over here to where the play was. So now I'm in that area in the editor and then I just dragged my actor into there to make it a little bit easier. So, all right, that is it for this section. And our next section, we're going to take a look at adding motion graphics and UI to this using UMG or Unreal motion graphics."}],"07_WorkshopPart4":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Now that we have all of the data set up and our pickup disappears, we need to now make sure that we can display that data to our user using Unreal Motion Graphics. So the first thing that we're going to be doing is we are going to be creating a user widget. So we're going to go to our user interface, we're going to select widget blueprint, and then we're going to select the user widget, which will allow us to create a widget blueprint that we can view on our UI."},{"start":"0:30","end":"1:01","startSec":30.4,"text":"So inside of our editor, we're going to hit control space to bring up our content browser, and then I'm just going to do this in my content folder where my pickup and my blueprint interface are currently located and just right click, we're going to go to user interface and widget blueprint. From our pick parent class, we're going to select user widget, and we're going to call this user widget underscore UI, and then I'm going to double click on it to open it up."},{"start":"1:01","end":"1:33","startSec":61.0,"text":"I might open up offscreen, so let me bring that over here. And with our HUD, the first thing we're going to add to it is a canvas panel. Now a canvas panel allows us to have multiple HUD elements. If we don't put a canvas panel on there, whatever element we apply is going to take up the entire widget. So if we were to put just a button, it would be just a button. So let's pop over to the editor now, and we're going to look for our canvas panel. There we go. We're just going to drag and drop that right onto our UI like so."},{"start":"1:33","end":"2:05","startSec":93.5,"text":"So now we have the ability to add multiple things to this UI. So what we're going to be doing is we're going to be adding a score and a text, sorry, a score and a time using text. So this is what we want to add. We want to add these two things, and we're going to add some parameters to them as well. So first off, we're going to come up here to text, and we're going to add that. And we're going to call this first one. We're going to set some things up here. So let's call this score. And we're just going to do zero, zero right now just to give us an idea of the size and"},{"start":"2:05","end":"2:35","startSec":125.1,"text":"everything like that. So let's go to our font here. We're going to set this to 64. And I probably should start from the top, but I wanted to get that size there because I want this size to content enabled. And then what we're going to do is we're going to take our position here and we're going to move this just down a little bit like so. So we'll make these numbers a whole and then we're going to move it over. We'll say something like maybe like 100. There we go. The other thing we're going to do to this is we're going to put an outline on it of"},{"start":"2:35","end":"3:09","startSec":155.4,"text":"say two. This is just going to make it easier to read. So we have our score and then we're going to go right click on that and we're going to say duplicate and it's going to bring it right up there. So right off the bat, we're going to call this one time. There we go. And the other thing we're going to do with this is we're going to come here to the anchor and the anchor defines where this element is anchored on the UI. And this is really important. We'll see in a second here why this is so important. So if you hold down control and you click over here on the far right hand side one,"},{"start":"3:09","end":"3:41","startSec":189.0,"text":"it's going to move that time over there. And the reason this is so important is if I was to drag on this handle here, notice that the score and the time stay in the same location relative to the UI size. So this is great because this means that I can make this UI for one setup and then have it work on a bunch of different resolutions. And I can ensure that that information stays exactly where I want it. So for our time though, it is outside. So we do need to come here to our position and we're going to move this over just a little"},{"start":"3:41","end":"4:13","startSec":221.8,"text":"bit, maybe something like that will do negative like 390 maybe. And then we're going to do the position here. We'll just move this down a little bit. I believe this one was at 70. So we'll do this one at 70 as well. There we go. All right. So we should have our time and our score. And the next thing that we're going to do, so we should have something like this, we're going to create a binding. Now before I make this binding, there's something I want to mention about binding."},{"start":"4:13","end":"4:48","startSec":253.5,"text":"So these are incredibly easy ways to send data to and from your UMG UI elements. But as your project grows in complexity, the more you use bindings, there is a point where you're going to start to encounter a performance issue. There's other ways to get and send data that are a little bit more efficient, but they're outside of the scope of this tutorial. So I just want to point out that while this is a very easy and quick and semi efficient"},{"start":"4:48","end":"5:20","startSec":288.2,"text":"way to interact with text with UMG and data, as your project becomes more heavy, you could encounter an issue in performance by doing this if you have like hundreds of UMG widgets. So just keep this in mind. This is simple and easy, but it does have the drawback that it could introduce some performance issues as your project grows in complexity. So what we're going to do is we're going to come over to our score and then under our content and text, we have this create binding."},{"start":"5:20","end":"5:52","startSec":320.1,"text":"So we are going to create a binding that's going to bring us up a little editor here. And inside of that editor, what we're going to be doing is we're going to do this. We're going to get to the player pond. We're going to cast to our sports car because that's where our current score is. And then we're going to format that text so that we have the score and then the value here, which we will automatically update from the value of our current score in our car. So let's go ahead and do that now. So what we're going to do is we're going to right click and we're going to look for get player pond."},{"start":"5:52","end":"6:23","startSec":352.8,"text":"There we go. And then from our player pond, we're going to cast to BP and we want our BP, P sports car. Now we are going to turn this into a pure cast because we know what we are looking for. So we don't necessarily need to put in any type of error correction or something if this fails because we know that that value is going to be there. So we're going to pull off of this and look for our current score."},{"start":"6:23","end":"6:55","startSec":383.3,"text":"And we are going to get the current score. And then we need to look for another node here just called format. And we want this text format text. And what we're going to do here is go score and then value and make sure that you use the curly brackets. And that's going to give you this value right here input. So we can take that and bring this in like so. So what's going to happen once we get our UI set up for the other thing is when we just"},{"start":"6:55","end":"7:28","startSec":415.5,"text":"compile this and we're going to go back to our designer. So basically when we start the game, when we get some amount of scoring some points, this is going to update right here. So we'll see 10 or 50 or whatever the value happens to be. And for our time, we're going to do something very similar. We're going to create a binding. We're going to cast to our game mode this time as our BP game mode, we're going to get the time remaining. And then we are going to put that into a format text just like we did with the score."},{"start":"7:28","end":"8:05","startSec":448.6,"text":"So let's go over here back to our blueprints. So we're going to go to time and then here create a binding. There we go. And then we're going to get game mode. And then from our game mode, we are going to cast to BP underscore GM vehicle basic. There we go. And we are going to right click and convert to pure cast. And then we're going to pull off of this and we're going to look for the get time remaining."},{"start":"8:05","end":"8:35","startSec":485.3,"text":"All right. And then we also want to format text. And inside of our format text, we want timer and then double brackets value. And then we're going to take our time remaining and bring that into our value right here and then our result into the return value. All right. And let's just straighten that. So that's what we have right there."},{"start":"8:35","end":"9:09","startSec":515.5,"text":"Let's compile and save. Okay. And then what we're going to do next is we're going to go over to our event begin play and we are going to create this user widget and then add it to the viewport. And remember that our what we're going to be accessing. So I'm just going to close off my which is going to come here and we're going to go to our blueprint and we're going to go to our BP GM vehicle basic. Right. And we're going to go off of this event begin play right here because that's we're going"},{"start":"9:09","end":"9:41","startSec":549.0,"text":"to basically load our UI and then start our game. So we're going to pull off of this and we're going to look for create. W ID, there we go. Create widget and then the widget that we want to create is our user widget UI. And then we want to add to view the either we go add to viewport. And what do we want to add to viewport? Well, we want to add this right here."},{"start":"9:41","end":"9:55","startSec":581.7,"text":"All right. So let's compile and save that. And next up, we're going to talk about some testing and then creating further user widgets."}],"08_WorkshopPart5":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Now that we have our UI set up, we need to start doing a little testing to make sure that everything is going to work. So the first thing we're going to do is we're going to pull in our little pickup object and then we're going to set its score and its time so that when we run our project, we have a score and a time set up and working. So let's go ahead and pop over to the engine now. All right, and now I have one already setting here, but if I don't have that, we're going"},{"start":"0:30","end":"1:02","startSec":30.8,"text":"to hit control space and then what we want is we're going to come up to our content and we're going to grab our pickup and we're just going to drop that in here. Now inside the details panel, again, I should have a score and a time. So maybe the score is 100 and the time is 10. And I'm just going to bring this up a little bit. So let's go ahead and hit play. So there's our score and our time and there we go. And it says timer. So maybe I should make that say time. So we'll just do this really quickly. If I come over here to my, there we go, that one right there, get text zero."},{"start":"1:02","end":"1:33","startSec":62.7,"text":"We need to go over to the graph, time. There we go. And then let's just compile and save that. And we're going to close this and then there we go. That looks a little bit better. So all right, that is working how we wanted it. That's looking really, really good. All right, so with our testing now completed and our next part, we're going to be taking a look at creating UMG menu so that we can have a game over menu and some other menus"},{"start":"1:33","end":"1:37","startSec":94.0,"text":"so that we can make a full game loop with this project."}],"09_WorkshopPart6":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Alright, with our UI now showing both our time and our score and our pickup working, what we need to do now is make some menus for what happens when the game ends, as well as a new level and a new menu for when you actually open the project. So when I start, what do we want to have happen? And this way we'll have a full game loop. So the first thing we're going to do is we're going to create a brand new widget blueprint. And we're going to add a canvas panel to it like we did before."},{"start":"0:32","end":"1:06","startSec":32.1,"text":"But this time we're going to add an image to it, make that image expand across the entire canvas panel so that we can add a game over screen like this. So let's go ahead and pop over to the editor now. And we're going to hit control space. And then right here in our content, we're just going to make a new user interface widget blueprint based on a user widget. I'm going to call it user widget underscore game over."},{"start":"1:07","end":"1:39","startSec":67.3,"text":"All right. So let's double click on this to open it up. And first things first, we do need to add a canvas panel. So we're going to look for C A N V. And we're going to look for that canvas panel right there. So we're going to drag that right over our UW game over. Okay. And the next thing we're going to look for is a image right there. So there's the image. We're going to bring that down. Now with our image, let's do a couple of things. So we're going to go to our anchors here. We're going to hit control and we're going to select this one right here."},{"start":"1:40","end":"2:12","startSec":100.1,"text":"And the reason we're going to do that, remember, that's going to allow this thing to be as big as we need it to be for any UI size. The other thing we're going to do is we're going to come over here to the color and opacity and change this maybe to like some bluish color, something like that. Okay. And we need to add a few elements to our canvas over here. So what we're going to add is we're going to add some text first. Okay. And then with our text here, we're going to again, size this to content."},{"start":"2:13","end":"2:46","startSec":133.1,"text":"And this first text is going to say game over. And then we're going to set it to something like 64. And a couple of things we're going to do here, we're going to take this anchor and we're going to put it by holding control. And we're going to go right here in the middle, but we're going to take our alignment and set this to .5. And this is going to move our box over. And this is just going to make it a lot easier for us to position this up, not on the X position, but on the Y position. So again, all I did is I just took that alignment, put it to .5."},{"start":"2:46","end":"3:19","startSec":166.4,"text":"And then this just makes things a little bit easier to get it kind of centered on the page there. I'm also going to put an outline of maybe like three on this and maybe do the size to like 96. There we go. So game over. And then what we'll do is we will right click on this and we will just duplicate it and then we will move this up just a little bit more, not the size. I'm sorry. We want to grab that game over and we want the Y position here. So we just move this up. And then we will make this say final score."},{"start":"3:22","end":"3:55","startSec":202.6,"text":"And then we'll actually do a little space right there. All right. And then the last thing that we're going to do is we're going to add a button here. So we'll take this button and bring it right down onto the canvas panel. Make sure it's selected. And then like we did before with our anchors, we're going to come here. We're going to hold down control and click so that it's anchored down here at the bottom of our screen. Much like I did with the text, I'm going to take the alignment set to point five and then this just makes it easier to position this up on the middle right here."},{"start":"3:56","end":"4:28","startSec":236.8,"text":"The other thing we're going to do is we're going to take some text here and we're going to drag it right onto the button and that's going to nest the text in that button. And if we click on with the button selected size to content, we can then have our text here say something like restart. And then we'll increase this maybe like 64. There we go. And give it an outline to. So there we go. We have our game over our final score and then our restart button, just like we"},{"start":"4:28","end":"5:01","startSec":268.5,"text":"have right here. And what we're going to do next is we are going to bind some text to our final score so that we can have that update when the game is over. So when the game is over, we'll show this menu screen. So like we did before, we're going to do the final score. We're going to create a binding. We're going to go to the player pond. We're going to get cast or BP sports car. We're going to get the current score and we're going to use that as the value with our format text for final score and then the value. So let's pop back over here to our editor and then our final score."},{"start":"5:02","end":"5:37","startSec":302.0,"text":"So that's what we want. We want to come over to our content text, click on that binding, create binding. And then we're going to get player pond and it would help if I would spell that correctly. There we go. Get player pond. And then from our player pond, we are going to cast to BP and we want this cast to BP sports car. Remember, we're going to convert this to a pure cast because we know the value that we are getting and we're 100% sure that current get current score is there."},{"start":"5:37","end":"6:10","startSec":337.8,"text":"Okay. And then what we're going to do is we're going to format text. And what are we going to do with this? Well, we're going to say final score and then X space, two curly brackets and the word value. And this is going to allow us to move this over and then go like this. So let's compile and save this. So again, we're going from our player pond. We're casting to our BP sports car to get the current score."},{"start":"6:10","end":"6:42","startSec":370.4,"text":"And then we're using our format text, putting in our final score. Remember, double curly brackets for the value so that we can get that current score and display that as the final value. Next, what we're going to do is we're going to select the button that we put restart on. And when we do an on clicked event, that's going to give us an on clicked and we're going to use this to basically open up the level that we were in again by creating this little bit of blueprint code."},{"start":"6:42","end":"7:11","startSec":402.7,"text":"So let's come over to our editor. So we're going to go back to the designer and then we're going to make sure that we have our button selected and then all the way down to the bottom of the details panel, we have our on clicked event. So on clicked, there we go. So we're going to get player controller. All right. And then we are going to set and put mode game only."},{"start":"7:18","end":"7:50","startSec":438.4,"text":"And then we're going to open level by name. And we need to give this a level name of L V L underscore V H I C L E V A S. Yes, I see vehicle basic, which is this level right here. All right. So let's make sure we compile and save. We can close this down. And now what we need to do is we're going to open up our game mode and remember"},{"start":"7:50","end":"8:19","startSec":470.0,"text":"our countdown uses a branch so that we can do something on the true and something on the false. So what we're going to be doing is we are going to be doing something on the true. So when the value equals zero, what are we going to do? Well, we are going to remove our current UI. Then we're going to show the mouse cursor. We're going to set the input mode to UI only so the player can only interact with the UI. We're going to create our game over widget that we just built."},{"start":"8:20","end":"8:52","startSec":500.0,"text":"And then we're going to add that to the viewport. So let's go ahead and do that now. So remember, we need to come over to our blueprints, BP, GM, vehicle, basic game mode. And remember, we're going to do this on the true. So we are going to say, remove from and we want remove from removed from parent. There we go. And we're going to take this right here."},{"start":"8:52","end":"9:25","startSec":532.1,"text":"So we want to remove the current UI. And then what we're going to do is we're going to go set show mouse cursor to true. Okay, so we're going to set our current mouse cursor to true. And then we are going to set input mode to UI only. All right. And we also need to get player controller. I'm going to put on my contact sensitivity so that I can get to our game player"},{"start":"9:25","end":"9:56","startSec":565.5,"text":"controller because we need to tell what player controller we currently want to enable all of this stuff on. So for our set show mouse cursor, the target is going to be our current player controller as well as our set input mode UI only. Then what we're going to do is we are going to create, create widget. And what widget do we want to create? Well, we want to create our game over. And who do we want to create that widget for?"},{"start":"9:56","end":"10:27","startSec":596.0,"text":"Well, we want to create it for our current player controller. And then we need to add to viewport. Add to, there we go, add to viewport. This widget. So if we compile and save this now, what should happen when I press play and the time gets to zero, well, let me just get a little bit of time here. And it counts down to zero. What should happen is we should now see our menu pop up. And once we do that, once we verify that, we will move on to the next part,"},{"start":"10:27","end":"10:59","startSec":627.8,"text":"which is going to be creating our empty level for our main menu. So let's press restart and boom, there we go. We have restarted. All right. So perfect. All right. What we're going to do now is make a new empty level called main menu. And we're then going to go to our project settings and our maps and modes and make sure that our editor startup map and our game default map are set to the start menu. This way that when we start our game, it's always going to load that map."},{"start":"10:59","end":"11:30","startSec":659.7,"text":"We could leave the editor startup map to the default, but in this case, we don't, we can choose to do that either way, which is great. So we're going to do a file new level. I'm going to say empty. All right. And we're going to save stuff because we've made some changes. And then we're going to hit control S. And I'm just going to save this in my content and we're going to call it main menu. Main menu. There we go. All right. And then we're going to go up to our edit project settings. I'm going to bring the project settings on screen for you to see here."},{"start":"11:31","end":"12:03","startSec":691.1,"text":"We're going to go down to our maps and modes. And I'm just going to make sure that the game default map is this main menu map that I made. So just change that to main menu. All right. Then what we're going to be doing is we're going to create another widget blueprint. And with this widget blueprint, what we're going to do is we're going to make a background, some text and a button. And when we press that button, we're going to make sure we show our mouse cursor."},{"start":"12:04","end":"12:33","startSec":724.4,"text":"And then we are going to set the input mode game only. And then we're going to open our level. And this works pretty much like we did with the other project. So let's go ahead and come over here to the editor window. So again, we're going to close this down. Okay. I'm going to hit control space and then we're going to come up to our content."},{"start":"12:34","end":"13:04","startSec":754.4,"text":"Right click user interface widget blueprint based off of a user widget. I'm going to call it user widget underscore main menu. All right. And let's double click on this to open it up. So again, we need our canvas, canvas panel. We're going to drag that down. And then we also need an image."},{"start":"13:05","end":"13:38","startSec":785.3,"text":"Remember with the image, we're going to hold down control and select the anchor that is right here on the very, very bottom right to spread that all the way across the screen, give it some color, maybe something like that. And then we're going to add some text. So remember with our text, we're going to select it. We will say size to content. We can hit control or click on the anchors. I'm sorry, press control, bring that to the center and set its offset here by point"},{"start":"13:38","end":"14:10","startSec":818.4,"text":"five, just to make it easier to align it to the center. I'm going to say 96 for the text and we'll just call this. Car game, very, very great title there. Spends a lot of time thinking about it. We'll just move it down a little bit. And then we need to add a button. So we're going to add a button. There we go. And again, with our button, we're going to come to our anchors. We're going to hit control to bring it down there."},{"start":"14:10","end":"14:40","startSec":850.4,"text":"And then we're going to offset it by point five. And then we'll just bring this up on the y-axis somewhere. There we go. Like negative 400. There we go. Then we're going to put some text inside of it, like so. There we go. And we'll size that. And then we will make that text also say. Start game. And we will also give it like some outline."},{"start":"14:41","end":"15:12","startSec":881.3,"text":"And go. Let's also give this guy a little bit of an outline here. We go car game. All right. And then what we want to do is with our button here, we want to on click. Okay. And we want to. We want to set show mouse cursor."},{"start":"15:18","end":"15:56","startSec":918.7,"text":"True. And then we're going to do that for our turn on context sensitivity again, because it's just cuts down on the clutter. Get player controller. There we go. And then we are going to set and put mode to a game only. And then what we're going to do is we are going to open level by name. And what's the level we're going to open? Well, it is L V L underscore V E H I C L E V A S."},{"start":"15:57","end":"16:30","startSec":957.8,"text":"See. All right. So let's just compile and save and recap. So again, off of our on click, we're going to show our mouse cursor to true. We're going to set our input mode to the player controller. We're going to open the level by name. That's what happens when we do that start game. So here is the blueprint for that. What we're going to do now is we are going to open our level blueprint so that when we start, we can actually show this mouse cursor and load this UI."},{"start":"16:30","end":"17:08","startSec":990.8,"text":"And we're also going to change our game mode to game mode override. If we leave it at the current game mode, what is going to happen is the car will actually spawn and then we will lose our UI. So let's go ahead and set all of this up right now. So we're going to come here. I can close this for the time being, but we are going to come up to our open level blueprint and then we can get rid of the event tech because we don't need to do something every frame. We just want to do it on event begin play. So we're going to go create widget and the widget we want to create is our main"},{"start":"17:08","end":"17:39","startSec":1028.4,"text":"menu and then we're going to add to viewport like so. Okay. Then what we're going to do is we're going to go set show mouse and I'm going to disable context sensitivity to find this. We want to set that mouse cursor true so that the user can actually use their mouse. They're going to go get player controller and I'm going to enable my context sensitivity because I want this game get player controller and we're going to plug"},{"start":"17:39","end":"18:10","startSec":1059.7,"text":"that in to the return value here on our target. And then we are going to set input mode UI only and we are going to put the player controller into there as well. And this is going to just allow us to make sure that we're only controlling the UI. The other thing I'm going to do after I close this is come here to our world settings and in my game mode override, I'm just going to change this to game mode. So what should happen now is when I press play, I will start the game."},{"start":"18:11","end":"18:41","startSec":1091.4,"text":"Go. Let me just get some time and a score here. So we'll wait for just a few, few moments for this to count its way down. Probably should have picked a shorter time. It's crazy how long 10 seconds seems to be when you're doing a demo versus when you are testing. So there we go. The time should be over and we should be able to restart and there we go. There we have it. So again, we start our game. We can start the game and then the time will run out and we can restart."},{"start":"18:41","end":"19:15","startSec":1121.9,"text":"We have something like this. So one of the other things that you could do to extend this further is on the restart here, you could actually add a quit or a main menu option. So you could have a look for the option quit inside of the editor. There's an option there that will quit your project for you. You can add that as a bonus. And then you could also restructure the restart code to have something that takes you to the main menu level so that you can then further refine your project's game loop."}],"10_Outro":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"With everything now set up, we have reached the end of this tutorial series. Now to quickly recap, we first started off by going over some of the more common blueprint nodes we'd be utilizing in the workshop. We then did the same with Unreal Motion Graphics or UMG. And inside of the workshop, we took our vehicle template and we set it up so that we could create a score and time pickup that then relayed this information to the user while the game was running."},{"start":"0:33","end":"1:04","startSec":33.0,"text":"Once the game was over, the user's final score was taken and displayed to them and the user was given the option to run the game another time. We also created a main menu that allows the user to actually start the project, allowing you to either quit or restart or go back to the main menu depending on what options you have. It was my great pleasure having you in today's tutorial and I look forward to seeing you next time."}]},"227.05":{"01_Overview":[{"start":"0:00","end":"0:27","startSec":0.0,"text":"Hello, and welcome to today's Unreal Engine training on the UMG fundamentals for HMI in design. So today we'll be covering setting up for modularity in this scene that you can see on the right hand side here. And we'll try to design with flexibility and ease in mind for other people using this interaction. We'll talk about new ways to input and display information. We'll talk about organizing menus and also animating user interfaces. So let's jump in."}],"02_UMG Fundamentals - Setting up your interface":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Let's cover some UMG fundamentals first and how to set up your interface in the scene that we'll be looking at today. So to get started, we can open a blank template and we can create an empty level to begin a project. And then what we can actually do is add a feature or content pack into the existing blank project so that we can just include some specific content for what we need today. So we're going to include the vehicle template asset and we'll just click add to project"},{"start":"0:33","end":"1:03","startSec":33.2,"text":"and this will give us access to this car model that you can see in the scene there. So it's a nice clean way to work. You don't have to come with all the bulk of other information from other content packs. So go ahead and do that, save all and we're good to get started. We'll be using the game mode today to store information and so I think it'd be useful to cover what a game mode is and especially in relation to HMI. So the game mode first of all is singleton so it can be accessed by any class, meaning"},{"start":"1:03","end":"1:36","startSec":63.4,"text":"that whenever you have a session active, you can find the game mode based on any class that's currently in that scene. It holds data so you can easily access and store data inside the game mode. And the cool thing about this is that it only exists as long as the level is open. So we use the game instance and also save states for long term data storage. So if you just want to access information during the actual session, then you can have"},{"start":"1:36","end":"2:07","startSec":96.9,"text":"whatever variables or information you want to store inside the game mode and that will be fine. It's like a one shot use of data. If we're wanting to maybe change the color of a car and actually save that information, you wouldn't want to do that on the game mode. You'd want to do it either in the game instance or in a save state. So it's worth highlighting the differences there. When we talk about controller in this instance in HMI, we're talking about something that"},{"start":"2:07","end":"2:37","startSec":127.3,"text":"we can possess. So we will when we load the session and play the session, controller will become active and we can interact with this scene with our controller. So for our purposes today, our controller will be our camera manager. So it's a digital representation of a user and we possess it like a pawn in a scene. It can have input assigned to it. So we can bind either keyboard and mouse events or any other peripheral that you have plugged"},{"start":"2:37","end":"3:07","startSec":157.4,"text":"in. We can actually take input into the controller. So it allows for a lot of flexibility there as well. And as you can see in a HMI, the controller can be used to change the interaction modes and manage the information as well. So a lot of power in the controller and that is what we'll be using today to interact with that scene. A pawn on the other hand is a representation of generally your avatar in the world."},{"start":"3:07","end":"3:37","startSec":187.6,"text":"So it's the user's visual or digital form. It's a CDO Singleton, but the HMI is like any visible pawn. So we just possess a camera to see the visual elements and there's no visual element needed because we don't need to move or manipulate anything. And then in a standard HMI game mode, the pawn class is set to none. So in that screen that we saw here, when we have a pawn class, we won't need any kind"},{"start":"3:38","end":"4:11","startSec":218.0,"text":"of pawn class assigned because the controller will be handling everything in this instance. And then looking at some default properties for our project settings, we want to go to the edit button at the top of our Unreal Engine window and go down to project settings, which you'll find towards the bottom. And you can go to the maps and mode sections and we just want to change some of these properties. So if you can't find any of these properties, there's a search bar at the top of project settings, which you can easily find any of these parameters here."},{"start":"4:11","end":"4:42","startSec":251.2,"text":"But we want to change the game mode up here. We want to change the default map to whatever map we want to load at the start and we want to change the game instance. So whatever you call your map, if you go to file, save as, and you call your map something, for example, display map in this instance, you just want to make sure that that's assigned. In case we package up the game or the executable and we want to share this with someone else, that will load the correct map by default."},{"start":"4:42","end":"5:13","startSec":282.5,"text":"So it's worth keeping those settings in mind. And today we'll be displaying some kind of data on the screen that we want to interact with and we use UMG for this, which stands for Unreal Motion Graphics. And they're the properties that you can see on the right hand side here. And we can design those, which we'll jump into in just a few moments. So what is this display of data? So it's a collapse UI. We have widgets as templates, so you can create a widget and assign it to various different"},{"start":"5:13","end":"5:47","startSec":313.5,"text":"interactive elements throughout this HMI demo. We have widget switches, which are contextual menu changes. So we can switch from one menu to another menu. We have widget layering. We have text displays, as you can see on the right there, where you can format your text, however you'd like it. And we can actually bind events to the input of clicking any of these buttons. So if we click this audio button, we can fire off some kind of logic, which will cause a state change in this demo, which will be really powerful moving forward."}],"03_Setting up the scene - building a 3D display area":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"And then let's quickly go over the scene setup for the demo today so that you can get a rough representation of what we're working with today. So we want to display the vehicle blueprint, which is an actor here, and the actor will take in data from the UI. We'll use the data to update the 3d model in some way. And also we can also hold a 3d widget component. So if you see this components box at the top left hand side here, you can see an add button, you can actually add"},{"start":"0:32","end":"1:05","startSec":32.8,"text":"widgets to this blueprint, which is really powerful functionality. Here's the vehicle blueprint component. And then also we have our scene setup. So we just have this blank level, we've got a camera actor. And if you go into the camera actor properties, you want to make sure auto activate for player is player zero. And this means that we can possess this camera like we were talking about before with our controller, we can take input when we actually want to play this experience."},{"start":"1:05","end":"1:23","startSec":65.8,"text":"We have a rec light setup, you can use a point light as well. They're both set to stationary. We want the vehicle in there. And then we've just created a cube, which is the mesh floor, and just stretched out there. So that's the basic scene setup that we'll be working with today."}],"04_Core UMG Widgets - HUD and reusable widget":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"So with that context in mind, let's now jump into creating a core UMG widget and talk about creating a HUD and a reusable widget. So we'll jump into an engine now. And when we're in engine, we'll start by creating a new HUD widget. So I've got a HMI folder here. I'll just right click and go to new folder and I'll type blueprints here because we'll be making a few different blueprints today. I'm going to right click and I'll go to user interface and then we'll go to widget blueprint"},{"start":"0:34","end":"1:10","startSec":34.9,"text":"at the bottom here. I use a widget is fine. So we'll just click that and we'll type HUD underscore UMG today. And then we'll just hit enter to open it up. And what I like to do is I like to just pin this next to the map here so it's a bit easier to toggle between the two. So now that we've created a new widget, we want to check the fill screen at the top right of the viewport here. So we've got fill screen here and we can set a desired screen size."},{"start":"1:10","end":"1:44","startSec":70.7,"text":"And so we'll do desired on screen. If you'd like to set a specific screen size there, we have these options. We can also just do a custom on screen as well. So whichever kind of aspects you want to work with, I'm just going to use 1920, 1080, which is going to be my aspect on the PC, but you can set the real estate to whatever you would like it to be there. And then on the top left hand side, we just need a canvas panel, which we will drag down"},{"start":"1:44","end":"2:19","startSec":104.6,"text":"into here and so that we have our canvas panel now part of our hierarchy in the bottom left hand side here. So we've got our basic layout. We will jump into creating a new blueprint now so that we can actually add this widget to some kind of class. So I'm just going to compile and save. Again, we're just building the foundations right now of our functionality. So I'm back in my content browser. I'm going to go to new blueprint class by right clicking and this time we will select"},{"start":"2:19","end":"2:50","startSec":139.9,"text":"player controller. And this is just going to be a display controller. And what we were talking about in the PowerPoint just a few minutes ago is that we need some kind of controller that can interact with the scene. As you recall, controllers can take input and consume input commands. So that's why we've created a controller right now. So I'm going to hit enter to open it up again. Alternatively, you can just double click this, but when it's already selected, you can just hit enter to open."},{"start":"2:51","end":"3:22","startSec":171.0,"text":"I'm just going to save it just to make sure we have the save preferences. And I'll go to the event graph in the top middle here. So when we go to the event graph, we can delete the tick if you'd like it like to delete that. Again, it doesn't really have functionality, it just cleans it up a bit. And so we'll go from the event begin play, and we'll create a widget. So create widget. So you just draw, drag off the the white execution pin and go to create widget. And we'll have something like that."},{"start":"3:22","end":"3:56","startSec":202.8,"text":"And then we just want to find the hood that we just created. So we called it hood underscore UMG. So we'll add that there. And then we want to promote this to a variable. So we'll drag off the blue pin and say promotes a variable. And we'll call this hood underscore UMG reference, something like this. It doesn't matter what the specific name is, as long as it's consistent with your naming convention and that you remember what that name is for use later on."},{"start":"3:56","end":"4:31","startSec":236.0,"text":"And then the last thing we want to do, we've got the controller, we've created our hood widget, now we just need to add it to the screen. So to do that, we say add to viewport. So we'll just click add to viewport. And as we now add functionality to this widget, it will get added to the viewport as long as we have our game mode set correctly, which we will do in the coming time here. So let's create our first bit of functionality to make sure we can see our UMG display and"},{"start":"4:31","end":"5:03","startSec":271.6,"text":"just make sure everything's working correctly. So I'm going to go back into the hood UMG now. I'm going to find a vertical box. So I'll go to vertical box. I'm going to drag and drop that down into here. And so you'll see a new box has been added and we can position this wherever we would like. We can change the positioning. It doesn't really matter too much for these purposes, but I'll just drag it out so you can see that happening."},{"start":"5:03","end":"5:37","startSec":303.6,"text":"And maybe I'll make it a little bit bigger. And we want to add a text box. So we'll just display some kind of text on the screen. So I'll get the text box and drag and drop that down to the vertical box as well. And then I will also add a name slot underneath that. There we go. So the text is just a text block there. And the name slot comes in at 180 by default."},{"start":"5:37","end":"6:09","startSec":337.2,"text":"I'm just going to rename that at the top here. Just name slot and then I'll compile and save. And then we can jump into our graph, which is on the top right here to start adding some kind of functionality. So we'll go to the graph. And we've got the event pre construct, which is what we want to use at the moment. So we want a few variables on the left hand side to add before we get into any kind of functionality. So we want to actually find our text block and make sure that our text block is editable."},{"start":"6:09","end":"6:39","startSec":369.9,"text":"So let's go back into our designer. Let's get this text block here, select the text block, and then just say is variable. We can take that up there, compile and save. And we'll go back into our graph. And you can now see that that text block is there. So we can also rename that. You don't need to do this, but I just want to make sure that the text block just nice clean naming conventions, compile and save, go back there. And so everything looks a little bit more organized."},{"start":"6:39","end":"7:11","startSec":399.9,"text":"And then we just want to create a new variable as well. Something along the lines of display text. And we'll create a named variable from this. So we'll change it from Boolean to will it be a text? I believe it might be a text variable. So we'll just compile and save that. And then we'll drag out the display text. I'm going to hold down control on my keyboard and drag out alternatively, you can just left mouse drag out. But then it'll say do you want to get or set the variable by holding down control, you will get the variable."},{"start":"7:11","end":"7:43","startSec":431.0,"text":"And by holding down alt, you will set the variable. So that's just a little shortcut in case you want to use that there. I'll compile and save. And then we want to set the text. So I'm just going to move these two events, we don't really need them at the moment. I'm going to grab the text block. So I'm going to hold down control again and drag that out. And I'll drag off the blue pin of the text block and just say set text. So select set text there."},{"start":"7:43","end":"8:16","startSec":463.8,"text":"And then we'll have the text there. And that'll be plugged in like that. So we're under pre construct, we've got some display text, and you want the text block to set the text. Now it's not going to set any text because we don't have any default information. So we'll just type test there, compile and save. And so that's our basic setup for making sure we have editable content. And the last thing we want to do is just make sure that variable is public, so that that"},{"start":"8:17","end":"8:48","startSec":497.4,"text":"is instance editable. And then we'll compile and save. And then before we move on, let's just make sure we can display the content on our screen. So we'll go to the display map and we need to create a new game mode. So we'll right click and go to blueprint class. And we'll select game mode base from here. And we'll just call that display game mode. And then open that up."},{"start":"8:48","end":"9:21","startSec":528.6,"text":"And we just want to make sure the player controller is assigned correctly. So the player controller is our display controller. And we'll compile and save that. We'll go to our default map, we'll make sure on the world settings, if you don't have world settings open, you can make sure that the windows open on world settings, and just make sure that display game mode is set there. And then we'll save all. I'm going to full screen my window by pressing F11 and go and hit alt and P on the keyboard."},{"start":"9:21","end":"9:52","startSec":561.2,"text":"And you'll see that our test is now visible on the top left hand side there. So you'll throughout this process, we've kind of created a new game mode that will display, well, use some kind of controller that takes input in the controller. We've added the UMG to the screen via this blueprint scripting here. And then the controller says load this HUD and add it to the screen."},{"start":"9:52","end":"10:22","startSec":592.0,"text":"And the HUD that we've created, which we can find by searching here is this UMG HUD. And the UMG HUD basically says, get some text and display text. So whatever's in this variable right now, if I change this to hello, and compile and save, then if I full screen and press alt P on the keyboard, you can see hello there. So we've got some really nice basic functionality of a UMG setup."},{"start":"10:22","end":"10:54","startSec":622.1,"text":"We know that everything's working correctly before we move on. So let's jump into the next section. Next we'll create a right panel widget using a sub menu, which will house a lot of interactive functionality that we can add to our scene. So let's jump into the editor again. And so we're back in editor now, we've got our HUD UMG class open. Now that we know this is working, I'm going to change custom back to fill screen, because that's going to be the desired behavior we want as we start adding more panels to our"},{"start":"10:54","end":"11:24","startSec":654.2,"text":"user interface. So we want to start by creating this right hand panel. So we want a size box. So we'll type in size on the top left hand side, grab a size box and get a size box at the bottom here. I will add it outside this vertical box actually, size box, and we'll call this size box, the right panel, for example. So we'll just call this right panel size box."},{"start":"11:24","end":"11:57","startSec":684.4,"text":"So we know exactly what that is. We want a grid panel view. So we want to get the grid and we want a grid panel view on this section here. So we want to child the grid panel, make sure that's underneath the size box there, and just compile and save. And we'll get this grid size box and just bring it over into some better real estate there. For example, there, you can even anchor it to the right right hand side there instead"},{"start":"11:57","end":"12:30","startSec":717.9,"text":"of the left, if you wanted to make sure it's right aligned. And so in this panel, we want to add three buttons. So we want an open and close button and a tab button. So we will add the open button first. So we'll go to button, add the button here, and that can go under the grid panel. And then we'll call, we'll just keep, because we're adding so many components at the same time, we'll just keep all our naming consistent."},{"start":"12:31","end":"13:05","startSec":751.1,"text":"So we want open, close, button, and then we will add another button as well. And this one will be called tab 01 button. And then we'll add some text to, oh, I changed the open, close button text in there. So let's rename that open, close button and selecting this button here. And we'll call this tab 01 button."},{"start":"13:05","end":"13:37","startSec":785.1,"text":"And then we want some text under this tab button. So we'll add the text similar to how we did last time. And we've got the text block there. And this text will be the audio text box. So we'll just say audio here. And then we want another tab button. So I'm just going to duplicate this by right clicking duplicate, and that'll bring the button with it as well. So this will be tab 02 button. And then keep that renamed."},{"start":"13:37","end":"14:12","startSec":817.4,"text":"And then this one, instead of audio, will be radio. If I can spell radio, there we go. And then I'll just make sure in the audio text book, I've got audio. So it says audio. And then I will call this text radio. There we go. We'll compile and save and then start formatting everything now. So to begin with, we want to sort out our grid panel here."},{"start":"14:12","end":"14:45","startSec":852.4,"text":"And we want to add the properties to the fill rule. So let's add a column fill. Let's add three indexes here. And you want to input one, one, and leave index zero as zero. And then on the row, we want zero. And then we want a one on the one integer and zero there. And then we will compile and save."},{"start":"14:45","end":"15:22","startSec":885.4,"text":"And then we just want to make sure our buttons are aligned correctly. So the open close button will click the downward arrow there. On audio, we will click that button there. And then on our radio will go one, two. And so we've got our button functionality as well. So we can add spacing as well and padding where needed if you want to on the options."},{"start":"15:22","end":"15:54","startSec":922.6,"text":"We can do that by just typing padding and then answering some kind of numerical value. If it's 10 or 20 or whatever that padding might be, maybe 20 looks good there. We'll just give it its own spacing. Something like that. Again, as soon as we start getting down to the visual level, it's up to you how you want to format things. But that'll be our basic layout."},{"start":"15:54","end":"16:28","startSec":954.1,"text":"And then the last option that we want, the last palette option is a widget switcher. So we just want to drag and drop the widget switcher down here and just remove that and make sure the widget switcher is called widget switcher. And we'll compile and save that. And then we will drop down the slot and the grid slot. And under the row variable, we want to change row to one and the column to one and the column"},{"start":"16:28","end":"17:00","startSec":988.7,"text":"span to two. There we go. And then compile and save again. And that's our basic right panel setup. So we'll move into scripting the functionality next. So into our graph, we will find some spare real estate and we want to select the tab 01 button here. And as soon as you select that, you'll see an on clicked event. So we'll just add the on clicked event and we will find the widget switcher, hold down"},{"start":"17:00","end":"17:35","startSec":1020.9,"text":"Ctrl and drag to get the variable and we'll type set active widget index. And we'll hook that into there. And then we'll also find tab 02 button on clicked. And then the exact same thing. So we'll copy and paste that. So I've just Ctrl C, Ctrl V the function there, and we'll change this index to one. And that'll set up some basic activity with the widget switcher on how to select each"},{"start":"17:35","end":"18:08","startSec":1055.8,"text":"one. Next, we will go back into our designer. And under our widget switcher, we will get a vertical, vertical, get a vertical box. We've got that there. And we will get a horizontal box as well. Horizontal box. And we're going to start building out a volume widget here. So we will get the vertical box, this will be the audio tab."},{"start":"18:08","end":"18:40","startSec":1088.7,"text":"So we want some kind of text input combo, which will be volume. So text, vertical, we'll call this volume. Let's just select the text box volume. And we could even center this up. I could even add some padding if you wanted."},{"start":"18:40","end":"19:11","startSec":1120.4,"text":"I won't start getting deep into the visual style at the moment. So we got our text box, text says volume, and then we want a spin, spin box as well adding to the vertical box. And that'll be this here. So we want to make sure on this that there is some numerical value in there. We also want to set some kind of properties as well."},{"start":"19:11","end":"19:41","startSec":1151.2,"text":"So we want to make sure that the slider has the options set. So we'll scroll down here to slider. And the min property here is going to be zero. So just make sure that that's at zero. The max is going to be zero. We could actually go to zero to 11 there actually. And then always use Delta snap."},{"start":"19:41","end":"20:14","startSec":1181.7,"text":"We can enable, we can make sure the Delta is at one there. Slider exponent is also okay there. And there should be, is the slider enabled? Let's just check. Yeah, so is enabled. That's okay. We've got the basic functionality in the slider set there. And I might just add some padding to this just to give it a bit more space in there."},{"start":"20:14","end":"20:48","startSec":1214.9,"text":"So again, just compile and save. Next we will add another text box. So add text below in this here. Again we'll center it up. We'll just make sure everything's aligned correctly. And we'll call this text. Let's find the text option. And we'll call this balance. And we could even just start naming these text blocks as well."},{"start":"20:48","end":"21:24","startSec":1248.5,"text":"So we know exactly what each of the text blocks are, just in case we need to reference them in blueprint. That is purely just naming convention, so it's not going to affect any functionality. So you can name them whatever you'd like. And then we want a slider now for balance. So we'll add a slider onto the vertical box. And the slider is going to have these values of, so value is 0.5 here."},{"start":"21:24","end":"21:59","startSec":1284.6,"text":"And the thumb image size is going to be 60. Let's make sure we get the correct options here. So we can type in thumb image. And this will be the normal thumb image. So from 8 and 14, we just want to change to 60 on both inputs there. So 60 and 60. And then if we cancel that out, the last thing we want is the thickness."},{"start":"21:59","end":"22:32","startSec":1319.4,"text":"So again, I'll just type this property, the bar thickness. I'll just change that to 1. Oh, 10. There we go. That'll look better. And then you can compile and save. So we've got some basic UMG layouts for the volume and balance here. Now let's switch to our horizontal box that we added before. So we can either just select this and all of the other information will disappear just because we've gone from the vertical box to the horizontal box."},{"start":"22:32","end":"23:03","startSec":1352.0,"text":"So don't worry if anything disappears. It's because we've got the horizontal box there. Alternatively, just to show that the widget switcher is working as intended, you can actually change the active widget index from 0. If I can just select 0 to 1 and it'll go from 0 to 1, which is exactly what we did in the graph here. So it's just toggling between two different options, which is a really nice functionality. So we've got our horizontal box. And again, we want to create a couple of options here."},{"start":"23:03","end":"23:37","startSec":1383.9,"text":"So we want two different text inputs. We want saved and we want the station slider here. So on the horizontal box, we will go to a text input and we'll drag the horizontal box here and this one will be called saved in the text. So we'll just select the text box there and we'll type saved. So we've got that there. And then we will make sure we have a named slot."},{"start":"23:37","end":"24:08","startSec":1417.7,"text":"So named slots underneath here. And that name slot can actually go underneath the text in this instance. And we will, so to get the name slot underneath there, we'll need a vertical box. So add the vertical box under the horizontal box, and then we'll add the text under the vertical and the named under there."},{"start":"24:08","end":"24:43","startSec":1448.8,"text":"And so that will get them to stack OK. And then we want the combo box adding. So combo box, which is the string version, and that will just go under the named slot there. So that'll be our basic vertical box functionality. And so then we will add the exact same, but call this a station. So we can maybe even right click, duplicate the vertical box here, and then we'll change"},{"start":"24:43","end":"25:16","startSec":1483.2,"text":"this text to station instead of saved. So station will be there. And we don't actually need the combo box this time. So we can delete that one. I'll rename this name slot to maybe let's call it station named slot. And you don't need to rename your content. It's more just to keep organized as this list ever expands. It's good to keep things organized. So I'll call this, this other one station named slot."},{"start":"25:16","end":"25:48","startSec":1516.5,"text":"There we go. So we can see exactly what we're doing. And then on the second vertical, we'll call this vertical, we'll rename it, let's say text input combo. And this will be the station one. And then this one will rename text input combo."},{"start":"25:48","end":"26:23","startSec":1548.7,"text":"And this will be the saved one. So this helps keep things a little bit more organized. And then on the second text input combo, which is the station, we just now want to add a slider. So we will go to the top, we will add a slider, and we will add this to here. And we can actually change this version of the slider. If we type in orientation, we can actually change this to vertical, which will look much"},{"start":"26:23","end":"26:57","startSec":1583.8,"text":"better. So the values for this one will be, let's see on the slider, we've got the value, let's call this 80. Let's say the min value is 80. And the max value in this instance will be 110. We've already changed the orientation. Let's change the step size. And we'll call this point one instead of point zero one."},{"start":"26:57","end":"27:28","startSec":1617.7,"text":"We'll change the thumb size again. And we will call this one, maybe 40 by 100. And again, changing that bar thickness as we did last time as well. We'll change this one to 10. So that's our basic styling done. And we now want to make sure this gets resized correctly."},{"start":"27:28","end":"27:58","startSec":1648.1,"text":"So let's maybe move this down here. And then maybe let's just try and fill this out here. So that will look much better. We could even change the horizontal. So we can change all the padding, things like this. So maybe let's try value of 20 again. And then maybe on each individual padding as well, we just pad this out a little bit more."},{"start":"27:58","end":"28:33","startSec":1678.3,"text":"Again, we're working with a lot of different properties. So you can kind of balance this to however you want it to look. And then this slider, this slider, let's just check the value here. That thumb, that thumb size doesn't feel right. So let's just check the thumb. So normal thumb image size. Let's see, let's try 40 and 100."},{"start":"28:33","end":"29:04","startSec":1713.7,"text":"There we go. That's made it look much better. So yeah, that value can then be set to 80 and we're okay to move on. So compile and save and we'll move on to the next section. So let's move into some visual scripting now. So we'll go back to our graph. And this time we want the station slider. So the slider that we've got is our station slider, which again, we didn't rename. So let's go in there and rename it so we can keep track of everything."},{"start":"29:04","end":"29:43","startSec":1744.7,"text":"So this slider 260 is our station slider, but let's make sure that's named correctly so we know exactly where it is. We'll compile and save, jump back into the graph. And now we've got the slider station here. So we actually want the, you've got a few different options, but we actually want the value changed option on the bottom here. So we'll just click on value changed. And then we just want to create a new custom event. So just right click custom event and we'll call this update station text."},{"start":"29:43","end":"30:15","startSec":1783.2,"text":"And we will actually then compile and save on the value changed. And this will just keep things modular. We will update the station text. So we'll click up, enter there and whatever we named this custom event, that's what this is calling. So if we double click this, you'll see that we go to this section here, which is really nice functionality. And we can actually add a new pin into the value by, I used to be able to drag that."},{"start":"30:15","end":"30:45","startSec":1815.5,"text":"I'm pretty sure, but anyway, we'll add a new input here and we'll call this just value. There we go. Change this to a float. So now we've got a value value. You'll see that this box is updated here and we can just drag and drop that in there. So whatever value the slider feeds into this event, we'll get this output here. This is what we were talking about when we were referring to working in a modular way."},{"start":"30:45","end":"31:17","startSec":1845.6,"text":"So you can have this functionality over here, which feeds out to this functionality here. So now we just want to update the text on the combo station based on whatever value is being fed into here. So we need to make sure we've got the correct text assigned. And again, going back to good naming, we want to make sure that the text input combo there, that station, we want to change that to get the text box here."},{"start":"31:17","end":"31:47","startSec":1877.8,"text":"So the text is station. Want to make sure that is a variable and we'll call this station text, compile and save. So we're looking for a station text. So we've got station text here. We'll grab this and then we'll do a set text as we did before. We've got a set text. There we go."},{"start":"31:48","end":"32:23","startSec":1908.1,"text":"We want to get this value and do a to text, which is in brackets, the flow. So we have a few different properties down here that we can edit. We'll just move this into position. We'll drag this into here. The use grouping, all these values are okay. The min max digits can be two and three. And the min max fractional digits are both one each."},{"start":"32:23","end":"32:53","startSec":1943.4,"text":"There we go. We'll just compile and save that. Next we will edit the saved station. So we'll go back into the designer and the combo box here, which is the saved. We have this combo box that we can select. And so we want to make sure that the default option, we'll just type in non here and set"},{"start":"32:53","end":"33:25","startSec":1973.5,"text":"non to the selected option. And then content pattern, that should be okay as is. We want to make sure that the down arrow is false. So has down arrow is false. And then item style, the text color is white. So item style."},{"start":"33:25","end":"34:00","startSec":2005.8,"text":"And we want to find the text color, make that white. There we go. And then the font, the size can be 20 in this instance. And an outline can be two. So let's see, outline size is two. And you can also of course add a button padding if you want to. And I've just compiled and saved this and noticed that the text isn't the correct color."},{"start":"34:00","end":"34:33","startSec":2040.4,"text":"So let's just make sure we fix that before moving on. So you can actually, I think maybe change the foreground color. Yeah, let's just change that foreground color to a white and then non should be correct. So you should end up with something like this. If I go back down to the horizontal box, I'll actually maybe just try and collapse some of this here so we can see a little bit better. But that should be overall what we're looking at for that section. Next, we want to create a list of saved stations."},{"start":"34:33","end":"35:00","startSec":2073.2,"text":"So we'll go back into our graph here and we'll create a new variable, which is a saved station list. So let's say saved station list and the variable type will be a string to float. Let's just add a string."},{"start":"35:03","end":"35:33","startSec":2103.6,"text":"Let's change that to an array, a map. And then so yeah, string and then to map. And then we want the actual flow here. There we go. And then we can compile and save that. And as we're adding variables, sometimes it's easier to just separate these out into maybe call it the setting config, the category config or something like this. And then if you do the display text and change that to config,"},{"start":"35:34","end":"36:06","startSec":2134.0,"text":"it'll create its own group of variables that you edit. So sometimes if you've got a whole list of variables here, it can just be a little bit easier to keep everything organized there. So just worth keeping in mind. The pre-construct, we'll just delete this now because this was just a test. So I won't do that. I'll compile and save. And then now we want to get this saved station list. And then we want to get the keys from this."},{"start":"36:06","end":"36:40","startSec":2166.1,"text":"So we'll type keys. We'll add this to the execution line. There we go. And then we'll for each from this array. So let's for each loop through this series of keys here. So we'll just loop through the whole station list and to try and find a certain variable. So from the array, we'll do add option. Well, from the actual station list, sorry, which is the combo box that we added before."},{"start":"36:40","end":"37:11","startSec":2200.7,"text":"So let's just make sure we have combo. So we've called that combo box string. So let's rename that combo. Again, this is why naming convention is good. So combo box save station. Let's go back to our graph now. Let's go back into here. Drag this out, holding down control. And then we'll add the option from here."},{"start":"37:11","end":"37:41","startSec":2231.7,"text":"Add option array element into there. So that's our pre-construct. So we can compile and save. And then we want on the combo saved stations. We actually want to change this property. So let's start commenting out our code so we know exactly what we're doing. So you can actually select a few boxes and you can just say like pre-construct and press C on the keyboard."},{"start":"37:41","end":"38:12","startSec":2262.0,"text":"Add that comment box and you can actually change the color if you want. If you're looking at any kind of execution wiring or anything like this, you can go to town on the font size, all this kind of stuff. So I just I'm going to keep things organized. Pressing C on my keyboard again. Widget switcher is there. Slider station. This is purely for organization."},{"start":"38:12","end":"38:44","startSec":2292.9,"text":"So it's completely up to you if you decide to do this. But it just helps see things at a higher level, exactly what's going on, especially when you've got a lot of blueprint being coded. So I'm just going to compile and save that. So from this combo box saved stations now, we will see the on selection changed here. So let's add this as a property here and we'll go get the saved station list from here."},{"start":"38:44","end":"39:13","startSec":2324.8,"text":"And we will drag off and type find. The selected item we will add into here. We will look for a specific value and then the slider station text, which is in the designer. So the slider station text, which is this, we'll go back into our graph. So that's the station text that we've got selected. Now we want to set a value here. Set."},{"start":"39:14","end":"39:45","startSec":2354.9,"text":"That's not the text that we want, is it? It's the actual slider. So let's grab the slider. There we go. Slider. Station. Let's grab the slider. That's what we want to do. Set value and drag that into there. And then the value can get passed out into there. And now, now we want to update the station text. So go back to our designer, we'll get our station text, go back into our graph."},{"start":"39:46","end":"40:19","startSec":2386.6,"text":"And then we will check that out there. And actually we have a update station text function already created. So let's just call that update station text because now we're reusing functionality. So we'll type update station text and you'll see that option there. And you just want to make sure whatever you called this event that we created before, you can just call that here and we can just drag out from the find and add that in there. If you want to clean things up, you can double click and create"},{"start":"40:19","end":"40:52","startSec":2419.0,"text":"re-root nodes on the actual line. And I can hold down alt on my keyboard and drag that in there. If you just want to make things a little bit cleaner, I'm just going to compile and save and we can move on to the next section. And then lastly, it'd be useful to show you some animation functionality if you want to add this for yourself. So we can actually go back into the designer and you'll see I've got an animation window open at the bottom here. If you don't have that open, you can just go to window, animations,"},{"start":"40:52","end":"41:25","startSec":2452.3,"text":"and this animation box will appear for you. And I'll just select the right panel size box and we will add an animation and we will just call this a close open panel. And if we select that now, we can add a track. So we want to make sure we have the right panel size box here. We will go to track, add rights panel size box."},{"start":"41:27","end":"42:00","startSec":2487.2,"text":"And we can now add a transform. So we'll go to track and we will add a transform and we can actually drop down this transform here. And we don't actually care about any of the other properties here. We mostly care about the translation. So I'm going to right click and delete the rotation. I'm going to delete the scale. I'm going to delete the shear. I just care about the translation. I actually only really care about the translation in X because I want to move from left to right."},{"start":"42:00","end":"42:32","startSec":2520.3,"text":"So I'm going to drag out maybe however many seconds you want the animation to go over. I'm just going to drag to maybe three seconds. I'm going to add an X key there and then I'm going to go back over to here and I want to change this translation maybe to maybe to 843. For example, I'm just scrolling across here. And now when I press play, you'll see that this slides into view over three seconds."},{"start":"42:32","end":"43:03","startSec":2552.9,"text":"So again, this is a very rudimentary kind of animation. I'm sure you could create something much nicer with giving a bit more time. And I just want to show you some basic animation inside of UMG if you wanted to add that. So to actually add that functionality. So we've got the animation here, but it's not actually part of the project. So if we want to add that into the project, we can go back into our graph"},{"start":"43:03","end":"43:34","startSec":2584.0,"text":"and we can find some empty space and the open close button that we created at the very start. We can just go to the on clicks of the open close button and we can get the close open animation. So we can make sure that we find the animation. Let's just make sure it's a variable. So let me just go to the graph, open, close panel."},{"start":"43:36","end":"44:06","startSec":2616.1,"text":"There we go. Just make sure it's called that. So close open panel. So I'll just right click close open panel and then I can play that animation. So actually I want to play the animation forward in this instance. So play animation forward. I'll just delete that. And there we go. And then we can actually just play that animation in reverse as well. Now, every time we click this button, we want it to do the opposite of what it just did."},{"start":"44:06","end":"44:38","startSec":2646.4,"text":"So I can drag out from the execution pin. I can flip flop here, add that flip flop in there, and actually just drag that into that. So every time I click the button, it'll play the animation. And every time I click it again, it'll reverse that animation. So keep flip flop in between, play in reverse, play in reverse. And therefore that will add the desired functionality that we want. So now let's make sure this all works in situ."},{"start":"44:38","end":"45:08","startSec":2678.0,"text":"So I'm going to go back to my designer. I'm going to find this first key. I'll make sure that the first key is this little button here because that's going to open the actual animation. So we'll see that that will open on the side. I can delete this text for now. That was just example. So we'll compile and save. So this is everything that we've seen so far. Because we've got our controller, we're adding the UMG to the screen."},{"start":"45:08","end":"45:41","startSec":2708.0,"text":"So that's already added. So let's go back into our map. Let's just make sure everything is saved before we try this out. We'll go to full screen hitting F11. I'm going to press Alt and P on my keyboard. Now it's out by default, but let's just check that this is working. So we can actually change that first key. But you'll see that this opens and closes, reversing and opening. So that's really nice functionality. And we have the different audio and radio stations"},{"start":"45:41","end":"46:13","startSec":2741.0,"text":"and we can update these based on those properties. So hopefully that gives you a good overview of the UMG and different functionalities we can add inside of our interfaces. If we had our test map open, then we'd be able to see our car in the background and have all that, the functionality required for that car configurator opening and closing. So hopefully you found that useful and we'll jump into the closing comments."}],"05_Thank You":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"So thank you again for watching today's course. Hopefully it gave you a really good overview of how to use UMG in your projects, all the different powerful functionality that UMG has. Again, just thinking about the approach in terms of controller and getting input into the controller and then setting up a camera in your scene so you can configure in this example, a car configurator with sliders on the UMG and different button clicks and even add in some animation."},{"start":"0:30","end":"0:41","startSec":30.0,"text":"So you can obviously spend hours on the styling to get exactly how you want to customize it, but hopefully you found the functionality today useful and we'll see you in the next course. Thanks."}]},"227.06":{"01_Overview_5.00":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Hello and welcome to today's Unreal Engine training on the UNG fundamentals for HMI. So we'll be specifically talking about materials today. In the course outline, we'll be talking about how to create UI materials and adding some border effects to the UIs. We'll talk about how you want to think about creating materials and then material instances to edit certain variables based on a parent material. We'll talk about how to edit these parameters and then also the communication of data."},{"start":"0:31","end":"0:32","startSec":31.2,"text":"So let's jump in."}],"02_MaterialsInstances_5.00":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Let's get started by talking about some materials and instances which are just child versions of materials. We'll talk about how to create some dynamic shadows in this section. So to start off with, let's talk about some textures, materials and models. So textures, we can pack multiple textures into one texture using the RGB and alpha channels. So you can learn more about this by going to the Unreal documentation page under rendering"},{"start":"0:34","end":"1:07","startSec":34.2,"text":"materials and material instances. But essentially what we're talking about here is you'll see in a slide in a second that we can put different maybe logos or noise effects or something that you only need black and white information for. If we pack a texture into a single channel, it doesn't come with any color information because it's a single channel, but we can also then take that texture input and maybe"},{"start":"1:07","end":"1:40","startSec":67.8,"text":"multiply it by a certain color or give it a certain effect, which you'll see in a moment here. So if you want multiple textures that only need grayscale information to start with, you can think about packing multiple textures into the different channels if you want. And you can use the RGB and alpha channels. You can see in this image here, we've got a white pin at the top of a, it's a base color in this instance, but you can see that it can be used for a texture sample. So if you pull off the white channel here, it's all channels and you obviously see the"},{"start":"1:40","end":"2:16","startSec":100.3,"text":"RGB and B outputs as well as the alpha output at the bottom. So you can actually pull information from individual channels, which is super useful. We can also use UI texture modes, which we'll touch upon in a second. And then we can also minimize texture lookups by using material instances, which will really help with performance. So you only create one master material and then you create material instances based on that parent material. And again, you can find that material instancing documentation online on the unrealengine.com"},{"start":"2:16","end":"2:48","startSec":136.5,"text":"documentation if needed. And then also we'll look at the models and how to minimize certain elements, whether it be in the mesh optimization. So for this project, say we have a target of a hundred thousand triangles for mid to high tier hardware. Again, mileage may vary depending on the project. You'll have different performance requirements. And you can also look into some Nanite mesh optimization, which is an Unreal Engine feature"},{"start":"2:49","end":"3:20","startSec":169.0,"text":"in a performance issue with the number of triangles on screen. So we can look at the models, the optimization for the models. We can also look at how many materials and material instances we're using. And then also if we have a lot of textures being used unnecessarily, say we're only pulling in a gray value or black and white value from a texture sample and we're using all four channels to pull it in. Maybe you could just pack it into the red channel and use the green and blue channel and alpha channel for another texture."},{"start":"3:20","end":"3:54","startSec":200.8,"text":"So just things to consider there when looking at some optimization for your projects. When we're looking at materials, we have some baked in functionality. So materials cannot be edited at runtime. So you'll see this material graph here. We essentially whatever we hook up here, that is what happens at runtime. However, we can expose certain parameters here into dynamic values. So you can if you had a texture sample, you can right click on that texture sample"},{"start":"3:54","end":"4:27","startSec":234.7,"text":"and you can see the convert to parameter at the top of the list there. And that will mean that that parameter then can be edited at runtime, which we can use material instances from. So instances can derive from parent materials and they just inherit all the functionality and then anything that is a parameter can then be edited at runtime. So if you want to create a material with a core shared logic, then derive an instance to control the specific parameters. That's how you would change things at runtime."},{"start":"4:27","end":"5:00","startSec":267.2,"text":"And again, the Unreal Engine documentation on rendering and materials will give you a lot of mileage here in terms of knowing what properties you can edit. And then looking at the main difference between material and material instances. Materials contain instructions and functions cannot be altered when the program is running, as we said in the previous slide. They can be applied directly to a mesh or a UI element or some kind of parent of an instance, whereas material instances require this parent material."},{"start":"5:00","end":"5:38","startSec":300.6,"text":"So you can see the material instance window down at the bottom here and you'll see that parent box here. That essentially means we've got a parent material sending us certain instructions and then the parameters that we can change are in this top section here. So we can expose parameters that can be edited at runtime. We can't change the instructions or functions inside the source material. So that's just something to be mindful of there. So for today's session, let's go ahead and import the hot and cold texture from your asset pack."},{"start":"5:38","end":"6:12","startSec":338.0,"text":"We just want to make sure the compression settings are the user interface 2D. So when we talk about compression settings, which you'll see just here, compression settings, you just want to make sure that texture is compressed correctly. So then let's get started by creating a new material. So we want to have imported the icon texture and then we want to create a new material. So I'll just jump into the editor quickly to show you how to make a material if you're on show. With your editor open, you just want to maybe create a new folder for material specific"},{"start":"6:13","end":"6:46","startSec":373.4,"text":"content. So you could right click and call this materials. So I've just right clicked on content, new folder, and you can also just add here a new folder. And then also when we're in our materials, you can either just right click in this gray space in the content browser and go to material or again, you can go to add material. So let's take a look at our material options here. So we've set the material domain to user interface. So you can see here, make sure you don't have any nodes selected."},{"start":"6:46","end":"7:17","startSec":406.9,"text":"And you'll see on the left hand side, you'll see user interface. And then we've set the blend mode to translucent. So make sure those two options are set. We have a scalar parameter in here called temp or in this image temperature. So we just hold down the number one key and left click. Or you can add a const one node, but number one and left click will give you this. And then just right click, convert to a parameter and call it either temperature or temp."},{"start":"7:17","end":"7:49","startSec":437.2,"text":"Just remember what you call this for later on. And then everything else, we've got two linear interpolates here. We've got a subtract and we've got an add node. To get these two color nodes, this is a const three. So you can hold down three and left click on your keyboard. And then just pick two different colors there. So we have our texture sample. You can select it in the content browser and then press T in here and left click. And that will create a texture sample. And because you've got it selected in your content browser,"},{"start":"7:49","end":"8:20","startSec":469.9,"text":"it will automatically assign the texture that you had imported on the previous slide. If not, you can drag and drop this texture sample from the content browser into here. Or you can create an empty texture sample, click on the node. And then on the left hand details panel, you'll see what texture to use. And you just want to plug that in from the content browser. And so here's a larger image of that if you want to see it up close. So what we have here is we have the multiplier of the red and blue channels by their respective colors."},{"start":"8:20","end":"8:53","startSec":500.1,"text":"We have the lerp based on the scalar parameter, which is this temperature that we had. And we just name this temperature. Then the opacity from the texture sample goes straight into the opacity of the material input. And then what we want to do is we want to save the material and close it. And then if we right click on this material that we've created, so you'll see this material in the content browser, you'll see the map. What you want to do is you want to right click on this map and create instance from material."},{"start":"8:53","end":"9:28","startSec":533.7,"text":"So I'll just jump into the editor and show you that. So if I have my material here, I can just right click create material instance. And then this type of material will now pop up, which you can see is the instance version of this. And by default, you should see the details panel selected in the top left. If you have any other windows open, just make sure that the parent material is in the hot and cold material and our temperature parameter is here. And we can actually just click that temperature and we can now change this temperature."},{"start":"9:28","end":"9:59","startSec":568.0,"text":"So you can see our material when working is dialing between this cold to hot. And if we just snap from zero to one, we can see that our material is changing. So that's the result of the parameter that you want to achieve with your material and then subsequently material instance. Next up, we want to create the display vehicle material. So in this, we'll be using some parameters, LURPS, PANNERS, and the Saturate and Clamp node."},{"start":"10:00","end":"10:31","startSec":600.4,"text":"But we'll apply this to the car model in the viewport. And again, we'll go through step by step how we go about creating this. So we have metallic and roughness. Again, hold down number one on your keyboard to create these boxes. Your nodes, these constants values may look a little bit different depending on what version of Unreal Engine you're using. In the more recent versions, you'll see a little value number inside this const one, but the functionality will be the same."},{"start":"10:31","end":"11:04","startSec":631.9,"text":"So metallic to one, roughness 2.5 there. And then we want to display three vectors. So hold down number three on the keyboard and go from the gray to the green to the red. And essentially, as the temperature value goes up, we want the wing color to change from blue to red. So that's essentially what we're doing here. And we again want that parameter. If we hold down number one on the keyboard, left click and go to temp,"},{"start":"11:05","end":"11:37","startSec":665.2,"text":"and then right click and convert it to a parameter just to name it that temperature value there as you did on the last material. The display material is going to be a little bit different than what you saw on our previous material. So nothing to be too worried about here if we just set it up step by step. So the local position provides the meshes local x and y directions. And then the divide mask adjust to shape it and resize it for the model."},{"start":"11:37","end":"12:11","startSec":697.5,"text":"So you can change the divide amount as needed for the size of your vehicle. The airspeed is a parameter. So again, just left click holding down number one and convert it to a parameter and name that airspeed. Now, it's important to note when calling parameters with two words like this, airspeed and even band frequency here, if you capitalize the letter without a space in when you go to edit the parameter, it will have a space there because you've gone from a lowercase letter to an uppercase letter."},{"start":"12:11","end":"12:47","startSec":731.6,"text":"So Unreal Engine detects that and creates a space in the actual user facing parameter settings. So that's just a really nice way. You shouldn't really add spaces to parameter names. It's not a terrible thing to do, but it's just a good practice to get into. It comes from more of the coding language side. So the airspeed is a parameter that we can drive up and down through the UI later. So it's important to add that. And make sure to give the panner an x or y value of one,"},{"start":"12:47","end":"13:19","startSec":767.1,"text":"depending on the direction that the car is facing or it won't move at all. A component mask here allows us to cut out the color channels and output what's left. So if you mask a basic coordinate, G creates a top bottom gradient and R creates a left right gradient. So if you want a top bottom gradient, use your green channel, G channel. And then if you want to use the R channel, that will create a left right gradient. And then we've got a multiply. You can hold down M on the keyboard for multiply."},{"start":"13:19","end":"13:50","startSec":799.4,"text":"And then sine provides a repeating wave pattern. So then we just want to clamp that at the end there. You can also go from sine to a saturate node if you want. That makes things a little bit cleaner. So you can drag off and do saturate. So you can either clamp or saturate there. And then we just want to make sure all the connections are hooked up there. So this is a series of nodes that we hooked in there. We've done our roughness and metallic values. And then we've got our color controls here."},{"start":"13:51","end":"14:23","startSec":831.4,"text":"And then as before, we have our master material. So you can right click on that material, select create material instance, and then just name it some version of what you called the master material, underscore instance. Unreal Engine will automatically add the underscore inst, but just name it whatever naming convention is consistent to your project. And then you can just tick these parameters and just alter them and see, have a play around with the material, get a feel for what it is actually doing inside the material editor,"},{"start":"14:23","end":"14:26","startSec":863.2,"text":"and then we'll be able to apply it to our blueprint."}],"03_VehicleDisplayBlueprint_5.00":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Now let's talk about the vehicle display blueprint and how to create a controllable scene. So first thing we want to do is assign the material to the car mesh. So open up the display vehicle blueprint by double clicking it in your content browser and then just select the vehicle mesh on the top left and then plug in the material by pressing that little arrow there. And that will essentially assign the material that you've just created to the blueprint."},{"start":"0:31","end":"1:03","startSec":31.9,"text":"Next up we'll create a display vehicle blueprint in the construction script here. So whatever element we plugged our material into we can create a material instance based on that index. So if you ended up plugging in your material just into element 0 which was the same for me on the previous slide so if I just go back to the previous slide I've got material element 0 on my car. If you've got a different material element so say it's on number 1 or number 2 which"},{"start":"1:03","end":"1:34","startSec":63.8,"text":"gives you the overall vehicle you need to just make sure this element is updated. So I'll jump into my editor and show you how to do that. So with my blueprint open I will go to construction script at the top here. I will bring in my vehicle mesh so I'm just going to hold down left click and drag out the vehicle mesh from the component list and then I'm going to create a dynamic material instance. So create dynamic material instance."},{"start":"1:34","end":"2:05","startSec":94.5,"text":"Again element 0 is going to be my element so just make sure whatever element you've plugged your material into so if I plugged my material into a different element say the chassis or the tyre something like this you would update this number inside the blueprint. So just make sure that you have in the construction script the correct element for your vehicle selected and then what you can do is you can just drag off here and promote this to a variable."},{"start":"2:05","end":"2:38","startSec":125.7,"text":"So drag off the blueprint promote to a variable and call this let's call this I generally go with the naming convention mi underscore car material but you can name this whatever you would like. So that's just created an instance here which we can use later in the tutorial but essentially this is the main setup. Now you can override the source material here if you would like because the vehicle has"},{"start":"2:38","end":"3:10","startSec":159.0,"text":"got the material already assigned you don't necessarily need to plug it in but I mean even as a backup if you browsed to the material and then plugged it in there that would also work completely fine. So you can plug in them just as a backup just to make sure the correct material is assigned but because the vehicle mesh already has it assigned you should be okay without plugging that in there. Next up we're going to add a scalar parameter to the variable that we just created so we"},{"start":"3:10","end":"3:42","startSec":190.5,"text":"want to create two new variables which are two float variables one called display airspeed and again you'll see that we are capitalizing each letter and there's no space in the name but you'll see Unreal Engine creates a space which is really nice and readable and it also means that we have a nice condensed variable name. So we've got display airspeed and airspeed total time with this kind of setup I'll jump into my editor now and show you exactly how to do this but this is the overview if you want to move forward into the next section."},{"start":"3:42","end":"4:15","startSec":222.9,"text":"So inside of Unreal here I'm just going to go to my variables tab I'm going to create the plus here and we'll call the first one display airspeed and then what we'll do we'll change the variable type on the top right to a float so we'll call that a float so it needs to be that green icon there and then we'll press plus again and this one needs to be called airspeed total time like that and again you'll see that I'm not putting"},{"start":"4:15","end":"4:52","startSec":255.1,"text":"spaces in my variable names and because I just create a float it creates another float again which is handy so I'm just going to compile and save just to make sure everything's okay. So when I'm dragging out variables I'm going to hold down control on my keyboard and left mouse drag so it does that. If I just left mouse drag this out without holding down control I get the option do I want to get the variable which is what this is or do I want to set the variable which is what this is. If I hold down alt and left mouse drag I get the set so it can be a few less button clicks"},{"start":"4:52","end":"5:22","startSec":292.8,"text":"if you hold down control on your keyboard and drag to get if you hold down alt on your keyboard to set alternative if I didn't hold down anything on my keyboard I would get the option get and set so completely up to you what methods you use there but essentially if I just delete these I want to get the display airspeed so I want that and so from the delta seconds I just want to multiply this so I'm going to multiply this by pressing the star"},{"start":"5:23","end":"5:59","startSec":323.1,"text":"key you can alternatively just type multiply and I need to add a additional pin here from the previous slide the bottom value is going to be 0.1 and I'm going to plug the airspeed into here so you should have something like this this is a multiply going into the display airspeed and then what we'll do is we'll add so I'm just going to press plus or you can type add onto here and we want to get the airspeed total time so I'm holding down control on my keyboard left mouse dragging so we get this kind of setup here next we want to set"},{"start":"5:59","end":"6:36","startSec":359.8,"text":"the total time so I'm going to hold alt on my keyboard left mouse drag and let's just plug that into there so essentially now we've got the variable that we need and now we just need to set the correct scale parameter on the material so you don't need to click here but on the construction script we've got this material now where we can edit parameters based on the material that we created so if I again you don't need to do this but I'm just going to go and find this in my content browser if I pin this up here I'm going to open up the material and what"},{"start":"6:36","end":"7:08","startSec":396.0,"text":"I'm looking for is I'm looking for airspeed so you'll see that I have this airspeed value here and this is the parameter that I want to edit so you'll see airspeed there so I'm just going to go back into my blueprint so you should be here by now if you didn't follow me down that little rabbit hole I'm going to stay in my edit graph I'm going to get my material instance so I'm going to ctrl drag out the material that I created again whatever you named this in your"},{"start":"7:08","end":"7:41","startSec":428.2,"text":"construction script this is what you're dragging out from the left-hand side I'm going to drag out the blue pin and say set scalar parameter value and then I'm just going to drag this out into here and then the value is going to be from this airspeed total time so you can just drag it into there sometimes I like to double click on the wire and add a little reroute node alternatively you could just if you don't want wires there do this as well and that would keep"},{"start":"7:41","end":"8:14","startSec":461.1,"text":"it equally as nice and clean and tidy so the parameter name here as I mentioned is airspeed and again that airspeed value is just from what we put in our material so whatever you named that in your material just type in airspeed there and then compile and save and we can move on to the next section lastly in this section we just want to create a new function which again I'll jump into the editor and do and so you can follow it step by step but if you know how to create functions we just want to create a set scalar parameter value and make sure the parameter whatever we"},{"start":"8:14","end":"8:46","startSec":494.7,"text":"named it whether we named it temperature or temp or whatever you called that parameter in your material that's essentially what we want to do so we'll send the value to the temp parameter in the material so let's jump into unreal and break that down for the function so back in our editor we can see that we've got a function section on the left on the side so I'm just going to click plus function and I'm going to say set temp again using lower and upper case letters to"},{"start":"8:46","end":"9:20","startSec":526.6,"text":"differentiate between sets and temp so there's no space here but because I capitalized a T that's now got a space I'll compile and save just to make sure I always just get into the habit of compiling and saving as you go so what we want to do here is we want to set a scalar parameter value based on the material so let's drag out our material again holding down ctrl I'm going to set scalar parameter by value and if we look at our material again you'll see that we've got this temp here so"},{"start":"9:20","end":"9:55","startSec":560.0,"text":"whatever you called this a value whether you call it temperature or temp this is what we're looking for here so I'm going to type in temp also a good practice is sometimes if you've got complex material parameter names I just click and then click again so it highlights you're going into the rename you can also hit f2 to rename but I'm going to copy that text paste it in there now it's quite hard to get temp wrong but if you have complex parameter names sometimes it's good practice to copy and paste the values in so you know that that's definitely working I'm gonna drag this"},{"start":"9:55","end":"10:22","startSec":595.1,"text":"variable in here now now what I'm going to do is I'm actually going to do a bit of a shortcut here so I'm going to get this value I'm going to drag it into here and it creates a new node so if you drag it into there it creates a new value I'm actually going to call this value temperature let's see if I can just disconnect this compile save let's try and call it temperature now"},{"start":"10:25","end":"10:57","startSec":625.6,"text":"so maybe that's not a shortcut maybe this works in yours this has always historically worked for me maybe doesn't work for some reason but I'm just gonna compile and save I've deleted the input let's go back to do it the old-fashioned way so I'm gonna select set temperature I'm going to go to input I'm going to press new input I'm going to type temperature wow it's not working okay this is super interesting let's call it temp okay so temp seemed to work so maybe it just"},{"start":"10:57","end":"11:31","startSec":657.2,"text":"doesn't like a certain variable I'm not sure why that is you should be able to type temperature but if you can let's go with temp which is a good temp name for this let's drop down to make sure it's a float and now we got our temperature input let's compile save and what I need to do now is I need to divide this so let's go to the the forward slash key for divide or we can type in divide here and we just want to divide this variable let's go like that and we just want to divide this by"},{"start":"11:31","end":"11:38","startSec":691.3,"text":"100 so plug in divide by 100 and then compile and save and that is your function created"}],"04_UMGMaterials_5.00":[{"start":"0:00","end":"0:39","startSec":0.0,"text":"Next up, let's talk about how we communicate between UMG and materials. So we want to go back into our widget display from a previous class. We want to open the right menu display widget and we'll be upgrading these new icons here. So this is what you'll probably see on the right display menu from a previous tutorial where we've had the temperature, airspeed, car speed and light. All we want to do is add a horizontal box to the bottom, add the text, which is something along the lines of the current temperature to 72 degrees,"},{"start":"0:39","end":"1:14","startSec":39.4,"text":"and then the image, which is the temp image. And then when we want, we change the brush to an image as you've done previously, and set the hot and cold material instance, which we created at the start of the tutorial here. So you can tweak those visuals to whatever you'd like. The visuals don't so much matter as much as the actual functionality. Of course, the visuals are important for the user experience. But for today's functionality and purposes, we'll talk about blueprinting."},{"start":"1:14","end":"1:48","startSec":74.1,"text":"So these are the three sections that we're going to be creating. So again, we'll jump into the editor to show you exactly what's going on here. But based on the previous variable creation, you should get a pretty good feel about what we're going to be doing here. So we've got three sections, which is the pre construct. We've got the air slider and we've got the temp slider. We will create two functions called update text and update image. And then we'll use three variables, which is the UI, the airspeed flow, and then also the display reference, which is the vehicle blueprint."},{"start":"1:48","end":"2:18","startSec":108.7,"text":"So let's jump in and break those down for you. So in our editor, let's create all of our variables that we'll need. So we'll go to create a new variable and we'll create a material reference variable. So material ref and this will be our material instance, which will be a sign in. So let's just go ahead and change this to material. And we'll just hit material there and then also object reference."},{"start":"2:18","end":"2:51","startSec":138.8,"text":"So that's our material. And then we want to create a new variable and this will be display vehicle reference. And if I spell vehicle correctly, vehicle compile and save just to make sure. And then we'll do the display vehicle. And you'll notice that we can get a reference to our blueprint here. So display vehicle and that'll be an object reference."},{"start":"2:51","end":"3:25","startSec":171.2,"text":"Let's make sure we begin to categorize these because as you can see, there's a lot of variables going on now. So you can actually select one, go to category and let's type in reference here. So we've got a reference and then material reference. We can now select it, drop down. And from this drop down, you'll see references now an option. So we've got our two reference variables. Now let's create our three float values that we said we wanted. So we've got temp UI, which again is a float value."},{"start":"3:25","end":"4:00","startSec":205.2,"text":"We've got airspeed UI. Speed UI. And then we've got our vehicle speed UI. There we go. Let's categorize these as well. So let's call these user input. So I do put a space on that category name as well."},{"start":"4:00","end":"4:33","startSec":240.2,"text":"Just so that's like that. So we've got five variables created. The categories don't so much matter as the material, the display vehicle. Make sure these variables are the variable type. And then we've got the three UI elements there. So let's start off with the pre construct. And so let's just right click, event, pre construct. So we'll select that and we'll go to a sequence. And a sequence essentially just fires a series of actions in order."},{"start":"4:33","end":"5:04","startSec":273.4,"text":"We'll go zero one and then you can add more to the pins if you want. But for this purpose, we don't need that. So I'm just going to compile, save. And then we'll get the material image, dynamic material of the temp image that we have. So we have our temp image here, which is a variable that has previously been created in the tutorial. So we'll hold down Control and we'll get dynamic material from this."},{"start":"5:04","end":"5:35","startSec":304.8,"text":"And we'll drag that out there. And then we'll set this as our material reference. I'm going to hold down Shift and Alt, sorry, and drag. Material instance. Oh, so this is a dynamic material instance. So I'm just going to delete this. I'm going to compile, save. And what we'll do is we'll change this from material to material instance. So we need a material instance up there instead. So let's go object type. Let's see now hold down Alt and drag out there."},{"start":"5:35","end":"6:06","startSec":335.9,"text":"And that plugs in nicely to there. So you just want to make sure you change that from material instance. Compile and save. We'll just keep compiling and saving as we go. And then next we want to get actor of class. So get actor of class. And we want to get the display vehicle from here. Display vehicle. And we can hold down Alt and drag and just drag that into there."},{"start":"6:06","end":"6:38","startSec":366.2,"text":"So something like that. Compile, save. Then we move on to the next section. So we want to update the air speed based on the variable that we created before. So let's right click, air spin. Let's see, we want to get the value change on the air spin box. So let's try air speed. Let's do on value changed."},{"start":"6:38","end":"7:10","startSec":398.5,"text":"So let's get on value changed here. So that's there. So we'll get the air speed UI. We'll drag out this holding down Alt. Left mouse drag there. And we'll get the, we'll set the air speed UI first of all based on that slider. So that's correct. And then we want to actually get the vehicle display reference from here. So I'm just going to hold down control and get this. Now you can actually right click these."},{"start":"7:10","end":"7:44","startSec":431.0,"text":"And if you just right click on the actual text, you can convert to a valid get. Now, the reason why we do this is we want to make sure that this vehicle exists. If for whatever reason you have this value on a slider and the vehicle does not exist in the game, in the scene, sorry, the, it potentially just crashed the application. So we want to, by getting a valid reference of the vehicle, it ensures that that vehicle does exist."},{"start":"7:44","end":"8:17","startSec":464.7,"text":"So we want to drag off the vehicle and we want to type in display and we want to set display air speed. So we'll set this. And this was a vehicle, a variable that we created on the vehicle previously. So if it's valid, we want to set the variable and that can just be dragged in through there. So that's essentially that. We'll save, compile, move on to the next section. Now we want to do the temperature slider because we create a temp UI slider there. So let's get the temperature slider again."},{"start":"8:17","end":"8:49","startSec":497.5,"text":"Let's do on value changed. So left click on value changed. Now we, first of all, on the value change and we want to, like we did with the speed UI, let's do the temp UI. So let's hold down alt, left mouse drag. So we'll set that up like this. And then we just want to make sure the temperature is set on the vehicle. And that's the function that we created before. So let's get a reference to the vehicle. And now when we drag out the vehicle, we'll type in set temp."},{"start":"8:49","end":"9:20","startSec":529.1,"text":"And that's essentially the function that we created. If you recall from the vehicle, we create this set temp function here. And that's exactly what we're calling here. So in a hood, we want to go back there and we just want to plug in that value there. So we have something like that. And then in the material reference, so we want to grab the material reference. We want to set the scalar parameter value set. Let's see."},{"start":"9:20","end":"9:55","startSec":560.0,"text":"Parameter. Let's see what's available to us. So we want to. We definitely want to set a scalar parameter. Let's see where that's at. Let's just move on from that for a second, because we definitely want to set a material instance. But let's just keep going with the set text of the actual UI. So we want to find the text of the UI, which as we created before,"},{"start":"9:55","end":"10:26","startSec":595.2,"text":"we've got the temperature here. So we just want to make sure that this is a variable of some form. And now we can go to the graph. We want to then, was that the temp display? Yep, temp display text. So we've got that. And then we want to set the text. So set text. We've got that. And then to get the actual text, we want to, first of all, get the temperature UI, which"},{"start":"10:26","end":"10:57","startSec":626.7,"text":"is the value that we've just created. We want to get the mid-range. There we go. And we want to set that as 100. And then we want to round up. So we'll do seal. And then we can actually then put that to the temperature."},{"start":"10:57","end":"11:27","startSec":657.7,"text":"So we can then go to format this text, format text. Let's give ourselves a bit more space here. Move this back. So what we want to do is we essentially want to format the text like temperature. So we have the temperature here, but we want to pull in this value. So what you can do is you can do the squiggly brackets. So hold down Shift and bracket on your keyboard. So Shift bracket. Let's do a temp like this."},{"start":"11:27","end":"12:00","startSec":687.9,"text":"And then because we got these two brackets, we now get temp here. And then we can format the text like that. And our two values on the range A are 60 and 95 there. So that's essentially how we format the text. Now we need to figure out how to actually set the scalar parameter value, as that doesn't seem to be working correctly. So let's just go ahead and maybe even create that material instance again. So I'm just going to delete the material reference."},{"start":"12:00","end":"12:31","startSec":720.5,"text":"I'm going to delete this material reference. And then I'll delete that material reference. I'm going to compile and save. And let's just try creating this material again. So promote variable material inst ref, or something like this. Let's try that. I'm going to compile, save. And let's see if this now updates. I'm going to hold down Control off my new material ref. Set scalar. OK, so it's got a parameter value now."},{"start":"12:31","end":"13:07","startSec":751.1,"text":"So it must just be the way we'd created our material instance before. So I've just created a new material reference. Just dragging off here, promote to variable, call that a new variable. We'll make sure we put it back into that references category as well. So that's there. And then we can just drag this out here. So yeah, it must just have been the way we created our material instance. So let's just slot that in there. And then let's call that temperature, or whatever you named in the material,"},{"start":"13:07","end":"13:38","startSec":787.4,"text":"temp. So actually, let's call this temp. So if you named yours temperature, call it temperature. And in my temp, so we've got temp. And then the value can just be the temp UI. So let's get the temp UI again. So I'm just going to copy and paste. I'm going to divide this by 100. So again, using that divide sign, or you can type in divide. And then we'll again do this by 100 as we did before."},{"start":"13:38","end":"14:08","startSec":818.1,"text":"And then we'll clamp the flow. So clamp float. And then the min and max at 1 is fine. So then we'll just do that. So we want a value between 0 and 1 going out to the temp. So we'll compile and save. And that's the setup for the temp slider. Let's just start commenting these. I can select everything. And we can hit C. And we can do temp slider functionality,"},{"start":"14:08","end":"14:39","startSec":848.6,"text":"or whatever you want to call it, really. But holding down C, pressing C, sorry, when you have certain nodes selected, let's say air speed functionality, you can just comment things. This is purely for aesthetic purposes and organization purposes. You can move the box around. You can change the colors if you want. Sometimes I like to drop the alpha a little bit just to make that functionality stand out. Whatever you'd like to do there, you can change the font size."},{"start":"14:39","end":"15:10","startSec":880.0,"text":"You can even copy the color and then paste the color if you want. Purely aesthetic reasons. So that's that. So I'm going to compile, save, move on to the next section. And then the last variable that we've not used yet is this car speed UI. So let's go ahead and just add that. So we essentially want the speed. So the speed slider on value changed. I think I might have already set this up previously."},{"start":"15:10","end":"15:30","startSec":910.2,"text":"But this is what you need here. So let's just drag this down here. I'll just recreate it so you know exactly what's going on. Let me compile and save. So car speed slider, we want the on value changed here. And then we've just got the car speed UI holding down Alt, left mouse dragging, just making sure all that's plugged in like that."}],"05_3DUMG_5.00":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Let's just finish out this tutorial by creating a quite a quick 3D UMG widget which creates some kind of stylized display in the world. So we'll create a new 3D widget which I'll jump into my editor here and show you and essentially we can just render the speed of the UMG in the actual world so we can see the speed changing to reflect the UI. So in the editor here just right click, user interface and the widget blueprint selected."},{"start":"0:34","end":"1:08","startSec":34.3,"text":"I've called this 3D display menu. So if I open this up you'll see that we have the canvas panel in place, we have just a background color which you can see here width and height is 200 and then we've also got some kind of bar here which I've bound to a progress bar which I will dig into in a second here and we've also got the speed text which is the vehicle display which again will bound to a set text functionality which again we'll go over in a second here."},{"start":"1:08","end":"1:40","startSec":68.1,"text":"Now the actual styling doesn't matter so much something along the lines of some text and a bar is good here, a progress bar and if we go into our vehicle blueprint now you can see that we've got this 3D widget component. So we can actually go to add and we can go to widget and you can actually add a widget into your blueprint and the widget class is going to be that 3D display widget."},{"start":"1:40","end":"2:12","startSec":100.2,"text":"So you can see here if I just delete this empty one now you'll see that this 3D widget just has a location and a rotation kind of moved it out. We've got the widget class set here so now when you actually go into the map you can see this widget displayed in real time which is really nice if you want some kind of visualization that's actually presented in the scene rather than just 2D on the user interface. So go ahead and compile and save and let's look at the blueprinting involved in this"},{"start":"2:12","end":"2:48","startSec":132.9,"text":"display menu. So first of all we want to use pre-construct again so we've got our pre-construct if you just right click enter pre-construct and then we want to right click get player controller, drag off the blue player controller and display controller and then the display controller we want to get the hood reference and then we want to get the input UMG promote that to a variable set that as the input UMG reference so input UMG you just want to set that there."},{"start":"2:48","end":"3:19","startSec":168.2,"text":"And then on the actual function side so when we've added functions we've got the speed bar which if we go back into the designer the speed bar we want to create a binding called speed bar and if I go back into here let's see what's going on. So we've got the input reference so we drag off here holding down control drag off we've got the car speed UI which is what we've created previously and you can just return that node"},{"start":"3:19","end":"3:54","startSec":199.5,"text":"there and then the set text in a similar way we can go to the set text we've got a bound event here so set text is our binding and essentially what we're doing in this function is we're getting the UMG again so drag out here we're getting our car speed UI we've got our map range clamped at 0 to 1 and then 0 to 150 on the out range and then we want to floor that value and in a similar way as we formatted the speed before if you drag out here type format text you"},{"start":"3:54","end":"4:28","startSec":234.5,"text":"want to type in speed and then add value in this the swirly brackets and then that will give you a value input which you can plug in that floor value there so that's essentially what we've got going on quick overview of a little UMG widget but hopefully that gives you an idea about is a similar functionality if we've done previously but instead of it being on the 2d interface we've now got this 3d widget which if we jump into the map now just check out what's going on if I just full screen"},{"start":"4:28","end":"4:58","startSec":268.4,"text":"this and press Alt and P you'll see that we've got our value in here we've got the car speed going up and down so you can see that that value changing and then the things that we've done before you'll see the airspeed changing and then also the temperature change in there so we've got some nice basic UMG functionality going on here again the styling could change but the main thing"},{"start":"4:58","end":"5:06","startSec":298.6,"text":"is that we've learned how to communicate between UMG and blueprints so let's go ahead and close out this tutorial in the next video"}],"06_ThankYou_5.00":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"So thank you for checking out today's tutorial. We've learned a lot about communicating between blueprints and UMG, talking about materials and material instances, talking about how to change parameters and variables based on certain inputs via blueprint, and then we've learned how to communicate between the both of those. So hopefully it's given you some good directions of working, learn how to create customization for your own projects."},{"start":"0:30","end":"0:32","startSec":30.1,"text":"So thanks again for watching and we'll see you in the next video."}]},"227.07":{"01_Overview_5.00":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hello and welcome to today's Unreal Engine training on the UMG fundamentals for HMI, where we're talking about lights and cameras. So we'll be talking about some fundamentals of UMG, of course, by setting up a blueprint and then diving into UMG and creating toggleable options via UMG, which is Unreal Engine Motion Graphics. So UMG stands for Unreal Motion Graphics. And then we'll set up some basic lights and cameras within that blueprint so you can have some interactivity in your scene. So let's jump in."}],"02_UMGFundamentals_5.00":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"As a quick introduction to the section, let's talk about what Unreal Motion graphics are and what we expect to see as the outcome today. So you'll see we have a scene here. The UMG elements are this UI element on the left, this UI element on the right, and then the top. And the top area is what we'll be focusing on today. So we have a little button here that we'll use to cycle through some cameras. You can see in this top image we have a few cameras up here which we'll cycle between so we can get different angles of the car. And then we'll also click this light button to turn the headlights on and off."},{"start":"0:34","end":"1:05","startSec":34.0,"text":"So that's essentially what we'll be covering in today's course. We'll talk about extending the UI, creating the change of cameras, and also toggling these lights on and off. So let's get stuck into the blueprint. Starting off with setting up the blueprint. The things we'll want to do, we'll want to find this car blueprint which is called Display Vehicle. I'll be jumping into my editor in a second here to show you exactly what I'm doing. But I'm finding this Display Vehicle blueprint which you can see here. And then we'll be adding a scene component which is the holder for the light."},{"start":"1:05","end":"1:37","startSec":65.0,"text":"And then we'll place two spotlights on this vehicle which will be movable because of the dynamically lit nature. We'll put them in the front headlights and then we'll be accessing these in UMG later on. So I'll jump into my editor here. And you can see that the scene starts out with this vehicle in the middle here. I'm just going to hit Ctrl and B on my keyboard. So pressing Ctrl and B actually navigates to the blueprint in the browser. You can do this for any of the actors in the scene. If you've got other things placed in there, you can just press Ctrl and B."},{"start":"1:37","end":"2:07","startSec":97.0,"text":"If you had any static meshes or anything that belongs in the content browser, hitting Ctrl and B will find that in the browser. And then we can actually double click that and open it up. You can also just click Edit in Blueprint here if you want to directly open the blueprint. But I always like to go from the content browser. So I'll double click that and then it'll load up. And I just like to pin my blueprint to the top of the screen here just so I can toggle between the two. We'll see that we can go to our event graph at the top."},{"start":"2:07","end":"2:37","startSec":127.0,"text":"Actually the viewport is what we want because we're adding the headlights. So we'll click on the viewport and you'll see that we have the front of the vehicle here and we just want to add two headlights here. So as mentioned, I'm just going to go to Add and then Scene. And this is essentially just an empty actor. You see that it's not got anything assigned to it. But I'm just going to rename this Light Holder like this. And I'll maybe just move it out. The location doesn't really matter too much."},{"start":"2:37","end":"3:09","startSec":157.0,"text":"But essentially we're just going to child two lights from this light holder so that when we move the light holder, the two spotlights would move with it. So I'm just going to add and I'm just going to type Spot here and then I'll click Add Spotlight. And because I had this light holder selected, the spotlight has now childed to this. If you didn't have it selected, you can go in and re-child things. So if I just added it here, for example, if you came in with it like this, you could just get this spotlight and go to your light holder there."},{"start":"3:09","end":"3:40","startSec":189.0,"text":"And then you could just re-child it. I just dragged and dropped that asset. So we won't try to make things look too pretty today. We're just going mainly for functionality. But you'll see that I'm kind of roughly moving this into place. Maybe I want to drop my grid down here to get it even more in line with the headlight. You could even just toggle the grid off if you wanted just to really dial in those values. But essentially we've got the spotlight here. I'm just going to rename this. So right click, Rename."},{"start":"3:40","end":"4:11","startSec":220.0,"text":"And I'm going to call this Spotlight. I'll call this L because I'm going to name it from the front of, well, from looking out at the vehicle. So I'm just going to name this L. And then what I'm going to do is I'm going to right click. I'm going to duplicate. And before we click off that, I'm just going to rename that. You can just again, just right click, Rename. Or you can actually hit the F2 key to rename that. So I'm going to select the right hand headlight here."},{"start":"4:11","end":"4:44","startSec":251.0,"text":"I'm just going to move this into position. Again, maybe just toggling off this grid just for the time being just to dial it in. And then we've got our two lights. So I'm just going to compile and save. I'll go back into my map and we can see that the headlights are casting some kind of light here. We could dial in these values if we wanted to. You could either make them a lot brighter. So if I raise the intensity there and compiled it, you can see that this headlight is brighter than the other. You'll of course want two consistent intensity headlights."},{"start":"4:44","end":"5:15","startSec":284.0,"text":"So what I might do is I might copy this once I'm really happy with the value there. I'm just going to right click and paste that value there. So it's the exact same value. You can just copy the actual value and paste it. Again, you can dial in the color of the LEDs on the headlights, whatever you'd like to do there. But that's essentially our setup. Once you've dialed in the values that you want for these lights, essentially we just want to be able to see them so that we know when they're toggling on and off. So once we can see that, we can move on to the next section."}],"03_UMGpt2_5.00":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Now that we've got our car set up, let's go ahead and look at adding the light and camera controls to the UMG. So we'll jump back into the editor here. We want to now create a new UMG for this toggling on and off the lights. So we'll go to our UMG folder down underneath the blueprints folder. You can see that we've got our display widget from the top and you'll see that we've got some panel widgets here, but we've got the the HUD UMG, which is the main element. And if I, you don't need to go ahead and double click this, but if you look, we've got the"},{"start":"0:31","end":"1:07","startSec":31.2,"text":"individual panel UMGs here that were created outside of this UMG here, this left and right panel, these left and right panels here. So what we'll do is if I just close this again, I'll create a new panel here to add to the main UMG HUD. So we can just go right click, user interface, widget blueprint, and we'll just select user widget here. And you could call this light cam underscore UMG, some kind of naming convention that makes"},{"start":"1:07","end":"1:40","startSec":67.1,"text":"sense to you for what the purpose is. Again, just underscore UMG is good at the end there because then that kind of tags the asset type as well. So I'm just going to double click this open. The size is just as desired, but what we would want is a size box to make sure that once we've got the desired size, we can add everything in there. So I'm just going to type size box at the top, size box appears here. I'm just going to drag this here. So we've got a size box here and then we want to get a canvas panel underneath this size"},{"start":"1:40","end":"2:17","startSec":100.4,"text":"box next. So we'll get a canvas panel and there we go. So we've got the canvas panel and now what we can do is we can build the background image from this and then also have a horizontal box with the two different images that we want to add for both the light and the camera. So we've got the canvas panel here. We also want a horizontal box. So we'll add a horizontal box. So we've got this here and then you'll see this box here, which we can shape as desired."},{"start":"2:17","end":"2:52","startSec":137.5,"text":"Then we'll add a border for the images. So we want a border for here. So we'll type in border and then after border, we want an image. So again, it's kind of just stacking these things. Image if I can spell that correctly. So we've got image. We drag and drop the image down there. And so what we actually want for the image is the light icon. So we want to make sure we find this light icon in our content browser."},{"start":"2:52","end":"3:26","startSec":172.4,"text":"So I'm going to go back into my map here. I believe it might be in materials, textures. Yeah, so we've got our light on and off here. So this is what we want. So I think we want the icon background for this section here. So we'll pull that into the UMG, go to image, and then we just want to override the image, which should be in the brush setting here. And then we'll just plug that icon in there. And you can see that the sizing isn't quite correct yet, but let's just get all the functionality"},{"start":"3:26","end":"3:58","startSec":206.9,"text":"set up and then we can go into detailing everything. So we've got the icon there and we also want the camera button that we want to click to go through. So I'm just going to select this horizontal box. Again, just the ordering of these things needs to be specific. Of course, you can design it however you want, but the ordering for this example makes sense in the structure that we're following. So let's just go to the horizontal box and type a button now."},{"start":"3:58","end":"4:29","startSec":238.8,"text":"So I want to drag and drop a button onto the horizontal box. And now we've got a button here and now we want an image for the button. Now I'm just going to, because we've now got multiple things going on, I'm just going to start renaming things as well, just as I go. So button here, I'm going to right click and rename. Again, F2 can do that as well. And then I'm going to call this camera BTN for button."},{"start":"4:29","end":"5:00","startSec":269.1,"text":"Then the border here, we'll call this the light border. So I'm just going to rename this light border and then you want the light image here. So we'll just call this light image. So we need another icon for our camera button. So let's go in and add an image here. Let's go back to our content. And then we just want to select the arrow, go back into our UMG and then go to find an"},{"start":"5:00","end":"5:31","startSec":300.5,"text":"image. So image, drag and drop this over the button and the image is going to be like that. So as a quick summary, we should have something that looks like this. So we've created a new UMG. We've got the size box here, we've got the canvas panel and the background. So just making sure your structure looks something similar to this. So we'll go ahead and update the size in here. We'll make sure the icon is then the correct off light icon and then move to the next step."},{"start":"5:31","end":"6:05","startSec":331.3,"text":"So let's jump back in our editor. And first, we just want to make sure that we fill out the correct boxes. So we'll go to the camera button, click fill, and then also the light button and click fill. So we've got one to one sizing going on here. And then also the light image that we mentioned, we now just want to make sure this is the correct off light button. So let's just check that that's working. So that looks good. And then I think that's pretty much it."},{"start":"6:05","end":"6:37","startSec":365.5,"text":"So I think we can go ahead and save and move to the next section. So we'll just compile, save and then move to the next section. Two detailing settings that we need to do before moving on, which I just forgot about is if we go to our light border, we just want to go back into our content and add that background image here, the icon. So we'll go back into our UMG on the light border, we will just go down to our brush settings. So under appearance, brush, I will plug that in. So we have the nice looking background that we wanted."},{"start":"6:37","end":"7:10","startSec":397.7,"text":"And then also this camera icon just needs making a little bit bigger. So on image size under brush, we'll just go to 128. Maybe that can be 256 by 256. Always trying to keep power of two icons where possible. So I'm going for 256. Again, it depends on the size that you've gone for here. But we should essentially end up with something that looks a little bit like this. So again, the style doesn't need to be spot on. But again, just keeping in mind the hierarchy here and then some kind of visual representation."},{"start":"7:10","end":"7:44","startSec":430.6,"text":"We'll be moving on to the blueprints now, which is actually the main functionality. So this is all mainly aesthetic at the moment. But hopefully, your results should look something a little bit like this. So again, we'll compile and save and then move into the graph now. So if we go to the graph, you'll see that we have this pre construct node already in place. This is what we want to use for the display vehicle blueprints. So we'll drag out from pre construct. And what we'll do is we'll type in get all actors. And then we want to select this top option, get all actors of class."},{"start":"7:44","end":"8:14","startSec":464.5,"text":"And then what we'll do is on the class to select, we want to get that vehicle that's in our map, which is the display vehicle. So if I just find the display vehicle, I can do that. And then what I'll do is actually have created the array version here. So I'll actually get all actors of class, get actor of class. That's the one that I want. So get actor of class. So just get actor of class."},{"start":"8:14","end":"8:46","startSec":494.6,"text":"All actors will return an array, which would still give us a similar result. But because we know we've only got one in the scene, just make sure it's a get actor of class. And then what we'll do is we'll drag off this blue pin and promote it to a variable and just call it maybe display. And you can see on the left hand side here, I'm typing in the reference, but display vehicle ref something like that. I always add ref to the end of my actor references just to make sure I know that it's an actor reference, but there's some kind of name like that. You'll notice that I didn't put a space between display vehicle."},{"start":"8:46","end":"9:18","startSec":526.9,"text":"And because I gave vehicle a capital V and ref a capital R, you'll see that actually spaces the name, which is quite nice. You don't need to actually add a space into your reference variable reference name as long as it's got a capital letter. So that's just a nice, nice tip to move forward. So on construct, which essentially just means when we're making this UMG, I want to find this display vehicle again, just remembering to plug this display vehicle reference into there and then we want to get the reference."},{"start":"9:18","end":"9:50","startSec":558.5,"text":"So again, we'll compile and save whenever working with blueprints, especially just get into the habit of compiling and saving and then we'll move to the next section. And then what we can do is we can go back into our designer and we want to get the light border and what we want to do is we essentially want to know whether the light has been essentially edited. So we'll scroll down to the bottom here again, selecting our light border and we want to find the on button, button mouse down here."},{"start":"9:50","end":"10:21","startSec":590.2,"text":"So if we click bind, we can just create a binding here. You should have whatever you named your light border. If you named it light border, you should see on light border mouse button down and that's essentially what we're looking for. And we're just going to plug in some code here. I'm just going to left mouse, drag these pins. I'm going to hold down alt and left click on the executable just to break that pin. So I'm going to first create a new Boolean value. So under variables, I'll just add a new variable and we'll call this is light on."},{"start":"10:21","end":"10:55","startSec":621.9,"text":"So I normally put B at the start of my Boolean because then that indicates it's a Boolean and I'll put B is light on question mark. And then what I'll do is I'll hold down control on my keyboard and left mouse drag to actually get the variable. If you just don't click anything on your keyboard and left mouse drag, it'll ask you whether you want to get or set it. So you can also do it that way. This time I'm going to select set. So I'm going to drag that in and click set. Instead of holding down control to get, you can actually hold down alt to set."},{"start":"10:55","end":"11:29","startSec":655.7,"text":"So we need one get, one set, and there's multiple ways that you can add that. I'm going to drag this in here and I'm going to drag off this bool here and type not. So we want a not Boolean, which will be at the top here. So not Boolean. So is light not on? That's what I essentially want to know. Is the light not on? And then we can just plug that in there because it's just going to flip it essentially. If it's not on, it's going to be on. If it's on, it's going to be not on essentially. So next we want to get our display vehicle reference."},{"start":"11:29","end":"11:59","startSec":689.8,"text":"So I'm going to hold down control and drag in here. And then we created a scene component called light holder. I believe it was. Let's just check what we, what we name this in a vehicle. Yeah. Light holder. So what we want to do is we want to get the light holder. Let's just see where this is. If we childed it. Oh, let's see."},{"start":"11:59","end":"12:30","startSec":719.9,"text":"Let's see what we've got here. Default scene route. Let's see if we need to get the default scene route. Let's just make sure we're getting this correctly. So we've got our display vehicle. We've got our display vehicle ref. I'm just going to compile this. And go back to here. Let's check this out. So let's just remove any binding errors to our light board. Maybe I've gone in and selected a wrong button somewhere."},{"start":"12:30","end":"13:02","startSec":750.8,"text":"Next to brush, it's got an unbound value here. So I'm just going to, that shouldn't be on yours. I may have just clicked that by accident. Let's see. Now I can compile, save, light holder. Let's see. I think what may have happened here is if we look at this display vehicle reference, it's just actor. So if I go back into my designer here, back into my graph, I'll come out of this function into the event graph."},{"start":"13:02","end":"13:33","startSec":782.6,"text":"You'll see that this actor here. So that's not correct. So it should actually be display vehicle. I'm not sure why it's not done display vehicle. But what I'll do is I'll go back into my graph. Sorry for clicking around here. I'll go to my light board. I'm just going to delete this variable for now. I'll go back to my event graph. I'm going to delete this display vehicle. I'm going to delete it from here as well. Again, if yours says display vehicle there, that's the correct thing. So I'm just going to compile and save. And now I'm going to call this display vehicle."},{"start":"13:33","end":"14:04","startSec":813.6,"text":"I'll probably just give it a slightly different name. So I'm not going to add ref there. And I'm just going to set that. So you can see now that it's display vehicle. So that's strange that it was actor. Should be display vehicle. If yours was actor, definitely redo that. If it's display vehicle, then you've done it correctly. And we'll just compile and save. Now let's go back into our light boarder. Now let's grab our display vehicle by holding down Control. Now we should be able to find this light holder. So let's see. Now we've got light holder."},{"start":"14:04","end":"14:34","startSec":844.0,"text":"If we scroll down to the bottom, the variables are going to be at the bottom there. So get the light holder. That's what we want it to see. And we'll just set the visibility here. So set visibility. And because the lights are childhood to this scene, they'll take on the visibility command, which is a nice kind of clean way of doing it. If we hadn't added this scene route, so in our display vehicle, you don't need to flip back and forth, but I'm just showing you. If you see the scene component, we've got two lights added to this scene component."},{"start":"14:34","end":"15:05","startSec":874.5,"text":"So if we change the visibility here, it changes the visibility on any of the children, which is a nice little optimization. But we could have got spotlight R, got spotlight L, opposite way around, and then just set visibility on both. But because we do it on the scene route, it actually applies it globally, which is to its children, which is quite nice. So we've got this. We need to get our light boarder. So we didn't actually make it a variable before. So let's go back into our designer."},{"start":"15:05","end":"15:37","startSec":905.0,"text":"On our light boarder, we just want to select is variable at the top there. Again, compile, save, just getting to that habit of doing that. So is variable is now ticked. And so now we have the light boarder variable down here. Again, I'm holding down control on my keyboard. I'm gonna set the brush color here. So set brush color. And then with the brush color, I'm going to select. So I'm gonna drag off this blue pin here and type select."},{"start":"15:37","end":"16:08","startSec":937.0,"text":"So I want it to actually do a select color option here. So we've dragged off the darker blue pin, select, and then we'll just do like maybe a deeper gray color here, and then maybe a whiter color here or something like this. Just something that indicates a change of color. And then I'm gonna drag the Beers light on, holding down control and add that there. So it's just essentially gonna set the visibility and set the brush color there."},{"start":"16:08","end":"16:39","startSec":968.5,"text":"And we want to plug in the return node here. And then we want to right click and type in handled. So we just want to make sure it's been handled by the event reply. So we'll find this handled option here, and we'll just drag that into there. So that's essentially what we have set up. And now we want to compile and save, and then move on to the next section. Now we actually want to toggle the light image"},{"start":"16:39","end":"17:11","startSec":999.2,"text":"so we can change these icons. You know, these ones that we have here, light on and light off, that's what we want to actually now toggle. So I'm gonna go back into my UMG. I want to find my light image. So we go to our light image here, and now we want to bind the icon. So we want to create a binding here. So we actually want to set the light icon, sorry. So what we'll do instead of get image brush,"},{"start":"17:11","end":"17:42","startSec":1031.5,"text":"we'll just rename this over here. So I'm just gonna right click the get image brush. I'm gonna rename this to set light icon. Which makes way more sense as a variable name, as a function name. So essentially we want to set the icon base if the light is on. So let's hold down control and bring in this Boolean here. And then from the return value, what we want to do is we want to drag off and say,"},{"start":"17:42","end":"18:15","startSec":1062.9,"text":"make brush from texture, which is this bottom element here. Now, whatever values you used in the width and height, so let's just go back into the designer. Whatever size you used here, if it was 128, I've just got 32 here, which has filled out the space. But again, if you've set this to 128, like we did 256 here, whatever these X and Y values are, that's what we want to override here. So I'm just gonna go back into my graph."},{"start":"18:15","end":"18:45","startSec":1095.6,"text":"I'm going to name these 32, but if you've used 128, 256, et cetera, you can plug those in there. And then we just want to do another select, dragging off this texture section. And then you'll see that by default, this select does not have this Boolean connector here. But what we can actually do is if we just drag that into the green pin anyway, it'll change it to a Boolean. So that'll hook in nicely there. And then the false is going to be the light on icon."},{"start":"18:45","end":"19:18","startSec":1125.7,"text":"So let's go back into here, select light on in our content browser and plug that in there. And then true, if we go back into our browser, we'll select off and then go back into there and select that like that. Then compile and save. And that'll be our function for updating the texture on when we hover over it. Now we want to go back into our main UMG and add this light cam UMG or whatever we've referred to it. I'm just going to save everything just to make sure everything's up to date."},{"start":"19:18","end":"19:50","startSec":1158.3,"text":"I can go back into my UMG folder and I'm going to open the main hood UMG now. So these are all user created widgets. So we want to search the panel that we've created in this user widgets section. So you can see a light cam UMG, which is one I created, whatever you named your UMG, the one that we called here, update that. So if I just drag that down here, you'll see that I can move this"},{"start":"19:50","end":"20:21","startSec":1190.0,"text":"into the real estate that I want. Again, the sizing is probably a little bit too big here, but I can change that sizing and positioning. So I'm just going to move across this position and maybe bring it down a bit. Again, it's probably a little bit too big. We want to scale it down by 50% maybe, but that'll do for now. So I'll just make sure, I'm not sure if that impacts it, but I just want to make sure that box is covering it. I assume it's to detect the input there."},{"start":"20:21","end":"20:53","startSec":1221.8,"text":"So I'm just going to compile and save. And so at least we've now added it to our user creation menu. Now, once it's compiled and saved, if we just jump back into our map here and then just press Alt and P, you'll see that it comes up. You'll see that we've got some kind of hovering going on here. And if I click the light on off, you'll see that the light is going on and off. Now from that, I noticed that the lights weren't turning on and off and also the icon was back to front."},{"start":"20:53","end":"21:23","startSec":1253.3,"text":"So let's just jump in there and fix that. So under the Lightcam UMG, in the graph and then in our border mouse down function, we just want to make sure that visibility is the bull. So yeah, that's all correct. And then, yeah, so we just missed this bull here, propagate to children. So let's just make sure we go in and compile and save that and test it out. So when we click, okay, the lights are turning on and off now."},{"start":"21:23","end":"21:53","startSec":1283.7,"text":"And now obviously the icon is back to front based on that variable. So I'm just going to go ahead and change around those bullion values. So I'm going to go back into my UMG. I'm going to set light icon. What I might do is just say, not here. This is kind of a little cheat and you could technically switch around on and off together. But let's just see if this works because that'll be the quick way to do it. Yeah, so off, on, on, off."},{"start":"21:53","end":"21:57","startSec":1313.9,"text":"So there we go. Everything's working and now let's move on to our cameras."}],"04_Cameras_5.00":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"So here's our camera section for the UMG fundamentals. So let's see what we're trying to set up here. So we can have a series of cameras, as mentioned at the outset, that we'll have around the car, and then we'll just cycle through them. So the amount of cameras doesn't matter, but just place a few cameras around your scene looking at the car. So let's jump into Unreal and add those now. So I'll just go to my place actors, and we'll go to cameras, and we'll add a cine camera actor."},{"start":"0:31","end":"1:03","startSec":31.0,"text":"So I'm just going to move these around the scene and kind of look at the car. I'm going to change the world to local, so I can kind of rotate in. And you may want to change some lens settings here. You know, if you want some wider shots of the car, obviously the focal length may change in that respect. So just add a few cameras here. I'm just going to change the world to grid again. You just want some kind of nice wide shot."},{"start":"1:03","end":"1:35","startSec":63.0,"text":"So we don't, I'm not again going to be too focused on what these cameras are looking at, some kind of cool angles. Maybe, maybe I can't resist. Let's just get a nice low shot from the back there. Yeah, cool. Okay, enough with the cameras. We've got four cameras in the scene. Again, the number doesn't matter here. We essentially just want to create some kind of functionality to cycle through them. So we want to go back into our UMG."},{"start":"1:35","end":"2:08","startSec":95.0,"text":"Before that, I'm just going to save, save all before we continue. And then I'm going to jump into the UMG. So essentially the setup will be this in the UMG graph editor. So we're going to pre construct again, like we had last time, we're going to add a few materials here. We'll get the cameras, promote them to a variable. We've got an on clicked event. So we'll get the next camera and the pre construct event. We'll gather all the cameras, store them in a button press and do all the heavy lifting. So just to note that the order of the cameras is based on the order that I just place them in"},{"start":"2:08","end":"2:40","startSec":128.0,"text":"and what you place them in the scene. So the system doesn't number and label them. We could do that later on. But for the purposes of this scene, let's just go ahead and add the functionality that we need. So we'll jump back into the editor here and we'll jump into the light cam UMG. We'll go back into our event graph. And we've also, we've got this display vehicle here. So on the pre construct, what we want to do this time is get all actors of class. So the mistake that I made previously, this is now why we want all actors of class"},{"start":"2:40","end":"3:10","startSec":160.0,"text":"because it'll return an array and that'll give us a list of cameras. So we want Cine camera actor here. So I added Cine camera actors. If you just added a normal camera actor, you would just add camera actor. But from this map, I added a Cine camera actor. So that's what I'm looking for in this UMG. So again, compile and save, just get into the habit of that. And I'm going to drag off the array here, set. I'm going to call this list of cameras."},{"start":"3:10","end":"3:41","startSec":190.0,"text":"And you'll see that it has got Cine camera actor here as a variable type, which is what we want to see. Again, if it's turned to actor for some reason, it might just be because I hadn't assigned the actor class when I promoted the variable before. So you just want to make sure that that's all hooked in correctly. And now we want to add an event to the on clicked to the camera button. So let's go to the designer. Let's go to the camera button here. I'm going to scroll down. And if I have the camera button selected, on clicked is going to be there."},{"start":"3:41","end":"4:12","startSec":221.0,"text":"So I'm going to add on clicked here. And so we want first an integer. So I'm going to add a variable here and I'm going to call that integer current camera. Again, just capitalizing my letters. I'm going to go to the Boolean. Add an integer. And so that's an integer. So I'm going to get the integer and going to get it. And then I want to also set this integer as well. So holding down alt, I'm going to set it."},{"start":"4:12","end":"4:42","startSec":252.0,"text":"I'm going to drag the construct, the click into the set cameras. Now we essentially want to get the current camera, add one to it. So it goes to the next camera from the list of cameras and then assign the current camera. So we want to increment this. So there is an increment integer, but we just want the add for now. So we're just going to add one to the integer like that. And then I'm going to get the list of cameras. So I'm going to hold down control, list of cameras."},{"start":"4:42","end":"5:13","startSec":282.0,"text":"I'm going to get the length of this because the length gets the number of cameras in the array. So if I've got four in my scene, it'll get an array of four. It doesn't go one, two, three, four though. It'll go zero, one, two, three. So just know that arrays always start at zero. And we'll get the percentage sign here, which is this. We'll drag that into there and we'll just put that into there and then also get that."},{"start":"5:13","end":"5:46","startSec":313.0,"text":"So we're saying now we have the next camera in the array. That's essentially what that's doing. It's saying get the current camera, cycle to the next camera and say this is the camera that we want. So now what we can do is we can get the player controller. So get player controller. So that's this here. And then I want to drag off the player controller and say set view targets with blend. So we'll set that. We can change the blend time to one that I'll blend over one second."},{"start":"5:46","end":"6:17","startSec":346.0,"text":"If you want to change that blend to five or whatever you want to do, you can add that. You can change the blend type easy and easy now. And you can also change the exponent there, but I'm just going to leave all those settings for now. Essentially, we just want to get the new view target. So what we want to do is we want to get the list of cameras holding down control. We want to drag off and get because we want to get a specific camera that's in the array. And the camera that we want to get is this current camera."},{"start":"6:17","end":"6:48","startSec":377.0,"text":"So we can actually just drag that down there and then get that into there. And that will essentially do all our heavy lifting for us. So let's just save and compile and let's just see if that works right now. So I'm going to add that. We'll see that's a nice camera that we added first. Let's see. Next camera. Next camera. And see now this is the downside of the system because now we're just blending."},{"start":"6:48","end":"7:18","startSec":408.0,"text":"So you want to make sure the cameras are far enough apart around there because we just went through the mesh. But you'll see that it just keeps looping around, which is a really, really nice style camera system to have. And it just gives us that nice little polish and functionality. So we've got some cool angles and we can kind of just cycle through them. That last one, a little bit clipping through the car. So again, the order that we place them around the car will matter. So maybe you want another one at the rear there on the left hand side of this frame just to make sure it circles around the car."},{"start":"7:18","end":"7:25","startSec":438.0,"text":"But that's essentially our UMG working. And now we can dig into closing out the tutorial."}],"05_ThankYou_5.00":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"So thank you for watching today's course on the UMG fundamentals. Hopefully it's given you a good deep dive on some of the UMG construction, both adding buttons and icons that you can click, and then also just adding some blueprint functionality, whether it's toggling on and off a certain element from say the vehicle lights, or even just adding cameras to the scene and knowing how to pan around the scene using some basic camera scripting. I mean it got a little bit complex there, but once you know it,"},{"start":"0:32","end":"0:46","startSec":32.3,"text":"then it's implemented and it's really really nice straightforward system to use, and you can kind of add that customization to your project. So thank you again for watching, and we'll see you in the next course."}]},"227.08":{"01_Overview_5.00 (Source)":[{"start":"0:00","end":"0:25","startSec":0.0,"text":"Hello and welcome to today's Unreal Engine training on intermediate HMI pipeline, which is more of a technical course. Today we'll be covering engineering concepts, we'll talk about some design considerations, we'll talk about some DevOps tools you can use, and then talk about how to optimize projects. And then we'll jump in with a little hands-on workshop to show you actually how to deploy and package builds with some interaction. So let's get stuck in."}],"02_Engineering_5.00 (Source)":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"To begin with, let's look at the engineering aspects of this project. So when we're talking about blueprint class and C++ classes, you can think of blueprint as the easy way to prototype something. You can get a lot of visual feedback very quickly. You can create rapid prototypes and it can feel like there's a better connection to other subsystems and tools because of the visual nature of it. If you use in material editors, animation graphs,"},{"start":"0:31","end":"1:05","startSec":31.4,"text":"any other kind of subsystem of Unreal Engine, you can get a more visual representation and therefore a better connection in some instances to the tools inside of Unreal Engine. It also has its own component editor window, so you can very quickly see and debug things that are going on in your blueprinting. Blueprinting is essentially C++ in a visual wrapper, though. So C++ can be faster because it's a lower level state. And this can even be up up to 10 to 30 times faster than a blueprint script."},{"start":"1:05","end":"1:39","startSec":65.3,"text":"So again, it depends on the projects that you want to create. It depends on the goals of the project. But if you want a really performant optimized project, maybe C++ is the route to go. And of course, it doesn't have to be one or the other. You can build some lower level language in your projects in C++ and then build out some blueprint scripting on top of that. There's no kind of hard defined clear rule there. So C++, you have more functions available to you. It's better for online replication and processing any kind of math based loops."},{"start":"1:40","end":"2:10","startSec":100.4,"text":"And it's also just a low level language there. When we think about a game mode in relation to HMI, you can think about the game mode as a singleton in that it can be accessed by any class. It holds data. It can be very easily accessed across the project. You can also store information in the game mode, which is super helpful, especially if you're wanting to set certain parameters and have those values remembered."},{"start":"2:11","end":"2:43","startSec":131.2,"text":"It will only exist as long as the level is open. So when you begin a session in your project, you can store data in there. You can reuse it in other places. However, when the level is closed, the game mode will go away. So if you're wanting to store long term data, there is a concept called game instance and also save states. So you can definitely dig into those if you want to maybe save some settings close down the session, open that session up with those remembered variables."},{"start":"2:43","end":"3:13","startSec":163.7,"text":"You'd want to use a game instance and save states there. Today, we'll be looking at setting up a controller, which you can see has been edited here, a menu controller. And you'll see that it's been edited by these little yellow icons. Whenever you see this, it means the default state has been changed inside of Unreal Engine. So we're mainly looking at a controller today. You'll see that the pawn class has been removed. And that's just because we don't actually need a physical representation of a pawn in today's course. So sometimes it's just easier to remove that."},{"start":"3:13","end":"3:46","startSec":193.9,"text":"So there's no crossed wires of communication. When we are talking about this controller that we're setting up, you can think of a controller in terms of the digital representation of the user. The user will possess a pawn, but the controller has all of the input. So every touch or click that you use to input some kind of action into the project, that will all be done on the controller. So the controller will decide the method of input, whether it be on the mouse or the touch screen on the cursor,"},{"start":"3:46","end":"4:17","startSec":227.0,"text":"any kind of peripheral that's being used, the controller will decide how to interact with the project. So in a HMI controller can be used to change the interaction modes, manage information. So in a control, you also have these mouse interface settings. So we can show the mouse cursor if it's off by default, we can enable click events. We can enable click events and that helps you interact with the levels in your project."},{"start":"4:18","end":"4:48","startSec":258.2,"text":"When we are thinking about a pawn in relation to HMI, the pawns usually represent some kind of visual avatar. It's the user's kind of digital form here and it's a pseudo singleton. HMI is generally like any kind of visible pawn. We generally just use it to possess a camera, to see some of the visual elements in the scene. But if no visible element is needed, then you don't need to have it move or manipulate anything."},{"start":"4:48","end":"5:20","startSec":288.7,"text":"So in a standard HMI game mode, HMI pawn class will be set to none, as we saw in the previous slide there. We can enable a few plugins for our project today. Batches in code slash data can be enabled or disabled through the plugins window. And when we're looking at sensor data with Unreal, Canbus is a redundant safety critical protocol that provides information from the sensors around the car. So you're provided with a file of what messages contain,"},{"start":"5:21","end":"5:56","startSec":321.1,"text":"and then you get them fed constantly at a specific rate. When a message content changes, then you get a different message, but they're repeatedly at the same rate. So car sensors provide only partial HMI info and Canbus isn't used for everything, which is why we have a service layer that provides all the information to the UI. So we tend to avoid direct Canbus connection to Unreal Engine because it's not useful in production. You can find a tutorial on how to do this on the case electronics dot com site,"},{"start":"5:56","end":"6:27","startSec":356.7,"text":"which is Canbus simple intro tutorial. And that's the CSS electronics dot com website. So we can initiate the proxy objects from the game instance and just make sure they're available before begin play of everything else. Otherwise, you'll have objects trying to act on null objects that aren't created yet. You may use MQTT, but you'd still need to write all the Unreal Engine C++ code and the service side code to have a complete solution."},{"start":"6:28","end":"6:42","startSec":388.1,"text":"But the API gear can generate all that code and it's the OEMs don't truly factor into the cost of decisions like that. But hopefully that's a good overview of sensor data with Unreal."}],"03_Design_5.00 (Source)":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Next, let's talk about how we might approach the design of our project today. So we can start off by looking at UMG, which is Unreal Engine's motion graphic system. It's a 2D slash 3D user interface designer. You can mock up UI directly inside of Unreal Engine. All of this content, maybe except this icon here was created inside of Unreal Engine. So you can draw text. You can have slider bars. You can have little pop out buttons."},{"start":"0:30","end":"1:03","startSec":30.4,"text":"It's very modular in nature. And it's very useful to begin prototyping any kind of content you might need for your projects. When we talk about touch screens, we want to make sure the icons are nice and large in our projects. We want to assume that the user is distracted. The roads are bumpy. Consider spacing out UI elements. So making sure we're considering the borders and the grids and just making sure the overall interface is nice and straightforward to use."},{"start":"1:03","end":"1:36","startSec":63.0,"text":"We, of course, want to make sure accessibility is kept in mind at all times. So any kind of high contrast modes, colorblind modes, any kind of outline on text that will support the user is really useful to consider at this stage. When we display data management, we can think about widgets as templates. When you're thinking about child widgets, we can create elements with default value from a custom class."},{"start":"1:36","end":"2:07","startSec":96.4,"text":"So essentially, if you're going to be reusing a lot of information and you don't want to keep making the same UI element again and again, we can have a parent widget that holds all the main information. And then what we can do is we can create a child widget from that parent widget and it can consume the data from the parent. But then you can also override specific variables or options that you want to kind of customize to this child class."},{"start":"2:07","end":"2:41","startSec":127.6,"text":"And it's just a much cleaner way to work. It means that if you want to change any of the larger structure, you can do so in the parent class. And then the child class, even if the child class was made after the fact, it will still inherit those new properties. So if you have to make a change, you only make the change once in the parent class and then it deploys across all the child classes as well. So it can also prevent larger bugs and issues and things like this. We have slate brushes, which are reusable brush strokes as well that we can be used in inside of Unreal Engine."},{"start":"2:41","end":"3:15","startSec":162.0,"text":"And also, as we mentioned on the previous slide, the text displays any kind of text you want. Say you want the vehicle speed displaying and we want to update the speed at runtime. We can bind specific elements of text and we can also format that text all at runtime. So if values are changing, we can do this inside of UNG. We also have rich text, which the rich text block uses a data table asset to manage the styles and the customization of your projects."},{"start":"3:15","end":"3:46","startSec":195.1,"text":"We can also embed video into our UI projects here. So we use the media framework in this instance. So you can just right click anywhere in your content browser, go to the media option. And on the media section, you can go to the file media source here. We've got the media textures, media player and the playlist. If you want to get more information about how to use video inside your projects, there's a really good Unreal Engine documentation page,"},{"start":"3:46","end":"4:22","startSec":226.9,"text":"which if you just type in Unreal Engine docs media framework, it'll come up for you and a very straightforward process. But it's more of a step by step how to on how to get videos inside your project. So the really useful thing about the video is it can be rendered either in 2D or 3D. So you can see in the screenshot, we've actually placed a plane in the world, which we can use to project the video. So it can either be overlaid on the screen in 2D or it can be projected in the world as 3D."},{"start":"4:22","end":"4:53","startSec":262.2,"text":"And all videos are in your content folder and in movies. So when you have your projects and you have a content folder with the various blueprints and assets that you've created, we just want to create a movies folder there to store all of our raw movies, which Unreal Engine then streams from that movie content folder. And when we're looking at performance interfaces, material complexity can be a useful thing to highlight here. It can increase the pixel cost of a render."},{"start":"4:53","end":"5:25","startSec":293.6,"text":"So the more instructions there are for each pixel, the more time the render needs to spend calculating its final value. So opaque materials on a UI, the least expensive, but can differ greatly based on the shading model or the base shader code. So if you're wanting any slightly transparent buttons, just know that it can come with a cost. So we can find more information. Again, documentation is a really good resource to start digging into."},{"start":"5:25","end":"6:02","startSec":325.5,"text":"So you can look at the testing and optimization documentation to find more information about this. And then there's also a documentation page on interactive experiences, which is a really good user best practice guide. So we can talk about performance in relation to project specific outcome. You just want to be thinking about that early on, making sure you get all your UI elements on the screen. If you're wanting to store any data from this UI, you can use the game instance, which means there's less loading and unloading."},{"start":"6:02","end":"6:33","startSec":362.8,"text":"As we were talking about before, if there's any kind of permanent storing and data, you want to use the game instance there. And we also have UMG tools built into the editor, which we have widget switches and user created widget components, which allows you to interact with any other custom components or between multiple widgets at the same time. Say you want to toggle through multiple screens or anything like this. We have that functionality inside the engine."}],"04_DeveloperOperations_5.00 (Source)":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Let's now dig into the developer operations section. So we'll have quite a lot of in-depth information pointing you to the correct areas of either documentation or tools that you might be able to use when working with HMI in your projects. So the first tool we want to go over today is the sometimes you'll see it be referred to as UAT, but it's essentially the Unreal Automation Tool. So the automation tool is a host program"},{"start":"0:33","end":"1:05","startSec":33.1,"text":"and a set of utility libraries you can use to script unattended processes relating to Unreal Engine when using C Sharp. So internally, we use the UAT for a variety of tasks, including building and cooking and running games. You can run automation tests and script other operations that can be executed on your build farm. So the source code for the automation tool and various scripts that run it can be found in your project"},{"start":"1:05","end":"1:37","startSec":65.7,"text":"in the Engine Source Programs Automation Tool. So you just want to go to where your Unreal Engine is installed, go to Engine Source Programs Automation Tool, and you can find that there. So the automation system is built on top of a functional testing framework, which is designed to do gameplay level testing, which works by performing one or more automation tests. So the more tests that are written, there may be more functional in nature,"},{"start":"1:37","end":"2:08","startSec":97.6,"text":"either low level core or editor tests that need to be written. You can use the automation framework system for these. So the test can be written, broken down into different categories, depending on their purpose. So you might have a unit test or a feature test or a smoke test. You may have heard these phrases before. You can even do things like screenshot comparisons. But if you do want to dig into this deeper, there again is great documentation. It's the testing and optimization"},{"start":"2:08","end":"2:39","startSec":129.0,"text":"section of the documentation. And there you can dig into exactly what the UAT is and how to use it in your own projects. We've also got continuous integration and continuous deployment. So as part of a packaging process, which we'll dig into a little bit later here, the automation tool can be used for this. And it's used to work through a set of utility scripts for manipulating Unreal Engine projects. So for the packaging process, the automation tool"},{"start":"2:39","end":"3:09","startSec":159.7,"text":"uses a particular command called build cook run. And this command can cook content from a platform, package it into the platform's native format for distribution, and then deploys it to a device. And it can automatically run the project where you want it to. So packaging your project doesn't solely require the use of the UAT. But you can use it from the File menu to select the available platforms or the command line"},{"start":"3:09","end":"3:40","startSec":189.8,"text":"to cook and package the content for a platform. So when we look at Gauntlet, Gauntlet is a framework to run things and validate results. It's specifically designed. It's not limited to this, but for running Unreal sessions on a variety of platforms. So an Unreal session is all the processes needed to execute a game with Unreal Engine. So you may have a multiplayer game that requires four clients and a server. You can use Gauntlet for that."},{"start":"3:40","end":"4:14","startSec":220.7,"text":"And then Jenkins is an automation. Jenkins in relation to automation is recommended. So you can combine it with the P4 plugin to manage the data, the P4 being the Perforce plugin. And you can build a trigger for automatically building your game. So a few good documentation pages to follow here as well. You've got Launching Unreal Engine Projects on Devices, which is a great documentation page. We've got Packaging and Cooking Games in Unreal Engine."},{"start":"4:14","end":"4:46","startSec":254.6,"text":"And we've also got Build Operations, Cooking, Packaging, Deploying, and Running Projects in Unreal Engine, which are all useful documentation pages to look into more. When we look at the hardware considerations of our projects, we want to know about the GPU versus CPU utilization. We want to know what background processes are going on based on the setup of any kind of specific vehicle hardware. We've got resolution scaling for optimization,"},{"start":"4:46","end":"5:17","startSec":287.0,"text":"depending on what screen we're using. We want to measure the performance available on Vulkan but not OpenGL. And you can also have device profiles, which you can customize the rendering settings on a per hardware basis. You can do all this in the project files, in config, default device profiles, any. So in your Windows Explorer, just go to your config folder of your project, and you can find the default device profiles there."},{"start":"5:17","end":"5:48","startSec":317.2,"text":"When you're working with multiple people in your team, this is good for solo development as well, but especially so when you're working in teams, we want some kind of version control. So version control helps prevent conflict resolution and asset locking. So it's almost like a library system where you can lock a file, take it out, use it without someone else editing that same file. So GitHub alone is not good source control."},{"start":"5:48","end":"6:20","startSec":348.3,"text":"We have a few options here. You've also got the multi-user editing plug-in on local network. But however you want to approach team development or solo development, it's definitely advisable to use version control. So again, some good documentation here. Using source control in Unreal Engine is a good documentation page, and also the multi-user editing in Unreal Engine is a really good documentation hub. When we look at using Unreal Engine source, you can grab that from GitHub. You just need to connect your Unreal Engine account for this,"},{"start":"6:20","end":"6:51","startSec":380.7,"text":"and you can just set up the menus and the connections here. And then we also want to install Visual Studio to build the source files from Unreal Engine. So no matter which source control software you end up using, the manner in which you interface with that software from inside of Unreal is the same. So the following guides that I'm about to say will detail everything you need to know about source control in Unreal Engine. So we have development setup building in Unreal Engine"},{"start":"6:51","end":"7:24","startSec":411.8,"text":"on the production side. We've also got just a source control in. If you go to the production pipeline setting in Unreal documentation, that's a really good place to start. So just production pipelines. And then there's a source control specific area in there, which you can see has in editor, per force, and SVN documentation. So that's a really good place to start learning about how you might integrate the engine code, but also just source control into your projects."},{"start":"7:24","end":"7:55","startSec":444.7,"text":"And when we look at the Make AAR, Make AAR versus the Android application, where we should use UE's library. So the Make AAR generates an AAR, which is the engine wrapped into an AAR and provides a Java-based API to initialize control at runtime. It sends data to and from the engine via blueprints. So the engine visualizes essentially any of the visuals from the engine"},{"start":"7:55","end":"8:27","startSec":475.9,"text":"are injected into the graphics library context for the Android Surface View. So basically, Make AAR integrates Unreal Engine into existing Android apps to render on your Surface View. So normally, Unreal would be its own application when you package it. But if you want to run Unreal inside of an Android Studio project using something like Surface View Target, or you want Unreal to be the full screen application,"},{"start":"8:27","end":"8:58","startSec":507.0,"text":"you don't need to use Make AAR. And when we're looking at cross-compiling here, we can compile Windows to Linux. And also the Mac native compiling. So cross-compiling makes it possible for developers to target Linux from Windows. And at this time, cross-compiling is only supported for Windows and Mac users. You currently have to the results of the native compiling. Additionally, we do support test and provide libraries and tool chains for Linux x86 on the 64 platform."},{"start":"8:58","end":"9:30","startSec":538.3,"text":"And if you do want to look at the documentation page, that's sharing and releasing with Linux in the native tool chain. So since Unreal 4.0, and so if you're using Unreal Engine 5 and onwards, the setup shell automatically downloads the tool chain, which generates to your computer and links with the code bases. So the native tool chain, you can then compile against a fixed SYS root, the system root."},{"start":"9:31","end":"9:41","startSec":571.0,"text":"And if you wanted to compile something on Ubuntu 1804, you'll be able to start the binary on the CentOS 7 there."}],"05_Optimization_5.00 (Source)":[{"start":"0:00","end":"0:39","startSec":0.0,"text":"Now let's look at some optimization tools and techniques you'll be able to use in your projects. So we've got some common performance factors here. So scaling for the hardware, any kind of background operations that are going on, you want to make sure that the engine content is not being unnecessarily packaged in your projects. We want to make sure memory leaks are being addressed so we can use Unreal Engine insights for this. We also have some timing and memory insights and you can use the console trace-memory to log any memory leaks that you might be experiencing."},{"start":"0:39","end":"1:15","startSec":39.0,"text":"So Unreal Insights is its own massive thing. Again, some great documentation to dig into this further, which is Unreal Insights in Unreal Engine, the documentation there. And then we've also got the memory insights in Unreal Engine, which will give you a good insight, pun intended, into finding these memory leaks and tracking them down to fix them. We can also do rendering optimization, which we can look at in a little while here. So using the Unreal Insights tool, Unreal Insights identifies areas of your project that require optimization."},{"start":"1:15","end":"1:53","startSec":75.0,"text":"So it's a telemetry capture and analyzing suite that provides you the capability to capture events from the application at high data rates. So it essentially just tracks everything that's going on in your project. So you can really find out what's costing a lot of memory, other certain hitches at certain parts of the session. A major component of Unreal Insights consists of the trace events. So the Unreal Trace Server, which records and save traces from the application and Unreal Insights, it then uses that to analyze and visualize the data."},{"start":"1:53","end":"2:26","startSec":113.0,"text":"So again, using that Unreal Insights documentation is a really good place to start. And the insights application can be found in your engine folder in binaries, Win64, and just locate Unreal Insights in there. So the memory insights is a new component that provides you with the capability to investigate memory usage and call stack tracing in your project. When we're looking at the package size and boot time, we want to make sure that we're not cooking anything unnecessary."},{"start":"2:26","end":"2:58","startSec":146.0,"text":"So we can create compressed cooked packages, which we'll do later in this course. And you want to cook everything in the project and the content folder directly. So you also want to ignore any maybe test maps you might have created, anything that has unnecessary data in there. We don't want to package that. We want to make sure that that pack file size is as small as we can get it. So we definitely want to check out the documentation guide on all the little tips and tricks here."},{"start":"2:58","end":"3:31","startSec":178.0,"text":"So performance and profiling section of the documentation section has a documentation page called Reducing Package Size. And that's a really good place to start. So we can use this size map that we spoke about earlier in the course. And the size map is a really good tool to just show exactly what assets in your project are costing what budget. So you can either right click on a single blueprint. So we've got a blueprint here that's the Audi A5 and we can see that the seats are taking up 239 megs alone."},{"start":"3:31","end":"4:05","startSec":211.0,"text":"And you'll see all the different data, how much each data is costing. And the size map is a really nice way to visualize all of that. So we can go to the optimization tool. So we just click the drop down here and go to the size map. Alternatively, we can use Alt Shift and M to open the size map. We just get this by right clicking any asset that you're wanting to get the size map of. And when we're looking at the rendering, we want to make sure that we've got the balance between are we using normal maps"},{"start":"4:05","end":"4:41","startSec":245.0,"text":"to present the data or are we using high vertex meshes? Maybe if you're using something like VR, you may not want to use normal maps because normal maps only work with a single view, whereas the power of the normal map generally gets lost in VR. So you may then want high vertex meshes. So it's going to be project specific. There's always going to be a texture versus poly count trade off. And that's down to the decision of the project and what your goals are for the project to determine whether you want to go more of a normal map direction or high vertices meshes."},{"start":"4:41","end":"5:15","startSec":281.0,"text":"Temporal AIA should be on by default for HMI. It's much faster than the MSAA 2X and looks better. When we're looking at materials, we want to optimize the texture resolution. We want to reduce draw calls and texture lookups. If you want any more information on draw calls and texture lookups, of course, there is great documentation on that. Draw call is essentially every unique asset that's in the scene. So and that even if it's the same static mesh, but with a different material, that's still a new draw call."},{"start":"5:15","end":"5:48","startSec":315.0,"text":"So you want to make sure you keep in the draw calls down and then also the number of different textures that you're using. There are tools to optimize this inside of Unreal Engine, such as merging actors and making sure textures all get baked into one texture. But there's it's up to you and the performance of your project about kind of what optimizations you're looking for. We also have the optimization view modes. If you go to show in your viewport in your engine and you go to optimization view modes, you can see that we might have."},{"start":"5:48","end":"6:24","startSec":348.0,"text":"I think this might be the quad overdraw viewport. I'm not sure. But we've got the quad overdraw. We've got lighting complexity. And you can see how your scene is looking based on the different optimization view modes. So they're definitely worth checking out. And you can also profile the GPU, which is its own tool that you can load up and see exactly what's taking time on the GPU. So whereas blueprint blueprinting and C++ will predominantly be on the CPU, any kind of visual data that you have in your scene will all be on the GPU there."},{"start":"6:24","end":"6:57","startSec":384.0,"text":"And then some useful console commands. So you can use console commands by pressing the tilde key generally found next to the one key on your keyboard. But you can open the console command at runtime in the editor when you have your projects loaded. And you can type in stats space GPU, which displays the amount of time and milliseconds used for the GPU. So you can get some good GPU information from there. We've also got stat unit, stat unit graph and stat texture group to get you started."},{"start":"6:57","end":"7:13","startSec":417.0,"text":"There are many, many console commands. And I believe it's you can press tilde and just type help and it'll print out all the different console commands that are available to you. And of course, there's a full list of console commands on the Unreal Engine documentation page."}],"06_PackagingExcercise_5.00 (Source)":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"Now to wrap up, let's talk about how we might package our projects. We've been talking about how we might approach the actual development tools. Now, how do we get the project that we've created and deploy it to the target platform? So it's important to note there's a variety of different packaging types you can use. You can use Dev versus Release. So if you want to have console commands access to you or any kind of development information, as we spoke about in a previous slide, you can use a Dev Release for this to be able to just debug any information."},{"start":"0:36","end":"1:11","startSec":36.4,"text":"And if you want Release, then there'll be no access. It's for the end consumer or the end user that you want to experience that. You don't really want the debug information in there. So we can get started by the Unreal Engine Android development. And so we can run the setup Android back, which is found in our Epic Games engine folder. We want to install Android Studio. And then if using the 5.0 version of Unreal Engine, you want to install these extra versions."},{"start":"1:11","end":"1:45","startSec":71.4,"text":"So anything 5.1 on later will already come with some of this content. So just double check which versions you're using and install the relevant APIs. You can also enable developer mode on the device. You want to check your Android version and typically tap in build number seven times. We'll allow that here on the bottom left hand side that you can see. And make sure don't sleep while charging is enabled and then also allow USB debugging."},{"start":"1:45","end":"2:17","startSec":105.7,"text":"When we're making a new project, we want to create a new blank project in Unreal Engine. So you just want to load the Epic Games launcher, pick a project, but then pick a blank project because this will be the cleanest version of a project that you can cook and package. And we want to just make sure the mobile and minimal settings are applied. So when you see the new project screen, you can just make sure you tick it's for mobile and the minimal settings are applied there."},{"start":"2:17","end":"2:47","startSec":137.0,"text":"Then we can make a blank map. And if we go to maps and modes in the project settings, so to find the project settings, we go to edit at the top, go down to project settings and there'll be a maps and modes in the project setting. And this new map that we've created, you can just assign that map as the editor startup map and also the game default map. The game mode and instance can be set there as well. If you want to update that or change that."},{"start":"2:48","end":"3:19","startSec":168.0,"text":"When we've created a new level, we want to create a couple of new blueprints. So we want to create a new controller and a new game mode. So for testing, you may be able to enable mouse click events. So you can do that in the controller as we showed earlier in the course, enable touch events there, enable click events is also accessible. When we've created the new controller in the game mode, we can then just assign those in the actual game instance class that we have."},{"start":"3:19","end":"4:00","startSec":199.9,"text":"So you'll see again, these changed icons here. This is what we've got. So we've got our custom controller. We've got our hood class and we've got our palm class. Next, we will make sure our project settings are set up correctly for Android. So we'll go back into our project settings. Again, you can find it edit at the top of your Unreal Engine browser and go to project settings. Go to the platform section and find Android and you just want to make sure you configure your project for Android here. And then optional, but you can show console on four finger tap, which is the tick box there just in case you want any debug information."},{"start":"4:00","end":"4:31","startSec":240.4,"text":"We can then create a new UMG widget by right clicking in your content browser, going to user interface and adding a widget blueprint. And you just when this box comes up, you can just click use a widget here. That's fine. And then we want to just create a basic window like this. So you want the canvas panel at the bottom as your first property here. And then you've got a background image. We've also got a test button and some test text."},{"start":"4:31","end":"5:04","startSec":271.1,"text":"So we've just created a basic UMG like this with some kind of button that will be accessed within the blueprint. So in the blueprint, we want to make sure we load up the custom controller that we assign to our game instance on event begin play of the controller. We want to drag off event begin play. And if you just type create widgets, then. It'll add a create widget box and we just want to assign the UMG widget that we just created in the previous slide."},{"start":"5:04","end":"5:35","startSec":304.1,"text":"So when you assign that there, that will the text here will update to whatever you called your widgets. So in this instance, we called it example widget. And so you can see create example widget widget. When you drag off owning player, drag off to the left and type self that will create a little self reference. And it just makes sure it adds to itself. And then on the return value, you can drag off here and type add to viewport. And that will add your example UMG to the screen."},{"start":"5:35","end":"6:08","startSec":335.8,"text":"Then when if we want to test it, we can test on the mobile preview. So on platforms, which is at the top of your viewport here, you can just go to mobile preview and then you can play a new editor window. And that will allow you to test whether the button is then clickable. To test deploying to the device, again, we can use this drop down here and we want to check that we've installed the SDK and Android Studio. We want to make sure we ran the setup Android back at the top of the hands on section here."},{"start":"6:08","end":"6:44","startSec":368.8,"text":"And we want to make sure developer mode is unlocked on the device. Compression between PC and HMI are different. So just make sure you pay attention to that. And then also it takes time to build and deploy. So when you click and it's just compiling and doing its thing, don't worry, it can take time to do that. You can run the Unreal Insights as we referenced previously if you want to test. But you just need to make sure you install that first. And so some packaging settings to use, you can choose whether you want the compressed cooked packages."},{"start":"6:44","end":"7:16","startSec":404.6,"text":"You want you want to exclude. You can choose whether you want to exclude on any unnecessary content. So maybe you only want to cook certain maps or have a list of some specific maps. Do you want to make sure it's not for distribution? Do you want to blueprint native eyes anything, which again is size versus speed as a trade off between performance? And then do you want to do a full rebuild or do you just want to iterate through the build so that every time you package the game, it gets a little bit faster?"},{"start":"7:16","end":"7:46","startSec":436.6,"text":"So here are a few options you may want to set for yourself inside your project settings. And then lastly, talking about packaging, we can go to platforms at the top of the browser here. You can go to Android and you can make sure that you have the Android ETC to set. And for this instance, we probably want a development packaging build so we can test those debug settings. We can do that four finger tap. And this is essentially how we would go about packaging a project."},{"start":"7:46","end":"8:04","startSec":466.9,"text":"So you can click package. Just know that that takes quite a while to go through. But by the end of it, you should have a package deployed build on your Android device. And you can then use it to debug any information you may want to see on the screen there."}],"07_ThankYou_5.00 (Source)":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"So thank you for being on the course today. Hopefully, it gave you a really good overview of the HMI pipeline, which is more of a technical approach. There's a lot of documentation to dig into, discover. Hopefully, today you found some new tools that you didn't know about inside of Unreal Engine to help you deploy your projects to Android devices and make user interfaces and think about the design and the execution of these package projects. So hopefully, it's given you a lot of information to take away"},{"start":"0:32","end":"0:36","startSec":32.8,"text":"and start digging into, and we'll see you in the next course."}]},"311.01":{"01_Overview_5.00":[{"start":"0:00","end":"0:29","startSec":0.0,"text":"Hello and welcome to today's Unreal Engine training on creating advanced landscape materials. So today we'll talk about creating hand-painted materials, we'll talk about weight map based materials, we'll talk about height map based materials, and then creating holes in landscape and some material optimizations you can do when it comes to landscape. We'll also cover some virtual texturing techniques and then also how you may go about creating holes in your landscape for some more natural looking results. So let's jump in."}],"02_HandPaintedMaterials_5.00":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"So starting off with hand painted materials, let's talk about how we might go about creating a material set up for hand painted materials. So to set this material up, you just need to first add a landscape layer blend node into a material, which you can see here. You can see the image on the left-hand side as well. And so this node will specify which layers and the colors of layers that you want in your landscape material. So you can actually add more inputs here"},{"start":"0:32","end":"1:04","startSec":32.4,"text":"by pressing the plus button. And so for this example, we'll be using three layers. We'll use a grass color, a dirt color and a rock color. And then just so you can name them the relevant blends. And then when we actually get to our landscape, we can apply the material that we've just created to the landscape. So we want to open up the landscape tools and then click on the paint option. And then we should have these three entries that you previously created, which is the grass, the dirt and the rock."},{"start":"1:04","end":"1:36","startSec":64.8,"text":"So if we press the plus icon here next to the layer and select weighted blend layer, which the brackets is normal there, we can save the new created asset in a location in your content browser. It'll suggest somewhere. So you can go ahead and save it there unless you'd like to save it somewhere different. But if you also look at the weighted blend layers, it allows you to paint on top of layers so that the layers blend correctly. So we can use this when we want to blend,"},{"start":"1:36","end":"2:07","startSec":96.6,"text":"say rock into dirt, for example. So a non-weighted blend layer would allow you to replace the layers as you paint over them. So you can use this when you want to have, say snow covering rocks or dirt. So just think about whether you want to use the weighted blend layers or the non-weighted blend layers and the difference, as we said, weighted blend means that you can blend more easily, say from rock to dirt. Non-weighted means that you might have snow covering rock or something like this."},{"start":"2:07","end":"2:19","startSec":127.9,"text":"And then we can repeat that process for the dirt and rock layers. And then when we're done, we'll be able to hand paint the landscape by selecting the layer from the list and then just painting it directly in the viewport."}],"03_WeightMapBasedMaterials_5.00":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Next, let's look at creating some weight map based materials. So weight maps are black and white maps that define where certain layers and your landscape material will show up. The weight maps can generally be generated in your external DCC and then imported to respect the layers inside of Unreal Engine. So you can generate these maps by hand, but just make sure that you note the size of the landscape that you are creating"},{"start":"0:30","end":"1:05","startSec":30.0,"text":"so that you can create things to the correct scale and then you can therefore import them correctly. So looking at a material that supports the weight map pipeline, the material can be set up in a similar way to how we just created the hand painted material. So we can use the layer blend node, and then once the material is set up, we still want to apply it to the landscape again in a similar way and then open the landscape tool, which you can see here on the image on the right hand side."},{"start":"1:05","end":"1:41","startSec":65.0,"text":"So the size of the layer weight map will be the size of the overall resolution when the landscape was created. So in this example, the size of the layer weight map should be 249 by 249 pixels, which you can see on the left hand side here. But if you are not sure what size, you can always just right click on the layer from the menu, select export to file, which is the option that you'll see in the list there. And you can then export that layer to say a PNG file. So once you have a layer weight created, you can then import it by right clicking on the layer it is associated with"},{"start":"1:41","end":"2:12","startSec":101.0,"text":"and then select the import from file, which you can see the image for here. So you will get a warning if your overall resolution wasn't set correctly. So just make sure the source file is related to the overall resolution and then you can click import. And then here's an end result of what you might get when you have a weight map material. So with this method, you can see some really nice natural looking results here."},{"start":"2:12","end":"2:27","startSec":132.0,"text":"The image was made using World Machine to generate the height map. And then the weight maps and then the material was set up just like in the hand painted material example we just went over. However, each layer was imported from a third party app."}],"04_HeightMapBasedMaterials_5.00":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Now that we've covered some weight map based examples, let's talk about height map based examples. So you can see how we approach a height based material. You can see how it works by showing a specific material when the landscape slope reaches a certain angle here. So it means that the flatter areas will be covered in a grass texture and all surfaces that have the slope will have a dirt or rock texture assigned like in this example. So the above image shows that the grass material function will be shown from zero."},{"start":"0:34","end":"1:14","startSec":34.8,"text":"So we can see the zero on the grass there. And then as the slope of the landscape approaches point five, it will then blend to the dirt, which we can see point five. And then once the slope reaches an angle greater than point five, we can see it goes straight to one there, which is the rock in this example. So the material setup you'll use are these three nodes specifically. We've got the material function, which are little snippets of the material graphs that can be saved in your content browser and you can reuse these functions across multiple materials."},{"start":"1:14","end":"1:50","startSec":74.2,"text":"We'll also need to have a make break material attributes, which these nodes are used for when you have a layered material workflow. And it allows you to not only use one aspect of the material that is being sampled, but for example, you may have a material layer that defines some kind of nice looking generic material such as steel. And then you may want to use the roughness and base color attributes from that layer in your final material. So rather than using the whole thing, you can use it in such cases where you might break the material attributes node to split up all of the incoming attributes of the material layer."},{"start":"1:50","end":"2:28","startSec":110.6,"text":"And then just picking to plug in the layers that you want. And then just to cover the world aligned blend, which is the material expression, the world aligned blend. This function takes in a vector and compares it against the world space surface normal. So the function provides zero to one alpha output where zero represents perpendicular vectors and then one represents parallel vectors. So if you think about it in a slightly different way, when using the Z axis, your in world vector value is going to be zero zero one."},{"start":"2:28","end":"2:58","startSec":148.4,"text":"So we're talking about the one in the Z axis there. So if that it will output black and white texture where the white represents flat and black represents a slope. So this value can be biased and sharpened to create clean lines between alpha values. And we can we have a few other controls here that will allow us to get the results that we want. So here's an extremely simplified process of how we might create this."},{"start":"2:58","end":"3:26","startSec":178.5,"text":"So when making a height based landscape material, the order in which the layers are put together is going to be super important here. So for example, we have rock and then dirt and then grass. So this makes sense as rock breaks down into dirt and grass grows into dirt. So really, really simplified process here, but hopefully gives you an idea of how that height based result may look inside your editor here."}],"05_LandscapeMaterialOptimizations_5.00":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Let's take a look now at how you might optimize some of these landscape materials that you're creating. So you can adjust landscape so that the further components use a simpler material for example. You can also activate the landscape modes panel and select the entire landscape. And then in the details panel under the landscape component, look for the override material section, which you can see here. So you can press the plus icon next to the array just to add a new"},{"start":"0:30","end":"1:01","startSec":30.7,"text":"element here and then set the LOD index to one. So the LOD index is one there and then we'll have a new material that we can plug in there. So you can maybe have a more simplified LOD version of the material here and you can see that the LOD level one will be further out. And then even if you wanted four, five, six different LODs, depending on the simplified material, you can do that and load the landscape there. We also can view this in action. So this is what our LOD may"},{"start":"1:01","end":"1:34","startSec":61.7,"text":"look like. So we've got good detail close to the camera and really good performance for further away. So the players or the viewers not going to really see too much difference between the two materials. But as you can see, there's a lot of complexity going on in this foreground material and therefore you may not want that being rendered in the distance where the pixels just won't represent that material. So creating LODs for your materials will be a really good approach there to optimize some landscape usage. And then we can also talk about distance blending as well. So"},{"start":"1:34","end":"2:04","startSec":94.0,"text":"distance blending allows you to blend one set of textures into another. So you would want to do this, for instance, where you have a highly detailed landscape that visually breaks down when viewed at close distance. So there are a number of different ways to approach this, but the quickest and easiest is to just use this distance blend material function that comes inside of Unreal. We can also have a shared source. So if your landscape material stopped compiling, it could"},{"start":"2:04","end":"2:41","startSec":124.8,"text":"be because you're using too many texture samples. So a sampler is something that tells a GPU how to sample the textures, whether it's linear filtering, point filtering, wrap addressing, etc. The D3D11 has a hard limit of using 16 texture samples and it's not something we can change. So you can use fewer samples in your material by changing the sampler source to shared shared wrap or clump, which you can see in this image here. Doing this, I will allow you to now use up to 128 unique textures. So from 16 to 128 into a single material, but don't enable this"},{"start":"2:41","end":"2:44","startSec":161.9,"text":"right away and only enable it if you need to."}],"06_VirtualTexturing_5.00":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Let's now take a look at virtual texturing. And so let's first talk about what virtual texturing is. So you can see how we have this option to enable virtual texture support, which you'll sometimes see it used as RVT, which is runtime virtual texturing and streaming virtual texturing, which is SVT. So the runtime virtual texturing provides an efficient way to render complex procedure generated or layered material."},{"start":"0:31","end":"1:04","startSec":31.2,"text":"So it makes runtime virtual texturing ideal for rendering complex materials and landscapes. And it enables improved rendering performance and workflows for landscape splines, which we'll cover in a little while here, decals for meshes and materials, along with general landscape and object blending. So the streaming virtual texturing reduces texture memory overhead when using very large sizes, which includes support for virtual texturing lightmaps and UDIM, which is U-Dimension."},{"start":"1:04","end":"1:36","startSec":64.9,"text":"The streaming virtual textures is an alternate way to stream textures from disk compared to existing MIP-based texture streaming. And it follows what we'll do is we'll show how we can follow using runtime virtual texturing. So if we enable the virtual texture support here by going to the rendering tab in your project settings and go to virtual texturing and then click the enable virtual texturing option, then we'll be able to make a new runtime virtual texture."},{"start":"1:36","end":"2:09","startSec":96.7,"text":"So once we've enabled that option, we can now go to a existing material that we want to use virtual texturing. So for this example, we've opened up the mat underscore virtual texturing underscore start material. So that's mat underscore virtual texturing underscore start material. And now we can add a break material attributes node, which we discussed previously, and a virtual texture feature switch, which you can see here as well. So you want to connect the output of the base color layer blend node to the base color input"},{"start":"2:09","end":"2:43","startSec":129.6,"text":"of the break material attribute nodes. And then we also want to connect the normal, the layer blend to the normal input of the break material attribute, and then also connect a scalar input with a value of 0.5 to the roughness, which you can see here into the break material attributes node as well. Then we can add a runtime virtual texture output node to the graph and then connect the output of the base color to the layer blend to the base color input of the runtime virtual texture output node, and then connect the output of the normal layer blend to the"},{"start":"2:43","end":"3:15","startSec":163.6,"text":"normal input of the runtime virtual texture output node. Then again, connect the 0.5 to the roughness input, add a constants node with a value of 1 and connect that to the opacity input, and then add a constants node with a value of 0 and connect that to the specular output. Now we want to add a runtime virtual texture sample node and make a material attributes node to the graph, connect the output on the runtime virtual texture sample to the respective"},{"start":"3:15","end":"3:46","startSec":195.6,"text":"inputs on the make material attributes nodes, then connect the output of the make material attributes node to the yes input of the virtual feature switch node. Then when completed, your material should look like this image here. Now we can add the runtime virtual texture volume to the level and then with the runtime virtual texture volume selected, go to the transformation from bound section and set the source actor to the landscape that is placed in the level."},{"start":"3:46","end":"4:19","startSec":227.0,"text":"So you just want to make sure you assign that landscape there and then press the copy rotation and copy bounds buttons to make the volume as big as the landscape actor. And then under the virtual texture input, select the virtual texture that was created in our first step. So just make sure you assign that virtual texture there. Now select the landscape actor in the level and then in the details panel of the landscape, go to the virtual texture section, press the plus icon and add a new input to the array"},{"start":"4:19","end":"4:50","startSec":259.6,"text":"and then input the virtual texture that was created in the first step. And then once all that has been completed, you should now see landscape material being rendered in the viewport. So you can see here the left hand side of the image shows that the landscape will look like using non-virtual texture and then on the right hand side, we've got an image showing what the landscape looks like using the virtual texture. So if your landscape has black parts in it after the virtual texture, just try rebuilding the landscape material, saving everything and then it should function correctly for"},{"start":"4:50","end":"5:21","startSec":290.9,"text":"you. We can also adjust the size of each of the tiles to make up the virtual texture. So this can help if the textual density of the landscape is low. To adjust this, all you need to do is open up the virtual texture and adjust the size of the virtual texture in the tiles and then also the size of each virtual texture tile. So keep in mind that when adjusting the virtual texture, the size has to be a power of two. If in doubt, the tool will give you advice on what settings to use here."},{"start":"5:21","end":"5:52","startSec":321.3,"text":"And then we can also use virtual texturing with landscape splines. So this is what it will look like when applied to a landscape spline. Then you can bake it down into a landscape. To make this work, you first have to add some splines to your landscape. So you can do this by holding down control and left clicking on the landscape to create a spline. And then in the details panel, under the landscape spline, press the segments button to select all the landscape splines."},{"start":"5:52","end":"6:25","startSec":352.5,"text":"And then if done correctly, you should now see a new option in the details panel called landscape spline mesh. If your landscape spline mesh is selected, press the plus icon to add the new static mesh to the array. And so for the mesh under the way using SM underscore street as a static mesh and then uncheck center horizontally and change the forward axis to Y. Finally, make sure to uncheck cast shadow. And so the shadowing was done for more of an aesthetic reason."},{"start":"6:25","end":"6:57","startSec":385.6,"text":"Doesn't necessarily need to be done for this to work. With the M underscore street material open, which is what was assigned to static mesh, go to the material section and then the material now needs to be set up like we did the landscape. So first make the material use material attributes, then bring the runtime virtual texturing output and sample nodes, connect them like you can see in this image here. And then you will end up with a result that looks something like this."},{"start":"6:57","end":"7:05","startSec":417.6,"text":"So you can see how we've got the normal spline on the left hand side and then also the virtual texturing spline on the right hand side."}],"07_LandscapeVisibilityMask_5.00":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Just before we wrap up here, it'd be good to go over landscape visibility masks for if you want to mask anything out in your landscape. So landscape visibility mask allow you to remove a visual collision mesh of your landscape so you can subterrain structures like caves or secret bases, anything where you want to kind of dig into the landscape a little bit. So it's achieved by placing a landscape visibility node in your landscape material. And then when applied to your landscape, you can then paint in the visibility of where"},{"start":"0:32","end":"1:04","startSec":32.5,"text":"you want to pass through. So to create this, you need to make a new material or use an existing material, but we need the landscape visibility mask node, which we can add maybe to an existing landscape material if we want. So we need to set the blend mode to masked in this instance, and it'll only work with masked materials. So make sure your blend mode is set to mask there. And then just select the landscape in the editor viewport and look for the landscape whole material and apply it in that section there."},{"start":"1:04","end":"1:19","startSec":64.2,"text":"Then when we have the landscape tools open, we can go to the visibility section and we can add or remove visibility using the paint tools as we would with the terrain tools, and you can add or remove landscape sections when painting."}],"08_ThankYou_5.00":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"So thank you for watching today's course on advanced landscape materials. Hopefully you learned a lot with the bases that we covered, whether it be from basic hand painting materials, either the weight or height map based materials. Also a little bit of optimisation on landscape materials to make sure there is performance as it can be. We discussed a little bit of virtual texturing and how you might approach virtual texturing in your projects, and also how to create holes in your landscape so you can paint in caves or anywhere where you want to go through the landscape"},{"start":"0:33","end":"0:42","startSec":33.0,"text":"as a player or a viewer. So hopefully that gave you some good starting points and directions to move in with your landscapes, and we'll see you in the next course. Thank you."}]},"311.02":{"01_Overview_5.00":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Hello and welcome to today's Unreal Engine training on advanced landscape sculpting and painting. So today we're going to be covering the sculpting and painting tools and how you modify the settings to get the desired results you're looking for. We'll also talk about how to refine some of these brush settings and we'll talk about the landscape spline tool, which is kind of useful for creating roads and barriers and things like this over your landscape. And then we'll discuss the landmass tool at the end of the course, so let's get jumped in."}],"02_LandscapeSculptingTools_5.00":[{"start":"0:00","end":"0:35","startSec":0.0,"text":"Let's start off by looking at some of the landscape sculpting tools. So I'll just open my editor and jump in there now. And with my editor open, I'm just in a default blank map here. And I'm going to go to the selection mode and go to my landscape. And you can change this to whatever size and scale you'd like. I just want to work with something a little bit smaller here today just to give you an idea of what's going on. I'll leave my components the same there and I'll just hit create. And then when we create, we also want to enable edit layers at the top left here."},{"start":"0:35","end":"1:06","startSec":35.0,"text":"And we'll show you what they do in a second as this gets loaded. And now with the landscape loaded, you can see that we've got this landscape here that we're preparing the shaders for as well. But at least we can start editing the shaders. So the landscape, sorry. So you'll see by default, I have this sculpt tool here. And what I can do is I can change the size of this by pressing the square bracket keys next to my key enter key on the keyboard."},{"start":"1:06","end":"1:36","startSec":66.1,"text":"So by doing open bracket, it goes smaller. Close bracket, it goes larger. And you can see this brush size is being changed here. So we can kind of just left click around to edit that. And so you can kind of see that we have all these different tools here. And if we go to flatten, we can kind of flatten out the landscape as well. But lots of different tools and you can change the strength of the tool depending on the result."},{"start":"1:36","end":"2:06","startSec":96.7,"text":"So brush size, brush fall off and the tool strength are going to be your friends here. And you can play around with some of these settings, especially on this top row here, just to kind of get the results that you're looking for on your landscape. You can also see that when we enabled edit layers, we have a few functionality available to us on our landscape. So once the edit layers has been added, we can then rename them to something more useful like a base mountains, roads, for example."},{"start":"2:06","end":"2:36","startSec":126.8,"text":"And then to use the edit layers, we first need to select a layer by clicking on it. And then we just edit the landscape as we usually would. So when we're done with that, we can just adjust the effect of the edit layer by adjusting the alpha input. So let's jump into the editor here and show you what's going on there. So you can see as we previously had, we had our landscape here. And you'll see that we have edit layers here. So we can right click on this edit layers, we can rename this to say, base, for example."},{"start":"2:36","end":"3:11","startSec":157.0,"text":"And then we've, you know, edited this layer as we've been using that tool. And then we can create a new one. And let's say we just scope some more on top of this layer. And you can see that then we can change the alpha of this layer to say how much of this layer we actually want to add on top of that, which it can be really useful for kind of painting in as we used in the previous example, the base and then the mountains and then the roads. So, you know, if I wanted to rename this mountain, for example, and just we can kind of make"},{"start":"3:11","end":"3:29","startSec":191.1,"text":"it so that it's preserving the information from the base and layering up our information. So edit layers might be useful for you, especially if you're doing a lot of detailed landscape work. And again, you can add as many layers as it takes to kind of get the results that you want while preserving the data from the layer below."}],"03_LandscapePaintingTools_5.00":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"Moving on to our landscape painting tools that we have available, you can see that in a similar editor window that we had before, you can see that we have the paint, the smooth, the flatten and the noise. And what's interesting here is we have these layers, which you see a grass layer, a dirt layer and a rock layer, which has been created through a material that we have applied to the landscape. So the material creation here is such that we use a layer blend node. So you can see the layer blend is just this option here. And then what"},{"start":"0:34","end":"1:08","startSec":34.6,"text":"we'll do is we'll add three expressions here. So you can just hold down three on your keyboard and left click, and that will bring up this coloured parameter here. Well, it's not a parameter by default, you can actually right click and make it a parameter if you'd like. So you can call this grass, you can call this rock, you could call this dirt if you wanted. But the main, the main thing we want to look at here is this layer blend node, where if we select it, we can actually add elements to the array by just clicking plus plus plus, that'll be on your bottom left hand of the screen here."},{"start":"1:08","end":"1:43","startSec":68.7,"text":"And if you make sure weight blend is assigned here, it should be set to that as default. But for each index, we then want to give it a layer name, we want to give it grass, maybe dirt, and then rock. And you can see that this will just go into the base colour of your landscape material. So it enables you to modify the appearance of part of our landscape by painting textures onto the landscape to help define some materials. So the tool settings here will work just as they do for"},{"start":"1:43","end":"2:15","startSec":103.8,"text":"the sculpting mode. And once the key difference is that you need to select the layer you wish to paint with when you're in landscape mode. So to show you what this looks like, if we've selected the layer on our landscape mode, you can show that we can either do a weight blended layer, which is a normal one, or we can do the non weight blended layer, depending on what this layer is trying to do. So to show you exactly what this looks like, you can see that the weight"},{"start":"2:15","end":"2:47","startSec":135.2,"text":"blended layer normal is this is the material and you would start painting in the grass. Whereas if it's non weight blended layer, everything is applied based on on the height of what your material is on the landscape. So you'll see I've created this super quick material in my editor here. I'm just going to make sure I go in and apply this material to the landscape, which you can just use by going back into selection mode, selecting the landscape,"},{"start":"2:48","end":"3:18","startSec":168.4,"text":"and then the landscape material just needs to be the landscape material there. So we'll just type in landscape. Try and find it. If I just say m underscore landscape, there we go. And then we'll apply that landscape material like this. And then if we go back into our landscape tool here, you can see that we've got our paint tab at the top here. And we essentially just want to be"},{"start":"3:18","end":"3:50","startSec":198.7,"text":"painting in the layers based on this layer information. So then we just want to press this little plus icon. And we want to select the weight weighted blend layer in brackets normal. So just as a reminder, the weight weight blend layers allows you to paint on top of layers, so the layers can then blend. So we want to use this when we want to blend say rock into an into dirt, sorry. And if you don't want the the weight, so non weight blended layers,"},{"start":"3:50","end":"4:22","startSec":230.3,"text":"it allows you to replace layers as you paint over them. So we want to use that when we have snow covering rocks or dirt, for example. So we can just press this plus button. We want the normal mode here. It'll suggest some kind of name for you. So you can just click save there. And then we'll just press plus and then click save. And then we'll just repeat this for the last time. And then layer normal, save. And then you can save everything here. So save all."},{"start":"4:23","end":"4:58","startSec":263.4,"text":"And then when everything's saved, it's just a case of painting in the information that you want. So if you want the rock, and I'll just make my brush a bit smaller here. But if we wanted the rock, we're just literally painting in the rock, as you see here. And again, we're changing the settings such as the fall off, the strength. You know, if you just want the solid rock there, you can do. Of course, this this won't look as beautiful as it possibly could do if you were actually trying to do it for for real. But you can imagine we have a dirt layer down here. I'll change the fall off"},{"start":"4:58","end":"5:33","startSec":298.6,"text":"a bit and maybe we just paint a bit of dirt down there, which is really strong. And then, you know, we change the tool strength, you kind of get the idea of how you may want the layers to blend. Your shader will keep rebuilding. You can imagine doing this on a larger scale. But here's a super, super basic material. Three const variables, vector const variables that we can change the color of. And you can see that we have the grass, the rock and the dirt. And it means we can paint that into the landscape and create some beautiful results like you can see here."}],"04_BrushSettings_5.00":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"So then onto our brush settings, we have a few things at our disposal here. We can have a circular brush like you saw in the example. We also can alpha a brush where we can assign a texture, a texture sorry, just to a pattern or an alpha style stamp which we can then use to paint into the landscape. So you don't just have to use a circle brush when editing landscapes. We can select this alpha which will allow us to use a texture as a mask here. And then also if we select a pattern, it will project a pattern onto the landscape which can be used as a mask."},{"start":"0:34","end":"1:04","startSec":34.0,"text":"So if we look at the settings here, both the alpha and pattern brush will allow you to adjust the look of the texture that is projected onto the landscape. And then you can store the different masks in the RGB and the alpha channels of a 2D texture. So if we use a clay brush to give the top of the brush a flatter look than the standard alpha brush, we can do that. And here are some settings that you might want to use between an alpha and a pattern brush, for example."},{"start":"1:04","end":"1:33","startSec":64.0,"text":"And then there are several different types of brush fall offs that can be selected with these settings enabled. So you can adjust the brush fall off to be more or less the brush fall off input in the brush settings section. And you can adjust the brush fall off from point one to one essentially. So we can see the smooth, the linear, the spherical, the tip. And you can just see how the different settings may adjust to whatever your desired result is."},{"start":"1:41","end":"1:45","startSec":101.0,"text":"So that's the end of the video. Thank you for watching."}],"05_LandscapeSplines_5.00":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Looking at landscape splines next. You can see that in this image here, you can see the splines being used to map out a road and some barriers here. And so landscape splines can do a number of really interesting things in your landscape. We can place splines down by holding down the Control key and clicking on the landscape, and then we can move and rotate and modify the tangent handles of the landscape splines. In a similar way, you might have used the spline tool in a number of other ways inside of Unreal."},{"start":"0:31","end":"1:05","startSec":31.7,"text":"It's the same controls there to move the tangent handles. And we can just click the landscape spline icon, which you can see here in the viewport to allow you to do this. So you can deform the landscape using splines as a guide, and it's great for making paths or roads. And to do that, you just go to the tool settings, click on the deform landscape to splines option, and then we can do this through the all splines or just the current one selected. So you can see an example here of using the spline"},{"start":"1:05","end":"1:35","startSec":65.8,"text":"in the details panel under landscape spline. You wanna press the segments buttons to select all the landscape splines. And if done correctly, you should now see the option in the details panel called the landscape spline mesh. So if you select the landscape spline mesh and press the plus icon to add a new static mesh to the array, we can add a road for example, like in this image. So for the mesh, we can import the SM underscore street"},{"start":"1:36","end":"2:06","startSec":96.0,"text":"static mesh, which I'll do here in a second in the editor to show you exactly what's going on. And then we just want to uncheck center horizontally and change the forward axis to Y because of the orientation of the road mesh. Just make sure you uncheck cash shadow on your road setting mesh. More for an aesthetic reason, doesn't necessarily need to be done, but it just looks a little bit cleaner when we add that road spline. So let's jump into the editor here and do that. So when we're back in our editor here,"},{"start":"2:06","end":"2:37","startSec":126.8,"text":"we can go to the manage tool at the top, select splines, we're still in our landscape mode as well. And then as mentioned, you hold down control and left click. And so that will add a key onto the landscape. So you can see that we've got landscape spline selected and you can just hold down alt and drag to create a second spline path here. So I'm just going to grab my road mesh."},{"start":"2:37","end":"3:11","startSec":157.0,"text":"I'm just going to right click on my content, create a folder called meshes. And from the other screen, I'm just going to drag in my FBX, which is the SM street FBX that we were talking about before. So we've got the street and let's just save all there and just make sure everything's saved correctly. So now in the detail setting of the landscape, we then want to find this details panel and we want to go to the segments section of the landscape."},{"start":"3:11","end":"3:44","startSec":191.4,"text":"So we can select the segments and then we want to go to the landscape spline mesh. And press the plus icon. And then you'll see this index here and it's looking for a mesh. So we just want SM street mesh found here. And then we want to uncheck center horizontally. As you can see, it's come in on the different axis. So let's just uncheck center horizontally"},{"start":"3:44","end":"4:15","startSec":224.3,"text":"and change the forward axis to Y. There we go. And so we can untick our shadow again for aesthetic reasons, completely optional and up to you. But you can start to see how we might be able to edit this landscape based on the different settings that we have available to us using the spline tools. So if I just hit space bar, you'll see I've got my gizmo here. And essentially again,"},{"start":"4:16","end":"4:48","startSec":256.8,"text":"as beautiful as we made this landscape look, you can make your roads look beautiful. You can hold down alt to add a new point. Again, like we said, we have the same widgets and gizmos available to us when making landscapes. So we can move these around. Again, you can like lift these up, et cetera, et cetera. You can kind of get the idea, but hopefully that gives you a good starting point for using splines on your landscape. Again, some of the settings that you'll need"},{"start":"4:48","end":"5:10","startSec":288.0,"text":"are to do with the segments of the mesh that you're using. If you're importing a mesh that doesn't look quite correct, just check whether the center horizontally needs and check in and also which the forward axis is. So if Y is the forward axis for your mesh, just make sure you set that. And then we untick shadow in this instance just to make it look a little bit more visually pleasing."}],"06_Landmass_5.00":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Next up, and lastly, we've got the landmass tool. So we can enable landmass from the plugin. So if you unsure where your plugins window is, you just go to edit at the top of your browser, go down to plugins, you can either just type landmass in the search bar, or you can find it in the other tab. When you enable that, your editor will likely want to restart. So just go ahead and restart your editor, and then we can move on to the next step. So we can still create a new landscape using landmass."},{"start":"0:31","end":"1:02","startSec":31.0,"text":"So we want to open up landscape tool, make a new landscape, any size again, however you would like to make that look, and just make sure that enable edit layers is enabled. The landmass tools require that setting as we used last time, in order for these to work. And then we have a few different options available to us. So we want to make sure we're in landscape sculpt mode, which is the setting that we used previously. And then from the quick add in the project menu, we want to look for the custom brush"},{"start":"1:02","end":"1:33","startSec":62.1,"text":"landmass. So with this little icon, you can just type in landmass. And this act will allow you to control the location that landscape will be affected by the brush. So we can add more points from this brush when we've dragged it in. You can add more points by selecting one and pressing alt whilst dragging exactly how we did with the spline tool in the landscape. So we can just make these different shapes using this custom brush landmass, which then you can edit over the top of."},{"start":"1:33","end":"2:06","startSec":93.5,"text":"So you can see that we can start getting some really cool results here. We can also use the material to offset the landscape. So if we wanted to add a change any settings here, here are some example brush settings, which is a simple brush where you can see that that just adds a lot of interest to the environment. So you can do that by first setting the brush type to material only. So you can see brush type is material only. And then to adjust the look, you just offset what you need to do in the brush material."},{"start":"2:06","end":"2:41","startSec":126.5,"text":"So when you can see that we've masked out some information here in our sample simple brush and you can see that landscape then gets edited based on this material information, which is pretty cool. And then we can also do some more custom things here. So we can use a material to offset the landscape. So again, material only, but we want to, so we want to set the material to material only. And then to adjust the look of the offset, we just need to, again, just use this custom override material where you can see that there's now the Unreal Engine logo, which is you just"},{"start":"2:41","end":"3:12","startSec":161.8,"text":"tick the override material. So even though we had a simple brush material to begin with, you have an override material as well. So here's an example of the material. So to make the material work with this, the material needs to be unlit. So make sure your material setup is unlit and use two material functions. So we want to unpack RGB height here. And this is for unpacking brush data into a format that can be worked into the editor. And then we also want to pack the RGB height."},{"start":"3:12","end":"3:42","startSec":192.8,"text":"And this is repackaging the brush into something that will work with landmass. So these two functions that highlighted, that's what you'll need to make your material work. And then the material was converted into a material instance to make it easier to work with the landmass system. So once you've created this, you can change that texture sample into a parameter if you want. Just turn it into a material instance because then that makes the editing easier. For a more in-depth example, check out the default landmass brush."}],"07_ThankYou_5.00":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"So thank you for checking out today's course on the landscape painting and sculpting. Hopefully it gave you a good overview of some interesting tools you may not have used before, whether that's to do with the landscape sculpting and painting tools, and also just the cool brush settings that we have available to us when editing these landscapes. We touched upon splines, which can be a really powerful tool to get a lot of mileage out of your landscapes, whether it be roads or with barriers or whatever it is you want to be adding to your landscapes."},{"start":"0:30","end":"0:45","startSec":30.0,"text":"And then the landmass tool, which is a cool new feature on Unreal Engine to really get some quite unique and interesting results from the landscape. So hope you got a good use of some tools that you may not have used before, and we'll see you in the next course. Thanks."}]},"311.03":{"01_Overview_5.00":[{"start":"0:00","end":"0:20","startSec":0.0,"text":"Hello and welcome to today's Unreal Engine training on advanced foliage and grass. So today we're going to be covering the foliage tools. We'll talk about the different types of foliage you can have. We'll talk about LODing, which is level of detail on your foliage just for some optimization. And then we'll go over some tips and tricks to close out. So let's get started."}],"02_FoliageSettings_5.00":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"So let's kick off with the foliage tool settings and to do that I'm going to jump inside my editor and with my editor open I'm going to go into the foliage mode. So you can find the foliage mode at the top left and we'll just go to foliage. You'll see the hotkey is shift 3. So if you want to hit shift and 3 on your keyboard you could also do that and you'll see that we have this new window pop up for the foliage. So we can essentially add any static mesh for foliage type we want into this tool and all we have to do is just drag"},{"start":"0:32","end":"1:04","startSec":32.5,"text":"the asset from the content browser which is down here into this foliage section. You can see this big text here saying drop foliage here. So we'll just go into our mesh and we'll get a bush mesh and we'll just drag and drop that in there and I'll give myself a bit more real estate here. And so you can see that we're preparing us for foliage shaders. You can see that we've got this bush selected here and you'll see now when we go into our browser you can see the painting tool. So we"},{"start":"1:04","end":"1:40","startSec":64.2,"text":"can if we left click here you'll see that we've painted some bushes and it's interesting to know if I'm just going to select mode now you'll see that we've got 41 actors and that was 41 bush meshes placed on that stroke. And so since we painted that foliage we just want to go in and sculpt our landscape. We can just left click wherever we would like and you can also shift and left click to remove foliage. So if I went back into the paint tool and I held down shift"},{"start":"1:40","end":"2:15","startSec":100.6,"text":"I could left click and that deletes some and you'll see that that number has gone down. So we've got a little save icon here where you can save the foliage assets and whether it's you know active or not. So if you toggle this on and off it depends whether that foliage is selected. So let's take a look at exactly what all these settings do. So I've loaded up a screenshot of exactly what you'll see in the foliage tool as we saw in the engine there and I just wanted to go over some of the settings here. So we've got the selection tool and that's used to select"},{"start":"2:15","end":"2:49","startSec":135.7,"text":"individual instances, all instances, deselect, we can lasso select. You can see all of these different settings for selection inside of your foliage settings. We've also got the paint tool which is used for adding and removing foliage instances from the world as you just saw. We've got the reapply tool which is used to change the parameters of instances already painted in the world. We've got the single tool that's used to place a single instance of the selected foliage"},{"start":"2:49","end":"3:21","startSec":169.4,"text":"using the paintbrush. We've also got the fill tool which is used to determine the number of meshes to place with the paint tool. Erase tool pretty self-explanatory but it's used to erase selected foliage. We've got the remove tool which removes the selected foliage and we've got move which moves the foliage to a different level. You may be using less of this tool in the more recent versions of Unreal Engine. It depends if you're changing levels as much with your foliage but it's still useful to know that. So the paint and brush options will have different options based"},{"start":"3:21","end":"3:52","startSec":201.6,"text":"on the tool selected and the filters then allow you to select which items you want from the foliage to be used on. So there's loads more settings that you'll see covered. You'll see that brush sizes, density, all quite self-explanatory and it's more about just playing around with these different settings to get the results that you want. We can also change the mesh as you saw when we were painting the mesh. You can see that the static mesh is found here so what we can also do once"},{"start":"3:52","end":"4:28","startSec":232.8,"text":"the objects are placed allowing you to quickly change and not having to rework it. So if you wanted to update that mesh and you didn't want to go in and paint everything again you could easily do that with the mesh update there. We also have the painting settings where we've got the density and we've got the radius but then we've also got scaling where we could change minimax values. Say you wanted some variation in your foliage size for example you could set the minimax to say 0.5 and 2 and you could get varying degrees of foliage so it just didn't feel like the same"},{"start":"4:29","end":"5:01","startSec":269.1,"text":"repeating action over and over. So the paint tools do allow you to control how many objects are placed and then the radius helps just make sure things are not intersecting so that that radius setting there just makes sure that you can either clump things densely together or really really space them out a lot more. We've also got the placement settings where placement allows you to control how the meshes are aligned to the surface area applied to so you can offset the vertical position"},{"start":"5:02","end":"5:36","startSec":302.6,"text":"up and down if you wanted to add some variation like you can see in this image here so you can give a max angle height and a max angle and height sorry that can be then applied. We've also got the instant settings here so instant settings essentially control how the foliage reacts to lighting, collision and culling so you can set if you want the foliage to use a light map or not it depends if you're using fully dynamic solutions like lumen. We can also set the distance"},{"start":"5:36","end":"6:08","startSec":336.0,"text":"at which the foliage should stop rendering and then lastly to cover some further settings we've got scalability settings here and that allows you to work the foliage with the scalability setting system built into unreal so this allows the system to control the foliage settings based on whatever user settings you may have set. We also have the physics so this is a physical material override that allows you to apply it to the foliage so physical materials could be used for certain"},{"start":"6:09","end":"6:40","startSec":369.5,"text":"surface parameters such as if you wanted it to be slippy ice or gravel but it also can be used to detect say footstep sounds and just different parameters you want when you're walking through foliage to change maybe the player's behavior. We do have the virtual texture here and that's for any foliage that you wish to draw to the virtual texture and then the h-lod which do you want to include them in their h-lod calculations there."}],"03_FoliageTypes_5.00":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Now that we understand what some of the foliage settings do, let's dig into foliage types and what you have access to here. So there's three main foliage types. We have the active foliage, the landscape grass type, and the static mesh foliage. So foliage types allow you to make presets that can be then used as bases for other types of foliage. So foliage types are made from and stored inside the content browser. So you can see these little icons here. That means they have some kind of data asset that belongs in the content browser."},{"start":"0:33","end":"1:06","startSec":33.6,"text":"And then each type is for a specific interaction type. So kicking off with active foliage here, the active foliage is if you want the foliage to be interacted with. The landscape grass type is for densely populated landscape grass. And then the static mesh foliage is for any static or non-interactive foliage you would like to use. So looking at these foliage types here, if you want to run a blueprint on your foliage, then active foliage is what you'd need to use."},{"start":"1:06","end":"1:42","startSec":66.1,"text":"It works just like any other foliage type, but it has an input for a blueprint actor, which you can see in the details panel here that can then be used to spawn from it. So it allows you to use the same tools, but scatter, say 100 or 1000 of it, an interactive object instead of having to hand place them individually. Then if you can see from this image here, you can see an example of that working. So the box in front of the use, the player will trigger an event when the user goes in"},{"start":"1:42","end":"2:14","startSec":102.0,"text":"and out. So we'll go in and out of this box. And then the boxes where the painted landscape are using the foliage tool. Then with the landscape grass type, this grass tool is used to densely cover the landscape, as we said before. So you can cover the landscape terrain with things like grass or flowers and small rocks. And you don't need to paint the area, but instead define where the grass should spawn based on which landscape layer is visible. So you can also specify things like density and offsets to allow for a variety of different"},{"start":"2:14","end":"2:49","startSec":134.3,"text":"looking grasses here. And then to show a setup here. So the grass tool allows you to add thousands of static meshes to the landscape to help simulate what grass will look like. So with the grass tool, you can add grass to the entire landscape or just specific landscape layers, like we said. So you can also use it to control the density in the distance at which the grass will render. So there's some optimization settings there. And then for this type of setup to work, you would need to add the landscape grass type,"},{"start":"2:49","end":"3:23","startSec":169.6,"text":"which is where the static meshes are used for the grass. And they're defined there. You can have more than one static mesh in a single grass type. So that should be noted there. So if we have landscape grass type, then we'd also want landscape grass output. And that is this material expression here. And it's the material expression node, which essentially just tells the landscape actor which layer you should have the grass placed on. So you can also have a number of different grass types in your material. And then the mesh used does not have to be grass, as we said before, it could be any kind of"},{"start":"3:23","end":"3:50","startSec":203.7,"text":"mesh or material you want to use there. So you can use it to display rocks and bushes and flowers and small trees, as we said previously. And then lastly, covering the static mesh foliage type. So with the foliage type, we can use static mesh foliage types with the foliage paint tool. So you can just see the paint settings here. So each foliage type you add can be painted using this tool. So nice and straightforward."}],"04_FoliageLODs_5.00":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"At this point it would be useful to touch upon some LOD settings you might be able to get access to in your foliage. So foliage does not support the use of level of detail or LOD meshes but there are a few other restrictions. So you should ensure that your static mesh has only one entry in the elements array which is visible under log zero. So that's the first step, make sure your static mesh only has one entry in the elements array under the LOD."},{"start":"0:31","end":"1:07","startSec":31.9,"text":"The light and shadow maps are shared between all LOD levels so LODs need to use the same unwrapping on their UVs. So currently the entire cluster of instances change LODs simultaneously. So there may be support for distance based fading per instance in the future but it's not currently supported. So lightmap coordinate index must be set to a valid UV channel that has a unique UV unwrapping. The static mesh editors generate UVs feature is an option here where you could just use"},{"start":"1:07","end":"1:41","startSec":67.2,"text":"in the static mesh editor window you can generate unique UVs and that will allow you to access the window from the window menu and quickly generate some unwrapping there. With the lightmap resolution this must be a small enough number so that all the shadow maps and for instances in a single cluster can be tiled together without exceeding the maximum texture resolution which is 1496 by 1496. So the shadow maps must be considered there. Again it depends if you're using a static solution or a fully dynamic global illumination"},{"start":"1:41","end":"2:07","startSec":101.3,"text":"system like Lumen but again you're going to have to make these trade-offs and with all LOD settings you need to make the trade-offs depending on what project you're working on. And then to make the foliage fade you just need to use a per distance fade node like this image here for a material setup. So hopefully that gives you some good initial LOD settings to start thinking about when working with foliage in your projects."}],"05_TipsTricks_5.00":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"And then lastly, let's go over some tips and tricks that you might be able to apply to your foliage in the project. So we can restrict foliage placement. So we can do a number of things to restrict the placement of foliage. In the advanced section here, which you can see highlighted, you can define the landscape layers and this foliage should be allowed on or not. So do you want to just place the foliage on specific layers, either add them to the inclusion layers or the exclusion layers and this will give you much more control of"},{"start":"0:31","end":"1:03","startSec":31.3,"text":"where you are placing the foliage. You can also adjust the ground slope angle to restrict the slope at which the foliage will be placed. So that's always worth knowing. And then also when we're looking at the landscape grass, the grass tool can be used to mask and adjust the placement or you can just disable the setting like the placement jitter to make something that looks like a field of crops. So, I mean, you can get some really, really nice results by actually using these tools to create something a bit more uniform if that's something that you"},{"start":"1:03","end":"1:26","startSec":63.5,"text":"want in your project. So when used with the foliage tools, the grass tools are really, really powerful. So worth considering those as well. So to close out here, we've covered foliage tools, the settings and the types, talked a little bit about LOD and hopefully giving you some cool tips and tricks there at the end on your foliage settings. So let's go and close out the video."}],"06_ThankYou_5.00":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"So thank you very much for watching this video today on the foliage settings, the advanced foliage and grass placement settings. We've talked about the tools, the types, foliage, LOD, a few tips and tricks. Hopefully it just gave you a good kind of onboarding onto your journey using foliage, what all the different buttons are doing. And a lot of it is just playing around with the different brush sizes and densities and ticking tick boxes and unticking them and just seeing what results you can get."},{"start":"0:31","end":"0:47","startSec":31.1,"text":"Again, hopefully we pointed you in the right direction of some tools that can help automate your life a little bit, you know, rather than having to go through and place individual bushes and rocks. Hopefully it gave you some good indication about what you might be able to apply to your projects. So thank you again for watching and we'll see you in the next video."}]},"311.04":{"01_Overview_5.00":[{"start":"0:00","end":"0:18","startSec":0.0,"text":"Hello and welcome to today's Unreal Engine Training on World Partition Techniques and Applications in 5.0. So today we're going to be covering what World Partition is, I will talk about the template that you can use for World Partition, and we'll talk about the tools and debug commands that are available to you. So let's jump in."}],"02_WorldPartitionOverview_5.00":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Let's kick off by talking about exactly what World Partition is and giving you a bit of an overview of this. So what is the big picture here? So World Partition we can use to create open worlds that will require you to use a few different tools in combination with each other. So all of these tools are designed to be used together to help you make open worlds run more efficiently. And you just want to keep in mind that some of the tools can be used independently if you know, one or a combination aren't supported."},{"start":"0:31","end":"1:06","startSec":31.5,"text":"So let's talk about World Partition in the top left here. So World Partition is an automatic data management and distance based level streaming system that provides a complete solution for a large world management. So if we're making any kind of large worlds and we want to take into account level streaming, World Partition is our go-to here. One file per actor reduces overlap between users by saving data for instances of actors in external files, removing the need to save main level file when making changes to its"},{"start":"1:06","end":"1:41","startSec":66.2,"text":"actors. So traditionally or historically, if you've used Unreal Engine, you may have had different departments working on different streamed levels inside of Unreal Engine, maybe just more for organization purposes, making sure multiple people can be working on the file. Now you can use one file per actor, which means users can work on individual actors and submit them to the change lists and things that you're working on rather than submitting entire level files, which is a massive improvement to a workflow there."},{"start":"1:41","end":"2:13","startSec":101.3,"text":"We got level instancing on the top right here and level instancing is a level based workflow that facilitates the porting of non-world partition worlds to world partition system. We've also got data layers and data layers are systems within world partition used for organizing your actors into separate layers. Then we've got the HLOD. The world partition is the hierarchical level of detail. That's what HLOD stands for, hierarchical level of detail. That's a system that uses custom HLOD layers to organize large amounts of static meshes"},{"start":"2:13","end":"2:45","startSec":133.7,"text":"and generates a single proxy at a mesh and a material to use within that HLOD. We got virtual textures and we need this for the MIP map to work. So virtualizing the textures will make the MIP maps function correctly here. We've also got virtual shadows. The virtual texture support for our project enables us to create and use large scale textures for lower and more consistent memory footprints at runtime. Then using Nanite, Nanite is UE5's virtualized geometry system, which uses new internal mesh"},{"start":"2:45","end":"3:16","startSec":165.9,"text":"format and rendering technology to render pixel scale and detail at high object count. So you can have much higher poly meshes, more detail in your scene using this Nanite technology. Other additional tools that can also help, but we won't be covering today, which is the mass entity and smart object. So you could do a bit of research on the documentation for mass entity and smart objects if you'd like to go into more detail in those areas. So let's look at world partition overview."},{"start":"3:16","end":"3:31","startSec":196.5,"text":"So when all of these tools are used together, you can make something like this. So the top image is the city sample, aka the matrix awakens. And then we've also got the valley of the ancients demo down in the left hand side here."}],"03_WorldPartitionTemplate_5.00":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"So how do we get access to this world partition? Well, world partition comes with a template that we can access from our launcher. So we can see here that the supported content, use one of these game templates, can help ensure that your project is open world compliant right from the start. So the blank, the first person, third person, top down and vehicle advanced are all project types and templates that can operate within the world partition. You can enable the needed features later on using games template,"},{"start":"0:33","end":"1:08","startSec":33.0,"text":"just to ensure that you are set up for success from the start. Next, we need to make sure streaming is enabled. So if you do not use the template, you can go to the world settings and then under world partition. So world settings can be found from a window at the top and go down to world settings. World settings, you just want to go to this world partition section, click enable streaming and this will set up the streaming portion. But you still need to set up other items like world partition, one file per actor, data layers and HLOD."},{"start":"1:08","end":"1:40","startSec":68.0,"text":"So the template level that you'll open within your project, just from a new level box, you can see that you can select the open world or empty open world and it'll start you off in a new map that's ready to use most of the world tools. So the default open world comes with, so if we select this new level, that will come with world partition, one file per actor, data layers, the hierarchical level of detail, which is a HLOD, it'll come with a sample 2K by 2K landscape, which you can see here,"},{"start":"1:40","end":"2:12","startSec":100.0,"text":"with a landscape material and lighting set up for an outdoor environment, which does a lot of the heavy lifting for you. You also got use of the sky atmosphere here. We've got the skylight, directional light, exponential height fog and also volumetric clouds. So right out of the game, Unreal does a lot of the heavy lifting for us if we use this template open world. Then looking at the grid of world partition. So the second fact that we're using to determine whether a grid cell is loaded or unloaded at runtime"},{"start":"2:12","end":"2:42","startSec":132.0,"text":"is the settings of the runtime grid itself. So runtime grid settings are located in the world settings. So again, go into that world settings panel. And then in the world partition setup section, which you can see here, we've got a 2D runtime hash grid that is provided by default. So you can see this runtime hash. So using more than one grid can negatively impact performance. So you just want to really go with one grid setup as that will impact performance."},{"start":"2:42","end":"3:14","startSec":162.0,"text":"So size is in meters. So cell size, you've got meters there. So 25,600 is 256 square meters for cell size. So the 76,800 loading range is 768 meter radius around the streaming source. So just to put those numbers into context, that's 768 meter radius around the streaming source."},{"start":"3:14","end":"3:46","startSec":194.0,"text":"And then you'll need to experiment as each project will have just different requirements based on what you're trying to achieve here. To give an overview of the streaming source. So the streaming of grid cells within a grid at runtime is determined by two factors here. We've got the streaming source and then we've also got the runtime grid settings. The streaming source found on the left hand side here, the components that define a position in the world and trigger the loading of cells around them. So the player controllers in this instance are the streaming source."},{"start":"3:46","end":"4:20","startSec":226.0,"text":"Other streaming sources can be added to the world using world partition streaming source component. If you want that extra functionality over who or what is a streaming source in the project. When we're looking at streaming the grid, there are two components here. That we're using for controlling the loading of cells around the streaming source. So the streaming source components that define position in the world and trigger the loading of cells around them. So again, like we said in the previous instance, you'll see the player controller here."},{"start":"4:20","end":"4:51","startSec":260.0,"text":"And the player controller is an example of the streaming source. And then the grid determines whether a grid cell is loaded or unloaded at runtime based on the cell size and the loading radius. So you can see these in the top down grid in action based on the settings that we set in the previous slide. So in order to see the grid working, you'll need to make sure you have a streaming source, which is usually the player seen in this image and then a content, some kind of content placed in the world, which we're getting from this template."},{"start":"4:51","end":"5:24","startSec":291.0,"text":"So below the grid, you'll see a key that tells you what corresponds to the grid image. So if you need to understand what you're visualizing here, you'll see that key. And then you can also view the grid using the commands WP.runtime.toggle.drawruntime.hash2d. And then also WP.runtime.toggle.drawruntime.hash3d."},{"start":"5:24","end":"5:54","startSec":324.0,"text":"So the hash2d and the hash3d. And if you type in these, it may just auto complete those as well. You can find all this in the documentation as well. So if we're looking at converting our existing worlds into world partition, you can use the world partition conversion commandlet like we mentioned at the start. So this is mainly for projects coming from UE4 that want to make the use of this UE5 feature. So if your documentation is going to be your friend here,"},{"start":"5:54","end":"5:59","startSec":354.0,"text":"you'll understand how to use this tool by digging into the documentation there."}],"04_WorldPartitionTools_5.00":[{"start":"0:00","end":"0:30","startSec":0.0,"text":"Next up, let's talk about the world partition tools that are available to you. So we have world partition and world partition is automatic data management and distance based level streaming as we mentioned at the start. So it's a system that provides a complete solution for large world management. The world partition system works by storing your world in a single persistent level file and then subdividing that space into a streamable grid like you can see here."},{"start":"0:30","end":"1:02","startSec":30.3,"text":"And then the streamable grid cells use the configuration that you set on the runtime grid. So these cells are loaded and unloaded at runtime by the presence of the streaming source. As we mentioned before, the streaming source is going to be the player here. And in this way, Unreal Engine only loads the parts of the level that the player sees and interacts with at a given time. So it's really, really nice, powerful optimization tool here. We've got level instance in here. So level instances were originally created to replace Fortnite's foundations,"},{"start":"1:02","end":"1:38","startSec":62.7,"text":"allowing multiple instances of a level to be used in the world partition level and the classic. So we improve the overall level editing workflow experience here. So what are the features? So the features are nested in hierarchical level instances. We've got edit in context, which always is the original level, not a pair instance or data edit support. We can also have multiple instances within the same world. We've got an embedded mode, which is the default mode, and that's content pushed to the persistent world partition grid."},{"start":"1:38","end":"2:10","startSec":98.5,"text":"And we've also got level streaming mode for non one file per actor levels. So if you do want to make use of level streaming, you can do that. But also, as we mentioned at the start, the one file per actor is a really great system for collaborative environments. Data layers on the level instance actor is also a good feature, and it's pushed to the entire content. So what are the use cases here? So we may do points of interest, we may do houses, standalone gameplay setups."},{"start":"2:10","end":"2:44","startSec":130.2,"text":"And then also, when we're talking about a packed level actor, we generate a single optimized version for the render engine blueprint actor. So it supports only static mesh components. So this is a non destructive way. So if we are looking at the packed level actor, the features outputs a packed level actor blueprint, which with only static mesh from the content. We've got the feature that outputs a level that is linked to a packed level actor for non destructive editing."},{"start":"2:44","end":"3:15","startSec":164.9,"text":"And then also you can have multiple instances like any other actor within the same world. And then the data layers are packed on the level actor only. So really, really cool features there. And then the use cases of the packed level actor might be static buildings in the city demo or very dense visual only setups with multiple instances of the same models. So as we've been alluding to the one file per actor is a really powerful tool to use in your projects in previous versions of Unreal."},{"start":"3:15","end":"3:48","startSec":195.1,"text":"When you wanted to make changes to one or more actors inside a level, you needed to check out that entire level in source control, which meant multiple people couldn't work on it. So it locked the team members out of that file until the work was complete. It could then slow down the development process because only one person could work on that file. So one file per actor reduces overlap between users by saving data for instances of actors in external files, removing the need to save the main level when making changes to its actors. So one file per actor is enabled by default when using world partition."},{"start":"3:48","end":"4:23","startSec":228.6,"text":"And the use of one file per actor outside of world partition is currently considered experimental and is disabled by default. So one file per actor feature is designed to be granular and can be used in two different ways. So first way, after selecting the option, you'll be asked if you want to enable the feature for all the actors in the level. Select yes to convert all the actors to one file per actor or no, which only enables it for the selected actor. So you can either say yes, I want to convert all actors to one file per actor or no, I only want to use it on this one actor that I have selected."},{"start":"4:23","end":"4:53","startSec":263.4,"text":"So it's kind of opt in or opt in to everything per actor, which is a really cool tool there. We also got data layers inside of Unreal Engine. So data layers are a system within world partition used for organizing the actors into separate layers. So the layers can be loaded and unloaded to organize your world. So data layers serve as a replacement for previous layers found in older versions of Unreal. And with data layers, gameplay elements and environment assets can be separated in the editor at runtime."},{"start":"4:53","end":"5:28","startSec":293.9,"text":"So if you're using data layers, what does that mean? How can we separate an editor and at runtime? So it means that artists can work on specific elements without interacting with gameplay triggers or objects. Designers can dynamically load layers to design intriguing gameplay and elaborate level transitions at runtime. This can be useful for gameplay purposes. Keeping with the world partition system's goal of minimizing file overlap between users, we can have data layers that reduce the need for users to check out important files such as world map file or actor files when making changes."},{"start":"5:28","end":"6:03","startSec":328.9,"text":"Each data layer has a display label and an internal unique identifier. And then Unreal stores the information in a list of data layers in the world data layer file, which provides some of the benefits that I'm going to go into. So three benefits here of world data layer is assigning data layers to an actor only affects the actor's file in world partition, which uses the one file per actor. We can also rename a data layer to have it only affect the associated level."},{"start":"6:03","end":"6:39","startSec":363.2,"text":"So then there'd be no need to update any actors associated with that layer. You can also delete the data layer, which only affects the world data layer file. So actors previously associated with the data layer are automatically cleaned up with no need to modify or save the actor. So data layers states can also be changed via blueprints. Next, looking at the hierarchical level of detail, which is the HLOD. This system uses HLOD layers to organize large amounts of static mesh actors to generate a single proxy mesh and material."},{"start":"6:39","end":"7:11","startSec":399.7,"text":"So this technique is used to visualize unloaded world partition grid cells to reduce the number of draw calls per frame. And it also increases performance, especially when you have these large open worlds. So you can create a HLOD layer by right clicking in the content browser and going to miscellaneous HLOD layer. And then you can have various HLOD layers that are used throughout your entire project. So the settings on the HLOD are instancing, merged mesh, simplified mesh and approximated mesh."},{"start":"7:11","end":"7:43","startSec":431.1,"text":"So with the instancing, which is the first option, the layer is composed of an instant static mesh. So you might say ISM for instant static mesh and their components used with the lowest level of detail meshes. So if you're using instancing, that's ideal for imposters, for example, trees ought to replicate the source actors geometry whilst dropping non-visual data. Merged mesh, meshes included in this layer are merged to create a single mesh."},{"start":"7:43","end":"8:17","startSec":463.2,"text":"Simplified mesh, where mesh is included in that layer, are merged and the mesh is simplified for performance. And then the approximated mesh is similar to simplified mesh, but it uses a newly developed algorithm that performs much better on complex scenes, which contains many instances on nano enabled static meshes. So to see the changes, you'll need to go to the build menu at the top of your editor and select the build HLOD option. And then the system will only build LODs that are needed to be rebuilt."},{"start":"8:17","end":"8:51","startSec":497.6,"text":"So this can be done from a command line as well, so that it can be run during nightly builds as well. Looking at the virtual textures, and so virtual texturing is needed for the minimap generation, like we said at the start. So while it's not required for open world tools to work, it does help and should be used whenever possible. So Unreal Engine supports two virtual texturing methods. We've got the runtime virtual texturing, which you'll sometimes see as RVT, runtime virtual texturing and streaming virtual texturing SVT."},{"start":"8:51","end":"9:24","startSec":531.2,"text":"So runtime virtual textures are used for procedurally generated content and heavy layered materials. Supports larger texture resolutions. The textual data cached in memory on demand. Textual data is generated by the GPU at runtime and it's well suited for textual data that can be rendered on demand. Such as procedural textures or composite layer materials. So the streaming virtual textures are used for reducing texture memory overhead when using larger texture sizes for items like lightmaps."},{"start":"9:24","end":"10:00","startSec":565.0,"text":"So it supports larger texture resolutions. Textual data is cached in memory on demand. Textual data is cooked and loaded from disk and that's well suited. So streaming virtual textures are well suited for textual data that takes time to generate, such as lightmaps or large detailed artist created textures. So using virtual shadow maps, which you'll sometimes heard as referred to as VSMs, is a new shadow mapping method used to deliver consistent high resolution shadowing that works with film quality assets and large dynamically lit open world."},{"start":"10:00","end":"10:32","startSec":600.2,"text":"So VSMs are built to work seamlessly in Unreal Engine. And we can use the Nanite virtualized geometry, the Lumen global illumination reflections and also world partition features with virtual shadows. And lastly, we have Nanite. So Nanite is Unreal Engine 5's virtualized geometry system, which uses the new internal mesh format and rendering technology to render pixel scale detail and high object counts. And it intelligently does work on only the detail that can be received and no more."},{"start":"10:32","end":"10:54","startSec":632.7,"text":"So only what the viewer can see, it'll work on that. So Nanite's data format is highly compressed and supports fine grained streaming with automatic level of detail. So Nanite should generally be enabled whenever possible. So any static mesh that has it enabled will typically render faster and take up less memory and also disk space."}],"05_DebugCommands_5.00":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Before we close out, let's just go over a couple of debug commands that you have access to with World Partition. So run in the console command wp.runtime.toggledraw runtime hash 2D. And again, this should auto fill on your console command. You can find these console commands on the documentation as well. So read that again. So it's wp.runtime.toggledraw runtime hash 2D. At runtime displays the HLOD cells that are loaded in the green."},{"start":"0:33","end":"0:45","startSec":33.6,"text":"And then you can also see the 3D version of the same command. So instead of using runtime hash 2D, you just use runtime hash 3D. So they can just help visualize what's going on in your scenes there."}],"06_ThankYou_5.00":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"So thank you for checking out today's Unreal Engine training on world partition techniques and applications in 5.0. We've covered a lot of ground with a lot of features, so we talked about the world partition and what it is, how to get set up using world partition in your templates, and also just how to enable it in your projects if you have existing projects where you didn't use a template. We covered all the different tools that come with world partition, and then we also gave a couple of debug commands at the end. So hopefully you found that useful to just get an overview of what world partition is"},{"start":"0:32","end":"0:37","startSec":32.7,"text":"and how you might use it in your projects. So thank you again for watching, and we'll see you in the next video."}]},"311.05":{"01_Introduction_5.00":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Hello, and welcome to another Unreal Engine training course. My name's James Burton, and today we're going to be taking a look at advanced landscape creation. Just to give you an outline of what the course actually entails, we'll first be taking a look at landscape technical details, which will allow us to essentially understand what's going on under the hood and what each section and each component of the landscape tool actually is. Then we're going to be taking a look at the landscape management so that we can actually edit our landscape and our components. And throughout the whole course, we'll be taking a look at how we create the new landscapes, and also we'll take a look at how to create landscapes"},{"start":"0:31","end":"0:36","startSec":31.6,"text":"on the high map itself. So let's go ahead and dive right in and take a look at some landscape technical details."}],"02_TechnicalDetails_5.00":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"So, if we take a look at this image here, this is the gizmo essentially that you'll be presented with when you go to create a landscape. So to enter this mode, if I go into my empty project here, and I've already entered it here but I'll go from scratch. So you can see if I've got a completely blank level, I can go to my landscape mode and I'll straight away be presented with the landscape creation tool. It's without any landscape to actually edit and have like you need to something to create."},{"start":"0:32","end":"1:03","startSec":32.8,"text":"So let's take a look at what each section of this actually means. So I'm going to go back to my slides so that we can see it a little bit clearer. But essentially we've got the yellow outline here which is going to be the landscape actor edge itself. So that's the edge of the full landscape considering everything. Then we've got these light green lines here which might even be easier to see on the landscape creation tool here but you've got the lighter green lines in the middle here and they're going to be our landscape component edges. Then we've got the sort of medium green lines here which are going to be the landscape section"},{"start":"1:03","end":"1:38","startSec":63.6,"text":"edge and then we've got each individual quad of the landscape itself. So that's the sort of color coding that gives you the information about how your landscape is going to be set up once you press create. Now it's important to understand how landscapes are divided. Landscapes are divided into multiple components which are essentially Unreal's base unit of rendering, visibility calculations and collisions. This is pertaining to the landscape specifically by the way and this isn't something that is relevant to anything else other than landscape. So components themselves in a landscape are all the same size and are always going to"},{"start":"1:38","end":"2:08","startSec":98.0,"text":"be square. Now the size of these components are going to be decided when the landscape is created and the choice is going to essentially depend on the size and detail of landscape that you want to create. Now components can optionally be divided into either one or four in two by two subsections. So using the four subsections gives you the same size of a height map as using four times as many components as a landscape with only one subsection each. However it's important to understand that using fewer components generally gives better"},{"start":"2:08","end":"2:40","startSec":128.9,"text":"performance so sometimes it's actually better to get a little bit more resolution and use fewer components than going for less vertices overall and more components. So that's something to keep in mind when creating your landscapes. Now when we go to actually create a landscape one of the things that's really important is to understand what scale we want to set our z height at because that's going to define the height that the landscape is actually going to have. Now if I take a look at it what we're talking about here in engine is this scale here that's"},{"start":"2:40","end":"3:15","startSec":160.8,"text":"set to 100 by default. Now what we want to be thinking of is a ratio of 1 over 512. Now what does this actually mean? When we import custom height maps we need to use this ratio to understand the correct height depth that we want to use. So essentially Unreal Engine is going to try and calculate the overall height of your height map based on this information that you're feeding in. So the height or the height or z value of our height map is going to be stored used in values between minus 256 and 255.992 and this is important to understand as well that"},{"start":"3:15","end":"3:47","startSec":195.2,"text":"it's stored with 16 bit position. So when you create your textures and want to import them into Unreal for the height information of a terrain or landscape you need to make sure that they're exported with 16 bit position. So it's important to understand then that with that information and the standing a scale value of 1 results in a maximum height of around 256 centimeters and maximum depth going down of minus 256 centimeters which is really small. By default then because we have a scale of 100 it means that our landscape range is going"},{"start":"3:47","end":"4:18","startSec":227.4,"text":"to have a value between 256 meters going up and minus 256 meters going down. If we wanted to actually calculate this in a more real world case scenario we can take a look at Mauna Kea inside of Hawaii which is the highest peak of Hawaii at 4027 meters. If we wanted to create this landscape within Unreal and we wanted to calculate what the z height of this landscape should be we'd have to go by the following method. So we take the height and turn it into centimeters because that's the Unreal Engine units we'd"},{"start":"4:18","end":"4:53","startSec":258.5,"text":"be using and that centimeter we multiply by that ratio that we defined in the previous slide. So the overall height or z height or z scale of our landscape here would have to be 821.6 and we didn't put this in here in our actual landscape scale section here on the create tab. Now the only problem with this is that this doesn't actually account for the amount of actual mountain that goes underneath in the deep under the sea below sea level."},{"start":"4:53","end":"5:24","startSec":293.4,"text":"So the way we'd actually calculate this properly would be to include that. So if we included that which is another 5,761 meters we would add these two together which gives you an overall number of centimeters of 996,800 centimeters then we'd multiply that by our ratio and that's the actual height that we'd want to be using to take into account that sort of sea level and beneath sea information about this mountain. So that's the kind of real world case scenario which you'd want to use to calculate the correct"},{"start":"5:24","end":"5:54","startSec":324.4,"text":"sizes and z height specifically for your landscape. Now when we actually go to create a landscape Epic has already provided us with a really handy chart that gives us recommended sizes that will essentially allow us to maximize the area that we're using while minimizing the number of landscape components that we have to create. So this chart is actually a really good resource to use when trying to determine the size of the landscape you want to use. If you use a size that isn't on this list essentially your landscape will have to make"},{"start":"5:54","end":"6:27","startSec":354.6,"text":"an extra row of components and vertices that might cause errors or undesirable results. So if we were to actually create a landscape we'd want to use this chart and the way we'd go about it let's say for example we want to create a smallish 253 by 253 landscape we would essentially follow the chart itself to get the right values. So I would go to my overall resolution here and go to 253 by 253. You can see Unreal Engine is already going to sort of automatically try and adjust to"},{"start":"6:27","end":"6:57","startSec":387.9,"text":"the things that we're actually trying to create here. So you can see I've got a 253 by 253, 2 by 2 subsections and 63 by 63 sections per component sorry section sizes. So if we take a look at the chart at this here this is essentially the landscape that I'd be making. It's really quite straightforward once you start to use it and Unreal Engine is going to actually take over and do as much as it can for you but it's good to always go to"},{"start":"6:57","end":"7:07","startSec":417.9,"text":"this chart to make sure that you stick to these sizes in order to get a nice performance and not so error prone landscape itself."}],"03_LandscapeManageMode_5.00":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Okay, so let's go ahead and take a look at the landscape manage mode. For this, it's actually best if we just jump into the engine. So I'm going to go ahead and do that so we can take a look at the tools itself within the context of the engine. So if I open up my editor here, I've got an empty map essentially with a little bit of light things that we can see what we're doing. And I'm going to go to my landscape tool and just create a flat normal landscape. You can see I've got it set up to 1009 by 1009, which is one of the recommended size on the chart. And let's go ahead and press create."},{"start":"0:31","end":"1:01","startSec":31.0,"text":"Now if I go to manage tab here, the manage tab essentially allows you to create or modify landscape components itself. So there's a few options here. We've got the new tab or the new button here, which allows you to create a new material, a new landscape completely. Import allows you to create a new landscape based on a height map texture that you will import, which we're going to take a look at later on. Let's go take a look at the meat and potatoes of this section here, which is these tools"},{"start":"1:01","end":"1:31","startSec":61.4,"text":"over here, like select, add, delete and splines really. So select allows me to select a few components and then I can go on the details panel to actually edit them. You can see everything's grayed out here. And the only reason for this is because I don't have my landscape actually selected in the outline. And so if I have the landscape selected, when I select those components, you can see now I can actually edit them. So select allows you to select and deselect if you, you know, re-click on a selected component. And you can see we have a brush size here."},{"start":"1:31","end":"2:03","startSec":91.4,"text":"And if I bring this brush size up, you can see it allows you to select more components at once. So this is consistent across all of these tools. So you should feel comfortable using it once you create a new or make a new selection or add something. And then we've got a little button here that's handy to just clear the selection so that we don't have to individually deselect the sections that we want. Add allows us to add a landscape component. So for example, I can just click and drag and add a new, an entire new row and delete"},{"start":"2:03","end":"2:33","startSec":123.2,"text":"can allow us to do exactly the same, but just, well, exactly the opposite rather and delete sections. Now, move and resize, we're going to skip for this. Move just to give you a quick overview. We need kind of a level set up to look at this, but it gives you the ability to move certain components to different streaming levels so they can be streamed in and out independently from the rest of the landscape, which is a nice sort of performance optimization that you could use. Resize allows you to resize the landscape. And then the splines tool is the one I wanted to take a look at because this one's actually"},{"start":"2:33","end":"3:04","startSec":153.5,"text":"quite powerful. It allows you to edit the landscape based on splines that you can draw. So say for example, I press control click to add a new spline point. I can press control click again to add a few spline points. And with these, I can also rotate them to change the tangents and say, for example, I would raise this point here and maybe lower this point a little bit. Once I click deform landscape to splines, and in this case, I'll just click all splines because we only have one, but you can see it will actually deform the landscape to the"},{"start":"3:04","end":"3:38","startSec":184.8,"text":"spline that I created, which is a really handy tool. And one other thing that I quite like about it is that it's additive. So once you've selected that, you could actually move this over and then add to that landscape that you created. So really neat little tool to actually just get some basic shapes and information layout just with some easy splines. Now when we take a look at managing and kind of like a real use case of how, you know, why we'd want to select a particular landscape components, let's say for example, that this"},{"start":"3:38","end":"4:10","startSec":218.8,"text":"is the playable space of the other player and that these landscape components, you know, they have some, let's say, let's give it some mountains, you know, some really, really basic mountains that I'm going to make here. But let's say you just have some background information that you actually don't need to be as detailed as the rest of your landscape. Maybe you want to give them a particular material that's a little bit more performant and simpler. So in order to actually edit that, what we'd want to do is select the sections that we"},{"start":"4:10","end":"4:44","startSec":250.1,"text":"want to edit. Say in this case for this mountain range, we'd select this last three rows of components and go ahead and select them. And what we'd want to do is essentially override the material. So if I said override, I can go ahead and override a material, add a new element here. And I'm just going to give this a new lot index of one. And I can now add, for example, a material that's a little bit more performant and simpler"},{"start":"4:44","end":"5:19","startSec":284.8,"text":"than what we have. So I'm just going to use a background material. And now what we have is a landscape component that's using a different material to the rest of the landscape. And as I say, this can be really handy to essentially relieve some of the complexity of the landscape in areas that the player doesn't really need to access or don't need high detail. And the cool thing about this is that you can set up as many LOD indexes as you need and you can actually sort of ramp that detail intensity away from the player or the playable space. So that's a really sort of real world case scenario of how you'd use the manage tool"},{"start":"5:19","end":"5:33","startSec":319.5,"text":"to edit the landscape components themselves. So with that being said, I think we'll go ahead and take a look at creating landscapes and how we can create a landscape from height maps and different landscape creation modes that we can use."}],"04_CreatingNewLandscapes_5.00":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"Okay, so now that we know how to actually manage our landscapes, I think it's time we take a look at all the ways in which we can actually create landscapes inside of Unreal Engine. So, there's a few ways of doing it. Perhaps the easiest way to actually go ahead about doing this is just using the open world template. So, this is an open world template that's going to come with a 2km by 2km landscape that already has a landscape material setup and all the setups that you'd actually need if you wanted to create an open world type game. So, it comes with a world partition, one file per actor, data layers, hierarchical levels"},{"start":"0:33","end":"1:03","startSec":33.1,"text":"of details. It's actually a really, really handy template. So, if you wanted to create a landscape that you can start editing from there in this way, all you have to do is make a new level and make sure you choose the open world template here. And there you go. You've got a really nice landscape that's already set up for a lot of features and you're good to go. You can just go ahead and edit this. That's one way that you can do it. Now, the other way that you can do it is by just having a basic world."},{"start":"1:03","end":"1:37","startSec":63.8,"text":"And the only reason I'm choosing basic is because we've got a bit of lighting so we can see what we're doing. But essentially, you can create a landscape the way we've been creating it. So, if we go to create new, I'm going to untick edit layers there because that's something I'm going to cover in a second. But you could just set up, look at the chart, figure it out, figure out what landscape size you want, press create. And there we go. We've got a landscape. I can go ahead and start sculpting on this and edit it. Now, one thing that I did want to cover about landscapes that we haven't covered up until now is that tick box that I just had to untick there, which is the edit layers."},{"start":"1:37","end":"2:11","startSec":97.7,"text":"So if we have enable edit layers, when I create this, we get this really handy feature here called edit layers, which essentially allows me to store the data that I painted inside of one of the landscapes into a layer, which means I can slowly use this alpha value to change the way in which my landscape edits in affects the actual landscape. To create a new layer, all I have to do is right click create. And now as long as I've got that layer selected, I'll be storing in that layer the information"},{"start":"2:11","end":"2:44","startSec":131.8,"text":"that I'm painting now. And again, all I can do, all I need to do is to click and drag this alpha value. I can go ahead and edit the intensity or the effect that that layer has on the landscape itself. This is a really, really useful tool that I actually really can't live without now. So I recommend that you actually set it up when you do your own landscape. Now the last way that we can create a landscape is to just import a height map that we've generated in something like World Machine or Zebra or Houdini, any real software and"},{"start":"2:44","end":"3:14","startSec":164.7,"text":"any other DCCE application where you can actually generate a terrain height map image. You could use the import into Unreal and generate that landscape from it. So how do we go about doing that? Well, let's go ahead and delete this landscape once again. And let's go ahead back to our landscape tool. And we're going to say import from file. Now I already have a file set up here, but I'd encourage you to just go into Photoshop and just paint a few lines in black and white and make sure that you export this as a 16"},{"start":"3:14","end":"3:48","startSec":194.9,"text":"bit depth image, okay, which you could save as a PNG. In our case, we've already got one ready. And remember that the size of this have to be relating to the chart that we mentioned earlier. So in our case, it's going to be 1009 by 1009. So we've got the right resolution. I've got a scale value here of 150 that I edited already. And I'm just going to move the landscape up a little bit and let's go ahead and import. And once we press import, you can see when we generate it from DCC package like this,"},{"start":"3:48","end":"4:19","startSec":228.4,"text":"we really get a nice level of detail that might be much harder for us to manually paint inside of Unreal. So if you want something that's artistic like this, this is a really good tool. And the beauty of this is that you can still edit it. So if you wanted to flatten a certain section of this, you could go ahead and use the flatten tool and flatten it out. But yeah, put your little houses there if you need to. Essentially, these are all the ways that we can create a landscape."},{"start":"4:19","end":"4:52","startSec":259.6,"text":"And as I say, it's a really versatile system. I hope this has been useful for you. The overall things that we've covered are just a few technical details and real world scenarios in which we can actually create landscape. We took a look at the managing tools or the manage tab for landscapes and how we can manage things like LOD in per component and how we can use spline. We also actually adjust the terrain of the landscape itself, how we can add or delete"},{"start":"4:52","end":"5:18","startSec":292.4,"text":"components. And then lastly, we went over different creation techniques for landscapes. We've only really scratched the surface of what we can do in landscape. So in the next few courses, we'll be doing stuff that's a lot more detailed and take a look at things like landscape materials and other fun stuff to do with this amazing tool, the landscape tool itself. I hope you enjoyed this and I'll see you next time."}]},"313.01":{"01_Introduction":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Hello and welcome to Metahuman DNA Calibration and Finalization. My name is Gabriela Cresenio-Tacas and I will be your host for this course. This course is a continuation of the Metahuman Fitting and DNA Calibration course. We will delve into more advanced use case scenarios for using the DNA Calibration library to modify the Metahuman Neutral Pose and explore workflows for integrating it with a custom Metahuman body."},{"start":"0:32","end":"1:03","startSec":32.1,"text":"We will also dive into best practices for finalizing Metahuman customizations in Unreal Engine. It is worth mentioning that with newer engine versions some of these workflows have changed and we will explore the new workflows in a future update. Now let's take a look at what we will be covering in this course. We will get started by touching upon advanced use cases where DNA calibration has been used to make changes to the Metahuman head and body."},{"start":"1:03","end":"1:35","startSec":63.7,"text":"One case is the 2023 Unreal Fest DNA Calibration deep dive and the other is how the stylized character Atomic Savage was customized with multiple workflows using DNA calibration. We will then look at all of the steps that were taken to customize Atomic Savage from the initial concept to the finalized rig. From there I will break down some of the workflows in greater detail and walk you through how you might apply these workflows to your own characters."},{"start":"1:35","end":"2:09","startSec":95.7,"text":"The first workflow we will delve into includes a modified version of the Unreal Fest Calibration script. We will go over how to edit the Metahuman Neutral Pose by transferring the details from the fitted head geometry assets that we looked at in the previous course to a Metahuman identity and then save those changes to the Metahuman DNA file. For the second workflow we will go over how we can merge the modified Metahuman Neutral Pose with a custom Metahuman body for seamless integration."},{"start":"2:09","end":"2:45","startSec":129.3,"text":"From there we will go through all of the steps for bringing the customized assets back into Unreal Engine with a hands-on exercise. We will go over how to re-import the head-LOD-FBX files, update the Metahuman DNA file and the Metahuman Blueprint, and then we will look at how to import and assign a custom Metahuman body skeletal mesh. We will then wrap up this course with some final recommendations and I will share some tips and resources for you to use as you continue your training with Metahumans."},{"start":"2:45","end":"3:17","startSec":165.5,"text":"This course will be using the project MEH9130055 and the level map should load automatically. The map is located in the content browser under the courses folder labeled MEH31301. In the course maps folder and it is named MEH31301MAPEX for example. This map contains the non-modified version of the atomic savage character and we will"},{"start":"3:17","end":"3:48","startSec":197.5,"text":"be using this map to configure all of the customizations we will be bringing into the engine for the hands-on portion of our course. If you want to inspect the fully assembled version of this character, that is located under the course folder named MEH21302 in the course maps folder and it is named MEH21302MAPC for customized. Now all of the scripts and assets we will be using throughout this course are located"},{"start":"3:48","end":"4:21","startSec":228.4,"text":"in the source files folder of our course named 31301DNACalibAssets. Inside of that folder you will find two scripts and their associated assets and in the folder named POSEDRIVERCONNECT you will find the RBF solvers that we will bring into the engine later on. If you need to reference the location of the course map that can be found at the beginning of the slide deck after the training outline. Now as we go through this course you will find that many slides in this presentation"},{"start":"4:21","end":"4:44","startSec":261.6,"text":"contain a lot of information and I will summarize all of that for you but if at any point you want to read what is on each of those slides feel free to pause and dive right in. Now let's get started with the first portion of this course where we look at some advanced use case scenarios for making changes to the metahuman face and body using the DNA calibration library."}],"02_GettingStarted_55":[{"start":"0:00","end":"0:34","startSec":0.0,"text":"In this section of our course, we will be looking at advanced use case scenarios where DNA calibration has been used to make changes to the metahuman head and body. We will have a look at the scripts that were demonstrated at the 2023 UnrealFest DNA calibration deep dive, and then we will look at the modified version of the UnrealFest script and the custom body integration workflow that were used for the stylized atomic savage character. So let's begin with the UnrealFest DNA calibration scripts."},{"start":"0:34","end":"1:06","startSec":34.5,"text":"The 2023 UnrealFest DNA calibration deep dive presentation, delivered by part of the three-lateral team, demonstrated what can be achieved with the DNA calibration library. Each piece of code from the calibration and scale script was explained in great detail, and all of the steps for bringing in the modified DNA file and head LOD-FBX files into Unreal Engine were shown. These scripts allow the user to edit the neutral pose and scale the entire rig."},{"start":"1:06","end":"1:38","startSec":66.5,"text":"They contain a combination of commands that allow users to transfer details from a provided model, snap surface joints to their new vertex positions, change the animated map setup, scale the body and the head, update the metahuman DNA file, and export the head LODs with material placeholders. If you have not seen this presentation, I highly recommend you watch it and practice using those scripts and the provided assets. I have included a link to the presentation in the resources section of this course."},{"start":"1:38","end":"2:08","startSec":98.8,"text":"Now let's take a look at the scripts that were used for the stylized atomic savage character. The stylized atomic savage character's body and facial features went beyond the standard metahuman template. The first script called atomic sDNA-calibe that was used is a modified version of the Unreal Fest calibration script. This version of the script transfers details from the fitted head geometry models to the neutral pose and updates the DNA file."},{"start":"2:08","end":"2:43","startSec":128.8,"text":"The DNA file that was generated from that script was used with the custom body integration script to merge the head with the custom metahuman body for a seamless integration. The custom body workflow aligns the head and body skeletons. It eliminates any seam issues that may occur during deformations, and it saves those changes to a new DNA file. This workflow uses multiple scripts and commands that are executed through a single script. We will be using both of these scripts, and as mentioned, these scripts and their associated"},{"start":"2:43","end":"3:06","startSec":163.2,"text":"assets are located in the source files folder of this course. Now that we have looked at what the Unreal Fest script allows users to achieve along with the two scripts that were used with atomic savage, let's move on to the next section of our course where we will explore all of the steps for taking atomic savage from an initial concept to a finalized metahuman character."}],"03_ConceptToFinal_55":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"In this section of our course, we will take a look at all of the workflows that were used for the atomic savage character. The process of bringing atomic savage to life began with an initial concept. Then came the question, is it possible to take a stylized character like atomic savage and transform him into a fully functioning metahuman? And if so, what steps would need to be taken in order to achieve this? So let's begin by looking at the first step of this character's journey."},{"start":"0:33","end":"1:15","startSec":33.0,"text":"The first step was to take the initial concept of this character and have a sculpted version created using ZBrush. The head and body were then separated. Using the topology of a metahuman preset, the metahuman head was fitted to the 3D sculpt. The metahuman identity texture was used to ensure that important edges and loops for the head were respected. Once the initial fitting was complete, the next step was to generate a metahuman identity. The 3D head model fitted with metahuman topology was used with a mesh-to-metahuman workflow using the template mesh option to generate the initial metahuman identity."},{"start":"1:15","end":"1:59","startSec":75.0,"text":"The template mesh option helped to get the initial geometry and joint positioning closer to the target delta across all the LODs. However, due to the scale and stylized features of this character, there was still more work to be done. The next step was to assemble and prepare this character's assets for the final fitting process. The source assets of the initial metahuman identity were downloaded from the Quixel Bridge standalone application. Then the LOD0 of the head geometry and the additional assets were refitted vertex by vertex to match precisely with the fitted 3D head mesh while using LOD2 for easier manipulation of polygons."},{"start":"1:59","end":"2:32","startSec":119.0,"text":"Once the final fitting process was complete, the next step was to identify the scale and positional measurements for the head that would be applied with DNA calibration. To identify the scale and positional measurements, in Maya, a locator was used to preserve the existing translation values of the joints. Once the locator was used to scale, translate, and rotate the metahuman identity, the values from this process could be applied to the metahuman identity with DNA calibration."},{"start":"2:32","end":"3:04","startSec":152.0,"text":"To demonstrate the process of using a locator, let's jump into Maya for a moment. Inside of Maya, I will walk you through the steps of how to use a locator to identify the scale and positional values while preserving the existing translation values of the joints. Now I have already loaded the DNA file into a new Maya scene and then added the fitted head mesh in here as a reference. Let me show you what steps I took in order to assemble the scene."},{"start":"3:04","end":"3:34","startSec":184.0,"text":"To load the DNA, I executed the DNA viewer run in Maya script. If I pull up the DNA viewer window, I loaded the DNA file of the initial metahuman identity for atomic savage. If you wish to go through these steps, you can find the DNA file I am using in the source files folder. It is located in the Atomic-S DNA folder. With the DNA loaded, I assembled only the head LOD zero mesh."},{"start":"3:34","end":"4:04","startSec":214.0,"text":"In the build options, I enabled the joints and skin clusters, and then I selected process. And once this was assembled, I added the fitted 3D head model. Now that I have gone over how I assembled the scene, let's go over how to use a locator. I am going to go to the head group and collapse it and select spine 4. Over here on the right, we can see that this has existing values."},{"start":"4:04","end":"4:38","startSec":244.0,"text":"To preserve these, we can use a locator. To do this, I will go to create, then down here, and I will select locator. In the outliner, I will make the locator a child of the head group, and then make spine 4 a child of the locator. Now, we can use a locator to scale and translate the identity while preserving the existing translation values of the spine."},{"start":"4:38","end":"5:13","startSec":278.0,"text":"I will unhide the fitted head mesh to use this as a reference, and I will select the locator. Now, I already have the values that are needed, but to demonstrate what this process would look like, I will switch over to wireframe for a moment. Then over here, for the translation x, I will set this to negative .106. For the y, I will set this to negative 18.954."},{"start":"5:13","end":"5:49","startSec":313.0,"text":"And for the z, I will set this to negative 20.869. Then for the scaling, I will change all three values to 1.192. Finally, for the rotate x, I will set this to 5.858. It takes a little trial and error to figure these values out. However, once you have the right values, you will notice that this is a very close approximation of the scale and proportions the head will need to have in order to match up with the target head mesh."},{"start":"5:49","end":"6:26","startSec":349.0,"text":"Now that we have seen what this process looks like, let's do a quick review of these steps before we move on. We just saw how we can use a locator to identify the scale and positional values that will need to be applied to the metahuman identity with DNA calibration. The steps for using a locator are to use the DNA viewer run in Maya script to load the DNA of the metahuman identity. In the DNA viewer window, assemble the LOD0 head mesh only and enable the joints and skin clusters in the build options."},{"start":"6:26","end":"7:03","startSec":386.0,"text":"Once the scene has been assembled, add the fitted head model into the scene for reference. To create a locator, go to create and select locator. Make the locator a child of the head group, then make spine 4 a child of the locator, and then use the locator to move and scale the identity in order to find the desired values. For atomic savage, once these values were identified, the next step was to prepare the body skeleton Maya file that is required for exporting the head LODs as FBX."},{"start":"7:03","end":"7:35","startSec":423.0,"text":"The images on this slide show the progression of steps that were taken to prepare the body skeleton Maya file asset. The first step was to take the original full body rig Maya file from the source assets downloaded from bridge. From root to spine 4, all of these joints must be perfectly aligned with the head rig. So for this reason, without touching the bones from spine 4 and above, spine 1, 2, and 3 were slightly adjusted while leaving everything else the same."},{"start":"7:35","end":"8:07","startSec":455.0,"text":"Then, using the same workflow for preparing the body skeleton that we covered in our previous course, the arms and legs were removed, and this prepared body skeleton Maya file was ready to be used with DNA calibration. The final step for preparing the assets that would be used with DNA calibration was to rig the custom metahuman body. To rig the custom metahuman body, the prepared body skeleton was used as a base for the height."},{"start":"8:07","end":"8:44","startSec":487.0,"text":"From there, the joints with the exception of the spine were adjusted to fit the upper portion of the custom body. Then, the arm and leg joints of the initial metahuman identity skeleton were bound to the skeleton and then adjusted to fit the rest of the body. We can see in the images on the slide what the skeleton looked like before and after this process. Now, with all of the assets ready to be used with DNA calibration, the first script that would be used is the modified version of the UnrealFest calibration script."},{"start":"8:44","end":"9:15","startSec":524.0,"text":"The modified version of the UnrealFest calibration script scales the head and transfers the details from the fitted geometry to the DNA. The script scales, translates, and rotates the head using the values that were identified with the locator. It then updates the neutral head by transferring the details from the fitted geometry assets. Then it snaps the surface joints to their new positions, which is important especially for those details to be preserved for lower LODs."},{"start":"9:15","end":"9:48","startSec":555.0,"text":"And finally, it saves these changes to the DNA file. In the images from left to right, we see what the initial metahuman identity looked like before DNA calibration and what it looked like after the script was executed. And all the way on the right is an image of the head LOD0FBX. Even though the head geometry and additional assets were finalized, the head skeleton and custom body still needed to be aligned, while also avoiding any seam issues that commonly arise from this process."},{"start":"9:48","end":"10:19","startSec":588.0,"text":"To achieve this, the custom body integration workflow script was used. The custom body integration workflow script aligns the skeletons for the head and body. It saves those changes to the DNA file and exports the head LODs as FBX with material placeholders. It also paints weights for the neck seam where the head and body connect, eliminating seam issues. The only other step after using this workflow was to match the normals for the head and body neck seam area."},{"start":"10:19","end":"10:57","startSec":619.0,"text":"The images on this slide show the skeleton before and after this script was used. Now, the final DNA file and the exported head LOD FBX files, along with the custom metahuman body with the adjusted skin weights on the neck seam area, were ready to be brought into Unreal Engine. All of the finalized assets for the head and body were brought into Unreal Engine and configured. The head LODs and updated DNA were re-imported, the body skeleton was imported and assigned to the metahuman-based skeleton, and the metahuman blueprint was updated."},{"start":"10:57","end":"11:33","startSec":657.0,"text":"The face and body were then tested with animations, and it was during the testing process it became apparent that due to the significant differences in skeleton proportions, animations would need to be retargeted from the standard metahuman-based skeleton to the custom body one, and body correctives would be needed to finalize this character's customizations. When applying animations to the body, due to the significant differences in skeleton proportions, animations had to be retargeted even though the source and target skeletons shared the metahuman-based skeleton."},{"start":"11:33","end":"12:03","startSec":693.0,"text":"To correct problematic areas during deformation, the pose driver connect tool set was used to author corrective poses. A good example of this is demonstrated in the images on the bottom of the slide where we can see what the shoulder and neck region looks like when animations are applied. Now, we have just seen how atomic savage went from a concept to a fully functioning metahuman, and we touched on the various workflows that were used to finalize this character."},{"start":"12:03","end":"12:11","startSec":723.0,"text":"In the next portion of our course, we delve deeper into the DNA calibration workflows that were used with this character."}],"04_EditGeometryPT1_55":[{"start":"0:00","end":"0:36","startSec":0.0,"text":"In this section, we will be delving into the first DNA calibration workflow that was used with Atomic Savage. The Atomic S DNA Calib script is a modified version of the UnrealFest calibration script. This script allows us to edit the metahuman neutral pose by transferring the details from the fitted head geometry assets to the metahuman identity, and then saves those changes to the metahuman DNA file. We will first go over the script input, the path settings, the constants, and how to execute the script."},{"start":"0:36","end":"1:14","startSec":36.0,"text":"So let's get started by reviewing the workflow. The script we will be using is named Atomic S DNA Calib. If you want to follow along, you can find the script and all of the associated assets that are needed to run it in the folder named Atomic S located in the source files folder. This script allows us to move, scale, and transform the rig to adequate positions using the values that were identified with the locator. It saves the current vertex and surface joint positions as a JSON file, then it updates the neutral mesh using the fitted head geometry OBJ files,"},{"start":"1:14","end":"1:45","startSec":74.0,"text":"it sets the new vertex positions and snaps the surface joints to their new positions, then it updates the DNA file to include the change in deltas. Now as we go over how to use the script, we will primarily work in Maya. As we complete portions of this workflow, I will review the completed steps. So let's jump into Maya and begin by looking at the script and the assets that we will be using. Inside of Maya, let's begin by going over the script and assets that we will be using for this workflow."},{"start":"1:45","end":"2:19","startSec":105.0,"text":"To locate the script and assets in the source files folder, navigate to the DNA Calib assets folder, then to the Atomic S from geometry folder. They will be inside of the folder named Atomic S. The Atomic S DNA Calib script is in the script folder. I have added it in the script editor in a new Python window. Now let's go over the setting paths that this script will use in order to locate specific assets from the work directory folder."},{"start":"2:19","end":"3:07","startSec":139.0,"text":"On line 10, for the root directory, enter the path that points to the DNA calibration folder. In my case, it's on my C drive. The work directory refers to the location of the Atomic S folder which contains the assets that this script will use. I have placed this on my D drive. Next, add quotations to the Maya version you are using. In my case, I'm using 2023. Now, if we scroll past all of these surface joints and all the way down here past this code to line 657, this section has the setting paths that will be used."},{"start":"3:07","end":"3:39","startSec":187.0,"text":"We already have an output folder and a temp folder. Inside of the output folder, I have added a folder that contains the exported FBX and final DNA generated from this script. For the character DNA, the path is pointed to the DNA called Atomic Savage in the DNA folder. Below is a list of the neutral meshes. These are the names of the fitted head geometry OBJ files in the model folder."},{"start":"3:39","end":"4:09","startSec":219.0,"text":"There is also a copy of the prepared body skeleton Maya scene in here. The temp folder is where the JSON file will be added when the vertex and surface joints are saved and it also contains a copy of the prepared body skeleton Maya scene. Over here, on line 699, this will be the name and path of the final DNA. And here is the path to the prepared body skeleton Maya file, which is in the temp folder."},{"start":"4:09","end":"4:39","startSec":249.0,"text":"For the scene files, the GUI and additional assembly script paths have already been set to point to the MH4 folder for the latest version of MetaHuman. If we go over here to line 712, these are the constants. For the fitted geometry OBJ files in the model folder, the mesh mapping names correspond to the name of the assets as they appear in Maya. On line 731, this is the name of the character."},{"start":"4:39","end":"5:11","startSec":279.0,"text":"Now, you can technically just run this entire script, but we are going to go through this one step at a time so that we can better understand what each command does. Now, before we move on, let's do a quick review of what we just covered. To use this script, for the root directory input, enter the path that points to the DNA calibration folder. For the work directory, enter the path that points to the atomic S folder. Ensure you add quotations to the Maya version you are using."},{"start":"5:11","end":"5:46","startSec":311.0,"text":"The paths for the GUI and additional assembly script are already directed to the MH4 folder for the updated rigs. Now, let's go over the path settings. The first setting path that is used for this script is the character DNA. This path points to the atomic S DNA folder. Next is the setting path for the new neutral meshes. This path points to the model folder with the fitted head geometry assets. Finally, the body file path points to the temp folder where the prepared body skeleton Maya scene is located."},{"start":"5:46","end":"6:22","startSec":346.0,"text":"I am mentioning these paths in the event you decide to use your own custom metahuman character. You will want to ensure that the location of your assets match the paths that the script is using. This includes the naming of constants. Let's take a look at those. For the fitted geometry assets in the model folder, the mesh mapping names correspond to the names of the assets as they appear in Maya. For example, if I add the head LOD0 obj file to a Maya scene, in the Outliner, its name will appear as head LOD0 identity solve."},{"start":"6:22","end":"6:40","startSec":382.0,"text":"This is important because if the naming is not the same, then the assets will not be loaded into the Maya scene when they are needed. Now that we have gone over the assets and the input paths that are needed for the script, let's move on to the next section where we will execute the script."}],"05_EditGeometryPT2_55":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In the previous section, we did an overview of the script and the assets that we will be using. In this section, we will be executing the script. As we complete portions of this workflow, I will review the completed steps. So let's return to Maya and begin using the script. Back inside of Maya, we are now ready to execute the script. As mentioned earlier, you can technically run this entire script, but we're going to go through this one step at a time and see what each command does."},{"start":"0:31","end":"1:02","startSec":31.2,"text":"The first thing we will do is initialize the script. Select everything from line 731 all the way to line 1 and execute it. This will bring everything into memory. Now let's go back down to line 733 and begin the initial work. Select line 734 to 741 and execute it. This will load the plugin and create an output and temp folder if they do not exist."},{"start":"1:02","end":"1:35","startSec":62.8,"text":"Now we can start to execute each of the steps. Scroll down to 743 where it says steps. From step 1 to 3, this portion of the script will move and transform the rig. We will not see anything happen in the viewport for these three steps, however, after each step, a new DNA file will be generated and added to the DNA folder. Select the entire section for step 1 and execute it. What this command does is it takes the scale values and applies them to the DNA and then"},{"start":"1:35","end":"2:07","startSec":95.9,"text":"saves this to a DNA file named scaled. Once this process is complete, select the entire section for step 2 and execute it. This takes the translation and rotation values that we have over here and it will apply them to the DNA. The DNA file will be named translated DNA. Once this process is complete, select the entire section for step 3 and execute it."},{"start":"2:07","end":"2:40","startSec":127.4,"text":"This changes the up access if needed by rotating the rig 90 degrees and applies this to a DNA named up access change. The first step is to initialize the script and create folders. Select the script from line 1 to 731 and run that part to load everything into memory. Next, select the script from line 734 to 741 to load the plugin and create the output and temp folder if they have not been created."},{"start":"2:40","end":"3:12","startSec":160.0,"text":"Then we can move on by running step 1 through step 3. For these steps we will not see anything in the viewport, however the DNA folder will be populated with new DNA files. Step 1 will scale the rig. Select the entire section of this step and run it. This will scale the DNA based on the values we provided. The new DNA file will be named scaled DNA. Step 2 will translate and rotate the rig based on the provided values. Select this entire section for that step and run it."},{"start":"3:12","end":"3:45","startSec":193.0,"text":"The new DNA file will be named translated DNA. Step 3 will change the up access if needed and rotate the rig 90 degrees. Select the entire section of this step and run it. The new DNA file will be named up access change. Now let's return to Maya and continue. In Maya we have just finished step 1 through 3 where we moved and scaled the rig. In the DNA folder we can see the DNA files that were created after each step."},{"start":"3:45","end":"4:22","startSec":225.6,"text":"We can now move on to step 4. This will load the last DNA that was generated which is the DNA file named up access change and it will save the surface joint positions as a JSON file. Select and run the first portion of the script to load the DNA into the scene. Now that it is loaded we can see it over here in the viewport. Next, run this portion of the script to save the current surface joint positions."},{"start":"4:22","end":"4:53","startSec":262.6,"text":"A JSON file will be created and added to the temp folder. Before we move on let's do a quick review of the steps we just completed. Step 4 will load the change up access DNA file that was generated from the previous step. It will then save the surface joint positions. Executing the first portion of step 4 will load the metahuman head geometry and joints into a new scene. The save surface joint positions command will generate a JSON file and add it to the temp"},{"start":"4:53","end":"5:25","startSec":293.8,"text":"folder. Now let's return to Maya and continue. Back in Maya with the surface joints saved we can move on to step 5. This portion of the script will update the LOD0 neutral head mesh from provided models. Run this first portion of the script to add the models into the scene. If we look in the outliner all of the fitted models have been loaded. As mentioned earlier, if the mesh mappings in the constants section of the script are"},{"start":"5:25","end":"5:59","startSec":325.4,"text":"labeled incorrectly the models might not load for this step. Now let's run this portion of the script. This will get the old and new mesh positions. We can now run the saveDNA portion down here to save the new mesh positions to the DNA file. This will create a new DNA file named meshDNA. Let's do a quick review of the steps we just went through before we move on. Step 5 updated the neutral mesh from the provided models."},{"start":"5:59","end":"6:30","startSec":359.4,"text":"The first command of step 5 will add the fitted geometry assets into the scene. Again, if using this with your own character ensure that the mesh mapping names correspond to the names of the models as they appear in Maya otherwise they may not load. The getMeshVertexPositions command will get the old and new mesh positions and then save the new mesh positions to the DNA. A new DNA file will be created and named meshDNA."},{"start":"6:30","end":"7:04","startSec":390.1,"text":"Now let's return to Maya and continue with the steps. In Maya, step 6 will update the surface joint positions using the JSON file from the temp folder for the meshDNA file that was generated from the previous step. Run the showMesh's command to load the updated meshDNA file. In the viewport we will see the DNA file has been assembled. Now to update the surface joints I'm going to position the head so that we can see what"},{"start":"7:04","end":"7:35","startSec":424.2,"text":"this process looks like once we run the next command. With this portion of step 6 selected I will execute this and we will see the surface joints snap to their new vertex positions. Now run the rest of the script over here. This will save the changes to the DNA and name it changesFromScene. Then it will load this new DNA."},{"start":"7:35","end":"8:08","startSec":455.8,"text":"Now that it is loaded I'm going to make the display panel visible and in the script editor I will go to the RecalculateLowerLOD section. If I go to the display panel and hide LOD0 we will see that the changes have only been applied to LOD0. In the script editor run the entire portion of the section named RecalculateLowerLODs over here. This will transfer the changes to the lower LODs based on LOD0 and it will save those"},{"start":"8:08","end":"8:40","startSec":488.7,"text":"changes to the final DNA. Let's do a quick review of these steps before we move on. Once we have updated the neutral mesh from the LOD0 head mesh the next step is to update the joint positions. Execute step 6 to do this. The showMesh's command will load the meshDNA file and then the rest of the commands will load the saved joint positions from the JSON file and then move the surface joints to their new vertex positions. This change will only be applied to LOD0."},{"start":"8:40","end":"9:12","startSec":520.9,"text":"Run the RecalculateLowerLODs based on LOD0 to transfer the changes that were made to LOD0 to all of the lower LODs and save the final DNA. Now let's return to Maya and go over the final steps of this script. Back in Maya execute all of step 7 to check the results. This will load the final DNA and assemble a full rig. This process will take a few moments to complete."},{"start":"9:12","end":"9:44","startSec":552.0,"text":"Once this process is complete in the viewport we can see the final DNA. Let's bring this closer to view. We can also see that the changes to the neutral have been transferred to all of the lower LODs. Now because we are in YUP we will notice that the faceboard is over here and that is okay because the last portion of the script contains the command that will rotate the rig back"},{"start":"9:44","end":"10:18","startSec":584.6,"text":"to 90 degrees. The faceboard controls will still work though. We can see that these are operational. Now if we are happy with everything the next step would be to run the export FBX for each LOD section. I'm not going to run this portion of the script for two reasons. The first reason is that the current version of the export FBX portion of the script results in a mismatch between the body and head skeleton. To work around this use the DNA viewer export FBX script from the examples folder."},{"start":"10:18","end":"10:52","startSec":618.9,"text":"The second reason is that we still need to align the skeleton for the head with the custom body skeleton for a seamless integration. Now we could do this by hand or we could use the custom body workflow script that will do this for us. Now let's review everything we just covered before we move on to the custom body workflow. Step 7 will assemble a full rig of the final DNA for inspection and if everything looks correct it will export FBX for each LOD and apply a material placeholder for all of the"},{"start":"10:52","end":"11:22","startSec":652.2,"text":"LODs. As mentioned the current version of the export FBX portion of this script results in a mismatch between the body and head skeleton. A workaround for this is to use the export FBX script from the examples folder. Using the final DNA from this script we will now move on to the next portion of our course where we will use the custom body workflow script to align the head and custom body skeletons for a seamless integration."}],"06_CustomBodyPT1_55":[{"start":"0:00","end":"0:39","startSec":0.0,"text":"In this portion of our course, we will be delving into the custom body workflow for a seamless head and body integration. This was the second DNA calibration workflow that was used with the Atomic Savage character. Using the metahuman DNA file that was generated from the previous workflow, the custom body workflow allows us to align the head and custom body skeleton while eliminating seam issues. The metahuman DNA that is generated from this workflow will be the final DNA, and this will be what is used to export the head LOD FBX files that will be brought into Unreal Engine."},{"start":"0:39","end":"1:16","startSec":39.0,"text":"Unlike the script we used in the previous section, this uses multiple scripts executed from a single script. Since this workflow is more advanced than the previous one we just went through, the steps have been broken down into smaller sections. So let's begin by looking at the steps of this workflow and then reviewing the script and assets that are needed for it to work. In this section we will be looking at the steps for using the custom body workflow. We will then review the script and all of the necessary files, folder paths and assets that are needed in order to execute it."},{"start":"1:16","end":"1:46","startSec":76.0,"text":"So let's start by looking at the workflow and what we are able to achieve with this. The custom body workflow allows us to achieve the following. It will position and scale the head rig for body integration, then it will update the neutral mesh if the nexium area has to be adjusted, and it will align the head joints with the body joints. Then it checks the body and head skin weights to make sure that only the skin weights that belong to the metahuman DNA are present."},{"start":"1:46","end":"2:16","startSec":106.0,"text":"If it finds skin weights that do not belong to the metahuman DNA, it allows us to fix this. It then merges the body and head skin weights for a seamless integration. To validate the results, it constrains the head joint hierarchy to the body so that the user can check if there are any seam issues when the body is animated. Finally, it will update the DNA file and export the head LODs as FBX with material placeholders."},{"start":"2:16","end":"2:50","startSec":136.0,"text":"We were able to achieve some of these steps in the previous workflow. For instance, we have already scaled and translated the head and updated the neutral mesh with neck geometry that fits the body nexium area. Now let's go over how to use the script. First thing we will need to do is locate the custom body folder that has been provided in the source files folder of our course. Inside of that folder, there are two folders. The first folder is named Custom Body Integration, and the second folder is named Working."},{"start":"2:50","end":"3:22","startSec":170.0,"text":"Place both of these folders in the DNA Calibration Library folder. Let's jump into Maya and go through this process, and then take a look at the files and assets this workflow needs in order to work. Inside of Maya, to use the custom body workflow, the first thing we will need to do is locate the custom body folder in the source files folder. Open up the custom body folder, and then open up the body head integration folder."},{"start":"3:22","end":"3:52","startSec":202.0,"text":"Copy the custom body integration and working folder, and then paste them into the DNA calibration folder. Now I've already added these in here. Let's go over each of these folders, starting with the custom body integration folder. In this folder, if we open up the folder named Workflow, this is where the API interface is located. In the script editor, paste the contents of the script in a new Python window."},{"start":"3:52","end":"4:30","startSec":232.0,"text":"The workflow folder also contains the neck falloff blending texture mask. This is used to control the skin weight blending between the body and head mesh. We also have the rig info JSON file over here. This contains additional rig definition information required for this workflow, and includes the bone mappings of the head and body joint hierarchies. Now let's go back and take a look at the working folder. The working folder contains the assets folder, the DNA files folder, the export folder, and the rigs folder."},{"start":"4:30","end":"5:07","startSec":270.0,"text":"The DNA files folder contains the metahuman DNA file for the original head rig that we wish to integrate with the body. In our case, we will be using the atomic sDNA file, which was the final DNA that was generated from the previous DNA calibration workflow. As we run commands, the in-between DNA files are generated, and will be added to this output folder in here. Next, we have the assets folder. This is where you would place the new neutral mesh OBJ file for step 2 that contains the neck geometry changes for body integration."},{"start":"5:07","end":"5:38","startSec":307.0,"text":"This is where we place the fitted LOD0 head geometry OBJ file. Finally, we have the rigs folder where the body rig Maya file has been placed. I already have this body rig Maya scene open. The skinned body combined mesh is the full body rig that has the metahuman skeleton and is what will be integrated with the head. The namespace string body combined is what's used for importing the body rig Maya file into a new scene."},{"start":"5:38","end":"6:10","startSec":338.0,"text":"Next, we have the separated head named body underscore head and the body asset. These are split versions of the full body skinned mesh, separated at the edge loop of the boundary where the head and body are combined on standard metahumans. If you wish to use this workflow with your own character, ensure that all three meshes have the correct skin weights and use the same namespaces as these. Now, before we move on, let's review what we just covered."},{"start":"6:10","end":"6:40","startSec":370.0,"text":"To use the custom body workflow, add the custom body integration and working folder to the DNA calibration folder. In the custom body integration workflow folder, locate the API interface script and paste its contents into a new Python window in the script editor. The workflow folder also contains the neck falloff blending texture mask, and this is used to control skin weight blending between the body and head mesh."},{"start":"6:40","end":"7:14","startSec":400.0,"text":"The rig info JSON file contains additional rig definition information that is required for this workflow. The working folder contains the assets folder, the DNA files folder, the rigs folder and the export folder. The DNA files folder contains the DNA file for the original head rig. The output folder is where the in-between DNA files are added. The assets folder is where the fitted head geometry OBJ file is placed and it should have the neck geometry changes for body integration."},{"start":"7:14","end":"7:44","startSec":434.0,"text":"The rig folder is where the body rig Maya file is located and should contain a skinned combined head and body and a separated head and body mesh. Inside of the body rig Maya file, the body combined mesh is the full body rig skinned mesh that is being integrated with the head and has the metahuman skeleton. The namespace string body combined is used for importing the body rig Maya file into a new scene."},{"start":"7:44","end":"8:15","startSec":464.0,"text":"The separated head and body are split versions of the full body skinned mesh and they are separated at the edge loop of the boundary where the head and body are combined on standard metahumans. If using this workflow with your own character, ensure that all three meshes have the correct skin weights. Now let's go over the DNA files that will be generated in the DNA file folder. The DNA files folder is where we place our original metahuman DNA file."},{"start":"8:15","end":"8:56","startSec":495.0,"text":"This is the default head rig that a user wishes to integrate with the body. In our case it is the atomic sDNA file which was the final DNA that was created from the previous script. In the output folder the two in-between metahuman DNA files that will be added in here are the updated scale DNA file which is generated from step one which bakes the new position and scale to the DNA. And the updated neutral DNA file which is generated from step two which updates the head mesh neck geometry to fit the body using the new neutral OBJ file that is located in the assets folder."},{"start":"8:56","end":"9:27","startSec":536.0,"text":"Now that we have gone over the assets that this script will use, let's return to Maya and go over the API interface script setting paths. Back in Maya in the script editor, in the Python window with the API interface script, let's go over the path settings. Scroll down to line 91. The first thing we will need to do is direct the root directory to point to the DNA calibration folder."},{"start":"9:27","end":"9:58","startSec":567.0,"text":"In my case it's on my C drive. Now for the rest of these paths below, these have already been set. If using these with your own character, you would leave the output and export folder as is. On line 96 for the source DNA file path, you would add the name of the DNA file. This is already pointing to the atomic s file we wish to use. On line 97 for the body rig, this is the name of the body rig Maya file."},{"start":"9:58","end":"10:33","startSec":598.0,"text":"On line 98 for the new neutral mesh, which is the fitted head geometry OBJ file with the correct neck area, this is named atomic s new neutral. Finally on line 103, the character name is the name of our character which is atomic s. If we look at line 104 and 105, these are the namespaces the script will be looking for, which is why it's important when assembling your own assets to keep these namespaces the same, otherwise you may run into errors."},{"start":"10:33","end":"11:08","startSec":633.0,"text":"Now let's do a quick review of what we just covered before we move on to the next section. To use the API interface script, for the root directory enter the path that points to the DNA calibration folder. For the source DNA, enter the path that points to the DNA file you wish to integrate with the body in the DNA files folder. For the body rig, enter the path that points to the body rig Maya file in the rigs folder. For the new neutral, enter the path that points to the new neutral mesh in the assets folder."},{"start":"11:08","end":"11:30","startSec":668.0,"text":"And lastly for the character name, this is the name that the new DNA files will include. All of the other paths can be left as is. Now that we have spent some time going over the workflow, the files the script will be using and the path settings, let's move on to the next section and begin to execute the script one step at a time."}],"07_CustomBodyPT2_55":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this section, we will continue going over the steps for using the custom body workflow. We will first initialize the script and load everything into memory. And then we will execute step one and step two. So let's go over initializing the script first. The steps to initialize the script are to first ensure you have pasted the entire API interface script into the script editor. Then select the script from line 1 to 72 and execute it."},{"start":"0:31","end":"1:02","startSec":31.6,"text":"To set the DNA calibration path and paths for the working folder, select line 75 to 105 and execute that. Let's jump into Maya and go through this. Inside of Maya, we will begin by initializing the script. I'm going to scroll down here, past all this code and references to other scripts, and I'm going to select everything from line 72 all the way up to 1 and then we'll execute"},{"start":"1:02","end":"1:36","startSec":62.9,"text":"this to load this into memory. Now I want to set the paths to the directories. So I will select everything from line 75 to 106 and execute this. We can now start executing each step. Let's begin with step one, which will position and scale the head rig for integration. Over here, I will select the first portion of step one from line 114 to 126 and execute it."},{"start":"1:36","end":"2:09","startSec":96.3,"text":"Once this is finished loading, over here, this will load the body combined rig into the scene. It has taken a copy of the head LOD zero from the MetaHumanDNA head mesh over here and named it position and scale mesh. If we had not used the previous DNA calibration script, the mesh would be much smaller and would probably be somewhere over here. For this portion of step one, we would select the position and scale mesh and just as we"},{"start":"2:09","end":"2:42","startSec":129.4,"text":"had done with the locator, we would manually position and scale it. The next step is to run the second part of step one. Select this section over here from line 133 to 146 and execute it. This will bake the position and scale to a new MetaHumanDNA file named updatedScale, which will be added to the output folder in the DNA files folder. It will then load the updatedScaleDNA with the body rig into a new scene."},{"start":"2:42","end":"3:14","startSec":162.3,"text":"Now that it is loaded, if I select the head group from this new DNA file, on the right over here, if we had made adjustments, we will see that there would be no transform values as those have been baked into the DNA. Another thing this command will do is it will match the head mesh and skeleton position with the body skeleton position. Now before we move on to step two, let's do a quick review of what we just covered."},{"start":"3:14","end":"3:46","startSec":194.9,"text":"Step one will position and scale the head rig for integration. Select the first portion of step one from line 113 to 126 and run it. This will load the MetaHumanDNA head meshes and joints and the body rig Maya file into a new scene. A copy of the LOD0 head geometry named position and scale mesh will appear. Since the atomic savage character has already been scaled and positioned from the previous workflow, the images on the right demonstrate what the unmodified version of the atomic"},{"start":"3:46","end":"4:17","startSec":226.8,"text":"savage DNA head mesh would look like. From here we would need to position and scale the head. Using the position and scale mesh, we would manually position and scale the head, as is shown in the images on the bottom right. This is similar to how we used the locator in the previous workflow, with the values being almost the same. Once we are happy with the scale and position, we can run the second portion of step one from line 133 to 137."},{"start":"4:17","end":"4:47","startSec":257.2,"text":"This portion of the script will bake the position and scale to a new DNA file named updated scale. We can then review the new DNA file by running the last portion of step one to load the DNA. Once we run the last portion of step one from line 143 to 146, this will load the updated scale DNA file and the body rig into a new scene. What we can see in the images on the bottom right is that the mesh and joint positioning"},{"start":"4:47","end":"5:19","startSec":287.8,"text":"of the new DNA matches the body rig position. Again, this is very similar to the previous workflow we went over, where it scales and translates the rig. Now let's take a look at step two before we jump back into Maya. For step two, if we were using the original atomic savage metahuman DNA file, for the first portion of this step, we would create a new neutral mesh using the updated scale DNA file in order to blend the neck area with the body."},{"start":"5:19","end":"5:50","startSec":319.1,"text":"The images on this slide demonstrate what this process would look like if we were to use the original atomic savage DNA file. The first and second image show what the neck seam would look like after step one, and the third image shows what the neck seam would look like after we have authored a new neutral mesh. Using the LOD0 head mesh from the updated scale DNA file, we would blend the neck vertex positions from the body with the neck area, and then export this as an obj file."},{"start":"5:50","end":"6:21","startSec":350.9,"text":"We would then place it in the assets folder. If using your own character, let's go over the steps for creating the new neutral mesh. To create a new neutral mesh with the updated neck seam, in a new Maya scene, use the DNA viewer run in Maya script to load the updated scale DNA file. For the meshes option, assemble only the head LOD0 mesh and leave everything else unchecked, as shown in the image on the bottom left."},{"start":"6:21","end":"6:53","startSec":381.7,"text":"From there, take the head LOD0 mesh and manually fit the neck geometry in order to integrate it with the body while respecting the edges and loops. Once the head mesh is properly fitted to the body, export that as an obj file and add the new head mesh to the assets folder. Back in Maya after the new neutral mesh has been created and placed in the assets folder, next we want to ensure that the path for the new neutral mesh obj file is correct on line"},{"start":"6:53","end":"7:28","startSec":413.6,"text":"156. From there, select everything from line 153 to 175 and execute it. This will update the DNA using the new neutral mesh obj file and then match the core joints of the spine, neck, and shoulders to the body rig. It will then load a new Maya scene so that we can inspect it. Now that this is finished loading, I am going to go into top view and I'm going to show"},{"start":"7:28","end":"7:59","startSec":448.6,"text":"the skeleton. I will select the head group so that we can see the skeleton and then select the body. And if we inspect the skeletons, we will see that the head joints are now aligned with the body, which is exactly what we wanted. Now let's do a quick review of step 2 before moving on. For step 2, once the new neutral mesh has been authored, using the updated scale DNA"},{"start":"7:59","end":"8:29","startSec":479.3,"text":"and then add it to the assets folder, make sure that the path to the new neutral mesh has been set correctly and then select everything from line 153 to 175 and execute it. This will update the DNA using the new neutral mesh obj file and the core joints of the spine, neck, and shoulders will match the body rig. With the head joints aligned with the body joints, as demonstrated in the images on the right, we can then proceed to step 3."},{"start":"8:29","end":"8:36","startSec":509.5,"text":"Now that's it for this section. In the next section, we will continue going through the rest of the steps for the custom body workflow."}],"08_CustomBodyPT3_55":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this section, we will continue going over the steps for using the custom body workflow by executing step 3 and 4. In the previous section, we executed step 1, where we positioned and scaled the head rig, and then executed step 2, where we updated the DNA using the new neutral mesh and aligned the head and body skeletons. The step 3 portion of the script will check the body and head skin weights, and step 4 will merge the body and head skin weights."},{"start":"0:31","end":"1:04","startSec":31.2,"text":"So let's return to Maya and execute step 3. Back inside of Maya, step 3 will check and validate the body and head skin weights. This will check if the skin weight influences on the neck region only contain influences that are supported by the standard metahuman head rig DNA description. In the script editor, I will scroll down here to step 3. I will select these lines here from 183 to 185 and execute this."},{"start":"1:04","end":"1:36","startSec":64.9,"text":"If the check fails, we will get this warning pop up. This notifies us that the head area contains skin weight influences not supported by the standard DNA description, and that gaps may appear at the seam during deformation. It recommends that we modify the body skin weights so that only influences included in the metahuman head rig are used in this region. Select I will fix this. Now the body skin weights that need to be adjusted are going to be highlighted."},{"start":"1:36","end":"2:10","startSec":96.7,"text":"I will go up here and select this tool in order to isolate the highlighted sections. Now with the selected, I will go up here to the top left and change this to rigging. Next go up here to skin and then select paint skin weights and click on this to open up the options. Now I'm going to move this over here. In the script editor, over here, it has listed the names of the unsupported influences."},{"start":"2:10","end":"2:46","startSec":130.5,"text":"I will copy the first one which is for the right upper arm. In the paint skin weight tool settings, I will paste the name in the search option to locate the selection and select it. Next I want to adjust the values. For the opacity, I want to ensure that this is set to 1 and for the value, I want to ensure this is set to 0. And now I can select flood. In the viewport, I will click on the highlighted selection and now I will repeat this for the"},{"start":"2:46","end":"3:16","startSec":166.5,"text":"other section. I'm going to go to the script editor and copy the name of the other unsupported influence and then paste it in the search option to locate the selection. I'm going to leave everything the same and select flood again and then click on the highlighted selection in the viewport. Now before we continue, let's do a quick review of the steps we just went through."},{"start":"3:16","end":"3:46","startSec":196.8,"text":"Step 3 validates the skin weights on the head and body. It will check whether the skin weight influences on the neck region only contain influences that can be described in the DNA file. To check the body and head skin weights, select line 183 to 185 and execute it. After a few moments, if the check fails, a pop-up will appear letting us know that we need to modify the body skin weights so that only influences included in the metahuman head rig are used in this region."},{"start":"3:46","end":"4:19","startSec":226.9,"text":"Otherwise, this may cause gaps to appear at the seam during deformation. We will need to modify the combined body rig skin weights in this case. Once we see the warning pop up and click on I will fix this, the skin weight sections on the combined body rig that need to be modified will be highlighted. We will need to remove the skin weight values associated with these selected vertices. To do this, isolate the selection, then go to skin and then select the paint skin weights"},{"start":"4:19","end":"4:50","startSec":259.3,"text":"and open up the skin weight tool settings. In the script editor, copy the name of the unsupported influence and then in the paint skin weight tool setting, paste the name in the search option to locate the selection. Ensure that opacity is set to 1, value is set to 0 and then select flood and click on the selection. Then repeat these steps for the other selection. With the combined body rig skin weights adjusted, we can now rerun the skin weight check."},{"start":"4:50","end":"5:23","startSec":290.3,"text":"So let's return to Maya and continue with step 3. Back in Maya, now that we have modified the body skin weights, we can rerun the validation. Select this section again and execute it. Now we will see a pop up letting us know that no issues were found and that the skin weight influence is complete. Now before we move on to step 4, since we have updated the skin weights on the combined body, we want to copy the skin weights to the body only mesh as that will be the mesh"},{"start":"5:23","end":"5:56","startSec":323.1,"text":"that will be brought into Unreal Engine. To transfer the updated skin weights from the combined body to the separated body mesh, first make the separated body visible. We will need to change over to rigging mode. And now select the combined mesh and then select the separated body mesh, go up here to skin and then select copy skin weights and click on this to open up the options."},{"start":"5:56","end":"6:27","startSec":356.8,"text":"In the skin options, check the settings, the default settings are fine and now select apply. I'm going to get out of this mode and now I want to export this as an FBX. To do this, select the separated body mesh and then select the root, go to file and choose export selection. Now before we move on, let's do a quick review of what we just covered."},{"start":"6:27","end":"6:57","startSec":387.1,"text":"In the script editor, we can rerun the body and head skin weights validation and if no issues are found, a notification will appear letting us know that the check is complete. Now since the skin weights on the combined body have been updated, we will want the body only mesh to also be updated as that is the body we will be bringing into Unreal Engine. To transfer the updated skin weights from the combined body to the separated body, we will need to change over to rigging mode."},{"start":"6:57","end":"7:27","startSec":417.5,"text":"Then select the combined body mesh and then the separated body mesh, then go to skin and select copy skin weights and open up the options. Select the settings and then select apply. From there, select the separated body mesh and root and export the selection as an FBX. Now let's return to Maya and execute step 4. Back inside of Maya, now that we have validated the head and body skin weights and saved the"},{"start":"7:27","end":"7:58","startSec":447.8,"text":"separated body and skeleton as an FBX, we can now run step 4 which will merge the body and head skin weights. I will select step 4 from line 191 to 197 and execute this. Step 4 will create new skin weights using the neck falloff weight blend mask that is located in the custom body integration workflow folder. This process writes new skin weights back into the DNA file and once it's complete,"},{"start":"7:58","end":"8:33","startSec":478.1,"text":"the DNA will be added to the export folder. Now this process may take up to 8 or 9 minutes to complete. I have sped up the recording for this process and left the script editor visible so that you can see what this will look like. As we wait for this to finish, let's do a quick review of step 4. Once the head and body skin weights have been validated, step 4 creates new skin weights using the neck falloff weight blend mask. Select all of step 4 from line 191 to 197 and execute it."},{"start":"8:33","end":"8:48","startSec":513.4,"text":"This process writes the new skin weights to the DNA file and it may take several minutes to complete. Now that's it for this section. In the next section we will wrap up this workflow by executing step 5."}],"09_CustomBodyPT4_55":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"In this section, we will wrap up the custom body workflow by going over step 5, where we validate the results, check for seam issues, and generate the final DNA and export the head LODs as FBX. So let's jump back into Maya and execute step 5. Back inside of Maya, now that this process is complete and with the new skin weights written to the DNA file, we can now check the results with step 5."},{"start":"0:32","end":"1:04","startSec":32.2,"text":"Select line 202 to 211 and execute it. This will load the new DNA and constrain the head core joint hierarchy to the body so that we can check the results to see if the skin weight merge was successful. Now that this is finished loading, in the viewport, I will switch to the top view to bring this closer. Then in the Outliner, I will collapse the head group and then collapse the head geometry"},{"start":"1:04","end":"1:39","startSec":64.7,"text":"and hide all of the other LODs. And then I will hide the spine. I will switch over to Rotate mode and then I will select the body rig root and make the joints visible. I will select the arm joint and I will rotate the arm to check and see if there are any seam issues in the front. And then turn the body around and check the back area."},{"start":"1:39","end":"2:14","startSec":99.2,"text":"We can see that the skin weight merge was successful and that there are no gaps at the seam lines between the head mesh and body. If you notice a line along the seam area, this indicates a difference in normals. Matching the normals would be the last step of this workflow. For this character, the normals have already been matched. Now before we move on to the final step, let's do a quick review of step 5. Step 5 validates the results by constraining the head core joint hierarchies to the body"},{"start":"2:14","end":"2:45","startSec":134.1,"text":"to test. Select all of step 5 from line 202 to 211 and execute it. This will connect the skeletal hierarchies and we can check the skin weights by moving the joints located along the neck seam line. We can select the clavicles and rotate them to ensure that no gaps appear at the seam between the body and head mesh. For this character, the normals have already been matched. However, if you are using your own metahuman character, you will need to match the normals"},{"start":"2:45","end":"3:16","startSec":165.6,"text":"at this point. If everything looks good, the next step is to export the final DNA head LODs as FBX. So let's return to Maya and complete this workflow. Back inside of Maya, we can now run the export to FBX portion of this script. Select this entire section from line 218 to 225 and execute it. This process will extract joint information from the body rig to extend the joints that"},{"start":"3:16","end":"3:50","startSec":196.5,"text":"are described in the DNA file. This will add the root joint, the spine, the neck, and the shoulder joints. And then it will export 1 FBX per LOD and assign shaders. As we wait for this process to complete, let's do a quick review of the export FBX step. The export FBX portion of this script will extend the joint information from the body rig to the DNA derived joints. This will grab the joint information from the body rig and extend it to the DNA derived"},{"start":"3:50","end":"4:26","startSec":230.7,"text":"joints and add the root, spine, neck, and shoulder joints. They will then export 1 FBX per LOD and assign shaders to each of the head geometry assets. The images on this slide demonstrate what the final head LOD FBX will look like for LOD 0. We can see how the skeleton has been updated from our atomic savage DNA to the final DNA. Now that the custom body workflow is complete, let's return to Maya one last time to locate the assets we will need to bring into Unreal Engine and finalize the rig."},{"start":"4:26","end":"4:56","startSec":266.6,"text":"Back in Maya, all of the LODs have been exported. In the export folder, we have the final DNA file and all of the head LOD FBX files and the body skeletal mesh with the modified skin weights. Inside of the viewport, we can see that the skeleton has been updated. And if we go to the Outliner and select the head mesh, if I go to the right over here and open up the Attributes Editor, we will see that a shader has been applied to the head and labeled correctly."},{"start":"4:56","end":"5:28","startSec":296.9,"text":"And this is also the case for all of the other head geometry assets. We are now ready to bring all of these assets into Unreal Engine and finalize our character. Now let's wrap up this section by reviewing the assets that we will be bringing into Unreal Engine. The assets located in the export folder that will be brought into Unreal Engine include the final metahuman DNA file, the exported head LODs as FBX, and the separated body mesh and skeleton with the updated skin weights."},{"start":"5:28","end":"5:44","startSec":328.8,"text":"The body and head FBX will be Y up in Maya, which is fine. Now that we have everything we need in order to finalize our customizations, in the next section we will delve into our hands-on exercise and go through the steps of bringing these assets into Unreal Engine."}],"10_HandsOn_FinalizedAssets_55":[{"start":"0:00","end":"0:32","startSec":0.0,"text":"Now that we have finished going through the custom body workflow and have all of the modified assets for Atomic Savage, we are now ready to bring them into Unreal Engine and finalize the rig. We will dive into a hands-on exercise where we will bring the head LOD-FBX files and final metahuman-DNA file into Unreal Engine and configure the metahuman blueprint and assign the custom body. We will also go over how to import the custom body into Unreal Engine and test the customized"},{"start":"0:32","end":"1:02","startSec":32.2,"text":"face and body with animations to make sure everything is working correctly. So let's dive into the hands-on exercise and start finalizing this custom metahuman character. In this section, we will go through a hands-on exercise. We will primarily work in Unreal Engine to bring in the head LODs, the calibrated metahuman-DNA file, we will configure the metahuman blueprint and assign the custom body. As we work through this exercise, you will note that this is broken down into a step-by-step"},{"start":"1:02","end":"1:33","startSec":62.7,"text":"process that is found in your slide deck. As we complete portions of the practical exercise, I will review the completed steps. So let's jump into Unreal Engine and begin to finalize our customized metahuman character. Inside of Unreal Engine, we will begin to bring in our modified metahuman assets. Let's get started by first duplicating the metahuman face skeletal mesh that we will be updating. I'm going to select Atomic Savage in our level."},{"start":"1:33","end":"2:04","startSec":93.2,"text":"This metahuman is named Atomic Savage Example. To locate this character's face mesh, I'm going to go to the Details panel and locate the head component and select it. Then I can go to the face skeletal mesh and use the folder to browse to its location. Now I'm going to right-click on the face skeletal mesh and select Duplicate. We will need this copy later on when we reassign the grooms in the metahuman blueprint."},{"start":"2:04","end":"2:41","startSec":124.5,"text":"Now I'm going to save this. And now I'm going to select the original skeletal mesh and double-click on it to open it. With this window open, the first step is to assign a source file path in order to re-import the head LOD FBX files. In the Asset Details panel, I will search for File. What we want to locate is the Import Settings. In the Asset Import Data File Path, we want to set the source file path for the FBX files."},{"start":"2:41","end":"3:16","startSec":161.2,"text":"I will click on this and this will open up the Exports folder and I'm going to select LOD 0 and then select Open. The next step is to re-import the head LODs as new files. Now it is worth mentioning that users may encounter issues when re-importing the FBX in the current 5.5 engine version. So to work around this, in the command Prompt, I will paste the command interchange.featureflag.import.fbx"},{"start":"3:16","end":"3:46","startSec":196.5,"text":"with the value set to 0 and hit Enter. I will save everything and now I'm going to go up here to the Re-import Mesh with Dialog drop-down and select Re-import Mesh with new file. This will open up the Exports folder, I will select LOD 0 and select Open and the FBX import options will appear."},{"start":"3:46","end":"4:16","startSec":226.9,"text":"Here I want to make sure that the face archetype is assigned as a skeleton. In the Transform section, I will change the import rotation to 90 degrees since the head FBX is in Y up and then select Import. This may take a moment. Now we have the head LOD 0 imported. It may look strange at first and that is because we have to update the metahumanDNA file."},{"start":"4:16","end":"4:51","startSec":256.9,"text":"I'm going to save this. Now we still need to re-import the other head LODs so I will clear my search in the Asset Details panel and locate the LOD Settings section. To re-import the lower LODs, I will go to the LOD import and drop this down. I will select Re-import LOD Level 1 and then select the LOD 1 FBX and select Open. And once the import process is complete, a notification will appear."},{"start":"4:51","end":"5:21","startSec":291.4,"text":"You can repeat this for all of the LODs if you wish. If you are going to be working with LOD 0 only, ensure that you set the forced LOD to 0 in the metahuman blueprint and I've already done that for this character. Now let's do a quick review of the steps we just went through before we move on. In order to bring in the modified metahuman assets, to get started we will want to duplicate the face skeletal mesh of the metahuman whose assets we will be updating."},{"start":"5:21","end":"5:53","startSec":321.9,"text":"To do this, locate the face skeletal mesh in the face folder of the metahuman characters folder. Then select the skeletal mesh, right click on it and select Duplicate. This duplicate of the head skeletal mesh will be used when reassigning the groom binding assets. Once that is complete, the first step is to assign a source file path in order to re-import the head LOD FBX files. To assign a source file path, open up the face skeletal mesh and go to the Asset Details"},{"start":"5:53","end":"6:27","startSec":353.7,"text":"panel. In the Import Settings section, for the Asset Import Data file path, direct it to the folder where the head LOD FBX files are located and then select the LOD0 FBX file. The next step is to re-import the head LOD FBX as new files. As mentioned, users may encounter issues when re-importing the head LOD FBX files in the current 5.5 engine version. To work around this, in the command Prompt, enter the Interchange Feature Flag Import"},{"start":"6:27","end":"6:59","startSec":387.6,"text":"FBX command and set the value to 0 and hit Enter. To re-import an LOD with a new file, go to the Re-import Mesh with Dialog option in the toolbar and select Re-import Mesh with New File. For the FBX import options, ensure that the face archetype skeleton is selected and then select Import. The head LOD0 will be re-imported and it may not look correct at first, but that is normal as the DNA file has not been updated yet."},{"start":"6:59","end":"7:31","startSec":419.6,"text":"The next step is to re-import the lower LODs. To re-import the lower LODs, in the Face Skeletal Mesh Asset, in the Asset Details panel, locate the LOD Settings section. Then in the LOD Import option, use the drop-down arrow to re-import each LOD. As mentioned, if you intend to use LOD0 only and do not wish to re-import the lower LODs, ensure that you change the forced LOD to 0 in the Metahuman Blueprint LOD Sync Component"},{"start":"7:31","end":"8:06","startSec":451.5,"text":"Settings. With the head LODs re-imported, the next step is to update the Metahuman DNA file. So let's return to Unreal Engine and continue with the steps. Back inside of Unreal Engine, let's navigate back to the main viewport. We will see that the grooms on the Metahuman do not look correct, and we will fix that in a moment. What we want to do for the next step is to import the new DNA file. To update the Metahuman DNA file, in the Content Browser, I'm going to select the original"},{"start":"8:06","end":"8:41","startSec":486.3,"text":"Face Skeletal Mesh and right-click on it. Over here I'm going to select Metahuman DNA and select Import New DNA File. I'm going to navigate to the Exports folder, which is inside of my DNA calibration folder in the Working folder, and then inside of the Export folder, I will select the Atomic S Final DNA, and then select Open. The DNA Import Options will open, and we just want to ensure that the correct Face Skeletal"},{"start":"8:41","end":"9:16","startSec":521.4,"text":"Mesh is selected, and then we can select Import. I'm going to save everything. Now before we move on, let's review the steps we just covered. To import the new Metahuman DNA file, select the Face Skeletal Mesh and right-click on it. Then select Metahuman DNA and choose Import New DNA File. Locate and select the DNA file that has been updated, and select Open. For the DNA Import Options, ensure that the Face Skeletal Mesh is assigned, and then select"},{"start":"9:16","end":"9:47","startSec":556.9,"text":"Import. Now let's return to Unreal Engine and continue with the next steps of this exercise. Back inside of Unreal Engine, we have just finished updating the Metahuman DNA. As we can see in the viewport, the grooms do not look correct, and that is because we need to reassign the groom assets. To do this, we will first select the duplicated skeletal mesh. Then we want to open up the Metahuman Blueprint for our character."},{"start":"9:47","end":"10:18","startSec":587.4,"text":"We can do this by selecting the Metahuman in the viewport, and next to its name in the Outliner, we can click on Edit Blueprint. This will open up the Metahuman Blueprint for our character. I will navigate to the viewport. Now we want to re-bind all of the grooms, so I will select the eyelashes component first. In the Details panel, I will navigate to the groom binding asset over here and open it."},{"start":"10:18","end":"10:49","startSec":618.5,"text":"With the duplicated face mesh still selected in the Content Browser, I'm going to assign it here using this arrow as the source skeletal mesh. I'm going to save this and close it. We will have to repeat this for all of the grooms. I will select the Peach Fuzz component. Then in the Details panel, I will open up the groom binding asset and use the arrow to assign the duplicated face mesh as the source skeletal mesh. I will save this and close it."},{"start":"10:49","end":"11:21","startSec":649.6,"text":"I will repeat this for the eyebrows component. Select it. Open up the groom binding and assign the duplicated face mesh as the source skeletal mesh. Save this and close it. For the hair component, again, I will select it. Then open up the groom binding asset and assign the duplicated face mesh as the original skeletal mesh. Now, this one will take a bit longer to process. Once it is done, I will save this and close it."},{"start":"11:21","end":"11:53","startSec":681.9,"text":"And finally, we have the beard component. I will select it. Open up the groom binding asset and assign the duplicated face mesh. Then save it and close it. What you will notice is that the grooms look correct now. However, the neck region does not. And the reason for this is that the head and updated joint positions are constrained to the original body so the skeletons are not aligned. So the next step is to assign the custom body."},{"start":"11:53","end":"12:24","startSec":713.4,"text":"Now I've already imported the custom body into this project and will go over the steps on how I imported it later on. For now, let's go back to the main viewport. In the content browser, we are going to locate the custom body. In our course assets folder, there is a folder named AtomicSBody. Inside of here, the skeletal mesh for the custom body is located here and it is named AtomicSBodyExportSkinweights."},{"start":"12:24","end":"12:56","startSec":744.6,"text":"With this selected, we are going to go back to the metahuman blueprint. Next select the body component and in the details panel, in the skeletal mesh section, I'm going to use the arrow to assign the custom body. We can see the skeletons are now aligned. We can compile and save this. And if we go back to our main viewport, we will see our finalized metahuman character."},{"start":"12:56","end":"13:29","startSec":776.6,"text":"Now let's do a quick review of what we just covered. Once we have re-imported the head LODs and updated the metahuman DNA, the next step is to re-bind the grooms. To do this, inside of the metahuman blueprint, select each of the groom components, then open up the groom binding asset, assign the duplicated face mesh as the source skeletal mesh, and then compile and save. To assign a custom body, in the metahuman blueprint, select the body component, then"},{"start":"13:29","end":"13:59","startSec":809.5,"text":"in the details panel, assign the body skeletal mesh to the skeletal mesh asset, then compile and save. Now we just went through the steps of finalizing the customizations of our metahuman character. For the hands-on exercise, I had already imported the custom body. In the next section, I will go over the steps of how to import the custom body and configure it so that it behaves correctly when it is assigned to the body component."}],"11_ImportCustomBody_55":[{"start":"0:00","end":"0:33","startSec":0.0,"text":"In this section, we will go over how to import a custom metahuman body skeletal mesh into Unreal Engine and configure it. If you wish to go through the steps, the custom body skeletal mesh is located in the source files folder of our course in the custom body working export folder. Now, let's jump back into Unreal Engine and go over the steps for importing a custom metahuman body. Right of Unreal Engine, I am going to go through the steps of importing the custom body FBX"},{"start":"0:33","end":"1:05","startSec":33.1,"text":"file. First, I will navigate to the body folder. Next, I will go to import and in the export folder, I am going to select the Atomic-S body export skin weights FBX file. Since I used the interchange feature flags command earlier, the FBX import options window will appear instead of the import content window. In the FBX import options window, I am going to assign the metahuman base skeleton over"},{"start":"1:05","end":"1:36","startSec":65.2,"text":"here. Since the body FBX file was exported in YUP, I want to make sure the import rotation is still set to 90 degrees. And I also want to make sure that import animations is checked off. Now I can select import. I am going to save everything now. Next, I am going to double click on the skeletal mesh to open it up. Now, we want to assign a material to this."},{"start":"1:36","end":"2:13","startSec":96.7,"text":"So I will go back to the main viewport and select our metahuman in the level. In the details panel, I will select the body component. And then I will locate the material and navigate to it using this folder icon. With this selected, I will return back to the skeletal mesh window. In the asset details panel in the materials slot, I will assign the body material instance to this. Next, I will scroll all the way down here to locate the default animating rig."},{"start":"2:13","end":"2:46","startSec":133.4,"text":"I will assign the metahuman control rig for the body here. I will use this drop down arrow and then locate it and select it. If you have an animation blueprint that is set up with body correctives, I will show you where you can assign that. I will scroll back to the top of the asset details panel. For the post process animation blueprint slot, I will use the drop down arrow and I will select the animBP RBF correctives blueprint."},{"start":"2:46","end":"3:20","startSec":166.0,"text":"And if you wish to inspect this blueprint, you can find it in the course assets folder in the atomic savage folder. I will delve into this animation blueprint later, but for now it is worth noting that it uses corrective poses that have been authored using the pose driver connect toolset. Now let's do a quick review of the steps we just went through before we move on. We just went over how to import a custom metahuman body into Unreal Engine. In the import options, under the common section, we want to change the offset rotation to 90"},{"start":"3:20","end":"3:50","startSec":200.3,"text":"degrees if the skeletal mesh is in Y up. Next, we want to assign the metahuman base skeleton under the common skeletal meshes and animation section. And under the animation section, we want to ensure that import animations is checked off and then we can select import. Once the skeletal mesh has been imported, the next step is to configure it. Inside of the skeletal mesh window, in the asset details panel, we can assign a material"},{"start":"3:50","end":"4:23","startSec":230.5,"text":"to the body. Then we want to assign the metahuman control rig for the default animating rig. If you have authored corrective poses using the pose driver connect toolset and have created an animation blueprint with those, you can assign that to the post process animation blueprint slot under the skeletal mesh section. Now the images on the top right demonstrate what the shoulder area looks like within without corrective poses. Once we have imported all of the modified assets and finalized our character, the last"},{"start":"4:23","end":"4:34","startSec":263.9,"text":"step is to test the character by applying animations to it. In the next section, we will test the face and body with animations and check to make sure that everything is behaving correctly."}],"12_TestAnimations_55":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"Once the customizations have been applied to our metahuman character in Unreal Engine, the next step is to check that everything is working correctly. In this section, we will test the face and body with animations to see if any additional adjustments need to be made in order to finalize this character. So let's jump into Unreal Engine and apply animations to the Atomic Savage character. Inside of Unreal Engine, I'm going to navigate to our course topics folder."},{"start":"0:31","end":"1:03","startSec":31.0,"text":"And then go to the folder named Atomic S, example, anim sequence. Inside of here, you will find a level sequence with a face and body animation that has already been assigned to Atomic Savage. I will double click on this to open it. Now to view the entire face and body, we can go to perspective and select the camera named cam01body. And then we can play the sequence. I'm going to stop this for a moment."},{"start":"1:03","end":"1:34","startSec":63.4,"text":"To check the face, I'm going to go here and disable the actor and sequencer. I'm also going to disable the body animation for now. And I'm going to go back to perspective and view this from the front view camera so that we can see the facial features up close. I'm going to play the sequence now. As mentioned in the previous course, this particular stylized character's facial features go beyond the golden triangle of the face."},{"start":"1:34","end":"2:06","startSec":94.0,"text":"And we anticipate that even though we've used DNA calibration workflows, we may still see some breaks in the range of motion. For example, in the eyes. I will zoom in here and continue playing this. We will notice some intersecting between the eyes and the eye shell shader when this character looks left and right. This may be due to the eyeball and eye shell geometry possibly intersecting, or the eye"},{"start":"2:06","end":"2:41","startSec":126.3,"text":"joints may need to be adjusted and moved a bit. Either way, this area may require some additional work. Now let's test the body. I'm going to go back to perspective and select the CAM01 body camera again. I will go back to the start of the sequence. And I will set the body animation track back to active and also set the actor track back to active. And now I will play the sequence again. When we get to the portion of the animation where the arms are raised, I will press pause"},{"start":"2:41","end":"3:17","startSec":161.5,"text":"right here. If we look at the shoulder and neck region, we can see that this does not look correct. Corrective poses can be created and applied to fix these problematic areas of deformation. To demonstrate what this will look like when corrective poses are applied, I will select the metahuman in the viewport. In the details panel, I will select the body component. And I will open up the body skeletal mesh. For the post-process animation blueprint slot, I will assign the RBF correctives animation"},{"start":"3:17","end":"3:49","startSec":197.0,"text":"blueprint over here. I will save everything. Now when we return back to the main viewport, we will see that with the corrective poses applied, the shoulder and neck region look much better. Another thing worth mentioning is that the body animation that has been applied to atomic savage has been retargeted from the female medium normal body weight using IK Retargetor. And the bone retargeting options have also been changed."},{"start":"3:49","end":"4:21","startSec":229.7,"text":"I will go to the skeletal mesh asset window again. And inside of here, I will go to the skeleton tree panel and use the cog wheel to select show retargeting options. I've changed the pelvis to animation scaled. And I've also changed the main joints from animation to skeleton while leaving the correctives set to animation. Now adjusting the retargeting options is helpful when retargeting animations from skeletons"},{"start":"4:21","end":"4:52","startSec":261.3,"text":"that are different proportions. Let's do a quick review of what we just covered before we move on. To finalize customizations to the metahuman face, it is important to test the face with animations to ensure that everything is working correctly. Another option is to use the face control rig with a forward solve by checking each control. Testing the face with animations can help you decide if there are any problematic areas that may still need further adjustments."},{"start":"4:52","end":"5:24","startSec":292.3,"text":"It is worth mentioning that the customized metahuman face will continue to be compatible with metahuman animation tool sets such as metahuman animator and live link face. When testing customizations to the metahuman body with animations or by using the control rig, keep in mind that if there are significant differences in the skeleton proportions from a metahuman based skeleton, body animations may need to be retargeted. The bone retargeting options may also need to be adjusted."},{"start":"5:24","end":"5:57","startSec":324.8,"text":"The images on the right demonstrate what the body looks like when all of the main joints are set to animation and what it looks like when they are set to skeleton. To adjust the bone retargeting options, go to the skeleton tree in the skeletal mesh or animation sequence window and use the cogwheel to check on show retargeting options. From there, change the pelvis to animation scaled and the main joints to skeleton. Now let's move on to the last portion of our course where we will go over some final recommendations."}],"13_FinalTips_55":[{"start":"0:00","end":"0:31","startSec":0.0,"text":"In this portion of our course, we will go over some final recommendations. I will provide you with some tips and resources for you to use as you continue your work in training with metahumans. We will first go over how to troubleshoot certain issues you may encounter. Then we will take a look at how to import and assign body correctives that have been authored using the PoseDriverConnect toolset. And we will finish off by looking at some resources related to the topics discussed in this course."},{"start":"0:31","end":"1:02","startSec":31.7,"text":"So let's first go over some troubleshooting tips. In this section, we will take a look at how to troubleshoot certain issues that you may encounter at various stages of the workflows we covered. We will go over how to handle issues with shaders, re-importing the head-LOD-FBX files, and material conflicts. We will also touch upon considerations when using the DNA calibration custom body workflow. So let's begin with troubleshooting shader issues."},{"start":"1:02","end":"1:37","startSec":62.8,"text":"The images below show the preset Lina that was modified using the UnrealFest DNA calibration script. When applying facial animations, you may encounter the shader issue she has on her upper eyelids. To fix this, you can recompute the tangents for the green channel of the head shader. Open up the face skeletal mesh, and in the asset details panel, locate the LOD0 sections. Section 0 is the head shader. Go to the recompute tangents dropdown and change it to green, and this will resolve the issue."},{"start":"1:37","end":"2:11","startSec":97.9,"text":"Let's take a look at another issue you may encounter when re-importing the head-LOD-FBX files. Depending on the engine version you are using, you may encounter issues when using the re-import with new file option. When re-importing the head-LOD-FBX file, using the re-import with new file option, if the process of importing the file takes a very long time and nothing happens, you can paste the interchange feature flags import-FBX command with the value of 0 into the command prompt,"},{"start":"2:11","end":"2:43","startSec":131.4,"text":"and then select the re-import with new file again. For engine versions 5.4 and earlier, in order for the FBX import option window to appear, when re-importing with the new file, you will need to go to the editor preferences and search for re-import. Then go to miscellaneous and enable show import dialog at re-import. When you are importing the LOD0 head-FBX, you may see a conflict show up in the re-import content window."},{"start":"2:43","end":"3:17","startSec":163.2,"text":"A material conflict may occur if you have named the head geometry assets incorrectly. Select reset to FBX to resolve the conflict. Another conflict you may encounter is for unmatched skeleton joints. This may occur if you use the export FBX script from the DNA calibration examples folder to export a newer version of MetaHuman. Make note of it and proceed. Now let's go over some considerations when using the DNA calibration custom body workflow."},{"start":"3:17","end":"3:54","startSec":197.1,"text":"The current version of the custom body workflow does not update the lower head LOD additional assets. The additional assets will not be scaled and translated with the head geometry asset. If you are planning to use LOD0 only, this will be fine. If you are going to need the lower LODs, consider using the AtomicSDNA calibration script to scale and translate the DNA and then use the custom body workflow for aligning the skeletons. Use the DNA file that is generated from the AtomicSDNA calibration workflow with the custom body workflow."},{"start":"3:54","end":"4:17","startSec":234.0,"text":"For step one, you will not have to do anything with the position and scaled mesh. And for step two, you can use the LOD0 head mesh as the new neutral mesh if the neck vertex positions have already been authored. Now let's move on to the final section of our course where we will go over how to import and assign body correctives to a MetaHuman character."}],"14_BodyCorrectives_55":[{"start":"0:00","end":"0:29","startSec":0.0,"text":"In this final section of our course, we will go over the workflow for importing and setting up body correctives that have been created using the PoseDriverConnect toolset. We will first go over the plugin that is needed to bring the RBF solvers into Unreal Engine. And then we will jump back into Unreal Engine one last time to go over the steps for importing and assigning them to the metahuman body. So let's begin by going over the required plugin."},{"start":"0:31","end":"1:02","startSec":31.0,"text":"The PoseDriverConnect toolset allows users to author their own corrective poses. And the PoseDriverConnect plugin allows users to import the poses into Unreal Engine. From there, they can be applied using an animation blueprint. The plugin is located in the FAP marketplace. Begin by installing it to the appropriate engine version. Then inside of Unreal Engine, open up the plugins menu and enable the PoseDriverConnect plugin and restart the engine."},{"start":"1:02","end":"1:33","startSec":62.0,"text":"Now let's jump back into Unreal Engine one last time to go over the steps for importing and assigning the body correctives. Inside of Unreal Engine, to import and assign the body correctives, let's first navigate to the Atomic Savage example body folder. I will open up the metahuman folder. Then go to the Atomic Savage example folder and then to the body folder. The first step is to create a folder for the corrective poses."},{"start":"1:33","end":"2:06","startSec":93.0,"text":"I have already created a folder named RBF Solvers EX for example. I will open this. Now the next step is to create an animation blueprint. I have already created one and named it RBF Correctives EX for example. But to walk you through the steps, right click in an empty space. Then select Animation and then select Animation Blueprint. In this pop-up window, assign the metahuman base skeleton and then select Create."},{"start":"2:06","end":"2:36","startSec":126.0,"text":"I am going to cancel this since I have already gone through these steps. Now let's double click on this to open it. I will dock this up here. Inside of here, I am going to navigate to the Preview tab up here on the right. For the mesh, I am going to search for the Atomic S body skin weights skeletal mesh and select it. And then I will click on Apply to Asset over here."},{"start":"2:37","end":"3:10","startSec":157.0,"text":"In the Anom Graph, I am going to right click and search for Input Pose and select it. I am going to connect it to the Output Pose and then I will zoom out and drag the Input Pose all the way over here. I will now compile and save this. Next, I will go back to the main viewport."},{"start":"3:10","end":"3:41","startSec":190.0,"text":"I will go up here to Tools and go down here and select Pose Driver Connect. In the Pose Driver Connect panel, for the Retarget Source Asset, I am going to use the drop-down arrow and then locate the Atomic S body skin weights skeletal mesh. It is right here, so I will select it. For the Animation Blueprint, I am going to assign the Animation Blueprint I have over here named RBF Solvers Example."},{"start":"3:41","end":"4:18","startSec":221.0,"text":"Next, we need to assign the RBF JSON file. I will go here and in File Explorer, up here I will paste the location of the source files folder of our course. In the Pose Driver Connect folder, inside of the folder named RBF Solvers, I am going to select the JSON file named Solver Data and then select Open. For the FBX Source Directory, I am going to paste the location of the source files folder up here again and then open the Pose Driver Connect folder."},{"start":"4:19","end":"4:56","startSec":259.0,"text":"I will then select the RBF Solvers folder and then select Open. For the FBX Import Directory, I will go to the MetaHumans folder, then to the Atomic Savage Example folder, then select the RBF Solvers Example folder. Now I can select Import All RBF Solvers. This will take a moment. Now that everything has been imported, I am going to save everything."},{"start":"4:56","end":"5:36","startSec":296.0,"text":"If we go to the Animation Blueprint now, inside of the Anim Graph, we will see that the body correctives have been added in here and are all connected. All we need to do now is compile and save. I will return back to the main viewport and if we want to view a body corrective, I will double click on this one to open it. In the Preview Scene panel, for the Preview Mesh, I will use the drop-down arrow to search for the Atomic-S Skeletal Mesh and I will select it."},{"start":"5:36","end":"6:14","startSec":336.0,"text":"And then I will select Apply to Asset. Now if I scrub through this animation, we can't really tell if the corrective is applied, so we will want to make sure that the Animation Blueprint is assigned to this Skeletal Mesh. I will go back to the main viewport, then in the Content Browser down here, I will go all the way down past all of these correctives and select the Animation Blueprint. With this selected, I will go back to the Animation Sequence window and in the Preview Mesh section, I will use the folder icon to browse to the Skeletal Mesh."},{"start":"6:14","end":"6:44","startSec":374.0,"text":"I will open this up and over here in the Asset Details panel, I would assign the Animation Blueprint here in the Post Process Animation Blueprint slot. Now before I do this, in the Skeleton Tree, I'm going to select the left upper arm and then rotate it. Now when I assign the Animation Blueprint over here, we can see what the upper arm area looks like when a corrective pose is applied."},{"start":"6:46","end":"7:22","startSec":406.0,"text":"And this is how you import and assign body corrective poses to a custom metahuman body. Now let's do a quick review of these steps and wrap up our course. With the PostDriverConnect plugin enabled in the Unreal Engine project, create a folder for the RBF solvers to be added to when they are imported. Next, create an Animation Blueprint and assign the metahuman-based Skeleton to it. Inside of the Animation Blueprint, in the Preview Scene, assign the Custom Body Skeletal Mesh and then select Apply to Asset."},{"start":"7:22","end":"8:02","startSec":442.0,"text":"In the AnomGraph, add an InputPose node and connect it to the OutputPose. Then drag the InputPose node away from the OutputPose to make room for the pose drivers. The next step is to import the pose drivers. To import the body correctives, in the MainView port go to Tools and select PoseDriverConnect. In the PoseDriverConnect panel, assign the Skeletal Mesh and Animation Blueprint. Then set the path directories for the RBF JSON file, the FBX Source directory, and the FBX Import directory where you want them to be added."},{"start":"8:03","end":"8:36","startSec":483.0,"text":"Next, open up the Animation Blueprint, Compile and Save. For the last step, assign the Animation Blueprint to the Skeletal Mesh. Inside of the Skeletal Mesh window, in the Asset Details panel, locate the Post Process Animation Blueprint slot and assign the Animation Blueprint. From there, you can test and see if the solvers are working. You can also open up the Animation Sequence window and play each corrective solver from the Asset Browser."},{"start":"8:36","end":"9:07","startSec":516.0,"text":"In the Preview Scene panel, assign the Skeletal Mesh and select Apply to Asset so that you can see the pose driver on the target Skeletal Mesh and update the thumbnail image. Now that we have gone through all of the steps for importing and assigning corrective poses for the body, let's wrap up this course with some resources that may be helpful. All of the online resources and links to some of the tools discussed today can be found by following the URLs on this slide."},{"start":"9:07","end":"9:41","startSec":547.0,"text":"Feel free to pause here or take a screenshot for later reference. In the Resources section, you will find links to the DNA Calibration Repository on GitHub and the 2023 DNA Calibration Deep Dive Demonstration. There is also a link to the Pose Driver Connect plugin on FAB and a tutorial on how to use the Pose Driver Connect Tool Set from the Epic Games Developer Community. This brings us to the end of the MetaHuman DNA Calibration and Finalization course."},{"start":"9:41","end":"10:03","startSec":581.0,"text":"As mentioned at the beginning of the course, with newer engine versions, some of the MetaHuman customization workflows have changed, and we will explore the new workflows in a future update. I want to thank you for spending your time with me and I hope that these videos help you as you continue working with MetaHumans in Unreal Engine."}]}}